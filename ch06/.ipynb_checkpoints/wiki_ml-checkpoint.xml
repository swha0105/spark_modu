<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.36.0-wmf.27</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="446" case="first-letter">Education Program</namespace>
      <namespace key="447" case="first-letter">Education Program talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>Bongard problem</title>
    <ns>0</ns>
    <id>1191936</id>
    <revision>
      <id>968951391</id>
      <parentid>964905991</parentid>
      <timestamp>2020-07-22T14:09:27Z</timestamp>
      <contributor>
        <username>Jukebokks</username>
        <id>37252050</id>
      </contributor>
      <minor/>
      <comment>/* External links */ added link to The On-Line Encyclopedia of Bongard Problems</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="4671" xml:space="preserve">[[File:Bongard_problem_convex_polygons.svg|thumb|300px|An example Bongard problem, the common factor of the left set being convex shapes (the right set are instead all concave).]]
A '''Bongard problem''' is a kind of puzzle invented by the Russian [[computer scientist]] [[Mikhail Moiseevich Bongard]] (Михаил Моисеевич Бонгард, 1924–1971), probably in the mid-1960s. They were published in his 1967 book on [[pattern recognition]]. The objective is to spot the differences between the two sides. Bongard, in the introduction of the book (which deals with a number of topics including [[perceptron]]s) credits the ideas in it to a group including [[M. N. Vaintsvaig]], [[V. V. Maksimov]], and [[M. S. Smirnov]].

==Overview==
The idea of a Bongard problem is to present two sets of relatively simple diagrams, say ''A'' and ''B''. All the diagrams from set ''A'' have a common factor or attribute, which is lacking in all the diagrams of set ''B''. The problem is to find, or to formulate, convincingly, the common factor. The problems were popularised by their occurrence in the 1979 book ''[[Gödel, Escher, Bach]]'' by [[Douglas Hofstadter]], himself a composer of Bongard problems. According to Hofstadter, "the skill of solving Bongard  problems lies very close to the core of "pure" intelligence, if there is such a thing".&lt;ref&gt;''[[Gödel, Escher, Bach]]'', [[Douglas Hofstadter]], Twentieth anniversary Edition, 1999, Artificial Intelligence: Prospects, p. 662&lt;/ref&gt; Bongard problems are also at the heart of the game [[Zendo (game)|Zendo]].

==Scientific works on Bongard problems==

* Bongard, M. M. (1970). Pattern Recognition. Rochelle Park, N.J.: Hayden Book Co., Spartan Books.  (Original publication: Проблема Узнавания, Nauka Press, Moscow, 1967)
* Maksimov, V. V. (1975). Система, обучающаяся классификации геометрических изображений (A system capable of learning to classify geometric images; as translated from the Russian by Marina Eskina), in Моделирование Обучения и Поведения (Modeling of Learning and Behavior, in Russian), M.S. Smirnov, V.V. Maksimov (eds.), Nauka, Moskva.
* Hofstadter, D. R. (1979). Gödel, Escher, Bach: an Eternal Golden Braid. New York: Basic Books.
* Montalvo, F. S. (1985). Diagram Understanding: the Intersection of Computer Vision and Graphics. M.I.T. Artificial Intelligence Laboratory, A. I. Memo 873, November 1985.
* Saito, K., and Nakano, R. (1993) A Concept Learning Algorithm with Adaptive Search. Proceedings of Machine Intelligence 14 Workshop. Oxford University Press. See pp.&amp;nbsp;347–363.
* Hofstadter, D. R. and the Fluid Analogies Research Group (1995). [[Fluid Concepts and Creative Analogies|Fluid Concepts and Creative Analogies: Computer Models of the Fundamental Mechanisms of Thought]]. New York: Basic Books.
* Hofstadter, D. R. (1995). On Seeing A’s and Seeing As. Stanford Humanities Review 4/2 pp.&amp;nbsp;109–121.
* Hofstadter, D. R. (1997). Le Ton beau de Marot. New York: Basic Books.
* Linhares, A. (2000). [http://app.ebape.fgv.br/comum/arq/Linhares2.pdf A glimpse at the metaphysics of Bongard problems]. [[Artificial Intelligence (journal)|Artificial Intelligence]], Volume 121, Issue 1-2, pp.&amp;nbsp;251–270.
* Foundalis, H. (2006). Phaeaco: A Cognitive Architecture Inspired by Bongard’s Problems. Doctoral dissertation, Indiana University, Center for Research on Concepts and Cognition (CRCC), Bloomington, Indiana. Foundalis left the field in 2008 due to ethical concerns regarding machines that can pass as human, and restarted in 2011 having considered that human suicide bombers are already here anyway.&lt;ref&gt;{{cite web|url=http://www.foundalis.com/soc/why_no_more_Bongard.html|accessdate=28 June 2020|title=Why I stopped working on the Bongard Problems|author=Harry Foundalis}}&lt;/ref&gt;
* Anastasiade, J., and Szalwinski, C. (2010). Building Computer-Based Tutors to Help Learners Solve Ill-Structured Problems. In [http://aace.org/conf/edmedia Proceedings of the World Conference on Educational Multimedia, Hypermedia and Telecommunications 2010]. Toronto, Ontario, Canada: Association for the Advancement of Computing in Education. pp.&amp;nbsp;3726–3732.

==References==
&lt;references/&gt;
==External links==
{{Wikibooks|Puzzles|Bongard problems}}
*[http://www.oebp.org The On-Line Encyclopedia of Bongard Problems]
*[http://www.foundalis.com/res/bps/bpidx.htm Index of Bongard problems]


[[Category:Puzzles]]
[[Category:Machine learning]]
[[Category:Cognitive science]]
[[Category:Cognitive psychology]]
[[Category:Computer-related introductions in 1967]]</text>
      <sha1>q1i79zgs6od3jam7thkdvna44an5v7d</sha1>
    </revision>
  </page>
  <page>
    <title>Generative model</title>
    <ns>0</ns>
    <id>1222578</id>
    <revision>
      <id>1004813011</id>
      <parentid>1004812143</parentid>
      <timestamp>2021-02-04T14:43:47Z</timestamp>
      <contributor>
        <username>Jordi Burguet Castell</username>
        <id>10149</id>
      </contributor>
      <comment>/* Deep Generative Models */ link to variational autoencoder</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="18305" xml:space="preserve">{{About|generative models in the context of statistical classification|generative models of [[Markov decision processes]]|Markov decision process#Simulator models}}
In [[statistical classification]], two main approaches are called the '''generative''' approach and the '''discriminative''' approach. These compute [[classification rule|classifiers]] by different approaches, differing in the degree of [[statistical model]]ling. Terminology is inconsistent,{{efn|Three leading sources, {{harvnb|Ng|Jordan|2002}}, {{harvnb|Jebara|2004}}, and {{harvnb|Mitchell|2015}}, give different divisions and definitions.}} but three major types can be distinguished, following {{harvtxt|Jebara|2004}}:
* Given an [[observable variable]] ''X'' and a [[target variable]] ''Y'', a '''generative model''' is a [[statistical model]] of the [[joint probability distribution]] on ''X''&amp;nbsp;×&amp;nbsp;''Y'', &lt;math&gt;P(X, Y)&lt;/math&gt;;&lt;ref name="ngjordan2002generative"&gt;{{harvtxt|Ng|Jordan|2002}}: "Generative classifiers learn a model of the joint probability, &lt;math&gt;p(x, y)&lt;/math&gt;, of the inputs ''x'' and the label ''y'', and make their predictions by using Bayes rules to calculate &lt;math&gt;p(y|x)&lt;/math&gt;, and then picking the most likely label ''y''.&lt;/ref&gt;
* A '''[[discriminative model]]''' is a model of the [[conditional probability]] of the target ''Y'', given an observation ''x'', symbolically, &lt;math&gt;P(Y|X = x)&lt;/math&gt;; and 
* Classifiers computed without using a probability model are also referred to loosely as "discriminative". 
The distinction between these last two classes is not consistently made;&lt;ref&gt;{{harvnb|Jebara|2004|loc=2.4 Discriminative Learning}}: "This distinction between conditional learning and discriminative learning is not currently a well established convention in the field."&lt;/ref&gt; {{harvtxt|Jebara|2004}} refers to these three classes as ''generative learning'', ''conditional learning'', and ''discriminative learning'', but {{harvtxt|Ng|Jordan|2002}} only distinguish two classes, calling them '''generative classifiers''' (joint distribution) and '''discriminative classifiers''' (conditional distribution or no distribution), not distinguishing between the latter two classes.&lt;ref&gt;{{harvnb|Ng|Jordan|2002}}: "Discriminative classifiers model the posterior &lt;math&gt;p(y|x)&lt;/math&gt; directly, or learn a direct map from inputs ''x'' to the class labels."&lt;/ref&gt; Analogously, a classifier based on a generative model is a '''generative classifier''', while a classifier based on a discriminative model is a '''discriminative classifier''', though this term also refers to classifiers that are not based on a model.

Standard examples of each, all of which are [[linear classifier]]s, are:

* generative classifiers: 
** [[naive Bayes classifier]] and 
** [[linear discriminant analysis]]
* discriminative model: 
** [[logistic regression]]

In application to classification, one wishes to go from an observation ''x'' to a label ''y'' (or probability distribution on labels). One can compute this directly, without using a probability distribution (''distribution-free classifier''); one can estimate the probability of a label given an observation, &lt;math&gt;P(Y|X=x)&lt;/math&gt; (''discriminative model''), and base classification on that; or one can estimate the joint distribution &lt;math&gt;P(X, Y)&lt;/math&gt; (''generative model''), from that compute the conditional probability &lt;math&gt;P(Y|X=x)&lt;/math&gt;, and then base classification on that. These are increasingly indirect, but increasingly probabilistic, allowing more domain knowledge and probability theory to be applied. In practice different approaches are used, depending on the particular problem, and hybrids can combine strengths of multiple approaches.

== Definition ==
An alternative division defines these symmetrically as:

* a '''generative model''' is a model of the conditional probability of the observable ''X'', given a target ''y'', symbolically, &lt;math&gt;P(X|Y = y)&lt;/math&gt;&lt;ref name="mitchell2015generative"&gt;{{harvnb|Mitchell|2015}}: "We can use Bayes rule as the basis for designing learning algorithms (function approximators), as follows: Given that we wish to learn some target function &lt;math&gt;f\colon X \to Y&lt;/math&gt;, or equivalently, &lt;math&gt;P(Y|X)&lt;/math&gt;, we use the training data to learn estimates of &lt;math&gt;P(X|Y)&lt;/math&gt; and &lt;math&gt;P(Y)&lt;/math&gt;. New ''X'' examples can then be classified using these estimated probability distributions, plus Bayes rule. This type of classifier is called a ''generative'' classifier, because we can view the distribution &lt;math&gt;P(X|Y)&lt;/math&gt; as describing how to generate random instances ''X'' conditioned on the target attribute ''Y''.&lt;/ref&gt;
* a '''discriminative model''' is a model of the conditional probability of the target ''Y'', given an observation ''x'', symbolically, &lt;math&gt;P(Y|X = x)&lt;/math&gt;&lt;ref name="mitchell2015discriminative"&gt;{{harvnb|Mitchell|2015}}: "Logistic Regression is a function approximation algorithm that uses training data to directly estimate &lt;math&gt;P(Y|X)&lt;/math&gt;, in contrast to Naive Bayes. In this sense, Logistic Regression is often referred to as a ''discriminative'' classifier because we can view the distribution &lt;math&gt;P(Y|X)&lt;/math&gt; as directly discriminating the value of the target value ''Y'' for any given instance ''X''&lt;/ref&gt;

Regardless of precise definition, the terminology is constitutional because a generative model can be used to "generate" random instances ([[outcome (probability)|outcomes]]), either of an observation and target &lt;math&gt;(x, y)&lt;/math&gt;, or of an observation ''x'' given a target value ''y'',&lt;ref name="mitchell2015generative"/&gt; while a discriminative model or discriminative classifier (without a model) can be used to "discriminate" the value of the target variable ''Y'', given an observation ''x''.&lt;ref name="mitchell2015discriminative"/&gt; The difference between "[[wikt:discriminate|discriminate]]" (distinguish) and "[[wikt:classify|classify]]" is subtle, and these are not consistently distinguished. (The term "discriminative classifier" becomes a [[wikt:pleonasm|pleonasm]] when "discrimination" is equivalent to "classification".)

The term "generative model" is also used to describe models that generate instances of output variables in a way that has no clear relationship to probability distributions over potential samples of input variables. [[Generative adversarial networks]] are examples of this class of generative models, and are judged primarily by the similarity of particular outputs to potential inputs. Such models are not classifiers.

=== Relationships between models ===
In application to classification, the observable ''X'' is frequently a [[continuous variable]], the target ''Y'' is generally a [[discrete variable]] consisting of a finite set of labels, and the conditional probability &lt;math&gt;P(Y|X)&lt;/math&gt; can also be interpreted as a (non-deterministic) [[target function]] &lt;math&gt;f\colon X \to Y&lt;/math&gt;, considering ''X'' as inputs and ''Y'' as outputs.

Given a finite set of labels, the two definitions of "generative model" are closely related. A model of the conditional distribution &lt;math&gt;P(X|Y = y)&lt;/math&gt; is a model of the distribution of each label, and a model of the joint distribution is equivalent to a model of the distribution of label values &lt;math&gt;P(Y)&lt;/math&gt;, together with the distribution of observations given a label, &lt;math&gt;P(X|Y)&lt;/math&gt;; symbolically, &lt;math&gt;P(X, Y) = P(X|Y)P(Y).&lt;/math&gt; Thus, while a model of the joint probability distribution is more informative than a model of the distribution of label (but without their relative frequencies), it is a relatively small step, hence these are not always distinguished.

Given a model of the joint distribution, &lt;math&gt;P(X, Y)&lt;/math&gt;, the distribution of the individual variables can be computed as the [[marginal distribution]]s &lt;math&gt;P(X) = \sum_y P(X , Y = y)&lt;/math&gt; and &lt;math&gt;P(Y) = \int_x P(Y, X = x)&lt;/math&gt; (considering ''X'' as continuous, hence integrating over it, and ''Y'' as discrete, hence summing over it), and either conditional distribution can be computed from the definition of [[conditional probability]]: &lt;math&gt;P(X|Y)=P(X, Y)/P(Y)&lt;/math&gt; and &lt;math&gt;P(Y|X)=P(X, Y)/P(X)&lt;/math&gt;.

Given a model of one conditional probability, and estimated [[probability distribution]]s for the variables ''X'' and ''Y'', denoted &lt;math&gt;P(X)&lt;/math&gt; and &lt;math&gt;P(Y)&lt;/math&gt;, one can estimate the opposite conditional probability using [[Bayes' rule]]:
:&lt;math&gt;P(X|Y)P(Y) = P(Y|X)P(X).&lt;/math&gt;
For example, given a generative model for &lt;math&gt;P(X|Y)&lt;/math&gt;, one can estimate:
:&lt;math&gt;P(Y|X) = P(X|Y)P(Y)/P(X),&lt;/math&gt;
and given a discriminative model for &lt;math&gt;P(Y|X)&lt;/math&gt;, one can estimate:
:&lt;math&gt;P(X|Y) = P(Y|X)P(X)/P(Y).&lt;/math&gt;
Note that Bayes' rule (computing one conditional probability in terms of the other) and the definition of conditional probability (computing conditional probability in terms of the joint distribution) are frequently conflated as well.

==Contrast with discriminative classifiers==
A generative algorithm models how the data was generated in order to categorize a signal. It asks the question: based on my generation assumptions, which category is most likely to generate this signal? A discriminative algorithm does not care about how the data was generated, it simply categorizes a given signal. So, discriminative algorithms try to learn &lt;math&gt;p(y|x)&lt;/math&gt; directly from the data and then try to classify data. On the other hand, generative algorithms try to learn &lt;math&gt;p(x,y)&lt;/math&gt; which can be transformed into &lt;math&gt;p(y|x)&lt;/math&gt; later to classify the data. One of the advantages of generative algorithms is that you can use &lt;math&gt;p(x,y)&lt;/math&gt; to generate new data similar to existing data. On the other hand, discriminative algorithms generally give better performance in classification tasks.&lt;ref&gt;{{harvnb|Ng|Jordan|2002}}&lt;/ref&gt;

Despite the fact that discriminative models do not need to model the distribution of the observed variables, they cannot generally express complex relationships between the observed and target variables. They don't necessarily perform better than generative models at [[Classification (machine learning)|classification]] and [[Regression analysis|regression]] tasks. The two classes are seen as complementary or as different views of the same procedure.&lt;ref&gt;{{citation|editor-first=J. M. |editor-last=Bernardo|title=Bayesian statistics 8: proceedings of the eighth Valencia International Meeting, June 2-6, 2006|url={{google books |plainurl=y |id=Vh7vAAAAMAAJ|page=3}}|date=24 September 2007|publisher=Oxford University Press|isbn=978-0-19-921465-5|first1=C. M. |last1=Bishop |first2=J. |last2=Lasserre |contribution=Generative or Discriminative? getting the best of both worlds |pp=3–23}}&lt;/ref&gt;

== Deep Generative Models ==
With the rise of deep learning, a new family of methods, called deep generative models (DGMs),&lt;ref name="auto1"&gt;{{Cite web|url=https://www.microsoft.com/en-us/research/blog/a-deep-generative-model-trifecta-three-advances-that-work-towards-harnessing-large-scale-power/|title=Scaling up—researchers advance large-scale deep generative models|date=April 9, 2020}}&lt;/ref&gt;&lt;ref name="auto"&gt;{{Cite web|url=https://openai.com/blog/generative-models/|title=Generative Models|date=June 16, 2016|website=OpenAI}}&lt;/ref&gt; is formed through the combination of generative models and deep neural networks. The trick of DGMs is that the neural networks used as generative models have a number of parameters significantly smaller than the amount of data used to train them on, so the models are forced to discover and efficiently internalize the essence of the data in order to generate it. 

Popular DGMs include [[Autoencoder#Variational autoencoder (VAE)|Variational Autoencoders]] (VAEs), Generative Adversarial Networks (GANs), and auto-regressive models. There is a trend to build large deep generative models.&lt;ref name="auto1"/&gt; For example, [[GPT-3]], and its precursor GPT-2,&lt;ref&gt;{{Cite web|url=https://openai.com/blog/better-language-models/|title=Better Language Models and Their Implications|date=February 14, 2019|website=OpenAI}}&lt;/ref&gt; for auto-regressive neural language models, BigGAN&lt;ref&gt;{{Cite arXiv |eprint = 1809.11096|last1 = Brock|first1 = Andrew|last2 = Donahue|first2 = Jeff|last3 = Simonyan|first3 = Karen|title = Large Scale GAN Training for High Fidelity Natural Image Synthesis|year = 2018|class = cs.LG}}&lt;/ref&gt; and VQ-VAE&lt;ref&gt;{{Cite arXiv |eprint = 1906.00446|last1 = Razavi|first1 = Ali|author2 = Aaron van den Oord|last3 = Vinyals|first3 = Oriol|title = Generating Diverse High-Fidelity Images with VQ-VAE-2|year = 2019|class = cs.LG}}&lt;/ref&gt; for image generation, Optimus&lt;ref&gt;{{Cite arXiv |eprint = 2004.04092|last1 = Li|first1 = Chunyuan|last2 = Gao|first2 = Xiang|last3 = Li|first3 = Yuan|last4 = Li|first4 = Xiujun|last5 = Peng|first5 = Baolin|last6 = Zhang|first6 = Yizhe|last7 = Gao|first7 = Jianfeng|title = Optimus: Organizing Sentences via Pre-trained Modeling of a Latent Space|year = 2020|class = cs.CL}}&lt;/ref&gt; as the largest VAE language model, and jukebox as the largest VAE model for music generation.&lt;ref&gt;{{Cite web|url=https://openai.com/blog/jukebox/|title=Jukebox|date=April 30, 2020|website=OpenAI}}&lt;/ref&gt;

DGMs have many short-term applications. But in the long run, they hold the potential to automatically learn the natural features of a dataset, whether categories or dimensions or something else entirely.&lt;ref name="auto"/&gt;

== Types ==

=== Generative models ===

Types of generative models are:

* [[Gaussian mixture model]] (and other types of [[mixture model]])
* [[Hidden Markov model]]
* [[Stochastic context-free grammar|Probabilistic context-free grammar]]
* [[Bayesian network]] (e.g. [[Naive bayes]], [[Autoregressive model]])
* [[Averaged one-dependence estimators]]
* [[Latent Dirichlet allocation]]
* [[Boltzmann machine]] (e.g. [[Restricted Boltzmann machine]], [[Deep belief network]])
* [[Autoencoder#Variational autoencoder (VAE)|Variational autoencoder]]
* [[Generative adversarial network]]
* [[Flow-based generative model]]
*[[Energy based model]]

If the observed data are truly sampled from the generative model, then fitting the parameters of the generative model to [[maximum likelihood estimation|maximize the data likelihood]] is a common method. However, since most statistical models are only approximations to the ''true'' distribution, if the model's application is to infer about a subset of variables conditional on known values of others, then it can be argued that the approximation makes more assumptions than are necessary to solve the problem at hand. In such cases, it can be more accurate to model the conditional density functions directly using a [[discriminative model]] (see below), although application-specific details will ultimately dictate which approach is most suitable in any particular case.

=== Discriminative models ===

* [[k-nearest neighbors algorithm]]
* [[Logistic regression]]
* [[Support Vector Machines]]
* [[Decision Trees]]
* [[Random Forest]]
* [[Maximum-entropy Markov model]]s
* [[Conditional random field]]s
* [[Neural network]]s

== Examples ==
=== Simple example ===
Suppose the input data is &lt;math&gt;x \in \{1, 2\}&lt;/math&gt;, the set of labels for &lt;math&gt;x&lt;/math&gt; is &lt;math&gt;y \in \{0, 1\}&lt;/math&gt;, and there are the following 4 data points:
&lt;math&gt;(x,y) = \{(1,0), (1,1), (2,0)\}&lt;/math&gt;

For the above data, estimating the joint probability distribution &lt;math&gt;p(x,y)&lt;/math&gt; from the [[empirical measure]] will be the following:
{| class="wikitable"
|-
!  !! &lt;math&gt;y=0
&lt;/math&gt;!! &lt;math&gt;y=1
&lt;/math&gt;
|-
| &lt;math&gt;x=1
&lt;/math&gt; || &lt;math&gt;4/9
&lt;/math&gt; ||&lt;math&gt;1/9
&lt;/math&gt;
|-
| &lt;math&gt;x=2
&lt;/math&gt; || &lt;math&gt;2/9
&lt;/math&gt; || &lt;math&gt;2/9
&lt;/math&gt;
|}

while &lt;math&gt;p(y|x)&lt;/math&gt; will be following:
{| class="wikitable"
|-
!  !! &lt;math&gt;y=0
&lt;/math&gt; !! &lt;math&gt;y=1
&lt;/math&gt;
|-
| &lt;math&gt;x=1
&lt;/math&gt;
| &lt;math&gt;1/2

&lt;/math&gt; || &lt;math&gt;1/2
&lt;/math&gt;
|-
| &lt;math&gt;x=2
&lt;/math&gt; || &lt;math&gt;1
&lt;/math&gt; || &lt;math&gt;0
&lt;/math&gt;
|}

=== Text generation ===
{{harvtxt|Shannon|1948}} gives an example in which a table of frequencies of English word pairs is used to generate a sentence beginning with "representing and speedily is an good"; which is not proper English but which will increasingly approximate it as the table is moved from word pairs to word triplets etc.

== See also ==
{{Portal|Mathematics}}
* [[Discriminative model]]
* [[Graphical model]]

==Notes==
{{notelist}}

==References==
{{reflist}}

==External links==
{{refbegin}}
* {{cite journal |authorlink=Claude Shannon |last=Shannon |first=C. E. |year=1948 |url=https://www.tnt.uni-hannover.de/edu/vorlesungen/InfoTheor/download/shannon1948.pdf |title=A Mathematical Theory of Communication |journal=[[Bell System Technical Journal]] |volume=27 |pages=379–423, 623–656 |issue=July, October|doi=10.1002/j.1538-7305.1948.tb01338.x |hdl=10338.dmlcz/101429 }}
* {{cite book |authorlink=Tom M. Mitchell |first=Tom M. |last=Mitchell |title=Machine Learning |year=2015 |chapter=3. Generative and Discriminative Classifiers: Naive Bayes and Logistic Regression |chapter-url=https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf }}
* {{cite journal |last1=Ng |first1=Andrew Y. |authorlink1=Andrew Ng |first2=Michael I. |last2=Jordan |authorlink2=Michael I. Jordan
 |title=On discriminative vs. generative classifiers: A comparison of logistic regression and naive bayes. |journal=Advances in Neural Information Processing Systems |url=http://robotics.stanford.edu/~ang/papers/nips01-discriminativegenerative.pdf |year=2002}}
* {{cite book |first=Tony |last=Jebara |title=Machine Learning: Discriminative and Generative |series=The Springer International Series in Engineering and Computer Science |publisher=Kluwer Academic (Springer) |year=2004 |isbn=978-1-4020-7647-3 |url=https://www.springer.com/us/book/9781402076473|ref=harv}}
* {{cite thesis |type=PhD |last=Jebara |first=Tony |date=2002 |title=Discriminative, generative, and imitative learning |publisher=[[Massachusetts Institute of Technology]] |hdl=1721.1/8323}}, ([https://www.cs.columbia.edu/~jebara/papers/jebara4.pdf mirror], [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.7.513&amp;rep=rep1&amp;type=pdf mirror]), published as book (above)
{{refend}}

{{Statistics|state=expanded}}

[[Category:Machine learning]]
[[Category:Statistical models]]
[[Category:Probabilistic models]]</text>
      <sha1>mcs8j9bn94z5gp6w56qb92s0g2rleua</sha1>
    </revision>
  </page>
  <page>
    <title>Inductive bias</title>
    <ns>0</ns>
    <id>173926</id>
    <revision>
      <id>997138626</id>
      <parentid>997138470</parentid>
      <timestamp>2020-12-30T04:42:53Z</timestamp>
      <contributor>
        <ip>49.204.227.31</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="4854" xml:space="preserve">The '''inductive bias''' (also known as '''learning bias''') of a learning algorithm is the set of assumptions that the learner uses to predict outputs of given inputs that it has not encountered.&lt;ref name=Mitchell1980&gt;
{{Citation
 | last = Mitchell
 | first = T. M.
 | title = The need for biases in learning generalizations
 | place = New Brunswick, New Jersey, USA
 | publisher = Rutgers University
 | series = CBM-TR 5-110
 | year = 1980
 | citeseerx = 10.1.1.19.5466
 }}
&lt;/ref&gt;

In [[machine learning]], one aims to construct algorithms that are able to ''learn'' to predict a certain target output. To achieve this, the learning algorithm is presented some training examples that demonstrate the intended relation of input and output values. Then the learner is supposed to approximate the correct output, even for examples that have not been shown during training.  Without any additional assumptions, this problem cannot be solved since unseen situations might have an arbitrary output value. The kind of necessary assumptions about the nature of the target function are subsumed in the phrase ''inductive bias''.&lt;ref name=Mitchell1980 /&gt;&lt;ref name=DesJardinsandGordon1995&gt;
{{Citation
 | last = DesJardins
 | first = M.
 | last2 = Gordon
 | first2 = D. F.
 | author2-link =
 | title = Evaluation and selection of biases in machine learning
 | series = Machine Learning Journal
 | volume = 5:1--17
 | year = 1995
 | url = http://citeseer.ist.psu.edu/article/desjardins95evaluation.html
}}
&lt;/ref&gt;

A classical example of an inductive bias is [[Occam's razor]], assuming that the simplest consistent hypothesis about the target function is actually the best. Here ''consistent'' means that the hypothesis of the learner yields correct outputs for all of the examples that have been given to the algorithm.

Approaches to a more formal definition of inductive bias are based on [[mathematical logic]]. Here, the inductive bias is a logical formula that, together with the training data, logically entails the hypothesis generated by the learner. However, this strict formalism fails in many practical cases, where the inductive bias can only be given as a rough description (e.g. in the case of [[artificial neural networks]]), or not at all.

==Types==

The following is a list of common inductive biases in machine learning algorithms.

* '''Maximum [[conditional independence]]''': if the hypothesis can be cast in a [[Bayesian inference|Bayesian]] framework, try to maximize conditional independence. This is the bias used in the [[Naive Bayes classifier]].
* '''Minimum [[Cross-validation (statistics)|cross-validation]] error''': when trying to choose among hypotheses, select the hypothesis with the lowest cross-validation error. Although cross-validation may seem to be free of bias, the [[No free lunch in search and optimization|"no free lunch"]] theorems show that cross-validation must be biased.
* '''Maximum margin''': when drawing a boundary between two classes, attempt to maximize the width of the boundary. This is the bias used in [[support vector machines]]. The assumption is that distinct classes tend to be separated by wide boundaries.
* '''[[Minimum description length]]''': when forming a hypothesis, attempt to minimize the length of the description of the hypothesis. The assumption is that simpler hypotheses are more likely to be true. See [[Occam's razor]].
* '''Minimum features''': unless there is good evidence that a [[feature space|feature]] is useful, it should be deleted. This is the assumption behind [[feature selection]] algorithms.
* '''Nearest neighbors''': assume that most of the cases in a small neighborhood in [[feature space]] belong to the same class. Given a case for which the class is unknown, guess that it belongs to the same class as the majority in its immediate neighborhood. This is the bias used in the [[k-nearest neighbors algorithm]]. The assumption is that cases that are near each other tend to belong to the same class.

==Shift of bias==

Although most learning algorithms have a static bias, some algorithms are designed to shift their bias as they acquire more data.&lt;ref name=Utgoff1984&gt;
{{Citation
 | last = Utgoff
 | first = P. E.
 | title = Shift of bias for inductive concept learning
 | place = New Brunswick, New Jersey, USA
 | publisher = Doctoral dissertation, Department of Computer Science, Rutgers University
 | year = 1984
 | url = https://books.google.com/?id=f9RylgKpHZsC&amp;pg=PA107&amp;dq=%22Shift+of+bias+for+inductive+concept+learning%22
| isbn = 9780934613002
 }}
&lt;/ref&gt; This does not avoid bias, since the bias shifting process itself must have a bias.

==See also==

* [[Algorithmic bias]]
* [[Cognitive bias]]
* [[No free lunch in search and optimization]]

==References==
{{reflist}}

{{Biases}}

[[Category:Bias]]
[[Category:Machine learning]]


{{Compu-AI-stub}}</text>
      <sha1>4dbjcaqfzw34kx3zfoixthfcd9m21tj</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Bayesian networks</title>
    <ns>14</ns>
    <id>1718975</id>
    <revision>
      <id>547373464</id>
      <parentid>500322264</parentid>
      <timestamp>2013-03-28T02:46:26Z</timestamp>
      <contributor>
        <username>Addbot</username>
        <id>6569922</id>
      </contributor>
      <minor/>
      <comment>[[User:Addbot|Bot:]] Migrating 1 interwiki links, now provided by [[Wikipedia:Wikidata|Wikidata]] on [[d:q8293927]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="122" xml:space="preserve">{{Cat main|Bayesian network}}
[[Category:Graphical models]]
[[Category:Bayesian statistics]]
[[Category:Machine learning]]</text>
      <sha1>k041puhavh5wkhm73874qyh6f0t7qbl</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Classification algorithms</title>
    <ns>14</ns>
    <id>1991254</id>
    <revision>
      <id>753358258</id>
      <parentid>717613671</parentid>
      <timestamp>2016-12-06T18:28:57Z</timestamp>
      <contributor>
        <username>Marcocapelle</username>
        <id>14965160</id>
      </contributor>
      <comment>removed [[Category:Classification]]; added [[Category:Statistical classification]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="320" xml:space="preserve">{{Commons category|Classification algorithms}}
This category is about statistical classification algorithms. For more information, see '''[[Statistical classification]]'''.

[[Category:Categorical data]]
[[Category:Statistical classification|Algorithms]]
[[Category:Data mining algorithms]]
[[Category:Machine learning]]</text>
      <sha1>0kuyvyx6xiuhstiy0pnqx5o7tcvy036</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Evolutionary algorithms</title>
    <ns>14</ns>
    <id>754055</id>
    <revision>
      <id>902071401</id>
      <parentid>753173674</parentid>
      <timestamp>2019-06-16T10:23:26Z</timestamp>
      <contributor>
        <username>Filipović Zoran</username>
        <id>20294490</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="678" xml:space="preserve">{{Commons cat|Evolutionary algorithms}}
An '''evolutionary algorithm''' ('''EA''') is a [[heuristic]] [[Program optimization|optimization]] [[algorithm]] using techniques inspired by mechanisms from [[Evolution|organic evolution]] such as [[mutation]], [[genetic recombination|recombination]], and [[natural selection]] to find an optimal configuration for a specific system within specific constraints. 

{{Cat main|Evolutionary algorithm}}

[[Category:Machine learning]]
[[Category:Algorithms]]
[[Category:Optimization algorithms and methods]]
[[Category:Evolutionary computation]]
[[Category:Artificial life models]]
[[Category:Digital organisms]]
[[Category:Metaheuristics]]</text>
      <sha1>i70r38ajip6k2xa4dauue640egpiz18</sha1>
    </revision>
  </page>
  <page>
    <title>Semi-supervised learning</title>
    <ns>0</ns>
    <id>2829632</id>
    <revision>
      <id>992216837</id>
      <parentid>984076465</parentid>
      <timestamp>2020-12-04T03:06:04Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 17 templates: del empty params (4×); del |ref=harv (1×); cvt lang vals (1×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="20307" xml:space="preserve">{{Machine learning bar}}
[[File:Example of unlabeled data in semisupervised learning.png|thumb|194px|An example of the influence of unlabeled data in semi-supervised learning. The top panel shows a decision boundary we might adopt after seeing only one positive (white circle) and one negative (black circle) example. The bottom panel shows a decision boundary we might adopt if, in addition to the two labeled examples, we were given a collection of unlabeled data (gray circles). This could be viewed as performing [[Cluster analysis|clustering]] and then labeling the clusters with the labeled data, pushing the decision boundary away from high-density regions, or learning an underlying one-dimensional manifold where the data reside.]]

'''Semi-supervised learning''' is an approach to [[machine learning]] that combines a small amount of [[labeled data]] with a large amount of unlabeled data during training. Semi-supervised learning falls between [[unsupervised learning]] (with no labeled training data) and [[supervised learning]] (with only labeled training data).

Unlabeled data, when used in conjunction with a small amount of labeled data, can produce considerable improvement in learning accuracy. The acquisition of labeled data for a learning problem often requires a skilled human agent (e.g. to transcribe an audio segment) or a physical experiment (e.g. determining the 3D structure of a protein or determining whether there is oil at a particular location). The cost associated with the labeling process thus may render large, fully labeled training sets infeasible, whereas acquisition of unlabeled data is relatively inexpensive. In such situations, semi-supervised learning can be of great practical value. Semi-supervised learning is also of theoretical interest in machine learning and as a model for human learning.

A set of &lt;math&gt;l&lt;/math&gt; [[Independent identically distributed|independently identically distributed]] examples &lt;math&gt;x_1,\dots,x_l \in X&lt;/math&gt; with corresponding labels &lt;math&gt;y_1,\dots,y_l \in Y&lt;/math&gt; and &lt;math&gt;u&lt;/math&gt; unlabeled examples &lt;math&gt;x_{l+1},\dots,x_{l+u} \in X&lt;/math&gt; are processed. Semi-supervised learning combines this information to surpass the [[Statistical classification|classification]] performance that can be obtained either by discarding the unlabeled data and doing supervised learning or by discarding the labels and doing unsupervised learning.

Semi-supervised learning may refer to either [[Transduction (machine learning)|transductive learning]] or [[Inductive reasoning|inductive learning]].&lt;ref&gt;{{Cite journal|title=Semi-Supervised Learning Literature Survey, Page 5|citeseerx = 10.1.1.99.9681|year = 2007}}&lt;/ref&gt; The goal of transductive learning is to infer the correct labels for the given unlabeled data &lt;math&gt;x_{l+1},\dots,x_{l+u}&lt;/math&gt; only. The goal of inductive learning is to infer the correct mapping from &lt;math&gt;X&lt;/math&gt; to &lt;math&gt;Y&lt;/math&gt;.

Intuitively, the learning problem can be seen as an exam and labeled data as sample problems that the teacher solves for the class as an aid in solving another set of problems. In the transductive setting, these unsolved problems act as exam questions. In the inductive setting, they become practice problems of the sort that will make up the exam.

It is unnecessary (and, according to [[Vapnik's principle]], imprudent) to perform transductive learning by way of inferring a classification rule over the entire input space; however, in practice, algorithms formally designed for transduction or induction are often used interchangeably.

==Assumptions ==
In order to make any use of unlabeled data, some relationship to the underlying distribution of data must exist. Semi-supervised learning algorithms make use of at least one of the following assumptions:{{sfn|Chapelle|Schölkopf|Zienin|2006}}

===Continuity assumption===
''Points that are close to each other are more likely to share a label.'' This is also generally assumed in supervised learning and yields a preference for geometrically simple [[decision boundary|decision boundaries]]. In the case of semi-supervised learning, the smoothness assumption additionally yields a preference for decision boundaries in low-density regions, so few points are close to each other but in different classes.

===Cluster assumption===
''The data tend to form discrete clusters, and points in the same cluster are more likely to share a label'' (although data that shares a label may spread across multiple clusters). This is a special case of the smoothness assumption and gives rise to [[feature learning]] with clustering algorithms.

===Manifold assumption===
''The data lie approximately on a [[manifold]] of much lower dimension than the input space.'' In this case learning the manifold using both the labeled and unlabeled data can avoid the [[curse of dimensionality]]. Then learning can proceed using distances and densities defined on the manifold.

The manifold assumption is practical when high-dimensional data are generated by some process that may be hard to model directly, but which has only a few degrees of freedom. For instance, human voice is controlled by a few vocal folds,&lt;ref name = "StevensKN"&gt;{{Cite book|title=Acoustic phonetics|last=Stevens, Kenneth N., 1924-|date=1998|publisher=MIT Press|isbn=0-585-08720-2|location=Cambridge, Mass.|oclc=42856189}}&lt;/ref&gt; and images of various facial expressions are controlled by a few muscles. In these cases distances and smoothness in the natural space of the generating problem, is superior to considering the space of all possible acoustic waves or images, respectively.

==History==
The heuristic approach of ''self-training'' (also known as ''self-learning'' or ''self-labeling'') is historically the oldest approach to semi-supervised learning,{{sfn|Chapelle|Schölkopf|Zienin|2006}} with examples of applications starting in the 1960s.&lt;ref&gt;{{Cite journal|last=Scudder|first=H.|date=July 1965|title=Probability of error of some adaptive pattern-recognition machines|journal=IEEE Transactions on Information Theory|volume=11|issue=3|pages=363–371|doi=10.1109/TIT.1965.1053799|issn=1557-9654}}&lt;/ref&gt;

The transductive learning framework was formally introduced by [[Vladimir Vapnik]] in the 1970s.&lt;ref&gt;{{cite book|last1=Vapnik |first1=V. |last2= Chervonenkis |first2=A.|title= Theory of Pattern Recognition |language= ru |publisher= Nauka |location=Moscow |year=1974}} cited in {{harvnb|Chapelle|Schölkopf|Zienin|2006|p= 3}}&lt;/ref&gt; Interest in inductive learning using generative models also began in the 1970s. A [[Probably approximately correct learning|''probably approximately correct'' learning]] bound for semi-supervised learning of a [[Gaussian]] mixture was demonstrated by Ratsaby and Venkatesh in 1995.&lt;ref name="Ratsaby"&gt;{{cite web|last1=Ratsaby |first1=J.|last2= Venkatesh|first2= S. |url=http://www.ariel.ac.il/sites/ratsaby/Publications/PDF/colt95.pdf |title=Learning from a mixture of labeled and unlabeled examples with parametric side information}} in {{Cite book|title=Proceedings of the eighth annual conference on Computational learning theory - COLT '95|date=1995|publisher=ACM Press|isbn=0-89791-723-5|location=New York, New York, USA|pp= 412–417 |doi=10.1145/225298.225348}}. Cited in {{harvnb|Chapelle|Schölkopf|Zienin|2006|p=4}}&lt;/ref&gt;

Semi-supervised learning has recently become more popular and practically relevant due to the variety of problems for which vast quantities of unlabeled data are available—e.g. text on websites, protein sequences, or images.&lt;ref name="survey"&gt;{{cite web|last=Zhu|first= Xiaojin |url=http://pages.cs.wisc.edu/~jerryzhu/pub/ssl_survey.pdf |title=Semi-supervised learning literature survey |publisher= University of Wisconsin-Madison |year=2008}}&lt;/ref&gt;

==Methods==

===Generative models===
Generative approaches to statistical learning first seek to estimate &lt;math&gt;p(x|y)&lt;/math&gt;,{{disputed inline|date=November 2017}} the distribution of data points belonging to each class. The probability &lt;math&gt;p(y|x)&lt;/math&gt; that a given point &lt;math&gt;x&lt;/math&gt; has label &lt;math&gt;y&lt;/math&gt; is then proportional to &lt;math&gt;p(x|y)p(y)&lt;/math&gt; by [[Bayes' theorem|Bayes' rule]]. Semi-supervised learning with [[generative model]]s can be viewed either as an extension of supervised learning (classification plus information about &lt;math&gt;p(x)&lt;/math&gt;) or as an extension of unsupervised learning (clustering plus some labels).

Generative models assume that the distributions take some particular form &lt;math&gt;p(x|y,\theta)&lt;/math&gt; parameterized by the vector &lt;math&gt;\theta&lt;/math&gt;. If these assumptions are incorrect, the unlabeled data may actually decrease the accuracy of the solution relative to what would have been obtained from labeled data alone.&lt;ref&gt;{{Citation|last=Fabio|first=Cozman|title=Risks of Semi-Supervised Learning: How Unlabeled Data Can Degrade Performance of Generative Classifiers|date=2006-09-22|work=Semi-Supervised Learning|pages=56–72|publisher=The MIT Press|isbn=978-0-262-03358-9|last2=Ira|first2=Cohen|doi=10.7551/mitpress/9780262033589.003.0004}} In: {{harvnb|Chapelle|Schölkopf|Zienin|2006}}&lt;/ref&gt; 
However, if the assumptions are correct, then the unlabeled data necessarily improves performance.&lt;ref name = "Ratsaby"/&gt;

The unlabeled data are distributed according to a mixture of individual-class distributions. In order to learn the mixture distribution from the unlabeled data, it must be identifiable, that is, different parameters must yield different summed distributions. Gaussian mixture distributions are identifiable and commonly used for generative models.

The parameterized [[joint distribution]] can be written as &lt;math&gt;p(x,y|\theta)=p(y|\theta)p(x|y,\theta)&lt;/math&gt; by using the [[Chain rule (probability)|chain rule]]. Each parameter vector &lt;math&gt;\theta&lt;/math&gt; is associated with a decision function &lt;math&gt;f_\theta(x) = \underset{y}{\operatorname{argmax}}\ p(y|x,\theta)&lt;/math&gt;. 
The parameter is then chosen based on fit to both the labeled and unlabeled data, weighted by &lt;math&gt;\lambda&lt;/math&gt;:

:&lt;math&gt;\underset{\Theta}{\operatorname{argmax}}\left( \log p(\{x_i,y_i\}_{i=1}^l | \theta) + \lambda \log p(\{x_i\}_{i=l+1}^{l+u}|\theta)\right) &lt;/math&gt;&lt;ref name="SSL_EoML"&gt;Zhu, Xiaojin. [http://pages.cs.wisc.edu/~jerryzhu/pub/SSL_EoML.pdf   Semi-Supervised Learning] University of Wisconsin-Madison.&lt;/ref&gt;

===Low-density separation===
Another major class of methods attempts to place boundaries in regions with few data points (labeled or unlabeled). One of the most commonly used algorithms is the [[Support vector machine#Transductive support vector machines|transductive support vector machine]], or TSVM (which, despite its name, may be used for inductive learning as well). Whereas [[support vector machines]] for supervised learning seek a decision boundary with maximal [[Margin (machine learning)|margin]] over the labeled data, the goal of TSVM is a labeling of the unlabeled data such that the decision boundary has maximal margin over all of the data. In addition to the standard [[hinge loss]] &lt;math&gt;(1-yf(x))_+&lt;/math&gt; for labeled data, a loss function &lt;math&gt;(1-|f(x)|)_+&lt;/math&gt; is introduced over the unlabeled data by letting &lt;math&gt;y=\operatorname{sign}{f(x)}&lt;/math&gt;. TSVM then selects &lt;math&gt;f^*(x) = h^*(x) + b&lt;/math&gt; from a [[reproducing kernel Hilbert space]] &lt;math&gt;\mathcal{H}&lt;/math&gt; by minimizing the [[Regularization (mathematics)|regularized]] [[Empirical risk minimization|empirical risk]]:

:&lt;math&gt;f^* = \underset{f}{\operatorname{argmin}}\left( 
\displaystyle \sum_{i=1}^l(1-y_if(x_i))_+ + \lambda_1 \|h\|_\mathcal{H}^2 + \lambda_2 \sum_{i=l+1}^{l+u} (1-|f(x_i)|)_+
\right) &lt;/math&gt;

An exact solution is intractable due to the non-[[convex function|convex]] term &lt;math&gt;(1-|f(x)|)_+&lt;/math&gt;, so research focuses on useful approximations.&lt;ref name="SSL_EoML"/&gt;

Other approaches that implement low-density separation include Gaussian process models, information regularization, and entropy minimization (of which TSVM is a special case).

===Graph-based methods===
Graph-based methods for semi-supervised learning use a graph representation of the data, with a node for each labeled and unlabeled example. The graph may be constructed using domain knowledge or similarity of examples; two common methods are to connect each data point to its &lt;math&gt;k&lt;/math&gt; nearest neighbors or to examples within some distance &lt;math&gt;\epsilon&lt;/math&gt;. The weight &lt;math&gt;W_{ij}&lt;/math&gt; of an edge between &lt;math&gt;x_i&lt;/math&gt; and &lt;math&gt;x_j&lt;/math&gt; is then set to &lt;math&gt;e^{\frac{-\|x_i-x_j\|^2}{\epsilon}}&lt;/math&gt;.

Within the framework of [[manifold regularization]],&lt;ref&gt;{{cite journal|author1=M. Belkin |author2=P. Niyogi |title=Semi-supervised Learning on Riemannian Manifolds|journal=Machine Learning|volume=56|issue=Special Issue on Clustering|pages=209–239|year=2004|url=http://booksc.org/dl/11288633/421f61|doi=10.1023/b:mach.0000033120.25363.1e|doi-access=free}}&lt;/ref&gt;&lt;ref&gt;M. Belkin, P. Niyogi, V. Sindhwani. On Manifold Regularization. AISTATS 2005.&lt;/ref&gt; the graph serves as a proxy for the manifold. A term is added to the standard [[Tikhonov regularization]] problem to enforce smoothness of the solution relative to the manifold (in the intrinsic space of the problem) as well as relative to the ambient input space. The minimization problem becomes

:&lt;math&gt;\underset{f\in\mathcal{H}}{\operatorname{argmin}}\left(
\frac{1}{l}\displaystyle\sum_{i=1}^l V(f(x_i),y_i) + 
\lambda_A \|f\|^2_\mathcal{H} + 
\lambda_I \int_\mathcal{M}\|\nabla_\mathcal{M} f(x)\|^2dp(x)
\right) &lt;/math&gt;&lt;ref name="SSL_EoML"/&gt;

where &lt;math&gt;\mathcal{H}&lt;/math&gt; is a reproducing kernel [[Hilbert space]] and &lt;math&gt;\mathcal{M}&lt;/math&gt; is the manifold on which the data lie. The regularization parameters &lt;math&gt;\lambda_A&lt;/math&gt; and &lt;math&gt;\lambda_I&lt;/math&gt; control smoothness in the ambient and intrinsic spaces respectively. The graph is used to approximate the intrinsic regularization term. Defining the [[Laplacian matrix|graph Laplacian]] &lt;math&gt;L = D - W&lt;/math&gt; where &lt;math&gt;D_{ii} = \sum_{j=1}^{l+u} W_{ij}&lt;/math&gt; and &lt;math&gt;\mathbf{f}&lt;/math&gt; the vector &lt;math&gt;[f(x_1)\dots f(x_{l+u})]&lt;/math&gt;, we have

:&lt;math&gt;\mathbf{f}^T L \mathbf{f} = \displaystyle\sum_{i,j=1}^{l+u}W_{ij}(f_i-f_j)^2 \approx \int_\mathcal{M}\|\nabla_\mathcal{M} f(x)\|^2dp(x)&lt;/math&gt;.

The Laplacian can also be used to extend the supervised learning algorithms: [[regularized least squares]] and support vector machines (SVM) to semi-supervised versions Laplacian regularized least squares and Laplacian SVM.

===Heuristic approaches===
Some methods for semi-supervised learning are not intrinsically geared to learning from both unlabeled and labeled data, but instead make use of unlabeled data within a supervised learning framework. For instance, the labeled and unlabeled examples &lt;math&gt;x_1,\dots,x_{l+u}&lt;/math&gt; may inform a choice of representation, [[distance metric]], or [[Kernel (statistics)|kernel]] for the data in an unsupervised first step. Then supervised learning proceeds from only the labeled examples.

''Self-training'' is a wrapper method for semi-supervised learning.&lt;ref&gt;{{Cite journal|title = Self-labeled techniques for semi-supervised learning: taxonomy, software and empirical study|journal = Knowledge and Information Systems|date = 2013-11-26|issn = 0219-1377|pages = 245–284|volume = 42|issue = 2|doi = 10.1007/s10115-013-0706-y|language = en|first = Isaac|last = Triguero|first2 = Salvador|last2 = García|first3 = Francisco|last3 = Herrera}}&lt;/ref&gt; First a supervised learning algorithm is trained based on the labeled data only. This classifier is then applied to the unlabeled data to generate more labeled examples as input for the supervised learning algorithm. Generally only the labels the classifier is most confident in are added at each step.&lt;ref&gt;{{Cite journal|title = Self-Trained LMT for Semisupervised Learning|journal = Computational Intelligence and Neuroscience|date = 2015-12-29|pages = 3057481|volume = 2016|doi = 10.1155/2016/3057481|pmid = 26839531|pmc = 4709606|language = en|first = Nikos|last = Fazakis|first2 = Stamatis|last2 = Karlos|first3 = Sotiris|last3 = Kotsiantis|first4 = Kyriakos|last4 = Sgarbas}}&lt;/ref&gt;

[[Co-training]] is an extension of self-training in which multiple classifiers are trained on different (ideally disjoint) sets of features and generate labeled examples for one another.&lt;ref&gt;{{Cite book|title = Analysis of Co-training Algorithm with Very Small Training Sets|publisher = Springer Berlin Heidelberg|date = 2012-11-07|isbn = 9783642341656|pages = 719–726|series = Lecture Notes in Computer Science|language = en|first = Luca|last = Didaci|first2 = Giorgio|last2 = Fumera|first3 = Fabio|last3 = Roli|editor-first = Georgy|editor-last = Gimel’farb|editor-first2 = Edwin|editor-last2 = Hancock|editor-first3 = Atsushi|editor-last3 = Imiya|editor-first4 = Arjan|editor-last4 = Kuijper|editor-first5 = Mineichi|editor-last5 = Kudo|editor-first6 = Shinichiro|editor-last6 = Omachi|editor-first7 = Terry|editor-last7 = Windeatt|editor-first8 = Keiji|editor-last8 = Yamada|doi = 10.1007/978-3-642-34166-3_79}}&lt;/ref&gt;

==In human cognition==
Human responses to formal semi-supervised learning problems have yielded varying conclusions about the degree of influence of the unlabeled data.&lt;ref name="ZhuGoldberg"&gt;
{{Cite book|title=Introduction to semi-supervised learning|last=Zhu|first=Xiaojin|date=2009|publisher=Morgan &amp; Claypool Publishers|others=Goldberg, A. B. (Andrew B.)|isbn=978-1-59829-548-1|location=[San Rafael, Calif.]|oclc=428541480}}&lt;/ref&gt; More natural learning problems may also be viewed as instances of semi-supervised learning. Much of human [[concept learning]] involves a small amount of direct instruction (e.g. parental labeling of objects during childhood) combined with large amounts of unlabeled experience (e.g. observation of objects without naming or counting them, or at least without feedback).

Human infants are sensitive to the structure of unlabeled natural categories such as images of dogs and cats or male and female faces.&lt;ref&gt;{{cite journal |author1=Younger B. A. |author2=Fearing D. D. | year = 1999 | title = Parsing Items into Separate Categories: Developmental Change in Infant Categorization | journal = Child Development | volume = 70 | issue = 2| pages = 291–303 | doi=10.1111/1467-8624.00022}}&lt;/ref&gt; Infants and children take into account not only unlabeled examples, but the [[sampling (statistics)|sampling]] process from which labeled examples arise.&lt;ref&gt;{{cite journal|author1=Xu, F.  |author2=Tenenbaum, J. B. |name-list-style=amp |year=2007|title=Sensitivity to sampling in Bayesian word learning|volume=10|issue=3 |pages=288–297|doi=10.1111/j.1467-7687.2007.00590.x|pmid=17444970 |journal=Developmental Science|citeseerx=10.1.1.141.7505 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal|author=Gweon, H., Tenenbaum J.B., and Schulz L.E|year=2010|title=Infants consider both the sample and the sampling process in inductive generalization|journal=Proc Natl Acad Sci U S A|volume=107|issue=20|pages=9066–71|doi=10.1073/pnas.1003095107|pmid=20435914|pmc=2889113|bibcode=2010PNAS..107.9066G}}&lt;/ref&gt;

==See also==
* [[PU learning]]
*[[Weak supervision]]

==References==
{{Reflist}}

== Sources ==
* {{Cite book  | last1 = Chapelle | first1 = Olivier | last2 = Schölkopf | first2 = Bernhard | last3 = Zien | first3 = Alexander | title = Semi-supervised learning | year = 2006 | publisher = MIT Press | location = Cambridge, Mass. | isbn = 978-0-262-03358-9 }}

==External links==
* [http://manifold.cs.uchicago.edu/manifold_regularization/software.html Manifold Regularization] A freely available [[MATLAB]] implementation of the graph-based semi-supervised algorithms Laplacian support vector machines and Laplacian regularized least squares.
* [http://sci2s.ugr.es/keel/algorithms.php#sub10 KEEL: A software tool to assess evolutionary algorithms for Data Mining problems (regression, classification, clustering, pattern mining and so on)] KEEL module for semi-supervised learning.
* [http://pages.cs.wisc.edu/~jerryzhu/ssl/software.html Semi-Supervised Learning Software] Semi-Supervised Learning Software
* [http://scikit-learn.org/stable/modules/label_propagation.html 1.14. Semi-Supervised — scikit-learn 0.22.1 documentation] Semi-Supervised algorithms in scikit-learn .

[[Category:Machine learning]]</text>
      <sha1>irdah4szs7f4nvirekry2r69wsaqk0y</sha1>
    </revision>
  </page>
  <page>
    <title>Learning automaton</title>
    <ns>0</ns>
    <id>3274742</id>
    <revision>
      <id>968959894</id>
      <parentid>964598442</parentid>
      <timestamp>2020-07-22T15:12:42Z</timestamp>
      <contributor>
        <username>PeterAbernathy</username>
        <id>39794652</id>
      </contributor>
      <minor/>
      <comment>add a demo of learning automaton</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="6669" xml:space="preserve">{{about|automata that learn|computational approaches to learn regular automata|Induction of regular languages}}
A '''learning automaton''' is one type of [[machine learning]] algorithm studied since 1970s. Learning automata select their current action based on past experiences from the environment. It will fall into the range of reinforcement learning if the environment is [[Stochastic process|stochastic]] and a [[Markov decision process]] (MDP) is used.

== History ==
Research in learning automata can be traced back to the work of [[Michael Lvovitch Tsetlin]] in the early 1960s in the Soviet Union. Together with some colleagues, he published a collection of papers on how to use matrices to describe automata functions. Additionally, Tsetlin worked on ''reasonable'' and ''collective automata behaviour'', and on ''automata games''. Learning automata were also investigated by researches in the United States in the 1960s. However, the term ''learning automaton'' was not used until Narendra and Thathachar introduced it in a survey paper in 1974.

== Definition ==
A learning automaton is an adaptive decision-making unit situated in a random environment that learns the optimal action through repeated interactions with its environment. The actions are chosen according to a specific probability distribution which is updated based on the environment response the automaton obtains by performing a particular action.

With respect to the field of [[reinforcement learning]], learning automata are characterized as [[Markov decision process#Policy iteration|policy iterators]]. In contrast to other reinforcement learners, policy iterators directly manipulate the policy π. Another example for policy iterators are [[evolutionary algorithm]]s.

Formally, Narendra and Thathachar define a '''stochastic automaton''' to consist of:
* a set ''X'' of possible inputs,
* a set Φ = { Φ&lt;sub&gt;1&lt;/sub&gt;, ..., Φ&lt;sub&gt;''s''&lt;/sub&gt; } of possible internal states,
* a set α = { α&lt;sub&gt;1&lt;/sub&gt;, ..., α&lt;sub&gt;''r''&lt;/sub&gt; } of possible outputs, or actions, with ''r'' ≤ ''s'',
* an initial state probability vector ''p(0)'' = ≪ ''p''&lt;sub&gt;1&lt;/sub&gt;(0), ..., ''p''&lt;sub&gt;''s''&lt;/sub&gt;(0) ≫,
* a [[computable function]] ''A'' which after each time step ''t'' generates ''p''(''t''+1) from ''p''(''t''), the current input, and the current state, and
* a function ''G'': Φ → α which generates the output at each time step.
In their paper, they investigate only stochastic automata with ''r'' = ''s'' and ''G'' being [[bijective]], allowing them to confuse actions and states.
The states of such an automaton correspond to the states of a "discrete-state discrete-parameter [[Markov process]]".&lt;ref&gt;(Narendra, Thathachar, 1974) p.325 left&lt;/ref&gt;
&lt;!---The following description had to be partly guessed on the base of the usual finite-state automaton definitions, since Narendra and Thathachar are not very explicit about that issue:---&gt;
At each time step ''t''=0,1,2,3,..., the automaton reads an input from its environment, updates ''p''(''t'') to ''p''(''t''+1) by ''A'', randomly chooses a successor state according to the probabilities ''p''(''t''+1) and outputs the corresponding action. The automaton's environment, in turn, reads the action and sends the next input to the automaton.
&lt;!---End of guess.---&gt;
Frequently, the input set ''X'' = { 0,1 } is used, with 0 and 1 corresponding to a ''nonpenalty'' and a ''penalty'' response of the environment, respectively; in this case, the automaton should learn to minimize the number of ''penalty'' responses, and the feedback loop of automaton and environment is called a "P-model". More generally, a "Q-model" allows an arbitrary finite input set ''X'', and an "S-model" uses the [[interval (mathematics)|interval]] [0,1] of [[real numbers]] as ''X''.&lt;ref&gt;(Narendra, Thathachar, 1974) p.325 right&lt;/ref&gt;

A visualised demo&lt;ref&gt;{{Citation|last=JieGH|title=JieGH/The-Ruler-of-Tsetlin-Automaton|date=2019-11-11|url=https://github.com/JieGH/The-Ruler-of-Tsetlin-Automaton|access-date=2020-07-22}}&lt;/ref&gt; &lt;ref&gt;{{Cite web|last=|first=|date=|title=The-Ruler-of-Tsetlin-Automaton|url=https://www.youtube.com/watch?v=LltDhg4ZuWo&amp;feature=youtu.be|url-status=live|archive-url=|archive-date=|access-date=2020-07-22|website=www.youtube.com|language=en}}&lt;/ref&gt;/ Art Work of a single Learning Automaton had been developed by µSystems (microSystems) Research Group at Newcastle University.

== Finite action-set learning automata ==
Finite action-set learning automata (FALA) are a class of learning automata for which the number of possible actions is finite or, in more mathematical terms, for which the size of the action-set is finite.&lt;ref name="Thathachar2002"&gt;{{cite journal|last1=Thathachar|first1=M.A.L.|last2=Sastry|first2=P.S.|title=Varieties of learning automata: an overview|journal=IEEE Transactions on Systems, Man, and Cybernetics - Part B: Cybernetics|date=December 2002|volume=32|issue=6|pages=711–722|doi=10.1109/TSMCB.2002.1049606|pmid=18244878|url=http://eprints.iisc.ac.in/5011/1/varieties.pdf}}&lt;/ref&gt;

==See also==
*[[Reinforcement learning]]
*[[Game theory]]
*[[Automata theory]]

== Literature ==
* Philip Aranzulla and John Mellor &lt;!---
---Trying to flesh out the previous poor reference hint, I found Mellor's home page and added all publications of Mellor+Aranzulla found there. They seem to fit not very well into this article, however.---
---&gt;([https://web.archive.org/web/20131203032954/http://www.bradford.ac.uk/scim/staff-profiles/profile/?u=jemellor Home page]):
** Mellor J and Aranzulla P (2000): "Using an S-Model Response Environment with Learnng Automata Based Routing Schemes for IP Networks ", Proc. Eighth IFIP Workshop on Performance Modelling and Evaluation of ATM and IP Networks, pp 56/1-56/12, Ilkley, UK.
** Aranzulla P and Mellor J (1997): "Comparing two routing algorithms requiring reduced signalling when applied to ATM networks", Proc. Fourteenth UK Teletraffic Symposium on Performance Engineering in Information Systems, pp 20/1-20/4, UMIST, Manchester, UK.
* {{cite journal|authors=Narendra K., Thathachar M.A.L.|title=Learning automata – a survey|journal=IEEE Transactions on Systems, Man, and Cybernetics|date=July 1974| volume= SMC-4| issue=4| pages=323–334| url=http://www.dklevine.com/archive/refs4481.pdf| doi=10.1109/tsmc.1974.5408453|citeseerx=10.1.1.295.2280}}
* [http://lib1.org/_ads/BFD1362D458D7DAECEB7FE60C5673242 Tsetlin M.L. Automation theory and modeling of biological systems. Academic Press; 1973.]{{Dead link|date=February 2020 |bot=InternetArchiveBot |fix-attempted=yes }}

==References==
{{reflist}}

[[Category:Machine learning]]
[[Category:Control theory]]</text>
      <sha1>n5dz2o7r9x98ykjgs4y6atrzlhljbbq</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Machine learning researchers</title>
    <ns>14</ns>
    <id>3832584</id>
    <revision>
      <id>952541507</id>
      <parentid>557550024</parentid>
      <timestamp>2020-04-22T19:51:54Z</timestamp>
      <contributor>
        <ip>50.26.172.216</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="219" xml:space="preserve">[[Researcher]]s who study [[machine learning]].
{{cat see also|Data miners|Artificial intelligence researchers}}

[[Category:Machine learning|Researchers]]
[[Category:Artificial intelligence researchers]]
{{CatAutoTOC}}</text>
      <sha1>9l4hjzbr25q5fw1sg8yahkahhn4v1t0</sha1>
    </revision>
  </page>
  <page>
    <title>Conditional random field</title>
    <ns>0</ns>
    <id>4118276</id>
    <revision>
      <id>1003588205</id>
      <parentid>994257623</parentid>
      <timestamp>2021-01-29T18:29:32Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 14 templates: hyphenate params (3×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="20811" xml:space="preserve">{{multiple issues|
{{context|date=January 2013}}
{{technical|date=June 2012}}
}}

{{machine learning bar}}
'''Conditional random fields''' ('''CRFs''') are a class of [[statistical model|statistical modeling method]] often applied in [[pattern recognition]] and [[machine learning]] and used for [[structured prediction]]. Whereas a [[statistical classification|classifier]] predicts a label for a single sample without considering "neighboring" samples, a CRF can take context into account. To do so, the prediction is modeled as a [[graphical model]], which implements dependencies between the predictions. What kind of graph is used depends on the application. For example, in [[natural language processing]], linear chain CRFs are popular, which implement sequential dependencies in the predictions. In image processing the graph typically connects locations to nearby and/or similar locations to enforce that they receive similar predictions.

Other examples where CRFs are used are: [[sequence labeling|labeling]] or [[parsing]] of sequential data for [[natural language processing]] or [[bioinformatics|biological sequences]],&lt;ref name="Laf:McC:Per01"&gt;{{cite conference | authors = Lafferty, J., McCallum, A., Pereira, F. |
title=Conditional random fields: Probabilistic models for segmenting and labeling sequence data|
book-title =Proc. 18th International Conf. on Machine Learning |
publisher= Morgan Kaufmann|
date = 2001| pages= 282–289|url= http://repository.upenn.edu/cgi/viewcontent.cgi?article=1162&amp;context=cis_papers }}
&lt;/ref&gt; [[POS tagging]], [[shallow parsing]],&lt;ref&gt;{{cite conference| title=shallow parsing with conditional random fields|author1=Sha, F. |author2=Pereira, F. | date=2003 |  url= http://portal.acm.org/ft_gateway.cfm?id=1073473&amp;type=pdf&amp;CFID=4684435&amp;CFTOKEN=39459323}}&lt;/ref&gt; [[named entity recognition]],&lt;ref&gt;{{cite conference|
url=http://www.aclweb.org/anthology/W04-1221.pdf |
title=Biomedical named entity recognition using conditional random fields and rich feature sets |
author= Settles, B.|date=2004|
book-title=Proceedings of the International Joint Workshop on Natural Language Processing in Biomedicine and its Applications |
pages= 104–107}}&lt;/ref&gt; [[Gene prediction|gene finding]], peptide critical functional region finding,&lt;ref&gt;{{cite conference | title = Analysis and Prediction of the Critical Regions of Antimicrobial Peptides Based on Conditional Random Fields. | 
publisher = PLoS ONE |author1=Chang KY |author2=Lin T-p |author3=Shih L-Y |author4=Wang C-K | 
date = 2015 | 
doi = 10.1371/journal.pone.0119490 |pmc=4372350 }}&lt;/ref&gt; and object recognition&lt;ref name="Rui:Gal:Gon15"&gt;{{cite conference | title = UPGMpp: a Software Library for Contextual Object Recognition. | 
author1=J.R. Ruiz-Sarmiento |author2=C. Galindo |author3=J. Gonzalez-Jimenez | 
date = 2015 |  
url= https://www.researchgate.net/publication/281620302 |
book-title= 3rd. Workshop on Recognition and Action for Scene Understanding (REACTS)}}&lt;/ref&gt; and [[image segmentation]] in [[computer vision]].&lt;ref&gt;{{cite news
 | title = Multiscale conditional random fields for image labeling
 | last1 = He | first1 = X. | author-link = Xuming He | last2 = Zemel | first2 = R.S. | last3 = Carreira-Perpinñán | first3 = M.A.
 | date = 2004
 | publisher = IEEE Computer Society
 | citeseerx = 10.1.1.3.7826
 }}&lt;/ref&gt;

==Description==
CRFs are a type of [[discriminative model|discriminative]] [[Markov random field|undirected]] [[Statistical model|probabilistic]] [[graphical model]].

[[John D. Lafferty|Lafferty]], [[Andrew McCallum|McCallum]] and Pereira&lt;ref name="Laf:McC:Per01"/&gt; define a CRF on observations &lt;math&gt;\boldsymbol{X}&lt;/math&gt; and [[random variable]]s &lt;math&gt;\boldsymbol{Y}&lt;/math&gt; as follows:

&lt;blockquote&gt;Let &lt;math&gt;G = (V , E)&lt;/math&gt; be a graph such that
&lt;math&gt;\boldsymbol{Y} = (\boldsymbol{Y}_v)_{v\in V}&lt;/math&gt;,
 so that &lt;math&gt;\boldsymbol{Y}&lt;/math&gt; is indexed by the vertices of &lt;math&gt;G&lt;/math&gt;. 
Then &lt;math&gt;(\boldsymbol{X}, \boldsymbol{Y})&lt;/math&gt; is a conditional random field when the random variables &lt;math&gt;\boldsymbol{Y}_v&lt;/math&gt;, conditioned on &lt;math&gt;\boldsymbol{X}&lt;/math&gt;, obey the [[Markov property]] with
respect to the graph: &lt;math&gt;p(\boldsymbol{Y}_v |\boldsymbol{X}, \boldsymbol{Y}_w, w \neq v) = p(\boldsymbol{Y}_v |\boldsymbol{X}, \boldsymbol{Y}_w, w \sim v)&lt;/math&gt;, where &lt;math&gt;\mathit{w} \sim v&lt;/math&gt; means
that &lt;math&gt;w&lt;/math&gt; and &lt;math&gt;v&lt;/math&gt; are [[Neighbourhood (graph theory)|neighbors]] in &lt;math&gt;G&lt;/math&gt;.
&lt;/blockquote&gt;

What this means is that a CRF is an [[Graphical model|undirected graphical model]] whose nodes can be divided into exactly two disjoint sets &lt;math&gt;\boldsymbol{X}&lt;/math&gt; and &lt;math&gt;\boldsymbol{Y}&lt;/math&gt;, the observed and output variables, respectively; the conditional distribution &lt;math&gt;p(\boldsymbol{Y}|\boldsymbol{X})&lt;/math&gt; is then modeled.

===Inference===
For general graphs, the problem of exact inference in CRFs is intractable. The inference problem for a CRF is basically the same as for an [[Markov random field#Inference|MRF]] and the same arguments hold.&lt;ref name=SuttonIntroduction&gt;{{cite arXiv |last1=Sutton |first1=Charles |last2=McCallum |first2=Andrew |class=stat.ML |year=2010 |eprint=1011.4088v1 |title=An Introduction to Conditional Random Fields}}&lt;/ref&gt;
However, there exist special cases for which exact inference is feasible:

* If the graph is a chain or a tree, message passing algorithms yield exact solutions. The algorithms used in these cases are analogous to the [[forward-backward algorithm|forward-backward]] and [[Viterbi algorithm]] for the case of HMMs.
* If the CRF only contains pair-wise potentials and the energy is [[Submodular function|submodular]], combinatorial min cut/max flow algorithms yield exact solutions.

If exact inference is impossible, several algorithms can be used to obtain approximate solutions. These include:
* [[Belief propagation#Approximate algorithm for general graphs|Loopy belief propagation]]
* Alpha expansion
* Mean field inference
* [[Linear programming relaxation]]s

===Parameter Learning===
Learning the parameters &lt;math&gt;\theta&lt;/math&gt; is usually done by [[maximum likelihood]] learning for &lt;math&gt;p(Y_i|X_i; \theta)&lt;/math&gt;. If all nodes have exponential family distributions and all nodes are observed during training, this [[Optimization (mathematics)|optimization]] is convex.&lt;ref name="SuttonIntroduction" /&gt; It can be solved for example using [[gradient descent]] algorithms, or [[Quasi-Newton method]]s such as the [[L-BFGS]] algorithm. On the other hand, if some variables are unobserved, the inference problem has to be solved for these variables. Exact inference is intractable in general graphs, so approximations have to be used.

===Examples===
In sequence modeling, the graph of interest is usually a chain graph. An input sequence of observed variables &lt;math&gt;X&lt;/math&gt; represents a sequence of observations and &lt;math&gt;Y&lt;/math&gt; represents a hidden (or unknown) state variable that needs to be inferred given the observations. The &lt;math&gt;Y_{i}&lt;/math&gt; are structured to form a chain, with an edge between each &lt;math&gt;Y_{i-1}&lt;/math&gt; and &lt;math&gt;Y_{i}&lt;/math&gt;. As well as having a simple interpretation of the &lt;math&gt;Y_{i}&lt;/math&gt; as "labels" for each element in the input sequence, this layout admits efficient algorithms for:
* model ''training'', learning the conditional distributions between the &lt;math&gt;Y_{i}&lt;/math&gt; and feature functions from some corpus of training data.
* ''decoding'', determining the probability of a given label sequence &lt;math&gt;Y&lt;/math&gt; given &lt;math&gt;X&lt;/math&gt;.
* ''inference'', determining the ''most likely'' label sequence &lt;math&gt;Y&lt;/math&gt; given &lt;math&gt;X&lt;/math&gt;.

The conditional dependency of each &lt;math&gt;Y_{i}&lt;/math&gt; on &lt;math&gt;X&lt;/math&gt; is defined through a fixed set of ''feature functions'' of the form &lt;math&gt;f(i, Y_{i-1}, Y_{i}, X)&lt;/math&gt;, which can be thought of as measurements on the input sequence that partially determine the [[Likelihood function|likelihood]] of each possible value for &lt;math&gt;Y_{i}&lt;/math&gt;. The model assigns each feature a numerical weight and combines them to determine the probability of a certain value for &lt;math&gt;Y_{i}&lt;/math&gt;.

Linear-chain CRFs have many of the same applications as conceptually simpler hidden Markov models (HMMs), but relax certain assumptions about the input and output sequence distributions. An HMM can loosely be understood as a CRF with very specific feature functions that use constant probabilities to model state transitions and emissions. Conversely, a CRF can loosely be understood as a generalization of an HMM that makes the constant transition probabilities into arbitrary functions that vary across the positions in the sequence of hidden states, depending on the input sequence.

Notably, in contrast to HMMs, CRFs can contain any number of feature functions, the feature functions can inspect the entire input sequence &lt;math&gt;X&lt;/math&gt; at any point during inference, and the range of the feature functions need not have a probabilistic interpretation.

==Variants==

===Higher-order CRFs and semi-Markov CRFs===

CRFs can be extended into higher order models by making each &lt;math&gt;Y_{i}&lt;/math&gt; dependent on a fixed number &lt;math&gt;k&lt;/math&gt; of previous variables &lt;math&gt;Y_{i-k}, ..., Y_{i-1}&lt;/math&gt;. In conventional formulations of higher order CRFs, training and inference are only practical for small values of &lt;math&gt;k&lt;/math&gt; (such as ''k'' ≤ 5),&lt;ref&gt;{{cite conference 
| url = http://aclweb.org/anthology/D17-1044
| title = Learning the Structure of Variable-Order CRFs: a Finite-State Perspective
| last1 = Lavergne
| first1 = Thomas
| last2 = Yvon
| first2 = François
| date = September 7, 2017
| publisher = Association for Computational Linguistics
| book-title = Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing
| pages = 433
| location = Copenhagen, Denmark
}}&lt;/ref&gt; since their computational cost increases exponentially with &lt;math&gt;k&lt;/math&gt;.

However, another recent advance has managed to ameliorate these issues by leveraging concepts and tools from the field of Bayesian nonparametrics. Specifically, the CRF-infinity approach&lt;ref&gt;{{cite journal 
| title = The Infinite-Order Conditional Random Field Model for Sequential Data Modeling
| last1 = Chatzis
| first1 = Sotirios
| last2 = Demiris
| first2 = Yiannis
| year = 2013
| journal = IEEE Transactions on Pattern Analysis and Machine Intelligence
| pages = 1523–1534
| volume = 35 | issue = 6
 | doi=10.1109/tpami.2012.208
| pmid = 23599063
| hdl = 10044/1/12614
| hdl-access = free
}}&lt;/ref&gt; constitutes a CRF-type model that is capable of learning infinitely-long temporal dynamics in a scalable fashion. This is effected by introducing a novel potential function for CRFs that is based on the Sequence Memoizer (SM), a nonparametric Bayesian model for learning infinitely-long dynamics in sequential observations.&lt;ref&gt;{{cite conference 
| title = Improvements to the Sequence Memoizer
| last1 = Gasthaus
| first1 = Jan
| last2 = Teh
| first2 = Yee Whye
| year = 2010
| book-title = Proc. NIPS
| url = https://papers.nips.cc/paper/3938-improvements-to-the-sequence-memoizer.pdf
}}&lt;/ref&gt; To render such a model computationally tractable, CRF-infinity employs a [[mean-field approximation]]&lt;ref&gt;{{cite journal 
| title = EM Procedures Using Mean Field-Like Approximations for Markov Model-Based Image Segmentation
| last1 = Celeux
| first1 = G.
| last2 = Forbes
| first2 = F.
| last3 = Peyrard
| first3 = N.
| year = 2003
| journal = Pattern Recognition
| pages = 131–144
| volume = 36 | issue = 1
 | doi=10.1016/s0031-3203(02)00027-4
| citeseerx = 10.1.1.6.9064
}}&lt;/ref&gt; of the postulated novel potential functions (which are driven by an SM). This allows for devising efficient approximate training and inference algorithms for the model, without undermining its capability to capture and model temporal dependencies of arbitrary length.

There exists another generalization of CRFs, the '''semi-Markov conditional random field (semi-CRF)''', which models variable-length ''segmentations'' of the label sequence &lt;math&gt;Y&lt;/math&gt;.&lt;ref&gt;{{Cite book
| publisher = MIT Press
| pages = 1185–1192
|editor= Lawrence K. Saul |editor2=Yair Weiss |editor3=Léon Bottou
| last = Sarawagi
| first = Sunita
| last2 = Cohen
| first2 = William W.
| chapter = Semi-Markov conditional random fields for information extraction
| chapter-url = http://papers.nips.cc/paper/2648-semi-markov-conditional-random-fields-for-information-extraction.pdf
| title = Advances in Neural Information Processing Systems 17
| url = http://papers.nips.cc/book/advances-in-neural-information-processing-systems-17-2004
| location = Cambridge, MA
| year = 2005
}}&lt;/ref&gt; This provides much of the power of higher-order CRFs to model long-range dependencies of the &lt;math&gt;Y_{i}&lt;/math&gt;, at a reasonable computational cost.

Finally, large-margin models for [[structured prediction]], such as the [[Structured SVM|structured Support Vector Machine]] can be seen as an alternative training procedure to CRFs.

===Latent-dynamic conditional random field===
'''Latent-dynamic conditional random fields''' ('''LDCRF''') or '''discriminative probabilistic latent variable models''' ('''DPLVM''') are a type of CRFs for sequence tagging tasks. They are [[latent variable model]]s that are trained discriminatively.

In an LDCRF, like in any sequence tagging task, given a sequence of observations '''x''' = &lt;math&gt;x_1,\dots,x_n&lt;/math&gt;, the main problem the model must solve is how to assign a sequence of labels '''y''' = &lt;math&gt;y_1,\dots,y_n&lt;/math&gt; from one finite set of labels {{mvar|Y}}. Instead of directly modeling {{mvar|P}}('''y'''|'''x''') as an ordinary linear-chain CRF would do, a set of latent variables '''h''' is "inserted" between '''x''' and '''y''' using the [[chain rule of probability]]:&lt;ref name="lvperceptron"&gt;{{cite conference |author1=Xu Sun |author2=Takuya Matsuzaki |author3=Daisuke Okanohara |author4=Jun'ichi Tsujii |title=Latent Variable Perceptron Algorithm for Structured Classification |conference=IJCAI |year=2009 |pages=1236–1242|url=http://www.aaai.org/ocs/index.php/IJCAI/IJCAI-09/paper/download/356/970}}&lt;/ref&gt;

:&lt;math&gt;P(\mathbf{y} | \mathbf{x}) = \sum_\mathbf{h} P(\mathbf{y}|\mathbf{h}, \mathbf{x}) P(\mathbf{h} | \mathbf{x})&lt;/math&gt;

This allows capturing latent structure between the observations and labels.&lt;ref name="morency"&gt;{{Cite book | last1 = Morency | first1 = L. P. | last2 = Quattoni | first2 = A. | last3 = Darrell | first3 = T. | doi = 10.1109/CVPR.2007.383299 | chapter = Latent-Dynamic Discriminative Models for Continuous Gesture Recognition | title = 2007 IEEE Conference on Computer Vision and Pattern Recognition | pages = 1| year = 2007 | isbn = 978-1-4244-1179-5 | chapter-url = http://dspace.mit.edu/bitstream/handle/1721.1/35276/MIT-CSAIL-TR-2007-002.pdf| citeseerx = 10.1.1.420.6836 }}&lt;/ref&gt; While LDCRFs can be trained using quasi-Newton methods, a specialized version of the [[perceptron]] algorithm called the '''latent-variable perceptron''' has been developed for them as well, based on Collins' [[structured perceptron]] algorithm.&lt;ref name="lvperceptron"/&gt; These models find applications in [[computer vision]], specifically [[gesture recognition]] from video streams&lt;ref name="morency"/&gt; and [[shallow parsing]].&lt;ref name="lvperceptron"/&gt;

== Software ==

This is a partial list of software that implement generic CRF tools.
* [https://github.com/zhongkaifu/RNNSharp RNNSharp] CRFs based on recurrent neural networks ([[C Sharp (programming language)|C#]], [[.NET Framework|.NET]])
* [https://web.archive.org/web/20131224113826/http://klcl.pku.edu.cn/member/sunxu/code.htm CRF-ADF] Linear-chain CRFs with fast online ADF training ([[C Sharp (programming language)|C#]], [[.NET Framework|.NET]])
* [https://github.com/zhongkaifu/CRFSharp CRFSharp] Linear-chain CRFs ([[C Sharp (programming language)|C#]], [[.NET Framework|.NET]])
* [http://vision.csd.uwo.ca/code/ GCO] CRFs with submodular energy functions ([[C++]], [[Matlab]])
* [http://research.project-10.de/dgm DGM] General CRFs ([[C++]])
* [http://mallet.cs.umass.edu/grmm/index.php GRMM] General CRFs ([[Java (programming language)|Java]])
* [http://factorie.cs.umass.edu/ factorie] General CRFs ([[Scala (programming language)|Scala]])
* [http://www.cs.ubc.ca/~murphyk/Software/CRFall.zip CRFall] General CRFs ([[MATLAB|Matlab]])
* [http://crf.sourceforge.net/ Sarawagi's CRF] Linear-chain CRFs ([[Java (programming language)|Java]])
* [http://sourceforge.net/projects/hcrf/ HCRF library] Hidden-state CRFs ([[C++]], [[MATLAB|Matlab]])
* [http://accord-framework.net Accord.NET] Linear-chain CRF, HCRF and HMMs ([[C Sharp (programming language)|C#]], [[.NET Framework|.NET]])
* [http://wapiti.limsi.fr/ Wapiti] Fast linear-chain CRFs ([[C (programming language)|C]])&lt;ref&gt;T. Lavergne, O. Cappé and F. Yvon (2010). [http://acl.eldoc.ub.rug.nl/mirror/P/P10/P10-1052.pdf Practical very large scale CRFs] {{webarchive|url=https://web.archive.org/web/20130718001211/http://acl.eldoc.ub.rug.nl/mirror/P/P10/P10-1052.pdf |date=2013-07-18 }}. Proc. 48th Annual Meeting of the [[Association for Computational Linguistics|ACL]], pp. 504-513.&lt;/ref&gt;
* [http://www.chokkan.org/software/crfsuite/ CRFSuite] Fast restricted linear-chain CRFs ([[C (programming language)|C]])
* [https://web.archive.org/web/20100421020327/http://crfpp.sourceforge.net/ CRF++] Linear-chain CRFs ([[C++]])
* [http://flexcrfs.sourceforge.net/ FlexCRFs] First-order and second-order Markov CRFs ([[C++]])
* [http://hackage.haskell.org/package/crf-chain1 crf-chain1] First-order, linear-chain CRFs ([[Haskell (programming language)|Haskell]])
* [https://web.archive.org/web/20190524215850/https://www.cs.rochester.edu/~bhole/code/crf/ imageCRF] CRF for segmenting images and image volumes ([[C++]])
* [http://mallet.cs.umass.edu/ MALLET] Linear-chain for sequence tagging ([[Java (programming language)|Java]])
* [https://pystruct.github.io/ PyStruct] Structured Learning in Python ([[Python (programming language)|Python]])
* [https://github.com/scrapinghub/python-crfsuite Pycrfsuite] A python binding for crfsuite ([[Python (programming language)|Python]])
* [https://github.com/p2t2/figaro Figaro] Probabilistic programming language capable of defining CRFs and other graphical models ([[Scala (programming language)|Scala]])
* [https://cran.r-project.org/web/packages/CRF/CRF.pdf CRF] Modeling and computational tools for CRFs and other undirected graphical models ([[R (programming language)|R]])
* [http://hciweb2.iwr.uni-heidelberg.de/opengm/index.php OpenGM] Library for discrete [[factor graph]] models and distributive operations on these models ([[C++]]) 
* [https://github.com/jotaraul/upgmpp UPGMpp]&lt;ref name="Rui:Gal:Gon15"/&gt; Library for building, training, and performing inference with Undirected Graphical Models ([[C++]]) 
* [http://keg.cs.tsinghua.edu.cn/jietang/software/KEG_CRF/ KEG_CRF] Fast Linear CRFs ([[C++]])

This is a partial list of software that implement CRF related tools.
* [https://github.com/NLPatVCU/medaCy MedaCy] Medical Named Entity Recognizer ([[Python (programming language)|Python]])
* [https://web.archive.org/web/20100112222803/http://www.broadinstitute.org/annotation/conrad/ Conrad] CRF based gene predictor ([[Java (programming language)|Java]])
* [http://nlp.stanford.edu/software/CRF-NER.shtml Stanford NER] Named Entity Recognizer ([[Java (programming language)|Java]])
* [https://web.archive.org/web/20100707042144/http://cbioc.eas.asu.edu/banner/ BANNER] Named Entity Recognizer ([[Java (programming language)|Java]])

== See also ==
* [[Hammersley–Clifford theorem]]
* [[Graphical model]]
* [[Markov random field]]
* [[Maximum entropy Markov model]] (MEMM)

== References ==
{{reflist|30em}}

==Further reading==
* McCallum, A.: [https://arxiv.org/abs/1212.2504 Efficiently inducing features of conditional random fields]. In: ''Proc. 19th Conference on Uncertainty in Artificial Intelligence''. (2003)
* [[Hanna Wallach|Wallach, H.M.]]: [http://www.cs.umass.edu/~wallach/technical_reports/wallach04conditional.pdf Conditional random fields: An introduction]. Technical report MS-CIS-04-21, University of Pennsylvania (2004)
* Sutton, C., McCallum, A.: An Introduction to Conditional Random Fields for Relational Learning. In "Introduction to Statistical Relational Learning". Edited by [[Lise Getoor]] and Ben Taskar. MIT Press. (2006) [http://www.cs.umass.edu/~mccallum/papers/crf-tutorial.pdf Online PDF]
* Klinger, R., Tomanek, K.: Classical Probabilistic Models and Conditional Random Fields. Algorithm Engineering Report TR07-2-013, Department of Computer Science, Dortmund University of Technology, December 2007. ISSN 1864-4503. [http://ls11-www.cs.uni-dortmund.de/_media/techreports/tr07-13.pdf Online PDF]

[[Category:Graphical models]]
[[Category:Machine learning]]</text>
      <sha1>p5inwl8rk0h7u5iuoukl19a17omfsk3</sha1>
    </revision>
  </page>
  <page>
    <title>Cross-entropy method</title>
    <ns>0</ns>
    <id>5767980</id>
    <revision>
      <id>965740656</id>
      <parentid>965740487</parentid>
      <timestamp>2020-07-03T04:04:05Z</timestamp>
      <contributor>
        <username>Cedar101</username>
        <id>374440</id>
      </contributor>
      <minor/>
      <comment>/* Pseudocode */ &amp;epsilon;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="7134" xml:space="preserve">The '''cross-entropy''' ('''CE''') '''method''' is a [[Monte Carlo method|Monte Carlo]] method for [[importance sampling]] and [[Optimization (mathematics)|optimization]]. It is applicable to both [[Combinatorial optimization|combinatorial]] and [[Continuous optimization|continuous]] problems, with either a static or noisy objective.

The method approximates the optimal importance sampling estimator by repeating two phases:&lt;ref&gt;Rubinstein, R.Y. and  Kroese, D.P. (2004), The Cross-Entropy Method: A Unified Approach to Combinatorial Optimization, Monte-Carlo Simulation, and Machine Learning, Springer-Verlag, New York {{ISBN|978-0-387-21240-1}}.&lt;/ref&gt;

#Draw a sample from a probability distribution.
#Minimize the [[cross entropy|''cross-entropy'']] between this distribution and a target distribution to produce a better sample in the next iteration.

[[Reuven Rubinstein]] developed the method in the context of ''rare event simulation'', where tiny probabilities must be estimated, for example in network reliability analysis, queueing models, or performance analysis of telecommunication systems. The method has also been applied to the [[traveling salesman problem|traveling salesman]], [[quadratic assignment problem|quadratic assignment]], [[Sequence alignment|DNA sequence alignment]], [[Maxcut|max-cut]] and buffer allocation problems.

==Estimation via importance sampling==
Consider the general problem of estimating the quantity

&lt;math&gt;\ell = \mathbb{E}_{\mathbf{u}}[H(\mathbf{X})] = \int H(\mathbf{x})\, f(\mathbf{x}; \mathbf{u})\, \textrm{d}\mathbf{x}&lt;/math&gt;,

where &lt;math&gt;H&lt;/math&gt; is some ''performance function'' and &lt;math&gt;f(\mathbf{x};\mathbf{u})&lt;/math&gt; is a member of some [[parametric family]] of distributions. Using [[importance sampling]] this quantity can be estimated as

&lt;math&gt;\hat{\ell} = \frac{1}{N} \sum_{i=1}^N H(\mathbf{X}_i) \frac{f(\mathbf{X}_i; \mathbf{u})}{g(\mathbf{X}_i)}&lt;/math&gt;,

where &lt;math&gt;\mathbf{X}_1,\dots,\mathbf{X}_N&lt;/math&gt; is a random sample from &lt;math&gt;g\,&lt;/math&gt;. For positive &lt;math&gt;H&lt;/math&gt;, the theoretically ''optimal'' importance sampling [[probability density function|density]] (PDF) is given by

&lt;math&gt; g^*(\mathbf{x}) = H(\mathbf{x}) f(\mathbf{x};\mathbf{u})/\ell&lt;/math&gt;.

This, however, depends on the unknown &lt;math&gt;\ell&lt;/math&gt;. The CE method aims to approximate the optimal PDF by adaptively selecting members of the parametric family that are closest (in the [[Kullback–Leibler divergence|Kullback–Leibler]] sense) to the optimal PDF &lt;math&gt;g^*&lt;/math&gt;.

==Generic CE algorithm==
# Choose initial parameter vector &lt;math&gt;\mathbf{v}^{(0)}&lt;/math&gt;; set t = 1.
# Generate a random sample &lt;math&gt;\mathbf{X}_1,\dots,\mathbf{X}_N&lt;/math&gt; from &lt;math&gt;f(\cdot;\mathbf{v}^{(t-1)})&lt;/math&gt;
# Solve for &lt;math&gt;\mathbf{v}^{(t)}&lt;/math&gt;, where&lt;br&gt;&lt;math&gt;\mathbf{v}^{(t)} = \mathop{\textrm{argmax}}_{\mathbf{u}} \frac{1}{N} \sum_{i=1}^N H(\mathbf{X}_i)\frac{f(\mathbf{X}_i;\mathbf{u})}{f(\mathbf{X}_i;\mathbf{v}^{(t-1)})} \log f(\mathbf{X}_i;\mathbf{v}^{(t-1)})&lt;/math&gt;
# If convergence is reached then '''stop'''; otherwise, increase t by 1 and reiterate from step 2.

In several cases, the solution to step 3 can be found ''analytically''.  Situations in which this occurs are
* When &lt;math&gt;f\,&lt;/math&gt; belongs to the [[Exponential family|natural exponential family]]
* When &lt;math&gt;f\,&lt;/math&gt; is [[discrete space|discrete]] with finite [[Support (mathematics)|support]]
* When &lt;math&gt;H(\mathbf{X}) = \mathrm{I}_{\{\mathbf{x}\in A\}}&lt;/math&gt; and &lt;math&gt;f(\mathbf{X}_i;\mathbf{u}) = f(\mathbf{X}_i;\mathbf{v}^{(t-1)})&lt;/math&gt;, then &lt;math&gt;\mathbf{v}^{(t)}&lt;/math&gt; corresponds to the [[Maximum likelihood|maximum likelihood estimator]] based on those &lt;math&gt;\mathbf{X}_k \in A&lt;/math&gt;.

== Continuous optimization&amp;mdash;example==
The same CE algorithm can be used for optimization, rather than estimation. 
Suppose the problem is to maximize some function &lt;math&gt;S&lt;/math&gt;, for example, 
&lt;math&gt;S(x) = \textrm{e}^{-(x-2)^2} + 0.8\,\textrm{e}^{-(x+2)^2}&lt;/math&gt;. 
To apply CE, one considers first the ''associated stochastic problem'' of estimating
&lt;math&gt;\mathbb{P}_{\boldsymbol{\theta}}(S(X)\geq\gamma)&lt;/math&gt;
for a given ''level'' &lt;math&gt;\gamma\,&lt;/math&gt;, and parametric family &lt;math&gt;\left\{f(\cdot;\boldsymbol{\theta})\right\}&lt;/math&gt;, for example the 1-dimensional 
[[Gaussian distribution]],
parameterized by its mean &lt;math&gt;\mu_t\,&lt;/math&gt; and variance &lt;math&gt;\sigma_t^2&lt;/math&gt; (so &lt;math&gt;\boldsymbol{\theta} = (\mu,\sigma^2)&lt;/math&gt; here).
Hence, for a given &lt;math&gt;\gamma\,&lt;/math&gt;, the goal is to find &lt;math&gt;\boldsymbol{\theta}&lt;/math&gt; so that
&lt;math&gt;D_{\mathrm{KL}}(\textrm{I}_{\{S(x)\geq\gamma\}}\|f_{\boldsymbol{\theta}})&lt;/math&gt;
is minimized. This is done by solving the sample version (stochastic counterpart) of the KL divergence minimization problem, as in step 3 above.
It turns out that parameters that minimize the stochastic counterpart for this choice of target distribution and
parametric family are the sample mean and sample variance corresponding to the ''elite samples'', which are those samples that have objective function value &lt;math&gt;\geq\gamma&lt;/math&gt;.
The worst of the elite samples is then used as the level parameter for the next iteration.
This yields the following randomized algorithm that happens to coincide with the so-called Estimation of Multivariate Normal Algorithm (EMNA), an [[estimation of distribution algorithm]].

===Pseudocode===
 ''// Initialize parameters''
 &amp;mu; := −6
 &amp;sigma;2 := 100
 t := 0
 maxits := 100
 N := 100
 Ne := 10
 ''// While maxits not exceeded and not converged''
 '''while''' t &lt; maxits '''and''' &amp;sigma;2 &gt; &amp;epsilon; '''do'''
     ''// Obtain N samples from current sampling distribution''
     X := SampleGaussian(&amp;mu;, &amp;sigma;2, N)
     ''// Evaluate objective function at sampled points''
     S := exp(−(X − 2) ^ 2) + 0.8 exp(−(X + 2) ^ 2)
     ''// Sort X by objective function values in descending order''
     X := sort(X, S)
     ''// Update parameters of sampling distribution''                  
     &amp;mu; := mean(X(1:Ne))
     &amp;sigma;2 := var(X(1:Ne))
     t := t + 1
 ''// Return mean of final sampling distribution as solution''
 '''return''' mu

==Related methods==
* [[Simulated annealing]]
* [[Genetic algorithms]]
* [[Harmony search]]
* [[Estimation of distribution algorithm]]
* [[Tabu search]]
* [[Natural Evolution Strategy]]

==See also==
* [[Cross entropy]]
* [[Kullback–Leibler divergence]]
* [[Randomized algorithm]]
* [[Importance sampling]]

== Journal papers ==
* De Boer, P-T., Kroese, D.P, Mannor, S. and Rubinstein, R.Y. (2005). A Tutorial on the Cross-Entropy Method. ''Annals of Operations Research'', '''134''' (1), 19–67.[http://www.maths.uq.edu.au/~kroese/ps/aortut.pdf]
*Rubinstein, R.Y. (1997). Optimization of Computer simulation Models with Rare Events, ''European Journal of Operational Research'', '''99''', 89–112.

==Software implementations==
* [https://cran.r-project.org/web/packages/CEoptim/index.html '''CEoptim''' R package]

==References==
{{reflist}}

[[Category:Heuristics]]
[[Category:Optimization algorithms and methods]]
[[Category:Monte Carlo methods]]
[[Category:Machine learning]]</text>
      <sha1>sk34zdka31z2o3q3s0ru22tbpyp9mzj</sha1>
    </revision>
  </page>
  <page>
    <title>Concept drift</title>
    <ns>0</ns>
    <id>3118600</id>
    <revision>
      <id>995541913</id>
      <parentid>993354959</parentid>
      <timestamp>2020-12-21T16:40:23Z</timestamp>
      <contributor>
        <ip>50.53.22.81</ip>
      </contributor>
      <comment>/* Real */ https</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="16900" xml:space="preserve">In [[predictive analytics]] and [[machine learning]], the '''concept drift''' means that the statistical properties of the target variable, which the model is trying to predict, change over time in unforeseen ways. This causes problems because the predictions become less accurate as time passes.

The term ''concept'' refers to the quantity to be predicted. More generally, it can also refer to other phenomena of interest besides the target concept, such as an input, but, in the context of concept drift, the term commonly refers to the target variable.

==Examples==
In a [[fraud detection]] application the target concept may be a [[Binary numeral system|binary]] attribute FRAUDULENT with values "yes" or "no" that indicates whether a given transaction is fraudulent. Or, in a [[weather prediction]] application, there may be several target concepts such as TEMPERATURE, PRESSURE, and HUMIDITY.

The behavior of the customers in an [[online shop]] may change over time. For example, if weekly merchandise sales are to be predicted, and a [[predictive modelling|predictive model]] has been developed that works satisfactorily. The model may use inputs such as the amount of money spent on [[advertising]], [[Promotion (marketing)|promotions]] being run, and other metrics that may affect sales. The model is likely to become less and less accurate over time – this is concept drift. In the merchandise sales application, one reason for concept drift may be seasonality, which means that shopping behavior changes seasonally. Perhaps there will be higher sales in the winter holiday season than during the summer, for example.

==Possible remedies==

To prevent deterioration in [[prediction]] accuracy because of concept drift, both active and passive solutions can be adopted.  Active solutions rely on triggering mechanisms, e.g., change-detection tests (Basseville and Nikiforov 1993; Alippi and Roveri, 2007) to explicitly detect concept drift as a change in the statistics of the data-generating process. In stationary conditions, any fresh information made available can be integrated to improve the model. Differently, when concept drift is detected, the current model is no longer up-to-date and must be substituted with a new one to maintain the prediction accuracy (Gama et al., 2004; Alippi et al., 2011). On the contrary, in passive solutions the model is continuously updated, e.g., by retraining the model on the most recently observed samples (Widmer and Kubat, 1996), or enforcing an ensemble of classifiers (Elwell and Polikar 2011).

Contextual information, when available, can be used to better explain the causes of the concept drift: for instance, in the sales prediction application, concept drift might be compensated by adding information about the season to the model. By providing information about the time of the year, the rate of deterioration of your model is likely to decrease, concept drift is unlikely to be eliminated altogether. This is because actual shopping behavior does not follow any static, [[finite model]]. New factors may arise at any time that influence shopping behavior, the influence of the known factors or their interactions may change.

Concept drift cannot be avoided for complex phenomena that are not governed by fixed [[Physical law|laws of nature]]. All processes that arise from human activity, such as [[socioeconomic]] processes, and [[biological processes]] are likely to experience concept drift. Therefore, periodic retraining, also known as refreshing, of any model is necessary.

==Software==
* [[RapidMiner]]: Formerly ''Yet Another Learning Environment'' (YALE): free open-source software for knowledge discovery, data mining, and machine learning also featuring data stream mining, learning time-varying concepts, and tracking drifting concept. It is used in combination with its data stream mining plugin (formerly concept drift plugin).
* EDDM ([https://web.archive.org/web/20070322063617/http://iaia.lcc.uma.es/Members/mbaena/papers/eddm/ Early Drift Detection Method]): free open-source implementation of drift detection methods in [[Weka (machine learning)|Weka]].
* [[MOA (Massive Online Analysis)]]: free open-source software specific for mining data streams with concept drift. It contains a prequential evaluation method, the EDDM concept drift methods, a reader of ARFF real datasets, and artificial stream generators as SEA concepts, STAGGER, rotating hyperplane, random tree, and random radius based functions. MOA supports bi-directional interaction with [[Weka (machine learning)|Weka]].

==Datasets==

===Real===
* '''USP Data Stream Repository''', 27 real-world stream datasets with concept drift compiled by Souza et al. (2020). [https://sites.google.com/view/uspdsrepository Access]
* '''Airline''', approximately 116 million flight arrival and departure records (cleaned and sorted) compiled by E. Ikonomovska. Reference: Data Expo 2009 Competition [http://stat-computing.org/dataexpo/2009/]. [http://kt.ijs.si/elena_ikonomovska/data.html Access]
* '''Chess.com''' (online games) and '''Luxembourg''' (social survey) datasets compiled by I. Zliobaite. [https://sites.google.com/site/zliobaite/resources-1 Access]
* '''ECUE spam''' 2 datasets each consisting of more than 10,000 emails collected over a period of approximately 2 years by an individual. [https://web.archive.org/web/20110513025937/http://www.comp.dit.ie/sjdelany/dataset.htm Access] from S.J.Delany webpage
* '''Elec2''', electricity demand, 2 classes, 45,312 instances. Reference: M. Harries, Splice-2 comparative evaluation: Electricity pricing, Technical report, The University of South Wales, 1999. [http://www.inescporto.pt/~jgama/ales/ales_5.html Access] from J.Gama webpage. [https://arxiv.org/abs/1301.3524 Comment on applicability].
* '''PAKDD'09 competition''' data represents the credit evaluation task. It is collected over a five-year period. Unfortunately, the true labels are released only for the first part of the data. [https://web.archive.org/web/20150315224049/http://sede.neurotech.com.br/PAKDD2009/ Access]
* '''Sensor stream''' and '''Power supply stream''' datasets are available from X. Zhu's Stream Data Mining Repository.  [http://www.cse.fau.edu/~xqzhu/stream.html Access]
* '''SMEAR''' is a benchmark data stream with a lot of missing values. Environment observation data over 7 years. Predict cloudiness. [https://github.com/zliobaite/paper-missing-values Access]
* '''Text mining''', a collection of [[text mining]] datasets with concept drift, maintained by I. Katakis. [https://web.archive.org/web/20100704072013/http://mlkd.csd.auth.gr/concept_drift.html Access]
* '''Gas Sensor Array Drift Dataset''', a collection of 13,910 measurements from 16 chemical sensors utilized for drift compensation in a discrimination task of 6 gases at various levels of concentrations. [https://archive.ics.uci.edu/ml/datasets/Gas+Sensor+Array+Drift+Dataset Access]

===Other===
* '''KDD'99 competition''' data contains ''simulated'' intrusions in a military network environment. It is often used as a benchmark to evaluate handling concept drift. [http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html Access]

===Synthetic===
* '''Extreme verification latency benchmark''', Souza, V.M.A.; Silva, D.F.; Gama, J.; Batista, G.E.A.P.A.  : Data Stream Classification Guided by Clustering on Nonstationary Environments and Extreme Verification Latency.  SIAM International Conference on Data Mining (SDM), pp.&amp;nbsp;873–881, 2015. [https://sites.google.com/site/nonstationaryarchive/ Access] from Nonstationary Environments – Archive.
* '''Sine, Line, Plane, Circle and Boolean Data Sets''', L.L.Minku, A.P.White, X.Yao, The Impact of Diversity on On-line Ensemble Learning in the Presence of Concept Drift,  IEEE Transactions on Knowledge and Data Engineering, vol.22, no.5, pp.&amp;nbsp;730–742, 2010. [https://www.cs.bham.ac.uk/~minkull/opensource/ArtificialConceptDriftDataSets.zip Access] from L.Minku webpage.
* '''SEA concepts''', N.W.Street, Y.Kim, A streaming ensemble algorithm (SEA) for large-scale classification, KDD'01: Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining, 2001. [https://web.archive.org/web/20080315131143/http://www.liaad.up.pt/~jgama/ales/ales_5.html Access] from J.Gama webpage.
* '''STAGGER''', J.C.Schlimmer, R.H.Granger, Incremental Learning from Noisy Data, Mach. Learn., vol.1, no.3, 1986.
* '''Mixed''', J.Gama, P.Medas, G.Castillo, P.Rodrigues, Learning with drift detection, 2004.

===Data generation frameworks===
* L.L.Minku, A.P.White, X.Yao, The Impact of Diversity on On-line Ensemble Learning in the Presence of Concept Drift,  IEEE Transactions on Knowledge and Data Engineering, vol.22, no.5, pp.&amp;nbsp;730–742, 2010. [https://www.cs.bham.ac.uk/~minkull/opensource/DriftsGenerator.zip Download] from L.Minku webpage.
* Lindstrom P, SJ Delany &amp; B MacNamee (2008) Autopilot: Simulating Changing Concepts in Real Data In: Proceedings of the 19th Irish Conference on Artificial Intelligence &amp; Cognitive Science, D Bridge, K Brown, B O'Sullivan &amp; H Sorensen (eds.) p272-263 [https://web.archive.org/web/20110716141110/http://www.comp.dit.ie/sjdelany/publications/aics08-pl.pdf PDF]
* Narasimhamurthy A., L.I. Kuncheva, A framework for generating data to simulate changing environments, Proc. IASTED, Artificial Intelligence and Applications, Innsbruck, Austria, 2007, 384–389 [https://wayback.archive-it.org/all/20110401035628/http://www.bangor.ac.uk/~mas00a/papers/anlkAIA07.pdf PDF] [http://pages.bangor.ac.uk/~mas00a/EPSRC_simulation_framework/changing_environments_stage1a.htm Code]

==Projects==
* [http://www.infer.eu/ INFER]: Computational Intelligence Platform for Evolving and Robust Predictive Systems (2010–2014), Bournemouth University (UK), Evonik Industries (Germany), Research and Engineering Centre (Poland) 
* [http://www.win.tue.nl/~mpechen/projects/hacdais/ HaCDAIS]: Handling Concept Drift in Adaptive Information Systems (2008–2012), Eindhoven University of Technology (the Netherlands)
* [http://www.liaad.up.pt/~kdus/ KDUS]: Knowledge Discovery from Ubiquitous Streams, INESC Porto and Laboratory of Artificial Intelligence and Decision Support (Portugal)
* [http://www.cs.man.ac.uk/~gbrown/adept/ ADEPT]: Adaptive Dynamic Ensemble Prediction Techniques, University of Manchester (UK), University of Bristol (UK)
* [https://web.archive.org/web/20090309132402/http://www.aladdinproject.org/ ALADDIN]: autonomous learning agents for decentralised data and information networks (2005–2010)

==Benchmarks==
* [https://github.com/numenta/NAB NAB]: The Numenta Anomaly Benchmark, benchmark for evaluating algorithms for anomaly detection in streaming, real-time applications. (2014–2018)

==Meetings==
*2014
** [http://www.ieee-wcci2014.org/accepted-ss.htm] Special Session on "Concept Drift, Domain Adaptation &amp; Learning in Dynamic Environments" @IEEE IJCNN 2014 
*2013
** [https://sites.google.com/site/realstream2013/ RealStream] Real-World Challenges for Data Stream Mining Workshop-Discussion at the [[ECML PKDD]] 2013, Prague, Czech Republic.
** [https://web.archive.org/web/20150908134145/http://aiai2013.cut.ac.cy/leaps-2013/ LEAPS 2013] The 1st International Workshop on Learning stratEgies and dAta Processing in nonStationary environments 
*2011
** [http://www.icmla-conference.org/icmla11/LEE.htm LEE 2011] Special Session on Learning in evolving environments and its application on real-world problems at ICMLA'11
** [http://wwwis.win.tue.nl/hacdais2011/ HaCDAIS 2011] The 2nd International Workshop on Handling Concept Drift in Adaptive Information Systems
** [https://web.archive.org/web/20101031152019/http://icais.uni-klu.ac.at/cfp.php ICAIS 2011] Track on Incremental Learning 
** [https://web.archive.org/web/20110128002602/http://www.ijcnn2011.org/special_section.php IJCNN 2011] Special Session on Concept Drift and Learning Dynamic Environments
** [http://www.soft-computing.de/CIDUE2011.html CIDUE 2011] Symposium on Computational Intelligence in Dynamic and Uncertain Environments  
*2010
** [http://wwwis.win.tue.nl/hacdais2010/ HaCDAIS 2010] International Workshop on Handling Concept Drift in Adaptive Information Systems: Importance, Challenges and Solutions
** [http://www.icmla-conference.org/icmla10/CFP_SpecialSession9.html ICMLA10] Special Session on Dynamic learning in non-stationary environments
** [https://web.archive.org/web/20100425011804/http://www.liaad.up.pt/~jgama/SAC10/ SAC 2010] Data Streams Track at ACM Symposium on Applied Computing 
** [https://web.archive.org/web/20100418214526/http://www.ornl.gov/sci/knowledgediscovery/SensorKDD-2010/ SensorKDD 2010] International Workshop on Knowledge Discovery from Sensor Data 
** [https://web.archive.org/web/20100419123949/http://lyle.smu.edu/cse/dbgroup/IDA/StreamKDD2010/ StreamKDD 2010] Novel Data Stream Pattern Mining Techniques 
** Concept Drift and Learning in Nonstationary Environments at [http://www.wcci2010.org/ IEEE World Congress on Computational Intelligence]
** [http://cig.iet.unipi.it/isda2010/files/MLMD.pdf MLMDS’2010] Special Session on Machine Learning Methods for Data Streams at the 10th International Conference on Intelligent Design and Applications, ISDA’10

== Bibliographic references ==
Many papers have been published describing algorithms for concept drift detection. Only reviews, surveys and overviews are here:

===Reviews===

* Souza, V. M. A., Reis, D. M., Maletzke, A. G., Batista, G. E. A. P. A. (2020). Challenges in Benchmarking Stream Learning Algorithms with Real-world Data, Data Mining and Knowledge Discovery, 1--54. https://link.springer.com/article/10.1007/s10618-020-00698-5
* Krawczyk, B., Minku, L.L., Gama, J., Stefanowski, J., Wozniak, M. (2017). "Ensemble Learning for Data Stream Analysis: a survey", Information Fusion, Vol 37, pp.&amp;nbsp;132–156,  [https://dx.doi.org/10.1016/j.inffus.2017.02.004 Access]
* Dal Pozzolo, A., Boracchi, G., Caelen, O., Alippi, C., &amp; Bontempi, G. (2015). Credit card fraud detection and concept-drift adaptation with delayed supervised information. In 2015 International Joint Conference on Neural Networks (IJCNN) (pp.&amp;nbsp;1–8). IEEE. [http://www.ulb.ac.be/di/map/adalpozz/pdf/IJCNN2015_final.pdf PDF]
* C.Alippi, "Learning in Nonstationary and Evolving Environments", Chapter in ''Intelligence for Embedded Systems.'' Springer, 2014, 283pp, {{ISBN|978-3-319-05278-6}}.
*Gama, J., Žliobaitė, I., Bifet, A., Pechenizkiy, M. and Bouchachia, A., 2014. A survey on concept drift adaptation. ''ACM computing surveys (CSUR)'', ''46''(4), p.44. [http://eprints.bournemouth.ac.uk/22491/1/ACM%20computing%20surveys.pdf PDF]
* C.Alippi, R.Polikar, Special Issue on Learning In Nonstationary and Evolving Environments, IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 25, NO. 1, JANUARY 2014
* Dal Pozzolo, A., Caelen, O., Le Borgne, Y. A., Waterschoot, S., &amp; Bontempi, G. (2014). Learned lessons in credit card fraud detection from a practitioner perspective. Expert systems with applications, 41(10), 4915–4928. [http://www.ulb.ac.be/di/map/adalpozz/pdf/FraudDetectionPaper_8.pdf PDF]
* Zliobaite, I., Learning under Concept Drift: an Overview. Technical Report. 2009, Faculty of Mathematics and Informatics, Vilnius University: Vilnius, Lithuania. [http://zliobaite.googlepages.com/Zliobaite_CDoverview.pdf PDF]{{Dead link|date=July 2020 |bot=InternetArchiveBot |fix-attempted=yes }}
* Jiang, J., A Literature Survey on Domain Adaptation of Statistical Classifiers. 2008. [https://web.archive.org/web/20081203104757/http://sifaka.cs.uiuc.edu/jiang4/domain_adaptation/survey/da_survey.pdf PDF]
* Kuncheva L.I. Classifier ensembles for detecting concept change in streaming data: Overview and perspectives, Proc. 2nd Workshop SUEMA 2008 (ECAI 2008), Patras, Greece, 2008, 5–10, [https://wayback.archive-it.org/all/20110401040229/http://www.bangor.ac.uk/~mas00a/papers/lkSUEMA2008.pdf PDF]
* Gaber, M, M., Zaslavsky, A., and Krishnaswamy, S., Mining Data Streams: A Review, in ACM SIGMOD Record, Vol. 34, No. 1, June 2005, {{ISSN|0163-5808}}
* Kuncheva L.I., Classifier ensembles for changing environments, Proceedings 5th International Workshop on Multiple Classifier Systems, MCS2004, Cagliari, Italy, in F. Roli, J. Kittler and T. Windeatt (Eds.), Lecture Notes in Computer Science, Vol 3077, 2004, 1–15, [https://wayback.archive-it.org/all/20110401040200/http://www.bangor.ac.uk/~mas00a/papers/lkMCS04.pdf PDF].
* Tsymbal, A., The problem of concept drift: Definitions and related work. Technical Report. 2004, Department of Computer Science, Trinity College: Dublin, Ireland. [https://www.cs.tcd.ie/publications/tech-reports/reports.04/TCD-CS-2004-15.pdf PDF]

==See also==
* [[Data stream mining]]
* [[Data mining]]
* [[Machine learning]]

[[Category:Data mining]]
[[Category:Machine learning]]</text>
      <sha1>4qyke2q5d02j90nz280lhc8bpocq699</sha1>
    </revision>
  </page>
  <page>
    <title>Concept learning</title>
    <ns>0</ns>
    <id>6968451</id>
    <revision>
      <id>997584867</id>
      <parentid>997231603</parentid>
      <timestamp>2021-01-01T07:11:49Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 29 templates: del empty params (7×); hyphenate params (8×); del |url-status= (1×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="31431" xml:space="preserve">{{multiple issues|
{{unfocused|date=March 2014}}
{{confusing|date=March 2014}}
{{expert needed|date=May 2011}}
{{More citations needed|date=April 2009}}
}}

'''Concept learning''', also known as '''category learning''', '''concept attainment''', and '''concept formation''', is defined by [[Jerome Bruner|Bruner]], Goodnow, &amp; Austin (1967) as "the search for and listing of attributes that can be used to distinguish exemplars from non exemplars of various categories". More simply put, concepts are the mental categories that help us classify objects, events, or ideas, building on the understanding that each object, event, or idea has a set of common relevant features. Thus, concept learning is a strategy which requires a learner to compare and contrast groups or categories that contain concept-relevant features with groups or categories that do not contain concept-relevant features.

In a concept learning task, a human or machine learner is trained to classify objects by being shown a set of example objects along with their class labels. The learner simplifies what has been observed by condensing it in the form of an example. This simplified version of what has been learned is then applied to future examples. Concept learning may be simple or complex because learning takes place over many areas. When a concept is difficult, it is less likely that the learner will be able to simplify, and therefore will be less likely to learn. Colloquially, the task is known as ''learning from examples.'' Most theories of concept learning are based [[Exemplar theory|on the storage of exemplars]] and avoid summarization or overt abstraction of any kind.

*Concept Learning: Inferring a Boolean-valued function from training examples of its input and output.
*A concept is an idea of something formed by combining all its features or attributes which construct the given concept. Every concept has two components:
*Attributes: features that one must look for to decide whether a data instance is a positive one of the concept.
*A rule: denotes what conjunction of constraints on the attributes will qualify as a positive instance of the concept.

== Types of concepts ==
Concept learning must be distinguished from learning by reciting something from memory (recall) or discriminating between two things that differ (discrimination). However, these issues are closely related, since memory recall of facts could be considered a "trivial" conceptual process where prior exemplars representing the concept are invariant. Similarly, while discrimination is not the same as initial concept learning, discrimination processes are involved in refining concepts by means of the repeated presentation of exemplars.

'''Concrete or Perceptual Concepts vs Abstract Concepts'''

Concrete concepts are objects that can be perceived by personal sensations and perceptions. These are objects like chairs and dogs where personal interactions occur with them and create a concept.&lt;ref&gt;{{Cite book|last=Paivio, Allan.|title=Mind and Its Evolution : a Dual Coding Theoretical Approach.|date=2014|publisher=Taylor and Francis|isbn=978-1-317-71690-7|oclc=868489792}}&lt;/ref&gt; Concepts become more concrete as the word we use to associate with it has a perceivable entity.&lt;ref&gt;Binder, J. R., Westbury, C. F., McKiernan, K. A., Possing, E. T., &amp; Medler, D. A. (2005). Distinct brain systems for processing concrete and abstract words. Journal of Cognitive Neuroscience, 17, 905–917.&lt;/ref&gt; According to Paivio’s [[Dual-coding theory|dual -coding theory]], concrete concepts are the one that is remembered easier from their perceptual memory codes.&lt;ref&gt;{{Cite book|last=Paivio|first=Allan|url=https://www.taylorfrancis.com/books/9781315785233|title=Mind and Its Evolution: A Dual Coding Theoretical Approach|date=2014-01-14|publisher=Psychology Press|isbn=978-1-315-78523-3|edition=1|language=en|doi=10.4324/9781315785233}}&lt;/ref&gt; Evidence has shown that when words are heard they are associated with a concrete concept and are re-enact any previous interaction with the word within the sensorimotor system.&lt;ref&gt;{{Cite journal|last1=Cappa|first1=Stefano F.|last2=Pulvermüller|first2=Friedemann|date=July 2012|title=Cortex special issue: Language and the motor system|journal=Cortex|volume=48|issue=7|pages=785–787|doi=10.1016/j.cortex.2012.04.010|pmid=22579224|s2cid=33954008|issn=0010-9452}}&lt;/ref&gt; Examples of concrete concepts in learning are early educational math concepts like adding and subtracting.

Abstract concepts are words and ideas that deal with emotions, personality traits and events.&lt;ref&gt;{{Cite journal|last1=Katja Wiemer-Hastings|first1=Katja|last2=Xu|first2=Xu|date=2005-09-10|title=Content Differences for Abstract and Concrete Concepts|journal=Cognitive Science|volume=29|issue=5|pages=719–736|doi=10.1207/s15516709cog0000_33|pmid=21702791|issn=0364-0213|doi-access=free}}&lt;/ref&gt; Terms like "fantasy" or "cold" have a more abstract concept within them. Every person has their personal definition, which is ever changing and comparing, of abstract concepts. For example, cold could mean the physical temperature of the surrounding area or it could define the action and personality of another person. While within concrete concepts there is still a level of abstractness, concrete and abstract concepts can be seen on a scale. Some ideas like chair and dog are more cut and dry in their perceptions but concepts like cold and fantasy can be seen in a more obscure way. Examples of abstract concept learning are topics like religion and ethics. Abstract-concept learning is seeing the comparison of the stimuli based on a rule (e.g., identity, difference, oddity, greater than, addition, subtraction) and when it is a novel stimulus.&lt;ref name=":0"&gt;Katz, J. S., Wright, A. A., &amp; Bodily, K. D. (2007). Issues in the Comparative Cognition of Abstract-Concept Learning. ''Comparative Cognition &amp; Behavior Reviews'', ''2'', 79–92.&lt;/ref&gt; With abstract-concept learning  have three criteria’s to rule out any alternative explanations to define the novelty of the stimuli. One transfer stimuli has to be novel to the individual. This means it needs to be a new stimulus to the individual. Two, there is no replication of the transfer stimuli. Third and lastly, to have a full abstract learning experience there has to be an equal amount of baseline performance and transfer performance.&lt;ref name=":0" /&gt;

Binder, Westbury, McKiernan, Possing, and Medler (2005)&lt;ref&gt;{{Cite journal|last1=Binder|first1=J. R.|last2=Westbury|first2=C. F.|last3=McKiernan|first3=K. A.|last4=Possing|first4=E. T.|last5=Medler|first5=D. A.|date=June 2005|title=Distinct Brain Systems for Processing Concrete and Abstract Concepts|journal=Journal of Cognitive Neuroscience|volume=17|issue=6|pages=905–917|doi=10.1162/0898929054021102|pmid=16021798|s2cid=207624180|issn=0898-929X}}&lt;/ref&gt; used fMRI to scan individuals' brains as they made lexical decisions on abstract and concrete concepts. Abstract concepts elicited greater activation in the left precentral gyrus, left inferior frontal gyrus and sulcus, and left superior temporal gyrus, whereas concrete concepts elicited greater activation in bilateral angular gyri, the right middle temporal gyrus, the left middle frontal gyrus, bilateral posterior cingulate gyri, and bilateral precunei.

In 1986 [[Allan Paivio]]&lt;ref&gt;Paivio, A. (1986). ''Mental representations: A dual coding approach''. New York: Oxford University Press.&lt;/ref&gt; hypothesized the [[Dual-coding theory|Dual Coding Theory]], which states that both verbal and visual information is used to represent information. When thinking of the concept “dog”  thoughts of both the word dog and an image of a dog occur. [[Dual-coding theory|Dual Coding Theory]] assumes that abstract concepts involve the verbal semantic system and concrete concepts are additionally involved with the visual imaginary system.

'''Defined (or Relational) and Associated Concepts'''

Relational and associated concepts are words, ideas and thoughts that are connected in some form. For relational concepts they are connected in a universal definition. Common relational terms are up-down, left-right, and food-dinner. These ideas are learned in our early childhood and are important for children to understand.&lt;ref&gt;Boehm, Ann (2004). ''The Psychoeducational Assessment of Preschool Children''. London: Lawrence Erlbaum associates. pp. 186–203.&lt;/ref&gt; These concepts are integral within our understanding and reasoning in conservation tasks.&lt;ref&gt;Walker, Alice A. (1979-09). "The Development of Relational Concepts in Three-and Four-Year-Olds". ''The Journal of Educational Research''. '''73''' (1): 37–40. [[Digital object identifier|doi]]:10.1080/00220671.1979.10885201. [[International Standard Serial Number|ISSN]] 0022-0671.&lt;/ref&gt; Relational terms that are verbs and prepositions have a large influence on how objects are understood. These terms are more likely to create a larger understanding of the object and they are able to cross over to other languages.&lt;ref&gt;J. Loewenstein, D. Gentner '''Relational language and the development of relational mapping''' Cognitive Psychology, 50 (2005), pp. 315-353&lt;br /&gt;&lt;/ref&gt;

Associated concepts are connected by the individual’s past and own perception. Associative concept learning (also called functional concept learning) involves categorizing stimuli based on a common response or outcome regardless of perceptual similarity into appropriate categories.&lt;ref&gt;{{Cite book|last=Urcuioli|first=Peter J.|title=Comparative Cognition ''Experimental'' Explorations of Animal Intelligence|chapter=Responses and Acquired Equivalence Classes|date=2009-04-08|work=Comparative CognitionExperimental Explorations of Animal Intelligence|pages=405–422|publisher=Oxford University Press|doi=10.1093/acprof:oso/9780195377804.003.0022|isbn=978-0-19-537780-4}}&lt;/ref&gt; This is associating these thoughts and ideas with other thoughts and ideas that are understood by a few or the individual. An example of this is in elementary school when learning the direction of the compass North, East, South and West. Teacher have used “Never Eat Soggy Waffles”, “Never Eat Sour Worms” and students were able to create their own version to help them learn the directions.&lt;ref&gt;{{Cite web|url=https://www.mnemonic-device.com/geography/wind-directions-north-east-south-west/|title=Wind Directions:North, East, South, West}}&lt;/ref&gt;

'''Complex Concepts'''. Constructs such as a [[Schema (psychology)|schema]] and a script are examples of complex concepts. A schema is an organization of smaller concepts (or features) and is revised by situational information to assist in comprehension. A script on the other hand is a list of actions that a person follows in order to complete a desired goal. An example of a script would be the process of buying a CD. There are several actions that must occur before the actual act of purchasing the CD and a script provides a sequence of the necessary actions and proper order of these actions in order to be successful in purchasing the CD.

== Methods of learning a concept ==
'''Discovery''' – Every baby discovers concepts for itself, such as discovering that each of its fingers can be individually controlled or that care givers are individuals.  Although this is perception driven, formation of the concept is more than memorizing perceptions.

'''Examples''' – Supervised or unsupervised generalizing from examples may lead to learning a new concept, but concept formation is more than generalizing from examples.
 
'''Words''' – Hearing or reading new words leads to learning new concepts, but forming a new concept is more than learning a dictionary definition.  A person may have previously formed a new concept before encountering the word or phrase for it.

'''Exemplars comparison and contrast''' – An efficient way to learn new categories and to induce new categorization rules is by comparing a few example objects while being informed about their categorical relation. Comparing two exemplars while being informed that the two are from the same category allows identifying the attributes shared by the category members, as it exemplifies variability within this category. On the other hand, contrasting two exemplars while being informed that the two are from different categories may allow identifying attributes with diagnostic value. Within category comparison and between categories contrast are not similarly useful for category learning (Hammer et al., 2008), and the capacity to use these two forms of comparison-based learning changes at childhood (Hammer et al., 2009).

'''Invention''' – When prehistoric people who lacked tools used their fingernails to scrape food from killed animals or smashed melons, they noticed that a broken stone sometimes had a sharp edge like a fingernail and was therefore suitable for scraping food. Inventing a stone tool to avoid broken fingernails was a new concept.

== Theoretical issues ==

In general, the theoretical issues underlying concept learning are those underlying [[Inductive reasoning|induction]]. These issues are addressed in many diverse publications, including literature on subjects like [[Version Spaces]], [[Statistical Learning Theory]], [[PAC Learning]], [[Information Theory]], and [[Algorithmic Information Theory]]. Some of the broad theoretical ideas are also discussed by Watanabe (1969,1985), Solomonoff (1964a,1964b), and Rendell (1986); see the reference list below.

== Modern psychological theories ==

It is difficult to make any general statements about human (or animal) concept learning without already assuming a particular psychological theory of concept learning. Although the classical views of [[concept]]s and concept learning in philosophy speak of a process of [[abstraction]], [[data compression]], simplification, and summarization, currently popular psychological theories of concept learning diverge on all these basic points. The history of psychology has seen the rise and fall of many theories about concept learning.  [[Classical conditioning]] (as defined by [[Ivan Pavlov|Pavlov]]) created the earliest experimental technique.  [[Reinforcement learning]] as described by [[John B. Watson|Watson]] and elaborated by [[Clark Hull]] created a lasting paradigm in [[behavioral psychology]].  [[Cognitive psychology]] emphasized a computer and information flow metaphor for concept formation.  [[Neural network]] models of concept formation and the structure of knowledge have opened powerful hierarchical models of knowledge organization such as [[George Armitage Miller|George Miller]]'s [[Wordnet]].  Neural networks are based on computational models of learning using [[factor analysis]] or [[convolution]].  Neural networks also are open to [[neuroscience]] and [[psychophysiological]] models of learning following [[Karl Lashley]] and [[Donald Hebb]].

=== Rule-based===
Rule-based theories of concept learning began with [[cognitive psychology]] and early computer models of learning that might be implemented in a high level computer language with computational statements such as [[Conditional (computer programming)#If–then(–else)|if:then]] production rules.  They take classification data and a rule-based theory as input which are the result of a rule-based learner with the hopes of producing a more accurate model of the data (Hekenaho 1997). The majority of rule-based models that have been developed are heuristic, meaning that rational analyses have not been provided and the models are not related to statistical approaches to induction. A rational analysis for rule-based models could presume that concepts are represented as rules, and would then ask to what degree of belief a rational agent should be in agreement with each rule, with some observed examples provided (Goodman, Griffiths, Feldman, and Tenenbaum). Rule-based theories of concept learning are focused more so on [[perceptual learning]] and less on definition learning. Rules can be used in learning when the stimuli are confusable, as opposed to simple. When rules are used in learning, decisions are made based on properties alone and rely on simple criteria that do not require a lot of memory ( Rouder and Ratcliff, 2006).

Example of rule-based theory:

"A radiologist using rule-based categorization would observe
whether specific properties of an X-ray image meet certain
criteria; for example, is there an extreme difference in brightness
in a suspicious region relative to other regions? A decision is
then based on this property alone." (see Rouder and Ratcliff 2006)

=== Prototype ===

The [[Prototype theory|prototype view of concept learning]] holds that people abstract out the central tendency (or prototype) of the examples experienced and use this as a basis for their categorization decisions.

The prototype view of concept learning holds that people categorize based on one or more central examples of a given category followed by a penumbra of decreasingly typical examples. This implies that people do not categorize based on a list of things that all correspond to a definition, but rather on a hierarchical inventory based on semantic similarity to the central example(s).

=== Exemplar ===

[[Exemplar theory]] is the storage of specific instances (exemplars), with new objects evaluated only with respect to how closely they resemble specific known members (and nonmembers) of the category. This theory hypothesizes that learners store examples ''verbatim''. This theory views concept learning as highly simplistic. Only individual properties are represented. These individual properties are not abstract and they do not create rules. An example of what exemplar theory might look like is, "water is wet". It is simply known that some (or one, or all) stored examples of water have the property wet. Exemplar based theories have become more empirically popular over the years with some evidence suggesting that human learners use exemplar based strategies only in early learning, forming prototypes and generalizations later in life. An important result of exemplar models in psychology literature has been a de-emphasis of complexity in concept learning. One of the best known exemplar theories of concept learning is the Generalized Context Model (GCM).

A problem with exemplar theory is that exemplar models critically depend on two measures: similarity between exemplars, and having a rule to determine group membership. Sometimes it is difficult to attain or distinguish these measures.

=== Multiple-prototype===

More recently, cognitive psychologists have begun to explore the idea that the prototype and exemplar models form two extremes. It has been suggested that people are able to form a multiple prototype representation, besides the two extreme representations. For example, consider the category 'spoon'. There are two distinct subgroups or conceptual clusters: spoons tend to be either large and wooden, or small and made of metal. The prototypical spoon would then be a medium-size object made of a mixture of metal and wood, which is clearly an unrealistic proposal. A more natural representation of the category 'spoon' would instead consist of multiple (at least two) prototypes, one for each cluster. A number of different proposals have been made in this regard (Anderson, 1991; Griffiths, Canini, Sanborn &amp; Navarro, 2007; Love, Medin &amp; Gureckis, 2004; Vanpaemel &amp; Storms, 2008). These models can be regarded as providing a compromise between exemplar and prototype models.

=== Explanation-based ===

The basic idea of explanation-based learning suggests that a new concept is acquired by experiencing examples of it and forming a basic outline.{{ref|1|1}} Put simply, by observing or receiving the qualities of a thing the mind forms a concept which possesses and is identified by those qualities.

The original theory, proposed by Mitchell, Keller, and Kedar-Cabelli in 1986 and called explanation-based generalization, is that learning occurs through progressive generalizing.{{ref|2|2}} This theory was first developed to program machines to learn. When applied to human cognition, it translates as follows: the mind actively separates information that applies to more than one thing and enters it into a broader description of a category of things.  This is done by identifying sufficient conditions for something to fit in a category, similar to schematizing.

The revised model revolves around the integration of four mental processes – generalization, chunking, operationalization, and analogy{{ref|3|3}}.

* Generalization is the process by which the characteristics of a concept which are fundamental to it are recognized and labeled. For example, birds have feathers and wings. Anything with feathers and wings will be identified as ‘bird’.
* When information is grouped mentally, whether by similarity or relatedness, the group is called a chunk. Chunks can vary in size from a single item with parts or many items with many parts.{{ref|4|4}}
* A concept is operationalized when the mind is able to actively recognize examples of it by characteristics and label it appropriately.{{ref|5|5}}
* Analogy is the recognition of similarities among potential examples.{{ref|6|6}}

This particular theory of concept learning is relatively new and more research is being conducted to test it.

=== Bayesian ===

Taking a mathematical approach to concept learning, Bayesian theories propose that the human mind produces ''probabilities'' for a certain concept definition, based on examples it has seen of that concept.&lt;ref name="Tenenbaum99"&gt;{{cite journal|last1=Tenenbaum|first1=Joshua B.|title=Bayesian modeling of human concept learning|journal=Advances in Neural Information Processing Systems|date=1999|volume=11|issue=12|pages=59–65|url=http://web.mit.edu/cocosci/Papers/bayes.pdf|access-date=30 January 2018}}&lt;/ref&gt; The Bayesian concept of [[Prior Probability]] stops learners' hypotheses being overly specific, while the [[Likelihood function|likelihood]] of a hypothesis ensures the definition is not too broad.

For example- say a child is shown three horses by a parent and told these are called "horses"- she needs to work out exactly what the adult means by this word. She is much more likely to define the word "horses" as referring to either this ''type of animal'' or ''all animals'', rather than an oddly specific example like ''"all horses except Clydedales"'', which would be an unnatural concept. Meanwhile, the likelihood of 'horses' meaning 'all animals' when the three animals shown are all very similar is low. The hypothesis that the word "horse" refers to all ''animals of this species'' is most likely of the three possible definitions, as it has both a reasonable prior probability and likelihood given examples.

[[Bayes' theorem]] is important because it provides a powerful tool for understanding, manipulating and controlling data&lt;sup&gt;5&lt;/sup&gt; that takes a larger view that is not limited to data analysis alone&lt;sup&gt;6&lt;/sup&gt;.  The approach is subjective, and this requires the assessment of prior probabilities&lt;sup&gt;6&lt;/sup&gt;, making it also very complex.  However, if Bayesians show that the accumulated evidence and the application of Bayes' law are sufficient, the work will overcome the subjectivity of the inputs involved&lt;sup&gt;7&lt;/sup&gt;.  Bayesian inference can be used for any honestly collected data and has a major advantage because of its scientific focus&lt;sup&gt;6&lt;/sup&gt;.

One model that incorporates the Bayesian theory of concept learning is the [[ACT-R]] model, developed by [[John Robert Anderson (psychologist)|John R. Anderson]]&lt;!--there is no such thing as a bayesian theory of concept learning in the basic ACT-R system. Source?--&gt;.{{Citation needed|date=April 2009}} The ACT-R model is a programming language that defines the basic cognitive and perceptual operations that enable the human mind by producing a step-by-step simulation of human behavior.  This theory exploits the idea that each task humans perform consists of a series of discrete operations.  The model has been applied to learning and memory, higher level cognition, natural language, perception and attention, human-computer interaction, education, and computer generated forces.{{Citation needed|date=April 2009}}

In addition to John R. Anderson, [[Joshua Tenenbaum]] has been a contributor to the field of concept learning; he studied the computational basis of human learning and inference using behavioral testing of adults, children, and machines from Bayesian statistics and probability theory, but also from geometry, graph theory, and linear algebra.  Tenenbaum is working to achieve a better understanding of human learning in computational terms and trying to build computational systems that come closer to the capacities of human learners.

=== Component display theory ===

M. D. Merrill's component display theory (CDT) is a cognitive matrix that focuses on the interaction between two dimensions: the level of performance expected from the learner and the types of content of the material to be learned.  Merrill classifies a learner's level of performance as: find, use, remember, and material content as: facts, concepts, procedures, and principles.  The theory also calls upon four primary presentation forms and several other secondary presentation forms.  The primary presentation forms include: rules, examples, recall, and practice.  Secondary presentation forms include: prerequisites, objectives, helps, mnemonics, and feedback.  A complete lesson includes a combination of primary and secondary presentation forms, but the most effective combination varies from learner to learner and also from concept to concept. Another significant aspect of the CDT model is that it allows for the learner to control the instructional strategies used and adapt them to meet his or her own learning style and preference. A major goal of this model was to reduce three common errors in concept formation: over-generalization, under-generalization and misconception.

== See also ==
* [[Sample exclusion dimension]]

== References ==
{{Reflist}}

* {{cite journal
  | last1 = Rouder
  | first1 = Jeffrey
  | title = Comparing Exemplar and Rule-Based Theories of Categorization
  | journal = Current Directions in Psychological Science
  | volume = 15
  | pages = 9–13
  | year = 2006
  | doi = 10.1111/j.0963-7214.2006.00397.x
  | last2 = Ratcliff
  | first2 = Roger| s2cid = 7290181
 }}
* {{cite web 
|url= https://www.mit.edu/~ndg/papers/op322-goodman.pdf
|title= A Rational Analysis of Rule-based Concept Learning|
accessdate=2007-12-04 }}
*{{cite web 
|url= http://citeseer.ist.psu.edu/85278.html
|title= GA-based Rule Enhancement in Concept Learning|
accessdate=2007-12-04 }}
* Bruner, J., Goodnow, J. J., &amp; Austin, G. A. (1967). A study of thinking. New York: Science Editions.
*{{cite journal
  | last = Feldman
  | first = Jacob
  | title = The Simplicity Principle in Human Concept Learning
  | journal = Current Directions in Psychological Science
  | volume = 12
  | issue = 6
  | pages = 227–232
  | year = 2003
  | doi=10.1046/j.0963-7214.2003.01267.x| s2cid = 15441281
 }}
*{{cite journal
  | last = Rendell
  | first = Larry
  | title = A general framework for induction and a study of selective induction
  | journal = Machine Learning
  | volume = 1
  | pages = 177–226
  | year = 1986
  | doi = 10.1007/BF00114117
  | issue = 2| doi-access = free
  }}
*{{cite journal
  | last = Hammer
  | first = Rubi
  | title = Comparison processes in category learning: From theory to behavior
  | journal = Brain Research
  | volume = 1225
  | pages = 102–118
  | year = 2008
  | doi = 10.1016/j.brainres.2008.04.079
  | issue = 15
  | pmid=18614160| s2cid = 106981
 }}
*{{cite journal
  | last = Hammer
  | first = Rubi
  | title = The development of category learning strategies: What makes the difference?
  | journal = Cognition
  | volume = 112
  | pages = 105–119
  | year = 2009
  | doi = 10.1016/j.cognition.2009.03.012
  | issue = 1
  | pmid=19426967| s2cid = 1199541
 }}
*{{cite book
  | last = Watanabe
  | first = Satosi
  | title = Knowing and Guessing: A Quantitative Study of Inference and Information
  | url = https://archive.org/details/knowingguessingq0000wata
  | url-access = registration
  | publisher = Wiley
  | year = 1969
  | location = New York}}
*{{cite book
  | last = Watanabe
  | first = Satosi
  | title = Pattern Recognition: Human and Mechanical
  | publisher = Wiley
  | year = 1985
  | location = New York}}
*{{cite journal
  | last = Solomonoff
  | first = R. J.
  | title = A formal theory of inductive inference. Part I
  | journal = Information and Control
  | volume = 7
  | issue = 1
  | pages = 1–22
  | year = 1964
  | doi = 10.1016/S0019-9958(64)90223-2| doi-access = free
  }}
*{{cite journal
  | last = Solomonoff
  | first = R. J.
  | title = A formal theory of inductive inference. Part II
  | journal = Information and Control
  | volume = 7
  | issue = 2
  | pages = 224–254
  | year = 1964
  | doi = 10.1016/S0019-9958(64)90131-7| doi-access = free
  }}
*{{cite web
  |url= http://web.mit.edu/bcs/people/tenenbaum.shtml 
  |title= Brain and Cognitive Sciences
  |access-date= 2007-11-23
  |publisher= Massachusetts Institute of Technology}}
*{{cite web
  | last = Kearsley
  | first = Greg
  | title = Component Display Theory (M.D. Merrill)
  | date = 1994
  | url = http://icebreakerideas.com/learning-theories/#Component_Display_Theory_MD_Merrill
  | access-date = 2007-12-04 }}
*{{cite web
  | last = Kearsley
  | first = Greg
  | title = Concept
  | date = 1994
  | url = http://tip.psychology.org/concept.html
  | access-date = 2007-12-04
  | archive-url = https://web.archive.org/web/20110709085344/http://tip.psychology.org/concept.html
  | archive-date = 2011-07-09
  | url-status = dead
  }}
*{{cite web
  | title = Component Display Theory
  | date = 2007-04-10
  | url = http://moogl.wordpress.com/2007/04/10/component-display-theory/
  | access-date = 2007-12-04 }}
*{{cite web
  | title = Concept Attainment
  | year = 1999
  | url = http://www.lovinlearning.org/concept/
  | access-date = 2007-12-04 }}
*{{cite web
  | title = Concept Learning
  | date = 2007-11-07
  | url = http://edutechwiki.unige.ch/en/Concept_learning
  | access-date = 2007-12-04 }}
*{{cite web
  | title = Concept Formation
  | year = 2007
  | url = http://edutechwiki.unige.ch/en/Concept_learning
  | publisher = The McGraw-Hill Companies 
  | access-date = 2007-12-04 }}
*&lt;sup&gt;6&lt;/sup&gt;{{cite journal
  | last= Berry
  | first= Donald A.
  | title= Teaching Elementary Bayesian Statistics with Real Applications in Science
  | journal= The American Statistician 
  | volume= 5
  | issue= 3
  | pages= 241–246
  | date= 1997–1998
  | doi=10.1080/00031305.1997.10473970}}
*&lt;sup&gt;7&lt;/sup&gt;{{cite journal
  | last= Brown
  | first= Harold I.
  | title= Reason, Judgment and Bayes's Law
  | journal= Philosophy of Science
  | volume= 61
  | issue= 3
  | pages= 351–369
  | year= 1994
  | doi= 10.1086/289808}}
*&lt;sup&gt;5&lt;/sup&gt;{{cite journal
  | last= Lindley
  | first= Dennis V.
  | title= Theory and Practice of Bayesian Statistics
  | journal= The Statistician 
  | volume= 32
  | issue= 1/2
  | pages= 1–11
  | year= 1983
  | doi= 10.2307/2987587
  | jstor= 2987587}}

[[Category:Learning theory (education)]]
[[Category:Machine learning]]</text>
      <sha1>fjs6inh9xj2a63z4z6i2nzm8vogxvno</sha1>
    </revision>
  </page>
  <page>
    <title>Robot learning</title>
    <ns>0</ns>
    <id>3290880</id>
    <revision>
      <id>948379243</id>
      <parentid>933109271</parentid>
      <timestamp>2020-03-31T18:41:37Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <comment>Alter: title. | You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | Activated by [[User:Zppix]] | [[Category:Machine learning‎]] | via #UCB_Category</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="9603" xml:space="preserve">'''Robot learning''' is a research field at the intersection of [[machine learning]] and [[robotics]]. It studies techniques allowing a robot to acquire novel skills or adapt to its environment through learning algorithms. The embodiment of the robot, situated in a physical embedding, provides at the same time specific difficulties (e.g. high-dimensionality, real time constraints for collecting data and learning) and opportunities for guiding the learning process (e.g. sensorimotor synergies, motor primitives).

Example of skills that are targeted by learning algorithms include sensorimotor skills such as locomotion, grasping, active [[Object recognition|object categorization]],  as well as interactive skills such as joint manipulation of an object with a human peer, and linguistic skills such as the grounded and situated [[Natural-language understanding|meaning of human language]]. Learning can happen either through autonomous self-exploration or through guidance from a human teacher, like for example in robot learning by imitation.

Robot learning can be closely related to [[adaptive control]], [[reinforcement learning]] as well as [[developmental robotics]] which considers the problem of autonomous lifelong acquisition of repertoires of skills.
While [[machine learning]] is frequently used by [[computer vision]] algorithms employed in the context of robotics, these applications are usually not referred to as "robot learning".

&lt;!--
==Methods==
See: http://www.allaboutcircuits.com/news/google-tasks-robots-with-learning-skills-from-one-another-via-cloud-robotic/
---&gt;

==Projects==
{{Expand section|date=January 2017}}
Maya Cakmak, assistant professor of computer science and engineering at the [[University of Washington]], is trying to create a robot that learns by imitating - a technique called "[[programming by demonstration]]". A researcher shows it a cleaning technique for the robot's vision system and it generalizes the cleaning motion from the human demonstration as well as identifying the "state of dirt" before and after cleaning.&lt;ref&gt;{{cite web|last1=Rosenblum|first1=Andrew|title=The robot you want most is far from reality|url=https://www.technologyreview.com/s/602128/the-robot-you-want-most-is-far-from-reality/|publisher=MIT Technology Review|accessdate=4 January 2017}}&lt;/ref&gt;

Similarly the [[Baxter (robot)|Baxter]] industrial robot can be taught how to do something by grabbing its arm and showing it the desired movements.&lt;ref&gt;{{cite web|title=Hands-on with Baxter, the factory robot of the future|url=https://arstechnica.com/gadgets/2014/06/hands-on-with-baxter-the-factory-robot-of-the-future/|publisher=Ars Technica|accessdate=4 January 2017}}&lt;/ref&gt; It can also use deep learning to teach itself to grasp an unknown object.&lt;ref&gt;{{cite web|title=Deep-Learning Robot Takes 10 Days to Teach Itself to Grasp|url=https://www.technologyreview.com/s/542076/deep-learning-robot-takes-10-days-to-teach-itself-to-grasp/|publisher=MIT Technology Review|accessdate=4 January 2017}}&lt;/ref&gt;&lt;ref name=technologyreview1/&gt;

==Sharing learned skills and knowledge==
{{Further|Cloud robotics}}
In Tellex's "Million Object Challenge," the goal is robots that learn how to spot and handle simple items and upload their data to the cloud to allow other robots to analyze and use the information.&lt;ref name="technologyreview1"&gt;{{cite web|last1=Schaffer|first1=Amanda|title=10 Breakthrough Technologies 2016: Robots That Teach Each Other|url=https://www.technologyreview.com/s/600768/10-breakthrough-technologies-2016-robots-that-teach-each-other/|publisher=MIT Technology Review|accessdate=4 January 2017}}&lt;/ref&gt;

[[RoboBrain]] is a knowledge engine for robots which can be freely accessed by any device wishing to carry out a task. The database gathers new information about tasks as robots perform them, by searching the Internet, interpreting natural language text, images, and videos, [[object recognition]] as well as interaction. The project is led by [[Ashutosh Saxena]] at [[Stanford University]].&lt;ref&gt;{{cite web|title=RoboBrain: The World's First Knowledge Engine For Robots|url=https://www.technologyreview.com/s/533471/robobrain-the-worlds-first-knowledge-engine-for-robots/|publisher=MIT Technology Review|accessdate=4 January 2017}}&lt;/ref&gt;&lt;ref&gt;{{cite web|last1=Hernandez|first1=Daniela|title=The Plan to Build a Massive Online Brain for All the World's Robots|url=https://www.wired.com/2014/08/robobrain/|publisher=WIRED|accessdate=4 January 2017}}&lt;/ref&gt;

[[RoboEarth]] is a project that has been described as a "[[World Wide Web]]&lt;!--and [[Wikipedia]]--&gt; for robots" − it is a network and database repository where robots can share information and learn from each other and a cloud for outsourcing heavy computation tasks. The project brings together researchers from five major universities in Germany, the Netherlands and Spain and is backed by the [[European Union]].&lt;ref&gt;{{cite web|title=Europe launches RoboEarth: 'Wikipedia for robots'|url=https://www.usatoday.com/story/tech/2014/01/17/robot-robotics-roboearth-europe-munich-netherlands/4575021/|publisher=USA TODAY|accessdate=4 January 2017}}&lt;/ref&gt;&lt;ref&gt;{{cite web|title=European researchers have created a hive mind for robots and it's being demoed this week|url=https://www.engadget.com/2014/01/14/roboearth-demo/|publisher=Engadget|accessdate=4 January 2017}}&lt;/ref&gt;&lt;ref&gt;{{cite web|title=Robots test their own world wide web, dubbed RoboEarth|url=https://www.bbc.com/news/technology-25727110|publisher=BBC News|accessdate=4 January 2017|date=14 January 2014}}&lt;/ref&gt;&lt;ref&gt;{{cite web|title='Wikipedia for robots': Because bots need an Internet too|url=https://www.cnet.com/news/wikipedia-for-robots-because-bots-need-an-internet-too/|publisher=CNET|accessdate=4 January 2017}}&lt;/ref&gt;&lt;ref&gt;{{cite web|title=New Worldwide Network Lets Robots Ask Each Other Questions When They Get Confused|url=http://www.popsci.com/technology/article/2013-03/new-cloud-engine-robots-can-learn-each-other|publisher=Popular Science|accessdate=4 January 2017}}&lt;/ref&gt;

Google Research, [[DeepMind]], and [[Google X]] have decided to allow their robots share their experiences.&lt;ref&gt;{{cite web|title=Google Tasks Robots with Learning Skills from One Another via Cloud Robotics|url=http://www.allaboutcircuits.com/news/google-tasks-robots-with-learning-skills-from-one-another-via-cloud-robotic/|website=allaboutcircuits.com|accessdate=4 January 2017}}&lt;/ref&gt;&lt;ref&gt;{{cite web|last1=Tung|first1=Liam|title=Google's next big step for AI: Getting robots to teach each other new skills {{!}} ZDNet|url=http://www.zdnet.com/article/googles-next-big-step-for-ai-getting-robots-to-teach-each-other-new-skills/|publisher=ZDNet|accessdate=4 January 2017}}&lt;/ref&gt;&lt;ref&gt;{{cite web|title=How Robots Can Acquire New Skills from Their Shared Experience|url=https://research.googleblog.com/2016/10/how-robots-can-acquire-new-skills-from.html|publisher=Google Research Blog|accessdate=4 January 2017}}&lt;/ref&gt;

==See also==

* [[Developmental robotics]]
* [[Cognitive robotics]]
* [[Evolutionary robotics]]

==References==
{{reflist}}

==External links==
* [http://www.ieee-ras.org/robot-learning IEEE RAS Technical Committee on Robot Learning (official IEEE website)]
* [http://learning-robots.de IEEE RAS Technical Committee on Robot Learning (TC members website)]
* [http://robot-learning.de  Robot Learning at the Max Planck Institute for Intelligent Systems and the Technical University Darmstadt]
* [http://www-clmc.usc.edu Robot Learning at the Computational Learning and Motor Control lab]
* [http://www.cns.atr.jp/ccc/en/ Humanoid Robot Learning at the Advanced Telecommunication Research Center (ATR)] {{in lang|en|ja}}
* [http://lasa.epfl.ch Learning Algorithms and Systems Laboratory at EPFL (LASA)]
* [http://www.idsia.ch/~juergen/learningrobots.html Robot Learning] at the [http://www.idsia.ch/~juergen/cogbotlab.html Cognitive Robotics Lab] of [[Juergen Schmidhuber]] at [[IDSIA]] and [[Technical University of Munich]]
* [https://web.archive.org/web/20070630111131/http://humanoid.fy.chalmers.se/ The Humanoid Project]: [[Peter Nordin]], [[Chalmers University of Technology]]
* [http://flowers.inria.Fr Inria and Ensta ParisTech FLOWERS team, France]: Autonomous lifelong learning in developmental robotics
* [https://www.cit-ec.de/ CITEC at University of Bielefeld, Germany]
* [https://web.archive.org/web/20130601122743/http://www.er.ams.eng.osaka-u.ac.jp/asadalab/index_en.html Asada Laboratory], Department of Adaptive Machine Systems, Graduate School of Engineering, Osaka University, Japan
* [http://www-robotics.cs.umass.edu/index.php The Laboratory for Perceptual Robotics], [[University of Massachusetts Amherst]] Amherst, USA
* [http://www.tech.plym.ac.uk/SOCCE/CRNS/ Centre for Robotics and Neural Systems], [http://www.plymouth.ac.uk/ Plymouth University] Plymouth, United Kingdom
* [https://www.cs.cmu.edu/~rll/ Robot Learning Lab] at [[Carnegie Mellon University]]
* [http://www.nimbro.net Project Learning Humanoid Robots] at [[University of Bonn]]
* [http://www.skilligent.com/ Skilligent Robot Learning and Behavior Coordination System (commercial product)]
* [http://www.cs.cornell.edu/Courses/cs4758/ Robot Learning class] at [[Cornell University]]
* [http://www.iit.it/en/advr-labs/learning-and-interaction.html Robot Learning and Interaction Lab] at [[Italian Institute of Technology]]
* [http://www.dcsc.tudelft.nl/~robotics/media.html Reinforcement learning for robotics] at [[Delft University of Technology]]

{{Robotics}}

[[Category:Robot control|Learning]]
[[Category:Machine learning]]
[[Category:Learning]]</text>
      <sha1>lwbzzhqncq757ktc19lqh2no995r13m</sha1>
    </revision>
  </page>
  <page>
    <title>Version space learning</title>
    <ns>0</ns>
    <id>7578809</id>
    <revision>
      <id>1000372056</id>
      <parentid>1000159131</parentid>
      <timestamp>2021-01-14T20:53:45Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>References after punctuation per [[WP:REFPUNCT]], [[WP:CITEFOOT]], [[WP:PAIC]] + other fixes</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="7123" xml:space="preserve">[[Image:Version space.png|thumb|right|300px|Version space for a "rectangle" hypothesis language in two dimensions.  Green pluses are positive examples, and red circles are negative examples.  GB is the maximally '''general''' positive hypothesis boundary, and SB is the maximally '''specific''' positive hypothesis boundary.  The intermediate (thin) rectangles represent the hypotheses in the version space.]]
'''Version space learning''' is a [[Symbolic artificial intelligence|logical]] approach to [[machine learning]], specifically [[binary classification]]. Version space learning algorithms search a predefined space of [[hypothesis|hypotheses]], viewed as a set of [[Sentence (logic)|logical sentences]]. Formally, the hypothesis space is a [[Logical disjunction|disjunction]]&lt;ref name="aima"&gt;{{Cite AIMA|2|pages=683–686}}&lt;/ref&gt;

:&lt;math&gt;H_1 \lor H_2 \lor ... \lor H_n&lt;/math&gt;

(i.e., either hypothesis 1 is true, or hypothesis 2, or any subset of the hypotheses 1 through {{mvar|n}}). A version space learning algorithm is presented with examples, which it will use to restrict its hypothesis space; for each example {{mvar|x}}, the hypotheses that are [[Consistency|inconsistent]] with {{mvar|x}} are removed from the space.&lt;ref name="Mitchel-1982"/&gt; This iterative refining of the hypothesis space is called the '''candidate elimination''' algorithm, the hypothesis space maintained inside the algorithm its ''version space''.{{r|aima}}

==The version space algorithm==
In settings where there is a generality-ordering on hypotheses, it is possible to represent the version space by two sets of hypotheses: (1) the '''most specific''' consistent hypotheses, and (2) the '''most general''' consistent hypotheses, where "consistent" indicates agreement with observed data.

The most specific hypotheses (i.e., the specific boundary '''SB''') cover the observed positive training examples, and as little of the remaining [[feature (machine learning)|feature space]] as possible.  These hypotheses, if reduced any further, ''exclude'' a ''positive'' training example, and hence become inconsistent.  These minimal hypotheses essentially constitute a (pessimistic) claim that the true concept is defined just by the ''positive'' data already observed: Thus, if a novel (never-before-seen) data point is observed, it should be assumed to be negative.  (I.e., if data has not previously been ruled in, then it's ruled out.)

The most general hypotheses (i.e., the general boundary '''GB''') cover the observed positive training examples, but also cover as much of the remaining feature space without including any negative training examples.  These, if enlarged any further, ''include'' a ''negative'' training example, and hence become inconsistent.  These maximal hypotheses essentially constitute a (optimistic) claim  that the true concept is defined just by the ''negative'' data already observed: Thus, if a novel (never-before-seen) data point is observed, it should be assumed to be positive. (I.e., if data has not previously been ruled out, then it's ruled in.)

Thus, during learning, the version space (which itself is a set – possibly infinite – containing ''all'' consistent hypotheses) can be represented by just its lower and upper bounds (maximally general and maximally specific hypothesis sets), and learning operations can be performed just on these representative sets.

After learning, classification can be performed on unseen examples by testing the hypothesis learned by the algorithm. If the example is consistent with multiple hypotheses, a majority vote rule can be applied.{{r|aima}}

==Historical background==
The notion of version spaces was introduced by Mitchell in the early 1980s{{r|Mitchel-1982}} as a framework for understanding the basic problem of supervised learning within the context of [[state space search|solution search]].  Although the basic "'''candidate elimination'''" search method that accompanies the version space framework is not a popular learning algorithm, there are some practical implementations that have been developed (e.g., Sverdlik &amp; Reynolds 1992, Hong &amp; Tsang 1997, Dubois &amp; Quafafou 2002).

A major drawback of version space learning is its inability to deal with noise: any pair of inconsistent examples can cause the version space to ''collapse'', i.e., become empty, so that classification becomes impossible.{{r|aima}} One solution of this problem is proposed by Dubois and Quafafou that proposed the Rough Version Space,&lt;ref name="Dubois Quafafou 2002"/&gt; where rough sets based approximations are used to learn certain and possible hypothesis in the presence of inconsistent data.

==See also==
*[[Formal concept analysis]]
*[[Inductive logic programming]]
*[[Rough set]]. [The rough set framework focuses on the case where ambiguity is introduced by an impoverished '''feature set'''. That is, the target concept cannot be decisively described because the available feature set fails to disambiguate objects belonging to different categories.  The version space framework focuses on the (classical induction) case where the ambiguity is introduced by an impoverished '''data set'''.  That is, the target concept cannot be decisively described because the available data fails to uniquely pick out a hypothesis.  Naturally, both types of ambiguity can occur in the same learning problem.]
*[[Inductive reasoning]]. [On the general problem of induction.]

==References==
&lt;references&gt;
&lt;ref name="Mitchel-1982"&gt;
{{cite journal
  | last = Mitchell
  | first = Tom M.
  | title = Generalization as search
  | journal = Artificial Intelligence
  | volume = 18
  | issue = 2
  | pages = 203–226
  | year = 1982
  | doi = 10.1016/0004-3702(82)90040-6}}
&lt;/ref&gt;
&lt;ref name="Dubois Quafafou 2002"&gt;
{{cite conference
  | first = Vincent 
  | last = Dubois
  |author2=Quafafou, Mohamed
  | title = Concept learning with approximation: Rough version spaces
  | book-title = Rough Sets and Current Trends in Computing: Proceedings of the Third International Conference, RSCTC 2002.    
  | pages = 239–246 
  | year = 2002
  | location = Malvern, Pennsylvania| doi = 10.1007/3-540-45813-1_31
 }}
&lt;/ref&gt;
&lt;/references&gt;

*{{cite journal
  | last = Hong      
  | first = Tzung-Pai 
  |author2=Shian-Shyong Tsang 
   | title = A generalized version space learning algorithm for noisy and uncertain data
  | journal = IEEE Transactions on Knowledge and Data Engineering   
  | volume = 9
  | issue = 2
  | pages = 336–340 
  | year = 1997 
  | doi = 10.1109/69.591457| url = https://semanticscholar.org/paper/60e5a9389fe2bf7ae993600256b1e952901e9c04 
 }}
*{{cite book
  | last = Mitchell
  | first = Tom M.
  | title = Machine Learning
  | publisher = McGraw-Hill
  | year = 1997
  | location = Boston}}
*{{cite conference
  | first = W.
  | last = Sverdlik     
  |author2=Reynolds, R.G.
   | title = Dynamic version spaces in machine learning
  | book-title = Proceedings, Fourth International Conference on Tools with Artificial Intelligence (TAI '92)   
  | pages = 308–315 
  | year = 1992
  | location = Arlington, VA}}

[[Category:Machine learning]]</text>
      <sha1>nolm90b4isnoopkg667cwvd6xpfvbzp</sha1>
    </revision>
  </page>
  <page>
    <title>Evolvability (computer science)</title>
    <ns>0</ns>
    <id>8416103</id>
    <revision>
      <id>993271784</id>
      <parentid>959884429</parentid>
      <timestamp>2020-12-09T18:55:40Z</timestamp>
      <contributor>
        <username>Michaelwallace22</username>
        <id>39374154</id>
      </contributor>
      <comment>deorphan</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="6254" xml:space="preserve">{{primary sources|date=October 2016}}
The term '''evolvability''' is used for a recent framework of computational learning introduced by [[Leslie Valiant]] in his paper of the same name and described below. The aim of this theory is to model biological evolution and categorize which types of mechanisms are evolvable. Evolution is an extension of [[Probably approximately correct learning|PAC learning]] and learning from statistical queries.

==General Framework==

Let &lt;math&gt;F_n\,&lt;/math&gt; and &lt;math&gt;R_n\,&lt;/math&gt; be collections of functions on &lt;math&gt;n\,&lt;/math&gt; variables. Given an ''ideal function'' &lt;math&gt;f \in F_n&lt;/math&gt;, the goal is to find by local search a ''representation'' &lt;math&gt;r \in R_n&lt;/math&gt; that closely approximates &lt;math&gt;f\,&lt;/math&gt;. This closeness is measured by the ''performance'' &lt;math&gt;\operatorname{Perf}(f,r)&lt;/math&gt; of &lt;math&gt;r\,&lt;/math&gt; with respect to &lt;math&gt;f\,&lt;/math&gt;.

As is the case in the biological world, there is a difference between genotype and phenotype. In general, there can be multiple representations (genotypes) that correspond to the same function (phenotype). That is, for some &lt;math&gt;r,r' \in R_n&lt;/math&gt;, with &lt;math&gt;r \neq r'\,&lt;/math&gt;, still &lt;math&gt;r(x) = r'(x)\,&lt;/math&gt; for all &lt;math&gt;x \in X_n&lt;/math&gt;. However, this need not be the case. The goal then, is to find a representation that closely matches the phenotype of the ideal function, and the spirit of the local search is to allow only small changes in the genotype. Let the ''neighborhood'' &lt;math&gt;N(r)\,&lt;/math&gt; of a representation &lt;math&gt;r\,&lt;/math&gt; be the set of possible mutations of &lt;math&gt;r\,&lt;/math&gt;.

For simplicity, consider Boolean functions on &lt;math&gt;X_n = \{-1,1\}^n\,&lt;/math&gt;, and let &lt;math&gt;D_n\,&lt;/math&gt; be a probability distribution on &lt;math&gt;X_n\,&lt;/math&gt;. Define the performance in terms of this. Specifically,
:&lt;math&gt; \operatorname{Perf}(f,r) = \sum_{x \in X_n} f(x) r(x) D_n(x). &lt;/math&gt;
Note that &lt;math&gt;\operatorname{Perf}(f,r) = \operatorname{Prob}(f(x)=r(x)) - \operatorname{Prob}(f(x) \neq r(x)).&lt;/math&gt; In general, for non-Boolean functions, the performance will not correspond directly to the probability that the functions agree, although it will have some relationship.

Throughout an organism's life, it will only experience a limited number of environments, so its performance cannot be determined exactly. The ''empirical performance'' is defined by
&lt;math&gt; \operatorname{Perf}_s(f,r) = \frac{1}{s} \sum_{x \in S} f(x)r(x), &lt;/math&gt;
where &lt;math&gt;S\,&lt;/math&gt; is a multiset of &lt;math&gt;s\,&lt;/math&gt; independent selections from &lt;math&gt;X_n\,&lt;/math&gt; according to &lt;math&gt;D_n\,&lt;/math&gt;. If &lt;math&gt;s\,&lt;/math&gt; is large enough, evidently &lt;math&gt;\operatorname{Perf}_s(f,r)&lt;/math&gt; will be close to the actual performance &lt;math&gt;\operatorname{Perf}(f,r)&lt;/math&gt;.

Given an ideal function &lt;math&gt;f \in F_n&lt;/math&gt;, initial representation &lt;math&gt;r \in R_n&lt;/math&gt;, ''sample size'' &lt;math&gt;s\,&lt;/math&gt;, and ''tolerance'' &lt;math&gt;t\,&lt;/math&gt;, the ''mutator'' &lt;math&gt;\operatorname{Mut}(f,r,s,t)&lt;/math&gt; is a random variable defined as follows. Each &lt;math&gt;r' \in N(r)&lt;/math&gt; is classified as beneficial, neutral, or deleterious, depending on its empirical performance. Specifically,
* &lt;math&gt;r'\,&lt;/math&gt; is a beneficial mutation if &lt;math&gt;\operatorname{Perf}_s(f,r') - \operatorname{Perf}_s(f,r) \geq t&lt;/math&gt;;
* &lt;math&gt;r'\,&lt;/math&gt; is a neutral mutation if &lt;math&gt;-t &lt; \operatorname{Perf}_s(f,r') - \operatorname{Perf}_s(f,r) &lt; t&lt;/math&gt;;
* &lt;math&gt;r'\,&lt;/math&gt; is a deleterious mutation if &lt;math&gt;\operatorname{Perf}_s(f,r') - \operatorname{Perf}_s(f,r) \leq -t&lt;/math&gt;.

If there are any beneficial mutations, then &lt;math&gt;\operatorname{Mut}(f,r,s,t)&lt;/math&gt; is equal to one of these at random. If there are no beneficial mutations, then &lt;math&gt;\operatorname{Mut}(f,r,s,t)&lt;/math&gt; is equal to a random neutral mutation. In light of the similarity to biology, &lt;math&gt;r\,&lt;/math&gt; itself is required to be available as a mutation, so there will always be at least one neutral mutation.

The intention of this definition is that at each stage of evolution, all possible mutations of the current genome are tested in the environment. Out of the ones who thrive, or at least survive, one is chosen to be the candidate for the next stage. Given &lt;math&gt;r_0 \in R_n&lt;/math&gt;, we define the sequence &lt;math&gt;r_0,r_1,r_2,\ldots&lt;/math&gt; by &lt;math&gt;r_{i+1} = \operatorname{Mut}(f,r_i,s,t)&lt;/math&gt;. Thus &lt;math&gt;r_g\,&lt;/math&gt; is a random variable representing what &lt;math&gt;r_0\,&lt;/math&gt; has evolved to after &lt;math&gt;g\,&lt;/math&gt; ''generations''.

Let &lt;math&gt;F\,&lt;/math&gt; be a class of functions, &lt;math&gt;R\,&lt;/math&gt; be a class of representations, and &lt;math&gt;D\,&lt;/math&gt; a class of distributions on &lt;math&gt;X\,&lt;/math&gt;. We say that &lt;math&gt;F\,&lt;/math&gt; is ''evolvable by &lt;math&gt;R\,&lt;/math&gt; over &lt;math&gt;D\,&lt;/math&gt;'' if there exists polynomials &lt;math&gt;p(\cdot,\cdot)&lt;/math&gt;, &lt;math&gt;s(\cdot,\cdot)&lt;/math&gt;, &lt;math&gt;t(\cdot,\cdot)&lt;/math&gt;, and &lt;math&gt;g(\cdot,\cdot)&lt;/math&gt; such that for all &lt;math&gt;n\,&lt;/math&gt; and all &lt;math&gt;\epsilon &gt; 0\,&lt;/math&gt;, for all ideal functions &lt;math&gt;f \in F_n&lt;/math&gt; and representations &lt;math&gt;r_0 \in R_n&lt;/math&gt;, with probability at least &lt;math&gt;1 - \epsilon\,&lt;/math&gt;,
:&lt;math&gt; \operatorname{Perf}(f,r_{g(n,1/\epsilon)}) \geq 1-\epsilon, &lt;/math&gt;
where the sizes of neighborhoods &lt;math&gt;N(r)\,&lt;/math&gt; for &lt;math&gt;r \in R_n\,&lt;/math&gt; are at most &lt;math&gt;p(n,1/\epsilon)\,&lt;/math&gt;, the sample size is &lt;math&gt;s(n,1/\epsilon)\,&lt;/math&gt;, the tolerance is &lt;math&gt;t(1/n,\epsilon)\,&lt;/math&gt;, and the generation size is &lt;math&gt;g(n,1/\epsilon)\,&lt;/math&gt;.

&lt;math&gt;F\,&lt;/math&gt; is ''evolvable over &lt;math&gt;D\,&lt;/math&gt;'' if it is evolvable by some &lt;math&gt;R\,&lt;/math&gt; over &lt;math&gt;D\,&lt;/math&gt;.

&lt;math&gt;F\,&lt;/math&gt; is ''evolvable'' if it is evolvable over all distributions &lt;math&gt;D\,&lt;/math&gt;.

==Results==
The class of conjunctions and the class of disjunctions are evolvable over the uniform distribution for short conjunctions and disjunctions, respectively.

The class of parity functions (which evaluate to the parity of the number of true literals in a given subset of literals) are not evolvable, even for the uniform distribution.

Evolvability implies [[Probably approximately correct learning|PAC learnability]].

==References==
#{{citation|first=L. G.|last=Valiant|authorlink=Leslie Valiant|title=Evolvability|year=2006|id={{ECCC|2006|06|120}}}}.

[[Category:Machine learning]]</text>
      <sha1>dpv11ei4jol7zjcimcd2366t9usuu2h</sha1>
    </revision>
  </page>
  <page>
    <title>Prior knowledge for pattern recognition</title>
    <ns>0</ns>
    <id>6881120</id>
    <revision>
      <id>908623928</id>
      <parentid>799308468</parentid>
      <timestamp>2019-07-30T22:11:25Z</timestamp>
      <contributor>
        <username>Jarble</username>
        <id>7226930</id>
      </contributor>
      <comment>adding links to references using [[Google Scholar]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="5464" xml:space="preserve">[[Pattern recognition]] is a very active field of research intimately bound to [[machine learning]]. Also known as classification or [[statistical classification]], pattern recognition aims at building a [[classifier (mathematics)|classifier]] that can determine the class of an input pattern. This procedure, known as training, corresponds to learning an unknown decision function based only on a set of input-output pairs &lt;math&gt;(\boldsymbol{x}_i,y_i)&lt;/math&gt; that form the training data (or training set). Nonetheless, in real world applications such as [[character recognition]], a certain amount of information on the problem is usually known beforehand. The incorporation of this prior knowledge into the training is the key element that will allow an increase of performance in many applications.

== Prior Knowledge ==

Prior knowledge&lt;ref&gt;B. Scholkopf and A. Smola, "[https://books.google.com/books?id=y8ORL3DWt4sC&amp;printsec=frontcover#v=onepage&amp;q=%22prior%20knowledge%22&amp;f=false Learning with Kernels]", MIT Press 2002.&lt;/ref&gt; refers to all information about the problem available in addition to the training data. However, in this most general form, determining a [[Model (abstract)|model]] from a finite set of samples without prior knowledge is an [[ill-posed]] problem, in the sense that a unique model may not exist. Many classifiers incorporate the general smoothness assumption that a test pattern similar to one of the training samples tends to be assigned to the same class.

The importance of prior knowledge in machine learning is suggested by its role in search and optimization. Loosely, the [[No free lunch in search and optimization|no free lunch theorem]] states that all search algorithms have the same average performance over all problems, and thus implies that to gain in performance on a certain application one must use a specialized algorithm that includes some prior knowledge about the problem. &lt;!-- This sentence is still not right. Read the "no free lunch" article to see why. 
David Wolpert actually published NFL-like results for machine learning before moving to
optimization with Bill Macready. Check his web site at NASA for a list of his publications.--&gt;

The different types of prior knowledge encountered in pattern recognition are now regrouped under two main categories: class-invariance and knowledge on the data.

== Class-invariance ==

A very common type of prior knowledge in pattern recognition is the invariance of the class (or the output of the classifier) to a [[Transformation (geometry)|transformation]] of the input pattern. This type of knowledge is referred to as '''transformation-invariance'''. The mostly used transformations used in image recognition are:

* [[Translation (geometry)|translation]];
* [[Rotation (mathematics)|rotation]];
* [[skewing]];
* [[Scaling (geometry)|scaling]].

Incorporating the invariance to a transformation &lt;math&gt;T_{\theta}: \boldsymbol{x} \mapsto T_{\theta}\boldsymbol{x}&lt;/math&gt; parametrized in &lt;math&gt;\theta&lt;/math&gt;  into a classifier of output &lt;math&gt;f(\boldsymbol{x})&lt;/math&gt; for an input pattern &lt;math&gt;\boldsymbol{x}&lt;/math&gt; corresponds to enforcing the equality

:&lt;math&gt;
f(\boldsymbol{x}) = f(T_{\theta}\boldsymbol{x}), \quad \forall \boldsymbol{x}, \theta .&lt;/math&gt;

Local invariance can also be considered for a transformation centered at &lt;math&gt;\theta=0&lt;/math&gt;, so that &lt;math&gt;T_0\boldsymbol{x} = \boldsymbol{x}&lt;/math&gt;, by using the constraint

:&lt;math&gt;
  \left.\frac{\partial}{\partial \theta}\right|_{\theta=0} f(T_{\theta} \boldsymbol{x}) = 0 .
&lt;/math&gt;

The function &lt;math&gt;f&lt;/math&gt; in these equations can be either the decision function of the classifier or its real-valued output.

Another approach is to consider class-invariance with respect to a "domain of the input space" instead of a transformation. In this case, the problem becomes finding &lt;math&gt;f&lt;/math&gt; so that

:&lt;math&gt;
	f(\boldsymbol{x}) = y_{\mathcal{P}},\ \forall \boldsymbol{x}\in \mathcal{P} ,
&lt;/math&gt;

where &lt;math&gt;y_{\mathcal{P}}&lt;/math&gt; is the membership class of the region &lt;math&gt;\mathcal{P}&lt;/math&gt; of the input space.

A different type of class-invariance found in pattern recognition is '''permutation-invariance''', i.e. invariance of the class to a permutation of elements in a structured input. A typical application of this type of prior knowledge is a classifier invariant to permutations of rows of the matrix inputs.

== Knowledge of the data ==

Other forms of prior knowledge than class-invariance concern the data more specifically and are thus of particular interest for real-world applications. The three particular cases that most often occur when gathering data are:
* '''Unlabeled samples''' are available with supposed class-memberships;
* '''Imbalance''' of the training set due to a high proportion of samples of a class;
* '''Quality of the data''' may vary from a sample to another.

Prior knowledge of these can enhance the quality of the recognition if included in the learning. Moreover, not taking into account the poor quality of some data or a large imbalance between the classes can mislead the decision of a classifier.

== Notes ==

&lt;references/&gt;

== References ==

* E. Krupka and N. Tishby, "[http://www.jmlr.org/proceedings/papers/v2/krupka07a.html Incorporating Prior Knowledge on Features into Learning]", Eleventh International Conference on Artificial Intelligence and Statistics (AISTATS 07)

[[Category:Machine learning]]
[[Category:Statistical classification]]</text>
      <sha1>p4c5hoj0w8jvekb3g11wr76loihnbwi</sha1>
    </revision>
  </page>
  <page>
    <title>Granular computing</title>
    <ns>0</ns>
    <id>1041204</id>
    <revision>
      <id>990958413</id>
      <parentid>988983449</parentid>
      <timestamp>2020-11-27T14:07:42Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 35 templates: del empty params (25×); hyphenate params (7×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="41157" xml:space="preserve">'''Granular computing''' (GrC) is an emerging [[computing]] paradigm of [[information processing]] that concerns the processing of complex information entities called "information [[granulation|granules]]", which arise in the process of data abstraction and [[knowledge extraction|derivation of knowledge]] from information or data.  Generally speaking, information granules are collections of entities that usually originate at the numeric level and are arranged together due to their [[Similarity measure|similarity]], functional or physical adjacency, indistinguishability, coherency, or the like.

At present, granular computing is more a ''theoretical perspective'' than a coherent set of methods or principles.  As a theoretical perspective, it encourages an approach to data that recognizes and exploits the knowledge present in data at various levels of resolution or scales.  In this sense, it encompasses all methods which provide flexibility and adaptability in the resolution at which knowledge or information is extracted and represented.

== Types of granulation ==
[[File:Catarina 26 mar 2004 1310Z.jpg|thumb|upright=1.10|Satellite view of cyclone.]] 
[[File:NASA Manhattan.jpg|thumb|upright=1.10|Satellite view of Manhattan.]] 
As mentioned above, ''granular computing'' is not an algorithm or process; there is no particular method that is called "granular computing".  It is rather an approach  to looking at data that recognizes how different and interesting regularities in the data can appear at different levels of granularity, much as different features become salient in [[satellite images]] of greater or lesser resolution.  On a low-resolution satellite image, for example, one might notice interesting cloud patterns representing [[cyclones]] or other large-scale weather phenomena, while in a higher-resolution image, one misses these large-scale atmospheric phenomena but instead notices smaller-scale phenomena, such as the interesting pattern that is the streets of [[Manhattan]].  The same is generally true of all data: At different resolutions or granularities, different features and relationships emerge.  The aim of granular computing is to try to take advantage of this fact in designing more effective machine-learning and reasoning systems.

There are several types of granularity that are often encountered in [[data mining]] and [[machine learning]], and we review them below:

=== Value granulation (discretization/quantization) ===
One type of granulation is the [[Quantization (signal processing)|quantization]] of variables.  It is very common that in data mining or machine-learning applications the resolution of variables needs to be ''decreased'' in order to extract meaningful regularities.  An example of this would be a variable such as "outside temperature" (&lt;math&gt;temp&lt;/math&gt;), which in a given application might be recorded to several decimal places of [[Arithmetic precision|precision]] (depending on the sensing apparatus).  However, for purposes of extracting relationships between "outside temperature" and, say, "number of health-club applications" (&lt;math&gt;club &lt;/math&gt;), it will generally be advantageous to quantize "outside temperature" into a smaller number of intervals.

==== Motivations ====
There are several interrelated reasons for granulating variables in this fashion:
* Based on prior [[domain knowledge]], there is no expectation that minute variations in temperature (e.g., the difference between {{convert|80|-|80.7|°F|C|1}}) could have an influence on behaviors driving the number of health-club applications.  For this reason, any "regularity" which our learning algorithms might detect at this level of resolution would have to be ''spurious'', as an artifact of overfitting.  By coarsening the temperature variable into intervals the difference between which we ''do'' anticipate (based on prior domain knowledge) might influence  number of health-club applications, we eliminate the possibility of detecting these spurious  patterns.  Thus, in this case, reducing resolution is a method of controlling [[overfitting]].
* By reducing the number of intervals in the temperature variable (i.e., increasing its ''grain size''), we increase the amount of sample data indexed by each interval designation.  Thus, by coarsening the variable, we increase sample sizes and achieve better statistical estimation.  In this sense, increasing granularity provides an antidote to the so-called ''[[curse of dimensionality]]'', which relates to the exponential decrease in statistical power with increase in number of dimensions or variable cardinality.
*Independent of prior domain knowledge, it is often the case that meaningful regularities (i.e., which can be detected by a given learning methodology, representational language, etc.) may exist at one level of resolution and not at another.

[[File:Value granulation.png|thumb|200 px|Benefits of value granulation: Implications here exist at the resolution of &lt;math&gt;\{X_i,Y_j\}&lt;/math&gt; that do not exist at the higher resolution of &lt;math&gt;\{x_i,y_j\}&lt;/math&gt;; in particular, &lt;math&gt;\forall x_i,y_j: x_i \not\to y_j&lt;/math&gt;, while at the same time, &lt;math&gt;\forall X_i \exists Y_j: X_i \leftrightarrow Y_j&lt;/math&gt;.]]
For example, a simple learner or pattern recognition system may seek to extract regularities satisfying a [[conditional probability]] threshold such as &lt;math&gt;p(Y=y_j|X=x_i) \ge \alpha &lt;/math&gt;.  In the special case where &lt;math&gt;\alpha = 1 &lt;/math&gt;, this recognition system is essentially detecting ''[[logical implication]]'' of the form &lt;math&gt;X=x_i \rightarrow Y=y_j &lt;/math&gt; or, in words, "if &lt;math&gt;X=x_i&lt;/math&gt;, then &lt;math&gt;Y=y_j &lt;/math&gt;".  The system's ability to recognize such implications (or, in general, conditional probabilities exceeding threshold)  is partially contingent on the resolution with which the system analyzes the variables.

As an example of this last point, consider the feature space shown to the right.  The variables may each be regarded at two different resolutions.  Variable &lt;math&gt;X&lt;/math&gt; may be regarded at a high (quaternary) resolution wherein it takes on the four values &lt;math&gt;\{x_1, x_2, x_3, x_4\}&lt;/math&gt; or at a lower (binary) resolution wherein it takes on the two values &lt;math&gt;\{X_1, X_2\}&lt;/math&gt;.  Similarly, variable &lt;math&gt;Y&lt;/math&gt; may be regarded at a high (quaternary) resolution or at a lower (binary) resolution, where it takes on the values &lt;math&gt;\{y_1, y_2, y_3, y_4\}&lt;/math&gt; or &lt;math&gt;\{Y_1, Y_2\}&lt;/math&gt;, respectively. At the high resolution, there are '''no''' detectable implications of the form &lt;math&gt;X=x_i \rightarrow Y=y_j &lt;/math&gt;, since every &lt;math&gt;x_i&lt;/math&gt; is associated with more than one &lt;math&gt;y_j&lt;/math&gt;, and thus, for all &lt;math&gt;x_i&lt;/math&gt;, &lt;math&gt;p(Y=y_j|X=x_i) &lt; 1 &lt;/math&gt;.  However, at the low (binary) variable resolution, two bilateral implications become detectable:    &lt;math&gt;X=X_1 \leftrightarrow Y=Y_1 &lt;/math&gt; and &lt;math&gt;X=X_2 \leftrightarrow Y=Y_2 &lt;/math&gt;, since every &lt;math&gt;X_1&lt;/math&gt; occurs ''iff'' &lt;math&gt;Y_1&lt;/math&gt; and &lt;math&gt;X_2&lt;/math&gt; occurs ''iff'' &lt;math&gt;Y_2&lt;/math&gt;.  Thus, a pattern recognition system scanning for implications of this kind would find them at the binary variable resolution, but would fail to find them at the   higher quaternary variable resolution.

====Issues and methods====
It is not feasible to exhaustively test all possible discretization resolutions on all variables in order to see which combination of resolutions yields interesting or significant results.  Instead, the feature space must be preprocessed (often by an [[information entropy|entropy]] analysis of some kind) so that some guidance can be given as to how the discretization process should proceed.  Moreover, one cannot generally achieve good results by naively analyzing and discretizing each variable independently, since this may obliterate the very interactions that we had hoped to discover.

A sample of papers that address the problem of variable discretization in general, and multiple-variable discretization in particular, is as follows: {{Harvtxt|Chiu|Wong|Cheung|1991}}, {{Harvtxt|Bay|2001}},  {{Harvtxt|Liu|Hussain|Tan|Dasii|2002}}, {{Harvtxt|Wang|Liu|1998}}, {{Harvtxt|Zighed|Rabaséda|Rakotomalala|1998}}, {{Harvtxt|Catlett|1991}}, {{Harvtxt|Dougherty|Kohavi|Sahami|1995}}, {{Harvtxt|Monti|Cooper|1999}}, {{Harvtxt|Fayyad|Irani|1993}}, {{Harvtxt|Chiu|Cheung|Wong|1990}}, {{Harvtxt|Nguyen|Nguyen|1998}}, {{Harvtxt|Grzymala-Busse|Stefanowski|2001}}, {{Harvtxt|Ting|1994}}, {{Harvtxt|Ludl|Widmer|2000}}, {{Harvtxt|Pfahringer|1995}}, {{Harvtxt|An|Cercone|1999}}, 
{{Harvtxt|Chiu|Cheung|1989}}, {{Harvtxt|Chmielewski|Grzymala-Busse|1996}}, {{Harvtxt|Lee|Shin|1994}}, {{Harvtxt|Liu|Wellman|2002}}, {{Harvtxt|Liu|Wellman|2004}}.

=== Variable granulation (clustering/aggregation/transformation) ===
Variable granulation is a term that could describe a variety of techniques, most of which are aimed at reducing dimensionality, redundancy, and storage requirements.  We briefly describe some of the ideas here, and present pointers to the literature.

====Variable transformation====
A number of classical methods, such as [[principal component analysis]], [[multidimensional scaling]], [[factor analysis]], and [[structural equation modeling]], and their relatives, fall under the genus of "variable transformation."  Also in this category are more modern areas of study such as [[dimensionality reduction]], [[projection pursuit]], and [[independent component analysis]].  The common goal of these methods in general is to find a representation of the data in terms of new variables, which are a linear or nonlinear transformation of the original variables, and in which important statistical relationships emerge. The resulting variable sets are almost always smaller than the original variable set, and hence these methods can be loosely said to impose a granulation on the feature space.  These dimensionality reduction methods are all reviewed in the standard texts, such as {{Harvtxt|Duda|Hart|Stork|2001}}, {{Harvtxt|Witten|Frank|2005}}, and {{Harvtxt|Hastie|Tibshirani|Friedman|2001}}.

====Variable aggregation====
A different class of variable granulation methods derive more from [[data clustering]] methodologies than from the linear systems theory informing the above methods.  It was noted fairly early that one may consider "clustering" related variables in just  the same way that one considers clustering related data.  In data clustering, one identifies a group of similar entities (using a "[[measure of similarity]]" suitable to the domain — {{Harvtxt|Martino|Giuliani|Rizzi|2018}}), and then in some sense ''replaces'' those entities with a prototype of some kind.  The prototype may be the simple average of the data in the identified cluster, or some other representative measure.  But the key idea is that in subsequent operations, we may be able to use the single prototype for the data cluster (along with perhaps a statistical model describing how exemplars are derived from the prototype) to ''stand in'' for the much larger set of exemplars.   These prototypes are generally such as to capture most of the information of interest concerning the entities.

[[File:Kraskov tree.png|thumb|400 px|A Watanabe-Kraskov variable agglomeration tree. Variables are agglomerated (or "unitized") from the bottom-up, with each merge-node representing a (constructed) variable having entropy equal to the joint entropy of the agglomerating variables. Thus, the agglomeration of two m-ary variables &lt;math&gt;X_1&lt;/math&gt; and &lt;math&gt;X_2&lt;/math&gt; having individual entropies &lt;math&gt;H(X_1)&lt;/math&gt; and &lt;math&gt;H(X_2)&lt;/math&gt; yields a single &lt;math&gt;m^2&lt;/math&gt;-ary variable &lt;math&gt;X_{1,2}&lt;/math&gt; with entropy &lt;math&gt;H(X_{1,2})=H(X_1,X_2)&lt;/math&gt;. When &lt;math&gt;X_1&lt;/math&gt; and &lt;math&gt;X_2&lt;/math&gt; are highly dependent (i.e., redundant) and have large mutual information &lt;math&gt;I(X_1;X_2)&lt;/math&gt;, then &lt;math&gt;H(X_{1,2})&lt;/math&gt; ≪ &lt;math&gt;H(X_1)+H(X_2)&lt;/math&gt; because &lt;math&gt;H(X_1,X_2)=H(X_1)+H(X_2)-I(X_1;X_2)&lt;/math&gt;, and this would be considered a parsimonious unitization or aggregation.]]
Similarly, it is reasonable to ask whether a large set of variables might be aggregated into a smaller set of ''prototype'' variables that capture the most salient relationships between the variables.    Although variable clustering methods based on [[linear correlation]] have been proposed ({{Harvnb|Duda|Hart|Stork|2001}};{{Harvnb|Rencher|2002}}), more powerful methods of variable clustering are based on the [[mutual information]] between variables. Watanabe has shown ({{Harvnb|Watanabe|1960}};{{Harvnb|Watanabe|1969}}) that for any set of variables one can construct a ''[[polytomy|polytomic]]'' (i.e., n-ary) tree representing a series of variable agglomerations in which the ultimate "total" correlation  among the complete variable set is the sum of the "partial" correlations exhibited by each agglomerating subset (see figure). Watanabe suggests that an observer might seek to thus partition a system in such a way as to minimize the interdependence between the parts "... as if they were looking for a natural division or a hidden crack."

One practical approach to building such a tree is to successively choose for agglomeration the two variables (either atomic variables or previously agglomerated variables) which have the highest pairwise mutual information {{Harv|Kraskov|Stögbauer|Andrzejak|Grassberger|2003}}. The product of each agglomeration is a new (constructed) variable that reflects the local [[joint distribution]] of the two agglomerating variables, and thus possesses an entropy equal to their [[joint entropy]].
(From a procedural standpoint, this agglomeration step involves replacing two columns in the attribute-value table—representing the two agglomerating variables—with a single column that has a unique value for every unique combination of values in the replaced columns {{Harv|Kraskov|Stögbauer|Andrzejak|Grassberger|2003}}.  No information is lost by such an operation; however, if one is exploring the data for inter-variable relationships, it would generally ''not'' be desirable to merge redundant variables in this way, since in such a context it is likely to be precisely the redundancy or ''dependency'' between variables that is of interest;  and once redundant variables are merged, their relationship to one another can no longer be studied.

=== System granulation (aggregation) ===

In [[database systems]], aggregations (see e.g. [[OLAP|OLAP aggregation]] and [[Business intelligence]] systems) result in transforming original data tables (often called information systems) into the tables with different semantics of rows and columns, wherein the rows correspond to the groups (granules) of original tuples and the columns express aggregated information about original values within each of the groups. Such aggregations are usually based on SQL and its extensions. The resulting granules usually correspond to the groups of original tuples with the same values (or ranges) over some pre-selected original columns.

There are also other approaches wherein the groups are defined basing on, e.g., physical adjacency of rows. For example, [[Infobright]] implemented a database engine wherein data was partitioned onto ''rough rows'', each consisting of 64K of physically consecutive (or almost consecutive) rows. Rough rows were automatically labeled with compact information about their values on data columns, often involving multi-column and multi-table relationships. It resulted in a higher layer of granulated information where objects corresponded to rough rows and attributes - to various aspects of rough information. Database operations could be efficiently supported within such a new framework, with an access to the original data pieces still available {{Harv|Slezak|Synak|Wróblewski|Wojna|2013}}.

=== Concept granulation (component analysis) ===
The origins of the ''granular computing'' ideology are to be found in the [[rough sets]] and [[fuzzy sets]] literatures.  One of the key insights of rough set research—although by no means unique to it—is that, in general, the selection of different sets of features or variables will yield different ''concept'' granulations.  Here, as in elementary rough set theory, by "concept" we mean a set of entities that are ''indistinguishable'' or ''indiscernible'' to the observer (i.e., a simple concept), or a set of entities that is composed from such simple concepts (i.e., a complex concept).  To put it in other words, by projecting a data set ([[value-attribute system]]) onto different sets of variables, we recognize alternative sets of equivalence-class "concepts" in the data, and these different sets of concepts will in general be conducive to the extraction of different relationships and regularities.

====Equivalence class granulation====
We illustrate with an example.  Consider the attribute-value system below:

:{| class="wikitable" style="text-align:center; width:30%" border="1"
|+ Sample Information System
! Object !! &lt;math&gt;P_{1}&lt;/math&gt; !! &lt;math&gt;P_{2}&lt;/math&gt; !! &lt;math&gt;P_{3}&lt;/math&gt; !! &lt;math&gt;P_{4}&lt;/math&gt; !! &lt;math&gt;P_{5}&lt;/math&gt;
|-
! &lt;math&gt;O_{1}&lt;/math&gt;
| 1 || 2 || 0 || 1 || 1
|-
! &lt;math&gt;O_{2}&lt;/math&gt;
| 1 || 2 || 0 || 1 || 1
|-
! &lt;math&gt;O_{3}&lt;/math&gt;
| 2 || 0 || 0 || 1 || 0
|-
! &lt;math&gt;O_{4}&lt;/math&gt;
| 0 || 0 || 1 || 2 || 1
|-
! &lt;math&gt;O_{5}&lt;/math&gt;
| 2 || 1 || 0 || 2 || 1
|-
! &lt;math&gt;O_{6}&lt;/math&gt;
| 0 || 0 || 1 || 2 || 2
|-
! &lt;math&gt;O_{7}&lt;/math&gt;
| 2 || 0 || 0 || 1 || 0
|-
! &lt;math&gt;O_{8}&lt;/math&gt;
| 0 || 1 || 2 || 2 || 1
|-
! &lt;math&gt;O_{9}&lt;/math&gt;
| 2 || 1 || 0 || 2 || 2
|-
! &lt;math&gt;O_{10}&lt;/math&gt;
| 2 || 0 || 0 || 1 || 0
|}

When the full set of attributes &lt;math&gt;P = \{P_{1},P_{2},P_{3},P_{4},P_{5}\}&lt;/math&gt; is considered, we see that we have the following seven equivalence classes or primitive (simple) concepts:

:&lt;math&gt;
\begin{cases} 
\{O_{1},O_{2}\} \\ 
\{O_{3},O_{7},O_{10}\} \\ 
\{O_{4}\} \\ 
\{O_{5}\} \\
\{O_{6}\} \\
\{O_{8}\} \\
\{O_{9}\} \end{cases}
&lt;/math&gt;

Thus, the two objects within the first equivalence class, &lt;math&gt;\{O_{1},O_{2}\}&lt;/math&gt;,  cannot be distinguished from one another based on the available attributes, and the three objects within the second equivalence class, &lt;math&gt;\{O_{3},O_{7},O_{10}\}&lt;/math&gt;, cannot be distinguished from one another based on the available attributes.  The remaining five objects are each discernible from all other objects.  Now, let us imagine a projection of the attribute value system onto attribute &lt;math&gt;P_{1}&lt;/math&gt; alone, which would represent, for example, the  view from an observer which is only capable of detecting this single attribute. Then we obtain the following much coarser equivalence class structure.

:&lt;math&gt;
\begin{cases} 
\{O_{1},O_{2}\} \\ 
\{O_{3},O_{5},O_{7},O_{9},O_{10}\} \\ 
\{O_{4},O_{6},O_{8}\} \end{cases}
&lt;/math&gt;

This is in a certain regard the same structure as before, but at a lower degree of resolution (larger grain size).  Just as in the case of [[#Value granulation (discretization/quantization)|value granulation (discretization/quantization)]], it is possible that relationships (dependencies) may emerge at one level of granularity that are not present at another.  As an example of this, we can consider the effect of concept granulation on the measure known as ''attribute dependency'' (a simpler relative of the [[mutual information]]).

To establish this notion of dependency (see also [[rough sets]]), let &lt;math&gt;[x]_Q = \{Q_1, Q_2, Q_3, \dots, Q_N \}&lt;/math&gt; represent a particular concept granulation, where each &lt;math&gt;Q_i&lt;/math&gt; is an equivalence class from the concept structure induced by attribute set &lt;math&gt;Q&lt;/math&gt;.  For example, if the  attribute set &lt;math&gt;Q&lt;/math&gt; consists of attribute &lt;math&gt;P_{1}&lt;/math&gt; alone, as above,  then the concept structure &lt;math&gt;[x]_Q&lt;/math&gt; will be composed of    &lt;math&gt;Q_1 = \{O_{1},O_{2}\}&lt;/math&gt;, &lt;math&gt;Q_2 = \{O_{3},O_{5},O_{7},O_{9},O_{10}\}&lt;/math&gt;, and &lt;math&gt;Q_3 = \{O_{4},O_{6},O_{8}\}&lt;/math&gt;.  The '''dependency''' of attribute set &lt;math&gt;Q&lt;/math&gt; on another attribute set &lt;math&gt;P&lt;/math&gt;, &lt;math&gt;\gamma_{P}(Q)&lt;/math&gt;, is given by

:&lt;math&gt;
\gamma_{P}(Q) =  \frac{\left | \sum_{i=1}^N {\underline P}Q_i \right |} {\left | \mathbb{U} \right |} \leq 1
&lt;/math&gt;

That is, for each equivalence class &lt;math&gt;Q_i&lt;/math&gt; in &lt;math&gt;[x]_Q&lt;/math&gt;, we add up the size of its "lower approximation" (see [[rough sets]]) by the attributes in &lt;math&gt;P&lt;/math&gt;, i.e., &lt;math&gt;{\underline P}Q_i&lt;/math&gt;.  More simply, this approximation  is the number of objects which on attribute set &lt;math&gt;P&lt;/math&gt; can be positively identified as belonging to target set &lt;math&gt;Q_i&lt;/math&gt;.  Added across all equivalence classes in &lt;math&gt;[x]_Q&lt;/math&gt;, the numerator above represents the total number of objects which—based on attribute set &lt;math&gt;P&lt;/math&gt;—can be positively categorized according to the classification induced by  attributes &lt;math&gt;Q&lt;/math&gt;.  The dependency ratio therefore expresses the proportion (within the entire universe) of such classifiable objects, in a sense capturing the "synchronization" of the two concept structures &lt;math&gt;[x]_Q&lt;/math&gt; and &lt;math&gt;[x]_P&lt;/math&gt;.  The dependency &lt;math&gt;\gamma_{P}(Q)&lt;/math&gt; "can be interpreted as a proportion of such objects in the information system for which it suffices to know the values of attributes in &lt;math&gt;P&lt;/math&gt; to determine the values of attributes in &lt;math&gt;Q&lt;/math&gt;" (Ziarko &amp; Shan 1995).

Having gotten definitions now out of the way, we can make the simple observation that the choice of concept granularity (i.e., choice of attributes) will influence the detected dependencies among attributes.  Consider again the attribute value table from above:

:{| class="wikitable" style="text-align:center; width:30%" border="1"
|+ Sample Information System
! Object !! &lt;math&gt;P_{1}&lt;/math&gt; !! &lt;math&gt;P_{2}&lt;/math&gt; !! &lt;math&gt;P_{3}&lt;/math&gt; !! &lt;math&gt;P_{4}&lt;/math&gt; !! &lt;math&gt;P_{5}&lt;/math&gt;
|-
! &lt;math&gt;O_{1}&lt;/math&gt;
| 1 || 2 || 0 || 1 || 1
|-
! &lt;math&gt;O_{2}&lt;/math&gt;
| 1 || 2 || 0 || 1 || 1
|-
! &lt;math&gt;O_{3}&lt;/math&gt;
| 2 || 0 || 0 || 1 || 0
|-
! &lt;math&gt;O_{4}&lt;/math&gt;
| 0 || 0 || 1 || 2 || 1
|-
! &lt;math&gt;O_{5}&lt;/math&gt;
| 2 || 1 || 0 || 2 || 1
|-
! &lt;math&gt;O_{6}&lt;/math&gt;
| 0 || 0 || 1 || 2 || 2
|-
! &lt;math&gt;O_{7}&lt;/math&gt;
| 2 || 0 || 0 || 1 || 0
|-
! &lt;math&gt;O_{8}&lt;/math&gt;
| 0 || 1 || 2 || 2 || 1
|-
! &lt;math&gt;O_{9}&lt;/math&gt;
| 2 || 1 || 0 || 2 || 2
|-
! &lt;math&gt;O_{10}&lt;/math&gt;
| 2 || 0 || 0 || 1 || 0
|}

Consider the dependency of attribute set  &lt;math&gt;Q = \{P_4, P_5\}&lt;/math&gt;
on attribute set &lt;math&gt;P = \{P_2, P_3\}&lt;/math&gt;.  That is, we wish to know what proportion of objects can be correctly classified into classes of &lt;math&gt;[x]_Q&lt;/math&gt; based on knowledge of &lt;math&gt;[x]_P&lt;/math&gt;.  The equivalence classes of &lt;math&gt;[x]_Q&lt;/math&gt; and of &lt;math&gt;[x]_P&lt;/math&gt; are shown below.

:{| class="wikitable"
|-
! &lt;math&gt;[x]_Q&lt;/math&gt;
! &lt;math&gt;[x]_P&lt;/math&gt;
|-
| &lt;math&gt;
\begin{cases} 
\{O_{1},O_{2}\} \\ 
\{O_{3},O_{7},O_{10}\} \\ 
\{O_{4},O_{5},O_{8}\} \\
\{O_{6},O_{9}\}\end{cases}
&lt;/math&gt;
| &lt;math&gt;
\begin{cases} 
\{O_{1},O_{2}\} \\ 
\{O_{3},O_{7},O_{10}\} \\ 
\{O_{4},O_{6}\} \\
\{O_{5},O_{9}\} \\
\{O_{8}\}\end{cases}
&lt;/math&gt;
|}

The objects that can be ''definitively'' categorized according to concept structure &lt;math&gt;[x]_Q&lt;/math&gt; based on &lt;math&gt;[x]_P&lt;/math&gt; are those in the set &lt;math&gt;\{O_{1},O_{2},O_{3},O_{7},O_{8},O_{10}\}&lt;/math&gt;, and since there are six of these, the dependency of &lt;math&gt;Q&lt;/math&gt; on &lt;math&gt;P&lt;/math&gt;,  &lt;math&gt;\gamma_{P}(Q) = 6/10&lt;/math&gt;.  This might be considered an interesting dependency in its own right, but perhaps in a particular data mining application only stronger dependencies are desired.

We might then consider the dependency of the smaller attribute set  &lt;math&gt;Q = \{P_4\}&lt;/math&gt;
on the attribute set &lt;math&gt;P = \{P_2, P_3\}&lt;/math&gt;.  The move from &lt;math&gt;Q = \{P_4, P_5\}&lt;/math&gt; to &lt;math&gt;Q = \{P_4\}&lt;/math&gt; induces a coarsening of the class structure &lt;math&gt;[x]_Q&lt;/math&gt;, as will be seen shortly.  We wish again to know what proportion of objects can be correctly classified into the (now larger) classes of &lt;math&gt;[x]_Q&lt;/math&gt; based on knowledge of &lt;math&gt;[x]_P&lt;/math&gt;.  The equivalence classes of the new &lt;math&gt;[x]_Q&lt;/math&gt; and of &lt;math&gt;[x]_P&lt;/math&gt; are shown below.

:{| class="wikitable"
|-
! &lt;math&gt;[x]_Q&lt;/math&gt;
! &lt;math&gt;[x]_P&lt;/math&gt;
|-
| &lt;math&gt;
\begin{cases} 
\{O_{1},O_{2},O_{3},O_{7},O_{10}\} \\ 
\{O_{4},O_{5},O_{6},O_{8},O_{9}\} \end{cases}
&lt;/math&gt;
| &lt;math&gt;
\begin{cases} 
\{O_{1},O_{2}\} \\ 
\{O_{3},O_{7},O_{10}\} \\ 
\{O_{4},O_{6}\} \\
\{O_{5},O_{9}\} \\
\{O_{8}\}\end{cases}
&lt;/math&gt;
|}

Clearly, &lt;math&gt;[x]_Q&lt;/math&gt; has a coarser granularity than it did earlier.  The objects that can now be ''definitively'' categorized according to the concept structure &lt;math&gt;[x]_Q&lt;/math&gt; based on &lt;math&gt;[x]_P&lt;/math&gt; constitute the complete universe &lt;math&gt;\{O_{1},O_{2},\ldots,O_{10}\}&lt;/math&gt;, and thus  the dependency of &lt;math&gt;Q&lt;/math&gt; on &lt;math&gt;P&lt;/math&gt;,  &lt;math&gt;\gamma_{P}(Q) = 1&lt;/math&gt;.  That is, knowledge of membership according to category set  &lt;math&gt;[x]_P&lt;/math&gt; is adequate to determine category membership in &lt;math&gt;[x]_Q&lt;/math&gt; with complete certainty; In this case we might say that &lt;math&gt;P \rightarrow Q&lt;/math&gt;.  Thus, by coarsening the concept structure, we were able to find a stronger (deterministic) dependency.  However, we also note that the classes induced in &lt;math&gt;[x]_Q&lt;/math&gt; from the reduction in resolution necessary to obtain this deterministic dependency are now themselves large and few in number; as a result, the dependency we found, while strong, may be less valuable to us than the weaker dependency found earlier under the higher resolution view of &lt;math&gt;[x]_Q&lt;/math&gt;.

In general it is not possible to test all sets of attributes to see which induced concept structures yield the strongest dependencies, and this search must be therefore be guided with some intelligence.  Papers which discuss this issue, and others relating to intelligent use of granulation, are those by Y.Y. Yao and [[Lotfi Zadeh]] listed in the [[#References]] below.

====Component granulation====
Another perspective on concept granulation may be obtained from work on parametric models of categories.  In [[mixture model]] learning, for example, a set of data is explained as a mixture of distinct [[Gaussian distribution|Gaussian]] (or other) distributions.  Thus, a large amount of data is "replaced" by a small number of distributions.  The choice of the number of these distributions, and their size, can again be viewed as a problem of ''concept granulation''.  In general, a better fit to the data is obtained by a larger number of distributions or parameters, but in order to extract meaningful patterns, it is necessary to constrain the number of distributions, thus deliberately  ''coarsening'' the concept resolution.  Finding the "right" concept resolution is a tricky problem for which many methods have been proposed (e.g., [[Akaike information criterion|AIC]], [[Bayesian information criterion|BIC]], [[Minimum description length|MDL]], etc.), and these are frequently  considered under the rubric of "[[model regularization]]".

==Different interpretations of granular computing==
Granular computing can be conceived as a framework of theories, methodologies, techniques, and tools that make use of information granules in the process of problem solving.  In this sense, granular computing is used as an umbrella term to cover topics that have been studied in various fields in isolation.  By examining all of these existing studies in light of the unified framework of granular computing and extracting their commonalities, it may be possible to develop a general theory for problem solving.

In a more philosophical sense, granular computing can describe a way of thinking that relies on the human ability to perceive the real world under various levels of granularity (i.e., abstraction) in order to abstract and consider only those things that serve a specific interest and to switch among different granularities. By focusing on different levels of granularity, one can obtain different levels of knowledge, as well as a greater understanding of the inherent knowledge structure.  Granular computing is thus essential in human problem solving and hence has a very significant impact on the design and implementation of intelligent systems.

== See also ==
* [[Rough set|Rough Sets]], [[Discretization]]
* [[Type-2 Fuzzy Sets and Systems]]

== References ==
{{refbegin|2}}
*{{Citation | last=An| first=Aijun |last2=Cercone| first2=Nick|year= 1999| chapter=Discretization of continuous attributes for learning classification rules | editor=Ning Zhong |editor2=Lizhu Zhou | title=Methodologies for Knowledge Discovery and Data Mining: Proceedings of the Third Pacific-Asia Conference, PAKDD-99 | volume=1574 | place=[[Beijing, China]] |doi=10.1007/3-540-48912-6_69 |pages=509–514| series=Lecture Notes in Computer Science | isbn=978-3-540-65866-5 }}.
*Bargiela, A. and Pedrycz, W. (2003) ''Granular Computing. An introduction'', Kluwer Academic Publishers
*{{Citation | last=Bay| first=Stephen D. | title=Multivariate discretization for set mining | journal=Knowledge and Information Systems |volume=3 |issue=4 | year=2001| pages=491–512 |doi=10.1007/PL00011680| citeseerx=10.1.1.217.921 }}.
*{{Citation | last=Catlett| first=J.|year= 1991| chapter=On changing continuous attributes into ordered discrete attributes | editor=Y. Kodratoff | title=Machine Learning—EWSL-91: European Working Session on Learning | place=[[Porto, Portugal]] | chapter-url=http://portal.acm.org/citation.cfm?coll=GUIDE&amp;dl=GUIDE&amp;id=112164 |pages=164–178}}.
*{{Citation | last=Chiu| first=David K. Y. | last2=Cheung| first2=Benny |year= 1989| chapter=Hierarchical maximum entropy discretization | editor=Ryszard Janicki |editor2=Waldemar W. Koczkodaj | title=Computing and Information: Proceedings of the International Conference on Computing and Information (ICCI '89) | publisher=North-Holland | place=[[Toronto|Toronto, Ontario]], Canada |pages=237–242}}.
*{{Citation | last=Chiu| first=David K. Y. | last3=Wong| first3=Andrew K. C.|last2=Cheung| first2=Benny | title=Information synthesis based on hierarchical maximum entropy discretization | journal=[[Journal of Experimental and Theoretical Artificial Intelligence]] |volume=2 |issue= 2| year=1990| pages=117–129 | doi=10.1080/09528139008953718}}.
*{{Citation | last=Chiu| first=David K. Y. | last2=Wong| first2=Andrew K. C.|last3=Cheung| first3=Benny |year= 1991| chapter=Information discovery through hierarchical maximum entropy discretization and synthesis | editor=Gregory Piatetsky-Shapiro |editor2=William J. Frawley | title=Knowledge Discovery in Databases | publisher=MIT Press | place=[[Cambridge, MA]] |pages=126–140}}.
*{{Citation | last=Chmielewski| first=Michal R. | last2=Grzymala-Busse| first2=Jerzy W.| title=Global discretization of continuous attributes as preprocessing for machine learning | journal=International Journal of Approximate Reasoning |volume=15 |issue= 4| year=1996| pages=319–331 | url=http://kuscholarworks.ku.edu/dspace/bitstream/1808/412/1/j36-draft.pdf | doi=10.1016/s0888-613x(96)00074-6}}.
*{{Citation | last=Dougherty| first=James | last2=Kohavi| first2=Ron | last3=Sahami| first3=Mehran| year=1995|chapter=Supervised and unsupervised discretization of continuous features | editor=Armand Prieditis |editor2=Stuart Russell | title=Machine Learning: Proceedings of the Twelfth International Conference (ICML 1995) | publisher=Morgan Kaufmann | place=[[Tahoe City, CA]] | chapter-url=http://citeseer.ist.psu.edu/dougherty95supervised.html |pages=194–202}}.
*{{Citation | last=Duda| first=Richard O.| last2=Hart| first2=Peter E. | last3=Stork| first3=David G. |title=Pattern Classification| publisher=John Wiley &amp; Sons| place=[[New York City]] | year=2001| edition=2nd |isbn=978-0-471-05669-0}}
*{{Citation | last=Fayyad| first=Usama M.| last2=Irani| first2=Keki B.|  year=1993|chapter=Multi-interval discretization of continuous-valued attributes for classification learning| title=Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence (IJCAI-93) | place=[[Chambéry, France]] |pages=1022–1027}}.
*{{Citation | last=Grzymala-Busse| first=Jerzy W. | last2=Stefanowski| first2=Jerzy| title=Three discretization methods for rule induction | journal=International Journal of Intelligent Systems |volume=16 |issue=1 | year=2001| pages=29–38 | doi=10.1002/1098-111X(200101)16:1&lt;29::AID-INT4&gt;3.0.CO;2-0| citeseerx=10.1.1.330.2975 }}.
*{{Citation | last=Hastie| first=Trevor|author-link1=Trevor Hastie|last2=Tibshirani| first2=Robert |author-link2=Robert Tibshirani| last3=Friedman| first3=Jerome |title=The Elements of Statistical Learning: Data Mining, Inference, and Prediction| publisher=Springer| place=[[New York City]] | year=2001| isbn=978-0-387-84857-0}}
*{{Citation
 | last=Kraskov | first=Alexander | last2=Stögbauer | first2=Harald
 | last3=Andrzejak| first3=Ralph G. | last4=Grassberger | first4=Peter
 | title=Hierarchical clustering based on mutual information
 | year=2003| arxiv=q-bio/0311039| bibcode=2003q.bio....11039K}}.
*{{Citation
 | last=Lee | first=Changhwan | last2=Shin | first2=Dong-Guk
 | year=1994
 | chapter=A context-sensitive discretization of numeric attributes for classification learning
 | editor=A. G. Cohn
 | title=Proceedings of the 11th European Conference on Artificial Intelligence (ECAI 94)
 | place=[[Netherlands|NL]]
 |pages=428–432}}.
*{{Citation
 | last=Liu | first=Chao-Lin | last2=Wellman | first2=Michael
 | year=2002
 | title=Evaluation of Bayesian networks with flexible state-space abstraction methods
 | journal=International Journal of Approximate Reasoning
 | volume=30 | issue=1 | pages=1–39 | doi=10.1016/S0888-613X(01)00067-6| citeseerx=10.1.1.127.7040 }}.
*{{Citation
 | last=Liu | first=Chao-Lin | last2=Wellman | first2=Michael
 | year=2004
 | title= Bounding probabilistic relationships in Bayesian networks using qualitative influences: Methods and applications
 | journal=International Journal of Approximate Reasoning
 | volume=36 | issue=1 | pages=31–73 | doi=10.1016/j.ijar.2003.06.002}}.
*{{Citation
 | last=Liu | first=Huan | last2=Hussain | first2=Farhad
 | last3=Tan| first3=Chew Lim | last4=Dasii | first4=Manoranjan
 | title=Discretization: An enabling technique
 | journal=Data Mining and Knowledge Discovery
 | volume=6 |issue=4 | year=2002| pages=393–423
 | doi=10.1023/A:1016304305535}}.
*{{Citation
 | last=Ludl | first=Marcus-Christopher | last2=Widmer | first2=Gerhard
 | year=2000
 | chapter=Relative unsupervised discretization for association rule mining
 | editor=Djamel A. Zighed |editor2=Jan Komorowski |editor3=Jan Zytkow
 | title=Proceedings of the 4th European Conference on Principles of Data Mining and Knowledge Discovery (PKDD 2000)
 | volume=1910 | place=[[Lyon, France]]
 | doi=10.1007/3-540-45372-5_15 |pages=148–158| series=Lecture Notes in Computer Science | isbn=978-3-540-41066-9 | doi-access=free }}.
*{{Citation
 | last=Monti | first=Stefano | last2=Cooper | first2=Gregory F.
 | year=1999
 | chapter=A latent variable model for multivariate discretization
 | title=Uncertainty 99: The 7th International Workshop on Artificial Intelligence and Statistics
 | place=[[Fort Lauderdale, FL]]
 | chapter-url=http://citeseer.ist.psu.edu/monti99latent.html }}.
*{{Citation
 | last=Martino | first=Alessio | last2=Giuliani | first2=Alessandro | last3=Rizzi | first3=Antonello
 | year=2018
 | chapter=Granular Computing Techniques for Bioinformatics Pattern Recognition Problems in Non-metric Spaces
 |editor=Pedrycz W. |editor2=Chen SM.
 | title=Computational Intelligence for Pattern Recognition
 | volume=777 | publisher=Springer International Publishing 
 |pages=53–81| doi=10.1007/978-3-319-89629-8_3 | series=Studies in Computational Intelligence | isbn=978-3-319-89628-1 }}.
*{{Citation
 | last=Nguyen | first=Hung Son | last2=Nguyen | first2=Sinh Hoa
 | year=1998 | chapter=Discretization methods in data mining
 | editor=Lech Polkowski |editor2=Andrzej Skowron
 | title=Rough Sets in Knowledge Discovery 1: Methodology and Applications
 | publisher=Physica-Verlag | place=[[Heidelberg]]
 | pages=451–482}}.
*{{Citation
 | last=Pfahringer | first=Bernhard | year=1995
 | chapter=Compression-based discretization of continuous attributes
 | editor=Armand Prieditis |editor2=Stuart Russell
 | title=Machine Learning: Proceedings of the Twelfth International Conference (ICML 1995)
 | publisher=Morgan Kaufmann | place=[[Tahoe City, CA]]
 | chapter-url=http://citeseer.ist.psu.edu/pfahringer95compressionbased.html 
 |pages=456–463}}.
*{{Citation
 | last=Rencher | first=Alvin C.
 | title=Methods of Multivariate Analysis
 | publisher=Wiley | place=[[New York City]] | year=2002}}.
*{{Citation
 | last=Simon | first=Herbert A. | last2=Ando | first2=Albert
 | year= 1963
 | chapter=Aggregation of variables in dynamic systems
 | editor=Albert Ando |editor2=Franklin M. Fisher |editor3=Herbert A. Simon
 | title=Essays on the Structure of Social Science Models
 | publisher=MIT Press | place=Cambridge, MA | pages=64–91
}}
*{{Citation
 | last=Simon | first=Herbert A.
 | year= 1996
 | chapter=The architecture of complexity: Hierarchic systems
 | editor=Herbert A. Simon
 | title=The Sciences of the Artificial
 | edition=2nd | publisher=MIT Press | place=Cambridge, MA
 | pages=183–216}}
*{{Citation | last=Slezak| first=Dominik | last2=Synak| first2=Piotr| last3=Wojna| first3=Arkadiusz| last4=Wroblewski| first4=Jakub| title=Two Database Related Interpretations of Rough Approximations: Data Organization and Query Execution | journal=Fundamenta Informaticae |volume=127 |issue=1–4 | year=2013| pages=445–459 | doi=10.3233/FI-2013-920}}.
*{{Citation
 | last=Ting| first=Kai Ming
 | title=Discretization of continuous-valued attributes and instance-based learning (Technical Report No.491)
 | publisher=Basser Department of Computer Science
 | place=[[Sydney]] | year=1994
 | url=http://citeseer.ist.psu.edu/145651.html }}.
*{{Citation
 | last=Wang | first=Ke | last2=Liu| first2=Bing
 | year=1998 | chapter=Concurrent discretization of multiple attributes
 | editor=Springer
 | title=Proceedings of the 5th Pacific Rim International Conference on Artificial Intelligence
 | publisher=Springer-Verlag | place=[[London]]
 | chapter-url=http://citeseer.ist.psu.edu/wang98concurrent.html
 |pages=250–259}}.
*{{Citation
 | last=Watanabe| first=Satosi
 | author-link=Satosi Watanabe
 | title=Information theoretical analysis of multivariate correlation
 | journal=IBM Journal of Research and Development
 | volume=4 |issue=1 | year=1960| pages=66–82 | doi=10.1147/rd.41.0066}}.
*{{Citation
 | last=Watanabe| first=Satosi
 | author-link=Satosi Watanabe
 | title=Knowing and Guessing: A Quantitative Study of Inference and Information
 | publisher=Wiley | place=[[New York City]] | year=1969}}.
*{{Citation
 | last=Witten | first=Ian H. | last2=Frank| first2=Eibe
 | title=Data Mining: Practical Machine Learning Tools and Techniques
 | publisher=Morgan Kaufmann | place=[[Amsterdam]] | edition=2
 | year=2005 | url=http://www.cs.waikato.ac.nz/~ml/weka/book.html}}
*Yao, Y.Y. (2004) "A Partition Model of Granular Computing", Lecture Notes in Computer Science (to appear)
*{{cite conference
  | first = Y. Y. | last = Yao
  | title = On modeling data mining with granular computing
  | book-title = Proceedings of the 25th Annual International Computer Software and Applications Conference (COMPSAC 2001)
  | pages = 638–643
  | year = 2001
  | url = http://portal.acm.org/citation.cfm?id=675398}}
*{{cite conference
  | first = Yiyu
  | last = Yao
  | title = Granular computing for data mining
  | book-title = Proceedings of the SPIE Conference on Data Mining, Intrusion Detection, Information Assurance, and Data Networks Security
  | year = 2006
  | editor = [[Belur V. Dasarathy|Dasarathy, Belur V.]]
  | url = http://www2.cs.uregina.ca/~yyao/PAPER_PDF/grcfordm06.pdf
  | archive-url = https://wayback.archive-it.org/all/20070418031341/http://www.cs.uregina.ca/~yyao/PAPER_PDF/grcfordm06.pdf
  | url-status = dead
  | archive-date = 2007-04-18
  }}
*{{cite conference
  | first = J. T. | last = Yao
  |author2=Yao, Y. Y.
  | title = Induction of classification rules by granular computing
  | book-title = Proceedings of the Third International Conference on Rough Sets and Current Trends in Computing (TSCTC'02)
  | pages = 331–338
  | publisher = Springer-Verlag
  | year = 2002
  | location = London, UK
  | url = http://www2.cs.uregina.ca/~jtyao/Papers/53_RSCTC02.pdf}}
*Zadeh, L.A. (1997) "Toward a Theory of Fuzzy Information Granulation and its Centrality in Human Reasoning and Fuzzy Logic"'', Fuzzy Sets and Systems'', 90:111-127
*{{Citation
 | last=Zighed | first=D. A. | last2=Rabaséda | first2=S.
 | last3=Rakotomalala | first3=R.
 | title=FUSINTER: A method for discretization of continuous attributes
 | journal=[[International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems]]
 | volume=6 | issue=3 | year=1998 | pages=307–326
 | url=http://portal.acm.org/citation.cfm?id=353472 | doi=10.1142/s0218488598000264}}.
{{refend}}

[[Category:Theoretical computer science]]
[[Category:Machine learning]]</text>
      <sha1>aupb20nsr4ha4i6ccml8z6jzyl0lj12</sha1>
    </revision>
  </page>
  <page>
    <title>Probability matching</title>
    <ns>0</ns>
    <id>9731945</id>
    <revision>
      <id>979055008</id>
      <parentid>876929142</parentid>
      <timestamp>2020-09-18T14:16:33Z</timestamp>
      <contributor>
        <username>Paradoctor</username>
        <id>4082870</id>
      </contributor>
      <comment>added [[Category:Cognitive biases]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2264" xml:space="preserve">{{no footnotes|date=February 2015}}
'''Probability matching''' is a [[decision strategy]] in which predictions of class membership are proportional to the class [[base rates]].  Thus, if in the training set positive examples are observed 60% of the time, and negative examples are observed 40% of the time, then the observer using a ''probability-matching'' strategy will predict (for unlabeled examples) a class label of "positive" on 60% of instances, and a class label of "negative" on 40% of instances.  

The optimal [[Bayesian decision theory|Bayesian decision strategy]] (to maximize the number of correct predictions, see {{Harvtxt|Duda|Hart|Stork|2001}}) in such a case is to always predict "positive" (i.e., predict the majority category in the absence of other information), which has 60% chance of winning rather than matching which has 52% of winning  (where ''p'' is the probability of positive realization, the result of matching would be &lt;math&gt;p^2+(1-p)^2&lt;/math&gt;, here &lt;math&gt;.6 \times .6+ .4 \times .4&lt;/math&gt;).  The probability-matching strategy is of psychological interest because it is frequently employed by human subjects in decision and classification studies (where it may be related to [[Thompson sampling]]).

The only case when probability matching will yield same results as Bayesian decision strategy mentioned above is when all class base rates are the same. So, if in the training set positive examples are observed 50% of the time, then the Bayesian strategy would yield 50% accuracy (1 × .5), just as probability matching (.5 ×.5 + .5 × .5). 

== References ==
*{{Citation
 | last=Duda| first=Richard O.| last2=Hart| first2=Peter E.
 | last3=Stork| first3=David G.
 | title=Pattern Classification | publisher=John Wiley &amp; Sons
 | place=[[New York City|New York]] | year=2001 | edition=2nd
 | url=http://www.wiley.com/WileyCDA/WileyTitle/productCd-0471056693.html}}

* Shanks, D. R., Tunney, R. J., &amp; McCarthy, J. D. (2002). A re‐examination of probability matching and rational choice. ''Journal of Behavioral Decision Making'', 15(3), 233-250.

[[Category:Statistical classification]]
[[Category:Machine learning]]
[[Category:Decision-making]]
[[Category:Cognitive science]]
[[Category:Cognitive biases]]


{{statistics-stub}}</text>
      <sha1>g0lwsye5fs9n7xlrqp7rjyosfczysys</sha1>
    </revision>
  </page>
  <page>
    <title>Structural risk minimization</title>
    <ns>0</ns>
    <id>10704974</id>
    <revision>
      <id>977568847</id>
      <parentid>919699321</parentid>
      <timestamp>2020-09-09T16:43:37Z</timestamp>
      <contributor>
        <username>Nfrumkin</username>
        <id>40122456</id>
      </contributor>
      <comment>Added SRM in terms of data + trade-off coefficient intuitions</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3083" xml:space="preserve">{{otheruses|Minimisation (disambiguation){{!}}Minimisation}}
'''Structural risk minimization (SRM)''' is an inductive principle of use in [[machine learning]]. Commonly in machine learning, a generalized model must be selected from a finite data set, with the consequent problem of [[overfitting]] &amp;ndash; the model becoming too strongly tailored to the particularities of the training set and generalizing poorly to new data. The SRM principle addresses this problem by balancing the model's complexity against its success at fitting the training data. This principle was first set out in a 1974 paper by [[Vladimir Vapnik]] and [[Alexey Chervonenkis]] and uses the [[VC dimension]].

In practical terms, Structural Risk Minimization is implemented by minimizing &lt;math&gt;E_{train} + \beta H(W)&lt;/math&gt;, where &lt;math&gt;E_{train}&lt;/math&gt; is the train error, the function &lt;math&gt;H(W)&lt;/math&gt; is called a regularization function, and &lt;math&gt;\beta&lt;/math&gt; is a constant.  &lt;math&gt;H(W)&lt;/math&gt; is chosen such that it takes large values on parameters &lt;math&gt;W&lt;/math&gt; that belong to high-capacity subsets of the parameter space. Minimizing &lt;math&gt;H(W)&lt;/math&gt; in effect limits the capacity of the accessible subsets of the parameter space, thereby controlling the trade-off between minimizing the training error and minimizing the expected gap between the training error and test error.&lt;ref&gt;{{Cite web|url=http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf|title=Gradient-Based Learning Applied to Document Recognition|last=LeCun|first=Yann|date=|website=|url-status=live|archive-url=|archive-date=|access-date=}}&lt;/ref&gt;

The SRM problem can be formulated in terms of data. Given n data points consisting of data x and labels y, the objective &lt;math&gt;J(\theta)&lt;/math&gt; is often expressed in the following manner:

&lt;math&gt;J(\theta) = \frac{1}{2n} \sum_{i=1}^{n}(h_{\theta}(x^i) - y^i)^2 + \frac{\lambda}{2} \sum_{j=1}^{d} \theta_j^2 &lt;/math&gt;

The first term is the mean squared error (MSE) term between the value of the learned model, &lt;math&gt;h_{\theta}&lt;/math&gt;, and the given labels &lt;math&gt;y&lt;/math&gt;. This term is the training error, &lt;math&gt;E_{train}&lt;/math&gt;, that was discussed earlier. The second term, places a prior over the weights, to favor sparsity and penalize larger weights. The trade-off coefficient, &lt;math&gt;\lambda&lt;/math&gt;, is a hyperparameter that places more or less importance on the regularization term. Larger &lt;math&gt;\lambda&lt;/math&gt; encourages sparser weights at the expense of a more optimal MSE, and smaller &lt;math&gt;\lambda&lt;/math&gt; relaxes regularization allowing the model to fit to data. Note that as &lt;math&gt;\lambda \to \infty&lt;/math&gt; the weights become zero, and as &lt;math&gt;\lambda \to 0&lt;/math&gt;, the model typically suffers from overfitting.



==See also==   
* [[Vapnik–Chervonenkis theory]]
* [[Support vector machines]]
* [[Model selection]]
* [[Occam Learning]]
*[[Empirical risk minimization]]

==References==
{{Reflist}}

==External links==
* [http://www.svms.org/srm/ Structural risk minimization] at the support vector machines website.

[[Category:Machine learning]]


{{compu-sci-stub}}</text>
      <sha1>95h4m1m8wp7pka9ij4ou6ryirkeil9h</sha1>
    </revision>
  </page>
  <page>
    <title>Lazy learning</title>
    <ns>0</ns>
    <id>10747879</id>
    <revision>
      <id>994716132</id>
      <parentid>991797900</parentid>
      <timestamp>2020-12-17T04:57:35Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 5 templates: del empty params (2×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="6493" xml:space="preserve">In [[machine learning]], '''lazy learning''' is a learning method in which generalization of the [[training data]] is, in theory, delayed until a query is made to the system, as opposed to [[eager learning]], where the system tries to generalize the training data before receiving queries. 

The primary motivation for employing lazy learning, as in the [[K-nearest neighbors]] algorithm, used by online [[recommendation system]]s ("people who viewed/purchased/listened to this movie/item/tune also ...") is that the data set is continuously updated with new entries (e.g., new items for sale at Amazon, new movies to view at Netflix, new clips at YouTube, new music at Spotify or Pandora). Because of the continuous update, the "training data" would be rendered obsolete in a relatively short time especially in areas like books and movies, where new best-sellers or hit movies/music are published/released continuously. Therefore, one cannot really talk of a "training phase".

Lazy classifiers are most useful for large, continuously changing datasets with few attributes that are commonly queried. Specifically, even if a large set of attributes exist - for example, books have a year of publication, author/s, publisher, title, edition, ISBN, selling price, etc. - recommendation queries rely on far fewer attributes - e.g., purchase or viewing co-occurrence data, and user ratings of items purchased/viewed. 

==Advantages==

The main advantage gained in employing a lazy learning method is that the target function will be approximated locally, such as in the [[k-nearest neighbor algorithm]]. Because the target function is approximated locally for each query to the system, lazy learning systems can simultaneously solve multiple problems and deal successfully with changes in the problem domain. At the same time they can reuse a lot of theoretical and applied results from linear regression modelling (notably [[PRESS statistic]]) and control.&lt;ref&gt;{{cite journal |last1=Bontempi |first1=Gianluca |last2=Birattari |first2=Mauro |last3=Bersini |first3=Hugues |title=Lazy learning for local modelling and control design |journal=International Journal of Control |date=1 January 1999 |volume=72 |issue=7–8 |pages=643–658 |doi=10.1080/002071799220830}}&lt;/ref&gt; It is said that the advantage of this system is achieved if the predictions using a single training set are only developed for few objects.&lt;ref&gt;{{Cite book|title=Encyclopedia of Machine Learning|last1=Sammut|first1=Claude|last2=Webb|first2=Geoffrey I.|date=2011|publisher=Springer Science &amp; Business Media|isbn=9780387307688|location=New York|pages=572}}&lt;/ref&gt; This can be demonstrated in the case of the k-NN technique, which is instance-based and function is only estimated locally.&lt;ref&gt;{{Cite book|title=Data Mining Applications. A Comparative Study for Predicting Student's Performance|last=Pal|first=Saurabh|date=2017-11-02|publisher=GRIN Verlag|isbn=9783668561458|language=en}}&lt;/ref&gt;

==Disadvantages==

Theoretical disadvantages with lazy learning include:

* The large space requirement to store the entire training dataset. In practice, this is not an issue because of advances in hardware and the relatively small number of attributes (e.g., as co-occurrence frequency) that need to be stored.
* Particularly noisy training data increases the case base unnecessarily, because no abstraction is made during the training phase. In practice, as stated earlier, lazy learning is applied to situations where any learning performed in advance soon becomes obsolete because of changes in the data. Also, for the problems for which lazy learning is optimal, "noisy" data does not really occur - the purchaser of a book has either bought another book or hasn't. 
* Lazy learning methods are usually slower to evaluate. In practice, for very large databases with high concurrency loads, the queries are ''not'' postponed until actual query time, but recomputed in advance on a periodic basis - e.g., nightly, in anticipation of future queries, and the answers stored. This way, the next time  new queries are asked about existing entries in the database, the answers are merely looked up rapidly instead of having to be computed on the fly, which would almost certainly bring a high-concurrency multi-user system to its knees.
*Larger training data also entail increased cost. Particularly, there is the fixed amount of computational cost,  where a processor can only process a limited amount of training data points.&lt;ref&gt;{{Cite book|title=Lazy Learning|last=Aha|first=David W.|date=2013|publisher=Springer Science &amp; Business Media|isbn=9789401720533|location=Berlin|pages=106}}&lt;/ref&gt;

There are standard techniques to improve re-computation efficiency so that a particular answer is not recomputed unless the data that impact this answer has changed (e.g., new items, new purchases, new views). In other words, the stored answers are updated incrementally.

This approach, used by large e-commerce or media sites, has long been used in the [[Entrez]] portal of the [[National Center for Biotechnology Information]] (NCBI) to precompute similarities between the different items in its large datasets: biological sequences, 3-D protein structures, published-article abstracts, etc. Because "find similar" queries are asked so frequently, the NCBI uses highly parallel hardware to perform nightly recomputation. The recomputation is performed only for new entries in the datasets against each other and against existing entries: the similarity between two existing entries need not be recomputed.

==Examples of Lazy Learning Methods==

* [[K-nearest neighbors]], which is a special case of instance-based learning.
* [[Local regression]].
* Lazy [[naive Bayes]] rules, which are extensively used in commercial spam detection software. Here, the spammers keep getting smarter and revising their spamming strategies, and therefore the learning rules must also be continually updated.

==References==
{{Reflist}}
* [https://cran.r-project.org/web/packages/lazy/ lazy: Lazy Learning for Local Regression], [[R (programming language)|R]] package with reference manual
* {{cite web|url=http://iridia0.ulb.ac.be/~lazy/|title=The Lazy Learning Package|archive-url=https://web.archive.org/web/20120216183916/http://iridia0.ulb.ac.be/~lazy/|archive-date=16 February 2012}}
*Webb G.I. (2011) Lazy Learning. In: Sammut C., Webb G.I. (eds) Encyclopedia of Machine Learning. Springer, Boston, MA


{{ai-stub}}
[[Category:Machine learning]]</text>
      <sha1>93nye9p5rh28rk46x9zp7hlgvy6mqij</sha1>
    </revision>
  </page>
  <page>
    <title>Eager learning</title>
    <ns>0</ns>
    <id>10747995</id>
    <revision>
      <id>995727810</id>
      <parentid>802474837</parentid>
      <timestamp>2020-12-22T15:51:22Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 2 templates: del empty params (6×); hyphenate params (1×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1472" xml:space="preserve">In [[artificial intelligence]], '''eager learning''' is a learning method in which the system tries to construct a general, input-independent target function during training of the system, as opposed to [[lazy learning]], where generalization beyond the training data is delayed until a query is made to the system. &lt;ref&gt;{{cite conference|url=https://books.google.com/books?id=GtcevX7n90wC&amp;pg=PA158 |title=Hybrid algorithms with Instance-Based Classification|author=Hendrickx, Iris|author2=Van den Bosch, Antal|author-link2=Antal van den Bosch|date=October 2005|publisher=Springer|book-title=Machine Learning: ECML2005|pages=158–169}}&lt;/ref&gt;
The main advantage gained in employing an eager learning method, such as an [[artificial neural network]], is that the target function will be approximated globally during training, thus requiring much less space than using a lazy learning system. Eager learning systems also deal much better with noise in the [[training data]]. Eager learning is an example of [[offline learning]], in which post-training queries to the system have no effect on the system itself, and thus the same query to the system will always produce the same result.

The main disadvantage with eager learning is that it is generally unable to provide good local approximations in the target function.&lt;ref&gt;{{Cite book|title=INTRODUCTION TO KNOWLEDGE PROCESSING|pages=2}}&lt;/ref&gt;

==References==
{{reflist}}

[[Category:Machine learning]]


{{compu-ai-stub}}</text>
      <sha1>0c4ckysurcvp6xipb5bwr7bmp6ubv04</sha1>
    </revision>
  </page>
  <page>
    <title>Data pre-processing</title>
    <ns>0</ns>
    <id>12386904</id>
    <revision>
      <id>993126132</id>
      <parentid>993099302</parentid>
      <timestamp>2020-12-08T22:53:14Z</timestamp>
      <contributor>
        <username>MeghOilwala</username>
        <id>40667734</id>
      </contributor>
      <comment>/* Data mining */  changes are to improve the use of python and why pre-processing is important for data miners</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="10030" xml:space="preserve">'''Data preprocessing''' is an important step in the [[data mining]] process. The phrase [[GIGO|"garbage in, garbage out"]] is particularly applicable to [[data mining]] and [[machine learning]] projects. [[Data collection|Data-gathering]] methods are often loosely controlled, resulting in [[range error|out-of-range]] values (e.g., Income: −100), impossible data combinations (e.g., Sex: Male, Pregnant: Yes), and [[missing values]], etc. Analyzing data that has not been carefully screened for such problems can produce misleading results. Thus, the representation and [[data quality|quality of data]] is first and foremost before running any analysis.&lt;ref&gt;Pyle, D., 1999. ''Data Preparation for Data Mining.'' Morgan Kaufmann Publishers, [[Los Altos, California]].&lt;/ref&gt; 
Often, data preprocessing is the most important phase of a [[machine learning]] project, especially in [[computational biology]].&lt;ref&gt;{{cite journal 
| vauthors = Chicco D
| title = Ten quick tips for machine learning in computational biology 
| journal = BioData Mining
| volume = 10
| issue =  35
| pages = 35 
| date = December 2017 
| pmid = 29234465
| doi = 10.1186/s13040-017-0155-3
| pmc= 5721660}}&lt;/ref&gt;

If there is much irrelevant and redundant information present or noisy and unreliable data, then [[knowledge discovery]] during the training phase is more difficult. Data preparation and filtering steps can take considerable amount of processing time. Data preprocessing includes [[Data cleaning|cleaning]], [[Instance selection]], [[data normalization|normalization]], [[data transformation|transformation]], [[feature extraction]] and [[Feature selection|selection]], etc. The product of data preprocessing is the final [[training set]].

Data pre-processing may affect the way in which outcomes of the final data processing can be interpreted. &lt;ref&gt;{{Cite journal|last1=Oliveri|first1=Paolo|last2=Malegori|first2=Cristina|last3=Simonetti|first3=Remo|last4=Casale|first4=Monica|date=2019|title=The impact of signal pre-processing on the final interpretation of analytical outcomes – A tutorial|journal=Analytica Chimica Acta|language=en|volume=1058|pages=9–17|doi=10.1016/j.aca.2018.10.055|pmid=30851858}}&lt;/ref&gt; This aspect should be carefully considered when interpretation of the results is a key point, such in the multivariate processing of chemical data ([[chemometrics]]).

==Tasks of data pre-processing==
*[[Data cleansing]]
*[[Data editing]]
*[[Data reduction]]
*[[Data wrangling]]
==Example==
In this example we have 5 Adults in our dataset who have the Sex of Male or Female and whether they are pregnant or not. We can detect that Adult 3 and 5 are impossible data combinations.
{|
|-
|
{| class="wikitable" style="border:none; float:left; margin-top:0; text-align:center;"
!style="background:white; border:none;" colspan="2" rowspan="2"|
!colspan="2" style="background:none;"|
|-
!Sex
!Pregnant
|-
!rowspan="5" style="height:6em;background:none;"|&lt;div&gt;Adult &lt;/div&gt;
!1
|Male
|No
|-
!2
|Female
|Yes
|-
!&lt;span style="color:red"&gt;3&lt;/span&gt;
|'''Male'''
|'''Yes'''
|-
!4
|Female
|No
|-
!&lt;span style="color:red"&gt;5&lt;/span&gt;
|'''Male'''
|'''Yes'''
|-
|}
|
|}
We can perform a [[Data cleansing]] and choose to delete such data from our table. We remove such data because we can determine that such data existing in the dataset is caused by user entry errors or data corruption. A reason that one might have to delete such data is because the impossible data will affect the calculation or data manipulation process in the later steps of the data mining process. 
{|
|-
|
{| class="wikitable" style="border:none; float:left; margin-top:0; text-align:center;"
!style="background:white; border:none;" colspan="2" rowspan="2"|
!colspan="2" style="background:none;"|
|-
!Sex
!Pregnant
|-
!rowspan="3" style="height:6em;background:none;"|&lt;div&gt;Adult &lt;/div&gt;
!1
|Male
|No
|-
!2
|Female
|Yes
|-
!4
|Female
|No
|-
|}
|
|}
We can perform a [[Data editing]] and change the Sex of the Adult by knowing that the Adult is Pregnant we can make the assumption that the Adult is Female and make changes accordingly. We edit the dataset to have a clearer analysis of the data when performing data manipulation in the later steps within the data mining process.  
{|
|-
|
{| class="wikitable" style="border:none; float:left; margin-top:0; text-align:center;"
!style="background:white; border:none;" colspan="2" rowspan="2"|
!colspan="2" style="background:none;"|
|-
!Sex
!Pregnant
|-
!rowspan="5" style="height:6em;background:none;"|&lt;div&gt;Adult &lt;/div&gt;
!1
|Male
|No
|-
!2
|Female
|Yes
|-
!&lt;span style="color:blue"&gt;3&lt;/span&gt;
|'''Female'''
|'''Yes'''
|-
!4
|Female
|No
|-
!&lt;span style="color:blue"&gt;5&lt;/span&gt;
|'''Female'''
|'''Yes'''
|-
|}
|
|}
We can use a form of [[Data reduction]] and sort the data by Sex and by doing this we can simplify our dataset and choose what Sex we want to focus on more.
{|
|-
|
{| class="wikitable" style="border:none; float:left; margin-top:0; text-align:center;"
!style="background:white; border:none;" colspan="2" rowspan="2"|
!colspan="2" style="background:none;"|
|-
!Sex
!Pregnant
|-
!rowspan="5" style="height:6em;background:none;"|&lt;div&gt;Adult &lt;/div&gt;
!2
|Female
|Yes
|-
!4
|Female
|No
|-
!1
|Male
|No
|-
!3
|Male
|Yes
|-
!5
|Male
|Yes
|-
|}
|
|}
==Data mining==
The origins of data preprocessing are located in [[data mining]].&lt;ref&gt;{{cite journal |title=Review of data preprocessing techniques in data mining |author=Alasadi, Suad A and Bhaya, Wesam S |journal=Journal of Engineering and Applied Sciences |volume=12 |number=16 |pages=4102–4107 |year=2017 |url=https://www.researchgate.net/publication/320161439}}&lt;/ref&gt; The idea is to aggregate existing information and search in the content. Later it was recognized, that for machine learning and neural networks a data preprocessing step is needed too. So it has become to a universal technique which is used in computing in general.

Data preprocessing allows for the removal of unwanted data with the use of data cleansing, this allows the user to have a dataset to contain more valuable information after the preprocessing stage for data manipulation later in the data mining process. Editing such dataset to either correct data corruption or human error is a crucial step to get accurate quantifiers like true positives ,true negatives,[[False positives and false negatives]] found in a [[Confusion matrix]] that are commonly used for a medical diagnosis. Users are able to join data files together and use preprocessing to filter any unnecessary noise from the data which can allow for higher accuracy. Users use Python programming scripts accompanied by the pandas library which give them the ability to import data from a [[Comma-separated values]] as a data-frame.The data-frame is then used to manipulate data that can be challenging otherwise to do in Excel. [[pandas (software)]] which is a powerful tool allows for data analysis and manipulation; which makes data visualizations, statistical operations and much more, a lot easier. Many also use the [[R (programming language)]] to do such tasks as well. 

The reason why a user transforms existing files into a new one is because of many reasons. Data preprocessing has the objective to add missing values, aggregate information, label data with categories ([[Data binning]]) and smooth a trajectory.&lt;ref&gt;{{cite journal |title=Review of data preprocessing techniques in data mining |author=Alasadi, Suad A and Bhaya, Wesam S |journal=Journal of Engineering and Applied Sciences |volume=12 |number=16 |pages=4102–4107 |year=2017 |url=https://www.researchgate.net/publication/320161439}}&lt;/ref&gt; More advanced techniques like principle component analysis and [[feature selection]] are working with statistical formulas and are applied to complex datasets which are recorded by GPS trackers and motion capture devices.

==Semantic data preprocessing==
Complex problems are asking for more elaborated analyzing techniques of existing information. Instead of creating a simple script for aggregating different numerical values into one, it make sense to focus on semantic based data preprocessing.&lt;ref&gt;{{cite conference |title=An ontology-based framework for semantic data preprocessing aimed at human activity recognition |author=Culmone, Rosario and Falcioni, Marco and Quadrini, Michela |s2cid=196091422 |conference=SEMAPRO 2014: The Eighth International Conference on Advances in Semantic Processing. Alexey Cheptsov, High Performance Computing Center Stuttgart (HLRS) |year=2014 }}&lt;/ref&gt; Here is the idea to build a dedicated [[Ontology (information science)|ontology]] which explains on a higher level what the problem is about.&lt;ref&gt;{{cite conference |doi=10.1007/11946465_24 |year=2006 |publisher=Springer Berlin Heidelberg |pages=262–272 |author=David Perez-Rey and Alberto Anguita and Jose Crespo |title=OntoDataClean: Ontology-Based Integration and Preprocessing of Distributed Data |conference=Biological and Medical Data Analysis }}&lt;/ref&gt; The [[Protégé (software)]] is the standard tool for this purpose.&lt;ref&gt;{{cite journal |doi=10.17485/ijst/2016/v9i10/88899 |year=2016 |publisher=Indian Society for Education and Environment |volume=9 |number=10 |author=F. Mary Harin Fernandez and R. Ponnusamy |title=Data Preprocessing and Cleansing in Web Log on Ontology for Enhanced Decision Making |journal=Indian Journal of Science and Technology |doi-access=free }}&lt;/ref&gt; A second more advanced technique is [[Fuzzy preprocessing]]. Here is the idea to ground numerical values with linguistic information. Raw data are transformed into [[natural language]].

==References==
{{reflist}}

==External links==
*[http://dataprocessing.aixcape.org Online Data Processing Compendium]
*[https://www.cambridge.org/core/journals/knowledge-engineering-review/article/data-preprocessing-in-predictive-data-mining/F7F2D7AC540D2815C613BA6575359AAA/share/92b3b50e7ed7363e5946baf406025281d2eb8c02 Data preprocessing in predictive data mining. Knowledge Eng. Review 34: e1 (2019)]

{{data}}

[[Category:Machine learning]]</text>
      <sha1>75z8zem7225l5wqx01d9ngwdfbc04yu</sha1>
    </revision>
  </page>
  <page>
    <title>Predictive state representation</title>
    <ns>0</ns>
    <id>11360852</id>
    <revision>
      <id>1000168447</id>
      <parentid>994282567</parentid>
      <timestamp>2021-01-13T22:47:14Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 5 templates: hyphenate params (3×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2781" xml:space="preserve">{{notability|date=March 2011}}

In [[computer science]], a '''predictive state representation''' ('''PSR''') is a way to model a state of controlled [[dynamical system]] from a history of actions taken and resulting observations. PSR captures the state of a system as a vector of predictions for future tests (experiments) that can be done on the system.&lt;ref&gt;{{Cite book|last=James|first=Michael R.|last2=Singh|first2=Satinder|date=2004-01-01|title=Learning and Discovery of Predictive State Representations in Dynamical Systems with Reset|journal=Proceedings of the Twenty-first International Conference on Machine Learning|series=ICML '04|location=New York, NY, USA|publisher=ACM|pages=53–|doi=10.1145/1015330.1015359|isbn=978-1581138382|citeseerx=10.1.1.67.5179}}&lt;/ref&gt; A test is a sequence of action-observation pairs and its prediction is the probability of the test's observation-sequence happening if the test's action-sequence were to be executed on the system. One of the advantage of using PSR is that the predictions are directly related to observable quantities.  This is in contrast to other models of dynamical systems, such as [[partially observable Markov decision process]]es (POMDPs) where the state of the system is represented as a [[probability distribution]] over unobserved nominal states.&lt;ref&gt;{{Cite web|url=https://www.semanticscholar.org/paper/A-Planning-Algorithm-for-Predictive-State-Izadi-Precup/b0bb9a5a8acd36692c13992151dfd812df24da81/pdf|title=A Planning Algorithm for Predictive State Representations (PDF) - Semantic Scholar|website=www.semanticscholar.org|language=en-US|access-date=2016-07-14}}&lt;/ref&gt;

==References==
{{Reflist}}
* {{cite conference
  | last = Littman | first = Michael L. | author-link = Michael L. Littman |author2=Richard S. Sutton |author2-link=Richard S. Sutton |author3=Satinder Singh
  | title = Predictive Representations of State
  | book-title = Advances in Neural Information Processing Systems 14 (NIPS)
  | pages = 1555–1561
  | year = 2002
  | url = http://www.eecs.umich.edu/~baveja/Papers/psr.pdf}}

* {{cite conference
  | last =Singh | first = Satinder |author2=Michael R. James |author3=Matthew R. Rudary
  | title = Predictive State Representations: A New Theory for Modeling Dynamical Systems
  | book-title = Uncertainty in Artificial Intelligence: Proceedings of the Twentieth Conference (UAI)
  | pages = 512–519
  | year = 2004
  | url = http://www.eecs.umich.edu/~baveja/Papers/uai2004psr.pdf}}

* {{Citation
  | last = Wiewiora | first = Eric Walter 
  | title = Modeling Probability Distributions with Predictive State Representations
  | year = 2008 
  | url = http://cseweb.ucsd.edu/~ewiewior/dissertation.pdf}}

[[Category:Machine learning]]
[[Category:Dynamical systems]]


{{Compu-AI-stub}}</text>
      <sha1>0ukulfccpsk0aqc46vqdt4k95irkm2h</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Kernel methods for machine learning</title>
    <ns>14</ns>
    <id>12535256</id>
    <revision>
      <id>588588547</id>
      <parentid>524635569</parentid>
      <timestamp>2013-12-31T23:26:08Z</timestamp>
      <contributor>
        <username>BotMultichill</username>
        <id>4080734</id>
      </contributor>
      <minor/>
      <comment>Adding Commons category link to [[:Commons:Category:Kernel methods for machine learning|category with the same name]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="208" xml:space="preserve">{{Commons category|Kernel methods for machine learning}}
This page lists categories and articles related to [[kernel methods]] for [[machine learning]].

[[Category:Machine learning]]
[[Category:Methodology]]</text>
      <sha1>7w3dg0stcjnjueytik0pu4mc7xr2d06</sha1>
    </revision>
  </page>
  <page>
    <title>Expectation propagation</title>
    <ns>0</ns>
    <id>14923880</id>
    <revision>
      <id>995558396</id>
      <parentid>994266720</parentid>
      <timestamp>2020-12-21T18:29:01Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 2 templates: del empty params (1×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2475" xml:space="preserve">{{Short description|Method to approximate a probability distribution}}

'''Expectation propagation (EP)''' is a technique in [[Bayesian inference|Bayesian machine learning]].&lt;ref name="bishop"&gt;{{Cite book|title=Pattern Recognition and Machine Learning|last=Bishop|first=Christopher|publisher=Springer-Verlag New York Inc.|year=2007|isbn=978-0387310732|location=New York}}&lt;/ref&gt;

EP finds approximations to a [[probability distribution]].&lt;ref name="bishop" /&gt; It uses an [[iterative]] approach that leverages the factorization structure of the target distribution.&lt;ref name="bishop" /&gt;  It differs from other Bayesian approximation approaches such as [[variational Bayesian methods]].&lt;ref name="bishop" /&gt;

More specifically, suppose we wish to approximate an intractable probability distribution &lt;math&gt;p(\mathbf{x})&lt;/math&gt; with a tractable distribution &lt;math&gt;q(\mathbf{x})&lt;/math&gt;. Expectation propagation achieves this approximation by minimizing the [[Kullback-Leibler divergence]] &lt;math&gt;\mathrm{KL}(p||q)&lt;/math&gt;.&lt;ref name="bishop" /&gt; Variational Bayesian methods minimize &lt;math&gt;\mathrm{KL}(q||p)&lt;/math&gt; instead.&lt;ref name="bishop" /&gt;

If &lt;math&gt;q(\mathbf{x})&lt;/math&gt; is a Gaussian &lt;math&gt;\mathcal{N}(\mathbf{x}|\mu, \Sigma)&lt;/math&gt;, then &lt;math&gt;\mathrm{KL}(p||q)&lt;/math&gt; is minimized with &lt;math&gt;\mu&lt;/math&gt; and &lt;math&gt;\Sigma&lt;/math&gt; being equal to the [[mean]] of &lt;math&gt;p(\mathbf{x})&lt;/math&gt; and the [[covariance]] of &lt;math&gt;p(\mathbf{x})&lt;/math&gt;, respectively; this is called [[moment matching]].&lt;ref name="bishop" /&gt;

==Applications==
Expectation propagation via moment matching plays a vital role in approximation for [[indicator functions]] that appear when deriving the [[Belief propagation|message passing equations]] for [[TrueSkill]].

==References==
{{Reflist}}
*{{cite book|author=Thomas Minka|author-link=Thomas Minka|chapter=Expectation Propagation for Approximate Bayesian Inference|url=http://research.microsoft.com/en-us/um/people/minka/papers/ep/minka-ep-uai.pdf|editor=Jack S. Breese, Daphne Koller|title=UAI '01: Proceedings of the 17th Conference in Uncertainty in Artificial Intelligence|location=University of Washington, Seattle, Washington, USA|date=August 2–5, 2001|pages=362–369}}

==External links==
* [http://research.microsoft.com/~minka/papers/ep/ Minka's EP papers]
* [http://research.microsoft.com/en-us/um/people/minka/papers/ep/roadmap.html List of papers using EP].

[[Category:Machine learning]]
[[Category:Bayesian statistics]]


{{compsci-stub}}</text>
      <sha1>e0og38h1hx47h956b9k7yod2jxkaihb</sha1>
    </revision>
  </page>
  <page>
    <title>Multiple-instance learning</title>
    <ns>0</ns>
    <id>14082194</id>
    <redirect title="Multiple instance learning" />
    <revision>
      <id>847187327</id>
      <parentid>831257287</parentid>
      <timestamp>2018-06-23T14:43:23Z</timestamp>
      <contributor>
        <username>Klbrain</username>
        <id>11677590</id>
      </contributor>
      <comment>Merge to [[Multiple instance learning]] following unopposed 2016 proposal; see [[Talk:Multiple instance learning#Merger proposal]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="88" xml:space="preserve">#REDIRECT [[Multiple instance learning]] {{R from merge}}

[[Category:Machine learning]]</text>
      <sha1>pb01ozl5d1imh09pzdqcedsmr81mpvp</sha1>
    </revision>
  </page>
  <page>
    <title>Ugly duckling theorem</title>
    <ns>0</ns>
    <id>5077439</id>
    <revision>
      <id>1003165415</id>
      <parentid>1002510034</parentid>
      <timestamp>2021-01-27T18:39:42Z</timestamp>
      <contributor>
        <username>Kjell Knudde</username>
        <id>7436027</id>
      </contributor>
      <comment>Added more categories</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="11852" xml:space="preserve">{{short description|An argument that classification is not really possible without some sort of bias}}
{{refimprove|date=October 2011}}

The '''Ugly duckling theorem''' is an [[argument]] showing that classification is not really possible without some sort of [[bias (statistics)|bias]]. More particularly, it assumes finitely many properties combinable by [[logical connective]]s, and finitely many objects; it asserts that any two [[Identity of indiscernibles|different]] objects share the same number of ([[Extension (predicate logic)|extensional]]) properties. The theorem is named after [[Hans Christian Andersen]]'s 1843 story "[[The Ugly Duckling]]", because it shows that a [[duckling]] is just as similar to a [[swan]] as two duckling are to each other. It was proposed by [[Satosi Watanabe]] in 1969.&lt;ref name="Watanabe.1969"&gt;{{cite book 
| lccn=68-56165 
| isbn=0-471-92130-0 
| url= https://archive.org/details/knowingguessingq0000wata
| url-access=registration
| author=Satosi Watanabe 
| title=Knowing and Guessing: A Quantitative Study of Inference and Information 
| location=New York 
| publisher=Wiley 
| year=1969 }}&lt;/ref&gt;{{rp|376–377}}

==Mathematical formula==
[[File:Watanabe UglyDucklingTheorem svg.svg|thumb|400px|Watanabe's example, using objects ''A'', ''B'', ''C'', and properties F ("first"), W ("white"). "0", "1", "[[negation|¬]]" , "[[conjunction (logic)|∧]]", "[[disjunction (logic)|∨]]", and "[[exclusive or|⊕]]" denote "''false''", "''true''", "''[[negation|not]]''", "''[[conjunction (logic)|and]]''", "''[[disjunction (logic)|or]]''", and "''[[exclusive or]]''", respectively. Since F happens to imply W, each predicate that can be formed from F and W coincides with another one, hence there are only 8 [[extension (semantics)|extensionally]] distinct possible predicates, each shown on an own line. The white ducklings ''A'' and ''B'' agree on 4 of them (line 2, 3, 4, 8), but so do ''A'' and ''C'', too (line 3, 5, 7, 8), and so do ''B'' and ''C'' (line 1, 3, 6, 8).&lt;ref name="Watanabe.1969"/&gt;{{rp|368}}&lt;ref&gt;Watanabe's ''x''&lt;sub&gt;1&lt;/sub&gt;, ''x''&lt;sub&gt;2&lt;/sub&gt;, ''x''&lt;sub&gt;3&lt;/sub&gt;, ''y''&lt;sub&gt;1&lt;/sub&gt;, and ''y''&lt;sub&gt;2&lt;/sub&gt;, correspond to ''C'', ''B'', ''A'', F, and W, respectively.&lt;/ref&gt;]]

Suppose there are &lt;var&gt;n&lt;/var&gt; things in the universe, and one wants to put them into classes or categories. One has no preconceived ideas or [[bias]]es about what sorts of categories are "natural" or "normal" and what are not. So one has to consider all the possible classes that could be, all the possible ways of making sets out of the &lt;var&gt;n&lt;/var&gt; objects. There are &lt;math&gt;2^n&lt;/math&gt; such ways, the size of the [[power set]] of &lt;var&gt;n&lt;/var&gt; objects. One can use that to measure the similarity between two objects: and one would see how many sets they have in common. However one can not. Any two objects have exactly the same number of classes in common if we can form any possible class, namely &lt;math&gt;2^{n-1}&lt;/math&gt; (half the total number of classes there are). To see this is so, one may imagine each class is a represented by an &lt;var&gt;n&lt;/var&gt;-bit [[bit array|string]] (or [[binary numeral system|binary encoded]] integer), with a zero for each element not in the class and a one for each element in the class. As one finds, there are &lt;math&gt;2^n&lt;/math&gt; such strings.

As all possible choices of zeros and ones are there, any two bit-positions will agree exactly half the time. One may pick two elements and reorder the bits so they are the first two, and imagine the numbers sorted lexicographically. The first &lt;math&gt;2^n/2&lt;/math&gt; numbers will have bit #1 set to zero, and the second &lt;math&gt;2^n/2&lt;/math&gt; will have it set to one. Within each of those blocks, the top &lt;math&gt;2^n/4&lt;/math&gt; will have bit #2 set to zero and the other &lt;math&gt;2^n/4&lt;/math&gt; will have it as one, so they agree on two blocks of &lt;math&gt;2^n/4&lt;/math&gt; or on half of all the cases. No matter which two elements one picks. So if we have no preconceived bias about which categories are better, everything is then equally similar (or equally dissimilar). The number of [[propositional function|predicates]] simultaneously satisfied by two non-identical elements is constant over all such pairs and is the same{{citation needed|date=March 2011}} as the number of those satisfied by one.&lt;!-- I calculated these as 2^{n-2} and 2^{n-1} respectively. --&gt; Thus, some kind of inductive{{citation needed|date=March 2011}} bias is needed to make judgements; i.e. to prefer certain categories over others.

===Boolean functions===
Let &lt;math&gt;x_1, x_2, \dots, x_n&lt;/math&gt; be a set of vectors of &lt;math&gt;k&lt;/math&gt; booleans each.  The ugly duckling is the vector which is least like the others.  Given the booleans, this can be computed using [[Hamming distance]].

However, the choice of boolean features to consider could have been somewhat arbitrary.  Perhaps there were features derivable from the original features that were important for identifying the ugly duckling.  The set of booleans in the vector can be extended with new features computed as [[boolean function]]s of the &lt;math&gt;k&lt;/math&gt; original features.  The only canonical way to do this is to extend it with ''all'' possible Boolean functions.  The resulting completed vectors have &lt;math&gt;2^k&lt;/math&gt; features.  The Ugly duckling theorem states that there is no ugly duckling because any two completed vectors will either be equal or differ in exactly half of the features.

Proof.  Let x and y be two vectors.  If they are the same, then their completed vectors must also be the same because any Boolean function of x will agree with the same Boolean function of y.  If x and y are different, then there exists a coordinate &lt;math&gt;i&lt;/math&gt; where the &lt;math&gt;i&lt;/math&gt;-th coordinate of &lt;math&gt;x&lt;/math&gt; differs from the &lt;math&gt;i&lt;/math&gt;-th coordinate of &lt;math&gt;y&lt;/math&gt;.  Now the completed features contain every Boolean function on &lt;math&gt;k&lt;/math&gt; Boolean variables, with each one exactly once.  Viewing these Boolean functions as polynomials in &lt;math&gt;k&lt;/math&gt; variables over GF(2), segregate the functions into pairs &lt;math&gt;(f,g)&lt;/math&gt; where &lt;math&gt;f&lt;/math&gt; contains the &lt;math&gt;i&lt;/math&gt;-th coordinate as a linear term and &lt;math&gt;g&lt;/math&gt; is &lt;math&gt;f&lt;/math&gt; without that linear term.  Now, for every such pair &lt;math&gt;(f,g)&lt;/math&gt;, &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt; will agree on exactly one of the two functions.  
If they agree on one, they must disagree on the other and vice versa.  (This proof is believed to be due to Watanabe.)

==Discussion==

{{clarify span|A solution to the Ugly duckling theorem|A problem may have a 'solution', but a theorem may not.|date=December 2017}} would be to introduce a constraint on how similarity is measured by limiting the properties involved in classification, say between A and B. However Medin et al. (1993) point out that this does not actually resolve the arbitrariness or bias problem since in what respects A is similar to B: “varies with the stimulus context and task, so that there is no unique answer, to the question of how similar is one object to another”.&lt;ref&gt;{{cite journal | author=Douglas L. Medin and R.L. Goldstone and Dedre Gentner | title=Respects for similarity | journal=Psychological Review | volume=100 | number=2 | pages=254–278 | year=1993 | doi=10.1037/0033-295x.100.2.254}}&lt;/ref&gt;{{#tag:ref|The philosopher [[Nelson Goodman]]&lt;ref&gt;{{cite book | editor=Nelson Goodman | title=Problems and Projects | location=New York | publisher=Bobs-Merril | author=Nelson Goodman | contribution=Seven Strictures on Similarity | pages=437–446 | year=1972 }}&lt;/ref&gt; came to the same conclusion: "But importance is a highly volatile matter, varying with every shift of context and interest, and quite incapable of supporting the fixed distinctions that philosophers so often seek to rest upon it".}} For example, "a barberpole and a zebra would be more similar than a horse and a zebra if the feature ''striped'' had sufficient weight. Of course, if these feature weights were fixed, then these similarity relations would be constrained". Yet the property "striped" as a weight 'fix' or constraint is arbitrary itself, meaning: "unless one can specify such criteria, then the claim that categorization is based on attribute matching is almost entirely vacuous".

Stamos (2003) has attempted to solve the Ugly duckling theorem by showing some judgments of overall similarity are non-arbitrary in the sense they are useful:

{{Quote|"Presumably, people's perceptual and conceptual processes have evolved that information that matters to human needs and goals can be roughly approximated by a similarity heuristic... If you are in the jungle and you see a tiger but you decide not to stereotype (perhaps because you believe that similarity is a false friend), then you will probably be eaten. In other words, in the biological world stereotyping based on veridical judgments of overall similarity statistically results in greater survival and reproductive success."&lt;ref&gt;Stamos, D. N. (2003). ''The Species Problem''. Lexington Books. p. 344.&lt;/ref&gt;}}

Unless some properties are considered more salient, or ‘weighted’ more important than others, everything will appear equally similar, hence Watanabe (1986) wrote: “any objects, in so far as they are distinguishable, are equally similar".&lt;ref&gt;{{cite journal | author=Satosi Watanabe | title=Epistemological Relativity | journal=Annals of the Japan Association for Philosophy of Science | volume=7 | number=1 | pages=1–14 | year=1986 | doi=10.4288/jafpos1956.7.1| doi-access=free }}&lt;/ref&gt; 

&lt;!---commented out (wrong):---Watanabe came to realize there is an unquantifiable number of shared properties between all objects, making any classification biased.---&gt;
In a weaker setting that assumes infinitely many properties, Murphy and Medin (1985) give an example of two putative classified things, plums and lawnmowers:

{{Quote|"Suppose that one is to list the attributes that plums and lawnmowers have in common in order to judge their similarity. It is easy to see that the list could be infinite: Both weigh less than 10,000 kg (and less than 10,001 kg), both did not exist 10,000,000 years ago (and 10,000,001 years ago), both cannot hear well, both can be dropped, both take up space, and so on. Likewise, the list of differences could be infinite… any two entities can be arbitrarily similar or dissimilar by changing the criterion of what counts as a relevant attribute."&lt;ref&gt;{{cite journal | url=http://matt.colorado.edu/teaching/highcog/spr10/readings/mm85.pdf | author=Gregory L. Murphy and Douglas L. Medin | title=The Role of Theories in Conceptual Coherence | journal=Psychological Review | volume=92 | number=3 | pages=289–316 | date=Jul 1985 | doi=10.1037/0033-295x.92.3.289}}&lt;/ref&gt;}}
&lt;!---commented out (doesn't refer to Watanabe's setting, no indication that is refers to Murphy and Medin's setting, either):---However, since there is an unlimited number of properties to choose from, it remains an arbitrary choice what properties to select/deselect. This makes classification biased.---&gt;
&lt;!---commented out (has been said in the lead):---Watanabe named this the "Ugly duckling theorem" because a swan is as similar to a duckling as to another swan (there are no constraints or fixes on what constitutes similarity).---&gt;

==See also==
* [[No free lunch in search and optimization]]
* [[No free lunch theorem]]
* [[Identity of indiscernibles]] – Classification (discernibility) is possible (with or without a [[bias (statistics)|bias]]), but there cannot be separate objects or entities that have all their properties in common.
==Notes==
&lt;references/&gt;

{{The Ugly Duckling}}

[[Category:Theorems]]
[[Category:Arguments]]
[[Category:Machine learning]]
[[Category:Ontology]]
[[Category:Metaphors referring to animals]]
[[Category:Metaphors referring to birds]]
[[Category:1960s neologisms]]</text>
      <sha1>2kcnd1z83ernyml11nmrt6uflkur55y</sha1>
    </revision>
  </page>
  <page>
    <title>Rademacher complexity</title>
    <ns>0</ns>
    <id>14529261</id>
    <revision>
      <id>998784141</id>
      <parentid>994013680</parentid>
      <timestamp>2021-01-07T01:02:21Z</timestamp>
      <contributor>
        <username>0.examiner</username>
        <id>40825137</id>
      </contributor>
      <minor/>
      <comment>inserted link to definition of symmetric sets</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="12163" xml:space="preserve">In [[computational learning theory]] ([[machine learning]] and [[theory of computation]]), '''Rademacher complexity''', named after [[Hans Rademacher]], measures richness of a class of real-valued functions with respect to a [[probability distribution]].

== Definitions ==
=== Rademacher complexity of a set ===
Given a set &lt;math&gt;A\subseteq \mathbb{R}^m&lt;/math&gt;, the '''Rademacher complexity of''' ''A'' is defined as follows:&lt;ref name=b11&gt;{{cite web|last1=Balcan|first1=Maria-Florina|authorlink= Maria-Florina Balcan |title=Machine Learning Theory – Rademacher Complexity|url=https://www.cs.cmu.edu/~ninamf/ML11/lect1117.pdf|accessdate=10 December 2016|date=November 15–17, 2011}}&lt;/ref&gt;&lt;ref name=book14&gt;Chapter 26 in {{Cite Shai Shai 2014}}&lt;/ref&gt;{{rp|326}}
:&lt;math&gt;
\operatorname{Rad}(A)
:= 
\frac{1}{m}
   \operatorname{E} \left[
   \sup_{a \in A}
      \sum_{i=1}^m \sigma_i a_i
\right]
&lt;/math&gt;

where &lt;math&gt;\sigma_1, \sigma_2, \dots, \sigma_m&lt;/math&gt; are independent random variables drawn from the [[Rademacher distribution]] i.e. &lt;math&gt;\Pr(\sigma_i = +1) = \Pr(\sigma_i = -1) = 1/2&lt;/math&gt; for &lt;math&gt;i=1,2,\dots,m&lt;/math&gt;, and &lt;math&gt; a=(a_1, \ldots, a_m)&lt;/math&gt;. Some authors take the absolute value of the sum before taking the supremum, but if &lt;math&gt;A&lt;/math&gt; is [[Symmetric set|symmetric]] this makes no difference.

=== Rademacher complexity of a function class ===
Given a sample &lt;math&gt;S=(z_1, z_2, \dots, z_m) \in Z^m&lt;/math&gt;, and a class &lt;math&gt;F&lt;/math&gt; of real-valued functions defined on a domain space &lt;math&gt;Z&lt;/math&gt;, where &lt;math&gt;f&lt;/math&gt; is the loss function &lt;math&gt;f(z) = \ell(h(x), y)&lt;/math&gt; of a classifier &lt;math&gt;h&lt;/math&gt;, the '''empirical Rademacher complexity''' of &lt;math&gt;F&lt;/math&gt; given &lt;math&gt;S&lt;/math&gt; is defined as:
:&lt;math&gt;
\operatorname{Rad}_S(F) 
= 
\frac{1}{m}
   \operatorname{E} \left[
   \sup_{f \in F}
   \sum_{i=1}^m \sigma_i f(z_i) 
\right]
&lt;/math&gt;

This can also be written using the previous definition:&lt;ref name=book14/&gt;{{rp|326}}
:&lt;math&gt;\operatorname{Rad}_S(F) = \operatorname{Rad}(F \circ S) &lt;/math&gt;
where &lt;math&gt;F \circ S&lt;/math&gt; denotes [[function composition]], i.e.:
:&lt;math&gt;F \circ S := \{ (f(z_1),\ldots,f(z_m))\mid  f\in F\}&lt;/math&gt;

Let &lt;math&gt;P&lt;/math&gt; be a probability distribution over &lt;math&gt;Z&lt;/math&gt;. 
The '''Rademacher complexity''' of the function class &lt;math&gt;F&lt;/math&gt; with respect to &lt;math&gt;P&lt;/math&gt; for sample size &lt;math&gt;m&lt;/math&gt; is:

:&lt;math&gt;
\operatorname{Rad}_{P,m}(F) 
:= 
\operatorname{E}_{S\sim P^m} \left[ \operatorname{Rad}_S(F) \right]
&lt;/math&gt;

where the above expectation is taken over an [[identically independently distributed]] (i.i.d.) sample &lt;math&gt;S=(z_1, z_2, \dots, z_m)&lt;/math&gt; generated according to &lt;math&gt;P&lt;/math&gt;.

== Examples ==
1. &lt;math&gt;A&lt;/math&gt; contains a single vector, e.g., &lt;math&gt;A = \{(a,b)\} \subset \mathbb{R}^2&lt;/math&gt;. Then:
:: &lt;math&gt;\operatorname{Rad}(A) = {1\over 2}\cdot \left({1\over 4}\cdot(a+b) + {1\over 4}\cdot(a-b) + {1\over 4}\cdot(-a+b) + {1\over 4}\cdot(-a-b)\right) = 0&lt;/math&gt;
The same is true for every singleton hypothesis class.&lt;ref name=book12&gt;{{Cite Mehryar Afshin Ameet 2012}}&lt;/ref&gt;{{rp|56}}

2. &lt;math&gt;A&lt;/math&gt; contains two vectors, e.g., &lt;math&gt;A = \{(1,1),(1,2)\} \subset \mathbb{R}^2&lt;/math&gt;. Then:
:: &lt;math&gt;
\begin{align}
\operatorname{Rad}(A) &amp; = {1\over 2}\cdot \left({1\over 4}\cdot\max(1+1, 1+2) + {1\over 4}\cdot\max(1-1, 1-2) + {1\over 4} \cdot \max(-1+1, -1+2) + {1\over 4}\cdot\max(-1-1, -1-2)\right) \\[5pt]
&amp; = {1\over 8}(3+0+1-2) = {1\over 4}
\end{align}
&lt;/math&gt;

== Using the Rademacher complexity ==
The Rademacher complexity can be used to derive data-dependent upper-bounds on the [[learnability]] of function classes. Intuitively, a function-class with smaller Rademacher complexity is easier to learn.

=== Bounding the representativeness ===
In [[machine learning]], it is desired to have a [[training set]] that represents the true distribution of some sample data &lt;math&gt;S&lt;/math&gt;. This can be quantified using the notion of '''representativeness'''. Denote by &lt;math&gt;P&lt;/math&gt; the [[probability distribution]] from which the samples are drawn. Denote by &lt;math&gt;H&lt;/math&gt; the set of hypotheses (potential classifiers) and denote by &lt;math&gt;F&lt;/math&gt; the corresponding set of error functions, i.e., for every hypothesis &lt;math&gt;h\in H&lt;/math&gt;, there is a function &lt;math&gt;f_h\in F&lt;/math&gt;, that maps each training sample (features,label) to the error of the classifier &lt;math&gt;h&lt;/math&gt; (note in this case hypothesis and classifier are used interchangeably). For example, in the case that &lt;math&gt;h&lt;/math&gt; represents a binary classifier, the error function is a 0–1 loss function, i.e. the error function &lt;math&gt;f_h&lt;/math&gt; returns 1 if &lt;math&gt;h&lt;/math&gt; correctly classifies a sample and 0 else. We omit the index and write &lt;math&gt;f&lt;/math&gt; instead of &lt;math&gt;f_h&lt;/math&gt; when the underlying hypothesis is irrelevant. Define:
:&lt;math&gt;L_P(f) := \operatorname E_{z\sim P}[f(z)]&lt;/math&gt; – the expected error of some error function &lt;math&gt;f\in F&lt;/math&gt; on the real distribution &lt;math&gt;P&lt;/math&gt;;
:&lt;math&gt;L_S(f) := {1\over m} \sum_{i=1}^m f(z_i)&lt;/math&gt; – the estimated error of some error function &lt;math&gt;f\in F&lt;/math&gt; on the sample &lt;math&gt;S&lt;/math&gt;.
The representativeness of the sample &lt;math&gt;S&lt;/math&gt;, with respect to &lt;math&gt;P&lt;/math&gt; and &lt;math&gt;F&lt;/math&gt;, is defined as:
:&lt;math&gt; \operatorname{Rep}_P(F,S) := \sup_{f\in F} (L_P(f) - L_S(f))&lt;/math&gt;

Smaller representativeness is better, since it provides a way to avoid [[overfitting]]: it means that the true error of a classifier is not much higher than its estimated error, and so selecting a classifier that has low estimated error will ensure that the true error is also low. Note however that the concept of representativeness is relative and hence can not be compared across distinct samples.

The expected representativeness of a sample can be bounded above by the Rademacher complexity of the function class:&lt;ref name=book14/&gt;{{rp|326}}
:&lt;math display=block&gt; \operatorname E_{S\sim P^m} [\operatorname{Rep}_P(F,S)] \leq 2 \cdot \operatorname E_{S\sim P^m} [\operatorname{Rad}(F\circ S)]&lt;/math&gt;

=== Bounding the generalization error ===
When the Rademacher complexity is small, it is possible to learn the hypothesis class H using [[empirical risk minimization]].

For example, (with binary error function),&lt;ref name=book14/&gt;{{rp|328}} for every &lt;math&gt;\delta&gt;0&lt;/math&gt;, with probability at least &lt;math&gt;1-\delta&lt;/math&gt;, for every hypothesis &lt;math&gt;h\in H&lt;/math&gt;:
:&lt;math&gt;L_P(h) - L_S(h) \leq 2 \operatorname{Rad}(F\circ S) + 4 \sqrt{2\ln(4/\delta)\over m}&lt;/math&gt;

== Bounding the Rademacher complexity ==
Since smaller Rademacher complexity is better, it is useful to have upper bounds on the Rademacher complexity of various function sets. The following rules can be used to upper-bound the Rademacher complexity of a set &lt;math&gt;A \subset \mathbb{R}^m&lt;/math&gt;.&lt;ref name=book14/&gt;{{rp|329–330}}

1. If all vectors in &lt;math&gt;A&lt;/math&gt; are translated by a constant vector &lt;math&gt;a_0 \in \mathbb{R}^m&lt;/math&gt;, then Rad(''A'') does not change.

2. If all vectors in &lt;math&gt;A&lt;/math&gt; are multiplied by a scalar &lt;math&gt;c\in \mathbb{R}&lt;/math&gt;, then Rad(''A'') is multiplied by &lt;math&gt;|c|&lt;/math&gt;.

3. Rad(''A'' + ''B'') = Rad(''A'') + Rad(''B'').&lt;ref name=book12/&gt;{{rp|56}}

4. (Kakade &amp; Tewari Lemma) If all vectors in &lt;math&gt;A&lt;/math&gt; are operated by a [[Lipschitz function]], then Rad(''A'') is (at most) multiplied by the [[Lipschitz constant]] of the function. In particular, if all vectors in &lt;math&gt;A&lt;/math&gt; are operated by a [[contraction mapping]], then Rad(''A'') strictly decreases.

5. The Rademacher complexity of the [[convex hull]] of &lt;math&gt;A&lt;/math&gt; equals Rad(''A'').

6. (Massart Lemma) The Rademacher complexity of a finite set grows logarithmically with the set size. Formally, let &lt;math&gt;A&lt;/math&gt; be a set of &lt;math&gt;N&lt;/math&gt; vectors in &lt;math&gt;\mathbb{R}^m&lt;/math&gt;, and let &lt;math&gt;\bar{a}&lt;/math&gt; be the mean of the vectors in &lt;math&gt;A&lt;/math&gt;. Then:
:&lt;math&gt;\operatorname{Rad}(A) \leq \max_{a\in A} \|a-\bar{a}\| \cdot {\sqrt{2\log N}\over m}&lt;/math&gt;
In particular, if &lt;math&gt;A&lt;/math&gt; is a set of binary vectors, the norm is at most &lt;math&gt;\sqrt{m}&lt;/math&gt;, so:
:&lt;math&gt;\operatorname{Rad}(A) \leq \sqrt{2\log N \over m} &lt;/math&gt;

=== Bounds related to the VC dimension ===
Let &lt;math&gt;H&lt;/math&gt; be a [[set family]] whose  [[VC dimension]]  is &lt;math&gt;d&lt;/math&gt;. It is known that the [[growth function]] of &lt;math&gt;H&lt;/math&gt; is bounded as:
:for all &lt;math&gt;m&gt;d+1&lt;/math&gt;: &lt;math&gt;\operatorname{Growth}(H,m)\leq (em/d)^d&lt;/math&gt;
This means that, for every set &lt;math&gt;h&lt;/math&gt; with at most &lt;math&gt;m&lt;/math&gt; elements, &lt;math&gt;|H\cap h|\leq (em/d)^d&lt;/math&gt;. The set-family &lt;math&gt;H\cap h&lt;/math&gt; can be considered as a set of binary vectors over &lt;math&gt;\mathbb{R}^m&lt;/math&gt;. Substituting this in Massart's lemma gives:
:&lt;math&gt;\operatorname{Rad}(H\cap h) \leq {\sqrt{2 d \log(em/d) \over m}}&lt;/math&gt;

With more advanced techniques ([[Dudley's theorem|Dudley's entropy bound]] and Haussler's upper bound&lt;ref&gt;Bousquet, O. (2004). Introduction to Statistical Learning Theory. ''Biological Cybernetics'', ''3176''(1), 169–207. &lt;nowiki&gt;http://doi.org/10.1007/978-3-540-28650-9_8&lt;/nowiki&gt;&lt;/ref&gt;) one can show, for example, that there exists a constant &lt;math&gt;C&lt;/math&gt;, such that any class of &lt;math&gt;\{0,1\}&lt;/math&gt;-indicator functions with [[Vapnik–Chervonenkis dimension]] &lt;math&gt;d&lt;/math&gt; has Rademacher complexity upper-bounded by &lt;math&gt;C\sqrt{\frac{d}{m}}&lt;/math&gt;.

=== Bounds related to linear classes ===
The following bounds are related to linear operations on &lt;math&gt;S&lt;/math&gt; – a constant set of &lt;math&gt;m&lt;/math&gt; vectors in &lt;math&gt;\mathbb{R}^n&lt;/math&gt;.&lt;ref name=book14/&gt;{{rp|332–333}}

1. Define &lt;math&gt;A_2 = \{(w\cdot x_1,\ldots,w\cdot x_m) \mid \|w\|_2\leq 1\} = &lt;/math&gt; the set of dot-products of the vectors in &lt;math&gt;S&lt;/math&gt; with vectors in the [[unit ball]]. Then:
:&lt;math&gt;\operatorname{Rad}(A_2) \leq {\max_i\|x_i\|_2 \over \sqrt{m}}&lt;/math&gt;

2. Define &lt;math&gt;A_1 = \{(w\cdot x_1,\ldots,w\cdot x_m) \mid \|w\|_1\leq 1\} = &lt;/math&gt; the set of dot-products of the vectors in &lt;math&gt;S&lt;/math&gt; with vectors in the unit ball of the 1-norm. Then:
:&lt;math&gt;\operatorname{Rad}(A_1) \leq \max_i\|x_i\|_\infty\cdot \sqrt{2\log(2n) \over m}&lt;/math&gt;

=== Bounds related to covering numbers ===
The following bound relates the Rademacher complexity of a set &lt;math&gt;A&lt;/math&gt; to its external [[covering number]] – the number of balls of a given radius &lt;math&gt;r&lt;/math&gt; whose union contains &lt;math&gt;A&lt;/math&gt;. The bound is attributed to Dudley.&lt;ref name=book14/&gt;{{rp|338}}

Suppose &lt;math&gt;A\subset \mathbb{R}^m&lt;/math&gt; is a set of vectors whose length (norm) is at most &lt;math&gt;c&lt;/math&gt;. Then, for every integer &lt;math&gt;M&gt;0&lt;/math&gt;:
:&lt;math&gt;
\operatorname{Rad}(A) \leq 
{c\cdot 2^{-M}\over \sqrt{m}}
+
{6c \over m}\cdot
\sum_{i=1}^M 2^{-i}\sqrt{\log\left(N^{\text{ext}}_{c\cdot 2^{-i}}(A)\right)} 
&lt;/math&gt;

In particular, if &lt;math&gt;A&lt;/math&gt; lies in a ''d''-dimensional subspace of &lt;math&gt;\mathbb{R}^m&lt;/math&gt;, then:
:&lt;math&gt;\forall r&gt;0: N^{\text{ext}}_r(A) \leq (2 c \sqrt{d}/r)^d&lt;/math&gt;
Substituting this in the previous bound gives the following bound on the Rademacher complexity:
:&lt;math&gt;
\operatorname{Rad}(A) \leq 
{6c \over m}\cdot
\bigg(\sqrt{d\log(2\sqrt{d})} + 2\sqrt{d}\bigg)
=
O\bigg({c\sqrt{d\log(d)}\over m}\bigg)
&lt;/math&gt;

== Gaussian complexity ==
'''Gaussian complexity''' is a similar complexity with similar physical meanings, and can be obtained from the Rademacher complexity using the random variables &lt;math&gt;g_i&lt;/math&gt; instead of &lt;math&gt;\sigma_i&lt;/math&gt;, where &lt;math&gt;g_i&lt;/math&gt; are [[Normal distribution|Gaussian]] [[Independent and identically distributed random variables|i.i.d.]] random variables with zero-mean and variance 1, i.e. &lt;math&gt;g_i \sim \mathcal{N}(0,1)&lt;/math&gt;. Gaussian and Rademacher complexities are known to be equivalent up to logarithmic factors.

==References==
{{reflist}}
* Peter L. Bartlett, Shahar Mendelson (2002) ''Rademacher and Gaussian Complexities: Risk Bounds and Structural Results''. Journal of Machine Learning Research 3 463–482
* Giorgio Gnecco, Marcello Sanguineti (2008) ''Approximation Error Bounds via Rademacher's Complexity''. Applied Mathematical Sciences, Vol. 2, 2008, no. 4, 153–176

[[Category:Machine learning]]
[[Category:Measures of complexity]]</text>
      <sha1>hvirh6vrt7202rwdb976qh2coo8udcw</sha1>
    </revision>
  </page>
  <page>
    <title>Curse of dimensionality</title>
    <ns>0</ns>
    <id>787776</id>
    <revision>
      <id>990730152</id>
      <parentid>989149238</parentid>
      <timestamp>2020-11-26T05:12:48Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 24 templates: del empty params (4×); hyphenate params (7×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="23053" xml:space="preserve">{{Short description|difficulties arising when analyzing data with many aspects ("dimensions")}}
The '''curse of dimensionality''' refers to various phenomena that arise when analyzing and organizing data in [[high-dimensional space]]s that do not occur in low-dimensional settings such as the [[three-dimensional space|three-dimensional]] [[physical space]] of everyday experience.  The expression was coined by [[Richard E. Bellman]] when considering problems in [[dynamic programming]].&lt;ref&gt;{{Cite book|first=Richard Ernest |last=Bellman|author2=Rand Corporation|title=Dynamic programming|url=https://books.google.com/books?id=wdtoPwAACAAJ|year=1957|publisher=Princeton University Press|isbn=978-0-691-07951-6|page=ix}},&lt;br /&gt;Republished: {{Cite book|first=Richard Ernest |last=Bellman|title=Dynamic Programming|url=https://books.google.com/books?id=fyVtp3EMxasC|year=2003|publisher=Courier Dover Publications|isbn=978-0-486-42809-3}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|first=Richard Ernest |last=Bellman|title=Adaptive control processes: a guided tour|url=https://books.google.com/books?id=POAmAAAAMAAJ|year=1961|publisher=Princeton University Press}}&lt;/ref&gt;

Dimensionally cursed phenomena occur in domains such as [[numerical analysis]], [[Sampling (statistics)|sampling]], [[combinatorics]], [[machine learning]], [[data mining]] and [[database]]s. The common theme of these problems is that when the dimensionality increases, the [[volume]] of the space increases so fast that the available data become sparse. This sparsity is problematic for any method that requires [[statistical significance]]. In order to obtain a statistically sound and reliable result, the amount of data needed to support the result often grows exponentially with the dimensionality. Also, organizing and searching data often relies on detecting areas where objects form groups with similar properties; in high dimensional data, however, all objects appear to be sparse and dissimilar in many ways, which prevents common data organization strategies from being efficient.

{{toclimit|3}}
== Domains ==

=== Combinatorics ===
In some problems, each variable can take one of several discrete values, or the range of possible values is divided to give a finite number of possibilities. Taking the variables together, a huge number of combinations of values must be considered. This effect is also known as the [[combinatorial explosion]]. Even in the simplest case of &lt;math&gt;d&lt;/math&gt; binary variables, the number of possible combinations already is &lt;math&gt;2^d&lt;/math&gt;, exponential in the dimensionality. Naively, each additional dimension doubles the effort needed to try all combinations.

=== Sampling ===
There is an exponential increase in volume associated with adding extra dimensions to a [[Space (mathematics)|mathematical space]]. For example, 10&lt;sup&gt;2&lt;/sup&gt;=100 evenly spaced sample points suffice to sample a [[unit interval]] (a "1-dimensional cube") with no more than 10&lt;sup&gt;−2&lt;/sup&gt;=0.01 distance between points; an equivalent sampling of a 10-dimensional [[unit hypercube]] with a lattice that has a spacing of 10&lt;sup&gt;−2&lt;/sup&gt;=0.01 between adjacent points would require 10&lt;sup&gt;20&lt;/sup&gt;=[(10&lt;sup&gt;2&lt;/sup&gt;)&lt;sup&gt;10&lt;/sup&gt;] sample points. In general, with a spacing distance of 10&lt;sup&gt;−n&lt;/sup&gt; the 10-dimensional hypercube appears to be a factor of 10&lt;sup&gt;n(10-1)&lt;/sup&gt;=[(10&lt;sup&gt;n&lt;/sup&gt;)&lt;sup&gt;10&lt;/sup&gt;/(10&lt;sup&gt;n&lt;/sup&gt;)] "larger" than the 1-dimensional hypercube, which is the unit interval. In the above example n=2: when using a sampling distance of 0.01 the 10-dimensional hypercube appears to be 10&lt;sup&gt;18&lt;/sup&gt; "larger" than the unit interval. This effect is a combination of the combinatorics problems above and the distance function problems explained below.

=== Optimization ===
When solving dynamic [[optimization (mathematics)|optimization]] problems by numerical [[backward induction]], the objective function must be computed for each combination of values. This is a significant obstacle when the dimension of the "state variable" is large.&lt;ref&gt;{{cite book |first=C. Robert |last=Taylor |chapter=Dynamic Programming and the Curses of Dimensionality |title=Applications Of Dynamic Programming To Agricultural Decision Problems |publisher=Westview Press |year=1993 |isbn=0-8133-8641-1 |pages=1–10 |chapter-url=https://www.google.com/books/edition/_/71SsDwAAQBAJ?hl=en&amp;gbpv=1&amp;pg=PA1 }} &lt;/ref&gt;

=== Machine Learning ===
In [[machine learning]] problems that involve learning a "state-of-nature" from a finite number of data samples in a high-dimensional [[feature space]] with each feature having a range of possible values, typically an enormous amount of training data is required to ensure that there are several samples with each combination of values. 

A typical rule of thumb is that there should be at least 5 training examples for each dimension in the representation.&lt;ref name="Pattern recog" &gt;{{cite book|last1=Koutroumbas|first2=Sergios |last2=Theodoridis |first1=Konstantinos|title=Pattern Recognition |edition=4th  |date=2008|location=Burlington|url=https://www.elsevier.com/books/pattern-recognition/theodoridis/978-1-59749-272-0 |isbn=978-1-59749-272-0 |access-date=8 January 2018 }}&lt;/ref&gt; In [[machine learning]] and insofar as predictive performance is concerned, the curse of dimensionality is used interchangeably with the ''peaking phenomenon'',&lt;ref name="Pattern recog"/&gt; which is also known as ''Hughes phenomenon''.&lt;ref&gt;{{cite journal |last=Hughes |first=G.F. |s2cid=206729491 |title=On the mean accuracy of statistical pattern recognizers |journal=IEEE Transactions on Information Theory |volume=14 |issue=1 |pages=55–63 |date=January 1968 |doi=10.1109/TIT.1968.1054102 }}&lt;/ref&gt; This phenomenon states that with a fixed number of training samples, the average (expected) predictive power of a classifier or regressor first increases as the number of dimensions or features used is increased but beyond a certain dimensionality it starts deteriorating instead of improving steadily.&lt;ref&gt;{{cite journal|last1=Trunk|first1=G. V.|title=A Problem of Dimensionality: A Simple Example|journal=IEEE Transactions on Pattern Analysis and Machine Intelligence|date=July 1979|volume=PAMI-1|issue=3|pages=306–307|doi=10.1109/TPAMI.1979.4766926|pmid=21868861}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |author1=B. Chandrasekaran |author2=A. K. Jain |title=Quantization Complexity and Independent Measurements|journal= IEEE Transactions on Computers|year=1974|doi=10.1109/T-C.1974.223789 |volume=23 |issue=8 |pages=102–106}}&lt;/ref&gt;&lt;ref name="McLachlan:2004"&gt;{{cite book |title=Discriminant Analysis and Statistical Pattern Recognition |first1=G. J. |last1=McLachlan |publisher=Wiley Interscience |isbn=978-0-471-69115-0 |year=2004 |mr=1190469}}&lt;/ref&gt; 

Nevertheless, in the context of a ''simple'' classifier ([[linear discriminant analysis]] in the multivariate Gaussian model under the assumption of a common known covariance matrix) Zollanvari et al. &lt;ref&gt;{{cite journal |author1=A. Zollanvari |author2=A. P. James |author3=R. Sameni |title=A Theoretical Analysis of the Peaking Phenomenon in Classification|journal= Journal of Classification |year=2020|doi=10.1007/s00357-019-09327-3 |volume=37 |pages=421–434}}&lt;/ref&gt; showed both analytically and empirically that as long as the relative cumulative efficacy of an additional feature set (with respect to features that are already part of the classifier) is greater (or less) than the size of this additional feature set, the expected error of the classifier constructed using these additional features will be less (or greater) than the expected error of the classifier constructed without them. In other words, both the size of additional features and their (relative) cumulative discriminatory effect are important in observing a decrease or increase in the average predictive power.

=== Distance functions ===
When a measure such as a [[Euclidean distance]] is defined using many coordinates, there is little difference in the distances between different pairs of samples.

One way to illustrate the "vastness" of high-dimensional Euclidean space is to compare the proportion of an inscribed [[hypersphere]] with radius &lt;math&gt;r&lt;/math&gt; and dimension &lt;math&gt;d&lt;/math&gt;, to that of a [[hypercube]] with edges of length &lt;math&gt;2r.&lt;/math&gt;
The volume of such a sphere is &lt;math&gt;\frac{2r^d\pi^{d/2}}{d \; \Gamma(d/2)}&lt;/math&gt;, where [[Gamma function|&lt;math&gt;\Gamma&lt;/math&gt;]] is the [[gamma function]], while the volume of the cube is &lt;math&gt;(2r)^d&lt;/math&gt;.
As the dimension &lt;math&gt;d&lt;/math&gt; of the space increases, the hypersphere becomes an insignificant volume relative to that of the hypercube. This can clearly be [[:commons:File:Ball-cube-volume-ratio-semilog.png|seen]] by comparing the proportions as the dimension &lt;math&gt;d&lt;/math&gt; goes to infinity:
:&lt;math&gt;\frac{V_\mathrm{hypersphere}}{V_\mathrm{hypercube}}=\frac{\pi^{d/2}}{d2^{d-1}\Gamma(d/2)}\rightarrow 0&lt;/math&gt; as &lt;math&gt;d \rightarrow \infty&lt;/math&gt;. 

Furthermore, the distance between the center and the corners is &lt;math&gt;r\sqrt{d}&lt;/math&gt;, which increases without bound for fixed r.
In this sense, nearly all of the high-dimensional space is "far away" from the centre. To put it another way, the high-dimensional unit hypercube can be said to consist almost entirely of the "corners" of the hypercube, with almost no "middle".

This also helps to understand the [[chi-squared distribution]]. Indeed, the (non-central) chi-squared distribution associated to a random point in the interval [-1, 1] is the same as the distribution of the length-squared of a random point in the ''d''-cube. By the law of large numbers, this distribution concentrates itself in a narrow band around ''d'' times the standard deviation squared (σ&lt;sup&gt;2&lt;/sup&gt;) of the original derivation. This illuminates the chi-squared distribution and also illustrates that most of the volume of the ''d''-cube concentrates near the surface of a sphere of radius &lt;math&gt;\sigma\sqrt{d}&lt;/math&gt;.

A further development of this phenomenon is as follows. Any fixed distribution on ''[[Real number|ℝ]]'' induces a product distribution on points in ''ℝ&lt;sup&gt;d&lt;/sup&gt;''. For any fixed ''n'', it turns out that the minimum and the maximum distance between a random reference point ''Q'' and a list of ''n'' random data points ''P&lt;sub&gt;1&lt;/sub&gt;,...,P&lt;sub&gt;n&lt;/sub&gt;'' become indiscernible compared to the minimum distance:&lt;ref&gt;{{Cite book | doi = 10.1007/3-540-49257-7_15 | title = When is "Nearest Neighbor" Meaningful? | year = 1999 | last1 = Beyer | first1 = K. | last2 = Goldstein | first2 = J. | series = LNCS | last3 = Ramakrishnan | first3 = R. | last4 = Shaft | first4 = U. | volume = 1540 | journal = Proc. 7th International Conference on Database Theory - ICDT'99| pages = 217–235| isbn = 978-3-540-65452-0| url = http://digital.library.wisc.edu/1793/60174 }}&lt;/ref&gt;
:&lt;math&gt;\lim_{d \to \infty} E\left(\frac{\operatorname{dist}_{\max} (d) - \operatorname{dist}_{\min} (d)}{\operatorname{dist}_{\min} (d)}\right) 
\to 0&lt;/math&gt;.
This is often cited as distance functions losing their usefulness (for the nearest-neighbor criterion in feature-comparison algorithms, for example) in high dimensions. However, recent research has shown this to only hold in the artificial scenario when the one-dimensional distributions ''ℝ'' are [[Independent and identically distributed random variables|independent and identically distributed]].&lt;ref name="survey" /&gt; When attributes are correlated, data can become easier and provide higher distance contrast and the [[signal-to-noise ratio]] was found to play an important role, thus [[feature selection]] should be used.&lt;ref name="survey" /&gt;

=== Nearest neighbor search ===
The effect complicates [[nearest neighbor search]] in high dimensional space. It is not possible to quickly reject candidates by using the difference in one coordinate as a lower bound for a distance based on all the dimensions.&lt;ref&gt;{{cite journal |first1=R.B. |last1=Marimont |first2=M.B. |last2=Shapiro |title=Nearest Neighbour Searches and the Curse of Dimensionality |journal=IMA J Appl Math |volume=24 |issue=1 |pages=59–70 |year=1979 |doi=10.1093/imamat/24.1.59 |url=http://imamat.oxfordjournals.org/content/24/1/59.short}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |first1=Edgar |last1=Chávez |first2=Gonzalo |last2=Navarro |first3=Ricardo |last3=Baeza-Yates |first4=José Luis |last4=Marroquín |title=Searching in Metric Spaces |journal=ACM Computing Surveys |volume=33 |issue=3 |pages=273–321 |year=2001 |doi=10.1145/502807.502808 |citeseerx = 10.1.1.100.7845 }}&lt;/ref&gt;

However, it has recently been observed that the mere number of dimensions does not necessarily result in difficulties,&lt;ref name="houle-ssdbm10"&gt;{{Cite conference | last1 = Houle | first1 = M. E. | last2 = Kriegel | first2 = H. P. | author-link2=Hans-Peter Kriegel | last3 = Kröger | first3 = P.| last4 = Schubert | first4 = E. | last5 = Zimek | first5 = A.| title = Can Shared-Neighbor Distances Defeat the Curse of Dimensionality? | doi = 10.1007/978-3-642-13818-8_34 | conference = Scientific and Statistical Database Management | series = Lecture Notes in Computer Science | volume = 6187 | pages = 482 | year = 2010 | isbn = 978-3-642-13817-1 | url = http://www.dbs.ifi.lmu.de/~zimek/publications/SSDBM2010/SNN-SSDBM2010-preprint.pdf}}&lt;/ref&gt; since ''relevant'' additional dimensions can also increase the contrast. In addition, for the resulting ranking it remains useful to discern close and far neighbors. Irrelevant ("noise") dimensions, however, reduce the contrast in the manner described above. In [[time series analysis]], where the data are inherently high-dimensional, distance functions also work reliably as long as the [[signal-to-noise ratio]] is high enough.&lt;ref name="houle-sstd11"&gt;{{Cite conference | last1 = Bernecker | first1 = T. | last2 = Houle | first2 = M. E. | last3 = Kriegel | first3 = H. P. | author-link3=Hans-Peter Kriegel| last4 = Kröger | first4 = P. | last5 = Renz | first5 = M. | last6 = Schubert | first6 = E. | last7 = Zimek | first7 = A. | title = Quality of Similarity Rankings in Time Series | doi = 10.1007/978-3-642-22922-0_25 | conference = Symposium on Spatial and Temporal Databases| series = Lecture Notes in Computer Science | volume = 6849 | pages = 422 | year = 2011 | isbn = 978-3-642-22921-3 }}&lt;/ref&gt;

====''k''-nearest neighbor classification====
Another effect of high dimensionality on distance functions concerns ''k''-nearest neighbor (''k''-NN) [[Graph (discrete mathematics)|graphs]] constructed from a [[data set]] using a distance function. As the dimension increases, the [[indegree]] distribution of the ''k''-NN [[directed graph|digraph]] becomes [[Skewness|skewed]] with a peak on the right because of the emergence of a disproportionate number of '''hubs''', that is, data-points that appear in many more ''k''-NN lists of other data-points than the average. This phenomenon can have a considerable impact on various techniques for [[Classification (machine learning)|classification]] (including the [[K-nearest neighbor algorithm|''k''-NN classifier]]), [[semi-supervised learning]], and [[Cluster analysis|clustering]],&lt;ref&gt;{{Cite journal
 | last1=Radovanović | first1=Miloš
 | last2=Nanopoulos | first2=Alexandros
 | last3=Ivanović | first3=Mirjana
 | year=2010
 | title=Hubs in space: Popular nearest neighbors in high-dimensional data
 | journal=Journal of Machine Learning Research
 | volume=11
 | pages=2487–2531
 | url=http://www.jmlr.org/papers/volume11/radovanovic10a/radovanovic10a.pdf
 }}&lt;/ref&gt; and it also affects [[information retrieval]].&lt;ref&gt;{{Cite conference| last1 = Radovanović | first1 = M. | last2 = Nanopoulos | first2 = A. | last3 = Ivanović | first3 = M. | doi = 10.1145/1835449.1835482 | title = On the existence of obstinate results in vector space models | conference = 33rd international ACM SIGIR conference on Research and development in information retrieval - SIGIR '10 | pages = 186 | year = 2010 | isbn = 9781450301534 }}&lt;/ref&gt;

=== Anomaly detection ===

In a 2012 survey, Zimek et al. identified the following problems when searching for [[anomaly detection|anomalies]] in high-dimensional data:&lt;ref name="survey"&gt;{{Cite journal | last1 = Zimek | first1 = A. | last2 = Schubert | first2 = E.| last3 = Kriegel | first3 = H.-P. | author-link3=Hans-Peter Kriegel| title = A survey on unsupervised outlier detection in high-dimensional numerical data | doi = 10.1002/sam.11161 | journal = Statistical Analysis and Data Mining | volume = 5 | issue = 5 | pages = 363–387| year = 2012 }}&lt;/ref&gt;

# Concentration of scores and distances: derived values such as distances become numerically similar
# Irrelevant attributes: in high dimensional data, a significant number of attributes may be irrelevant
# Definition of reference sets: for local methods, reference sets are often nearest-neighbor based
# Incomparable scores for different dimensionalities: different subspaces produce incomparable scores
# Interpretability of scores: the scores often no longer convey a semantic meaning
# Exponential search space: the search space can no longer be systematically scanned
# [[Data snooping]] bias: given the large search space, for every desired significance a hypothesis can be found
# Hubness: certain objects occur more frequently in neighbor lists than others.

Many of the analyzed specialized methods tackle one or another of these problems, but there remain many open research questions.

=== Blessing of dimensionality ===

Surprisingly and despite the expected  "curse of dimensionality" difficulties, common-sense heuristics based on the  most straightforward methods "can yield results which are almost surely optimal" for high-dimensional problems.&lt;ref name="Kainen1997"&gt;{{Citation |last1= Kainen| first1= Paul C.|year= 1997 | contribution= Utilizing Geometric Anomalies of High Dimension: When Complexity Makes Computation Easier| editor-last1 = Kárný | editor-first1 = M.| editor-last2 = Warwick | editor-first2 = K.| title= Computer Intensive Methods in Control and Signal Processing|pages=283–294  |doi=10.1007/978-1-4612-1996-5_18}}&lt;/ref&gt; The term "blessing of dimensionality" was introduced in the late 1990s.&lt;ref name="Kainen1997"/&gt; [[David Donoho|Donoho]] in his "Millennium manifesto" clearly explained why the "blessing of dimensionality"  will form a basis of future data mining.&lt;ref name="Donoho2000"&gt;{{Citation |last1= Donoho| first1= David L.|year= 2000 | contribution= High-Dimensional Data Analysis: The Curses and Blessings of Dimensionality| title=Invited lecture at Mathematical Challenges of the 21st Century, AMS National Meeting, Los Angeles, CA, USA, August 6-12, 2000|citeseerx = 10.1.1.329.3392 | author1-link= David Donoho}}&lt;/ref&gt; The effects of the blessing of dimensionality were discovered in many applications and found their foundation in the [[Concentration of measure|concentration of measure phenomena]].&lt;ref name="GorbanEntr2020"&gt;{{cite journal |author-link=Aleksandr Gorban |last1=Gorban  | first1= Alexander N. |last2= Makarov| first2= Valery A.|last3= Tyukin|first3=Ivan Y.|year= 2020 |title= High-Dimensional Brain in a High-Dimensional World: Blessing of Dimensionality|journal=Entropy|volume=22|issue=1|pages= 82 |doi=10.3390/e22010082|doi-access=free | arxiv= 2001.04959 |bibcode=2020Entrp..22...82G }}&lt;/ref&gt; One example of the blessing of dimensionality phenomenon is linear separability of a random point from a large finite random set with high probability even if this set is exponentially large: the number of elements in this random set can grow exponentially with dimension. Moreover, this linear functional can be selected in the form of the simplest linear [[Linear discriminant analysis|Fisher discriminant]]. This separability theorem was proven for a wide class of probability distributions: general uniformly log-concave distributions, product distributions in a cube and many other families (reviewed recently in &lt;ref name="GorbanEntr2020"/&gt;). 

"The blessing of dimensionality and the curse of dimensionality are two sides of the same coin."&lt;ref name="GorTyukPhTranRS2018"&gt;{{cite journal |last1=  Gorban| first1= Alexander N. |last2= Tyukin|first2= Ivan Y.|year= 2018 |title= Blessing of dimensionality: mathematical foundations of the statistical physics of data|journal= Phil. Trans. R. Soc. A|volume=376|issue= 2118|pages= 20170237 |doi=10.1098/rsta.2017.0237| pmid= 29555807 | pmc= 5869543 |doi-access=free | arxiv= 1801.03421| bibcode= 2018RSPTA.37670237G }}&lt;/ref&gt; For example, the typical property of essentially high-dimensional probability distributions in a high-dimensional space is: the squared distance of random points to a selected point is, with high probability, close to the average (or median) squared distance. This property significantly simplifies the expected geometry of data and indexing of high-dimensional data (blessing),&lt;ref name="Hecht1994"&gt;{{Citation  |author-link=Robert Hecht-Nielsen |last1=Hecht-Nielsen | first1= Robert|year= 1994 | contribution= Context vectors: general-purpose approximate meaning representations self-organized from raw data| editor-last1 = Zurada | editor-first1 = J.M.| editor-last2 =Marks | editor-first2 = R.J.| editor-last3 = Robinson | editor-first3 = C.J.| title= Computational intelligence: imitating life; Proceedings of World Congress on Computational Intelligence, Neural Networks; 1994; Orlando; FL |isbn=0780311043  |pages=43–56  |publisher= [[IEEE]] Press |location= Piscataway, NJ   }}&lt;/ref&gt; but, at the same time, it makes the similarity search in high dimensions difficult and even useless (curse).&lt;ref name="PestovCamwa2013"&gt;{{cite journal |last1= Pestov | first1= Vladimir|year= 2013|title= Is the k-NN classifier in high dimensions affected by the curse of dimensionality?|journal=Comput. Math. Appl.|volume=65|issue= 10|pages= 43–56 |doi=10.1016/j.camwa.2012.09.011|doi-access=free}}&lt;/ref&gt;

Zimek et al.&lt;ref name="survey" /&gt; noted that while the typical formalizations of the curse of dimensionality affect [[Independent and identically distributed random variables|i.i.d.]] data, having data that is separated in each attribute becomes easier even in high dimensions, and argued that the [[signal-to-noise ratio]] matters: data becomes easier with each attribute that adds signal, and harder with attributes that only add noise (irrelevant error) to the data. In particular for unsupervised data analysis this effect is known as swamping.

==See also==
{{Div col|colwidth=22em}}
*[[Bellman equation]]
*[[Clustering high-dimensional data]]
*[[Concentration of measure]]
*[[Dimension reduction]]
*[[Model Order Reduction]]
*[[Dynamic programming]]
*[[Fourier-related transforms]]
*[[Linear least squares (mathematics)|Linear least squares]]
*[[Multilinear principal component analysis|Multilinear PCA]]
*[[Multilinear subspace learning]]
*[[Principal component analysis]]
*[[Singular value decomposition]]
{{div col end}}

==References==
{{Reflist|30em}}

[[Category:Numerical analysis]]
[[Category:Dynamic programming]]
[[Category:Machine learning]]
[[Category:Dimension]]</text>
      <sha1>g8av1ictcyfdgmiwwc1li6torqf03yl</sha1>
    </revision>
  </page>
  <page>
    <title>Uncertain data</title>
    <ns>0</ns>
    <id>19058043</id>
    <revision>
      <id>1000113787</id>
      <parentid>926153840</parentid>
      <timestamp>2021-01-13T17:13:32Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 4 templates: hyphenate params (2×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="4364" xml:space="preserve">In [[computer science]], '''uncertain data''' is data that contains [[measurement error|noise]] that makes it deviate from the correct, intended or original values. In the age of [[big data]], uncertainty or data veracity is one of the defining characteristics of data. Data is constantly growing in volume, variety, velocity and uncertainty (1/veracity). Uncertain data is found in abundance today on the web, in sensor networks, within enterprises both in their structured and unstructured sources. For example, there may be uncertainty regarding the address of a customer in an enterprise dataset, or the temperature readings captured by a sensor due to aging of the sensor. In 2012 IBM called out '''managing uncertain data at scale''' in its '''global technology outlook''' report&lt;ref&gt;{{cite report|url=http://www.zurich.ibm.com/pdf/isl/infoportal/GTO_2012_Booklet.pdf|title=Global Technology Outlook|year=2012}}&lt;/ref&gt; that presents a comprehensive analysis looking three to ten years into the future seeking to identify significant, disruptive technologies that will change the world. In order to make confident business decisions based on real-world data, analyses must necessarily account for many different kinds of uncertainty present in very large amounts of data. Analyses based on uncertain data will have an effect on the quality of subsequent decisions, so the degree and types of inaccuracies in this uncertain data cannot be ignored.

Uncertain data is found in the area of [[sensor networks]]; text where [[noisy text]] is found in abundance on social media, web and within enterprises where the structured and [[unstructured data]] may be old, outdated, or plain incorrect; in modeling where the [[mathematical model]] may only be an approximation of the actual process. When representing such data in a [[database]], some indication of the [[probability]] of the correctness of the various values also needs to be estimated.

There are three main models of uncertain data in databases. In '''attribute uncertainty''', each uncertain attribute in a tuple is subject to its own independent [[probability distribution]].&lt;ref name="orion"&gt;{{cite journal|last=Prabhakar|first=Sunil |title=ORION: Managing Uncertain (Sensor) Data|url=http://mobisensors.cs.pitt.edu/files/papers/prabhakar.pdf}}&lt;/ref&gt; For example, if readings are taken of temperature and wind speed, each would be described by its own probability distribution, as knowing the reading for one measurement would not provide any information about the other.

In '''correlated uncertainty''', multiple attributes may be described by a [[joint probability distribution]].&lt;ref name="orion"/&gt; For example, if readings are taken of the position of an object, and the ''x''- and ''y''-coordinates stored, the probability of different values may depend on the distance from the recorded coordinates. As distance depends on both coordinates, it may be appropriate to use a joint distribution for these coordinates, as they are not [[Statistical independence|independent]].

In '''tuple uncertainty''', all the attributes of a [[tuple]] are subject to a joint probability distribution. This covers the case of correlated uncertainty, but also includes the case where there is a probability of a tuple not belonging in the relevant relation, which is indicated by all the probabilities not summing to one.&lt;ref name="orion"/&gt; For example, assume we have the following tuple from a [[probabilistic database]]:
{| class="wikitable" border="1"
|-
|| (a, 0.4) | (b, 0.5)
|}

Then, the tuple has 10% chance of not existing in the database.

==References==
{{reflist}}

*{{cite conference|first=Habich|last=Volk|author2=Clemens Utzny, Ralf Dittmann, Wolfgang Lehner|publisher=IEEE|title=Error-Aware Density-Based Clustering of Imprecise Measurement Values|book-title=Seventh IEEE International Conference on Data Mining Workshops, 2007. ICDM Workshops 2007. }}
*{{cite conference|first=Volk|last=Rosentahl|author2=Martin Hahmann, Dirk Habich, Wolfgang Lehner|publisher=IEEE|title=Clustering Uncertain Data With Possible Worlds|book-title=Proceedings of the 1st Workshop on Management and mining Of Uncertain Data in conjunction with the 25th International Conference on Data Engineering, 2009.}}

[[Category:Machine learning]]
[[Category:Data mining]]
[[Category:Statistical theory]]


{{compu-sci-stub}}</text>
      <sha1>lhkqwypjh7gc1g5fwuygmawzapcno5q</sha1>
    </revision>
  </page>
  <page>
    <title>Knowledge integration</title>
    <ns>0</ns>
    <id>4144848</id>
    <revision>
      <id>895061437</id>
      <parentid>710817190</parentid>
      <timestamp>2019-05-01T18:57:00Z</timestamp>
      <contributor>
        <username>Sportfish</username>
        <id>1659498</id>
      </contributor>
      <comment>/* Further reading */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="4194" xml:space="preserve">'''Knowledge integration''' is the process of synthesizing multiple [[knowledge model]]s (or representations) into a common model (representation).

Compared to [[information integration]], which involves merging information having different schemas and representation models, knowledge integration focuses more on synthesizing the understanding of a given subject from different perspectives.

For example, multiple interpretations are possible of a set of student grades, typically each from a certain perspective. An overall, integrated view and understanding of this information can be achieved if these interpretations can be put under a common model, say, a student performance index.

The [http://wise.berkeley.edu Web-based Inquiry Science Environment (WISE)], from the [[University of California at Berkeley]] has been developed along the lines of knowledge integration theory.

'''Knowledge integration''' has also been studied as the process of incorporating new information into a body of existing knowledge with an [[interdisciplinary]] approach.  This process involves determining how the new information and the existing knowledge interact, how existing knowledge should be modified to accommodate the new information, and how the new information should be modified in light of the existing knowledge.

A learning agent that actively investigates the consequences of new information can detect and exploit a variety of learning opportunities; e.g., to resolve knowledge conflicts and to fill knowledge gaps.  By exploiting these learning opportunities the learning agent is able to learn beyond the explicit content of the new information.

The [[machine learning]] program KI, developed by Murray and Porter at the [[University of Texas at Austin]], was created to study the use of automated and semi-automated knowledge integration to assist [[knowledge engineers]] constructing a large [[knowledge base]].

A possible technique which can be used is [[semantic matching]]. More recently, a technique useful to minimize the effort in mapping validation and visualization has been presented which is based on [[Minimal mappings|Minimal Mappings]]. Minimal mappings are high quality mappings such that i) all the other mappings can be computed from them in time linear in the size of the input graphs, and ii) none of them can be dropped without losing property i).

The [[University of Waterloo]] operates a Bachelor of Knowledge Integration [[undergraduate degree]] program as an academic major or minor. The program started in 2008.

==See also==
* [[Knowledge value chain]]

==References==
{{Reflist}}&lt;!--added under references heading by script-assisted edit--&gt;

==Further reading==
* Linn, M. C. (2006) The Knowledge Integration Perspective on Learning and Instruction. R. Sawyer (Ed.). In ''The Cambridge Handbook of the Learning Sciences.'' Cambridge, MA. Cambridge University Press
* Murray, K. S. (1996) KI: A tool for Knowledge Integration. Proceedings of the Thirteenth National Conference on Artificial Intelligence
* Murray, K. S. (1995) [http://www.ai.sri.com/pubs/files/1636.pdf Learning as Knowledge Integration], Technical Report TR-95-41, The University of Texas at Austin
* Murray, K. S. (1990) Improving Explanatory Competence, Proceedings of the Twelfth Annual Conference of the Cognitive Science Society
* Murray, K. S., Porter, B. W. (1990) Developing a Tool for Knowledge Integration: Initial Results. International Journal for Man-Machine Studies, volume 33
* Murray, K. S., Porter, B. W. (1989) Controlling Search for the Consequences of New Information during Knowledge Integration. Proceedings of the Sixth International Machine Learning Conference
* Shen, J., Sung, S., &amp; Zhang, D.M. (2016) Toward an analytic framework of interdisciplinary reasoning and communication (IRC) processes in science. International Journal of Science Education, 37 (17), 2809-2835.
* Shen, J., Liu, O., &amp; Sung, S. (2014). Designing interdisciplinary assessments in science for college students: An example on osmosis. International Journal of Science Education, 36 (11), 1773-1793.
[[Category:Knowledge representation]]
[[Category:Learning]]
[[Category:Machine learning]]</text>
      <sha1>r8eiqptklkn74rwj7k2rvsw1uwhd2hv</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Learning in computer vision</title>
    <ns>14</ns>
    <id>19314112</id>
    <revision>
      <id>604225892</id>
      <parentid>604225655</parentid>
      <timestamp>2014-04-14T23:19:15Z</timestamp>
      <contributor>
        <username>Deva Ramanan</username>
        <id>21191864</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="695" xml:space="preserve">Learning-based methods in [[computer vision]] make use of training data to build systems for visual analysis. For example, one may train a system for detecting faces using training images of faces. Training data is often given in the forms of image or video collections, together with target labels. Such data is often fed into a [[machine learning]] algorithm, that will learn to predict such labels given novel images or video. Learning-based methods have been used for a variety of computer vision tasks, including low-level problems such as image-denoising, and high-level tasks such as object recognition and scene classification.

[[Category:Computer vision]]
[[Category:Machine learning]]</text>
      <sha1>svxifbvd4z6r02uvef3yvxuqo2z5ddt</sha1>
    </revision>
  </page>
  <page>
    <title>Offline learning</title>
    <ns>0</ns>
    <id>10748030</id>
    <revision>
      <id>995355299</id>
      <parentid>951447664</parentid>
      <timestamp>2020-12-20T16:15:09Z</timestamp>
      <contributor>
        <username>Lennart97</username>
        <id>14423028</id>
      </contributor>
      <minor/>
      <comment>Unlinked: [[Time lag]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3629" xml:space="preserve">{{More citations needed|date=February 2018}}

In [[machine learning]], systems which employ offline learning do not change their approximation of the target function when the initial training phase has been completed.{{Citation needed|date=February 2018}} These systems are also typically examples of [[eager learning]].{{Citation needed|date=February 2018}}

While in online learning, only the set of possible elements is known, in offline learning, the identity of the elements as well as the order in which they are presented is known to the learner.&lt;ref&gt;{{Cite journal|last=Ben-David|first=Shai|last2=Kushilevitz|first2=Eyal|last3=Mansour|first3=Yishay|date=1997-10-01|title=Online Learning versus Offline Learning|journal=Machine Learning|language=en|volume=29|issue=1|pages=45–63|doi=10.1023/A:1007465907571|issn=0885-6125|doi-access=free}}&lt;/ref&gt;

==Applications for robotics control==
The ability of robots to learn is equal to create a [[table (information)]] which is filled with values. One option for doing so is [[programming by demonstration]]. Here, the table is filled with values by a human teacher. The demonstration is provided either as [[direct numerical control]] policy which is equal to a trajectory, or as an indirect [[objective function]] which is given in advance.&lt;ref&gt;{{cite journal |title=Learning robot objectives from physical human interaction |author=Bajcsy, Andrea and Losey, Dylan P and O’Malley, Marcia K and Dragan, Anca D |journal=Proceedings of Machine Learning Research |volume=78 |pages=217–226 |year=2017 |publisher=PMLR }}&lt;/ref&gt;

Offline learning is working in [[batch mode]]. In step 1 the task is demonstrated and stored in the table, and in step 2 the task is reproduced by the robot.&lt;ref&gt;{{cite conference |title=Occupancy grid models for robot mapping in changing environments |author=Meyer-Delius, Daniel and Beinhofer, Maximilian and Burgard, Wolfram |conference=Twenty-Sixth AAAI Conference on Artificial Intelligence |year=2012 }}&lt;/ref&gt; The pipeline is slow and inefficient because a delay is there between behavior demonstration and skill replay.&lt;ref&gt;{{cite conference |doi=10.1109/iros.2016.7759574 |year=2016 |publisher=IEEE |author=Luka Peternel and Erhan Oztop and Jan Babic |title=A shared control method for online human-in-the-loop robot learning based on Locally Weighted Regression |conference=2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) }}&lt;/ref&gt;&lt;ref name="Jun2003"&gt;{{cite conference |title=Robot behavior learning with a dynamically adaptive RBF network: Experiments in offline and online learning |author=Jun, Li and Duckett, Tom |conference=Proc. 2 Intern. Conf. on Comput. Intelligence, Robotics and Autonomous System, CIRAS |year=2003 |publisher=Citeseer }}&lt;/ref&gt;

A short example will help to understand the idea. Suppose the robot should learn a [[Maze_solving_algorithm#Wall_follower|wall following]] task and the internal table of the robot is empty. Before the robot gets activated in the replay mode, the human demonstrator has to teach the behavior. He is controlling the robot with [[teleoperation]] and during the learning step the skill table is generated. The process is called offline, because the robot control software is doing nothing but the device is utilized by the human operator as a [[pointing device]] for driving along the wall.&lt;ref name="Jun2003" /&gt;

==See also==
* [[online machine learning|Online learning]], the opposite model
* [[Incremental learning]], a learning model for the incremental extension of knowledge

==References==
&lt;references /&gt;

[[Category:Machine learning]]


{{compu-stub}}</text>
      <sha1>rbsafb1llybs42rzxugr8ewoum3xg51</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Ensemble learning</title>
    <ns>14</ns>
    <id>3985352</id>
    <revision>
      <id>786890664</id>
      <parentid>243007847</parentid>
      <timestamp>2017-06-22T05:58:02Z</timestamp>
      <contributor>
        <username>Rentier</username>
        <id>454738</id>
      </contributor>
      <comment>rm (dead) external link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="322" xml:space="preserve">'''Ensemble learning''' is a type of [[machine learning]] that studies [[algorithms]] and architectures that build collections, or ''ensembles'', of [[statistical classification|statistical classifiers]] that are more accurate than a single classifier.

[[Category:Classification algorithms]]
[[Category:Machine learning]]</text>
      <sha1>355g8efhuyhe8cb9y3zsl07mszneeiw</sha1>
    </revision>
  </page>
  <page>
    <title>Neural modeling fields</title>
    <ns>0</ns>
    <id>19208664</id>
    <revision>
      <id>984690928</id>
      <parentid>901881314</parentid>
      <timestamp>2020-10-21T14:43:17Z</timestamp>
      <contributor>
        <username>LearnMore</username>
        <id>134016</id>
      </contributor>
      <comment>General proofreading.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="22735" xml:space="preserve">'''Neural modeling field (NMF)''' is a mathematical framework for [[machine learning]] which combines ideas from [[neural networks]], [[fuzzy logic]], and [[model based recognition]]. It has also been referred to as '''modeling fields''',  '''modeling fields theory''' (MFT),  '''Maximum likelihood artificial neural networks''' (MLANS).&lt;ref&gt;[http://www.oup.com/us/catalog/he/subject/Engineering/ElectricalandComputerEngineering/ComputerEngineering/NeuralNetworks/?view=usa&amp;ci=9780195111620]: Perlovsky, L.I. 2001. Neural Networks and Intellect: using model based concepts. New York: Oxford University Press&lt;/ref&gt;&lt;ref&gt;Perlovsky, L.I. (2006). Toward Physics of the Mind: Concepts, Emotions, Consciousness, and Symbols. Phys. Life Rev. 3(1), pp.22-55.&lt;/ref&gt;&lt;ref&gt;[http://ieeexplore.ieee.org/xpl/absprintf.jsp?arnumber=713700&amp;page=FREE]: Deming, R.W.,  
Automatic buried mine detection using the maximum likelihoodadaptive neural system (MLANS), in Proceedings of ''Intelligent Control (ISIC)'', 1998. Held jointly with ''IEEE International Symposium on Computational Intelligence in Robotics and Automation (CIRA), Intelligent Systems and Semiotics (ISAS)''&lt;/ref&gt;&lt;ref&gt;[http://www.mdatechnology.net/techprofile.aspx?id=227 ]: MDA Technology Applications Program web site&lt;/ref&gt;
&lt;ref&gt;[http://ieeexplore.ieee.org/search/wrapper.jsp?arnumber=4274797]: Cangelosi, A.; Tikhanoff, V.; Fontanari, J.F.; Hourdakis, E., Integrating Language and Cognition: A Cognitive Robotics Approach, Computational Intelligence Magazine, IEEE, Volume 2,  Issue 3,  Aug. 2007 Page(s):65 - 70&lt;/ref&gt;&lt;ref&gt;[http://spie.org/x648.xml?product_id=521387&amp;showAbstracts=true&amp;origin_id=x648]: Sensors, and Command, Control, Communications, and Intelligence (C3I) Technologies for Homeland Security and Homeland Defense III (Proceedings Volume), Editor(s): Edward M. Carapezza, Date: 15 September 2004,{{ISBN|978-0-8194-5326-6}}, See Chapter: ''Counter-terrorism threat prediction architecture''&lt;/ref&gt;
This framework has been developed by [[Leonid Perlovsky]] at the [[AFRL]].  NMF is interpreted as a mathematical description of mind’s mechanisms, including [[concept]]s, [[emotions]], [[instincts]], [[imagination]], [[thinking]], and [[understanding]].  NMF is a multi-level, hetero-hierarchical system. At each level in NMF there are concept-models encapsulating the knowledge; they generate so-called top-down signals, interacting with input, bottom-up signals. These interactions are governed by dynamic equations, which drive concept-model learning, adaptation, and formation of new concept-models for better correspondence to the input, bottom-up signals.

==Concept models and similarity measures==
In the general case, NMF system consists of multiple processing levels. At each level, output signals are the concepts recognized in (or formed from) input, bottom-up signals. Input signals are associated with (or recognized, or grouped into) concepts according to the models and at this level.   In the process of learning the concept-models are adapted for better representation of the input signals so that similarity between the concept-models and signals increases. This increase in similarity can be interpreted as satisfaction of an instinct for knowledge, and is felt as [[aesthetic emotions]].

Each hierarchical level consists of N "neurons" enumerated by index n=1,2..N. These neurons receive input, bottom-up signals, '''X(n)''', from lower levels in the processing hierarchy. '''X'''(n) is a field of bottom-up neuronal synaptic activations, coming from neurons at a lower level.  Each neuron has a number of synapses; for generality, each neuron activation is described as a set of numbers, 

:&lt;math&gt; \vec X(n) = \{ X_d(n) \}, d = 1..D.&lt;/math&gt;

, where D is the number or dimensions necessary to describe individual neuron's activation.  

Top-down, or priming signals to these neurons are sent by concept-models, '''M'''&lt;sub&gt;m&lt;/sub&gt;('''S'''&lt;sub&gt;m&lt;/sub&gt;,n) 

:&lt;math&gt; \vec M_m(\vec S_m, n), m = 1..M.&lt;/math&gt;

, where  M is the number of models.  Each model is characterized by its parameters, '''S&lt;sub&gt;m&lt;/sub&gt;'''; in the neuron structure of the brain they are encoded by strength of synaptic connections, mathematically, they are given by a set of numbers, 

:&lt;math&gt; \vec S_m = \{ S_m^a \}, a = 1..A.&lt;/math&gt;

, where A is the number of dimensions necessary to describe individual model.

Models represent signals in the following way.  Suppose that signal '''X(''n'')''' is coming from sensory neurons n activated by object m, which is characterized by parameters '''S&lt;sub&gt;m&lt;/sub&gt;'''. These parameters may include position, orientation, or lighting of an object m. Model '''M&lt;sub&gt;m&lt;/sub&gt;'''('''S&lt;sub&gt;m&lt;/sub&gt;''',n) predicts a value '''X'''(n) of a signal at neuron n.  For example, during visual perception, a neuron n in the visual cortex receives a signal '''X'''(n) from retina and a [[Priming (psychology)|priming]] signal '''M&lt;sub&gt;m&lt;/sub&gt;'''('''S&lt;sub&gt;m&lt;/sub&gt;''',n) from an object-concept-model ''m''.  Neuron ''n'' is activated if both the bottom-up signal from lower-level-input and the top-down priming signal are strong.  Various models compete for evidence in the bottom-up signals, while adapting their parameters for better match as described below. This is a simplified description of perception. The most benign everyday visual perception uses many levels from retina to object perception. The NMF premise is that the same laws describe the basic interaction dynamics at each level.  Perception of minute features, or everyday objects, or cognition of complex abstract concepts is due to the same mechanism described below. Perception and cognition involve concept-models and learning. In perception, concept-models correspond to objects; in cognition models correspond to relationships and situations.

Learning is an essential part of perception and cognition, and in NMF theory it is driven by the dynamics that increase a [[similarity measure]] between the sets of models and signals, L({'''X'''},{'''M'''}).  The similarity measure is a function of model parameters and associations between the input bottom-up signals and top-down, concept-model signals. In constructing a mathematical description of the similarity measure, it is important to acknowledge two principles:
:''First'', the visual field content is unknown before perception occurred
:''Second'', it may contain any of a number of objects. Important information could be contained in any bottom-up signal;

Therefore, the similarity measure is constructed so that it accounts for all bottom-up signals, ''X''(''n''),

:&lt;math&gt; L( \{\vec X(n)\}, \{\vec M_m( \vec S_m, n)\} ) = \prod_{n=1}^N{l(\vec X(n))}.&lt;/math&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; (1)

This expression contains a product of partial similarities, l('''X'''(n)), over all bottom-up signals; therefore it forces the NMF system to account for every signal (even if one term in the product is zero, the product is zero, the similarity is low and the knowledge instinct is not satisfied); this is a reflection of the first principle.  Second, before perception occurs, the mind does not know which object gave rise to a signal from a particular retinal neuron. Therefore a partial similarity measure is constructed so that it treats each model as an alternative (a sum over concept-models) for each input neuron signal.  Its constituent elements are conditional partial similarities between signal '''X'''(n) and model '''M&lt;sub&gt;m&lt;/sub&gt;''', l('''X'''(n)|m). This measure is “conditional” on object m being present, therefore, when combining these quantities into the overall similarity measure, L, they are multiplied by r(m), which represent a probabilistic measure of object m actually being present. Combining these elements with the two principles noted above, a similarity measure is constructed as follows: 

:&lt;math&gt; L( \{\vec X(n)\}, \{\vec M_m( \vec S_m, n)\} ) = \prod_{n=1}^N{ \sum_{m=1}^M { r(m) l(\vec X(n) | m) } }.&lt;/math&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;(2)

The structure of the expression above follows standard principles of the probability theory: a summation is taken over alternatives, m, and various pieces of evidence, n, are multiplied. This expression is not necessarily a probability, but it has a probabilistic structure. If learning is successful, it approximates probabilistic description and leads to near-optimal Bayesian decisions. The name “conditional partial similarity” for l('''X'''(n)|m) (or simply l(n|m)) follows the probabilistic terminology. If learning is successful, l(n|m) becomes a conditional probability density function, a probabilistic measure that signal in neuron n originated from object m.  Then L is a total likelihood of observing signals {'''X'''(n)} coming from objects described by concept-model {'''M&lt;sub&gt;m&lt;/sub&gt;'''}. Coefficients r(m), called priors in probability theory, contain preliminary biases or expectations, expected objects m have relatively high r(m) values; their true values are usually unknown and should be learned, like other parameters '''S&lt;sub&gt;m&lt;/sub&gt;'''.

Note that in probability theory, a product of probabilities usually assumes that evidence is independent. Expression for L contains a product over n, but it does not assume independence among various signals '''X'''(n). There is a dependence among signals due to concept-models: each model '''M&lt;sub&gt;m&lt;/sub&gt;'''('''S&lt;sub&gt;m&lt;/sub&gt;''',n) predicts expected signal values in many neurons n. 

During the learning process, concept-models are constantly modified. Usually, the functional forms of models, '''M&lt;sub&gt;m&lt;/sub&gt;'''('''S&lt;sub&gt;m&lt;/sub&gt;''',n),  are all fixed and learning-adaptation involves only model parameters, '''S&lt;sub&gt;m&lt;/sub&gt;'''.  From time to time a system forms a new concept, while retaining an old one as well; alternatively, old concepts are sometimes merged or eliminated. This requires a modification of the similarity measure L; The reason is that more models always result in a better fit between the models and data. This is a well known problem, it is addressed by reducing similarity L using a “skeptic penalty function,” ([[Penalty method]]) p(N,M) that grows with the number of models M, and this growth is steeper for a smaller amount of data N. For example, an asymptotically unbiased maximum likelihood estimation leads to multiplicative p(N,M) = exp(-N&lt;sub&gt;par&lt;/sub&gt;/2), where N&lt;sub&gt;par&lt;/sub&gt; is a total number of adaptive parameters in all models (this penalty function is known as [[Akaike information criterion]], see (Perlovsky 2001) for further discussion and references).

==Learning in NMF using dynamic logic algorithm==
	
The learning process consists of estimating model parameters '''S''' and associating signals with concepts by maximizing the similarity L. Note that all possible combinations of signals and models are accounted for in expression (2) for L. This can be seen by expanding a sum and multiplying all the terms resulting in M&lt;sup&gt;N&lt;/sup&gt; items, a huge number. This is the number of combinations between all signals (N) and all models (M). This is the source of Combinatorial Complexity, which is solved in NMF by utilizing the idea of [[Perlovsky|dynamic logic]],.&lt;ref&gt;Perlovsky, L.I. (1996). Mathematical Concepts of Intellect. Proc. World Congress on Neural Networks, San Diego, CA; Lawrence Erlbaum Associates, NJ, pp.1013-16&lt;/ref&gt;&lt;ref&gt;Perlovsky, L.I.(1997). Physical Concepts of Intellect. Proc. Russian Academy of Sciences, 354(3), pp. 320-323.&lt;/ref&gt; An important aspect of dynamic logic is ''matching vagueness or fuzziness of similarity measures to the uncertainty of models''. Initially, parameter values are not known, and uncertainty of models is high; so is the fuzziness of the similarity measures. In the process of learning, models become more accurate, and the similarity measure more crisp, the value of the similarity increases. 

The maximization of similarity L is done as follows. First, the unknown parameters {'''S'''&lt;sub&gt;m&lt;/sub&gt;} are randomly initialized. Then the association variables f(m|n) are computed,

:&lt;math&gt; f(m|n) = \frac{r(m) l( \vec X(n|m)) }{ \sum_{m'=1}^M { r(m') l( \vec X(n|m')) } } &lt;/math&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; (3).

Equation for f(m|n) looks like the Bayes formula for a posteriori probabilities; if l(n|m) in the result of learning become conditional likelihoods, f(m|n) become Bayesian probabilities for signal n originating from object m. The dynamic logic of the NMF is defined as follows:

:&lt;math&gt; \frac{d \vec S_m }{dt} = \sum_{n=1}^N { f(m|n) \frac{\partial{\ln l(n|m)} }{\partial{\vec M_m} } \frac{\partial{\vec M_m}}{\partial{\vec S_m}} } &lt;/math&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; (4).

:&lt;math&gt; \frac{df(m|n)}{dt} = f(m|n)\sum_{m'=1}^M { [\delta_{mm'} - f(m'|n)] \frac{\partial{\ln l(n|m')}}{\partial{\vec M_{m'}}} } \frac{\partial{\vec M_{m'}}}{\partial{\vec S_{m'}}} \frac{d \vec S_{m'}}{dt} &lt;/math&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; (5)

The following theorem has been proved (Perlovsky 2001):

''Theorem''. Equations (3), (4), and (5) define a convergent dynamic NMF system with stationary states defined by max{S&lt;sub&gt;m&lt;/sub&gt;}L.

It follows that the stationary states of an MF system are the maximum similarity states.  When partial similarities are specified as probability density functions (pdf), or likelihoods, the stationary values of parameters {'''S'''&lt;sub&gt;m&lt;/sub&gt;} are asymptotically unbiased and efficient estimates of these parameters.&lt;ref&gt;Cramer, H. (1946). Mathematical Methods of Statistics, Princeton University Press, Princeton NJ.&lt;/ref&gt; The computational complexity of dynamic logic is linear in N. 

Practically, when solving the equations through successive iterations, f(m|n) can be recomputed at every iteration using (3), as opposed to incremental formula (5).

The proof of the above theorem contains a proof that similarity L increases at each iteration.  This has a psychological interpretation that the instinct for increasing knowledge is satisfied at each step, resulting in the positive emotions: NMF-dynamic logic system emotionally enjoys learning.

==Example of dynamic logic operations==
Finding patterns below noise can be an exceedingly complex problem. If an exact pattern shape is not known and depends on unknown parameters, these parameters should be found by fitting the pattern model to the data. However, when the locations and orientations of patterns are not known, it is not clear which subset of the data points should be selected for fitting. A standard approach for solving this kind of problem is multiple hypothesis testing (Singer et al. 1974). Since all combinations of subsets and models are exhaustively searched, this method faces the problem of combinatorial complexity. In the current example, noisy ‘smile’ and ‘frown’ patterns are sought. They are shown in Fig.1a without noise, and in Fig.1b with the noise, as actually measured. The true number of patterns is 3, which is not known. Therefore, at least 4 patterns should be fit to the data, to decide that 3 patterns fit best. The image size in this example is 100x100 = 10,000 points. If one attempts to fit 4 models to all subsets of 10,000 data points, computation of complexity, M&lt;sup&gt;N&lt;/sup&gt; ~ 10&lt;sup&gt;6000&lt;/sup&gt;. An alternative computation by searching through the parameter space, yields lower complexity: each pattern is characterized by a 3-parameter parabolic shape. Fitting 4x3=12 parameters to 100x100 grid by a brute-force testing would take about 10&lt;sup&gt;32&lt;/sup&gt; to 10&lt;sup&gt;40&lt;/sup&gt; operations, still a prohibitive computational complexity.
To apply NMF and dynamic logic to this problem one needs to develop parametric adaptive models of expected patterns. The models and conditional partial similarities for this case are described in details in:&lt;ref&gt;Linnehan, R., Mutz, Perlovsky, L.I., C., Weijers, B., Schindler, J., Brockett, R. (2003). Detection of Patterns Below Clutter in Images. Int. Conf. On Integration of Knowledge Intensive Multi-Agent Systems, Cambridge, MA Oct.1-3, 2003.&lt;/ref&gt; a uniform model for noise, Gaussian blobs for highly-fuzzy, poorly resolved patterns, and parabolic models for ‘smiles’ and ‘frowns’. The number of computer operations in this example was about 10&lt;sup&gt;10&lt;/sup&gt;. Thus, a problem that was not solvable due to combinatorial complexity becomes solvable using dynamic logic.

During an adaptation process, initially fuzzy and uncertain models are associated with structures in the input signals, and fuzzy models become more definite and crisp with successive iterations. The type, shape, and number, of models are selected so that the internal representation within the system is similar to input signals: the NMF concept-models represent structure-objects in the signals. The figure below illustrates operations of dynamic logic. In Fig. 1(a) true ‘smile’ and ‘frown’ patterns are shown without noise; (b) actual image available for recognition (signal is below noise, signal-to-noise ratio is between –2dB and –0.7dB); (c) an initial fuzzy model, a large fuzziness corresponds to uncertainty of knowledge; (d) through (m) show improved models at various iteration stages (total of 22 iterations). Every five iterations the algorithm tried to increase or decrease the number of models. Between iterations (d) and (e) the algorithm decided, that it needs three Gaussian models for the ‘best’ fit. 

There are several types of models: one uniform model describing noise (it is not shown) and a variable number of blob models and parabolic models; their number, location, and curvature are estimated from the data. Until about stage (g) the algorithm used simple blob models, at (g) and beyond, the algorithm decided that it needs more complex parabolic models to describe the data. Iterations stopped at (h), when similarity stopped increasing.

[[File:ExampleOfApplicationOfDynamicLogicToNoisyImage.JPG|center |frame| Fig.1. Finding ‘smile’ and ‘frown’ patterns in noise, an example of dynamic logic operation: (a) true ‘smile’ and ‘frown’ patterns are shown without noise; (b) actual image available for recognition (signal is below noise, signal-to-noise ratio is between –2dB and –0.7dB); (c) an initial fuzzy blob-model, the fuzziness corresponds to uncertainty of knowledge; (d) through (m) show improved models at various iteration stages (total of 22 iterations). Between stages (d) and (e) the algorithm tried to fit the data with more than one model and decided, that it needs three blob-models to ‘understand’ the content of the data. There are several types of models: one uniform model describing noise (it is not shown) and a variable number of blob-models and parabolic models, which number, location, and curvature are estimated from the data. Until about stage (g) the algorithm ‘thought’ in terms of simple blob models, at (g) and beyond, the algorithm decided that it needs more complex parabolic models to describe the data. Iterations stopped at (m), when similarity L stopped increasing. This example is discussed in more details in (Linnehan et al. 2003).]]

==Neural modeling fields hierarchical organization==
	
Above, a single processing level in a hierarchical NMF system was described. At each level of hierarchy there are input signals from lower levels, models, similarity measures (L), emotions, which are defined as changes in similarity, and actions; actions include adaptation, behavior satisfying the knowledge instinct – maximization of similarity. An input to each level is a set of signals '''X'''(n), or in neural terminology, an input field of neuronal activations. The result of signal processing at a given level are activated models, or concepts m recognized in the input signals n; these models along with the corresponding instinctual signals and emotions may activate behavioral models and generate behavior at this level.

The activated models initiate other actions. They serve as input signals to the next processing level, where more general concept-models are recognized or created. Output signals from a given level, serving as input to the next level, are the model activation signals, a&lt;sub&gt;m&lt;/sub&gt;, defined as

a&lt;sub&gt;m&lt;/sub&gt; =  ∑&lt;sub&gt;n=1..N&lt;/sub&gt; f(m|n).	

The hierarchical NMF system is illustrated in Fig. 2. Within the hierarchy of the mind, each concept-model finds its “mental” meaning and purpose at a higher level (in addition to other purposes). For example, consider a concept-model “chair.” It has a “behavioral” purpose of initiating sitting behavior (if sitting is required by the body), this is the “bodily” purpose at the same hierarchical level. In addition, it has a “purely mental” purpose at a higher level in the hierarchy, a purpose of helping to recognize a more general concept, say of a “concert hall,” a model of which contains rows of chairs. 

[[File:NMF Hierarchy.JPG|center |frame| Fig.2. Hierarchical NMF system. At each level of a hierarchy there are models, similarity measures, and actions (including adaptation, maximizing the knowledge instinct - similarity). High levels of partial similarity measures correspond to concepts recognized at a given level. Concept activations are output signals at this level and they become input signals to the next level, propagating knowledge up the hierarchy.]]

From time to time a system forms a new concept or eliminates an old one. At every level, the NMF system always keeps a reserve of vague (fuzzy) inactive concept-models. They are inactive in that their parameters are not adapted to the data; therefore their similarities to signals are low. Yet, because of a large vagueness (covariance) the similarities are not exactly zero. When a new signal does not fit well into any of the active models, its similarities to inactive models automatically increase (because first, every piece of data is accounted for, and second, inactive models are vague-fuzzy and potentially can “grab” every signal that does not fit into more specific, less fuzzy, active models. When the activation signal a&lt;sub&gt;m&lt;/sub&gt; for an inactive model, m, exceeds a certain threshold, the model is activated. Similarly, when an activation signal for a particular model falls below a threshold, the model is deactivated. Thresholds for activation and deactivation are set usually based on information existing at a higher hierarchical level (prior information, system resources, numbers of activated models of various types, etc.). Activation signals for active models at a particular level { a&lt;sub&gt;m&lt;/sub&gt; } form a “neuronal field,” which serve as input signals to the next level, where more abstract and more general concepts are formed.

==References==
{{Reflist}}

==Related==
* [[Leonid Perlovsky]]

[[Category:Artificial intelligence]]
[[Category:Machine learning]]</text>
      <sha1>62qk17o0go1vsfoxvo2e6q7f18h439b</sha1>
    </revision>
  </page>
  <page>
    <title>Semantic analysis (machine learning)</title>
    <ns>0</ns>
    <id>14271782</id>
    <revision>
      <id>1003131775</id>
      <parentid>985586069</parentid>
      <timestamp>2021-01-27T15:20:02Z</timestamp>
      <contributor>
        <username>BattyBot</username>
        <id>15996738</id>
      </contributor>
      <comment>Replaced [[Template:Unreferenced|{{unreferenced}}]] with [[Template:More citations needed|{{more citations needed}}]] and other [[WP:AWB/GF|General fixes]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1894" xml:space="preserve">{{other uses|Semantic analysis (disambiguation)}}
{{More citations needed|date=January 2021}}{{Semantics}}
In [[machine learning]], '''semantic analysis''' of a [[Text corpus|corpus]] is the task of building structures that approximate concepts from a large set of documents. It generally does not involve prior semantic understanding of the documents. A [[metalanguage]] based on [[predicate logic]] can analyze the speech of humans.&lt;ref name="IndurkhyaDamerau2010"&gt;{{cite book|author1=Nitin Indurkhya|author2=Fred J. Damerau|title=Handbook of Natural Language Processing|url=https://books.google.com/books?id=nK-QYHZ0-_gC|date=22 February 2010|publisher=CRC Press|isbn=978-1-4200-8593-8}}&lt;/ref&gt;{{rp|93-}} Another strategy to understand the semantics of a text is [[symbol grounding]]. If language is grounded, it is equal to recognizing a machine readable meaning. For the restricted domain of spatial analysis, a computer based language understanding system was demonstrated.&lt;ref name="Spranger2016"&gt;{{cite book|author=Michael Spranger|title=The evolution of grounded spatial language|url=https://books.google.com/books?id=z0VFDAAAQBAJ&amp;pg=PA123|date=15 June 2016|publisher=Language Science Press|isbn=978-3-946234-14-2}}&lt;/ref&gt;{{rp|123}}

[[Latent semantic analysis]] (sometimes latent semantic indexing), is a class of techniques where documents are represented as [[linear algebra|vectors]] in term space. A prominent example is [[Probabilistic latent semantic indexing|PLSI]].

[[Latent Dirichlet allocation]] involves attributing document terms to topics.

[[n-gram]]s and [[hidden Markov models]] work by representing the term stream as a [[markov chain]] where each term is derived from the few terms before it.

== See also ==
* [[Information extraction]]
* [[Semantic similarity]]
* [[Ontology learning]]

== References ==
{{reflist}}

[[Category:Machine learning]]


{{Compsci-stub}}</text>
      <sha1>kphwkykxjcnkqwnl6qdafug59gis2lr</sha1>
    </revision>
  </page>
  <page>
    <title>Algorithmic inference</title>
    <ns>0</ns>
    <id>20890511</id>
    <revision>
      <id>959019571</id>
      <parentid>929030828</parentid>
      <timestamp>2020-05-26T19:38:19Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <comment>Alter: url. | You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | Activated by AManWithNoPlan | All pages linked from [[User:AManWithNoPlan/sandbox2]] | via #UCB_webform_linked</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="17662" xml:space="preserve">'''Algorithmic inference''' gathers new developments in the [[statistical inference]] methods made feasible by the powerful computing devices widely available to any data analyst. Cornerstones in this field are [[computational learning theory]], [[granular computing]], [[bioinformatics]], and, long ago, structural probability {{harv|Fraser|1966}}.
The main focus is on the algorithms which compute statistics rooting the study of a random phenomenon, along with the amount of data they must feed on to produce reliable results. This shifts the interest of mathematicians from the study of the [[probability distribution|distribution laws]] to the functional properties of the [[statistics]], and the interest of computer scientists from the algorithms for processing data to the [[information]] they process.

== The Fisher parametric inference problem ==
Concerning the identification of the parameters of a distribution law, the mature reader may recall lengthy disputes in the mid 20th century about the interpretation of their variability in terms of [[fiducial distribution]] {{harv|Fisher|1956}}, structural probabilities {{harv|Fraser|1966}}, priors/posteriors {{harv|Ramsey|1925}}, and so on. From an [[epistemologic|epistemology]] viewpoint, this entailed a companion dispute as to the nature of [[probability]]: is it a physical feature of phenomena to be described through [[random variables]] or a way of synthesizing data about a phenomenon? Opting for the latter, Fisher defines a ''fiducial distribution'' law of parameters of a given random variable that he deduces from a sample of its specifications. With this law he computes, for instance “the probability that μ (mean of a [[Normal distribution|Gaussian variable]] – our note) is less than any assigned value, or the probability that it lies between any assigned values, or, in short, its probability distribution, in the light of the sample observed”.

== The classic solution ==
Fisher fought hard to defend the difference and superiority of his notion of parameter distribution in comparison to 
analogous notions, such as  Bayes' [[posterior distribution]], Fraser's constructive probability and Neyman's [[confidence intervals]]. For half a century, Neyman's confidence intervals  won out for all practical purposes, crediting the phenomenological nature of probability. With this perspective, when you deal with a Gaussian variable, its mean μ is fixed by the physical features of the phenomenon you are observing, where the observations are random operators, hence the observed values are specifications of a [[random sample]]. Because of their randomness, you may compute from the sample specific intervals containing the fixed μ with a given probability that you denote ''confidence''.

=== Example ===
Let ''X'' be a Gaussian variable&lt;ref&gt;By default, capital letters (such as ''U'', ''X'') will denote random variables and small letters (''u'', ''x'') their corresponding specifications.&lt;/ref&gt; with parameters &lt;math&gt;\mu&lt;/math&gt; and &lt;math&gt;\sigma^2&lt;/math&gt; 
and &lt;math&gt;\{X_1,\ldots,X_m\}&lt;/math&gt; a sample drawn from it. Working with statistics

: &lt;math&gt;S_\mu =\sum_{i=1}^m X_i&lt;/math&gt;

and

: &lt;math&gt;S_{\sigma^2}=\sum_{i=1}^m (X_i-\overline X)^2,\text{ where }\overline X = \frac{S_{\mu}}{m} &lt;/math&gt;

is the sample mean, we recognize that

: &lt;math&gt;T=\frac{S_{\mu}-m\mu}{\sqrt{S_{\sigma^2}}}\sqrt\frac{m-1}{m}=\frac{\overline X-\mu}{\sqrt{S_{\sigma^2}/(m(m-1))}}&lt;/math&gt;

follows a [[Student's t distribution]] {{harv|Wilks|1962}} with parameter (degrees of freedom) ''m''&amp;nbsp;−&amp;nbsp;1, so that

: &lt;math&gt;f_T(t)=\frac{\Gamma(m/2)}{\Gamma((m-1)/2)}\frac{1}{\sqrt{\pi(m-1)}}\left(1 + \frac{t^2}{m-1}\right)^{m/2}.&lt;/math&gt;

Gauging ''T'' between two quantiles and inverting its expression as a function of &lt;math&gt;\mu&lt;/math&gt; you obtain confidence intervals for &lt;math&gt;\mu&lt;/math&gt;.

With the  sample specification:

:&lt;math&gt;\mathbf x=\{7.14, 6.3, 3.9, 6.46, 0.2, 2.94, 4.14, 4.69, 6.02, 1.58\}&lt;/math&gt;

having size ''m'' = 10, you compute the  statistics &lt;math&gt;s_\mu = 43.37&lt;/math&gt; and &lt;math&gt;s_{\sigma^2}=46.07&lt;/math&gt;, and obtain a 0.90 confidence interval for &lt;math&gt;\mu&lt;/math&gt; with extremes (3.03,&amp;nbsp;5.65).
{{clear}}

== Inferring functions with the help of a computer ==
From a modeling perspective the entire dispute looks like a chicken-egg dilemma: either fixed data by first and probability distribution of their properties as a consequence, or fixed properties by first and probability distribution of the observed data as a corollary.
The classic solution has one benefit and one drawback. The former was appreciated particularly back  when people still did computations with  sheet and pencil. Per se, the task of computing a Neyman  confidence interval for the fixed parameter θ is hard: you don’t know θ, but you look for disposing around it an interval with a possibly very low probability of failing. The analytical solution is allowed for a very limited number of theoretical cases.  ''Vice versa'' a large variety of instances may be quickly solved in an ''approximate way'' via the [[central limit theorem]] in terms of confidence interval around a Gaussian distribution – that's the benefit. 
The drawback is that the central limit theorem is applicable when the sample size is sufficiently large. Therefore, it is less and less applicable with the sample involved in modern inference instances. The fault is not in the sample size on its own part. Rather, this size is not sufficiently large because of the [[complexity]] of the inference problem.

With the availability of large computing facilities,  scientists refocused from isolated parameters inference to complex functions inference, i.e. re sets of highly nested parameters identifying functions. In these cases we speak about ''learning of functions'' (in terms for instance of [[regression analysis|regression]], [[Neuro-fuzzy|neuro-fuzzy system]] or [[computational learning theory|computational learning]]) on the basis of highly informative samples. A first effect of having a complex structure linking data is the reduction of the number of sample [[Degrees of freedom (statistics)|degrees of freedom]], i.e. the burning of a part of sample points, so that the effective sample size to be considered in the central limit theorem is too small. Focusing  on the sample size ensuring a limited learning error with a given [[confidence level]], the consequence is that the  lower bound on this size grows with [[complexity index|complexity indices]] such as [[VC dimension]] or [[Complexity index#Detail|detail of a class]] to which the function we want to learn belongs.

=== Example ===
A sample of 1,000 independent bits is enough to ensure an absolute error of at most 0.081 on the estimation of the parameter ''p'' of the underlying Bernoulli variable with a confidence of at least 0.99. The same size cannot guarantee a threshold less than 0.088 with the same confidence 0.99 when the error is identified with the probability that a 20-year-old man living in New York does not fit the ranges of height, weight and waistline observed on 1,000 Big Apple inhabitants. The accuracy shortage occurs because both the VC dimension and the detail of the class of parallelepipeds, among which the one observed from the 1,000 inhabitants' ranges falls, are equal to 6.
{{clear}}

== The general inversion problem solving the Fisher question ==
With insufficiently large samples, the approach: ''fixed sample – random properties'' suggests inference procedures in three steps:
{|
|- valign="top" 
|{{Anchor|Sampling mechanism}}1. || '''Sampling mechanism'''. It consists of a pair &lt;math&gt;(Z, g_{\boldsymbol\theta})&lt;/math&gt;, where the seed ''Z'' is a random variable without unknown parameters, while the explaining function &lt;math&gt;g_{\boldsymbol\theta}&lt;/math&gt; is a function mapping from samples of ''Z'' to samples of the random variable ''X'' we are interested in. The parameter vector &lt;math&gt;\boldsymbol\theta&lt;/math&gt; is a specification of the random parameter &lt;math&gt;\mathbf\Theta&lt;/math&gt;. Its components  are  the parameters of the   ''X'' distribution law. The Integral Transform Theorem &lt;!-- {{harv|Mood|1962}} What's that? --&gt; ensures the existence of such a mechanism for each (scalar or vector) ''X'' when the seed coincides with the random variable ''U'' [[Uniform distribution (continuous)|uniformly]] distributed in &lt;math&gt;[0,1]&lt;/math&gt;. 
{|
|- valign="top" 
|{{Anchor|Pareto Example}}''Example. ''|| For ''X'' following a [[Pareto distribution]] with parameters ''a'' and ''k'', i.e.

:&lt;math&gt;F_X(x)=\left(1-\frac{k}{x}^a\right) I_{[k,\infty)}(x),&lt;/math&gt;

a sampling mechanism &lt;math&gt;(U, g_{(a,k)})&lt;/math&gt; for ''X'' with seed ''U''  reads:

:&lt;math&gt;g_{(a,k)}(u)=k (1-u)^{-\frac{1}{a}},&lt;/math&gt;  
or, equivalently, &lt;math&gt; g_{(a,k)}(u)=k u^{-1/a}. &lt;/math&gt;
|}
|- valign="top" 
| {{Anchor|Master equation}}2. || '''Master equations'''. The actual connection between the model and the observed data is tossed in terms of a set of relations between statistics on the data and unknown parameters that come as a corollary of the sampling mechanisms. We call these relations ''master equations''. Pivoting around the statistic &lt;math&gt;s=h(x_1,\ldots,x_m)= h(g_{\boldsymbol\theta}(z_1),\ldots, g_{\boldsymbol\theta}(z_m))&lt;/math&gt;, the general form of a master equation is:

:&lt;math&gt;s= \rho(\boldsymbol\theta;z_1,\ldots,z_m)&lt;/math&gt;.

With these relations we may inspect the values of the parameters that could have generated a sample with the observed statistic from a particular setting of the seeds representing the seed of the sample. Hence, to the population of sample seeds corresponds a population of parameters. In order to ensure this population clean properties, it is enough to draw randomly the seed values and involve either [[sufficient statistics]] or, simply,  [[well-behaved statistic]]s  w.r.t. the parameters, in the master equations.

For example, the statistics &lt;math&gt;s_1=\sum_{i=1}^m \log x_i&lt;/math&gt; and &lt;math&gt;s_2=\min_{i=1,\ldots,m} \{x_i\}&lt;/math&gt; prove to be sufficient for parameters ''a'' and ''k'' of a Pareto random variable ''X''. Thanks to the (equivalent form of the) sampling mechanism &lt;math&gt;g_{(a,k)}&lt;/math&gt; we may read them as
:&lt;math&gt;s_1=m\log k+1/a \sum_{i=1}^m \log u_i&lt;/math&gt;
:&lt;math&gt;s_2=\min_{i=1,\ldots,m} \{k u_i^{-\frac{1}{a}}\},&lt;/math&gt;
respectively.
|- valign="top" 
| 3. || '''Parameter population'''. Having fixed a set of master equations, you may map sample seeds into parameters either numerically through a [[bootstrapping populations|population bootstrap]], or analytically through a [[Twisting properties#twisting argument|twisting argument]]. Hence from a population of seeds you obtain a population of parameters.

{|
|- valign="top"
|''Example. '' || From the above master equation we can draw a pair  of parameters, &lt;math&gt;( a, k)&lt;/math&gt;, ''compatible'' with the observed sample by solving the following system of equations:

:&lt;math&gt; a=\frac{\sum\log u_i-m\log \min \{u_i\}}{s_1-m\log s_2}.&lt;/math&gt;
:&lt;math&gt; k=\mathrm e^{\frac{ a s_1-\sum\log u_i}{m a}}&lt;/math&gt;

where &lt;math&gt;s_1&lt;/math&gt; and &lt;math&gt;s_2&lt;/math&gt; are the observed statistics and &lt;math&gt;u_1,\ldots,u_m&lt;/math&gt; a set of uniform seeds. Transferring to the parameters the probability (density) affecting the seeds,  you obtain the distribution law of the random  parameters ''A'' and ''K'' compatible with the statistics you have observed.
|}
Compatibility denotes parameters of compatible populations, i.e. of populations that ''could have generated'' a sample giving rise to the observed statistics. You may formalize this notion as follows:
|}

===Definition===
For a random variable and a sample drawn from it a {{Anchor|compatible distribution}}''compatible distribution'' is a distribution having the same [[Algorithmic inference#Sampling mechanism|sampling mechanism]] &lt;math&gt;\mathcal M_X=(Z,g_{\boldsymbol\theta})&lt;/math&gt; of ''X'' with a value &lt;math&gt;\boldsymbol\theta&lt;/math&gt; of the random parameter &lt;math&gt;\mathbf\Theta&lt;/math&gt; derived from a master equation rooted on a well-behaved statistic ''s''.

=== Example ===
[[Image:Parecdf.png|frame|left|90px|Joint empirical cumulative distribution function of parameters &lt;math&gt;(A,K)&lt;/math&gt; of a Pareto random variable.]][[Image:Mucdf.png|frame|right|90px|Cumulative distribution function of the mean ''M'' of a Gaussian random variable]]You may find the distribution law of the Pareto parameters ''A''&amp;nbsp;and ''K''&amp;nbsp;as an implementation example of the [[bootstrapping populations|population bootstrap]]&amp;nbsp;method as in the figure on the left.

Implementing the [[Twisting properties#twisting argument|twisting argument]]&amp;nbsp;method,  you get the distribution  law &lt;math&gt;F_M(\mu)&lt;/math&gt;&amp;nbsp;of the mean  ''M''&amp;nbsp;of a Gaussian variable ''X''&amp;nbsp;on the basis of the statistic &lt;math&gt;s_M=\sum_{i=1}^m x_i&lt;/math&gt;&amp;nbsp;when &lt;math&gt;\Sigma^2&lt;/math&gt;&amp;nbsp;is known to be equal to &lt;math&gt;\sigma^2&lt;/math&gt;&amp;nbsp;{{harv|Apolloni|Malchiodi|Gaito|2006}}. Its expression is:

:&lt;math&gt;F_M(\mu)=\Phi\left(\frac{m\mu-s_M}{\sigma\sqrt{m}}\right), &lt;/math&gt;

shown in the figure on the right, where &lt;math&gt;\Phi&lt;/math&gt; is the [[cumulative distribution function]] of  a [[standard normal distribution]].
 
[[Image:Muconfint.png|frame|90px|left|Upper (purple curve) and lower (blue curve) extremes of a 90% confidence interval of the mean ''M'' of a Gaussian random variable for a fixed &lt;math&gt;\sigma&lt;/math&gt; and different values of the statistic ''s''&lt;sub&gt;''m''&lt;/sub&gt;.]] Computing a [[confidence interval]]&amp;nbsp;for ''M''&amp;nbsp;given its distribution function is straightforward: we need only find two quantiles (for instance &lt;math&gt;\delta/2&lt;/math&gt;&amp;nbsp;and &lt;math&gt;1-\delta/2&lt;/math&gt;&amp;nbsp;quantiles in case we are interested in a confidence interval of level δ symmetric in the tail's probabilities) as indicated  on the left in the diagram showing the behavior of the two bounds for different values of the statistic ''s''&lt;sub&gt;''m''&lt;/sub&gt;.

The Achilles heel of Fisher's approach lies in the joint distribution of more than one parameter, say mean and variance of a Gaussian distribution. On the contrary, with the last approach (and  above-mentioned methods: [[bootstrapping populations|population bootstrap]] and [[Twisting properties#twisting argument|twisting argument]]) we may learn the joint distribution of many parameters. For instance, focusing on the distribution of two or many more parameters, in the figures below we report two confidence regions where the function to be learnt falls with a confidence of 90%. The former concerns the probability with which an extended [[support vector machine]] attributes a binary label 1 to the points of the &lt;math&gt;(x,y)&lt;/math&gt; plane. The two surfaces are drawn on the basis of a set of sample points in turn labelled according to a specific distribution law {{harv|Apolloni|Bassis|Malchiodi|Witold|2008}}. The latter concerns the confidence region of the hazard rate of breast cancer recurrence computed from a censored sample {{harv|Apolloni|Malchiodi|Gaito|2006}}.
{|
| [[Image:Svmconf.png|frame|100px|90% confidence region for the family of support vector machines endowed with hyperbolic tangent profile function]]
| [[Image:Hazardconf.png|frame|100px|90% confidence region for the hazard function of breast cancer recurrence computed from the censored sample &lt;math&gt;t=(9, 13, &gt; 13, 18, 12, 23, 31, 34, &gt; 45, 48, &gt; 161),\, &lt;/math&gt;

with &gt;&amp;nbsp;''t'' denoting a censored time]]
|}

&lt;!--Referenze

Fraser, D.A.S.: Statistics. An Introduction. John Wiley &amp; Sons, London (1958)
Fisher, M.A.: The fiducial argument in statistical inference. Annals of Eugenics 6
(1935) 391–398
Vapnick
Valiant
M. Blanchette, T. Kunisaewa, D. Sankoff Parametric genome rearrangement, Gene 172 (1996) GC 11–17 Elsevier
L: Birkedal, M. Tofte, A constraint-based region inference algorithm --&gt;

== Notes ==

&lt;references /&gt;

{{more footnotes|date=July 2011}}

== References ==

*{{Citation
 | last = Fraser | first = D. A. S.
 | year = 1966
 | title = Structural probability and generalization
 | journal = Biometrika
 | volume = 53
 | issue = 1/2
 | pages = 1–9
 | ref = harv
 | postscript = .
 | doi=10.2307/2334048
| jstor = 2334048
 }}
*{{Citation
 | last=Fisher |first=M. A. 
 | title=Statistical Methods and Scientific Inference
 | publisher=Oliver and Boyd
 | location=Edinburgh and London
 | year=1956
 | ref=harv
 | url=https://psycnet.apa.org/record/1957-00078-000
}}
*{{Citation
 | last1=Apolloni |first1=B.
 | last2=Malchiodi | first2=D.
 | last3=Gaito | first3=S.
 | title=Algorithmic Inference in Machine Learning
 | publisher=Magill
 | series=International Series on Advanced Intelligence
 | location=Adelaide
 | volume=5
 | quote=Advanced Knowledge International
 | edition=2nd 
 | year=2006
 | ref=harv
}}
*{{Citation
 | last1=Apolloni |first1=B.
 | last2=Bassis | first2=S.
 | last3=Malchiodi | first3=D.
 | last4=Witold | first4=P.
 | title=The Puzzle of Granular Computing
 | publisher=Springer
 | series=Studies in Computational Intelligence
 | location=Berlin
 | volume=138
 | year=2008
 | ref=harv
 | url=https://books.google.com/books?id=2PkW8Z8cANEC&amp;printsec=frontcover&amp;dq=%22Algorithmic+inference%22#v=onepage
|isbn=9783540798637
 }}
*{{Citation
 | last= Ramsey |first= F. P. 
 | title= The Foundations of Mathematics
 | year= 1925
 | journal=Proceedings of the London Mathematical Society 
 |pages= 338–384 
 | ref=harv
 | postscript= .
 | doi=10.1112/plms/s2-25.1.338
}}
*{{Citation
 | last=Wilks |first=S.S.
 | title=Mathematical Statistics
 | series=Wiley Publications in Statistics
 | publisher=John Wiley
 | location=New York
 | year=1962
 | ref=harv
}}

[[Category:Algorithmic inference| ]]
[[Category:Machine learning]]</text>
      <sha1>b5z9i5msh9z2q63xsfq5fospyl6qjq8</sha1>
    </revision>
  </page>
  <page>
    <title>Decision list</title>
    <ns>0</ns>
    <id>19317802</id>
    <revision>
      <id>984677251</id>
      <parentid>923327025</parentid>
      <timestamp>2020-10-21T13:02:22Z</timestamp>
      <contributor>
        <username>Frap</username>
        <id>612852</id>
      </contributor>
      <comment>/* Definition */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2192" xml:space="preserve">'''Decision lists''' are a representation for Boolean functions which can be easily learnable from examples.&lt;ref&gt;{{cite journal|author=Ronald L. Rivest|authorlink=Ronald L. Rivest|title=Learning decision lists|journal=Machine Learning|volume=2|issue=3|pages=229–246|date=Nov 1987|doi=10.1023/A:1022607331053|url=http://people.csail.mit.edu/rivest/pubs/Riv87b.pdf}}&lt;/ref&gt;  Single term decision lists are more expressive than [[Logical disjunction|disjunctions]] and [[Logical_conjunction|conjunctions]]; however, 1-term decision lists are less expressive than the general [[disjunctive normal form]] and the [[conjunctive normal form]].

The language specified by a k-length decision list includes as a subset the language specified by a k-depth [[decision tree]].

Learning decision lists can be used for [[attribute efficient learning]].&lt;ref&gt;Adam R. Klivans and Rocco A. Servedio, "Toward Attribute Efficient Learning of Decision Lists and Parities", ''Journal of Machine Learning Research'' '''7''':12:587-602 [http://dl.acm.org/citation.cfm?id=1248567&amp;dl=ACM&amp;coll=DL&amp;CFID=344844478&amp;CFTOKEN=13074001 ACM Digital Library] [http://www.jmlr.org/papers/volume7/klivans06a/klivans06a.pdf full text]&lt;/ref&gt;

== Definition ==

A decision list (DL) of length {{mvar|r}} is of the form:

 '''if''' {{math|''f''&lt;sub&gt;1&lt;/sub&gt;}} '''then''' 
     output {{math|''b''&lt;sub&gt;1&lt;/sub&gt;}}
 '''else if''' {{math|''f''&lt;sub&gt;2&lt;/sub&gt;}} '''then'''
     output {{math|''b''&lt;sub&gt;2&lt;/sub&gt;}}
 ...
 '''else if''' {{mvar|f&lt;sub&gt;r&lt;/sub&gt;}} '''then'''
     output {{mvar|b&lt;sub&gt;r&lt;/sub&gt;}}

where {{mvar|f&lt;sub&gt;i&lt;/sub&gt;}} is the {{mvar|i}}th formula and {{mvar|b&lt;sub&gt;i&lt;/sub&gt;}} is the {{mvar|i}}th [[Boolean data type|boolean]] for &lt;math&gt;i \in \{1...r\}&lt;/math&gt;.  The last if-then-else is the default case, which means formula {{mvar|f&lt;sub&gt;r&lt;/sub&gt;}} is always equal to true. A {{mvar|k}}-DL is a decision list where all of formulas have at most {{mvar|k}} terms.  Sometimes "decision list" is used to refer to a 1-DL, where all of the formulas are either a variable or its [[negation]].

== See also ==
* [[Decision stump]]

==References==
&lt;references/&gt;

[[Category:Artificial intelligence]]
[[Category:Machine learning]]


{{AI-stub}}</text>
      <sha1>11s6rwthcj7ktfwpf3ba3klp56c03aq</sha1>
    </revision>
  </page>
  <page>
    <title>Rule induction</title>
    <ns>0</ns>
    <id>7517319</id>
    <revision>
      <id>1000107163</id>
      <parentid>975022378</parentid>
      <timestamp>2021-01-13T16:33:40Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 4 templates: hyphenate params (1×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3313" xml:space="preserve">[[File:Decision Tree.jpg|thumb|Decision Tree]]
'''Rule induction''' is an area of [[machine learning]] in which formal rules are extracted from a set of observations.  The rules extracted may represent a full [[scientific model]] of the data, or merely represent local [[patterns]] in the data.

[[Data mining]] in general and rule induction in detail are trying to create algorithms without human programming but with analyzing existing data structures.&lt;ref name="TriantaphyllouFelici2006"&gt;{{cite book|author1=Evangelos Triantaphyllou|author2=Giovanni Felici|title=Data Mining and Knowledge Discovery Approaches Based on Rule Induction Techniques|url=https://books.google.com/books?id=AYJGAAAAQBAJ&amp;pg=PA415|date=10 September 2006|publisher=Springer Science &amp; Business Media|isbn=978-0-387-34296-2}}&lt;/ref&gt;{{rp|415-}} In the easiest case, a rule is expressed with “if-then statements” and was created with the [[ID3 algorithm]] for decision tree learning.&lt;ref name="Freitas2013"&gt;{{cite book|author=Alex A. Freitas|title=Data Mining and Knowledge Discovery with Evolutionary Algorithms|url=https://books.google.com/books?id=0empCAAAQBAJ|date=11 November 2013|publisher=Springer Science &amp; Business Media|isbn=978-3-662-04923-5}}&lt;/ref&gt;{{rp|7}}&lt;ref name=TriantaphyllouFelici2006 /&gt;{{rp|348}} Rule learning algorithm are taking training data as input and creating rules by partitioning the table with [[cluster analysis]].&lt;ref name=Freitas2013 /&gt;{{rp|7}} A possible alternative over the ID3 algorithm is genetic programming which evolves a program until it fits to the data.&lt;ref name="PappaFreitas2009"&gt;{{cite book|author1=Gisele L. Pappa|author2=Alex Freitas|title=Automating the Design of Data Mining Algorithms: An Evolutionary Computation Approach|url=https://books.google.com/books?id=nWJHAAAAQBAJ&amp;pg=PA126|date=27 October 2009|publisher=Springer Science &amp; Business Media|isbn=978-3-642-02541-9}}&lt;/ref&gt;{{rp|2}}

Creating different algorithm and testing them with input data can be realized in the WEKA software.&lt;ref name=PappaFreitas2009 /&gt;{{rp|125}} Additional tools are machine learning libraries for Python like scikit-learn.

== Paradigms ==

Some major rule induction paradigms are:
*[[Association rule learning]] algorithms (e.g., Agrawal)
*[[Decision rules|Decision rule]] algorithms (e.g., Quinlan 1987)
*[[Hypothesis testing]] algorithms (e.g., RULEX)
*[[Horn clause]] induction
*[[Version spaces]]
*[[Rough set]] rules
*[[Inductive Logic Programming]]
*Boolean decomposition (Feldman)

== Algorithms ==

Some rule induction algorithms are:
*Charade&lt;ref&gt;Sahami, Mehran. "[https://pdfs.semanticscholar.org/9039/68adbb73916120b67d8098e5df95a0166eb6.pdf Learning classification rules using lattices]." Machine learning: ECML-95 (1995): 343-346.&lt;/ref&gt;
*Rulex
*[[PROGOL|Progol]]
*[[CN2 algorithm | CN2]]

== References ==
&lt;references /&gt;
*{{cite conference
  | first = J. R.
  | last = Quinlan
  | title = Generating production rules from decision trees
  | book-title = Proceedings of the Tenth International Joint Conference on Artificial Intelligence (IJCAI-87)
  | pages = 304–307
  | date = 1987
  | location = Milan, Italy
  | editor = McDermott, John
  | url = http://www.ijcai.org/Proceedings/87-1/Papers/063.pdf}}

[[Category:Machine learning]]
[[Category:Inductive reasoning]]

{{Comp-sci-stub}}</text>
      <sha1>d796wipfqzvpgifzijoryh3m16aw4wm</sha1>
    </revision>
  </page>
  <page>
    <title>Instance-based learning</title>
    <ns>0</ns>
    <id>22589574</id>
    <revision>
      <id>962636761</id>
      <parentid>962636624</parentid>
      <timestamp>2020-06-15T06:01:08Z</timestamp>
      <contributor>
        <username>Edchi</username>
        <id>1519833</id>
      </contributor>
      <comment>Meant to only delete one pgraph.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2417" xml:space="preserve">In [[machine learning]], '''instance-based learning''' (sometimes called '''memory-based learning'''&lt;ref&gt;{{cite book |author1=Walter Daelemans |authorlink1=Walter Daelemans |author2=Antal van den Bosch |authorlink2=Antal van den Bosch |year=2005 |title=Memory-Based Language Processing |publisher=Cambridge University Press}}&lt;/ref&gt;) is a family of learning algorithms that, instead of performing explicit generalization, compares new problem instances with instances seen in training, which have been stored in memory.

It is called instance-based because it constructs hypotheses directly from the training instances themselves.&lt;ref name='aima733'&gt;[[Stuart J. Russell|Stuart Russell]] and [[Peter Norvig]] (2003). ''[[Artificial Intelligence: A Modern Approach]]'', second edition, p. 733. Prentice Hall. {{ISBN|0-13-080302-2}}&lt;/ref&gt;
This means that the hypothesis complexity can grow with the data:&lt;ref name='aima733'/&gt; in the worst case, a hypothesis is a list of ''n'' training items and the computational complexity of [[Classification (machine learning)|classifying]] a single new instance is [[Big O notation|''O'']](''n''). One advantage that instance-based learning has over other methods of machine learning is its ability to adapt its model to previously unseen data. Instance-based learners may simply store a new instance or throw an old instance away.

Examples of instance-based learning algorithm are the [[k-nearest neighbors algorithm|''k''-nearest neighbors algorithm]], [[kernel method|kernel machines]] and [[Radial basis function network|RBF networks]].&lt;ref&gt;{{cite book |author=Tom Mitchell |title=Machine Learning |year=1997 |publisher=McGraw-Hill}}&lt;/ref&gt;{{rp|ch. 8}} These store (a subset of) their training set; when predicting a value/class for a new instance, they compute distances or similarities between this instance and the training instances to make a decision.

To battle the memory complexity of storing all training instances, as well as the risk of [[overfitting]] to noise in the training set, ''instance reduction'' algorithms have been proposed.&lt;ref&gt;{{cite journal |title=Reduction techniques for instance-based learning algorithms |author1=D. Randall Wilson |author2=Tony R. Martinez |journal=[[Machine Learning (journal)|Machine Learning]] |year=2000}}&lt;/ref&gt;


==See also==
*[[Analogical modeling]]

==References==
{{reflist|30em}}

[[Category:Machine learning]]

{{AI-stub}}</text>
      <sha1>7bvf1p5ljsojc8z3b87xuam5ryen1e0</sha1>
    </revision>
  </page>
  <page>
    <title>Overfitting</title>
    <ns>0</ns>
    <id>173332</id>
    <revision>
      <id>998424321</id>
      <parentid>998339910</parentid>
      <timestamp>2021-01-05T09:12:39Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 13 templates: hyphenate params (2×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="19522" xml:space="preserve">{{short description|Analysis that corresponds too closely to a particular set of data and may fail to fit additional data}}
{{Refimprove|date=August 2017}}

[[Image:Overfitting.svg|thumb|300px|Figure 1.&amp;nbsp; The green line represents an overfitted model and the black line represents a regularized model. While the green line best follows the training data, it is too dependent on that data and it is likely to have a higher error rate on new unseen data, compared to the black line.]]
[[Image:Overfitted Data.png|thumb|300px|Figure 2.&amp;nbsp; Noisy (roughly linear) data is fitted to a linear function and a [[polynomial]] function. Although the polynomial function is a perfect fit, the linear function can be expected to generalize better: if the two functions were used to extrapolate beyond the fitted data, the linear function should make better predictions.]]
[[Image:Parabola_on_line.png|thumb|300px|Figure 3.&amp;nbsp; The blue dashed line represents an underfitted model. A straight line can never fit a parabola. This model is too simple.]]

In statistics, '''overfitting''' is "the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit additional data or predict future observations reliably".&lt;ref&gt;Definition of "[https://en.oxforddictionaries.com/definition/overfitting overfitting]" at [[OxfordDictionaries.com]]: this definition is specifically for statistics.&lt;/ref&gt; An '''overfitted model''' is a [[statistical model]] that contains more [[parameter]]s than can be justified by the data.&lt;ref name=CDS/&gt; The essence of overfitting is to have unknowingly extracted some of the residual variation (i.e. the [[Statistical noise|noise]]) as if that variation represented underlying model structure.&lt;ref name="BA2002" /&gt;{{rp|45}}

In other words, the model remembers a huge number of examples instead of learning to notice features.

'''Underfitting''' occurs when a statistical model cannot adequately capture the underlying structure of the data. An '''under-fitted model''' is a model where some parameters or terms that would appear in a correctly specified model are missing.&lt;ref name=CDS/&gt; Under-fitting would occur, for example, when fitting a linear model to non-linear data. Such a model will tend to have poor predictive performance.

Over-fitting and under-fitting can occur in [[machine learning]], in particular. In machine learning, the phenomena are sometimes called "over-training" and "under-training". 

The possibility of over-fitting exists because the criterion used for [[model selection|selecting the model]] is not the same as the criterion used to judge the suitability of a model. For example, a model might be selected by maximizing its performance on some set of [[training data]], and yet its suitability might be determined by its ability to perform well on unseen data; then over-fitting occurs when a model begins to "memorize" training data rather than "learning" to generalize from a trend. 

As an extreme example, if the number of parameters is the same as or greater than the number of observations, then a model can perfectly predict the training data simply by memorizing the data in its entirety. (For an illustration, see Figure&amp;nbsp;2.) Such a model, though, will typically fail severely when making predictions. 

The potential for overfitting depends not only on the number of parameters and data but also the conformability of the model structure with the data shape, and the magnitude of model error compared to the expected level of noise or error in the data.{{Citation needed|date=September 2017}} Even when the fitted model does not have an excessive number of parameters, it is to be expected that the fitted relationship will appear to perform less well on a new data set than on the data set used for fitting (a phenomenon sometimes known as ''shrinkage'').&lt;ref name="CDS"&gt;Everitt B.S., Skrondal A. (2010), ''Cambridge Dictionary of Statistics'', [[Cambridge University Press]].&lt;/ref&gt; In particular, the value of the [[coefficient of determination]] will [[Shrinkage (statistics)|shrink]] relative to the original data.

To lessen the chance of, or amount of, overfitting, several techniques are available (e.g. [[Model selection|model comparison]], [[cross-validation (statistics)|cross-validation]], [[regularization (mathematics)|regularization]], [[early stopping]], [[pruning (algorithm)|pruning]], [[Prior distribution|Bayesian priors]], or [[Dropout (neural networks)|dropout]]). The basis of some techniques is either (1) to explicitly penalize overly complex models or (2) to test the model's ability to generalize by evaluating its performance on a set of data not used for training, which is assumed to approximate the typical unseen data that a model will encounter.

==Statistical inference==
{{expand section|date=October 2017}}
In statistics, an [[Statistical inference|inference]] is drawn from a [[statistical model]], which has been [[model selection|selected]] via some procedure. Burnham&amp;nbsp;&amp; Anderson, in their much-cited text on model selection, argue that to avoid overfitting, we should adhere to the "[[Principle of Parsimony]]".&lt;ref name="BA2002"&gt;{{Citation |last1=Burnham |first1=K. P. |last2=Anderson |first2=D. R. |year=2002 |title=Model Selection and Multimodel Inference |edition=2nd |publisher=Springer-Verlag }}.&lt;/ref&gt; The authors also state the following.&lt;ref name="BA2002" /&gt;{{rp|32–33}}
{{quote|text= Overfitted models &amp;hellip; are often free of bias in the parameter estimators, but have estimated (and actual) sampling variances that are needlessly large (the precision of the estimators is poor, relative to what could have been accomplished with a more parsimonious model). False treatment effects tend to be identified, and false variables are included with overfitted models. &amp;hellip; A best approximating model is achieved by properly balancing the errors of underfitting and overfitting.}}

Overfitting is more likely to be a serious concern when there is little theory available to guide the analysis, in part because then there tend to be a large number of models to select from. The book ''Model Selection and Model Averaging'' (2008) puts it this way.&lt;ref&gt;{{citation|last1=Claeskens|first1=G.|author1-link= Gerda Claeskens |author-link2=Nils Lid Hjort|last2=Hjort|first2=N.L.|year=2008|title=Model Selection and Model Averaging|publisher=[[Cambridge University Press]]}}.&lt;/ref&gt;
{{quote| text=Given a data set, you can fit thousands of models at the push of a button, but how do you choose the best? With so many candidate models, overfitting is a real danger. Is the monkey who typed Hamlet actually a good writer?}}

===Regression===
In [[regression analysis]], overfitting occurs frequently.&lt;ref name="RMS"&gt;{{citation| title= Regression Modeling Strategies | last= Harrell | first= F. E., Jr. | year= 2001 | publisher= Springer}}.&lt;/ref&gt; As an extreme example, if there are ''p'' variables in a [[linear regression]] with ''p'' data points, the fitted line can go exactly through every point.&lt;ref&gt;{{cite web
| url=http://www.ma.utexas.edu/users/mks/statmistakes/ovefitting.html
| title=Overfitting
| author=Martha K. Smith
| date=2014-06-13
| publisher=[[University of Texas at Austin]]
| access-date=2016-07-31}}&lt;/ref&gt; For [[logistic regression]] or Cox [[proportional hazards models]], there are a variety of rules of thumb (e.g. 5–9,&lt;ref name="Vittinghoff et al. (2007)"&gt;{{cite journal |first1=E. |last1=Vittinghoff |first2=C. E. |last2=McCulloch |year=2007 |title=Relaxing the Rule of Ten Events per Variable in Logistic and Cox Regression |journal=[[American Journal of Epidemiology]] |volume=165 |issue=6 |pages=710–718 |doi=10.1093/aje/kwk052 |pmid=17182981|doi-access=free }}&lt;/ref&gt; 10&lt;ref&gt;{{cite book
| title = Applied Regression Analysis 
| edition= 3rd 
| last1 = Draper
| first1 = Norman R.
| last2 = Smith
| first2 = Harry
| publisher = [[John Wiley &amp; Sons|Wiley]]
| year = 1998
| isbn = 978-0471170822}}&lt;/ref&gt; and 10–15&lt;ref&gt;{{cite web
| url = http://blog.minitab.com/blog/adventures-in-statistics/the-danger-of-overfitting-regression-models
| title = The Danger of Overfitting Regression Models
| author = Jim Frost
| date = 2015-09-03
| access-date = 2016-07-31}}&lt;/ref&gt; — the guideline of 10 observations per independent variable is known as the "[[one in ten rule]]"). In the process of regression model selection, the mean squared error of the random regression function can be split into random noise, approximation bias, and variance in the estimate of the regression function. The [[bias–variance tradeoff]] is often used to overcome overfit models.

With a large set of [[explanatory variable]]s that actually have no relation to the [[dependent variable]] being predicted, some variables will in general be falsely found to be [[statistically significant]] and the researcher may thus retain them in the model, thereby overfitting the model. This is known as [[Freedman's paradox]].

==Machine learning==
[[Image:Overfitting svg.svg|thumb|300px|Figure 4.  Overfitting/overtraining in supervised learning (e.g., [[neural network]]). Training error is shown in blue, validation error in red, both as a function of the number of training cycles. If the validation error increases(positive slope) while the training error steadily decreases(negative slope) then a situation of overfitting may have occurred. The best predictive and fitted model would be where the validation error has its global minimum.]]

Usually a learning [[algorithm]] is trained using some set of "training data": exemplary situations for which the desired output is known. The goal is that the algorithm will also perform well on predicting the output when fed "validation data" that was not encountered during its training.

Overfitting is the use of models or procedures that violate [[Occam's razor]], for example by including more adjustable parameters than are ultimately optimal, or by using a more complicated approach than is ultimately optimal. For an example where there are too many adjustable parameters, consider a dataset where training data for {{mvar|y}} can be adequately predicted by a linear function of two independent variables. Such a function requires only three parameters (the intercept and two slopes). Replacing this simple function with a new, more complex quadratic function, or with a new, more complex linear function on more than two independent variables, carries a risk: Occam's razor implies that any given complex function is ''a priori'' less probable than any given simple function. If the new, more complicated function is selected instead of the simple function, and if there was not a large enough gain in training-data fit to offset the complexity increase, then the new complex function "overfits" the data, and the complex overfitted function will likely perform worse than the simpler function on validation data outside the training dataset, even though the complex function performed as well, or perhaps even better, on the training dataset.&lt;ref name=hawkins&gt;{{cite journal | last1 = Hawkins | first1 = Douglas M | year = 2004 | title = The problem of overfitting | journal = [[Journal of Chemical Information and Modeling]] | volume = 44 | issue = 1| pages = 1–12 | doi = 10.1021/ci0342472 | pmid = 14741005 }}&lt;/ref&gt;

When comparing different types of models, complexity cannot be measured solely by counting how many parameters exist in each model; the expressivity of each parameter must be considered as well. For example, it is nontrivial to directly compare the complexity of a neural net (which can track curvilinear relationships) with {{mvar|m}} parameters to a regression model with {{mvar|n}} parameters.&lt;ref name=hawkins /&gt;

Overfitting is especially likely in cases where learning was performed too long or where training examples are rare, causing the learner to adjust to very specific random features of the training data that have no [[causal relation]] to the [[Function approximation|target function]]. In this process of overfitting, the performance on the training examples still increases while the performance on unseen data becomes worse.

As a simple example, consider a database of retail purchases that includes the item bought, the purchaser, and the date and time of purchase. It's easy to construct a model that will fit the training set perfectly by using the date and time of purchase to predict the other attributes, but this model will not generalize at all to new data, because those past times will never occur again.

Generally, a learning algorithm is said to overfit relative to a simpler one if it is more accurate in fitting known data (hindsight) but less accurate in predicting new data (foresight). One can intuitively understand overfitting from the fact that information from all past experience can be divided into two groups: information that is relevant for the future, and irrelevant information ("noise"). Everything else being equal, the more difficult a criterion is to predict (i.e., the higher its uncertainty), the more noise exists in past information that needs to be ignored. The problem is determining which part to ignore. A learning algorithm that can reduce the chance of fitting noise is called "[[Robustness (computer science)#Robust machine learning|robust]]."

===Consequences===
The most obvious consequence of overfitting is poor performance on the validation dataset. Other negative consequences include:&lt;ref name=hawkins /&gt;

* A function that is overfitted is likely to request more information about each item in the validation dataset than does the optimal function; gathering this additional unneeded data can be expensive or error-prone, especially if each individual piece of information must be gathered by human observation and manual data-entry.
* A more complex, overfitted function is likely to be less portable than a simple one. At one extreme, a one-variable linear regression is so portable that, if necessary, it could even be done by hand. At the other extreme are models that can be reproduced only by exactly duplicating the original modeler's entire setup, making reuse or scientific reproduction difficult.

===Remedy===
The optimal function usually needs verification on bigger or completely new datasets.  There are, however, methods like [[minimum spanning tree]] or [[life-time of correlation]] that applies the dependence between correlation coefficients and time-series (window width). Whenever the window width is big enough, the correlation coefficients are stable and don't depend on the window width size anymore. Therefore, a correlation matrix can be created by calculating a coefficient of correlation between investigated variables. This matrix can be represented topologically as a complex network where direct and indirect influences between variables are visualized.

==Underfitting==

Underfitting occurs when a statistical model or machine learning algorithm cannot adequately capture the underlying structure of the data. It occurs when the model or algorithm does not fit the data enough. Underfitting occurs if the model or algorithm shows low variance but high bias (to contrast the opposite, overfitting from high variance and low bias). It is often a result of an excessively simple model&lt;ref&gt;{{cite web|first=Eric|last=Cai|title=Machine Learning Lesson of the Day – Overfitting and Underfitting|url=http://www.statsblogs.com/2014/03/20/machine-learning-lesson-of-the-day-overfitting-and-underfitting/|website=StatBlogs|date=2014-03-20|access-date=2016-12-29|archive-url=https://web.archive.org/web/20161229170858/http://www.statsblogs.com/2014/03/20/machine-learning-lesson-of-the-day-overfitting-and-underfitting/|archive-date=2016-12-29|url-status=dead}}&lt;/ref&gt; which is not able to process the complexity of the problem (see also [[approximation error]]). This results in a model which is not suitable to handle all the signal and is therefore forced to take some signal as noise. If instead a model is capable to handle the signal but anyways takes a part of it as noise as well, it is also considered to be underfitted. The latter case can happen if the [[loss function]] of a model includes a penalty which is too high in that specific case. 

Burnham&amp;nbsp;&amp; Anderson state the following.&lt;ref name="BA2002"/&gt;{{rp|32}}
{{quote|text= &amp;hellip; an underfitted model would ignore some important replicable (i.e., conceptually replicable in most other samples) structure in the data and thus fail to identify effects that were actually supported by the data. In this case, bias in the parameter estimators is often substantial, and the sampling variance is underestimated, both factors resulting in poor confidence interval coverage. Underfitted models tend to miss important treatment effects in experimental settings.}}

== See also ==
{{Div col|colwidth=20em}}
* [[Bias–variance tradeoff]]
* [[Curve fitting]]
* [[Data dredging]]
* [[Feature selection]]
* [[Freedman's paradox]] 
* [[Generalization error]]
* [[Goodness of fit]]
* [[Life-time of correlation]]
* [[Model selection]]
* [[Occam's razor]]
* [[Helmut_Norpoth#%22Primary_Model%22_for_US_presidential_elections|Primary model]]
* [[VC dimension]] – larger VC dimension implies larger risk of overfitting
{{Div col end}}

== Notes ==
{{reflist}}

== References ==
* {{Cite journal
| last1 = Leinweber
| first1 = D. J.
| author-link = David Leinweber
| title = Stupid data miner tricks
| journal = [[The Journal of Investing]]
| volume = 16
| pages = 15–22
| year = 2007
| doi = 10.3905/joi.2007.681820| s2cid = 108627390
}}

* {{cite journal
| last1 = Tetko
| first1 = I. V.
| last2 = Livingstone
| first2 = D. J.
| last3 = Luik
| first3 = A. I.
| title = Neural network studies. 1. Comparison of Overfitting and Overtraining
| journal = [[Journal of Chemical Information and Modeling]]
| year = 1995
| volume = 35
| issue = 5
| pages = 826–833
| url = http://www.vcclab.org/articles/jcics-overtraining.pdf
| doi = 10.1021/ci00027a006 }}

* ''Tip 7: Minimize overfitting''. {{cite journal 
| last = Chicco 
| first = D.
| title = Ten quick tips for machine learning in computational biology 
| journal = [[BioData Mining]]
| volume = 10
| issue =  35
| pages = 35 
| date = December 2017 
| pmid = 29234465
| doi = 10.1186/s13040-017-0155-3
| pmc= 5721660}}

== Further reading ==

* {{citation
 | last1 = Christian | first1 = Brian | author1-link = Brian Christian
 | last2 = Griffiths | first2 = Tom
 | title = Algorithms To Live By: The computer science of human decisions
 | date = April 2017
 | chapter = Chapter 7: Overfitting
 | pages = 149–168
 | publisher = [[William Collins (imprint)|William Collins]]
 | isbn = 978-0-00-754799-9
}}

== External links ==
* [http://blog.lokad.com/journal/2009/4/22/overfitting-when-accuracy-measure-goes-wrong.html Overfitting: when accuracy measure goes wrong] (an introductory video tutorial)
* [http://www3.cs.stonybrook.edu/~skiena/jaialai/excerpts/node16.html The Problem of Overfitting Data] &amp;mdash;[[Stony Brook University]]
* [https://statmodeling.stat.columbia.edu/2017/07/15/what-is-overfitting-exactly/ What is "overfitting," exactly?] &amp;mdash;[[Andrew Gelman]] blog
* [http://courses.cs.washington.edu/courses/cse546/12wi/slides/cse546wi12LinearRegression.pdf CSE546: Linear Regression Bias / Variance Tradeoff] &amp;mdash;[[University of Washington]]

[[Category:Statistical inference]]
[[Category:Regression analysis]]
[[Category:Machine learning]]</text>
      <sha1>avo893hlkjmmo9753c82nqz0hdkzc13</sha1>
    </revision>
  </page>
  <page>
    <title>Uniform convergence in probability</title>
    <ns>0</ns>
    <id>22999791</id>
    <revision>
      <id>975915142</id>
      <parentid>892212908</parentid>
      <timestamp>2020-08-31T03:49:38Z</timestamp>
      <contributor>
        <username>Kaleodu</username>
        <id>26301405</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="12820" xml:space="preserve">{{Short description|Notion of convergence of random variables}}
{{other|uniform convergence}}
'''Uniform convergence in probability''' is a form of [[convergence in probability]] in [[Asymptotic theory (statistics)|statistical asymptotic theory]] and [[probability theory]]. It means that, under certain conditions, the ''empirical frequencies'' of all events in a certain event-family converge to their ''theoretical probabilities''.  Uniform convergence in probability has applications to [[statistics]] as well as [[machine learning]] as part of [[statistical learning theory]].

The [[law of large numbers]] says that, for each ''single'' event, its empirical frequency in a sequence of independent trials converges (with high probability) to its theoretical probability. But in some applications, we are interested not in a single event but in a whole ''family of events''. We would like to know whether the empirical frequency of every event in the family converges to its theoretical probability ''simultaneously''.{{Citation needed|date=August 2020}} The Uniform Convergence Theorem gives a sufficient condition for this convergence to hold. Roughly, if the event-family is sufficiently simple (its [[VC dimension]] is sufficiently small) then uniform convergence holds.

{{TOC limit|3}}

== Definitions ==
For a class of [[Predicate (mathematical logic)|predicates]] &lt;math&gt;H&lt;/math&gt; defined on a set &lt;math&gt;X&lt;/math&gt; and a set of samples &lt;math&gt;x=(x_1,x_2,\dots,x_m)&lt;/math&gt;, where &lt;math&gt;x_i\in X&lt;/math&gt;, the ''empirical frequency'' of &lt;math&gt;h\in H&lt;/math&gt; on &lt;math&gt;x&lt;/math&gt; is

: &lt;math&gt;\widehat{Q}_x(h)=\frac 1 m |\{i:1\leq i\leq m, h(x_i)=1\}|.&lt;/math&gt;

The ''theoretical probability'' of &lt;math&gt;h\in H&lt;/math&gt; is defined as &lt;math&gt;Q_P(h) = P\{y\in X : h(y)=1\}.&lt;/math&gt;

The Uniform Convergence Theorem states, roughly, that if &lt;math&gt;H&lt;/math&gt; is "simple" and we draw samples independently (with replacement) from &lt;math&gt;X&lt;/math&gt; according to any distribution &lt;math&gt;P&lt;/math&gt;, then [[with high probability]], the empirical frequency will be close to its [[expected value]], which is the theoretical probability.{{Citation needed|date=August 2020}}

Here "simple" means that the [[Vapnik–Chervonenkis dimension]] of the class &lt;math&gt;H&lt;/math&gt; is small relative to the size of the sample. In other words, a sufficiently simple collection of functions behaves roughly the same on a small random sample as it does on the distribution as a whole.

The Uniform Convergence Theorem was first proved by Vapnik and Chervonenkis&lt;ref name=vc&gt;{{Cite Vapnik Chervonenkis}}&lt;/ref&gt; using the concept of [[growth function]].

==Uniform convergence theorem ==

The statement of the uniform convergence theorem is as follows:&lt;ref name="books.google.com"&gt;[https://books.google.com/books?id=OiSJYwp4lzYC&amp;dq=neural+network+learning+theoretical+foundations&amp;printsec=frontcover&amp;source=bn&amp;hl=en&amp;ei=kF32SZDNG8TgtgeXxpSfDw&amp;sa=X&amp;oi=book_result&amp;ct=result&amp;resnum=4 Martin Anthony Peter, l. Bartlett. Neural Network Learning: Theoretical Foundations, pages 46–50. First Edition, 1999. Cambridge University Press] {{ISBN|0-521-57353-X}}&lt;/ref&gt;

If &lt;math&gt;H&lt;/math&gt; is a set of &lt;math&gt;\{0,1\}&lt;/math&gt;-valued functions defined on a set &lt;math&gt;X&lt;/math&gt; and  &lt;math&gt;P&lt;/math&gt; is a probability distribution on &lt;math&gt;X&lt;/math&gt; then for &lt;math&gt;\varepsilon&gt;0&lt;/math&gt; and &lt;math&gt;m&lt;/math&gt; a positive integer, we have:
: &lt;math&gt;P^m\{|Q_P(h)-\widehat{Q_x}(h)|\geq\varepsilon \text{ for some } h\in H\}\leq 4\Pi_H(2m)e^{-\varepsilon^2 m/8}.&lt;/math&gt;
: where, for any &lt;math&gt;x\in X^m,&lt;/math&gt;,
: &lt;math&gt;Q_P(h)=P\{(y\in X:h(y)=1\},&lt;/math&gt;
: &lt;math&gt;\widehat{Q}_x(h)=\frac 1 m |\{i:1\leq i\leq m,h(x_{i})=1\}|&lt;/math&gt;
: and &lt;math&gt;|x|=m&lt;/math&gt;. &lt;math&gt;P^m&lt;/math&gt; indicates that the probability is taken over &lt;math&gt;x&lt;/math&gt; consisting of &lt;math&gt;m&lt;/math&gt; i.i.d. draws from the distribution &lt;math&gt;P&lt;/math&gt;.

: &lt;math&gt;\Pi_H&lt;/math&gt; is defined as: For any &lt;math&gt;\{0,1\}&lt;/math&gt;-valued functions &lt;math&gt;H&lt;/math&gt; over &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;D\subseteq X &lt;/math&gt;,
: &lt;math&gt;\Pi_H(D)=\{h\cap D:h\in H\}.&lt;/math&gt;

And for any natural number &lt;math&gt;m&lt;/math&gt;, the [[shattering number]] &lt;math&gt;\Pi_H(m)&lt;/math&gt; is defined as:
: &lt;math&gt;\Pi_H(m)=\max|\{h\cap D:|D|=m,h\in H\}|.&lt;/math&gt;

From the point of Learning Theory one can consider &lt;math&gt;H&lt;/math&gt; to be the [[Concept class|Concept/Hypothesis]] class defined over the instance set &lt;math&gt;X&lt;/math&gt;. Before getting into the details of the proof of the theorem we will state Sauer's Lemma which we will need in our proof.

== Sauer–Shelah lemma ==
The [[Sauer–Shelah lemma]]&lt;ref&gt;[http://ttic.uchicago.edu/~tewari/lectures/lecture11.pdf Sham Kakade and Ambuj Tewari, CMSC 35900 (Spring 2008) Learning Theory, Lecture 11]&lt;/ref&gt; relates the shattering number &lt;math&gt;\Pi_{h}(m)&lt;/math&gt; to the VC Dimension.

'''Lemma:''' &lt;math&gt;\Pi_{H}(m)\leq\left( \frac{em}{d}\right)^{d}&lt;/math&gt;, where &lt;math&gt;d&lt;/math&gt; is the [[VC Dimension]] of the concept class &lt;math&gt;H&lt;/math&gt;.

'''Corollary:''' &lt;math&gt;\Pi_{H}(m)\leq m^{d}&lt;/math&gt;.

== Proof of uniform convergence theorem ==
&lt;ref name=vc/&gt; and &lt;ref name="books.google.com"/&gt; are the sources of the proof below. Before we get into the details of the proof of the ''Uniform Convergence Theorem'' we will present a high level overview of the proof.

#''Symmetrization:'' We transform the problem of analyzing &lt;math&gt;|Q_{P}(h)-\widehat{Q}_{x}(h)|\geq\varepsilon&lt;/math&gt; into the problem of analyzing &lt;math&gt;|\widehat{Q}_{r}(h)-\widehat{Q}_{s}(h)|\geq\varepsilon/2&lt;/math&gt;, where &lt;math&gt;r&lt;/math&gt; and &lt;math&gt;s&lt;/math&gt; are i.i.d samples of size &lt;math&gt;m&lt;/math&gt; drawn according to the distribution &lt;math&gt;P&lt;/math&gt;. One can view &lt;math&gt;r&lt;/math&gt; as the original randomly drawn sample of length &lt;math&gt;m&lt;/math&gt;, while &lt;math&gt;s&lt;/math&gt; may be thought as the testing sample which is used to estimate &lt;math&gt;Q_{P}(h)&lt;/math&gt;.
#''Permutation:'' Since &lt;math&gt;r&lt;/math&gt; and &lt;math&gt;s&lt;/math&gt; are picked identically and independently, so swapping elements between them will not change the probability distribution on &lt;math&gt;r&lt;/math&gt; and &lt;math&gt;s&lt;/math&gt;. So, we will try to bound the probability of &lt;math&gt;|\widehat{Q}_{r}(h)-\widehat{Q}_{s}(h)|\geq\varepsilon/2&lt;/math&gt; for some &lt;math&gt;h \in H&lt;/math&gt; by considering the effect of a specific collection of permutations of the joint sample &lt;math&gt;x=r||s&lt;/math&gt;. Specifically, we consider permutations &lt;math&gt;\sigma(x)&lt;/math&gt; which swap &lt;math&gt;x_i&lt;/math&gt; and &lt;math&gt;x_{m+i}&lt;/math&gt; in some subset of &lt;math&gt;{1,2,...,m}&lt;/math&gt;. The symbol &lt;math&gt;r||s&lt;/math&gt; means the concatenation of &lt;math&gt;r&lt;/math&gt; and &lt;math&gt;s&lt;/math&gt;.{{Citation needed|date=August 2020}}
#''Reduction to a finite class:'' We can now restrict the function class &lt;math&gt;H&lt;/math&gt; to a fixed joint sample and hence, if &lt;math&gt;H&lt;/math&gt; has finite VC Dimension, it reduces to the problem to one involving a finite function class.

We present the technical details of the proof.

=== Symmetrization ===

'''Lemma:''' Let &lt;math&gt;V=\{x\in X^m:|Q_P(h)-\widehat{Q}_x(h)|\geq\varepsilon \text{ for some } h\in H\}&lt;/math&gt; and
: &lt;math&gt;R=\{(r,s)\in X^m \times X^m:|\widehat{Q_r}(h)-\widehat{Q}_s(h) |\geq \varepsilon /2 \text{ for some } h\in H\}.&lt;/math&gt;

Then for &lt;math&gt;m\geq\frac 2 {\varepsilon^2}&lt;/math&gt;, &lt;math&gt;P^m(V)\leq 2P^{2m}(R)&lt;/math&gt;.

Proof: 
By the triangle inequality,&lt;br&gt; 
if &lt;math&gt;|Q_{P}(h)-\widehat{Q}_r(h)|\geq\varepsilon&lt;/math&gt; and &lt;math&gt;|Q_P(h)-\widehat{Q}_s (h)|\leq\varepsilon /2&lt;/math&gt; then &lt;math&gt;|\widehat{Q}_r(h)-\widehat{Q}_s (h)|\geq\varepsilon /2&lt;/math&gt;.

Therefore,

: &lt;math&gt;
\begin{align}
&amp; P^{2m}(R) \\[5pt]
\geq {} &amp; P^{2m}\{\exists h\in H,|Q_{P}(h)-\widehat{Q}_r(h)| \geq \varepsilon \text{ and } |Q_P(h)-\widehat{Q}_s(h)|\leq\varepsilon /2\} \\[5pt]
= {} &amp; \int_V P^m\{s:\exists h\in H,|Q_P(h)-\widehat{Q}_r(h)|\geq\varepsilon \text{ and } |Q_P(h)-\widehat{Q}_s(h)|\leq\varepsilon /2\} \, dP^m(r) \\[5pt]
= {} &amp; A
\end{align}
&lt;/math&gt;

since &lt;math&gt;r&lt;/math&gt; and &lt;math&gt;s&lt;/math&gt; are independent.

Now for &lt;math&gt;r\in V&lt;/math&gt; fix an &lt;math&gt;h\in H&lt;/math&gt; such that &lt;math&gt;|Q_P(h)-\widehat{Q}_r(h)|\geq\varepsilon&lt;/math&gt;. For this &lt;math&gt;h&lt;/math&gt;, we shall show that

: &lt;math&gt;P^m \left\{ |Q_P(h)-\widehat{Q}_s(h)|\leq\frac \varepsilon 2\right\} \geq\frac 1 2. &lt;/math&gt;

Thus for any &lt;math&gt;r\in V&lt;/math&gt;, &lt;math&gt;A\geq\frac{P^m(V)}2&lt;/math&gt; and hence &lt;math&gt;P^{2m}(R)\geq\frac{P^m(V)}2&lt;/math&gt;. And hence we perform the first step of our high level idea.

Notice, &lt;math&gt;m\cdot \widehat{Q}_s(h)&lt;/math&gt; is a binomial random variable with expectation &lt;math&gt;m\cdot Q_{P}(h)&lt;/math&gt; and variance &lt;math&gt;m\cdot Q_P(h)(1-Q_P(h))&lt;/math&gt;. By [[Chebyshev's inequality]] we get

: &lt;math&gt;P^m \left\{|Q_P(h)-\widehat{Q_s(h)}| &gt; \frac \varepsilon 2\right\} \leq \frac{m\cdot Q_P(h)(1-Q_P(h))}{(\varepsilon m/2)^2} \leq \frac 1 {\varepsilon^2 m} \leq\frac 1 2 &lt;/math&gt;

for the mentioned bound on &lt;math&gt;m&lt;/math&gt;. Here we use the fact that &lt;math&gt;x(1-x)\leq 1/4&lt;/math&gt; for &lt;math&gt;x&lt;/math&gt;.

=== Permutations ===

Let &lt;math&gt;\Gamma_{m}&lt;/math&gt; be the set of all permutations of &lt;math&gt;\{1,2,3,\dots,2m\}&lt;/math&gt; that swaps &lt;math&gt;i&lt;/math&gt; and &lt;math&gt;m+i&lt;/math&gt; &lt;math&gt;\forall i&lt;/math&gt; in some subset of &lt;math&gt;\{1,2,3,\ldots,2m\}&lt;/math&gt;.

'''Lemma:''' Let &lt;math&gt;R&lt;/math&gt; be any subset of &lt;math&gt;X^{2m}&lt;/math&gt; and &lt;math&gt;P&lt;/math&gt; any probability distribution on &lt;math&gt;X&lt;/math&gt;. Then,

: &lt;math&gt;P^{2m}(R)=E[\Pr[\sigma(x)\in R]]\leq \max_{x\in X^{2m}}(\Pr[\sigma(x)\in R]),&lt;/math&gt; 

where the expectation is over &lt;math&gt;x&lt;/math&gt; chosen according to &lt;math&gt;P^{2m}&lt;/math&gt;, and the probability is over &lt;math&gt;\sigma&lt;/math&gt; chosen uniformly from &lt;math&gt;\Gamma_{m}&lt;/math&gt;.

Proof: 
For any &lt;math&gt;\sigma\in\Gamma_m,&lt;/math&gt;

: &lt;math&gt; P^{2m}(R) = P^{2m}\{x:\sigma(x)\in R\} &lt;/math&gt;

(since coordinate permutations preserve the product distribution &lt;math&gt; P^{2m}&lt;/math&gt;.)

: &lt;math&gt;
\begin{align}
\therefore P^{2m}(R) = {} &amp; \int_{X^{2m}}1_{R}(x) \, dP^{2m}(x) \\[5pt]
= {} &amp; \frac{1}{|\Gamma_{m}|}\sum_{\sigma\in\Gamma_m} \int_{X^{2m}} 1_R(\sigma(x)) \, dP^{2m}(x) \\[5pt]
= {} &amp; \int_{X^{2m}} \frac 1 {|\Gamma_m|}\sum_{\sigma\in\Gamma_m} 1_R (\sigma(x)) \, dP^{2m}(x) \\[5pt]
&amp; \text{(because } |\Gamma_{m}| \text{ is finite)} \\[5pt]
= {} &amp; \int_{X^{2m}} \Pr[\sigma(x)\in R] \, dP^{2m}(x) \quad \text{(the expectation)} \\[5pt]
\leq {} &amp; \max_{x\in X^{2m}}(\Pr[\sigma(x)\in R]).
\end{align}
&lt;/math&gt;

The maximum is guaranteed to exist since there is only a finite set of values that probability under a random permutation can take.

=== Reduction to a finite class ===

'''Lemma:''' Basing on the previous lemma,
: &lt;math&gt;\max_{x\in X^{2m}}(\Pr[\sigma(x)\in R])\leq 4\Pi_H(2m)e^{-\varepsilon^2 m/8} &lt;/math&gt;.

Proof:
Let us define &lt;math&gt;x=(x_1,x_2,\ldots,x_{2m})&lt;/math&gt; and &lt;math&gt;t=|H|_x|&lt;/math&gt; which is at most &lt;math&gt;\Pi_H(2m)&lt;/math&gt;. This means there are functions &lt;math&gt;h_1,h_2,\ldots,h_t\in H&lt;/math&gt; such that for any &lt;math&gt;h\in H,\exists i&lt;/math&gt; between &lt;math&gt;1&lt;/math&gt; and &lt;math&gt;t&lt;/math&gt; with &lt;math&gt;h_i(x_k)=h(x_k)&lt;/math&gt; for &lt;math&gt;1\leq k\leq 2m. &lt;/math&gt;

We see that &lt;math&gt;\sigma(x)\in R&lt;/math&gt; iff for some &lt;math&gt;h&lt;/math&gt; in &lt;math&gt;H&lt;/math&gt; satisfies,
&lt;math&gt;|\frac{1}{m}|\{1\leq i\leq m:h(x_{\sigma_{i}})=1\}|-\frac{1}{m}|\{m+1\leq i\leq 2m:h(x_{\sigma_{i}})=1\}||\geq\frac{\varepsilon}{2}&lt;/math&gt;.  
Hence if we define &lt;math&gt;w^{j}_{i}=1&lt;/math&gt; if &lt;math&gt;h_{j}(x_{i})=1&lt;/math&gt; and &lt;math&gt;w^{j}_{i}=0&lt;/math&gt; otherwise.

For &lt;math&gt;1\leq i\leq m&lt;/math&gt; and &lt;math&gt;1\leq j\leq t&lt;/math&gt;, we have that &lt;math&gt;\sigma(x)\in R&lt;/math&gt; iff for some &lt;math&gt;j&lt;/math&gt; in &lt;math&gt;{1,\ldots,t}&lt;/math&gt; satisfies &lt;math&gt;|\frac 1 m \left(\sum_i w^j_{\sigma(i)}-\sum_i w^j_{\sigma(m+i)}\right)|\geq\frac \varepsilon 2 &lt;/math&gt;. By union bound we get

: &lt;math&gt;\Pr[\sigma(x)\in R]\leq t\cdot \max\left(\Pr[|\frac 1 m \left(\sum_i w^j_{\sigma_i} - \sum_i w^j_{\sigma_{m+i}}\right)| \geq \frac \varepsilon 2]\right)&lt;/math&gt;

:&lt;math&gt;\leq \Pi_{H}(2m)\cdot \max\left(\Pr\left[ \left| \frac 1 m \left(\sum_i w^j_{\sigma_i}-\sum_i w^j_{\sigma_{m+i}}\right)\right| \geq \frac \varepsilon 2 \right] \right).&lt;/math&gt;

Since, the distribution over the permutations &lt;math&gt;\sigma&lt;/math&gt; is uniform for each &lt;math&gt;i&lt;/math&gt;, so &lt;math&gt;w^j_{\sigma_i}-w^j_{\sigma_{m+i}}&lt;/math&gt; equals &lt;math&gt;\pm |w^j_i-w^j_{m+i}|&lt;/math&gt;, with equal probability.

Thus,

: &lt;math&gt;\Pr\left[\left|\frac 1 m \left(\sum_i \left(w^j_{\sigma_i}-w^j_{\sigma_{m+i}}\right)\right)\right|\geq\frac \varepsilon 2\right] = \Pr\left[ \left| \frac 1 m \left( \sum_i|w^j_i-w^j_{m+i}|\beta_i\right)\right|\geq\frac \varepsilon 2\right],&lt;/math&gt;

where the probability on the right is over &lt;math&gt;\beta_{i}&lt;/math&gt; and both the possibilities are equally likely. By [[Hoeffding's inequality]], this is at most &lt;math&gt;2e^{-m\varepsilon^2/8}&lt;/math&gt;.

Finally, combining all the three parts of the proof we get the '''Uniform Convergence Theorem'''.

==References==
{{Reflist}}

[[Category:Combinatorics]]
[[Category:Machine learning]]
[[Category:Articles containing proofs]]
[[Category:Probability theorems]]</text>
      <sha1>1re7gh8aov2v6w4lg8wx7ktfvynftxf</sha1>
    </revision>
  </page>
  <page>
    <title>Center for Biological and Computational Learning</title>
    <ns>0</ns>
    <id>17114678</id>
    <revision>
      <id>914440478</id>
      <parentid>910442672</parentid>
      <timestamp>2019-09-07T13:58:32Z</timestamp>
      <contributor>
        <username>SporkBot</username>
        <id>12406635</id>
      </contributor>
      <minor/>
      <comment>Remove template per [[Wikipedia:Templates for discussion/Log/2019 August 25|TFD outcome]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2696" xml:space="preserve">The '''Center for Biological &amp; Computational Learning''' is a research lab at the [[Massachusetts Institute of Technology]].

CBCL was established in 1992 with support from the [[National Science Foundation]]. It is based in the Department of Brain &amp; Cognitive Sciences at MIT, and is associated with the [[McGovern Institute for Brain Research]], and the [[MIT Computer Science and Artificial Intelligence Laboratory]].

It was founded with the belief that learning is at the very core of the problem of intelligence, both biological and artificial. Learning is thus the gateway to understanding how the human brain works and for making intelligent machines. CBCL studies the problem of learning within a multidisciplinary approach. Its main goal is to nurture serious research on the mathematics, the engineering and the neuroscience of learning. 

Research is focused on the problem of learning in theory, engineering applications, and [[neuroscience]].

In [[computational neuroscience]], the center has developed a model of the [[ventral stream]] in the [[visual cortex]] which accounts for much of the physiological data, and [[Psychophysiology|psychophysical]] experiments in difficult object recognition tasks. The model performs at the level of the best computer vision systems{{Citation needed|date=April 2016}}.

==See also==
[[Tomaso Poggio]] director of CBCL

==External links==
*[http://cbcl.mit.edu/ The Center for Biological and Computational Learning (CBCL)]
*BBC:  [http://video.google.com/videoplay?docid=1900129797336249123&amp;q=serre+oliva+poggio&amp;pr=goog-sl Visions of the Future]  -  February 29, 2008 - This is part of the excellent BBC series entitled "visions of the future". This short clip (3min) here shows work performed at CBCL (MIT) about a computational neuroscience model of the ventral stream of the visual cortex. The story here focuses on recent work by Serre, Oliva and Poggio on comparing the performance of the model to human observers during a rapid object categorization task.
*THE DISCOVERY CHANNEL  [Toronto, Canada] by Jennifer Scott  (June 17, 2002): Video:[http://cbcl.mit.edu/news/files/discovery-video.wmv Science, Lies &amp; Videotape]  -  Tony Ezzat and Tomaso Poggio. 
*NBC TODAY SHOW with Katie Couric (May 20, 2002): Video:* [http://cbcl.mit.edu/news/files/100tdy_couric_mitvideo_020520.asf (100 kbit/s)] [http://cbcl.mit.edu/news/files/300tdy_couric_mitvideo_020520.asf (300 kbit/s)] - Tony Ezzat and Tomaso Poggio.


[[Category:Vision]]
[[Category:Visual perception]]
[[Category:Neuroscience research centers in the United States]]
[[Category:Cognitive neuroscience]]
[[Category:Massachusetts Institute of Technology]]
[[Category:Machine learning]]</text>
      <sha1>s36n3ytm0oniqmduuf2dpt318p3k0f4</sha1>
    </revision>
  </page>
  <page>
    <title>Matthews correlation coefficient</title>
    <ns>0</ns>
    <id>12306500</id>
    <revision>
      <id>1004811487</id>
      <parentid>1003257752</parentid>
      <timestamp>2021-02-04T14:33:41Z</timestamp>
      <contributor>
        <ip>93.224.38.73</ip>
      </contributor>
      <comment>MCC does not measure how similar a predictor is to random guessing unless MCC=-1, 0, or +1 (citation included)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="18278" xml:space="preserve">{{Merge from|Phi coefficient|date=August 2020}}
The '''Matthews correlation coefficient''' (MCC) or '''phi coefficient''' is used in [[machine learning]] as a measure of the quality of binary (two-class) [[Binary classification|classifications]], introduced by biochemist [[Brian Matthews (biochemist)|Brian W. Matthews]] in 1975.&lt;ref name="Matthews1975"&gt;{{cite journal|last=Matthews|first=B. W.|title=Comparison of the predicted and observed secondary structure of T4 phage lysozyme|journal=Biochimica et Biophysica Acta (BBA) - Protein Structure|date=1975|volume=405|issue=2|pages=442–451|doi=10.1016/0005-2795(75)90109-9|pmid=1180967}}&lt;/ref&gt; The MCC is defined identically to [[Phi coefficient|Pearson's phi coefficient]], introduced by [[Karl Pearson]],&lt;ref&gt;Cramer, H.  (1946). ''Mathematical Methods of Statistics''. Princeton: Princeton  University Press, p. 282 (second paragraph). {{ISBN|0-691-08004-6}}&lt;/ref&gt;&lt;ref&gt;Date unclear, but prior to his death in 1936.&lt;/ref&gt; also known as the Yule phi coefficient from its introduction by [[Udny Yule]] in 1912.&lt;ref&gt;{{Cite journal|title=On the Methods of Measuring Association Between Two Attributes|journal=Journal of the Royal Statistical Society|last=Yule|first=G. Udny|volume=75|pages=579–652|issue=6|year=1912|doi=10.2307/2340126|jstor=2340126|url=https://zenodo.org/record/1449482}}&lt;/ref&gt; Despite these antecedents which predate Matthews's use by several decades, the term MCC is widely used in the field of bioinformatics and machine learning.

The coefficient takes into account true and false positives and negatives and is generally regarded as a balanced measure which can be used even if the classes are of very different sizes.&lt;ref name="Boughorbel2017"&gt;{{cite journal|last=Boughorbel|first=S.B |title=Optimal classifier for imbalanced data using Matthews Correlation Coefficient metric|journal=PLOS ONE|volume=12 |issue=6 |pages=e0177678 |date=2017|doi=10.1371/journal.pone.0177678 |pmid=28574989 |pmc=5456046 |bibcode=2017PLoSO..1277678B }}&lt;/ref&gt; The MCC is in essence a correlation coefficient between the observed and predicted binary classifications; it returns a value between &amp;minus;1 and +1. A coefficient of +1 represents a perfect prediction, 0 no better than random prediction and &amp;minus;1 indicates total disagreement between prediction and observation. However, if MCC equals neither &amp;minus;1, 0, or +1, it is not a reliable indicator of how similar a predictor is to random guessing.&lt;ref name="Chicco2021"&gt;{{cite journal|last=Chicco|first=D. |title=The Matthews correlation coefficient (MCC) is more reliable than balanced accuracy, bookmaker informedness, and markedness in two-class confusion matrix evaluation|journal=BioDataMining|volume=14 |date=2021|doi=10.1186/s13040-021-00244-z|url=https://doi.org/10.1186/s13040-021-00244-z}}&lt;/ref&gt; MCC is closely related to the [[Pearson's chi-square test|chi-square statistic]] for a 2×2 [[contingency table]]

: &lt;math&gt;|\text{MCC}| = \sqrt{\frac{\chi^2}{n}}&lt;/math&gt;

where ''n'' is the total number of observations.

While there is no perfect way of describing the [[confusion matrix]] of true and false positives and negatives by a single number, the Matthews correlation coefficient is generally regarded as being one of the best such measures.&lt;ref name="Powers2011"&gt;{{cite journal |first=David M W |last=Powers |date=2011 |title=Evaluation: From Precision, Recall and F-Measure to ROC, Informedness, Markedness &amp; Correlation |journal=Journal of Machine Learning Technologies |volume=2 |issue=1 |pages=37–63 |url=http://www.flinders.edu.au/science_engineering/fms/School-CSEM/publications/tech_reps-research_artfcts/TRRA_2007.pdf}}&lt;/ref&gt; Other measures, such as the proportion of correct predictions (also termed [[accuracy]]), are not useful when the two classes are of very different sizes. For example, assigning every object to the larger set achieves a high proportion of correct predictions, but is not generally a useful classification.

The MCC can be calculated directly from the [[confusion matrix]] using the formula:

: &lt;math&gt;
\text{MCC} = \frac{ \mathit{TP} \times \mathit{TN} - \mathit{FP} \times \mathit{FN} } {\sqrt{ (\mathit{TP} + \mathit{FP}) ( \mathit{TP} + \mathit{FN} ) ( \mathit{TN} + \mathit{FP} ) ( \mathit{TN} + \mathit{FN} ) } }
&lt;/math&gt;

In this equation, ''TP'' is the number of [[true positive]]s, ''TN'' the number of [[true negative]]s, ''FP'' the number of [[false positive]]s and ''FN'' the number of [[false negative]]s. If any of the four sums in the denominator is zero, the denominator can be arbitrarily set to one; this results in a Matthews correlation coefficient of zero, which can be shown to be the correct limiting value.

The MCC can be calculated with the formula:
: &lt;math&gt;
\text{MCC} = \sqrt{\mathit{PPV} \times \mathit{TPR} \times \mathit{TNR} \times \mathit{NPV}}
-\sqrt{\mathit{FDR} \times \mathit{FNR} \times \mathit{FPR} \times \mathit{FOR}}
&lt;/math&gt;
using the positive predictive value, the true positive rate, the true negative rate, the negative predictive value, the false discovery rate, the false negative rate, the false positive rate, and the false omission rate.

The original formula as given by Matthews was:&lt;ref name=Matthews1975 /&gt;
: &lt;math&gt;
N = \mathit{TN} + \mathit{TP} + \mathit{FN} + \mathit{FP}
&lt;/math&gt;
: &lt;math&gt;
S = \frac{ \mathit{TP} + \mathit{FN} } { N }
&lt;/math&gt;
: &lt;math&gt;
P = \frac{ \mathit{TP} + \mathit{FP} } { N }
&lt;/math&gt;
: &lt;math&gt;
\text{MCC} = \frac{ \mathit{TP} / N - S \times P } {\sqrt{ P S  ( 1 - S)  ( 1 - P ) } }
&lt;/math&gt;

This is equal to the formula given above. As a [[Correlation and dependence|correlation coefficient]], the Matthews correlation coefficient is the [[geometric mean]] of the [[regression coefficient]]s of the problem and its [[Dual (mathematics)|dual]]. The component regression coefficients of the Matthews correlation coefficient are [[Markedness]] (Δp) and [[Youden's J statistic]] ([[Informedness]] or Δp').&lt;ref name="Powers2011" /&gt;&lt;ref name="Perruchet2004"&gt;{{cite journal |first1=P. |last1=Perruchet |first2=R. |last2=Peereman |year=2004 |title=The exploitation of distributional information in syllable processing |journal=J. Neurolinguistics |volume=17 |issue=2–3 |pages=97–119 |doi=10.1016/s0911-6044(03)00059-9|s2cid=17104364 }}&lt;/ref&gt; [[Markedness]] and [[Informedness]] correspond to different directions of information flow and generalize [[Youden's J statistic]], the &lt;math&gt; \delta &lt;/math&gt;p statistics and (as their geometric mean) the Matthews Correlation Coefficient to more than two classes.&lt;ref name="Powers2011" /&gt;

Some scientists claim the Matthews correlation coefficient to be the most informative single score to establish the quality of a binary classifier prediction in a confusion matrix context.&lt;ref name="Chicco2017"&gt;{{cite journal 
| vauthors = Chicco D
| title = Ten quick tips for machine learning in computational biology 
| journal = BioData Mining
| volume = 10
| issue =  35
| pages = 35 
| date = December 2017 
| pmid = 29234465
| doi = 10.1186/s13040-017-0155-3
| pmc= 5721660}}&lt;/ref&gt;

==Example==
Given a sample of 13 pictures, 8 of cats and 5 of dogs, where cats belong to class 1 and dogs belong to class 0, 

:actual = [1,1,1,1,1,1,1,1,0,0,0,0,0],

assume that a classifier that distinguishes between cats and dogs is trained, and we take the 13 pictures and run them through the classifier, and the classifier makes 8 accurate predictions and misses 5: 3 cats wrongly predicted as dogs (first 3 predictions) and 2 dogs wrongly predicted as cats (last 2 predictions).

:prediction = [0,0,0,1,1,1,1,1,0,0,0,1,1]

With these two labelled sets (actual and predictions) we can create a confusion matrix that will summarize the results of testing the classifier:
{|
|-
|
{| class="wikitable" style="border:none; float:left; margin-top:0; text-align:center;"
!style="background:white; border:none;" colspan="2" rowspan="2"|
!colspan="2" style="background:none;"| Actual class
|-
!Cat
!Dog
|-
!rowspan="2" style="height:6em;background:none;"|&lt;div&gt;Predicted&lt;br&gt;class&lt;/div&gt;
!Cat
|'''5'''
|2
|-
!Dog
|3
|'''3'''
|-
|}
|
|}
In this confusion matrix, of the 8 cat pictures, the system judged that 3 were dogs, and of the 5 dog pictures, it predicted that 2 were cats. All correct predictions are located in the diagonal of the table (highlighted in bold), so it is easy to visually inspect the table for prediction errors, as they will be represented by values outside the diagonal.

In abstract terms, the confusion matrix is as follows:
{|
|-
|
{| class="wikitable" style="border:none; float:left; margin-top:0; text-align:center"
!style="background:white; border:none;" colspan="2" rowspan="2"|
!colspan="2" style="background:none;"| Actual class
|-
!P
!N
|-
!rowspan="2" style="height:6em;background:none;"|&lt;div&gt;Predicted&lt;br&gt;class&lt;/div&gt;
!P
|'''TP'''
|FP
|-
!N
|FN
|'''TN'''
|-
|}
|
|}
where: P = Positive; N = Negative; TP = True Positive; FP = False Positive; TN = True Negative; FN = False Negative.

Plugging the numbers from the formula:

MCC = [(5*3) - (2*3)]/ SQRT[(5+2)*(5+3)*(3+2)*(3+3)] = 9/SQRT[1680] = 0.219

== Confusion matrix ==
{{main article|Confusion matrix}}

{{Confusion matrix terms|recall=}}

Let us define an experiment from '''P''' positive instances and '''N''' negative instances for some condition. The four outcomes can be formulated in a 2×2 ''[[contingency table]]'' or ''[[confusion matrix]]'', as follows:

{{DiagnosticTesting_Diagram}}

== Multiclass case ==
The Matthews correlation coefficient has been generalized to the multiclass case. This generalization was called the  &lt;math&gt;R_K&lt;/math&gt; statistic (for K different classes) by the author, and defined in terms of a &lt;math&gt;K\times K&lt;/math&gt; confusion matrix &lt;math&gt;C&lt;/math&gt;
&lt;ref name="gorodkin2004comparing"&gt;{{cite journal|last=Gorodkin|first=Jan|title=Comparing two K-category assignments by a K-category correlation coefficient|journal=Computational Biology and Chemistry|date=2004|volume=28|number=5|pages=367–374|doi=10.1016/j.compbiolchem.2004.09.006|pmid=15556477}}&lt;/ref&gt;
.&lt;ref name="GorodkinRk2006"&gt;{{cite web|last1=Gorodkin|first1=Jan|title=The Rk Page|url=http://rk.kvl.dk/introduction/index.html|website=The Rk Page|access-date=28 December 2016}}&lt;/ref&gt;

:&lt;math&gt;
\text{MCC} = \frac{\sum_{k}\sum_{l}\sum_{m} C_{kk}C_{lm} - C_{kl}C_{mk}}{
\sqrt{
\sum_{k}(\sum_l C_{kl} )(\sum_{k' | k' \neq k}\sum_{l'} C_{k'l'})
}
\sqrt{
\sum_{k}(\sum_l C_{lk} )(\sum_{k' | k' \neq k}\sum_{l'} C_{l'k'})
}
}
&lt;/math&gt;

When there are more than two labels the MCC will no longer range between -1 and +1. Instead the minimum value will be between -1 and 0 depending on the true distribution. The maximum value is always +1.

&lt;!-- 
TODO: potentially un-comment later, for now just stick with referenced version--&gt;

This formula can be more easily understood by defining intermediate variables:&lt;ref&gt;{{cite web|url=https://scikit-learn.org/stable/modules/model_evaluation.html#matthews-corrcoef|title=Matthew Correlation Coefficient|website=scikit-learn.org}}&lt;/ref&gt; 
* &lt;math&gt;t_k=\sum_i C_{ik}&lt;/math&gt; the number of times class k truly occurred, 
* &lt;math&gt;p_k=\sum_i C_{ki}&lt;/math&gt; the number of times class k was predicted, 
* &lt;math&gt;c=\sum_{k} C_{kk}&lt;/math&gt; the total number of samples correctly predicted, 
* &lt;math&gt;s=\sum_i \sum_j C_{ij}&lt;/math&gt; the total number of samples. This allows the formula to be expressed as:

:&lt;math&gt;
\text{MCC} = \frac{cs - \vec{t} \cdot \vec{p}}{
\sqrt{s^2 - \vec{p} \cdot \vec{p}}
\sqrt{s^2 - \vec{t} \cdot \vec{t}}
}
&lt;/math&gt;

Using above formula to compute MCC measure for the Dog &amp; Cat prediction discussed above, where the Confusion Matrix is treated as a 2 x Multiclass example:

numer = (8*13) - (7*8) - (6*5) = 18

denom = SQRT[(13^2 - 7^2 - 6^2) * (13^2 - 8^2 - 5^2)] = SQRT[6720]

MCC = 18/81.975 = 0.219

== Advantages of MCC over accuracy and F1 score ==
As explained by Davide Chicco in his paper ''"Ten quick tips for machine learning in computational biology"'' ([[BioData Mining]], 2017) and by Giuseppe Jurman in his paper ''"The advantages of the Matthews correlation coefficient (MCC) over F1 score and accuracy in binary classification evaluation"'' ([[BMC Genomics]], 2020), the Matthews correlation coefficient is more informative than F1 score and accuracy in evaluating binary classification problems, because it takes into account the balance ratios of the four confusion matrix categories (true positives, true negatives, false positives, false negatives).&lt;ref name="Chicco2017" /&gt;&lt;ref&gt;{{cite journal | vauthors = Chicco D, Jurman G | title = The advantages of the Matthews correlation coefficient (MCC) over F1 score and accuracy in binary classification evaluation | journal = BMC Genomics| volume = 21| issue =  1| date = January 2020 | page = 6-1–6-13 | pmid = 31898477| doi = 10.1186/s12864-019-6413-7| pmc= 6941312}}&lt;/ref&gt;

The former article explains, for ''Tip 8'':

{{Quote
|text=In order to have an overall understanding of your prediction, you decide to take advantage of common statistical scores, such as accuracy, and F1 score.
: &lt;math&gt;
\text{accuracy} = \frac{ TP+TN } {TP+TN+FP+FN} 
&lt;/math&gt;
(Equation 1, accuracy: worst value = 0; best value = 1)

: &lt;math&gt;
\text{F1 score} = \frac{ 2 TP } {2 TP+FP+FN}
&lt;/math&gt;
(Equation 2, F1 score: worst value = 0; best value = 1)

However, even if accuracy and F1 score are widely employed in statistics, both can be misleading, since they do not fully consider the size of the four classes of the confusion matrix in their final score computation.

Suppose, for example, you have a very imbalanced validation set made of 100 elements, 95 of which are positive elements, and only 5 are negative elements (as explained in Tip 5). And suppose also you made some mistakes in designing and training your machine learning classifier, and now you have an algorithm which always predicts positive. Imagine that you are not aware of this issue.

By applying your only-positive predictor to your imbalanced validation set, therefore, you obtain values for the confusion matrix categories:

TP = 95, FP = 5; TN = 0, FN = 0.

These values lead to the following performance scores: accuracy = 95%, and F1 score = 97.44%. By reading these over-optimistic scores, then you will be very happy and will think that your machine learning algorithm is doing an excellent job. Obviously, you would be on the wrong track.

On the contrary, to avoid these dangerous misleading illusions, there is another performance score that you can exploit: the Matthews correlation coefficient [40] (MCC).
: &lt;math&gt;
\text{MCC} = \frac{ TP \times TN - FP \times FN } {\sqrt{ (TP + FP) ( TP + FN ) ( TN + FP ) ( TN + FN ) } }
&lt;/math&gt;
(Equation 3, MCC: worst value = −1; best value = +1).

By considering the proportion of each class of the confusion matrix in its formula, its score is high only if your classifier is doing well on both the negative and the positive elements.

In the example above, the MCC score would be undefined (since TN and FN would be 0, therefore the denominator of Equation 3 would be 0). By checking this value, instead of accuracy and F1 score, you would then be able to notice that your classifier is going in the wrong direction, and you would become aware that there are issues you ought to solve before proceeding.

Consider this other example. You ran a classification on the same dataset which led to the following values for the confusion matrix categories:

TP = 90, FP = 4; TN = 1, FN = 5.

In this example, the classifier has performed well in classifying positive instances, but was not able to correctly recognize negative data elements. Again, the resulting F1 score and accuracy scores would be extremely high: accuracy = 91%, and F1 score = 95.24%. Similarly to the previous case, if a researcher analyzed only these two score indicators, without considering the MCC, they would wrongly think the algorithm is performing quite well in its task, and would have the illusion of being successful.

On the other hand, checking the Matthews correlation coefficient would be pivotal once again. In this example, the value of the MCC would be 0.14 (Equation 3), indicating that the algorithm is performing similarly to random guessing. Acting as an alarm, the MCC would be able to inform the data mining practitioner that the statistical model is performing poorly.

For these reasons, we strongly encourage to evaluate each test performance through the Matthews correlation coefficient (MCC), instead of the accuracy and the F1 score, for any binary classification problem.
|title=Ten quick tips for machine learning in computational biology&lt;ref name="Chicco2017" /&gt;
|author=Davide Chicco}}

Note that the F1 score depends on which class is defined as the positive class. In the first example above, the F1 score is high because the majority class is defined as the positive class. Inverting the positive and negative classes results in the following confusion matrix:

TP = 0, FP = 0; TN = 5, FN = 95

This gives an F1 score = 0%.

The MCC doesn't depend on which class is the positive one, which has the advantage over the F1 score to avoid incorrectly defining the positive class.

== See also ==
* [[Cohen's kappa]]
* [[Cramér's V (statistics)|Cramér's V]], a similar measure of association between nominal variables.
* [[F1 score]]
* [[Phi coefficient]]
* [[Fowlkes–Mallows index]]

== References ==

{{Reflist}}

&lt;!--should reference in the main text  === General References ===
* [[Pierre Baldi|Baldi, P.]]; Brunak, S.; Chauvin, Y.; Andersen, C. A. F.; Nielsen, H. Assessing the accuracy of prediction algorithms for classification: an overview" ''Bioinformatics'' 2000, 16, 412&amp;ndash;424. [http://bioinformatics.oxfordjournals.org/cgi/content/abstract/16/5/412]
* Carugo, O., Detailed estimation of bioinformatics prediction reliability through the Fragmented Prediction Performance Plots. BMC Bioinformatics 2007. [https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2148069/]
--&gt;

{{DEFAULTSORT:Matthews Correlation Coefficient}}
[[Category:Machine learning]]
[[Category:Information retrieval evaluation]]
[[Category:Statistical classification]]
[[Category:Computational chemistry]]
[[Category:Cheminformatics]]
[[Category:Bioinformatics]]
[[Category:Statistical ratios]]
[[Category:Summary statistics for contingency tables]]</text>
      <sha1>ph61yl8mup3lira0crps9y4kpubgmqv</sha1>
    </revision>
  </page>
  <page>
    <title>Learning with errors</title>
    <ns>0</ns>
    <id>23864530</id>
    <revision>
      <id>993404822</id>
      <parentid>944768530</parentid>
      <timestamp>2020-12-10T13:01:57Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <comment>Add: s2cid, author pars. 1-1. Removed parameters. Some additions/deletions were actually parameter name changes. | You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | Suggested by מושך בשבט | [[Category:Cryptography]] | via #UCB_Category 279/303</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="18539" xml:space="preserve">{{technical|date=October 2018}}
'''Learning with errors''' ('''LWE''') is the [[computational problem]] of inferring a linear &lt;math&gt;n&lt;/math&gt;-ary function &lt;math&gt;f&lt;/math&gt; over a finite ring from given samples &lt;math&gt;y_i = f(\mathbf{x}_i)&lt;/math&gt; some of which may be erroneous.
The LWE problem is conjectured to be hard to solve,&lt;ref&gt;{{Cite journal |doi = 10.1145/1568318.1568324|title = On lattices, learning with errors, random linear codes, and cryptography|journal = Journal of the ACM|volume = 56|issue = 6|pages = 1–40|year = 2009|last1 = Regev|first1 = Oded|s2cid = 207156623}}&lt;/ref&gt; and thus be useful in [[cryptography]].

More precisely, the LWE problem is defined as follows. Let &lt;math&gt;\mathbb{Z}_q &lt;/math&gt; denote the ring of integers [[Modular arithmetic|modulo]] &lt;math&gt;q&lt;/math&gt; and let
&lt;math&gt;\mathbb{Z}_q^n &lt;/math&gt; denote the set of &lt;math&gt;n&lt;/math&gt;-[[Vector (mathematics and physics)|vectors]] over &lt;math&gt;\mathbb{Z}_q &lt;/math&gt;. There exists a certain unknown linear function &lt;math&gt;f:\mathbb{Z}_q^n \rightarrow \mathbb{Z}_q&lt;/math&gt;, and the input to the LWE problem is a sample of pairs &lt;math&gt;(\mathbf{x},y)&lt;/math&gt;, where &lt;math&gt;\mathbf{x}\in \mathbb{Z}_q^n&lt;/math&gt; and &lt;math&gt;y \in \mathbb{Z}_q&lt;/math&gt;, so that with high probability &lt;math&gt;y=f(\mathbf{x})&lt;/math&gt;. Furthermore, the deviation from the equality is according to some known noise model. The problem calls for finding the function &lt;math&gt;f&lt;/math&gt;, or some close approximation thereof, with high probability.

The LWE problem was introduced by [[Oded Regev (computer scientist)|Oded Regev]] in 2005&lt;ref name="regev05"/&gt; (who won the 2018 [[Gödel Prize]] for this work), it is a generalization of the [[parity learning]] problem. Regev showed that the LWE problem is as hard to solve as several worst-case [[lattice problems]]. Subsequently, the LWE problem has been used as a [[Computational hardness assumption|hardness assumption]] to create [[Public-key cryptography|public-key cryptosystems]],&lt;ref name="regev05"&gt;Oded Regev, “On lattices, learning with errors, random linear codes, and cryptography,” in Proceedings of the thirty-seventh annual ACM symposium on Theory of computing (Baltimore, MD, USA: ACM, 2005), 84–93, http://portal.acm.org/citation.cfm?id=1060590.1060603.&lt;/ref&gt;&lt;ref name="peikert09"&gt;Chris Peikert, “Public-key cryptosystems from the worst-case shortest vector problem: extended abstract,” in Proceedings of the 41st annual ACM symposium on Theory of computing (Bethesda, MD, USA: ACM, 2009), 333–342, http://portal.acm.org/citation.cfm?id=1536414.1536461.&lt;/ref&gt; such as the [[ring learning with errors key exchange]] by Peikert.&lt;ref&gt;{{Cite book|publisher = Springer International Publishing|date = 2014-10-01|isbn = 978-3-319-11658-7|pages = 197–219|series = Lecture Notes in Computer Science|first = Chris|last = Peikert|editor-first = Michele|editor-last = Mosca|doi = 10.1007/978-3-319-11659-4_12|title = Post-Quantum Cryptography|volume = 8772|chapter = Lattice Cryptography for the Internet|citeseerx = 10.1.1.800.4743}}&lt;/ref&gt;

== Definition ==
Denote by &lt;math&gt;\mathbb{T}=\mathbb{R}/\mathbb{Z}&lt;/math&gt; the [[Circle_group|additive group on reals modulo one]]. 
Let &lt;math&gt;\mathbf{s} \in \mathbb{Z}_q^n&lt;/math&gt; be a fixed vector.
Let &lt;math&gt;\phi&lt;/math&gt; be a fixed probability distribution over &lt;math&gt;\mathbb{T}&lt;/math&gt;.
Denote by &lt;math&gt;A_{\mathbf{s},\phi}&lt;/math&gt; the distribution on &lt;math&gt;\mathbb{Z}_q^n \times \mathbb{T}&lt;/math&gt; obtained as follows.
# Pick a vector &lt;math&gt;\mathbf{a}\in \mathbb{Z}_q^n&lt;/math&gt; from the uniforms distribution over &lt;math&gt;\mathbf{a}\in \mathbb{Z}_q^n&lt;/math&gt;, 
# Pick a number &lt;math&gt;e\in\mathbb{T}&lt;/math&gt; from the distribution &lt;math&gt;\phi&lt;/math&gt;,
# Evaluate &lt;math&gt;t=\langle \mathbf{a},\mathbf{s} \rangle /q + e&lt;/math&gt;, where &lt;math&gt;\textstyle \langle \mathbf{a},\mathbf{s} \rangle = \sum_{i=1}^n a_i s_i&lt;/math&gt; is the standard inner product in &lt;math&gt;\mathbb{Z}_q^n&lt;/math&gt;, the division is done in the [[field of reals]] (or more formally, this "division by &lt;math&gt;q&lt;/math&gt;" is notation for the group homomorphism &lt;math&gt; \mathbb{Z}_q \longrightarrow \mathbb{T}&lt;/math&gt; mapping &lt;math&gt; 1 \in \mathbb{Z}_q &lt;/math&gt; to &lt;math&gt; 1/q + \mathbb{Z} \in \mathbb{T}&lt;/math&gt;), and the final addition is in &lt;math&gt;\mathbb{T}&lt;/math&gt;.
# Output the pair &lt;math&gt;(\mathbf{a},t)&lt;/math&gt;.

The '''learning with errors problem''' &lt;math&gt;\mathrm{LWE}_{q,\phi}&lt;/math&gt; is to find &lt;math&gt;\mathbf{s} \in \mathbb{Z}_q^n&lt;/math&gt;, given access to polynomially many samples of choice from &lt;math&gt;A_{\mathbf{s},\phi}&lt;/math&gt;.

For every &lt;math&gt;\alpha &gt; 0&lt;/math&gt;, denote by &lt;math&gt;D_\alpha&lt;/math&gt; the one-dimensional [[Normal distribution|Gaussian]] with zero mean and variance
&lt;math&gt;\alpha^2/(2\pi)&lt;/math&gt;, that is, the density function is &lt;math&gt;D_\alpha(x)=\rho_\alpha(x)/\alpha&lt;/math&gt; where &lt;math&gt;\rho_\alpha(x)=e^{-\pi(|x|/\alpha)^2}&lt;/math&gt;, and let &lt;math&gt;\Psi_\alpha&lt;/math&gt; be the distribution on &lt;math&gt;\mathbb{T}&lt;/math&gt; obtained by considering &lt;math&gt;D_\alpha&lt;/math&gt; modulo one.  The version of LWE considered in most of the results would be &lt;math&gt;\mathrm{LWE}_{q,\Psi_\alpha}&lt;/math&gt;

== Decision version ==

The '''LWE''' problem described above is the ''search'' version of the problem. In the ''decision'' version ('''DLWE'''), the goal is to distinguish between noisy inner products and uniformly random samples from &lt;math&gt;\mathbb{Z}_q^n \times \mathbb{T}&lt;/math&gt; (practically, some discretized version of it). Regev&lt;ref name="regev05" /&gt; showed that the ''decision'' and ''search'' versions are equivalent when &lt;math&gt;q&lt;/math&gt; is a prime bounded by some polynomial in &lt;math&gt;n&lt;/math&gt;.

=== Solving decision assuming search ===
Intuitively, if we have a procedure for the search problem, the decision version can be solved easily: just feed the input samples for the decision problem to the solver for the search problem. Denote the given samples by &lt;math&gt;\{(\mathbf{a}_i,\mathbf{b}_i)\} \subset \mathbb{Z}^n_q \times \mathbb{T}&lt;/math&gt;. If the solver returns a candidate &lt;math&gt;\mathbf{s}&lt;/math&gt;, for all &lt;math&gt;i&lt;/math&gt;, calculate &lt;math&gt;\{\langle \mathbf{a}_i, \mathbf{s} \rangle - \mathbf{b}_i \} &lt;/math&gt;.  If the samples are from an LWE distribution, then the results of this calculation will be distributed according &lt;math&gt;\chi&lt;/math&gt;, but if the samples are uniformly random, these quantities will be distributed uniformly as well.

=== Solving search assuming decision ===
For the other direction, given a solver for the decision problem, the search version can be solved as follows: Recover &lt;math&gt;\mathbf{s}&lt;/math&gt; one coordinate at a time. To obtain the first coordinate, &lt;math&gt;\mathbf{s}_1&lt;/math&gt;, make a guess &lt;math&gt;k \in Z_q&lt;/math&gt;, and do the following. Choose a number &lt;math&gt;r \in \mathbb{Z}_q&lt;/math&gt; uniformly at random. Transform the given samples &lt;math&gt;\{(\mathbf{a}_i,\mathbf{b}_i)\} \subset \mathbb{Z}^n_q \times \mathbb{T}&lt;/math&gt; as follows. Calculate &lt;math&gt;\{(\mathbf{a}_i+(r,0,\ldots,0), \mathbf{b}_i + (r k)/q)\}&lt;/math&gt;.  Send the transformed samples to the decision solver.

If the guess &lt;math&gt;k&lt;/math&gt; was correct, the transformation takes the distribution &lt;math&gt;A_{\mathbf{s},\chi}&lt;/math&gt; to itself, and otherwise, since &lt;math&gt;q&lt;/math&gt; is prime, it takes it to the uniform distribution. So, given a polynomial-time solver for the decision problem that errs with very small probability, since &lt;math&gt;q&lt;/math&gt; is bounded by some polynomial in &lt;math&gt;n&lt;/math&gt;, it only takes polynomial time to guess every possible value for &lt;math&gt;k&lt;/math&gt; and use the solver to see which one is correct.

After obtaining &lt;math&gt;\mathbf{s}_1&lt;/math&gt;, we follow an analogous procedure for each other coordinate &lt;math&gt;\mathbf{s}_j&lt;/math&gt;.  Namely, we transform our &lt;math&gt;\mathbf{b}_i&lt;/math&gt; samples the same way, and transform our &lt;math&gt;\mathbf{a}_i&lt;/math&gt; samples by calculating &lt;math&gt;\mathbf{a}_i + (0, \ldots, r, \ldots, 0)&lt;/math&gt;, where the &lt;math&gt;r&lt;/math&gt; is in the &lt;math&gt;j^\text{th}&lt;/math&gt; coordinate.&lt;ref name="regev05" /&gt;

Peikert&lt;ref name="peikert09" /&gt; showed that this reduction, with a small modification, works for any &lt;math&gt;q&lt;/math&gt; that is a product of distinct, small (polynomial in &lt;math&gt;n&lt;/math&gt;) primes.  The main idea is if &lt;math&gt;q = q_1 q_2 \cdots q_t&lt;/math&gt;, for each &lt;math&gt;q_{\ell}&lt;/math&gt;, guess and check to see if &lt;math&gt;\mathbf{s}_j&lt;/math&gt; is congruent to &lt;math&gt;0 \mod q_{\ell}&lt;/math&gt;, and then use the [[Chinese remainder theorem]] to recover &lt;math&gt;\mathbf{s}_j&lt;/math&gt;.

=== Average case hardness ===
Regev&lt;ref name="regev05" /&gt; showed the [[random self-reducibility]] of the '''LWE''' and '''DLWE''' problems for arbitrary &lt;math&gt;q&lt;/math&gt; and &lt;math&gt;\chi&lt;/math&gt;.  Given samples &lt;math&gt;\{(\mathbf{a}_i,\mathbf{b}_i)\}&lt;/math&gt; from &lt;math&gt;A_{\mathbf{s},\chi}&lt;/math&gt;, it is easy to see that &lt;math&gt;\{(\mathbf{a}_i,\mathbf{b}_i + \langle \mathbf{a}_i, \mathbf{t} \rangle)/q\}&lt;/math&gt; are samples from &lt;math&gt;A_{\mathbf{s} + \mathbf{t},\chi}&lt;/math&gt;.

So, suppose there was some set &lt;math&gt;\mathcal{S} \subset \mathbb{Z}_q^n&lt;/math&gt; such that &lt;math&gt;|\mathcal{S}|/|\mathbb{Z}_q^n| = 1/\operatorname{poly}(n)&lt;/math&gt;, and for distributions &lt;math&gt;A_{\mathbf{s}',\chi}&lt;/math&gt;, with &lt;math&gt;\mathbf{s}' \leftarrow \mathcal{S}&lt;/math&gt;, '''DLWE''' was easy.

Then there would be some distinguisher &lt;math&gt;\mathcal{A}&lt;/math&gt;, who, given samples &lt;math&gt;\{(\mathbf{a}_i,\mathbf{b}_i) \}&lt;/math&gt;, could tell whether they were uniformly random or from &lt;math&gt;A_{\mathbf{s}',\chi}&lt;/math&gt;.  If we need to distinguish uniformly random samples from &lt;math&gt;A_{\mathbf{s},\chi}&lt;/math&gt;, where &lt;math&gt;\mathbf{s}&lt;/math&gt; is chosen uniformly at random from &lt;math&gt;\mathbb{Z}_q^n&lt;/math&gt;, we could simply try different values &lt;math&gt;\mathbf{t} &lt;/math&gt; sampled uniformly at random from &lt;math&gt;\mathbb{Z}_q^n&lt;/math&gt;, calculate &lt;math&gt;\{(\mathbf{a}_i,\mathbf{b}_i + \langle \mathbf{a}_i, \mathbf{t} \rangle)/q\}&lt;/math&gt; and feed these samples to &lt;math&gt;\mathcal{A}&lt;/math&gt;.  Since &lt;math&gt;\mathcal{S}&lt;/math&gt; comprises a large fraction of &lt;math&gt;\mathbb{Z}_q^n&lt;/math&gt;, with high probability, if we choose a polynomial number of values for &lt;math&gt;\mathbf{t}&lt;/math&gt;, we will find one such that &lt;math&gt;\mathbf{s} + \mathbf{t} \in \mathcal{S}&lt;/math&gt;, and &lt;math&gt;\mathcal{A}&lt;/math&gt; will successfully distinguish the samples.

Thus, no such &lt;math&gt;\mathcal{S}&lt;/math&gt; can exist, meaning '''LWE''' and '''DLWE''' are (up to a polynomial factor) as hard in the average case as they are in the worst case.

== Hardness results ==

=== Regev's result ===
For a ''n''-dimensional lattice &lt;math&gt;L&lt;/math&gt;, let ''smoothing parameter'' &lt;math&gt;\eta_\varepsilon(L)&lt;/math&gt; denote the smallest &lt;math&gt;s&lt;/math&gt; such that &lt;math&gt;\rho_{1/s}(L^*\setminus \{\mathbf{0}\}) \leq \varepsilon &lt;/math&gt; where &lt;math&gt;L^*&lt;/math&gt; is the dual of &lt;math&gt;L&lt;/math&gt; and &lt;math&gt;\rho_\alpha(x)=e^{-\pi(|x|/\alpha)^2}&lt;/math&gt; is extended to sets by summing over function values at each element in the set. Let &lt;math&gt;D_{L,r}&lt;/math&gt; denote the discrete Gaussian distribution on &lt;math&gt;L&lt;/math&gt; of width &lt;math&gt;r&lt;/math&gt; for a lattice &lt;math&gt;L&lt;/math&gt; and real &lt;math&gt;r&gt;0&lt;/math&gt;. The probability of each &lt;math&gt;x \in L&lt;/math&gt; is proportional to &lt;math&gt;\rho_r(x)&lt;/math&gt;.

The ''discrete Gaussian sampling problem''(DGS) is defined as follows: An instance of &lt;math&gt;DGS_\phi&lt;/math&gt; is given by an &lt;math&gt;n&lt;/math&gt;-dimensional lattice &lt;math&gt;L&lt;/math&gt; and a number &lt;math&gt;r \geq \phi(L)&lt;/math&gt;. The goal is to output a sample from &lt;math&gt;D_{L,r}&lt;/math&gt;. Regev shows that there is a reduction from &lt;math&gt;\operatorname{GapSVP}_{100\sqrt{n}\gamma(n)}&lt;/math&gt; to &lt;math&gt;DGS_{\sqrt{n}\gamma(n)/\lambda(L^*)}&lt;/math&gt; for any function &lt;math&gt;\gamma(n)&lt;/math&gt;.

Regev then shows that there exists an efficient quantum algorithm for &lt;math&gt;DGS_{\sqrt{2n}\eta_\varepsilon(L)/\alpha}&lt;/math&gt; given access to an oracle for &lt;math&gt;\mathrm{LWE}_{q,\Psi_\alpha}&lt;/math&gt; for integer &lt;math&gt;q&lt;/math&gt; and &lt;math&gt;\alpha \in (0,1)&lt;/math&gt; such that &lt;math&gt;\alpha q &gt; 2\sqrt{n}&lt;/math&gt;. This implies the hardness for LWE. Although the proof of this assertion works for any &lt;math&gt;q&lt;/math&gt;, for creating a cryptosystem, the &lt;math&gt;q&lt;/math&gt; has to be polynomial in &lt;math&gt;n&lt;/math&gt;.

=== Peikert's result ===

Peikert proves&lt;ref name="peikert09" /&gt; that there is a probabilistic polynomial time reduction from the [[Lattice problems#GapSVP|&lt;math&gt;\operatorname{GapSVP}_{\zeta,\gamma}&lt;/math&gt;]] problem in the worst case to solving &lt;math&gt;\mathrm{LWE}_{q,\Psi_\alpha}&lt;/math&gt; using &lt;math&gt;\operatorname{poly}(n)&lt;/math&gt; samples for parameters &lt;math&gt;\alpha \in (0,1)&lt;/math&gt;, &lt;math&gt;\gamma(n)\geq n/(\alpha \sqrt{\log n})&lt;/math&gt;, &lt;math&gt;\zeta(n) \geq \gamma(n)&lt;/math&gt; and &lt;math&gt;q \geq (\zeta/\sqrt{n}) \omega \sqrt{\log n})&lt;/math&gt;.

== Use in cryptography ==

The '''LWE''' problem serves as a versatile problem used in construction of several&lt;ref name="regev05" /&gt;&lt;ref name="peikert09" /&gt;&lt;ref&gt;Chris Peikert and Brent Waters, “Lossy trapdoor functions and their applications,” in Proceedings of the 40th annual ACM symposium on Theory of computing (Victoria, British Columbia, Canada: ACM, 2008), 187-196, http://portal.acm.org/citation.cfm?id=1374406.&lt;/ref&gt;&lt;ref&gt;Craig Gentry, Chris Peikert, and Vinod Vaikuntanathan, “Trapdoors for hard lattices and new cryptographic constructions,” in Proceedings of the 40th annual ACM symposium on Theory of computing (Victoria, British Columbia, Canada: ACM, 2008), 197-206, http://portal.acm.org/citation.cfm?id=1374407.&lt;/ref&gt; cryptosystems. In 2005, Regev&lt;ref name="regev05" /&gt; showed that the decision version of LWE is hard assuming quantum hardness of the [[lattice problems]] &lt;math&gt;\mathrm{GapSVP}_\gamma&lt;/math&gt; (for &lt;math&gt;\gamma&lt;/math&gt; as above) and &lt;math&gt;\mathrm{SIVP}_t&lt;/math&gt; with &lt;math&gt; t=O(n/\alpha) &lt;/math&gt;). In 2009, Peikert&lt;ref name="peikert09" /&gt; proved a similar result assuming only the classical hardness of the related problem [[Lattice problems#GapSVP|&lt;math&gt;\mathrm{GapSVP}_{\zeta,\gamma}&lt;/math&gt;]]. The disadvantage of Peikert's result is that it bases itself on a non-standard version of an easier (when compared to SIVP) problem GapSVP.

=== Public-key cryptosystem ===
Regev&lt;ref name="regev05" /&gt; proposed a [[public-key cryptosystem]] based on the hardness of the '''LWE''' problem. The cryptosystem as well as the proof of security and correctness are completely classical. The system is characterized by &lt;math&gt;m,q&lt;/math&gt; and a probability distribution &lt;math&gt;\chi&lt;/math&gt; on &lt;math&gt;\mathbb{T}&lt;/math&gt;. The setting of the parameters used in proofs of correctness and security is
* &lt;math&gt;q \geq 2 &lt;/math&gt;, usually a prime number between &lt;math&gt;n^2&lt;/math&gt; and &lt;math&gt;2n^2&lt;/math&gt;.
* &lt;math&gt;m=(1+\varepsilon)(n+1) \log q&lt;/math&gt; for an arbitrary constant &lt;math&gt;\varepsilon&lt;/math&gt;
* &lt;math&gt;\chi=\Psi_{\alpha(n)}&lt;/math&gt; for &lt;math&gt;\alpha(n) \in o(1/\sqrt{n}\log n)&lt;/math&gt;, where &lt;math&gt;\Psi_\beta&lt;/math&gt; is a probability distribution obtained by sampling a normal variable with mean &lt;math&gt;0&lt;/math&gt; and standard variation &lt;math&gt;\frac{\beta}{\sqrt{2\pi}}&lt;/math&gt; and reducing the result modulo &lt;math&gt;1&lt;/math&gt;.

The cryptosystem is then defined by:
* ''Private key'': Private key is an &lt;math&gt;\mathbf{s}\in \mathbb{Z}^n_q&lt;/math&gt; chosen uniformly at random.
* ''Public key'': Choose &lt;math&gt;m&lt;/math&gt; vectors &lt;math&gt;\mathbf{a}_1,\ldots,\mathbf{a}_m \in  \mathbb{Z}^n_q&lt;/math&gt; uniformly and independently. Choose error offsets &lt;math&gt;e_1,\ldots,e_m \in \mathbb{T}&lt;/math&gt; independently according to &lt;math&gt;\chi&lt;/math&gt;. The public key consists of &lt;math&gt;(\mathbf{a}_i,b_i=\langle \mathbf{a}_i,\mathbf{s} \rangle/q + e_i)^m_{i=1}&lt;/math&gt;
* ''Encryption'': The encryption of a bit &lt;math&gt;x \in \{0,1\}&lt;/math&gt; is done by choosing a random subset &lt;math&gt;S&lt;/math&gt; of &lt;math&gt;[m]&lt;/math&gt; and then defining &lt;math&gt;\operatorname{Enc}(x)&lt;/math&gt; as
:: &lt;math&gt;\left(\sum_{i \in S} \mathbf{a}_i, \frac x 2 + \sum_{i \in S} b_i\right)&lt;/math&gt;
* ''Decryption'': The decryption of &lt;math&gt;(\mathbf{a},b)&lt;/math&gt; is &lt;math&gt;0&lt;/math&gt; if &lt;math&gt;b-\langle \mathbf{a}, \mathbf{s} \rangle/q&lt;/math&gt; is closer to &lt;math&gt;0&lt;/math&gt; than to &lt;math&gt;\frac{1}{2}&lt;/math&gt;, and &lt;math&gt;1&lt;/math&gt; otherwise.

The proof of correctness follows from choice of parameters and some probability analysis. The proof of security is by reduction to the decision version of '''LWE''': an algorithm for distinguishing between encryptions (with above parameters) of &lt;math&gt;0&lt;/math&gt; and &lt;math&gt;1&lt;/math&gt; can be used to distinguish between &lt;math&gt;A_{s,\chi}&lt;/math&gt; and the uniform distribution over &lt;math&gt;\mathbb{Z}^n_q \times \mathbb{T}&lt;/math&gt;

=== CCA-secure cryptosystem ===
{{Expand section|date=December 2009}}
Peikert&lt;ref name="peikert09" /&gt; proposed a system that is secure even against any [[chosen-ciphertext attack]].

=== Key exchange ===
{{Main|Ring learning with errors key exchange}}
The idea of using LWE and Ring LWE for key exchange was proposed and filed at the University of Cincinnati in 2011 by Jintai Ding. The idea comes from the associativity of matrix multiplications, and the errors are used to provide the security. The paper&lt;ref&gt;{{Cite journal|last=Lin|first=Jintai Ding, Xiang Xie, Xiaodong|date=2012-01-01|title=A Simple Provably Secure Key Exchange Scheme Based on the Learning with Errors Problem|url=https://eprint.iacr.org/2012/688}}&lt;/ref&gt; appeared in 2012 after a provisional patent application was filed in 2012.

The security of the protocol is proven based on the hardness of solving the LWE problem. In 2014, Peikert presented a key-transport scheme&lt;ref&gt;{{Cite journal|last=Peikert|first=Chris|date=2014-01-01|title=Lattice Cryptography for the Internet|url=https://eprint.iacr.org/2014/070}}&lt;/ref&gt; following the same basic idea of Ding's, where the new idea of sending an additional 1-bit signal for rounding in Ding's construction is also used. The "new hope" implementation&lt;ref&gt;{{Cite journal|last1=Alkim|first1=Erdem|last2=Ducas|first2=Léo|last3=Pöppelmann|first3=Thomas|last4=Schwabe|first4=Peter|date=2015-01-01|title=Post-quantum key exchange - a new hope|url=https://eprint.iacr.org/2015/1092}}&lt;/ref&gt; selected for Google's post-quantum experiment,&lt;ref&gt;{{Cite news|url=https://security.googleblog.com/2016/07/experimenting-with-post-quantum.html|title=Experimenting with Post-Quantum Cryptography|newspaper=Google Online Security Blog|access-date=2017-02-08|language=en-US}}&lt;/ref&gt; uses Peikert's scheme with variation in the error distribution.

== See also ==
*[[Post-quantum cryptography]]
*[[Lattice-based cryptography]]
*[[Ring learning with errors key exchange]]
*[[Short integer solution problem|Short integer solution (SIS) problem]]

==References==
&lt;references/&gt;

{{Computational hardness assumptions}}

[[Category:Machine learning]]
[[Category:Cryptography]]
[[Category:Post-quantum cryptography]]</text>
      <sha1>livlrgiz9bmq0fay8pb7r7moe51a92a</sha1>
    </revision>
  </page>
  <page>
    <title>CIML community portal</title>
    <ns>0</ns>
    <id>22795783</id>
    <revision>
      <id>954269834</id>
      <parentid>801403242</parentid>
      <timestamp>2020-05-01T15:06:13Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* External links */add authority control</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3473" xml:space="preserve">The [[computational intelligence]] and [[machine learning]] (CIML) community portal is an international multi-university initiative.  Its primary purpose is to help facilitate a [[virtual scientific community]] infrastructure for all those involved with, or interested in, computational intelligence and machine learning.  This includes CIML research-, education, and application-oriented resources residing at the portal and others that are linked from the CIML site.

== Overview ==
The CIML community portal was created to facilitate an online virtual scientific community wherein anyone interested in CIML can share research, obtain resources, or simply learn more. The effort is currently led by [[Jacek Zurada]] (principal investigator), with Rammohan Ragade and Janusz Wojtusiak, aided by a team of 25 volunteer researchers from 13 different countries.&lt;ref&gt;Jacek M. Zurada, Janusz Wojtusiak, Maciej A. Mazurowski, Devendra Mehta, Khalid Moidu, Steve Margolis, Toward Multidisciplinary Collaboration in the CIML Virtual Community, Proceedings of the 2008 Workshop on Building Computational Intelligence and Machine Learning Virtual Organizations, pp. 62–66&lt;/ref&gt;&lt;ref&gt;Jacek M. Zurada, Janusz Wojtusiak, Rommohan Ragade, James Gentle, Maciej A. Mazurowski, and Artur Abdullin, Building Virtual Community in Computational Intelligence and Machine Learning, ''IEEE Computational Intelligence Magazine'', February 2009, pp. 43–54&lt;/ref&gt;

The ultimate goal of the CIML community portal is to accommodate and cater to a broad range of users, including experts, students, the public, and outside researchers interested in using CIML methods and software tools.  Each community member and user will be guided through the portal resources and tools based on their respective CIML experience (e.g. expert, student, outside researcher) and goals (e.g. collaboration, education).  A preliminary version of the community's portal, with limited capabilities, is now operational and available for users.&lt;ref&gt;{{cite web|url=http://www.cimlcommunity.org/|title=Cimlcommunity.org|publisher=}}&lt;/ref&gt;  All electronic resources on the portal are peer-reviewed to ensure high quality and cite-ability for literature.

==Further reading==
*Jacek M. Zurada, Janusz Wojtusiak, Fahmida Chowdhury, James E. Gentle, Cedric J. Jeannot, and Maciej A. Mazurowski, Computational Intelligence Virtual Community: Framework and Implementation Issues, Proceedings of the IEEE World Congress on Computational Intelligence, Hong Kong, June 1–6, 2008.
* Jacek M. Zurada, Janusz Wojtusiak, Maciej A. Mazurowski, Devendra Mehta, Khalid Moidu, Steve Margolis, Toward Multidisciplinary Collaboration in the CIML Virtual Community, Proceedings of the 2008 Workshop on Building Computational Intelligence and Machine Learning Virtual Organizations, pp.&amp;nbsp;62–66
*Chris Boyle, Artur Abdullin, Rammohan Ragade, Maciej A. Mazurowski, Janusz Wojtusiak, Jacek M. Zurada, Workflow considerations in the emerging CI-ML virtual organization, Proceedings of the 2008 Workshop on Building Computational Intelligence and Machine Learning Virtual Organizations, pp.&amp;nbsp;67–70

==See also==
*[[Artificial Intelligence]]
*[[Computational Intelligence]]
*[[Machine Learning]]
*[[National Science Foundation]]

==References==
&lt;references /&gt;

== External links ==
* {{Official website|http://www.cimlcommunity.org/ }}

{{authority control}}

[[Category:Machine learning]]
[[Category:International research institutes]]</text>
      <sha1>9mqo7xh61shk7ancu7hm2txjks9a2pq</sha1>
    </revision>
  </page>
  <page>
    <title>Learning to rank</title>
    <ns>0</ns>
    <id>25050663</id>
    <revision>
      <id>1003264018</id>
      <parentid>999882862</parentid>
      <timestamp>2021-01-28T04:33:54Z</timestamp>
      <contributor>
        <ip>98.210.2.140</ip>
      </contributor>
      <comment>/* List of methods */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="36959" xml:space="preserve">{{short description|Use of machine learning to rank items}}
{{machine learning bar}}
'''Learning to rank'''&lt;ref name="liu"&gt;{{citation
|author=Tie-Yan Liu
|title=Learning to Rank for Information Retrieval
|journal=Foundations and Trends in Information Retrieval
|year=2009
|isbn=978-1-60198-244-5
|doi=10.1561/1500000016
|pages=225–331
|volume=3
|issue=3
}}. Slides from Tie-Yan Liu's talk at [[World Wide Web Conference|WWW]] 2009 conference are [http://wwwconference.org/www2009/pdf/T7A-LEARNING%20TO%20RANK%20TUTORIAL.pdf available online]
&lt;/ref&gt; or '''machine-learned ranking''' ('''MLR''') is the application of [[machine learning]], typically [[Supervised learning|supervised]], [[Semi-supervised learning|semi-supervised]] or [[reinforcement learning]], in the construction of [[ranking function|ranking models]] for [[information retrieval]] systems.&lt;ref&gt;[[Mehryar Mohri]], Afshin Rostamizadeh, Ameet Talwalkar (2012) ''Foundations of Machine Learning'', The
MIT Press {{ISBN|9780262018258}}.&lt;/ref&gt; [[Training data]] consists of lists of items with some [[partial order]] specified between items in each list. This order is typically induced by giving a numerical or ordinal score or a binary judgment (e.g. "relevant" or "not relevant") for each item. The ranking model  purposes to rank, i.e. producing a [[permutation]] of items in new, unseen lists in a similar way to rankings in the training data.

== Applications ==

=== In information retrieval ===
[[File:MLR-search-engine-example.png|250px|thumb|A possible architecture of a machine-learned search engine.]]
Ranking is a central part of many [[information retrieval]] problems, such as [[document retrieval]], [[collaborative filtering]], [[sentiment analysis]], and [[online advertising]].

A possible architecture of a machine-learned search engine is shown in the accompanying figure.

Training data consists of queries and documents matching them together with relevance degree of each match. It may be prepared manually by human ''assessors'' (or ''raters'', as [[Google]] calls them),
&lt;!-- "assessor" is the more standard term, used e.g. by TREC conference --&gt;
who check results for some queries and determine [[Relevance (information retrieval)|relevance]] of each result. It is not feasible to check the relevance of all documents, and so typically a technique called pooling is used — only the top few documents, retrieved by some existing ranking models are checked. &lt;!--
  TODO: write something about selection bias caused by pooling
--&gt; Alternatively, training data may be derived automatically by analyzing ''clickthrough logs'' (i.e. search results which got clicks from users),&lt;ref name="Joachims2002"&gt;{{citation
 | author=Joachims, T.
 | journal=Proceedings of the ACM Conference on Knowledge Discovery and Data Mining
 | url=http://www.cs.cornell.edu/people/tj/publications/joachims_02c.pdf
 | title=Optimizing Search Engines using Clickthrough Data
 | year=2002
}}&lt;/ref&gt; ''query chains'',&lt;ref&gt;{{citation
 |author1=Joachims T. |author2=Radlinski F. | title=Query Chains: Learning to Rank from Implicit Feedback
 | url=http://radlinski.org/papers/Radlinski05QueryChains.pdf
 | year=2005
 | journal=Proceedings of the ACM Conference on Knowledge Discovery and Data Mining
|arxiv=cs/0605035 |bibcode=2006cs........5035R }}&lt;/ref&gt; or such search engines' features as Google's [[Google SearchWiki|SearchWiki]].

Training data is used by a learning algorithm to produce a ranking model which computes the relevance of documents for actual queries.

Typically, users expect a search query to complete in a short time (such as a few hundred milliseconds for web search), which makes it impossible to evaluate a complex ranking model on each document in the corpus, and so a two-phase scheme is used.&lt;ref&gt;{{citation
 |author1=B. Cambazoglu |author2=H. Zaragoza |author3=O. Chapelle |author4=J. Chen |author5=C. Liao |author6=Z. Zheng |author7=J. Degenhardt. | title=Early exit optimizations for additive machine learned ranking systems
 | journal=WSDM '10: Proceedings of the Third ACM International Conference on Web Search and Data Mining, 2010. 
 | url=http://olivier.chapelle.cc/pub/wsdm2010.pdf
}}&lt;/ref&gt; First, a small number of potentially relevant documents are identified using simpler retrieval models which permit fast query evaluation, such as the [[vector space model]], [[Standard Boolean model|boolean model]], weighted AND,&lt;ref&gt;{{citation
 | author1=Broder A.
 | author2=Carmel D.
 | author3=Herscovici M.
 | author4=Soffer A.
 | author5=Zien J.
 | title=Efficient query evaluation using a two-level retrieval process
 | journal=Proceedings of the Twelfth International Conference on Information and Knowledge Management
 | year=2003
 | pages=426–434
 | isbn=978-1-58113-723-1
 | url=http://cis.poly.edu/westlab/papers/cntdstrb/p426-broder.pdf
 | access-date=2009-12-15
 | archive-url=https://web.archive.org/web/20090521102038/http://cis.poly.edu/westlab/papers/cntdstrb/p426-broder.pdf
 | archive-date=2009-05-21
 | url-status=dead
 }}&lt;/ref&gt; or [[Okapi BM25|BM25]]. This phase is called ''top-&lt;math&gt;k&lt;/math&gt; document retrieval'' and many heuristics were proposed in the literature to accelerate it, such as using a document's static quality score and tiered indexes.&lt;ref name="manning-q-eval"&gt;{{citation
 |author1=Manning C. |author2=Raghavan P. |author3=Schütze H. | title=Introduction to Information Retrieval
 | publisher=Cambridge University Press
 | year=2008}}. Section [http://nlp.stanford.edu/IR-book/html/htmledition/efficient-scoring-and-ranking-1.html 7.1]&lt;/ref&gt; In the second phase, a more accurate but computationally expensive machine-learned model is used to re-rank these documents.

=== In other areas ===
Learning to rank algorithms have been applied in areas other than information retrieval:
* In [[machine translation]] for ranking a set of hypothesized translations;&lt;ref name="Duh09"&gt;{{citation
 | author=Kevin K. Duh
 | title=Learning to Rank with {{sic|hide=y|Partially|-}}Labeled Data
 | year=2009
 | url=http://ssli.ee.washington.edu/people/duh/thesis/uwthesis.pdf
}}&lt;/ref&gt;
* In [[computational biology]] for ranking candidate 3-D structures in protein structure prediction problem.&lt;ref name="Duh09" /&gt;
* In [[recommender system]]s for identifying a ranked list of related news articles to recommend to a user after he or she has read a current news article.&lt;ref&gt;Yuanhua Lv, Taesup Moon, Pranam Kolari, Zhaohui Zheng, Xuanhui Wang, and Yi Chang, [http://sifaka.cs.uiuc.edu/~ylv2/pub/www11-relatedness.pdf ''Learning to Model Relatedness for News Recommendation''] {{Webarchive|url=https://web.archive.org/web/20110827065356/http://sifaka.cs.uiuc.edu/~ylv2/pub/www11-relatedness.pdf |date=2011-08-27 }}, in International Conference on World Wide Web (WWW), 2011.&lt;/ref&gt;
* In [[software engineering]], learning-to-rank methods have been used for fault localization.&lt;ref&gt;{{Cite book|doi = 10.1109/ICSME.2014.41|chapter = Learning to Combine Multiple Ranking Metrics for Fault Localization|title = 2014 IEEE International Conference on Software Maintenance and Evolution|pages = 191–200|year = 2014|last1 = Xuan|first1 = Jifeng|last2 = Monperrus|first2 = Martin|citeseerx = 10.1.1.496.6829|chapter-url=https://hal.archives-ouvertes.fr/hal-01018935/document|isbn = 978-1-4799-6146-7|s2cid = 11223473}}&lt;/ref&gt;

== Feature vectors ==
For the convenience of MLR algorithms, query-document pairs are usually represented by numerical vectors, which are called ''[[feature vector]]s''. Such an approach is sometimes called ''bag of features'' and is analogous to the [[bag of words]] model and [[vector space model]] used in information retrieval for representation of documents.

Components of such vectors are called ''[[feature (machine learning)|feature]]s'', ''factors'' or ''ranking signals''. They may be divided into three groups (features from [[document retrieval]] are shown as examples):
* ''Query-independent'' or ''static'' features — those features, which depend only on the document, but not on the query. For example, [[PageRank]] or document's length. Such features can be precomputed in off-line mode during indexing. They may be used to compute document's ''static quality score'' (or ''static rank''), which is often used to speed up search query evaluation.&lt;ref name="manning-q-eval" /&gt;&lt;ref&gt;
{{cite conference
 | first=M. |last=Richardson |author2=Prakash, A. |author3=Brill, E.
 | title=Beyond PageRank: Machine Learning for Static Ranking
 | book-title=Proceedings of the 15th International World Wide Web Conference
 | pages=707–715
 | year=2006
 | url=http://research.microsoft.com/en-us/um/people/mattri/papers/www2006/staticrank.pdf
 }}&lt;/ref&gt;
* ''Query-dependent'' or ''dynamic'' features — those features, which depend both on the contents of the document and the query, such as [[TF-IDF]] score or other non-machine-learned ranking functions.
* ''[[Query-level feature]]s'' or ''query features'', which depend only on the query. For example, the number of words in a query.

Some examples of features, which were used in the well-known [https://www.microsoft.com/en-us/research/project/letor-learning-rank-information-retrieval/  LETOR] dataset:
* TF, [[TF-IDF]], [[Okapi BM25|BM25]], and [[language modeling]] scores of document's [[Information retrieval|zone]]s (title, body, anchors text, URL) for a given query;
* Lengths and [[Inverse document frequency|IDF]] sums of document's zones;
* Document's [[PageRank]], [[HITS algorithm|HITS]] ranks and their variants.

Selecting and designing good features is an important area in machine learning, which is called [[feature engineering]].

== Evaluation measures ==
{{main|Evaluation_measures_(information_retrieval)#Offline_metrics}}

There are several measures (metrics) which are commonly used to judge how well an algorithm is doing on training data and to compare the performance of different MLR algorithms. Often a learning-to-rank problem is reformulated as an optimization problem with respect to one of these metrics.

Examples of ranking quality measures:
*[[Mean Average Precision|Mean average precision]] (MAP);
* [[Discounted cumulative gain|DCG]] and [[Normalized discounted cumulative gain|NDCG]];
* [[Precision (information retrieval)|Precision]]@''n'', NDCG@''n'', where "@''n''" denotes that the metrics are evaluated only on top ''n'' documents;
* [[Mean reciprocal rank]];
* [[Kendall's tau]];
* [[Spearman's rank correlation coefficient|Spearman's rho]].

DCG and its normalized variant NDCG are usually preferred in academic research when multiple levels of relevance are used.&lt;ref&gt;http://www.stanford.edu/class/cs276/handouts/lecture15-learning-ranking.ppt&lt;/ref&gt; Other metrics such as MAP, MRR and precision, are defined only for binary judgments.

Recently, there have been proposed several new evaluation metrics which claim to model user's satisfaction with search results better than the DCG metric:
* Expected reciprocal rank (ERR);&lt;ref&gt;{{citation
|author1=Olivier Chapelle |author2=Donald Metzler |author3=Ya Zhang |author4=Pierre Grinspan |title=Expected Reciprocal Rank for Graded Relevance
|url=http://research.yahoo.com/files/err.pdf |archive-url=https://web.archive.org/web/20120224053008/http://research.yahoo.com/files/err.pdf |url-status=dead |archive-date=2012-02-24 |journal=CIKM
|year=2009
}}&lt;/ref&gt;
* [[Yandex]]'s pfound.&lt;ref&gt;{{citation
|author1=Gulin A. |author2=Karpovich P. |author3=Raskovalov D. |author4=Segalovich I. |title=Yandex at ROMIP'2009: optimization of ranking algorithms by machine learning methods
|url=http://romip.ru/romip2009/15_yandex.pdf
|journal=Proceedings of ROMIP'2009
|year=2009
|pages=163–168
}} (in Russian)&lt;/ref&gt;
Both of these metrics are based on the assumption that the user is more likely to stop looking at search results after examining a more relevant document, than after a less relevant document.

== Approaches ==
{{Expand section|date=December 2009}}
Tie-Yan Liu of [[Microsoft Research Asia]] has analyzed existing algorithms for learning to rank problems in his paper "Learning to Rank for Information Retrieval".&lt;ref name="liu" /&gt; He categorized them into three groups by their input representation and [[loss function]]: the pointwise, pairwise, and listwise approach. In practice, listwise approaches often outperform pairwise approaches and pointwise approaches. This statement was further supported by a large scale experiment on the performance of different learning-to-rank methods on a large collection of benchmark data sets.&lt;ref name="Tax2015"&gt;{{citation |author1=Tax, Niek |author2=Bockting, Sander |author3=Hiemstra, Djoerd |journal=Information Processing &amp; Management |volume=51 |issue=6 |title=A cross-benchmark comparison of 87 learning to rank methods |pages=757–772 |year=2015 |url=http://wwwhome.cs.utwente.nl/~hiemstra/papers/ipm2015.pdf |doi=10.1016/j.ipm.2015.07.002 |access-date=2017-10-15 |archive-url=https://web.archive.org/web/20170809115827/http://wwwhome.cs.utwente.nl/~hiemstra/papers/ipm2015.pdf |archive-date=2017-08-09 |url-status=dead }}&lt;/ref&gt;

=== Pointwise approach ===
In this case, it is assumed that each query-document pair in the training data has a numerical or ordinal score. Then the learning-to-rank problem can be approximated by a regression problem — given a single query-document pair, predict its score.

A number of existing [[Supervised learning|supervised]] machine learning algorithms can be readily used for this purpose. [[Ordinal regression]] and [[classification (machine learning)|classification]] algorithms can also be used in pointwise approach when they are used to predict the score of a single query-document pair, and it takes a small, finite number of values.

=== Pairwise approach ===
In this case, the learning-to-rank problem is approximated by a classification problem — learning a [[binary classifier]] that can tell which document is better in a given pair of documents. The goal is to minimize the average number of [[Permutation#Inversions|inversions]] in ranking.

=== Listwise approach ===
These algorithms try to directly optimize the value of one of the above evaluation measures, averaged over all queries in the training data. This is difficult because most evaluation measures are not continuous functions with respect to ranking model's parameters, and so continuous approximations or bounds on evaluation measures have to be used.

=== List of methods ===
A partial list of published learning-to-rank algorithms is shown below with years of first publication of each method:
:{|class="wikitable sortable"
! Year || Name || Type || Notes
|-
| 1989 || OPRF &lt;ref name="Fuhr1989"&gt;{{citation
 | last=Fuhr
 | first=Norbert
 | journal=ACM Transactions on Information Systems
 | title=Optimum polynomial retrieval functions based on the probability ranking principle
 | volume=7
 | number=3
 | pages=183–204 
 | year=1989
 | doi=10.1145/65943.65944
| s2cid=16632383
 }}&lt;/ref&gt; || &lt;span style="display:none"&gt;2&lt;/span&gt; pointwise || Polynomial regression (instead of machine learning, this work refers to pattern recognition, but the idea is the same)
|-
| 1992 || SLR &lt;ref name="Cooperetal1992"&gt;{{citation
 |author1=Cooper, William S. |author2=Gey, Frederic C. |author3=Dabney, Daniel P. | journal=SIGIR '92 Proceedings of the 15th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval 
 | title=Probabilistic retrieval based on staged logistic regression
 | pages=198–210 
 | year=1992
 | doi=10.1145/133160.133199
|isbn=978-0897915236 |s2cid=125993 }}&lt;/ref&gt;   || &lt;span style="display:none"&gt;2&lt;/span&gt; pointwise || Staged logistic regression
|-
| 1994 || NMOpt &lt;ref name="Bartelletal1994"&gt;{{citation
 |author1=Bartell, Brian T. |author2=Cottrell Garrison W. |author3=Belew, Richard K. | journal=SIGIR '94 Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval 
 | title=Automatic Combination of Multiple Ranked Retrieval Systems
 | pages=173-181 
 | year=1994
 | url=https://link.springer.com/chapter/10.1007/978-1-4471-2099-5_18
|isbn=978-0387198897 }}&lt;/ref&gt;   || &lt;span style="display:none"&gt;2&lt;/span&gt; listwise || Non-Metric Optimization
|-
| 1999 || [http://www-stat.stanford.edu/~jhf/ftp/trebst.ps MART] (Multiple Additive Regression Trees) || &lt;span style="display:none"&gt;2&lt;/span&gt; pairwise || 
|-
| 2000 || [http://research.microsoft.com/apps/pubs/default.aspx?id=65610 Ranking SVM] (RankSVM) || &lt;span style="display:none"&gt;2&lt;/span&gt; pairwise ||  A more recent exposition is in,&lt;ref name="Joachims2002" /&gt; which describes an application to ranking using clickthrough logs.
|-
| 2002 || Pranking&lt;ref&gt;{{cite journal | citeseerx = 10.1.1.20.378 | title = Pranking }}&lt;/ref&gt; || &lt;span style="display:none"&gt;1&lt;/span&gt; pointwise || Ordinal regression.
|-
| 2003 &lt;!-- or 1998? --&gt; || [http://jmlr.csail.mit.edu/papers/volume4/freund03a/freund03a.pdf RankBoost] || &lt;span style="display:none"&gt;2&lt;/span&gt; pairwise ||
|-
| 2005 || [https://www.microsoft.com/en-us/research/wp-content/uploads/2005/08/icml_ranking.pdf RankNet] || &lt;span style="display:none"&gt;2&lt;/span&gt; pairwise ||
|-
| 2006 || [http://research.microsoft.com/en-us/people/tyliu/cao-et-al-sigir2006.pdf IR-SVM] || &lt;span style="display:none"&gt;2&lt;/span&gt; pairwise || Ranking SVM with query-level normalization in the loss function.
|-
| 2006 || [http://research.microsoft.com/en-us/um/people/cburges/papers/lambdarank.pdf LambdaRank] || pairwise/listwise || RankNet in which pairwise loss function is multiplied by the change in the IR metric caused by a swap.
|-
| 2007 || [http://research.microsoft.com/en-us/people/junxu/sigir2007-adarank.pdf AdaRank] || &lt;span style="display:none"&gt;3&lt;/span&gt; listwise ||
|-
| 2007 || [http://research.microsoft.com/apps/pubs/default.aspx?id=70364 FRank] || &lt;span style="display:none"&gt;2&lt;/span&gt; pairwise || Based on RankNet, uses a different loss function - fidelity loss.
|-
| 2007 || [http://www.cc.gatech.edu/~zha/papers/fp086-zheng.pdf GBRank] || &lt;span style="display:none"&gt;2&lt;/span&gt; pairwise || 
|-
| 2007 || [http://research.microsoft.com/apps/pubs/default.aspx?id=70428 ListNet] || &lt;span style="display:none"&gt;3&lt;/span&gt; listwise ||
|-
| 2007 || [http://research.microsoft.com/apps/pubs/default.aspx?id=68128 McRank] || &lt;span style="display:none"&gt;1&lt;/span&gt; pointwise ||
|-
| 2007 || [https://web.archive.org/web/20100807162456/http://www.stat.rutgers.edu/~tzhang/papers/nips07-ranking.pdf QBRank] || &lt;span style="display:none"&gt;2&lt;/span&gt; pairwise ||
|-
| 2007 || [http://research.microsoft.com/en-us/people/hangli/qin_ipm_2008.pdf RankCosine] || &lt;span style="display:none"&gt;3&lt;/span&gt; listwise ||
|-
| 2007 || RankGP&lt;ref&gt;{{cite journal | citeseerx = 10.1.1.90.220 | title = RankGP }}&lt;/ref&gt; || &lt;span style="display:none"&gt;3&lt;/span&gt; listwise ||
|-
| 2007 || [http://staff.cs.utu.fi/~aatapa/publications/inpPaTsAiBoSa07a.pdf RankRLS] || &lt;span style="display:none"&gt;2&lt;/span&gt; pairwise ||
Regularized least-squares based ranking. The work is extended in
&lt;ref name=pahikkala2009efficient&gt;{{Citation|last=Pahikkala|first=Tapio |author2=Tsivtsivadze, Evgeni |author3=Airola, Antti |author4=Järvinen, Jouni |author5=Boberg, Jorma |title=An efficient algorithm for learning to rank from preference graphs|journal=Machine Learning|year=2009|volume=75|issue=1|pages=129–165|doi=10.1007/s10994-008-5097-z|postscript=.|doi-access=free}}&lt;/ref&gt; to learning to rank from general preference graphs.
|-
| 2007 || [http://www.cs.cornell.edu/People/tj/publications/yue_etal_07a.pdf SVM&lt;sup&gt;map&lt;/sup&gt;] || &lt;span style="display:none"&gt;3&lt;/span&gt; listwise ||
|-
| 2008 || [http://research.microsoft.com/pubs/69536/tr-2008-109.pdf LambdaSMART/LambdaMART]  || pairwise/listwise || Winning entry in the recent Yahoo Learning to Rank competition used an ensemble of LambdaMART models. Based on MART (1999)&lt;ref&gt;C. Burges. (2010). [https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf From RankNet to LambdaRank to LambdaMART: An Overview].&lt;/ref&gt; “LambdaSMART”, for Lambda-submodel-MART, or LambdaMART for the case with no submodel [https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-2008-109.pdf (https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-2008-109.pdf]).
|-
| 2008 || [http://research.microsoft.com/en-us/people/tyliu/icml-listmle.pdf ListMLE] || &lt;span style="display:none"&gt;3&lt;/span&gt; listwise || Based on ListNet.
|-
| 2008 || [http://research.microsoft.com/en-us/people/junxu/sigir2008-directoptimize.pdf PermuRank] || &lt;span style="display:none"&gt;3&lt;/span&gt; listwise ||
|-
| 2008 || [http://research.microsoft.com/apps/pubs/?id=63585 SoftRank] || &lt;span style="display:none"&gt;3&lt;/span&gt; listwise ||
|-
| 2008 || [http://www.cs.pitt.edu/~valizadegan/Publications/ranking_refinement.pdf Ranking Refinement]&lt;ref&gt;Rong Jin, Hamed Valizadegan, Hang Li, [http://www.cs.pitt.edu/~valizadegan/Publications/ranking_refinement.pdf ''Ranking Refinement and Its Application for Information Retrieval''], in International Conference on World Wide Web (WWW), 2008.&lt;/ref&gt; || &lt;span style="display:none"&gt;2&lt;/span&gt; pairwise || A semi-supervised approach to learning to rank that uses Boosting.
|-
| 2008 || [https://web.archive.org/web/20100723152841/http://www-connex.lip6.fr/~amini/SSRankBoost/ SSRankBoost]&lt;ref&gt;Massih-Reza Amini, Vinh Truong, Cyril Goutte, [http://www-connex.lip6.fr/~amini/Publis/SemiSupRanking_sigir08.pdf ''A Boosting Algorithm for Learning Bipartite Ranking Functions with Partially Labeled Data''] {{Webarchive|url=https://web.archive.org/web/20100802093049/http://www-connex.lip6.fr/~amini/Publis/SemiSupRanking_sigir08.pdf |date=2010-08-02 }}, International ACM SIGIR conference, 2008. The [http://www-connex.lip6.fr/~amini/SSRankBoost/ code] {{Webarchive|url=https://web.archive.org/web/20100723152841/http://www-connex.lip6.fr/~amini/SSRankBoost/ |date=2010-07-23 }} is available for research purposes.&lt;/ref&gt;  || &lt;span style="display:none"&gt;2&lt;/span&gt; pairwise|| An extension of RankBoost to learn with partially labeled data (semi-supervised learning to rank)
|-
| 2008 || [http://phd.dii.unisi.it/PosterDay/2009/Tiziano_Papini.pdf SortNet]&lt;ref&gt;Leonardo Rigutini, Tiziano Papini, Marco Maggini, Franco Scarselli, [http://research.microsoft.com/en-us/um/beijing/events/lr4ir-2008/PROCEEDINGS-LR4IR%202008.PDF "SortNet: learning to rank by a neural-based sorting algorithm"], SIGIR 2008 workshop: Learning to Rank for Information Retrieval, 2008&lt;/ref&gt; || &lt;span style="display:none"&gt;2&lt;/span&gt; pairwise|| SortNet, an adaptive ranking algorithm which orders objects using a neural network as a comparator. 
|-
| 2009 || [https://web.archive.org/web/20101122085504/http://itcs.tsinghua.edu.cn/papers/2009/2009031.pdf MPBoost] || &lt;span style="display:none"&gt;2&lt;/span&gt; pairwise || Magnitude-preserving variant of RankBoost. The idea is that the more unequal are labels of a pair of documents, the harder should the algorithm try to rank them.
|-
| 2009 || [https://web.archive.org/web/20130620070239/http://machinelearning.org/archive/icml2009/papers/498.pdf BoltzRank] || &lt;span style="display:none"&gt;3&lt;/span&gt; listwise || Unlike earlier methods, BoltzRank produces a ranking model that looks during query time not just at a single document, but also at pairs of documents.
|-
| 2009 || [http://www.iis.sinica.edu.tw/papers/whm/8820-F.pdf BayesRank] || &lt;span style="display:none"&gt;3&lt;/span&gt; listwise || A method combines Plackett-Luce Model and neural network to minimize the expected Bayes risk, related to NDCG, from the decision-making aspect.
|-
| 2010 || [https://people.cs.pitt.edu/~valizadegan/Publications/NDCG_Boost.pdf NDCG Boost]&lt;ref&gt;Hamed Valizadegan, Rong Jin, Ruofei Zhang, Jianchang Mao, [http://www.cs.pitt.edu/~valizadegan/Publications/NDCG_Boost.pdf ''Learning to Rank by Optimizing NDCG Measure''], in Proceeding of Neural Information Processing Systems (NIPS), 2010.&lt;/ref&gt; || &lt;span style="display:none"&gt;3&lt;/span&gt; listwise || A boosting approach to optimize NDCG.
|-
| 2010 || [https://arxiv.org/abs/1001.4597 GBlend] || &lt;span style="display:none"&gt;2&lt;/span&gt; pairwise || Extends GBRank to the learning-to-blend problem of jointly solving multiple learning-to-rank problems with some shared features.
|-
| 2010 || [https://web.archive.org/web/20100601205607/http://wume.cse.lehigh.edu/~ovd209/wsdm/proceedings/docs/p151.pdf IntervalRank] || &lt;span style="display:none"&gt;2&lt;/span&gt; pairwise &amp; listwise || 
|-
| 2010 || [http://www.eecs.tufts.edu/~dsculley/papers/combined-ranking-and-regression.pdf CRR] || &lt;span style="display:none"&gt;2&lt;/span&gt; pointwise &amp; pairwise || Combined Regression and Ranking. Uses [[stochastic gradient descent]] to optimize a linear combination of a pointwise quadratic loss and a pairwise hinge loss from Ranking SVM.
|-
| 2014 || [https://storage.googleapis.com/pub-tools-public-publication-data/pdf/42242.pdf LCR] || &lt;span style="display:none"&gt;2&lt;/span&gt; pairwise || Applied local low-rank assumption on collaborative ranking. Received best student paper award at WWW'14.
|-
|2015
|[https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Schroff_FaceNet_A_Unified_2015_CVPR_paper.pdf FaceNet]
|pairwise
|Ranks face images with the triplet metric via deep convolutional network.
|-
|2016
|[https://arxiv.org/abs/1603.02754 XGBoost]
|pairwise
|Supports various ranking objectives and evaluation metrics.
|-
|2017 || [http://eprints.nottingham.ac.uk/41540/1/dls_sac2017.pdf ES-Rank] || listwise || Evolutionary Strategy Learning to Rank technique with 7 fitness evaluation metrics
|-
|2018
|[http://www.jmlr.org/papers/volume19/17-179/17-179.pdf PolyRank]&lt;ref&gt;{{Cite journal|last1=Davidov|first1=Ori|last2=Ailon|first2=Nir|last3=Oliveira|first3=Ivo F. D.|date=2018|title=A New and Flexible Approach to the Analysis of Paired Comparison Data|url=http://jmlr.org/papers/v19/17-179.html|journal=Journal of Machine Learning Research|volume=19|issue=60|pages=1–29|issn=1533-7928}}&lt;/ref&gt;
|pairwise
|Learns simultaneously the ranking and the underlying generative model from pairwise comparisons.
|-
|2018 || [https://arxiv.org/abs/1803.05796 FATE-Net/FETA-Net] &lt;ref&gt;{{cite arXiv |last1=Pfannschmidt |first1=Karlson |last2=Gupta |first2=Pritha | last3=Hüllermeier |first3=Eyke |date=2018 |title=Deep Architectures for Learning Context-dependent Ranking Functions |class=stat.ML |eprint=1803.05796}}&lt;/ref&gt;|| listwise || End-to-end trainable architectures, which explicitly take all items into account to model context effects.
|-
|2019
|[http://cs-people.bu.edu/fcakir/papers/fastap_cvpr2019.pdf FastAP] &lt;ref&gt;Fatih Cakir, Kun He, Xide Xia, Brian Kulis, Stan Sclaroff, [http://cs-people.bu.edu/fcakir/papers/fastap_cvpr2019.pdf ''Deep Metric Learning to Rank''], In Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019.&lt;/ref&gt;
|listwise
|Optimizes Average Precision to learn deep embeddings
|-
|2019
|[https://arxiv.org/abs/1905.06452 Mulberry] || listwise &amp; hybrid || Learns ranking policies maximizing multiple metrics across the entire dataset
|-
|2019 
|[https://ecmlpkdd2019.org/downloads/paper/400.pdf DirectRanker] || pairwise || Generalisation of the RankNet architecture 
|}

Note: as most [[supervised learning]] algorithms can be applied to pointwise case, only those methods which are specifically designed with ranking in mind are shown above.

== History ==
[[Norbert Fuhr]] introduced the general idea of MLR in 1992, describing learning approaches in information retrieval as a generalization of parameter estimation;&lt;ref name="Fuhr1992"&gt;{{citation
 | last=Fuhr
 | first=Norbert
 | journal=Computer Journal
 | title=Probabilistic Models in Information Retrieval
 | volume=35
 | number=3
 | pages=243–255
 | year=1992
 | doi=10.1093/comjnl/35.3.243
| doi-access=free
 }}&lt;/ref&gt; a specific variant of this approach (using [[polynomial regression]]) had been published by him three years earlier.&lt;ref name="Fuhr1989" /&gt; Bill Cooper proposed [[logistic regression]] for the same purpose in 1992 &lt;ref name="Cooperetal1992" /&gt; and used it with his  [[University of California at Berkeley|Berkeley]] research group to train a successful ranking function for [[Text Retrieval Conference|TREC]].  Manning et al.&lt;ref&gt;{{citation |author1=Manning C. |author2=Raghavan P. |author3=Schütze H. |title=Introduction to Information Retrieval |publisher=Cambridge University Press |year=2008}}. Sections [http://nlp.stanford.edu/IR-book/html/htmledition/references-and-further-reading-7.html 7.4] and [http://nlp.stanford.edu/IR-book/html/htmledition/references-and-further-reading-15.html 15.5]&lt;/ref&gt;  suggest that these early works achieved limited results in their time due to little available training data and poor machine learning techniques.

Several conferences, such as [[Neural Information Processing Systems|NIPS]], [[Special Interest Group on Information Retrieval|SIGIR]] and [[International Conference on Machine Learning|ICML]] had workshops devoted to the learning-to-rank problem since mid-2000s (decade).

=== Practical usage by search engines ===
Commercial [[web search engine]]s began using machine learned ranking systems since the 2000s (decade). One of the first search engines to start using it was [[AltaVista]] (later its technology was acquired by [[Overture Services, Inc.|Overture]], and then [[Yahoo]]), which launched a [[gradient boosting]]-trained ranking function in April 2003.&lt;ref&gt;Jan O. Pedersen. [http://jopedersen.com/Presentations/The_MLR_Story.pdf The MLR Story] {{Webarchive|url=https://web.archive.org/web/20110713120113/http://jopedersen.com/Presentations/The_MLR_Story.pdf |date=2011-07-13 }}&lt;/ref&gt;&lt;ref&gt;{{US Patent|7197497}}&lt;/ref&gt;

[[Bing (search engine)|Bing]]'s search is said to be powered by [https://www.microsoft.com/en-us/research/wp-content/uploads/2005/08/icml_ranking.pdf RankNet] algorithm,&lt;ref&gt;[http://www.bing.com/community/blogs/search/archive/2009/06/01/user-needs-features-and-the-science-behind-bing.aspx?PageIndex=4 Bing Search Blog: User Needs, Features and the Science behind Bing]&lt;/ref&gt;{{when|date=February 2014}} which was invented at [[Microsoft Research]] in 2005.

In November 2009 a Russian search engine [[Yandex]] announced&lt;ref name="snezhinsk"&gt;[http://webmaster.ya.ru/replies.xml?item_no=5707&amp;ncrnd=5118 Yandex corporate blog entry about new ranking model "Snezhinsk"] (in Russian)&lt;/ref&gt; that it had significantly increased its search quality due to deployment of a new proprietary [[MatrixNet]] algorithm, a variant of [[gradient boosting]] method which uses oblivious decision trees.&lt;ref&gt;The algorithm wasn't disclosed, but a few details were made public in [http://download.yandex.ru/company/experience/GDD/Zadnie_algoritmy_Karpovich.pdf] and [http://download.yandex.ru/company/experience/searchconf/Searchconf_Algoritm_MatrixNet_Gulin.pdf].&lt;/ref&gt; Recently they have also sponsored a machine-learned ranking competition "Internet Mathematics 2009"&lt;ref&gt;{{Cite web |url=http://imat2009.yandex.ru/academic/mathematic/2009/en/ |title=Yandex's Internet Mathematics 2009 competition page |access-date=2009-11-11 |archive-url=https://web.archive.org/web/20150317144535/http://imat2009.yandex.ru/academic/mathematic/2009/en/ |archive-date=2015-03-17 |url-status=dead }}&lt;/ref&gt; based on their own search engine's production data. Yahoo has announced a similar competition in 2010.&lt;ref&gt;{{Cite web |url=http://learningtorankchallenge.yahoo.com/ |title=Yahoo Learning to Rank Challenge |access-date=2010-02-26 |archive-url=https://web.archive.org/web/20100301011649/http://learningtorankchallenge.yahoo.com/ |archive-date=2010-03-01 |url-status=dead }}&lt;/ref&gt;

As of 2008, [[Google]]'s [[Peter Norvig]] denied that their search engine exclusively relies on machine-learned ranking.&lt;ref&gt;{{cite web
 |url         = http://anand.typepad.com/datawocky/2008/05/are-human-experts-less-prone-to-catastrophic-errors-than-machine-learned-models.html
 |archive-url  = https://www.webcitation.org/5sq8irWNM?url=http://anand.typepad.com/datawocky/2008/05/are-human-experts-less-prone-to-catastrophic-errors-than-machine-learned-models.html
 |archive-date = 2010-09-18
 |title       = Are Machine-Learned Models Prone to Catastrophic Errors?
 |date        = 2008-05-24
 |last        = Rajaraman
 |first       = Anand
 |author-link  = Anand Rajaraman
 |access-date = 2009-11-11
 |url-status    = live
}}&lt;/ref&gt; [[Cuil]]'s CEO, Tom Costello, suggests that they prefer hand-built models because they can outperform machine-learned models when measured against metrics like click-through rate or time on landing page, which is because machine-learned models "learn what people say they like, not what people actually like".&lt;ref&gt;{{cite web
  | url = http://www.cuil.com/info/blog/2009/06/26/so-how-is-bing-doing
  | archive-url = https://archive.is/20090627213358/http://www.cuil.com/info/blog/2009/06/26/so-how-is-bing-doing
  | archive-date = 2009-06-27
  | title = Cuil Blog: So how is Bing doing?
  | date = 2009-06-26
  | last = Costello
  | first = Tom}}&lt;/ref&gt;

In January 2017 the technology was included in the [[Open-source software|open source]] search engine [[Apache Solr]]™,&lt;ref&gt;{{Cite news|url=https://www.techatbloomberg.com/blog/bloomberg-integrated-learning-rank-apache-solr/|title=How Bloomberg Integrated Learning-to-Rank into Apache Solr {{!}} Tech at Bloomberg|date=2017-01-23|work=Tech at Bloomberg|access-date=2017-02-28|language=en-US}}&lt;/ref&gt; thus making machine learned search rank widely accessible also for enterprise search.

== Vulnerabilities ==

Similar to recognition applications in [[computer vision]], recent neural network based ranking algorithms are also found to be susceptible to covert [[generative adversarial network | adversarial attacks]], both on the candidates and the queries.&lt;ref name="Zhou Niu Wang Zhang 2020"&gt;{{cite arXiv | last1=Zhou | first1=Mo | last2=Niu | first2=Zhenxing | last3=Wang | first3=Le | last4=Zhang | first4=Qilin | last5=Hua | first5=Gang | title=Adversarial Ranking Attack and Defense | year=2020 | class=cs.CV | eprint=2002.11293v2 }}&lt;/ref&gt; With small perturbations imperceptible to human beings, ranking order could be arbitrarily altered. In addition, model-agnostic transferable adversarial examples are found to be possible, which enables black-box adversarial attacks on deep ranking systems without requiring access to their underlying implementations.&lt;ref name="Zhou Niu Wang Zhang 2020"&gt;{{cite arXiv | last1=Zhou | first1=Mo | last2=Niu | first2=Zhenxing | last3=Wang | first3=Le | last4=Zhang | first4=Qilin | last5=Hua | first5=Gang | title=Adversarial Ranking Attack and Defense | year=2020 | class=cs.CV | eprint=2002.11293v2 }}&lt;/ref&gt;&lt;ref name="Li Ji Liu Hong pp. 4899–4908"&gt;{{cite web | last1=Li | first1=Jie | last2=Ji | first2=Rongrong | last3=Liu | first3=Hong | last4=Hong | first4=Xiaopeng | last5=Gao | first5=Yue | last6=Tian | first6=Qi | title=Universal Perturbation Attack Against Image Retrieval | website=International Conference on Computer Vision (ICCV 2019) | url=https://openaccess.thecvf.com/content_ICCV_2019/html/Li_Universal_Perturbation_Attack_Against_Image_Retrieval_ICCV_2019_paper.html | pages=4899–4908}}&lt;/ref&gt; 

Conversely, the robustness of such ranking systems can be improved via adversarial defenses such as the Madry defense.&lt;ref name="Madry Makelov Schmidt Tsipras 2017"&gt;{{cite arXiv | last1=Madry | first1=Aleksander | last2=Makelov | first2=Aleksandar | last3=Schmidt | first3=Ludwig | last4=Tsipras | first4=Dimitris | last5=Vladu | first5=Adrian | title=Towards Deep Learning Models Resistant to Adversarial Attacks | date=2017-06-19 | class=stat.ML | eprint=1706.06083v4 }}&lt;/ref&gt; 

==See also==
*[[Content-based image retrieval]]
*[[Multimedia information retrieval]]
*[[Image retrieval]]
*[[Triplet loss]]

== References ==
{{reflist|2}}


== External links ==
; Competitions and public datasets
* [https://www.microsoft.com/en-us/research/project/letor-learning-rank-information-retrieval/ LETOR: A Benchmark Collection for Research on Learning to Rank for Information Retrieval]
* [https://web.archive.org/web/20150912134134/http://imat2009.yandex.ru/en Yandex's Internet Mathematics 2009]
* [https://web.archive.org/web/20100301011649/http://learningtorankchallenge.yahoo.com/ Yahoo! Learning to Rank Challenge]
* [http://research.microsoft.com/en-us/projects/mslr/default.aspx Microsoft Learning to Rank Datasets]

; Open Source code
* [https://mloss.org/software/view/332/ Parallel C++/MPI implementation of Gradient Boosted Regression Trees for ranking, released September 2011]
* [https://sites.google.com/site/rtranking/ C++ implementation of Gradient Boosted Regression Trees and Random Forests for ranking]
* [http://dlib.net/ml.html#svm_rank_trainer C++ and Python tools for using the SVM-Rank algorithm]
* [https://github.com/apache/lucene-solr/tree/master/solr/contrib/ltr Java implementation in the Apache Solr search engine]

[[Category:Information retrieval techniques]]
[[Category:Machine learning]]
[[Category:Ranking functions]]</text>
      <sha1>ohr2syxvl8y9dp1tty15twsibhpzd2a</sha1>
    </revision>
  </page>
  <page>
    <title>Transduction (machine learning)</title>
    <ns>0</ns>
    <id>960361</id>
    <revision>
      <id>1005260702</id>
      <parentid>1005256559</parentid>
      <timestamp>2021-02-06T20:21:02Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <minor/>
      <comment>Dating maintenance tags: {{Citation needed}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="8114" xml:space="preserve">{{short description|Type of statistical inference}}
{{No footnotes|date=April 2011}}

In [[logic]], [[statistical inference]], and [[supervised learning]],
'''transduction''' or '''transductive inference''' is [[reasoning]] from
observed, specific (training) cases to specific (test) cases. In contrast,
[[induction (philosophy)|induction]] is reasoning from observed training cases
to general rules, which are then applied to the test cases. The distinction is
most interesting in cases where the predictions of the transductive model are
not achievable by any inductive model. Note that this is caused by transductive
inference on different test sets producing mutually inconsistent predictions.

Transduction was introduced by [[Vladimir Vapnik]] in the 1990s, motivated by
his view that transduction is preferable to induction since, according to him, induction requires
solving a more general problem (inferring a function) before solving a more
specific problem (computing outputs for new cases): "When solving a problem of
interest, do not solve a more general problem as an intermediate step. Try to
get the answer that you really need but not a more general one."{{citation needed|date=February 2021}} A similar
observation had been made earlier by [[Bertrand Russell]]:
"we shall reach the conclusion that Socrates is mortal with a greater approach to 
certainty if we make our argument purely inductive than if we go by way of 'all men are mortal' and then use 
deduction" (Russell 1912, chap VII).

An example of learning which is not inductive would be in the case of binary
classification, where the inputs tend to cluster in two groups. A large set of
test inputs may help in finding the clusters, thus providing useful information
about the classification labels. The same predictions would not be obtainable
from a model which induces a function based only on the training cases.  Some
people may call this an example of the closely related [[semi-supervised learning]], since Vapnik's motivation is quite different. An example of an algorithm in this category is the Transductive [[Support Vector Machine]] (TSVM).

A third possible motivation which leads to transduction arises through the need
to approximate. If exact inference is computationally prohibitive, one may at
least try to make sure that the approximations are good at the test inputs. In
this case, the test inputs could come from an arbitrary distribution (not
necessarily related to the distribution of the training inputs), which wouldn't
be allowed in semi-supervised learning. An example of an algorithm falling in
this category is the [[Bayesian Committee Machine]] (BCM).

==Example problem==

The following example problem contrasts some of the unique properties of transduction against induction.

[[File:labels.png]]

A collection of points is given, such that some of the points are labeled (A, B, or C), but most of the points are unlabeled (?). The goal is to predict appropriate labels for all of the unlabeled points.

The inductive approach to solving this problem is to use the labeled points to train a [[supervised learning]] algorithm, and then have it predict labels for all of the unlabeled points. With this problem, however, the supervised learning algorithm will only have five labeled points to use as a basis for building a predictive model. It will certainly struggle to build a model that captures the structure of this data. For example, if a nearest-neighbor algorithm is used, then the points near the middle will be labeled "A" or "C", even though it is apparent that they belong to the same cluster as the point labeled "B".

Transduction has the advantage of being able to consider all of the points, not just the labeled points, while performing the labeling task. In this case, transductive algorithms would label the unlabeled points according to the clusters to which they naturally belong. The points in the middle, therefore, would most likely be labeled "B", because they are packed very close to that cluster.

An advantage of transduction is that it may be able to make better predictions with fewer labeled points, because it uses the natural breaks found in the unlabeled points. One disadvantage of transduction is that it builds no predictive model. If a previously unknown point is added to the set, the entire transductive algorithm would need to be repeated with all of the points in order to predict a label. This can be computationally expensive if the data is made available incrementally in a stream. Further, this might cause the predictions of some of the old points to change (which may be good or bad, depending on the application). A supervised learning algorithm, on the other hand, can label new points instantly, with very little computational cost.

==Transduction algorithms==

Transduction algorithms can be broadly divided into two categories: those that seek to assign discrete labels to unlabeled points, and those that seek to regress continuous labels for unlabeled points. Algorithms that seek to predict discrete labels tend to be derived by adding partial supervision to a [[Cluster analysis|clustering]] algorithm. Two classes of algorithms can be used: flat clustering and hierarchical clustering. The latter can be further subdivided into two categories: those that cluster by partitioning, and those that cluster by agglomerating. Algorithms that seek to predict continuous labels tend to be derived by adding partial supervision to a [[manifold learning]] algorithm.

===Partitioning transduction===

Partitioning transduction can be thought of as top-down transduction. It is a semi-supervised extension of partition-based clustering. It is typically performed as follows:

 Consider the set of all points to be one large partition.
 While any partition P contains two points with conflicting labels:
   Partition P into smaller partitions.
 For each partition P:
   Assign the same label to all of the points in P.

Of course, any reasonable partitioning technique could be used with this algorithm. [[Max flow min cut]] partitioning schemes are very popular for this purpose.

===Agglomerative transduction===

Agglomerative transduction can be thought of as bottom-up transduction. It is a semi-supervised extension of agglomerative clustering. It is typically performed as follows:

 Compute the pair-wise distances, D, between all the points.
 Sort D in ascending order.
 Consider each point to be a cluster of size 1.
 For each pair of points {a,b} in D:
   If (a is unlabeled) or (b is unlabeled) or (a and b have the same label)
     Merge the two clusters that contain a and b.
     Label all points in the merged cluster with the same label.

===Manifold transduction===

Manifold-learning-based transduction is still a very young field of research.

==See also==

* [[Epilogism]]

==References==

* V. N. Vapnik. ''Statistical learning theory''. New York: Wiley, 1998. ''(See pages 339-371)''
* V. Tresp. ''A Bayesian committee machine'', Neural Computation, 12, 2000, [http://www.tresp.org/papers/bcm6.pdf pdf].
* B. Russell. ''The Problems of Philosophy'', Home University Library, 1912. [http://www.ditext.com/russell/rus7.html].

==External links==
* A Gammerman, V. Vovk, V. Vapnik (1998). "[http://www1.cs.columbia.edu/~dplewis/candidacy/gammerman98learning.pdf Learning by Transduction]." An early explanation of transductive learning.
* "[http://www.kyb.mpg.de/ssl-book/discussion.pdf A Discussion of Semi-Supervised Learning and Transduction]," Chapter 25 of ''Semi-Supervised Learning,'' Olivier Chapelle, Bernhard Schölkopf and Alexander Zien, eds. (2006). MIT Press. A discussion of the difference between SSL and transduction.
* [http://waffles.sourceforge.net Waffles] is an open source C++ library of machine learning algorithms, including transduction algorithms, also [[Waffles (machine learning)|Waffles]].
* [http://www.cs.cornell.edu/people/tj/svm_light/ SVMlight] is a general purpose SVM package that includes the transductive SVM option.

{{DEFAULTSORT:Transduction (Machine Learning)}}
[[Category:Machine learning]]</text>
      <sha1>5mkndqkdjwtlp5nab8m56w4461lxm6s</sha1>
    </revision>
  </page>
  <page>
    <title>Cross-validation (statistics)</title>
    <ns>0</ns>
    <id>416612</id>
    <revision>
      <id>1004443563</id>
      <parentid>1003796599</parentid>
      <timestamp>2021-02-02T16:43:39Z</timestamp>
      <contributor>
        <username>Suriname0</username>
        <id>35897031</id>
      </contributor>
      <comment>Importing Wikidata [[Wikipedia:Short description|short description]]: "Statistical model validation technique" ([[Wikipedia:Shortdesc helper|Shortdesc helper]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="39822" xml:space="preserve">{{short description|Statistical model validation technique}}
{{More citations needed|date=August 2017}}

[[File:K-fold cross validation EN.svg|thumb|250px|right|Diagram of k-fold cross-validation.]]
'''Cross-validation''',&lt;ref&gt;{{cite journal |last=Allen | first=David M |year=1974 |title=The Relationship between Variable Selection and Data Agumentation and a Method for Prediction |journal=Technometrics |volume=16 |issue=1 |pages=125–127 |doi=10.2307/1267500| jstor=1267500 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last=Stone | first=M |year=1974 |title=Cross-Validatory Choice and Assessment of Statistical Predictions |journal=Journal of the Royal Statistical Society: Series B (Methodological) |volume=36 |issue=2 |pages=111–147 |doi=10.1111/j.2517-6161.1974.tb00994.x}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last=Stone | first=M |year=1977 |title=An Asymptotic Equivalence of Choice of Model by Cross-Validation and Akaike's Criterion |journal=Journal of the Royal Statistical Society: Series B (Methodological) |volume=39 |issue=1 |pages=44–47 | jstor=2984877 }}}&lt;/ref&gt; sometimes called '''rotation estimation'''&lt;ref&gt;{{cite book |last=Geisser |first=Seymour |year=1993 |title=Predictive Inference |publisher=Chapman and Hall |location=New York, NY |isbn=978-0-412-03471-8 }}&lt;/ref&gt;&lt;ref name="Kohavi95"&gt;{{cite journal |last=Kohavi |first=Ron |year=1995 |title=A study of cross-validation and bootstrap for accuracy estimation and model selection |journal=Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence |citeseerx = 10.1.1.48.529 |volume=2 |issue=12 |pages=1137–1143 | publisher = Morgan Kaufmann | location = San Mateo, CA }}&lt;/ref&gt;&lt;ref name="Devijver82"&gt;{{cite book | last1 = Devijver | first1 = Pierre A. | last2 = Kittler | first2 = Josef | title = Pattern Recognition: A Statistical Approach | publisher = Prentice-Hall | location = London, GB | date = 1982 |isbn=0-13-654236-0 }}&lt;/ref&gt; or '''out-of-sample testing''', is any of various similar [[model validation]] techniques for assessing how the results of a [[statistics|statistical]] analysis will [[Generalization error|generalize]] to an independent data set. It is mainly used in settings where the goal is prediction, and one wants to estimate how [[accuracy|accurately]] a [[predictive modelling|predictive model]] will perform in practice.  In a prediction problem, a model is usually given a dataset of ''known data'' on which training is run (''training dataset''), and a dataset of ''unknown data'' (or ''first seen'' data) against which the model is tested (called the [[validation set|validation dataset]] or ''testing set'').&lt;ref&gt;{{cite web |title= What is the difference between test set and validation set? |url=https://stats.stackexchange.com/q/19051 |first=Alexander |last=Galkin |date=November 28, 2011 |access-date=10 October 2018}}&lt;/ref&gt;&lt;ref name="Newbie question: Confused about train, validation and test data!"&gt;{{cite web|url=http://www.heatonresearch.com/node/1823 |title=Newbie question: Confused about train, validation and test data! |access-date=2013-11-14 |url-status=bot: unknown |archive-url=https://web.archive.org/web/20150314221014/http://www.heatonresearch.com/node/1823 |archive-date=2015-03-14 }}&lt;/ref&gt; The goal of cross-validation is to test the model's ability to predict new data that was not used in estimating it, in order to flag problems like [[overfitting]] or [[selection bias]]&lt;ref&gt;{{Cite journal|url=http://www.jmlr.org/papers/volume11/cawley10a/cawley10a.pdf|title = On Over-fitting in Model Selection and Subsequent Selection Bias in Performance Evaluation|last1 = Cawley|first1 = Gavin C.|last2 = Talbot|first2 = Nicola L. C. |publisher = Journal of Machine Learning Research|year = 2010|pages =2079–2107|volume=11 }}&lt;/ref&gt; and to give an insight on how the model will generalize to an independent dataset (i.e., an unknown dataset, for instance from a real problem).

One round of cross-validation involves [[partition of a set|partitioning]] a [[statistical sample|sample]] of [[data]] into [[Complement (set theory)|complementary]] subsets, performing the analysis on one subset (called the ''training set''), and validating the analysis on the other subset (called the ''validation set'' or ''testing set''). To reduce [[variance|variability]], in most methods multiple rounds of cross-validation are performed using different partitions, and the validation results are combined (e.g. averaged) over the rounds to give an estimate of the model's predictive performance.

In summary, cross-validation combines (averages) measures of [[Goodness of fit|fitness]] in prediction to derive a more accurate estimate of model prediction performance.&lt;ref name=":0"&gt;{{Cite journal|title = Ensemble Methods in Data Mining: Improving Accuracy Through Combining Predictions|journal = Synthesis Lectures on Data Mining and Knowledge Discovery|volume = 2|last = Grossman|first = Robert|publisher = Morgan &amp; Claypool|year = 2010|pages = 1–126|last2 = Seni|first2 = Giovanni|last3 = Elder|first3 = John|last4 = Agarwal|first4 = Nitin|last5 = Liu|first5 = Huan|doi = 10.2200/S00240ED1V01Y200912DMK002}}&lt;/ref&gt;

==Motivation==

Suppose we have a [[statistical model|model]] with one or more unknown [[parameters]], and a data set to which the model can be fit (the training data set).  The fitting process [[optimization (mathematics)|optimizes]] the model parameters to make the model fit the training data as well as possible.  If we then take an [[independence (probability theory)|independent]] sample of validation data from the same [[statistical population|population]] as where the training data have been taken, it will generally turn out that the model does not fit the validation data as well as it fits the training data. The size of this difference is likely to be large especially when the size of the training data set is small, or when the number of parameters in the model is large.  Cross-validation is a way to estimate the size of this effect.

In linear regression we have [[real number|real]] ''response values'' ''y''&lt;sub&gt;1&lt;/sub&gt;, ..., ''y&lt;sub&gt;n&lt;/sub&gt;'', and ''n'' ''p''-dimensional [[Euclidean vector|vector]] ''covariates'' '''''x'''''&lt;sub&gt;1&lt;/sub&gt;, ..., '''''x'''''&lt;sub&gt;''n''&lt;/sub&gt;.  The components of the vector '''''x'''''&lt;sub&gt;''i''&lt;/sub&gt; are denoted ''x''&lt;sub&gt;''i''1&lt;/sub&gt;, ..., ''x''&lt;sub&gt;''ip''&lt;/sub&gt;. If we use [[least squares]] to fit a function in the form of a [[hyperplane]] '''''ŷ''''' = ''a'' + '''''β'''''&lt;sup&gt;T&lt;/sup&gt;'''''x''''' to the data ('''''x'''''&lt;sub&gt;''i''&lt;/sub&gt;, ''y''&lt;sub&gt;''i''&lt;/sub&gt;)&lt;sub&gt;&amp;nbsp;1&amp;nbsp;≤&amp;nbsp;''i''&amp;nbsp;≤&amp;nbsp;''n''&lt;/sub&gt;, we could then assess the fit using the [[mean squared error]] (MSE). The MSE for given estimated parameter values ''a'' and '''''β''''' on the training set ('''''x'''''&lt;sub&gt;''i''&lt;/sub&gt;, ''y''&lt;sub&gt;''i''&lt;/sub&gt;)&lt;sub&gt;&amp;nbsp;1&amp;nbsp;≤&amp;nbsp;''i''&amp;nbsp;≤&amp;nbsp;''n''&lt;/sub&gt; is defined as

:&lt;math&gt;
MSE = \frac 1 n \sum_{i=1}^n (y_i - \hat{y}_i)^2 = \frac 1 n \sum_{i=1}^n (y_i - a - \boldsymbol\beta^T \mathbf{x}_i)^2 = \frac{1}{n}\sum_{i=1}^n (y_i - a - \beta_1x_{i1} - \dots - \beta_px_{ip})^2
&lt;/math&gt;

If the model is correctly specified, it can be shown under mild assumptions that the [[expected value]] of the MSE for the training set is (''n''&amp;nbsp;&amp;minus;&amp;nbsp;''p''&amp;nbsp;&amp;minus;&amp;nbsp;1)/(''n''&amp;nbsp;+&amp;nbsp;''p''&amp;nbsp;+&amp;nbsp;1)&amp;nbsp;&lt;&amp;nbsp;1 times the expected value of the MSE for the validation set&lt;ref&gt;{{Cite journal|last=Trippa|first=Lorenzo|last2=Waldron|first2=Levi|last3=Huttenhower|first3=Curtis|last4=Parmigiani|first4=Giovanni|date=March 2015|title=Bayesian nonparametric cross-study validation of prediction methods|journal=The Annals of Applied Statistics|language=EN|volume=9|issue=1|pages=402–428|doi=10.1214/14-AOAS798|issn=1932-6157|arxiv=1506.00474|bibcode=2015arXiv150600474T}}&lt;/ref&gt; (the expected value is taken over the distribution of training sets).  Thus if we fit the model and compute the MSE on the training set, we will get an optimistically [[bias (statistics)|biased]] assessment of how well the model will fit an independent data set.  This biased estimate is called the ''in-sample'' estimate of the fit, whereas the cross-validation estimate is an ''out-of-sample'' estimate.

Since in linear regression it is possible to directly compute the factor (''n''&amp;nbsp;&amp;minus;&amp;nbsp;''p''&amp;nbsp;&amp;minus;&amp;nbsp;1)/(''n''&amp;nbsp;+&amp;nbsp;''p''&amp;nbsp;+&amp;nbsp;1) by which the training MSE underestimates the validation MSE under the assumption that the model specification is valid, cross-validation can be used for checking whether the model has been [[overfitting|overfitted]], in which case the MSE in the validation set will substantially exceed its anticipated value. (Cross-validation in the context of linear regression is also useful in that it can be used to select an optimally [[Regularization (mathematics)|regularized]] [[Loss function|cost function]].)
In most other regression procedures (e.g. [[logistic regression]]), there is no simple formula to compute the expected out-of-sample fit. Cross-validation is, thus, a generally applicable way to predict the performance of a model on unavailable data using numerical computation in place of theoretical analysis.

==Types==
Two types of cross-validation can be distinguished: exhaustive and non-exhaustive cross-validation.

===Exhaustive cross-validation ===
Exhaustive cross-validation methods are cross-validation methods which learn and test on all possible ways to divide the original sample into a training and a validation set.

====Leave-p-out cross-validation====
Leave-''p''-out cross-validation ('''LpO CV''') involves using ''p'' observations as the validation set and the remaining observations as the training set. This is repeated on all ways to cut the original sample on a validation set of ''p'' observations and a training set.&lt;ref&gt;{{Cite journal|last=Celisse|first=Alain|date=1 October 2014|title=Optimal cross-validation in density estimation with the $L^{2}$-loss|journal=The Annals of Statistics|language=en|volume=42|issue=5|pages=1879–1910|doi=10.1214/14-AOS1240|issn=0090-5364|arxiv=0811.0802}}&lt;/ref&gt;

LpO cross-validation require training and validating the model &lt;math&gt;C^n_p&lt;/math&gt; times, where ''n'' is the number of observations in the original sample, and where &lt;math&gt;C^n_p&lt;/math&gt; is the [[binomial coefficient]].  For ''p'' &gt; 1 and for even moderately large ''n'', LpO CV can become computationally infeasible.  For example, with ''n'' = 100 and ''p'' = 30, &lt;math&gt;C^{100}_{30} \approx 3\times 10^{25}.&lt;/math&gt;

A variant of LpO cross-validation with p=2 known as leave-pair-out cross-validation has been recommended as a nearly unbiased method for estimating the area under [[ROC curve]] of binary classifiers.&lt;ref&gt;{{Cite journal|last=Airola|first=A.|last2=Pahikkala|first2=T.|last3=Waegeman|first3=W.|last4=De Baets|first4=Bernard|last5=Salakoski|first5=T.|date=2011-04-01|title=An experimental comparison of cross-validation techniques for estimating the area under the ROC curve|journal=Computational Statistics &amp; Data Analysis |language=en|volume=55|issue=4|pages=1828–1844|doi=10.1016/j.csda.2010.11.018}}&lt;/ref&gt;

====Leave-one-out cross-validation====&lt;!-- This section is linked from [[Data mining]] --&gt;
[[File:LOOCV.gif|right|thumb|300x300px|Illustration of leave-one-out cross-validation (LOOCV) when n = 8 observations. A total of 8 models will be trained and tested.|alt=]]
Leave-''one''-out cross-validation ('''LOOCV''') is a particular case of leave-''p''-out cross-validation with ''p''&amp;nbsp;=&amp;nbsp;1.The process looks similar to [[Jackknife resampling|jackknife]]; however, with cross-validation one computes a statistic on the left-out sample(s), while with jackknifing one computes a statistic from the kept samples only.

LOO cross-validation requires less computation time than LpO cross-validation because there are only &lt;math&gt;C^n_1=n&lt;/math&gt; passes rather than &lt;math&gt;C^n_p&lt;/math&gt;. However, &lt;math&gt;n&lt;/math&gt; passes may still require quite a large computation time, in which case other approaches such as k-fold cross validation may be more appropriate.&lt;ref&gt;{{Cite journal|last=Molinaro|first=A. M.|last2=Simon|first2=R.|last3=Pfeiffer|first3=R. M.|date=2005-08-01|title=Prediction error estimation: a comparison of resampling methods|journal=Bioinformatics|language=en|volume=21|issue=15|pages=3301–3307|doi=10.1093/bioinformatics/bti499|pmid=15905277|issn=1367-4803|doi-access=free}}&lt;/ref&gt;

'''Pseudo-Code-Algorithm:'''

'''Input:'''

x, {vector of length N with x-values of incoming points}

y, {vector of length N with y-values of the expected result}

interpolate( x_in, y_in, x_out ), { returns the estimation for point x_out after the model is trained with x_in-y_in pairs}

'''Output:'''

err, {estimate for the prediction error}

'''Steps:'''

  err ← 0
  for i ← 1, ..., N do
    // define the cross-validation subsets
    x_in ← (x[1], ..., x[i − 1], x[i + 1], ..., x[N])
    y_in ← (y[1], ..., y[i − 1], y[i + 1], ..., y[N])
    x_out ← x[i]
    y_out ← interpolate(x_in, y_in, x_out)
    err ← err + (y[i] − y_out)^2
  end for
  err ← err/N

=== Non-exhaustive cross-validation ===
Non-exhaustive cross validation methods do not compute all ways of splitting the original sample. Those methods are approximations of leave-''p''-out cross-validation.

====''k''-fold cross-validation====
[[File:KfoldCV.gif|right|thumb|350x350px|Illustration of k-fold cross-validation when n = 12 observations and k = 3. After data is shuffled, a total of 3 models will be trained and tested.]]

In ''k''-fold cross-validation, the original sample is randomly partitioned into ''k'' equal sized subsamples. Of the ''k'' subsamples, a single subsample is retained as the validation data for testing the model, and the remaining ''k''&amp;nbsp;−&amp;nbsp;1 subsamples are used as training data. The cross-validation process is then repeated ''k'' times, with each of the ''k'' subsamples used exactly once as the validation data.  The ''k'' results can then be averaged to produce a single estimation. The advantage of this method over repeated random sub-sampling  (see below) is that all observations are used for both training and validation, and each observation is used for validation exactly once. 10-fold cross-validation is commonly used,&lt;ref name="McLachlan"&gt;{{cite book |title=Analyzing microarray gene expression data |first= Geoffrey J. |last= McLachlan |first2=Kim-Anh |last2=Do|author2-link=Kim-Anh Do |first3=Christophe |last3=Ambroise |year=2004 |publisher= Wiley }}&lt;/ref&gt; but in general ''k'' remains an unfixed parameter.

For example, setting ''k''&amp;nbsp;=&amp;nbsp;''2'' results in 2-fold cross-validation. In 2-fold cross-validation, we randomly shuffle the dataset into two sets ''d''&lt;sub&gt;0&lt;/sub&gt; and ''d''&lt;sub&gt;1&lt;/sub&gt;, so that both sets are equal size (this is usually implemented by shuffling the data array and then splitting it in two). We then train on ''d''&lt;sub&gt;0&lt;/sub&gt; and validate on ''d''&lt;sub&gt;1&lt;/sub&gt;, followed by training on ''d''&lt;sub&gt;1&lt;/sub&gt; and validating on&amp;nbsp;''d''&lt;sub&gt;0&lt;/sub&gt;.

When ''k''&amp;nbsp;=&amp;nbsp;''n'' (the number of observations), ''k''-fold cross-validation is equivalent to leave-one-out cross-validation.&lt;ref&gt;{{Cite web|url=https://web.stanford.edu/~hastie/ElemStatLearn/|title=Elements of Statistical Learning: data mining, inference, and prediction. 2nd Edition.|website=web.stanford.edu|access-date=2019-04-04}}&lt;/ref&gt;

In ''stratified'' ''k''-fold cross-validation, the partitions are selected so that the mean response value is approximately equal in all the partitions.  In the case of binary classification, this means that each partition contains roughly the same proportions of the two types of class labels.

In ''repeated'' cross-validation the data is randomly split into ''k'' partitions several times. The performance of the model can thereby be averaged over several runs, but this is rarely desirable in practice.&lt;ref&gt;{{Cite book|url=https://lirias.kuleuven.be/1655861?limo=0|title=On Estimating Model Accuracy with Repeated Cross-Validation.|last=Vanwinckelen|first=Gitte|date=2 October 2019|website=lirias.kuleuven|pages=39–44|isbn=9789461970442}}&lt;/ref&gt;

====Holdout method====

In the holdout method, we randomly assign data points to two sets ''d''&lt;sub&gt;0&lt;/sub&gt; and ''d''&lt;sub&gt;1&lt;/sub&gt;, usually called the training set and the test set, respectively. The size of each of the sets is arbitrary although typically the test set is smaller than the training set. We then train (build a model) on ''d''&lt;sub&gt;0&lt;/sub&gt; and test (evaluate its performance) on ''d''&lt;sub&gt;1&lt;/sub&gt;.

In typical cross-validation, results of multiple runs of model-testing are averaged together; in contrast, the holdout method, in isolation, involves a single run. It should be used with caution because without such averaging of multiple runs, one may achieve highly misleading results. One's indicator of predictive accuracy ([[#Statistical properties|''F''&lt;sup&gt;*&lt;/sup&gt;]]) will tend to be unstable since it will not be smoothed out by multiple iterations (see below).  Similarly, indicators of the specific role played by various predictor variables (e.g., values of regression coefficients) will tend to be unstable.

While the holdout method can be framed as "the simplest kind of cross-validation",&lt;ref&gt;{{cite web|title=Cross Validation|url=https://www.cs.cmu.edu/~schneide/tut5/node42.html|access-date=11 November 2012}}&lt;/ref&gt; many sources instead classify holdout as a type of simple validation, rather than a simple or degenerate form of cross-validation.&lt;ref name="Kohavi95" /&gt;&lt;ref&gt;{{cite journal |last=Arlot |first=Sylvain |first2=Alain |last2=Celisse |title=A survey of cross-validation procedures for model selection |journal=Statistics Surveys |volume=4 |year=2010 |pages=40–79 |quote=In brief, CV consists in averaging several hold-out estimators of the risk corresponding to different data splits. |doi=10.1214/09-SS054 |arxiv=0907.4728 }}&lt;/ref&gt;

====Repeated random sub-sampling validation====

This method, also known as [[Monte Carlo method|Monte Carlo]] cross-validation,&lt;ref name="mccv"&gt;{{Cite book|title = Fundamentals of data mining in genomics and proteomics|last = Dubitzky|first = Werner|publisher = Springer Science &amp; Business Media|year = 2007|pages = 178|last2 = Granzow|first2 = Martin|last3 = Berrar|first3 = Daniel}}&lt;/ref&gt; creates multiple random splits of the dataset into training and validation data.&lt;ref&gt;{{Cite book|title=Applied Predictive Modeling|last=Kuhn|first=Max|last2=Johnson|first2=Kjell|date=2013|publisher=Springer New York|isbn=9781461468486|location=New York, NY|language=en|doi=10.1007/978-1-4614-6849-3}}&lt;/ref&gt; For each such split, the model is fit to the training data, and predictive accuracy is assessed using the validation data. The results are then averaged over the splits. The advantage of this method (over ''k''-fold cross validation) is that the proportion of the training/validation split is not dependent on the number of iterations (i.e., the number of partitions). The disadvantage of this method is that some observations may never be selected in the validation subsample, whereas others may be selected more than once. In other words, validation subsets may overlap. This method also exhibits [[Monte Carlo method|Monte Carlo]] variation, meaning that the results will vary if the analysis is repeated with different random splits.

As the number of random splits approaches infinity, the result of repeated random sub-sampling validation tends towards that of leave-p-out cross-validation.

In a stratified variant of this approach, the random samples are generated in such a way that the mean response value (i.e. the dependent variable in the regression) is equal in the training and testing sets. This is particularly useful if the responses are [[dichotomous]] with an unbalanced representation of the two response values in the data.

==Nested cross-validation==

When cross-validation is used simultaneously for selection of the best set of [[Hyperparameter (machine learning)|hyperparameters]] and for error estimation (and assessment of generalization capacity), a nested cross-validation is required. Many variants exist. At least two variants can be distinguished:

===k*l-fold cross-validation===

This is a truly nested variant (for instance used by &lt;code&gt;cross_val_score&lt;/code&gt; in [[scikit-learn]]&lt;ref&gt;{{cite web|title= Nested versus non-nested cross-validation|url= https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html |access-date=19 February 2019}}&lt;/ref&gt;), which contains an outer loop of ''k'' sets and an inner loop of ''l'' sets. The total data set is split into ''k'' sets. One by one, a set is selected as the (outer) test set and the ''k''&amp;nbsp;-&amp;nbsp;1 other sets are combined into the corresponding outer training set. This is repeated for each of the ''k'' sets. Each outer training set is further sub-divided into ''l'' sets.  One by one, a set is selected as inner test (validation) set and the ''l''&amp;nbsp;-&amp;nbsp;1 other sets are combined into the corresponding inner training set. This is repeated for each of the ''l'' sets. The inner training sets are used to fit model parameters, while the outer test set is used as a validation set to provide an unbiased evaluation of the model fit. Typically, this is repeated for many different hyperparameters (or even different model types) and the validation set is used to determine the best hyperparameter set (and model type) for this inner training set. After this, a new model is fit on the entire outer training set, using the best set of hyperparameters from the inner cross-validation. The performance of this model is then evaluated using the outer test set.

===k-fold cross-validation with validation and test set===

This is a type of k*l-fold cross-validation when ''l''&amp;nbsp;=&amp;nbsp;''k''&amp;nbsp;-&amp;nbsp;1. A single k-fold cross-validation is used with both a [[Training, validation, and test sets|validation and test set]]. The total data set is split into ''k'' sets. One by one, a set is selected as test set. Then, one by one, one of the remaining sets is used as a validation set and the other ''k''&amp;nbsp;-&amp;nbsp;2 sets are used as training sets until all possible combinations have been evaluated. Similar to the k*l-fold cross validation, the training set is used for model fitting and the validation set is used for model evaluation for each of the hyperparameter sets. Finally, for the selected parameter set, the test set is used to evaluate the model with the best parameter set. Here, two variants are possible: either evaluating the model that was trained on the training set or evaluating a new model that was fit on the combination of the train and the validation set.

==Measures of fit==

The goal of cross-validation is to estimate the expected level of fit of a model to a data set that is independent of the data that were used to train the model.  It can be used to estimate any quantitative measure of fit that is appropriate for the data and model.  For example, for [[binary classification]] problems, each case in the validation set is either predicted correctly or incorrectly. In this situation the misclassification error rate can be used to summarize the fit, although other measures like [[positive predictive value]] could also be used.  When the value being predicted is continuously distributed, the [[mean squared error]], [[root mean squared error]] or [[median absolute deviation]] could be used to summarize the errors.

==Using prior information==
When users apply cross-validation to select a good configuration &lt;math&gt;\lambda&lt;/math&gt;, then they might want to balance the cross-validated choice with their own estimate of the configuration. In this way, they can attempt to counter the volatility of cross-validation when the sample size is small and include relevant information from previous research. In a forecasting combination exercise, for instance, cross-validation can be applied to estimate the weights that are assigned to each forecast. Since a simple equal-weighted forecast is difficult to beat, a penalty can be added for deviating from equal weights.&lt;ref name="Hoornweg2018SUS"&gt;{{cite book |last1=Hoornweg |first1=Victor |title=Science: Under Submission | date=2018 |publisher=Hoornweg Press |isbn=978-90-829188-0-9 |url=http://www.victorhoornweg.com}}&lt;/ref&gt;  Or, if cross-validation is applied to assign individual weights to observations, then one can penalize deviations from equal weights to avoid wasting potentially relevant information.&lt;ref name = "Hoornweg2018SUS" /&gt;  Hoornweg (2018) shows how a tuning parameter &lt;math&gt;\gamma&lt;/math&gt; can be defined so that a user can intuitively balance between the accuracy of cross-validation and the simplicity of sticking to a reference parameter &lt;math&gt;\lambda_R&lt;/math&gt; that is defined by the user.

If &lt;math&gt;\lambda_i&lt;/math&gt; denotes the &lt;math&gt;i^{th}&lt;/math&gt; candidate configuration that might be selected, then the [[Loss_function#Statistics|loss function]] that is to be minimized can be defined as
: &lt;math&gt;
	L_{\lambda_i} = (1-\gamma) \mbox{ Relative Accuracy}_i + \gamma \mbox{ Relative Simplicity}_i.
&lt;/math&gt;
Relative accuracy can be quantified as &lt;math&gt;\mbox{MSE}(\lambda_i)/\mbox{MSE}(\lambda_R)&lt;/math&gt;, so that the mean squared error of a candidate  &lt;math&gt;\lambda_i&lt;/math&gt; is made relative to that of a user-specified &lt;math&gt;\lambda_R&lt;/math&gt;. The relative simplicity term measures the amount that &lt;math&gt;\lambda_i&lt;/math&gt; deviates from &lt;math&gt;\lambda_R&lt;/math&gt; relative to the maximum amount of deviation from &lt;math&gt;\lambda_R&lt;/math&gt;. Accordingly, relative simplicity can be specified as &lt;math&gt;\frac{(\lambda_i-\lambda_R)^2}{(\lambda_{\max}-\lambda_R)^2}&lt;/math&gt;, where &lt;math&gt;\lambda_{\max}&lt;/math&gt; corresponds to the &lt;math&gt;\lambda&lt;/math&gt; value with the highest permissible deviation from &lt;math&gt;\lambda_R&lt;/math&gt;. With &lt;math&gt;\gamma\in[0,1]&lt;/math&gt;, the user determines how high the influence of the reference parameter is relative to cross-validation.

One can add relative simplicity terms for multiple configurations &lt;math&gt;c=1,2,...,C&lt;/math&gt; by specifying the loss function as
: &lt;math&gt;
	L_{\lambda_i} = \mbox{ Relative Accuracy}_i + \sum_{c=1}^C \frac{\gamma_c}{1-\gamma_c} \mbox{ Relative Simplicity}_{i,c}.
&lt;/math&gt;
Hoornweg (2018) shows that a loss function with such an accuracy-simplicity tradeoff can also be used to intuitively define [[shrinkage estimator]]s like the (adaptive) lasso and [[Bayesian regression|Bayesian]] / [[ridge regression]].&lt;ref name = "Hoornweg2018SUS" /&gt; Click on the [[Lasso (statistics)#Interpretations of lasso|lasso]] for an example.

==Statistical properties==

Suppose we choose a measure of fit ''F'', and use cross-validation to produce an estimate ''F&lt;sup&gt;*&lt;/sup&gt;'' of the expected fit ''EF'' of a model to an independent data set drawn from the same population as the training data. If we imagine sampling multiple independent training sets following the same distribution, the resulting values for ''F&lt;sup&gt;*&lt;/sup&gt;'' will vary. The statistical properties of ''F&lt;sup&gt;*&lt;/sup&gt;'' result from this variation.

The cross-validation estimator ''F&lt;sup&gt;*&lt;/sup&gt;'' is very nearly unbiased for ''EF''.&lt;ref&gt;{{cite web |title=Thoughts on prediction and cross-validation |first=Ronald |last=Christensen |publisher=Department of Mathematics and Statistics University of New Mexico |date=May 21, 2015 |url=https://math.unm.edu/~fletcher/Prediction.pdf |access-date=May 31, 2017 }}&lt;/ref&gt;{{Citation needed|date=October 2016}} The reason that it is slightly biased is that the training set in cross-validation is slightly smaller than the actual data set (e.g. for LOOCV the training set size is ''n''&amp;nbsp;&amp;minus;&amp;nbsp;1 when there are ''n'' observed cases). In nearly all situations, the effect of this bias will be conservative in that the estimated fit will be slightly biased in the direction suggesting a poorer fit. In practice, this bias is rarely a concern.

The variance of ''F&lt;sup&gt;*&lt;/sup&gt;'' can be large.&lt;ref name="Efron97"&gt;{{cite journal |last1=Efron |first1=Bradley |last2=Tibshirani |first2=Robert |year=1997 |title=Improvements on cross-validation: The .632 + Bootstrap Method |journal=[[Journal of the American Statistical Association]] |volume=92 |pages=548–560 |mr=1467848 |jstor=2965703 |doi=10.2307/2965703 |issue=438 }}&lt;/ref&gt;&lt;ref name="Stone77"&gt;{{cite journal |last=Stone |first=Mervyn |year=1977 |title=Asymptotics for and against cross-validation |journal=[[Biometrika]] |volume=64 |number=1 |pages=29–35 |doi=10.1093/biomet/64.1.29 |mr=0474601 |jstor=2335766 }}&lt;/ref&gt; For this reason, if two statistical procedures are compared based on the results of cross-validation, the procedure with the better estimated performance may not actually be the better of the two procedures (i.e. it may not have the better value of ''EF'').  Some progress has been made on constructing [[confidence interval]]s around cross-validation estimates,&lt;ref name="Efron97" /&gt; but this is considered a difficult problem.

==Computational issues==

Most forms of cross-validation are straightforward to implement as long as an implementation of the prediction method being studied is available.  In particular, the prediction method can be a "black box" – there is no need to have access to the internals of its implementation.  If the prediction method is expensive to train, cross-validation can be very slow since the training must be carried out repeatedly.  In some cases such as [[least squares]] and [[kernel regression]], cross-validation can be sped up significantly by pre-computing certain values that are needed repeatedly in the training, or by using fast "updating rules" such as the [[Sherman–Morrison formula]].  However one must be careful to preserve the "total blinding" of the validation set from the training procedure, otherwise bias may result.  An extreme example of accelerating cross-validation occurs in [[linear regression]], where the results of cross-validation have a [[closed-form expression]] known as the ''prediction residual error sum of squares'' ([[PRESS statistic|PRESS]]).

==Limitations and misuse==

Cross-validation only yields meaningful results if the validation set and training set are drawn from the same population and only if human biases are controlled.

In many applications of predictive modeling, the structure of the system being studied evolves over time (i.e. it is "non-stationary").  Both of these can introduce systematic differences between the training and validation sets.  For example, if a model for [[stock market prediction|predicting stock values]] is trained on data for a certain five-year period, it is unrealistic to treat the subsequent five-year period as a draw from the same population.  As another example, suppose a model is developed to predict an individual's risk for being [[medical diagnosis|diagnosed]] with a particular disease within the next year.  If the model is trained using data from a study involving only a specific population group (e.g. young people or males), but is then applied to the general population, the cross-validation results from the training set could differ greatly from the actual predictive performance.

In many applications, models also may be incorrectly specified and vary as a function of modeler biases and/or arbitrary choices. When this occurs, there may be an illusion that the system changes in external samples, whereas the reason is that the model has missed a critical predictor and/or included a confounded predictor.   New evidence is that cross-validation by itself is not very predictive of external validity, whereas a form of experimental validation known as swap sampling that does control for human bias can be much more predictive of external validity.&lt;ref&gt;{{cite journal |last=Consortium |first=MAQC |year=2010 |title=The Microarray Quality Control (MAQC)-II study of common practices for the development and validation of microarray-based predictive models |journal=Nature Biotechnology  |volume=28 |issue=8 |pages=827–838 |publisher=Nature Publishing Group |location = London | doi = 10.1038/nbt.1665 |pmid=20676074 |pmc=3315840}}&lt;/ref&gt;  As defined by this large MAQC-II study across 30,000 models, swap sampling incorporates cross-validation in the sense that predictions are tested across independent training and validation samples. Yet, models are also developed across these independent samples and by modelers who are blinded to one another.  When there is a mismatch in these models developed across these swapped training and validation samples as happens quite frequently, MAQC-II shows that this will be much more predictive of poor external predictive validity than traditional cross-validation.

The reason for the success of the swapped sampling is a built-in control for human biases in model building.  In addition to placing too much faith in predictions that may vary across modelers and lead to poor external validity due to these confounding modeler effects, these are some other ways that cross-validation can be misused:

* By performing an initial analysis to identify the most informative [[features (pattern recognition)|features]] using the entire data set – if feature selection or model tuning is required by the modeling procedure, this must be repeated on every training set. Otherwise, predictions will certainly be upwardly biased.&lt;ref name="Bermingham-intro"&gt;{{cite journal |title= Application of high-dimensional feature selection: evaluation for genomic prediction in man |first1=Mairead L. |last1=Bermingham |first2=Ricardo |last2=Pong-Wong | first3=Athina|last3=Spiliopoulou | first4=Caroline|last4=Hayward |first5=Igor|last5=Rudan |first6=Harry|last6=Campbell |first7=Alan F.|last7=Wright |first8=James F.|last8=Wilson |first9=Felix |last9=Agakov |first10=Pau|last10=Navarro |first11=Chris S.|last11=Haley |journal=[[Scientific Reports|Sci. Rep.]] |volume=5 |year=2015 |doi=10.1038/srep10312 |page=10312|bibcode=2015NatSR...510312B|pmc=4437376 |pmid=25988841 }}&lt;/ref&gt;  If cross-validation is used to decide which features to use, an ''inner cross-validation'' to carry out the feature selection on every training set must be performed.&lt;ref&gt;{{Cite journal| doi = 10.1186/1471-2105-7-91| pmid = 16504092| pmc = 1397873| title = Bias in error estimation when using cross-validation for model selection| year = 2006| last1 = Varma | first1 = Sudhir| last2 = Simon | first2 = Richard| journal = BMC Bioinformatics| volume = 7| pages = 91}}&lt;/ref&gt;
* By allowing some of the training data to also be included in the test set – this can happen due to "twinning" in the data set, whereby some exactly identical or nearly identical samples are present in the data set. To some extent twinning always takes place even in perfectly independent training and validation samples. This is because some of the training sample observations will have nearly identical values of predictors as validation sample observations. And some of these will correlate with a target at better than chance levels in the same direction in both training and validation when they are actually driven by confounded predictors with poor external validity.  If such a cross-validated model is selected from a ''k''-fold set, human [[confirmation bias]] will be at work and determine that such a model has been validated. This is why traditional cross-validation needs to be supplemented with controls for human bias and confounded model specification like swap sampling and prospective studies.

==Cross validation for time-series models==
Since the order of the data is important, cross-validation might be problematic for [[time-series]] models. A more appropriate approach might be to use rolling cross-validation.

However, if performance is described by a single [[Summary statistics|summary statistic]], it is possible that the approach described by Politis and Romano as a [[stationary bootstrap]]&lt;ref&gt;{{Cite journal |doi = 10.1080/01621459.1994.10476870|title = The Stationary Bootstrap|journal = Journal of the American Statistical Association|volume = 89|issue = 428|pages = 1303–1313|year = 1994|last1 = Politis|first1 = Dimitris N.|last2 = Romano|first2 = Joseph P.}}&lt;/ref&gt; will work. The statistic of the bootstrap needs to accept an interval of the time series and return the summary statistic on it. The call to the stationary bootstrap needs to specify an appropriate mean interval length.

==Applications==

Cross-validation can be used to compare the performances of different predictive modeling procedures.  For example, suppose we are interested in [[optical character recognition]], and we are considering using either [[support vector machines]] (SVM) or [[k nearest neighbors|''k''-nearest neighbors]] (KNN) to predict the true character from an image of a handwritten character.  Using cross-validation, we could objectively compare these two methods in terms of their respective fractions of misclassified characters.  If we simply compared the methods based on their in-sample error rates, the KNN method would likely appear to perform better, since it is more flexible and hence more prone to [[overfitting]] {{Citation needed|reason=Under which conditions|date=August 2017}} compared to the SVM method.

Cross-validation can also be used in [[Feature selection|''variable selection'']].&lt;ref name="Picard84"&gt;{{cite journal |last=Picard |first=Richard |last2=Cook |first2=Dennis |year=1984 |title=Cross-Validation of Regression Models |journal=Journal of the American Statistical Association |jstor=2288403 |volume=79 |pages=575–583 |doi=10.2307/2288403 |issue=387 }}&lt;/ref&gt; Suppose we are using the [[gene expression|expression]] levels of 20 [[proteins]] to predict whether a [[cancer]] patient will respond to a [[drug]]. A practical goal would be to determine which subset of the 20 features should be used to produce the best predictive model. For most modeling procedures, if we compare feature subsets using the in-sample error rates, the best performance will occur when all 20 features are used. However under cross-validation, the model with the best fit will generally include only a subset of the features that are deemed truly informative.

A recent development in medical statistics is its use in meta-analysis. It forms the basis of the validation statistic, Vn which is used to test the statistical validity of meta-analysis summary estimates.&lt;ref&gt;{{cite journal |vauthors=Willis BH, Riley RD| year = 2017 | title = Measuring the statistical validity of summary meta-analysis and meta-regression results for use in clinical practice | journal = Statistics in Medicine | volume = 36 | issue = 21 | pages = 3283–3301 | doi = 10.1002/sim.7372| pmid = 28620945 | pmc=5575530}}&lt;/ref&gt;  It has also been used in a more conventional sense in meta-analysis to estimate the likely prediction error of meta-analysis results.&lt;ref&gt;{{cite journal |vauthors=Riley RD, Ahmed I, Debray TP, Willis BH, Noordzij P, Higgins JP, Deeks JJ| year = 2015 | title = Summarising and validating test accuracy results across multiple studies for use in clinical practice.| journal = Statistics in Medicine | volume = 34 | issue = 13 | pages = 2081–2103 | doi = 10.1002/sim.6471| pmid = 25800943 | pmc=4973708}}&lt;/ref&gt;

==See also==
{{Commons category|Cross-validation (statistics)}}
* [[Boosting (machine learning)]]
* [[Bootstrap aggregating]] (bagging)
* [[Bootstrapping (statistics)]]
* [[Leakage (machine learning)]]
* [[Model selection]]
* [[Resampling (statistics)]]
* [[Stability (learning theory)]]
* [[Validity (statistics)]]

==Notes and references==
{{reflist|30em}}

{{Statistics|hide}}

{{DEFAULTSORT:Cross-Validation (Statistics)}}
[[Category:Model selection]]
[[Category:Regression variable selection]]
[[Category:Machine learning]]</text>
      <sha1>plzh6e00t67sfq57hr47510oev570kg</sha1>
    </revision>
  </page>
  <page>
    <title>Predictive learning</title>
    <ns>0</ns>
    <id>2291650</id>
    <revision>
      <id>910521352</id>
      <parentid>538191324</parentid>
      <timestamp>2019-08-12T17:19:31Z</timestamp>
      <contributor>
        <username>Gnomingstuff</username>
        <id>34573757</id>
      </contributor>
      <minor/>
      <comment>stub sort</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="911" xml:space="preserve">{{Unreferenced stub|auto=yes|date=December 2009}}

'''Predictive learning''' is a technique of [[machine learning]] in which an agent tries to build a model of its environment by trying out different actions in various circumstances. It uses knowledge of the effects its actions appear to have, turning them into planning operators. These allow the agent to act purposefully in its world. Predictive learning is one attempt to learn with a minimum of pre-existing mental structure. It may have been inspired by [[Jean Piaget|Piaget]]'s account of how children construct knowledge of the world by interacting with it. [[Gary Drescher]]'s book 'Made-up Minds' was seminal for the area.

Another more recent predictive learning theory is [[Jeff Hawkins]]' [[memory-prediction framework]], which is laid out in his [[On Intelligence]].

{{DEFAULTSORT:Predictive Learning}}
[[Category:Machine learning]]

{{ai-stub}}</text>
      <sha1>k0mp7d67fv3np3brs4ujbdp85ifjddu</sha1>
    </revision>
  </page>
  <page>
    <title>Empirical risk minimization</title>
    <ns>0</ns>
    <id>1455062</id>
    <revision>
      <id>999420727</id>
      <parentid>926149186</parentid>
      <timestamp>2021-01-10T02:14:47Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 1 template: hyphenate params (1×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="5097" xml:space="preserve">{{machine learning bar}}
'''Empirical risk minimization''' (ERM) is a principle in [[statistical learning theory]] which defines a family of [[machine learning|learning algorithms]] and is used to give theoretical bounds on their performance. The core idea is that we cannot know exactly how well an algorithm will work in practice (the true "risk") because we don't know the true distribution of data that the algorithm will work on, but we can instead measure its performance on a known set of training data (the "empirical" risk). 

== Background ==
Consider the following situation, which is a general setting of many [[supervised learning]] problems. We have two spaces of objects &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt; and would like to learn a function &lt;math&gt;\ h: X \to Y&lt;/math&gt; (often called ''hypothesis'') which outputs an object &lt;math&gt;y \in Y&lt;/math&gt;, given &lt;math&gt;x \in X&lt;/math&gt;. To do so, we have at our disposal a ''training set'' of &lt;math&gt;n&lt;/math&gt; examples &lt;math&gt;\ (x_1, y_1), \ldots, (x_n, y_n)&lt;/math&gt; where &lt;math&gt;x_i \in X&lt;/math&gt; is an input and &lt;math&gt;y_i \in Y&lt;/math&gt; is the corresponding response that we wish to get from &lt;math&gt;\ h(x_i)&lt;/math&gt;.

To put it more formally, we assume that there is a [[joint probability distribution]] &lt;math&gt;P(x, y)&lt;/math&gt; over &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt;, and that the training set consists of &lt;math&gt;n&lt;/math&gt; instances &lt;math&gt;\ (x_1, y_1), \ldots, (x_n, y_n)&lt;/math&gt; drawn [[i.i.d.]] from &lt;math&gt;P(x, y)&lt;/math&gt;. Note that the assumption of a joint probability distribution allows us to model uncertainty in predictions (e.g. from noise in data) because &lt;math&gt;y&lt;/math&gt; is not a deterministic function of {{nowrap|&lt;math&gt;x&lt;/math&gt;,}} but rather a [[random variable]] with [[conditional distribution]] &lt;math&gt;P(y | x)&lt;/math&gt; for a fixed &lt;math&gt;x&lt;/math&gt;.

We also assume that we are given a non-negative real-valued [[loss function]] &lt;math&gt;L(\hat{y}, y)&lt;/math&gt; which measures how different the prediction &lt;math&gt;\hat{y}&lt;/math&gt; of a hypothesis is from the true outcome &lt;math&gt;y.&lt;/math&gt; The [[Risk (statistics)|risk]] associated with hypothesis &lt;math&gt;h(x)&lt;/math&gt; is then defined as the [[Expected value|expectation]] of the loss function:
: &lt;math&gt;R(h) = \mathbf{E}[L(h(x), y)] = \int L(h(x), y)\,dP(x, y).&lt;/math&gt;

A loss function commonly used in theory is the [[0-1 loss function]]: &lt;math&gt;L(\hat{y}, y) = \begin{cases} 1 &amp; \mbox{ If }\quad \hat{y} \ne y \\ 0 &amp; \mbox{ If }\quad \hat{y} = y \end{cases}&lt;/math&gt;.

The ultimate goal of a learning algorithm is to find a hypothesis &lt;math&gt; h^*&lt;/math&gt; among a fixed class of functions &lt;math&gt;\mathcal{H}&lt;/math&gt; for which the risk &lt;math&gt;R(h)&lt;/math&gt; is minimal:
: &lt;math&gt;h^* = \arg \min_{h \in \mathcal{H}} R(h).&lt;/math&gt;

== Empirical risk minimization ==
In general, the risk &lt;math&gt;R(h)&lt;/math&gt; cannot be computed because the distribution &lt;math&gt;P(x, y)&lt;/math&gt; is unknown to the learning algorithm (this situation is referred to as [[agnostic learning]]). However, we can compute an approximation, called ''empirical risk'', by averaging the loss function on the training set:
: &lt;math&gt;\! R_\text{emp}(h) = \frac{1}{n} \sum_{i=1}^n L(h(x_i), y_i).&lt;/math&gt;

The empirical risk minimization principle&lt;ref&gt;V. Vapnik (1992). [http://papers.nips.cc/paper/506-principles-of-risk-minimization-for-learning-theory.pdf ''Principles of Risk Minimization
for Learning Theory.'']&lt;/ref&gt; states that the learning algorithm should choose a hypothesis &lt;math&gt;\hat{h}&lt;/math&gt; which minimizes the empirical risk:
: &lt;math&gt;\hat{h} = \arg \min_{h \in \mathcal{H}} R_{\text{emp}}(h).&lt;/math&gt;
Thus the learning algorithm defined by the ERM principle consists in solving the above [[Mathematical optimization|optimization]] problem.

== Properties ==
{{Expand section|date=February 2010}}

=== Computational complexity ===
Empirical risk minimization for a classification problem with a [[0-1 loss function]] is known to be an [[NP-hard]] problem even for such a relatively simple class of functions as [[linear classifier]]s.&lt;ref&gt;V. Feldman, V. Guruswami, P. Raghavendra and Yi Wu (2009). [https://arxiv.org/abs/1012.0729 ''Agnostic Learning of Monomials by Halfspaces is Hard.''] (See the paper and references therein)&lt;/ref&gt; Though, it can be solved efficiently when the minimal empirical risk is zero, i.e. data is [[linearly separable]].

In practice, machine learning algorithms cope with that either by employing a [[Convex optimization|convex approximation]] to the 0-1 loss function (like [[hinge loss]] for [[Support vector machine|SVM]]), which is easier to optimize, or by imposing assumptions on the distribution &lt;math&gt;P(x, y)&lt;/math&gt; (and thus stop being agnostic learning algorithms to which the above result applies).

==See also==

*[[Maximum likelihood estimation]]
*[[M-estimator]]

== References ==
{{Reflist}}

== Further reading ==
* {{cite book
    | last=Vapnik
    | first=V.
    | author-link = Vladimir Vapnik
    | title=The Nature of Statistical Learning Theory
    | publisher = [[Springer-Verlag]]
    | series=Information Science and Statistics
    | year = 2000
    | isbn=978-0-387-98780-4}}

[[Category:Machine learning]]</text>
      <sha1>s0urygkg63tar30elcgciob51tpppeg</sha1>
    </revision>
  </page>
  <page>
    <title>Product of experts</title>
    <ns>0</ns>
    <id>24825162</id>
    <revision>
      <id>883129250</id>
      <parentid>508558707</parentid>
      <timestamp>2019-02-13T13:21:11Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Add: citeseerx. | You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[WP:UCB|User-activated]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1224" xml:space="preserve">'''Product of experts''' (PoE) is a [[machine learning]] technique. It models a probability distribution by combining the output from several simpler distributions.
It was proposed by [[Geoff Hinton]], along with an algorithm for training the parameters of such a system.

The core idea is to combine several probability distributions ("experts") by multiplying their density functions—making the PoE classification similar to an "and" operation. This allows each expert to make decisions on the basis of a few dimensions without having to cover the full dimensionality of a problem.

This is related to (but quite different from) a [[mixture model]], where several probability distributions are combined via an "or" operation, which is a weighted sum of their density functions.

==External links==
*{{Cite journal|doi=10.1162/089976602760128018|last=Hinton |first=Geoffrey E.|year=2002|title=Training Products of Experts by Minimizing Contrastive Divergence|journal=Neural Computation|volume=14|issue=8|pages=1771–1800|url=http://www.cs.toronto.edu/~hinton/absps/nccd.pdf|accessdate=2009-10-25|pmid=12180402|citeseerx=10.1.1.35.8613 }}

{{DEFAULTSORT:Product Of Experts}}
[[Category:Machine learning]]


{{Compu-stub}}</text>
      <sha1>3jjp1gml2yiztdcjt1h7s5o8fthc8s1</sha1>
    </revision>
  </page>
  <page>
    <title>Unsupervised learning</title>
    <ns>0</ns>
    <id>233497</id>
    <revision>
      <id>1003505182</id>
      <parentid>1001697007</parentid>
      <timestamp>2021-01-29T08:59:42Z</timestamp>
      <contributor>
        <username>AlecCoates</username>
        <id>37039784</id>
      </contributor>
      <minor/>
      <comment>Added wikilink to supervised learning</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="27369" xml:space="preserve">{{Short description|Machine learning technique}}
{{Machine learning bar}}

'''Unsupervised learning''' (UL) is a type of algorithm that learns patterns from untagged data.  The hope is that through mimicry, the machine is forced to build a compact internal representation of its world.  In contrast to [[Supervised learning|Supervised Learning]] (SL) where data is tagged by a human, eg. as "car" or "fish" etc, UL exhibits self-organization that captures patterns as neuronal predelections or probability densities.&lt;ref name="Hinton99a"&gt;{{cite book |first1=Geoffrey |last1=Hinton |first2=Terrence |last2=Sejnowski |title=Unsupervised Learning: Foundations of Neural Computation |publisher= MIT Press |year=1999 |isbn=978-0262581684 }}&lt;/ref&gt;  The other levels in the supervision spectrum are  [[Reinforcement Learning]] where the machine is given only a numerical performance score as its guidance, and [[Semi-supervised learning]] where a smaller portion of the data is tagged.  Two broad methods in UL are Neural Networks and Probabilistic Methods.
&lt;!--
'''Unsupervised learning''' (UL) is a type of [[machine learning]] that utilizes a data set with no pre-existing labels with a minimum of human supervision,&lt;ref&gt;{{Cite web|last=Salian|first=Isha|date=2018-08-02|title=NVIDIA Blog: Supervised Vs. Unsupervised Learning|url=https://blogs.nvidia.com/blog/2018/08/02/supervised-unsupervised-learning/|access-date=2021-01-15|website=The Official NVIDIA Blog|language=en-US}}&lt;/ref&gt; often for the purpose of searching for previously undetected patterns. In contrast to supervised learning (SL) that usually makes use of human-labeled data, unsupervised learning, also known as [[self-organization]] allows for modeling of [[Probability density function|probability densities]] over inputs.&lt;ref name="Hinton99a"&gt;{{cite book |first1=Geoffrey |last1=Hinton |first2=Terrence |last2=Sejnowski |title=Unsupervised Learning: Foundations of Neural Computation |publisher= MIT Press |year=1999 |isbn=978-0262581684 }}&lt;/ref&gt; It forms one of the three main categories of machine learning, along with [[supervised learning|supervised]] and [[reinforcement learning]]. [[Semi-supervised learning]], a related variant, makes use of supervised and unsupervised techniques.
--&gt;
== Probabilistic methods ==

Two of the main methods used in unsupervised learning are [[principal component analysis|principal component]] and [[cluster analysis]]. [[Cluster analysis]] is used in unsupervised learning to group, or segment, datasets with shared attributes in order to extrapolate algorithmic relationships.&lt;ref&gt;{{Cite web|url=https://towardsdatascience.com/unsupervised-machine-learning-clustering-analysis-d40f2b34ae7e|title=Unsupervised Machine Learning: Clustering Analysis|last=Roman|first=Victor|date=2019-04-21|website=Medium|access-date=2019-10-01}}&lt;/ref&gt;  Cluster analysis is a branch of [[machine learning]] that groups the data that has not been [[labeled data|labelled]], classified or categorized. Instead of responding to feedback, cluster analysis identifies commonalities in the data and reacts based on the presence or absence of such commonalities in each new piece of data. This approach helps detect anomalous data points that do not fit into either group.

The only requirement to be called an unsupervised learning strategy is to learn a new feature space that captures the characteristics of the original space by maximizing some objective function or minimising some loss function. Therefore, generating a [[covariance matrix]] is not unsupervised learning, but taking the [[eigenvectors]] of the covariance matrix is because the linear algebra eigendecomposition operation maximizes the variance; this is known as principal component analysis.&lt;ref&gt;{{Cite journal|url=https://vixra.org/abs/2003.0581|title=Machine Learning in Asset Management: Part 2: Portfolio Construction—Weight Optimization|last=Snow|first=Dr Derek|date=2020-03-26|journal=Journal of Financial Data Science|volume=2|issue=2|pages=17–24|language=en|access-date=2020-05-16|doi=10.3905/jfds.2020.1.029 |s2cid=215932953}}&lt;/ref&gt; Similarly, taking the log-transform of a dataset is not unsupervised learning, but passing input data through multiple sigmoid functions while minimising some distance function between the generated and resulting data is, and is known as an [[Autoencoder]].

A central application of unsupervised learning is in the field of [[density estimation]] in [[statistics]],&lt;ref name="JordanBishop2004"&gt;{{cite book |first1=Michael I. |last1=Jordan |first2=Christopher M. |last2=Bishop |chapter=Neural Networks |editor=Allen B. Tucker |title=Computer Science Handbook, Second Edition (Section VII: Intelligent Systems) |location=Boca Raton, Florida |publisher=Chapman &amp; Hall/CRC Press LLC |year=2004 |isbn=1-58488-360-X }}&lt;/ref&gt; though unsupervised learning encompasses many other domains involving summarizing and explaining data features.  It could be contrasted with supervised learning by saying that whereas supervised learning intends to infer a [[conditional probability distribution]] &lt;math display="inline"&gt;p_X(x\,|\,y)&lt;/math&gt; conditioned on the label &lt;math display="inline"&gt;y&lt;/math&gt; of input data; unsupervised learning intends to infer an [[a priori probability]] distribution &lt;math display="inline"&gt;p_X(x)&lt;/math&gt;.
&lt;!-- [[Generative adversarial networks]] can be used with supervised learning or unsupervised and reinforcement techniques --&gt;

=== Approaches ===
Some of the most common algorithms used in unsupervised learning include: (1) Clustering, (2) Anomaly detection, (3) Neural Networks, and (4) Approaches for learning latent variable models.
Each approach uses several methods as follows:

* [[Data clustering|Clustering]] methods include:  [[hierarchical clustering]],&lt;ref&gt;{{cite book|last=Hastie, Trevor, Robert Tibshirani|first=Friedman, Jerome|title=The Elements of Statistical Learning: Data mining, Inference, and Prediction|date=2009|publisher=Springer|location=New York|isbn=978-0-387-84857-0|pages=485–586}}&lt;/ref&gt; [[k-means]],&lt;ref&gt;{{Cite web|url=https://towardsdatascience.com/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1|title=Understanding K-means Clustering in Machine Learning|last=Garbade|first=Dr Michael J.|date=2018-09-12|website=Medium|language=en|access-date=2019-10-31}}&lt;/ref&gt; [[mixture models]], [[DBSCAN]], and [[OPTICS algorithm]]
* [[Anomaly detection]] methods include: [[Local Outlier Factor]], and [[Isolation Forest]]
* Approaches for learning [[latent variable model]]s such as [[Expectation–maximization algorithm]] (EM), [[Method of moments (statistics)|Method of moments]], and [[Blind signal separation]] techniques ( [[Principal component analysis]], [[Independent component analysis]], [[Non-negative matrix factorization]], [[Singular value decomposition]] )
&lt;!-- * [[Artificial neural network|Neural Networks]] methods include: [[Autoencoder]]s, [[Deep belief network|Deep Belief Nets]], [[Hebbian Learning]], [[Generative adversarial network]]s, and [[Self-organizing map]] --&gt;

=== Method of moments ===
One of the statistical approaches for unsupervised learning is the [[method of moments (statistics)|method of moments]]. In the method of moments, the unknown parameters (of interest) in the model are related to the moments of one or more random variables, and thus, these unknown parameters can be estimated given the moments. The moments are usually estimated from samples empirically. The basic moments are first and second order moments. For a random vector, the first order moment is the [[mean]] vector, and the second order moment is the [[covariance matrix]] (when the mean is zero). Higher order moments are usually represented using [[tensors]] which are the generalization of matrices to higher orders as multi-dimensional arrays.

In particular, the method of moments is shown to be effective in learning the parameters of [[latent variable model]]s.&lt;ref name="TensorLVMs"&gt;{{cite journal |last1=Anandkumar |first1=Animashree |last2=Ge |first2=Rong |last3=Hsu |first3=Daniel |last4=Kakade |first4=Sham |first5= Matus |last5=Telgarsky |date=2014 |title=Tensor Decompositions for Learning Latent Variable Models |url=http://www.jmlr.org/papers/volume15/anandkumar14b/anandkumar14b.pdf |journal=Journal of Machine Learning Research |volume=15 |pages=2773–2832|bibcode=2012arXiv1210.7559A |arxiv=1210.7559 }}&lt;/ref&gt;
Latent variable models are statistical models where in addition to the observed variables, a set of latent variables also exists which is not observed. A highly practical example of latent variable models in machine learning is the [[topic modeling]] which is a statistical model for generating the words (observed variables) in the document based on the topic (latent variable) of the document. In the topic modeling, the words in the document are generated according to different statistical parameters when the topic of the document is changed. It is shown that method of moments (tensor decomposition techniques) consistently recover the parameters of a large class of latent variable models under some assumptions.&lt;ref name="TensorLVMs" /&gt;

The [[Expectation–maximization algorithm]] (EM) is also one of the most practical methods for learning latent variable models. However, it can get stuck in local optima, and it is not guaranteed that the algorithm will converge to the true unknown parameters of the model. In contrast, for the method of moments, the global convergence is guaranteed under some conditions.&lt;ref name="TensorLVMs" /&gt;

== Neural networks ==

=== Basics ===
'''First, some vocabulary:'''&lt;br&gt;
{| 
|- style="vertical-align: top;" 
| ''activation''     || = state value of the neuron.  For binary neurons, this is usually 0 / 1, or +1 / -1. 
|- style="vertical-align: top;" 
| ''CAM''            || = content addressable memory.  Recalling a memory by a partial pattern instead of a memory address.
|- style="vertical-align: top;" 
| ''convergence''    || = the stabilization of an activation pattern on a network.  In SL, convergence means stabilization of weights &amp; biases rather than activations.
|- style="vertical-align: top;" 
| ''discriminative'' || = relating to recognition tasks.  Also called analysis (in Pattern Theory), or inference.
|- style="vertical-align: top;" 
| ''energy''         || = a macroscopic quantity describing the activation pattern in a network. (see below)
|- style="vertical-align: top;" 
| ''generalization'' || = behaving accurately on unseen inputs
|- style="vertical-align: top;" 
| ''generative''     || = Machine imagined and recall task.  sometimes called synthesis (in Pattern Theory), mimicry, or deep fakes.
|- style="vertical-align: top;" 
| ''inference''      || = the "run" phase (as opposed to training).  During inference the network performs the task it is trained to do—either recognizing a pattern (SL) or creating one (UL).  Usually inference descends the gradient of an energy function.  In contrast to SL, gradient descent occurs during training, NOT inference.
|- style="vertical-align: top;" 
| ''machine vision'' || = machine learning on images. 
|- style="vertical-align: top;" 
| ''NLP''            || = Natural Language Processing.  Machine learning of human languages.
|- style="vertical-align: top;" 
| ''pattern''        || = network activations that has an internal order in some sense, or that can be described more compactly by features in the activations.  For example, the pixel pattern of a zero, whether it's given as data or imagined by the network, has a feature that is describable as a single loop.  The features are encoded in the hidden neurons.
|- style="vertical-align: top;" 
| ''training''       || = the learning phase.  Here, the network adjusts its weights &amp; biases to learn from the inputs.
|}

'''Tasks'''&lt;br&gt;
[[File:Task-guidance.png|thumb|300px|Tendency for a task to employ Supervised vs. Unsupervised methods]]
UL methods usually prepare a network for generative tasks rather than recognition, but grouping tasks as supervised or not can be hazy.  For example, handwriting recognition started off in the 1980s as SL.  Then in 2007, UL is used to prime the network for SL afterwards.  Currently, SL has regained its position as the better method.

'''Training'''&lt;br&gt;
During the learning phase, an unsupervised network tries to mimic the data it's given and uses the error in its mimicked output to correct itself (eg. its weights &amp; biases).  This resembles the mimicry behavior of children as they learn a language.  Sometimes the error is expressed as a low probability that the erroneous output occurs, or it might be express as an unstable high energy state in the network.

'''Energy'''&lt;br&gt;
An energy function is a macroscopic measure of a network's state.  This analogy with physics is inspired by Ludwig Boltzmann's analysis of a gas' macroscopic energy from the microscopic probabilities of particle motion p &lt;math&gt;\propto&lt;/math&gt; e&lt;sup&gt;E/kT&lt;/sup&gt;, where k is the Boltzmann constant and T is temperature.  In neural networks the relation is p = e&lt;sup&gt;-E&lt;/sup&gt; / Z, where p &amp; E vary over every possible input pattern.  Hence, early neural networks bear the name Boltzmann Machine.  Paul Smolensky calls -E the Harmony.  A network seeks low energy which is high Harmony.

'''Networks'''&lt;br&gt;
{| class="wikitable"
|-
! Hopfield !! Boltzmann !! RBM !! Helmholtz !! Autoencoder || VAE
|-
| [[File:Hopfield-net-vector.svg|thumb]] || [[File:Boltzmannexamplev1.png|thumb]] || [[File:Restricted Boltzmann machine.svg|thumb|restricted Boltzmann machine]] || [[File:Helmholtz Machine.png|thumb|]] 
|| [[File:Autoencoder_schema.png|thumb|autoencoder]] || [[File:VAE blocks.png|thumb|variational autoencoder]]
|}
Boltzmann and Helmholtz came before neural networks formulations, but these networks borrowed from their analyses, so these networks bear their names.  Hopfield, however, directly contributed to UL.

=== Intermediate ===
Here, distributions p(x) and q(x) will be abbreviated as p and q.

'''History'''&lt;br&gt;
{| border=0
|- style="vertical-align: top;"
| 1969 || Perceptrons by Minsky &amp; Papert shows a perceptron without hidden layers fails on XOR
|- style="vertical-align: top;"
| 1970s || (approximate dates) AI winter I 
|- style="vertical-align: top;"
| 1974 || Ising magnetic model proposed by WA Little for cognition
|- style="vertical-align: top;"
| 1980 || Fukushima introduces the neocognitron, which is later called a convolution neural network.  It is mostly used in SL, but deserves a mention here.
|- style="vertical-align: top;"
| 1982 || Ising variant Hopfield net described as CAMs and classifiers by John Hopfield.
|- style="vertical-align: top;"
| 1983 || Ising variant Boltzmann machine with probabilistic neurons described by Hinton &amp; Sejnowski following Sherington &amp; Kirkpatrick's 1975 work.  
|- style="vertical-align: top;"
| 1986 || Paul Smolensky publishes Harmony Theory, which is an RBM with practically the same Boltzmann energy function.  Smolensky did not give an practical training scheme.  Hinton did in mid-2000s
|- style="vertical-align: top;"
| 1995 || Schmidthuber introduces the LSTM neuron for languages.
|- style="vertical-align: top;"
| 1995 || Dayan &amp; Hinton introduces Helmholtz machine
|- style="vertical-align: top;"
| 1995-2005 || (approximate dates) AI winter II 
|- style="vertical-align: top;"
| 2013 || Kingma, Rezende, &amp; co.  introduced Variational Autoencoders as Bayesian graphical probability network, with neural nets as components.
|}

'''Some more vocabulary:'''&lt;br&gt;
{| 
|- style="vertical-align: top;"
| '''Probability''' || 
|- style="vertical-align: top;"
| ''cdf'' || = cumulative distribution function.  the integral of the pdf.  The probability of getting near 3 is the area under the curve between 2.9 and 3.1.
|- style="vertical-align: top;"
| ''contrastive divergence'' || = a learning method where one lowers the energy on training patterns and raises the energy on unwanted patterns outside of the training set.  This is very different from the KL-divergence, but shares a similar wording.
|- style="vertical-align: top;"
| ''expected value '' || = E(x) = &lt;math&gt; \sum_x &lt;/math&gt; x * p(x).  This is the mean value, or average value.  For continuous input x, replace the summation with an integral.
|- style="vertical-align: top;"
| ''latent variable'' || = an unobserved quantity that helps to explain observed data.  for instance, a flu infection (unobserved) can explain why the a person sneezes (observed).  In probabilistic neural networks, hidden neurons act as latent variables, though their latent interpretation is not explicitly known.
|- style="vertical-align: top;"
| ''pdf'' || = probability density function.  The probability that a random variable takes on a certain value. For continuous pdf, p(3) = 1/2 can still mean there is near zero chance of achieving this exact value of 3.  We rationalize this with the cdf.
|- style="vertical-align: top;"
| ''stochastic'' || = behaves according to a well described probability density formula.
|-
| '''Thermodynamics''' || 
|- style="vertical-align: top;"
| ''Boltzmann distribution'' ||  = Gibbs distribution.  p &lt;math&gt;\propto&lt;/math&gt; e&lt;sup&gt;E/kT&lt;/sup&gt;
|- style="vertical-align: top;"
| ''entropy'' || = expected information = &lt;math&gt; \sum_x &lt;/math&gt; p * log p
|- style="vertical-align: top;"
| ''Gibbs free energy || = thermodynamic potential.  It's the maximum reversible work that may be performed by a heat system at constant temperature and pressure.  free energy G = heat - temperature * entropy 
|- style="vertical-align: top;"
| ''information'' || = the information amount of a message x = -log p(x) 
|- style="vertical-align: top;"
| ''KLD'' || = relative entropy.  For probabilistic networks, this is the analogue of the error between input &amp; mimicked output.  The Kullback-Liebler divergence (KLD) measures the entropy deviation of 1 distribution from another distribution.  KLD(p,q) = &lt;math&gt; \sum_x &lt;/math&gt; p * log( p / q ).  Typically, p reflects the input data, q reflects the network's interpretation of it, and KLD reflects the difference between the two.
|}

'''Comparison of Networks'''
{| class="wikitable"
|-
!  !! Hopfield !! Boltzmann !! RBM !! Helmholtz !! Autoencoder !! VAE 
|-
| '''usage &amp; notables''' || CAM, traveling salesman problem || CAM.  The freedom of connections makes this network difficult to analyze. || pattern recognition (MNIST, speech recognition) || imagination, mimicry || &lt;!--AE--&gt; language: creative writing, translation.  Vision: enhancing blurry images || generate realistic data 
|-
| '''neuron''' || deterministic binary state.  Activation = { 0 (or -1) if x is negative, 1 otherwise } || stochastic binary Hopfield neuron || stochastic binary.  Extended to real-valued in mid 2000s || binary, sigmoid || &lt;!--AE--&gt; language: LSTM.  vision: local receptive fields.  usually real valued relu activation. || &lt;!--VAE--&gt; 
|-
| '''connections''' || 1-layer with symmetric weights.  No self-connections.  || 2-layers.  1-hidden &amp; 1-visible.  symmetric weights. || 2-layers. symmetric weights.  no lateral connections within a layer. || 3-layers:  asymmetric weights. 2 networks combined  into 1.  || &lt;!--AE--&gt; 3-layers. The input is considered a layer even though it has no inbound weights.   recurrent layers for NLP.  feedforward convolutions for vision.  input &amp; output have the same neuron counts. || 3-layers: input, encoder, distribution sampler decoder.  the sampler is not considered a layer (e) 
|-
| '''inference &amp; energy''' || energy is given by Gibbs probability measure :&lt;math&gt;E = -\frac12\sum_{i,j}{w_{ij}{s_i}{s_j}}+\sum_i{\theta_i}{s_i}&lt;/math&gt; || ← same || ←  same || minimize KL divergence || inference is only feed-forward.  previous UL networks ran forwards AND backwards  || minimize error = reconstruction error - KLD 
|-
| '''training''' || Δw&lt;sub&gt;ij&lt;/sub&gt; = s&lt;sub&gt;i&lt;/sub&gt;*s&lt;sub&gt;j&lt;/sub&gt;, for +1/-1 neuron || Δw&lt;sub&gt;ij&lt;/sub&gt; = e*(p&lt;sub&gt;ij&lt;/sub&gt; - p'&lt;sub&gt;ij&lt;/sub&gt;).  This is derived from minimizing KLD.  e = learning rate, p' = predicted and p = actual distribution.
  || contrastive divergence w/ Gibbs Sampling || wake-sleep 2 phase training || &lt;!--AE--&gt; back propagate the reconstruction error || reparameterize hidden state for backprop  
|-
| '''strength''' || resembles physical systems so it inherits their equations || &lt;--- same.  hidden neurons act as internal representatation of the external world || faster more practical training scheme than Boltzmann machines || mildly anatomical. analyzable w/ information theory &amp; statistical mechanics || &lt;!--AE--&gt; || &lt;!--VAE--&gt; 
|-
| '''weakness''' || hopfield || hard to train due to lateral connections || RBM || Helmholtz || &lt;!--AE--&gt; || &lt;!--VAE--&gt; 
|}

'''Specific Networks'''&lt;br&gt;
Here, we highlight some characteristics of each networks.  Ferromagnetism inspired Hopfield networks, Boltzmann machines, and RBMs.  A neuron correspond to an iron domain with binary magnetic moments Up and Down, and neural connections correspond to the domain's influence on each other.  Symmetric connections enables a global energy formulation.  During inference the network updates each state using the standard activation step function.  Symmetric weights guarantees convergence to a stable activation pattern.&lt;br&gt;
'''Hopfield''' networks are used as CAMs and are guaranteed to settle to a some pattern.  Without symmetric weights, the network is very hard to analyze.  With the right energy function, a network will converge.&lt;br&gt;
'''Boltzmann machines''' are stochastic Hopfield nets.  Their state value is sampled from this pdf as follows:  suppose a binary neuron fires with the Bernoulli probability p(1) = 1/3 and rests with p(0) = 2/3.  One samples from it by taking a UNIFORMLY distributed random number y, and plugging it into the inverted cumulative distribution function, which in this case is the step function thresholded at 2/3.  The inverse function = { 0 if x &lt;= 2/3, 1 if x &gt; 2/3 }&lt;br&gt;
'''Helmholtz''' machines are early inspirations for the Variational Auto Encoders.  It's 2 networks combined into one—forward weights operates recognition and backward weights implements imagination.  It is perhaps the first network to do both.  Helmholtz did not work in machine learning but he inspired the view of "statistical inference engine whose function is to infer probable causes of sensory input" (3).  the stochastic binary neuron outputs a probability that its state is 0 or 1.  The data input is normally not considered a layer, but in the Helmholtz machine generation mode, the data layer receives input from the middle layer has separate weights for this purpose, so it is considered a layer.  Hence this network has 3 layers.&lt;br&gt;
'''Variational Autoencoder''' (VAE) are inspired by Helmholtz machines and combines probability network with neural networks.  An Autoencoder is a 3-layer CAM network, where the middle layer is supposed to be some internal representation of input patterns.  The weights are named phi &amp; theta rather than W and V as in Helmholtz—a cosmetic difference.  The encoder neural network is a probability distribution q&lt;sub&gt;φ&lt;/sub&gt;(z|x) and the decoder network is p&lt;sub&gt;θ&lt;/sub&gt;(x|z).  These 2 networks here can be fully connected, or use another NN scheme.

'''Hebbian Learning, ART, SOM'''&lt;br&gt;
The classical example of unsupervised learning in the study of neural networks is [[Donald Hebb]]'s principle, that is, neurons that fire together wire together.&lt;ref&gt;{{Cite book|last1=Buhmann|first1=J.|last2=Kuhnel|first2=H.|title= &amp;#91;Proceedings 1992&amp;#93; IJCNN International Joint Conference on Neural Networks|volume=4|pages=796–801|publisher=IEEE|doi=10.1109/ijcnn.1992.227220|isbn=0780305590|chapter=Unsupervised and supervised data clustering with competitive neural networks|year=1992|s2cid=62651220}}&lt;/ref&gt; In [[Hebbian learning]], the connection is reinforced irrespective of an error, but is exclusively a function of the coincidence between action potentials between the two neurons.&lt;ref&gt;{{Cite journal|last1=Comesaña-Campos|first1=Alberto|last2=Bouza-Rodríguez|first2=José Benito|date=June 2016|title=An application of Hebbian learning in the design process decision-making|journal=Journal of Intelligent Manufacturing|volume=27|issue=3|pages=487–506|doi=10.1007/s10845-014-0881-z|s2cid=207171436|issn=0956-5515|url=https://www.semanticscholar.org/paper/4059b77be03fea077350c106e6e9aa9fce23e8c7}}&lt;/ref&gt; A similar version that modifies synaptic weights takes into account the time between the action potentials ([[spike-timing-dependent plasticity]] or STDP). Hebbian Learning has been hypothesized to underlie a range of cognitive functions, such as [[pattern recognition]] and experiential learning.

Among [[Artificial neural network|neural network]] models, the [[self-organizing map]] (SOM) and [[adaptive resonance theory]] (ART) are commonly used in unsupervised learning algorithms. The SOM is a topographic organization in which nearby locations in the map represent inputs with similar properties. The ART model allows the number of clusters to vary with problem size and lets the user control the degree of similarity between members of the same clusters by means of a user-defined constant called the vigilance parameter. ART networks are used for many pattern recognition tasks, such as [[automatic target recognition]] and seismic signal processing.&lt;ref&gt;{{cite journal|author1=Carpenter, G.A.  |author2=Grossberg, S. |name-list-style=amp |year=1988|title=The ART of adaptive pattern recognition by a self-organizing neural network|journal= Computer|volume=21|issue=3 |pages=77–88|url=http://www.cns.bu.edu/Profiles/Grossberg/CarGro1988Computer.pdf|doi=10.1109/2.33|s2cid=14625094 }}
&lt;/ref&gt;

=== Advanced ===

== See also ==
* [[Automated machine learning]]
* [[Cluster analysis]]
* [[Anomaly detection]]
* [[Expectation–maximization algorithm]]
* [[Generative topographic map]]
* [[Meta-learning (computer science)]]
* [[Multivariate analysis]]
* [[Radial basis function network]]
*[[Weak supervision]]

== Notes ==
{{Reflist}}

== Further reading ==
* {{cite book |editor1=Bousquet, O. |editor3=Raetsch, G. |editor2=von Luxburg, U. |title=Advanced Lectures on Machine Learning |url=https://archive.org/details/springer_10.1007-b100712 |publisher=Springer-Verlag |year=2004 |isbn=978-3540231226}}
* {{cite book |author1=Duda, Richard O. |author2-link=Peter E. Hart |author2=Hart, Peter E. |author3=Stork, David G. |year=2001 |chapter=Unsupervised Learning and Clustering  |title=Pattern classification |edition=2nd |publisher=Wiley |isbn=0-471-05669-3|author1-link=Richard O. Duda |title-link=Pattern classification }}
*{{cite book |first1=Trevor |last1=Hastie |first2=Robert |last2=Tibshirani |title=The Elements of Statistical Learning: Data mining, Inference, and Prediction |year=2009 |publisher=Springer| location=New York |isbn=978-0-387-84857-0 |pages=485–586 |doi=10.1007/978-0-387-84858-7_14}}
* {{cite book |editor1=Hinton, Geoffrey |editor-link=Geoffrey Hinton |editor2=Sejnowski, Terrence J. |editor2-link=Terrence J. Sejnowski |year=1999 |title=Unsupervised Learning: Foundations of Neural Computation |publisher=[[MIT Press]] |isbn=0-262-58168-X}} (This book focuses on unsupervised learning in [[neural network]]s)

{{DEFAULTSORT:Unsupervised Learning}}
[[Category:Unsupervised learning| ]]
[[Category:Machine learning]]</text>
      <sha1>id2whnkf1iwrvttyo9ootpfvdezbuap</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Loss functions</title>
    <ns>14</ns>
    <id>28004586</id>
    <revision>
      <id>740645154</id>
      <parentid>739999869</parentid>
      <timestamp>2016-09-22T10:45:53Z</timestamp>
      <contributor>
        <username>Marcocapelle</username>
        <id>14965160</id>
      </contributor>
      <comment>removed [[Category:Econometrics]], this is rather about decision theory</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="89" xml:space="preserve">[[Category:Model selection]]
[[Category:Optimal decisions]]
[[Category:Machine learning]]</text>
      <sha1>7rco192043fhyqgwwii50538sfona3u</sha1>
    </revision>
  </page>
  <page>
    <title>Meta learning (computer science)</title>
    <ns>0</ns>
    <id>4615464</id>
    <revision>
      <id>994178598</id>
      <parentid>993114014</parentid>
      <timestamp>2020-12-14T13:41:34Z</timestamp>
      <contributor>
        <username>WikiCleanerBot</username>
        <id>18872885</id>
      </contributor>
      <minor/>
      <comment>v2.04b - [[User:WikiCleanerBot#T20|Bot T20 CW#61]] - Fix errors for [[WP:WCW|CW project]] (Reference before punctuation)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="20105" xml:space="preserve">{{short description|Subfield of machine learning}}
{{About|meta learning in machine learning|meta learning in social psychology|Meta learning|metalearning in neuroscience|Metalearning (neuroscience)}}
{{More citations needed|date=August 2010}}
'''Meta learning'''&lt;ref name="sch1987"&gt;{{cite journal | last1 = Schmidhuber | first1 = Jürgen | year = 1987| title = Evolutionary principles in self-referential learning, or on learning how to learn: the meta-meta-... hook | url= http://people.idsia.ch/~juergen/diploma1987ocr.pdf | journal = Diploma Thesis, Tech. Univ. Munich}}&lt;/ref&gt;&lt;ref name="scholarpedia"&gt;{{cite journal | last1 = Schaul | first1 = Tom | last2 = Schmidhuber | first2 = Jürgen | year = 2010| title = Metalearning | journal = Scholarpedia | volume = 5 | issue = 6| page = 4650 | doi=10.4249/scholarpedia.4650| bibcode = 2010SchpJ...5.4650S | doi-access = free }}&lt;/ref&gt;
is a subfield of [[machine learning]] where automatic learning algorithms are applied to [[meta-data|metadata]] about machine learning experiments. As of 2017 the term had not found a standard interpretation, however the main goal is to use such metadata to understand how automatic learning can become flexible in solving learning problems, hence to improve the performance of existing [[learning algorithms]] or to learn (induce) the learning algorithm itself, hence the alternative term '''learning to learn'''.&lt;ref name="sch1987" /&gt;

Flexibility is important because each learning algorithm is based on a set of assumptions about the data, its [[inductive bias]].&lt;ref name="utgoff1986"&gt;{{Cite journal 
 | author = P. E. Utgoff
 | title = Shift of bias for inductive concept learning
 | journal = In R. Michalski, J. Carbonell, &amp; T. Mitchell: Machine Learning
 | pages = 163–190
 | year = 1986
}}&lt;/ref&gt; This means that it will only learn well if the bias matches the learning problem. A learning algorithm may perform very well in one domain, but not on the next. This poses strong restrictions on the use of [[machine learning]] or [[data mining]] techniques, since the relationship between the learning problem (often some kind of [[database]]) and the effectiveness of different learning algorithms is not yet understood.

By using different kinds of metadata, like properties of the learning problem, algorithm properties (like performance measures), or patterns previously derived from the data, it is possible to learn, select, alter or combine different learning algorithms to effectively solve a given learning problem. Critiques of meta learning approaches bear a strong resemblance to the critique of [[metaheuristic]], a possibly related problem. A good analogy to meta-learning, and the inspiration for [[Jürgen Schmidhuber]]'s early work (1987)&lt;ref name="sch1987" /&gt; and [[Yoshua Bengio]] et al.'s work (1991),&lt;ref&gt;{{cite conference|last=Bengio|first=Yoshua|last2=Bengio|first2=Samy|last3=Cloutier|first3=Jocelyn|conference=IJCNN'91|url=http://bengio.abracadoudou.com/publications/pdf/bengio_1991_ijcnn.pdf|date=1991|title=Learning to learn a synaptic rule}}&lt;/ref&gt; considers that genetic evolution learns the learning procedure encoded in genes and executed in each individual's brain. In an open-ended hierarchical meta learning system&lt;ref name="sch1987" /&gt; using [[genetic programming]], better evolutionary methods can be learned by meta evolution, which itself can be improved by meta meta evolution, etc.&lt;ref name="sch1987" /&gt;

== Definition ==
A proposed definition&lt;ref&gt;{{Cite journal|last=Lemke|first=Christiane|last2=Budka|first2=Marcin|last3=Gabrys|first3=Bogdan|date=2013-07-20|title=Metalearning: a survey of trends and technologies|journal=Artificial Intelligence Review|language=en|volume=44|issue=1|pages=117–130|doi=10.1007/s10462-013-9406-y|issn=0269-2821|pmc=4459543|pmid=26069389}}&lt;/ref&gt; for a meta learning system combines three requirements:
* The system must include a learning subsystem.
* Experience is gained by exploiting meta knowledge extracted
** in a previous learning episode on a single dataset, or
** from different domains.
* Learning bias must be chosen dynamically.
''Bias'' refers to the assumptions that influence the choice of explanatory hypotheses&lt;ref&gt;{{Cite book|title=Metalearning - Springer|doi=10.1007/978-3-540-73263-1|series = Cognitive Technologies|year = 2009|isbn = 978-3-540-73262-4|last1 = Brazdil|first1 = Pavel|last2=Carrier|first2=Christophe Giraud|last3=Soares|first3=Carlos|last4=Vilalta|first4=Ricardo}}&lt;/ref&gt; and not the notion of bias represented in the [[bias-variance dilemma]]. Meta learning is concerned with two aspects of learning bias.
* Declarative bias specifies the representation of the space of hypotheses, and affects the size of the search space (e.g., represent hypotheses using linear functions only).
* Procedural bias imposes constraints on the ordering of the inductive hypotheses (e.g., preferring smaller hypotheses). &lt;ref&gt;{{cite journal |last1=Gordon |first1=Diana |last2=Desjardins |first2=Marie |title=Evaluation and Selection of Biases in Machine Learning |journal=Machine Learning |date=1995 |volume=20 |pages=5–22 |doi=10.1023/A:1022630017346 |url=https://link.springer.com/content/pdf/10.1023/A:1022630017346.pdf |access-date=27 March 2020}}&lt;/ref&gt;

==Common approaches==
There are three common approaches:&lt;ref name="paper1"&gt;[https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html] Lilian Weng(2018). Meta-Learning: Learning to Learn Fast. OpenAI Blog . November 2018 . Retrieved 27 October 2019&lt;/ref&gt;
* 1) using (cyclic) networks with external or internal memory (model-based)
* 2) learning effective distance metrics (metrics-based)
* 3) explicitly optimizing model parameters for fast learning (optimization-based).

===Model-Based===
Model-based meta-learning models updates its parameters rapidly with a few training steps, which can be achieved by its internal architecture or controlled by another meta-learner model.&lt;ref name="paper1"/&gt;

====Memory-Augmented Neural Networks====
The model is known as MANN short for Memory-Augmented [[Neural Network]]s, which is expected to encode new information fast and thus to adapt to new tasks after only a few samples, it fits well for meta-learning.&lt;ref name="paper2"&gt;[http://proceedings.mlr.press/v48/santoro16.pdf] Adam Santoro, Sergey Bartunov, Daan Wierstra, Timothy Lillicrap. Meta-Learning with Memory-Augmented Neural Networks. Google DeepMind. Retrieved 29 October 2019&lt;/ref&gt;

====Meta Networks====
Meta Networks (MetaNet) learns a meta-level knowledge across tasks and shifts its inductive biases via fast parameterization for rapid generalization.&lt;ref name="paper3"&gt;[https://arxiv.org/abs/1703.00837] Tsendsuren Munkhdalai , Hong Yu(2017). Meta Networks.arXiv:1703.00837 [cs.LG]&lt;/ref&gt;

===Metric-Based===
The core idea in metric-based meta-learning is similar to [[K-nearest neighbor algorithm|nearest neighbors]] algorithms, which weight is generated by a kernel function. It aims to learn a metric or distance function over objects. The notion of a good metric is problem-dependent. It should represent the relationship between inputs in the task space and facilitate problem solving.&lt;ref name="paper1" /&gt;

====Convolutional Siamese [[Neural Network]]====
Siamese [[neural network]] is composed of two twin networks whose output is jointly trained. There is a function above to learn the relationship between input data sample pairs. The two networks are the same, sharing the same weight and network parameters.&lt;ref name="paper4"&gt;[http://www.cs.toronto.edu/~rsalakhu/papers/oneshot1.pdf] Gregory Koch GKOCH, Richard Zemel ZEMEL, Ruslan Salakhutdinov(2015).Siamese Neural Networks for One-shot Image Recognition. Department of Computer Science, University of Toronto. Toronto, Ontario, Canada.&lt;/ref&gt;

====Matching Networks====
Matching Networks learn a network that maps a small labelled support set and an unlabelled example to its label, obviating the need for fine-tuning to adapt to new class types.&lt;ref name="paper5"&gt;[http://papers.nips.cc/paper/6385-matching-networks-for-one-shot-learning.pdf] Vinyals, O. , Blundell, C. , Lillicrap, T. , Kavukcuoglu, K. , &amp; Wierstra, D. . (2016). Matching networks for one shot learning. Google DeepMind. Retrieved 3 November, 2019&lt;/ref&gt;

====Relation Network====
The Relation Network (RN), is trained end-to-end from scratch. During meta-learning, it learns to learn a deep distance metric to compare a small number of images within episodes, each of which is designed to simulate the few-shot setting.&lt;ref name="paper6"&gt;[http://openaccess.thecvf.com/content_cvpr_2018/papers_backup/Sung_Learning_to_Compare_CVPR_2018_paper.pdf] Sung, F. , Yang, Y. , Zhang, L. , Xiang, T. , Torr, P. H. S. , &amp; Hospedales, T. M. . (2018). Learning to compare: relation network for few-shot learning&lt;/ref&gt;

====Prototypical Networks====
Prototypical Networks learn a [[metric space]] in which classification can be performed by computing distances to prototype representations of each class. Compared to recent approaches for few-shot learning, they reflect a simpler inductive bias that is beneficial in this limited-data regime, and achieve satisfied results.&lt;ref name="paper7"&gt;[http://papers.nips.cc/paper/6996-prototypical-networks-for-few-shot-learning.pdf] Snell, J. , Swersky, K. , &amp; Zemel, R. S. . (2017). Prototypical networks for few-shot learning.&lt;/ref&gt;

===Optimization-Based===
What optimization-based meta-learning algorithms intend for is to adjust the [[optimization algorithm]] so that the model can be good at learning with a few examples.&lt;ref name="paper1"/&gt;

====LSTM Meta-Learner====
LSTM-based meta-learner is to learn the exact [[optimization algorithm]] used to train another learner [[neural network]] [[classification rule|classifier]] in the few-shot regime. The parametrization allows it to learn appropriate parameter updates specifically for the [[scenario]] where a set amount of updates will be made, while also learning a general initialization of the learner (classifier) network that allows for quick convergence of training.&lt;ref name="paper8"&gt;[https://openreview.net/pdf?id=rJY0-Kcll] Sachin Ravi∗and Hugo Larochelle(2017).” Optimization as a model for few-shot learning”. ICLR 2017. Retrieved 3 November, 2019&lt;/ref&gt;

====Temporal Discreteness====
MAML, short for Model-Agnostic Meta-Learning, is a fairly general [[optimization algorithm]], compatible with any model that learns through gradient descent.&lt;ref name="paper9"&gt;[https://arxiv.org/abs/1703.03400] Chelsea Finn, Pieter Abbeel, Sergey Levine(2017). “Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks” arXiv:1703.03400 [cs.LG]&lt;/ref&gt;

====Reptile====
Reptile is a remarkably simple meta-learning optimization algorithm, given that both rely on meta-optimization through gradient descent and both are model-agnostic.&lt;ref name="paper10"&gt;[https://arxiv.org/abs/1803.02999] Chelsea Finn, Pieter Abbeel, Sergey Levine(2017). Alex Nichol and Joshua Achiam and John Schulman(2018).” On First-Order Meta-Learning Algorithms”. arXiv:1803.02999 [cs.LG]&lt;/ref&gt;

==Examples==

Some approaches which have been viewed as instances of meta learning:

* [[Recurrent neural networks]] (RNNs) are universal computers. In 1993, [[Jürgen Schmidhuber]] showed how "self-referential" RNNs can in principle learn by [[backpropagation]] to run their own weight change algorithm, which may be quite different from backpropagation.&lt;ref name="sch1993"&gt;{{cite journal | last1 = Schmidhuber | first1 = Jürgen | year = 1993| title = A self-referential weight matrix | journal = Proceedings of ICANN'93, Amsterdam | pages = 446–451}}&lt;/ref&gt; In 2001, [[Sepp Hochreiter]] &amp; A.S. Younger &amp; P.R. Conwell built a successful supervised meta learner based on [[Long short-term memory]] RNNs. It learned through backpropagation a learning algorithm for quadratic functions that is much faster than backpropagation.&lt;ref name="hoch2001"&gt;{{cite journal | last1 = Hochreiter | first1 = Sepp | last2 = Younger | first2 = A. S. | last3 = Conwell | first3 = P. R. | year = 2001| title = Learning to Learn Using Gradient Descent | journal = Proceedings of ICANN'01| pages = 87–94}}&lt;/ref&gt;&lt;ref name="scholarpedia" /&gt; Researchers at [[Deepmind]] (Marcin Andrychowicz et al.) extended this approach to optimization in 2017.&lt;ref name="marcin2017"&gt;{{cite journal | last1 = Andrychowicz | first1 = Marcin | last2 = Denil | first2 = Misha | last3 = Gomez | first3 = Sergio | last4 = Hoffmann | first4 = Matthew | last5 = Pfau | first5 = David | last6 = Schaul | first6 = Tom | last7 = Shillingford | first7 = Brendan | last8 = de Freitas | first8 = Nando | year = 2017| title = Learning to learn by gradient descent by gradient descent | journal = Proceedings of ICML'17, Sydney, Australia}}&lt;/ref&gt;

* In the 1990s, Meta [[Reinforcement Learning]] or Meta RL was achieved in Schmidhuber's research group through self-modifying policies written in a universal programming language that contains special instructions for changing the policy itself. There is a single lifelong trial. The goal of the RL agent is to maximize reward. It learns to accelerate reward intake by continually improving its own learning algorithm which is part of the "self-referential" policy.&lt;ref name="sch1994"&gt;{{cite journal | last1 = Schmidhuber | first1 = Jürgen | year = 1994| title = On learning how to learn learning strategies | journal = Technical Report FKI-198-94, Tech. Univ. Munich}}&lt;/ref&gt;&lt;ref name="sch1997"&gt;{{cite journal | last1 = Schmidhuber | first1 = Jürgen | last2 = Zhao | first2 = J. | last3 = Wiering | first3 = M. | year = 1997| title = Shifting inductive bias with success-story algorithm, adaptive Levin search, and incremental self-improvement | journal = Machine Learning | volume = 28 | pages = 105–130 | doi=10.1023/a:1007383707642| doi-access = free }}&lt;/ref&gt; 
* An extreme type of Meta [[Reinforcement Learning]] is embodied by the [[Gödel machine]], a theoretical construct which can inspect and modify any part of its own software which also contains a general [[Automated theorem proving|theorem prover]]. It can achieve [[recursive self-improvement]] in a provably optimal way.&lt;ref name="goedelmachine"&gt;{{cite journal | last1 = Schmidhuber | first1 = Jürgen | year = 2006| title = Gödel machines: Fully Self-Referential Optimal Universal Self-Improvers | url=https://archive.org/details/arxiv-cs0309048| journal = In B. Goertzel &amp; C. Pennachin, Eds.: Artificial General Intelligence | pages = 199–226}}&lt;/ref&gt;&lt;ref name="scholarpedia" /&gt;
* ''Model-Agnostic Meta-Learning'' (MAML) was introduced in 2017 by Chelsea Finn et al.&lt;ref name="maml" /&gt; Given a sequence of tasks, the parameters of a given model are trained such that few iterations of gradient descent with few training data from a new task will lead to good generalization performance on that task. MAML "trains the model to be easy to fine-tune."&lt;ref name="maml" /&gt; MAML was successfully applied to few-shot image classification benchmarks and to policy gradient-based reinforcement learning.&lt;ref name="maml"&gt;{{cite arxiv | last1 = Finn | first1 = Chelsea | last2 = Abbeel | first2 = Pieter | last3 = Levine | first3 = Sergey |year = 2017| title = Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks | eprint=1703.03400|class=cs.LG }}&lt;/ref&gt;
* ''Discovering [[meta-knowledge]]'' works by inducing knowledge (e.g. rules) that expresses how each learning method will perform on different learning problems. The metadata is formed by characteristics of the data (general, statistical, information-theoretic,... ) in the learning problem, and characteristics of the learning algorithm (type, parameter settings, performance measures,...). Another learning algorithm then learns how the data characteristics relate to the algorithm characteristics. Given a new learning problem, the data characteristics are measured, and the performance of different learning algorithms are predicted. Hence, one can predict the algorithms best suited for the new problem.
* ''Stacked generalisation'' works by combining multiple (different) learning algorithms. The metadata is formed by the predictions of those different algorithms. Another learning algorithm learns from this metadata to predict which combinations of algorithms give generally good results. Given a new learning problem, the predictions of the selected set of algorithms are combined (e.g. by (weighted) voting) to provide the final prediction. Since each algorithm is deemed to work on a subset of problems, a combination is hoped to be more flexible and able to make good predictions.
* ''[[Boosting (meta-algorithm)|Boosting]]'' is related to stacked generalisation, but uses the same algorithm multiple times, where the examples in the training data get different weights over each run. This yields different predictions, each focused on rightly predicting a subset of the data, and combining those predictions leads to better (but more expensive) results.
* ''Dynamic bias selection'' works by altering the inductive bias of a learning algorithm to match the given problem. This is done by altering key aspects of the learning algorithm, such as the hypothesis representation, heuristic formulae, or parameters. Many different approaches exist.
* ''[[Inductive transfer]]'' studies how the learning process can be improved over time. Metadata consists of knowledge about previous learning episodes and is used to efficiently develop an effective hypothesis for a new task. A related approach is called [[learning to learn]], in which the goal is to use acquired knowledge from one domain to help learning in other domains.
* Other approaches using metadata to improve automatic learning are [[learning classifier system]]s, [[case-based reasoning]] and [[constraint satisfaction]].
* Some initial, theoretical work has been initiated to use ''[[Applied Behavioral Analysis]]'' as a foundation for agent-mediated meta-learning about the performances of human learners, and adjust the instructional course of an artificial agent.&lt;ref name="Begoli, PRS-ABA, ABA Ontology"&gt;{{cite book|last1=Begoli|first1=Edmon|title=Procedural-Reasoning Architecture for Applied Behavior Analysis-based Instructions|date=May 2014|publisher=University of Tennessee, Knoxville|location=Knoxville, Tennessee, USA|pages=44–79|url=http://trace.tennessee.edu/utk_graddiss/2749|access-date=14 October 2017}}&lt;/ref&gt;
* [[AutoML]] such as Google Brain's "AI building AI" project, which according to Google briefly exceeded existing [[ImageNet]] benchmarks in 2017.&lt;ref&gt;{{cite news|title=Robots Are Now 'Creating New Robots,' Tech Reporter Says|url=https://www.npr.org/2018/03/15/593863645/robots-are-now-creating-new-robots-tech-reporter-says|access-date=29 March 2018|work=NPR.org|date=2018|language=en}}&lt;/ref&gt;&lt;ref&gt;{{cite news|title=AutoML for large scale image classification and object detection|url=https://research.googleblog.com/2017/11/automl-for-large-scale-image.html|access-date=29 March 2018|work=Google Research Blog|date=November 2017}}&lt;/ref&gt;

&lt;!--==See also==

--&gt;==References==
{{Reflist}}

== External links ==
* [http://www.scholarpedia.org/article/Metalearning Metalearning] article in [[Scholarpedia]]
* Vilalta R. and Drissi Y. (2002). ''[http://axon.cs.byu.edu/Dan/478/misc/Vilalta.pdf A perspective view and survey of meta-learning]'', Artificial Intelligence Review, 18(2), 77—95.
* Giraud-Carrier, C., &amp; Keller, J. (2002). Dealing with the data flood, J. Meij (ed), chapter Meta-Learning. STT/Beweton, The Hague.
* Brazdil P., Giraud-Carrier C., Soares C., Vilalta R. (2009) [https://books.google.com/books?id=-Gsi_cxZGpcC&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false Metalearning: applications to data mining], chapter Metalearning: Concepts and Systems, Springer
* Video courses about Meta-Learning with step-by-step explanation of [https://www.youtube.com/watch?v=IkDw22a8BDE MAML], [https://www.youtube.com/watch?v=rHGPfl0pvLY Prototypical Networks], and [https://www.youtube.com/watch?v=j8qDaVfrO_c Relation Networks]. 

{{DEFAULTSORT:Meta Learning (Computer Science)}}
[[Category:Machine learning]]</text>
      <sha1>a2abwvt5g8mgqms1zi24ejxmm1io2qg</sha1>
    </revision>
  </page>
  <page>
    <title>Multi-armed bandit</title>
    <ns>0</ns>
    <id>2854828</id>
    <revision>
      <id>994953571</id>
      <parentid>992720211</parentid>
      <timestamp>2020-12-18T11:52:34Z</timestamp>
      <contributor>
        <username>WikiCleanerBot</username>
        <id>18872885</id>
      </contributor>
      <minor/>
      <comment>v2.04b - [[User:WikiCleanerBot#T20|Bot T20 CW#61]] - Fix errors for [[WP:WCW|CW project]] (Reference before punctuation)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="63566" xml:space="preserve">[[File:Las Vegas slot machines.jpg|thumb|right|A row of slot machines in Las Vegas]]

In [[probability theory]], the '''multi-armed bandit problem''' (sometimes called the '''''K''-&lt;ref name="doi10.1023/A:1013689704352"&gt;{{Cite journal | last1 = Auer | first1 = P. | last2 = Cesa-Bianchi | first2 = N. | last3 = Fischer | first3 = P. | journal = Machine Learning | volume = 47 | issue = 2/3 | pages = 235–256 | year = 2002 |title=Finite-time Analysis of the Multiarmed Bandit Problem| doi = 10.1023/A:1013689704352 | doi-access = free }}&lt;/ref&gt; or ''N''-armed bandit problem'''&lt;ref&gt;{{Cite journal | last1 = Katehakis | first1 = M. N. | last2 = Veinott | first2 = A. F. | doi = 10.1287/moor.12.2.262 | title = The Multi-Armed Bandit Problem: Decomposition and Computation | journal = Mathematics of Operations Research | volume = 12 | issue = 2 | pages = 262–268 | year = 1987 | s2cid = 656323 | url = https://semanticscholar.org/paper/e4fe28113fed71999a0db30a930e0b42d3ce55f1 }}&lt;/ref&gt;) is a problem in which a fixed limited set of resources must be allocated between competing (alternative) choices in a way that maximizes their expected gain, when each choice's properties are only partially known at the time of allocation, and may become better understood as time passes or by allocating resources to the choice.&lt;ref name="Gittins89" /&gt;&lt;ref name="BF"/&gt; This is a classic [[reinforcement learning]] problem that exemplifies the exploration&amp;ndash;exploitation tradeoff dilemma. The name comes from imagining a [[gambler]] at a row of [[slot machines]] (sometimes known as "[[wikt:one-armed bandit|one-armed bandit]]s"), who has to decide which machines to play, how many times to play each machine and in which order to play them, and whether to continue with the current machine or try a different machine.&lt;ref name="weber"&gt;{{citation
 | last = Weber | first = Richard
 | issue = 4
 | journal = [[Annals of Applied Probability]]
 | pages = 1024–1033
 | title = On the Gittins index for multiarmed bandits
 | volume = 2
 | year = 1992
 | jstor=2959678
 | doi = 10.1214/aoap/1177005588| doi-access = free
 }}&lt;/ref&gt; The multi-armed bandit problem also falls into the broad category of [[stochastic scheduling]].

In the problem, each machine provides a random reward from a [[probability distribution]] specific to that machine. The objective of the gambler is to maximize the sum of rewards earned through a sequence of lever pulls.&lt;ref name="Gittins89"/&gt;&lt;ref Name="BF"/&gt; The crucial tradeoff the gambler faces at each trial is between "exploitation" of the machine that has the highest expected payoff and "exploration" to get more [[Bayes' theorem|information]] about the expected payoffs of the other machines. The trade-off between exploration and exploitation is also faced in [[machine learning]]. In practice, multi-armed bandits have been used to model problems such as managing research projects in a large organization like a science foundation or a [[Pharmaceutical industry|pharmaceutical company]].&lt;ref name="Gittins89" /&gt;&lt;ref name="BF"/&gt; In early versions of the problem, the gambler begins with no initial knowledge about the machines.

[[Herbert Robbins]] in 1952, realizing the importance of the problem, constructed convergent population selection strategies in "some aspects of the sequential design of experiments".&lt;ref&gt;{{Cite journal | last1 = Robbins | first1 = H. | title = Some aspects of the sequential design of experiments | doi = 10.1090/S0002-9904-1952-09620-8 | journal = Bulletin of the American Mathematical Society | volume = 58 | issue = 5 | pages = 527–535 | year = 1952 | doi-access = free }}&lt;/ref&gt; A theorem, the [[Gittins index]], first published by [[John C. Gittins]], gives an optimal policy for maximizing the expected discounted reward.&lt;ref&gt;{{cite journal | author = J. C. Gittins | author-link = John C. Gittins | year = 1979 | title = Bandit Processes and Dynamic Allocation Indices | journal = Journal of the Royal Statistical Society. Series B (Methodological)  | volume = 41 | issue = 2 | pages = 148–177 | doi =  10.1111/j.2517-6161.1979.tb01068.x| jstor = 2985029 }}&lt;/ref&gt;

==Empirical motivation==
[[File:The Jet Propulsion Laboratory (9416811752).jpg|thumb|How must a given budget be distributed among these research departments to maximize results?]]
The multi-armed bandit problem models an agent that simultaneously attempts to acquire new knowledge (called "exploration") and optimize their decisions based on existing knowledge (called "exploitation"). The agent attempts to balance these competing tasks in order to maximize their total value over the period of time considered. There are many practical applications of the bandit model, for example:

* [[clinical trial]]s investigating the effects of different experimental treatments while minimizing patient losses,&lt;ref name="Gittins89" /&gt;&lt;ref name="BF"/&gt;&lt;ref name="WHP"/&gt;&lt;ref name="KD"&gt;Press (1986)&lt;/ref&gt;
* [[adaptive routing]] efforts for minimizing delays in a network,
* [[Portfolio (finance)|financial portfolio design]]&lt;ref name="BrochuHoffmandeFreitas" /&gt;&lt;ref name="ShenWangJiangZha" /&gt;

In these practical examples, the problem requires balancing reward maximization based on the knowledge already acquired with attempting new actions to further increase knowledge. This is known as the ''exploitation vs. exploration tradeoff'' in [[machine learning]].

The model has also been used to control dynamic allocation of resources to different projects, answering the question of which project to work on, given uncertainty about the difficulty and payoff of each possibility.&lt;ref name="farias2011irrevocable" /&gt;

Originally considered by Allied scientists in [[World War II]], it proved so intractable that, according to [[Peter Whittle (mathematician)|Peter Whittle]], the problem was proposed to be dropped over [[Germany]] so that German scientists could also waste their time on it.&lt;ref name="Whittle79"/&gt;

The version of the problem now commonly analyzed was formulated by [[Herbert Robbins]] in 1952.

==The multi-armed bandit model==
The multi-armed bandit (short: ''bandit'' or MAB) can be seen as a set of real [[Probability distribution|distributions]] &lt;math&gt;B = \{R_1, \dots ,R_K\}&lt;/math&gt;, each distribution being  associated with the rewards delivered by one of the &lt;math&gt;K \in \mathbb{N}^+&lt;/math&gt; levers. Let &lt;math&gt;\mu_1, \dots , \mu_K&lt;/math&gt; be the mean values associated with these reward distributions. The gambler iteratively plays one lever per round and observes the associated reward. The objective is to maximize the sum of the collected rewards. The horizon &lt;math&gt;H&lt;/math&gt; is the number of rounds that remain to be played. The bandit problem is formally equivalent to a one-state [[Markov decision process]]. The [[Regret (decision theory)|regret]] &lt;math&gt;\rho&lt;/math&gt; after &lt;math&gt;T&lt;/math&gt; rounds is defined as the expected difference between the reward sum associated with an optimal strategy and the sum of the collected rewards: 

&lt;math&gt;\rho = T \mu^* - \sum_{t=1}^T \widehat{r}_t&lt;/math&gt;,

where &lt;math&gt;\mu^*&lt;/math&gt; is the maximal reward mean, &lt;math&gt;\mu^* = \max_k \{ \mu_k \}&lt;/math&gt;, and &lt;math&gt;\widehat{r}_t&lt;/math&gt; is the reward in round ''t''.

A ''zero-regret strategy'' is a strategy whose average regret per round &lt;math&gt;\rho / T&lt;/math&gt; tends to zero with probability 1 when the number of played rounds tends to infinity.&lt;ref name="Vermorel2005"/&gt; Intuitively, zero-regret strategies are guaranteed to converge to a (not necessarily unique) optimal strategy if enough rounds are played.

==Variations==
A common formulation is the ''Binary multi-armed bandit'' or ''Bernoulli multi-armed bandit,'' which issues a reward of one with probability &lt;math&gt;p&lt;/math&gt;, and otherwise a reward of zero.

Another formulation of the multi-armed bandit has each arm representing an independent Markov machine. Each time a particular arm is played, the state of that machine advances to a new one, chosen according to the Markov state evolution probabilities. There is a reward depending on the current state of the machine. In a generalization called the "restless bandit problem", the states of non-played arms can also evolve over time.&lt;ref name="Whittle88"/&gt; There has also been discussion of systems where the number of choices (about which arm to play) increases over time.&lt;ref name="Whittle81"/&gt;

Computer science researchers have studied multi-armed bandits under worst-case assumptions, obtaining algorithms to minimize regret in both finite and infinite ([[asymptotic]]) time horizons for both stochastic&lt;ref name="doi10.1023/A:1013689704352"/&gt; and non-stochastic&lt;ref&gt;{{Cite journal | last1 = Auer | first1 = P. | last2 = Cesa-Bianchi | first2 = N. | last3 = Freund | first3 = Y. | last4 = Schapire | first4 = R. E. | title = The Nonstochastic Multiarmed Bandit Problem | doi = 10.1137/S0097539701398375 | journal = [[SIAM Journal on Computing|SIAM J. Comput.]] | volume = 32 | issue = 1 | pages = 48–77 | year = 2002 | citeseerx = 10.1.1.130.158 }}&lt;/ref&gt; arm payoffs.

==Bandit strategies==
A major breakthrough was the construction of optimal population selection strategies, or policies (that possess uniformly maximum convergence rate  to the population with highest mean) in the work described below.

===Optimal solutions===
&lt;!-- [[File:1966-HerbertRobbins.jpg|thumb|Herbert Robbins]] --&gt;
In the paper "Asymptotically efficient adaptive allocation rules", Lai and Robbins&lt;ref&gt;{{cite journal | last1 = Lai | first1 = T.L. | last2 = Robbins | first2 = H. | year = 1985 | title = Asymptotically efficient adaptive allocation rules | journal = Advances in Applied Mathematics | volume = 6 | issue = 1| pages =4–22 | doi = 10.1016/0196-8858(85)90002-8  }}&lt;/ref&gt;  (following papers of Robbins and his co-workers going back to Robbins in the year 1952) constructed convergent population selection policies that possess the fastest rate of convergence (to the population with highest mean) for the case that the population reward distributions are the one-parameter exponential family.  Then, in [[Michael Katehakis|Katehakis]] and [[Herbert Robbins|Robbins]]&lt;ref&gt;{{cite journal | last1 = Katehakis | first1 = M.N. | last2 = Robbins | first2 = H.  | year = 1995 | title = Sequential choice from several populations | journal = Proceedings of the National Academy of Sciences of the United States of America | volume = 92 | issue = 19| pages =8584–5 | doi = 10.1073/pnas.92.19.8584 | pmid = 11607577 | pmc = 41010  | bibcode = 1995PNAS...92.8584K}}&lt;/ref&gt; simplifications of the policy and the main proof were given for the case of normal populations with known variances. The next notable progress was obtained by Burnetas and [[Michael Katehakis|Katehakis]]  in the paper "Optimal adaptive policies for sequential allocation problems",&lt;ref&gt;{{cite journal | last1 = Burnetas | first1 = A.N. | last2 = Katehakis | first2 = M.N. | year = 1996 | title = Optimal adaptive policies for sequential allocation problems | journal = Advances in Applied Mathematics | volume = 17 | issue = 2| pages =122–142 | doi = 10.1006/aama.1996.0007  }}&lt;/ref&gt; where index based policies  with uniformly maximum convergence rate were constructed, under more general conditions that include the case in which the distributions of outcomes from each population depend on a vector of unknown parameters. Burnetas and Katehakis (1996) also provided an explicit solution for the important case in which the distributions of outcomes follow arbitrary (i.e., non-parametric) discrete, univariate distributions.

Later in "Optimal adaptive policies for Markov decision processes"&lt;ref&gt;{{cite journal | last1 = Burnetas | first1 = A.N. | last2 = Katehakis | first2 = M.N. | year = 1997 | title = Optimal adaptive policies for Markov decision processes | journal = Math. Oper. Res. | volume = 22 | issue = 1| pages =222–255 | doi = 10.1287/moor.22.1.222  }}&lt;/ref&gt;  Burnetas and Katehakis studied the much larger model of Markov Decision Processes under partial information,  where the transition law and/or the expected one period rewards may depend on unknown parameters. In this work the explicit form for a class of adaptive policies that possess uniformly maximum convergence rate  properties for the total expected finite horizon reward, were constructed under sufficient assumptions of finite state-action spaces and irreducibility of the transition law. A main feature of these policies is that the choice of actions, at each state and time period, is based on indices that are inflations of the right-hand side of the estimated average reward optimality equations. These inflations have recently been called the optimistic approach in the work of Tewari and Bartlett,&lt;ref&gt;{{cite journal | last1 = Tewari | first1 = A. | last2 = Bartlett | first2 = P.L. | year = 2008 | title = Optimistic linear programming gives logarithmic regret for irreducible MDPs | url = http://books.nips.cc/papers/files/nips20/NIPS2007_0673.pdf | journal = Advances in Neural Information Processing Systems | volume = 20 | citeseerx=10.1.1.69.5482 }}&lt;/ref&gt; Ortner&lt;ref&gt;{{cite journal | last1 = Ortner | first1 = R. | year = 2010 | title = Online regret bounds for Markov decision processes with deterministic transitions | journal = Theoretical Computer Science | volume = 411 | issue = 29| pages =2684–2695 | doi = 10.1016/j.tcs.2010.04.005  }}&lt;/ref&gt; Filippi,  Cappé, and Garivier,&lt;ref&gt;Filippi, S. and Cappé, O. and Garivier, A. (2010). "Online regret bounds for Markov decision processes with deterministic transitions", ''Communication, Control, and Computing (Allerton), 2010 48th Annual Allerton Conference on'', pp. 115–122&lt;/ref&gt; and Honda and Takemura.&lt;ref&gt;{{cite journal | last1=Honda | first1= J.|last2= Takemura  | first2= A. |year=2011|title=An asymptotically optimal policy for finite support models in the multi-armed bandit problem|journal=Machine Learning|volume=85|issue=3|pages= 361–391 | arxiv=0905.2776 |doi=10.1007/s10994-011-5257-4| s2cid= 821462}}&lt;/ref&gt;

When optimal solutions to multi-arm bandit tasks &lt;ref&gt; {{cite journal | last1 = Averbeck | first1 = B.B. | title = Theory of choice in bandit, information sampling, and foraging tasks | journal = PLOS Computational Biology | volume = 11 | issue = 3 | pages = e1004164 | doi = 10.1371/journal.pcbi.1004164 | pmid = 25815510 | pmc = 4376795 | year = 2015 | bibcode = 2015PLSCB..11E4164A }}&lt;/ref&gt; are used to derive the value of animals' choices, the activity of neurons in the amygdala and ventral striatum encodes the values derived from these policies, and can be used to decode when the animals make exploratory versus exploitative choices. Moreover, optimal policies better predict animals' choice behavior than alternative strategies (described below). This suggests that the optimal solutions to multi-arm bandit problems are biologically plausible, despite being computationally demanding. &lt;ref&gt; {{cite journal | last1 = Costa | first1 = V.D. | last2 = Averbeck | first2 = B.B. | year = 2019 | title = Subcortical Substrates of Explore-Exploit Decisions in Primates | url = https://www.cell.com/neuron/pdfExtended/S0896-6273(19)30442-8#secsectitle0010 | journal = Neuron | volume = 103 | issue = 3 | pages = 533–535 | doi = 10.1016/j.neuron.2019.05.017 | pmid = 31196672 | pmc = 6687547 }}&lt;/ref&gt;

* '''UCBC (Historical Upper Confidence Bounds with clusters):''' &lt;ref&gt;{{Cite book|last=Bouneffouf|first=D.|title=Optimal Exploitation of Clustering and History Information in Multi-Armed Bandit|journal=Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligen|pages=270–279|publisher=AAAI. Soc|doi=10.1109/sfcs.2000.892116|isbn=978-0769508504|year=2019|s2cid=28713091}}&lt;/ref&gt; The algorithm adapts UCB for a new setting such that it can incorporate both clustering and historical information. The algorithm incorporates the historical observations by utilizing both in the computation of the observed mean rewards and the uncertainty term. The algorithm incorporates the clustering information by playing at two levels: first picking a cluster using a UCB-like strategy at each time step, and subsequently picking an arm within the cluster, again using a UCB-like strategy.

===Approximate solutions===
Many strategies exist which provide an approximate solution to the bandit problem, and can be put into the four broad categories detailed below.

====Semi-uniform strategies====
Semi-uniform strategies were the earliest (and simplest) strategies discovered to approximately solve the bandit problem. All those strategies have in common a [[Greedy algorithm|greedy]] behavior where the ''best'' lever (based on previous observations) is always pulled except when a (uniformly) random action is taken.

* '''Epsilon-greedy strategy''':&lt;ref&gt;Sutton, R. S. &amp; Barto, A. G. 1998 Reinforcement learning: an introduction. Cambridge, MA: MIT Press.&lt;/ref&gt; The best lever is selected for a proportion &lt;math&gt;1 - \epsilon&lt;/math&gt; of the trials, and a lever is selected at random (with uniform probability) for a proportion &lt;math&gt;\epsilon&lt;/math&gt;. A typical parameter value might be &lt;math&gt;\epsilon = 0.1&lt;/math&gt;, but this can vary widely depending on circumstances and predilections.
* '''Epsilon-first strategy'''{{Citation needed|date=March 2015}}: A pure exploration phase is followed by a pure exploitation phase. For &lt;math&gt;N&lt;/math&gt; trials in total, the exploration phase occupies &lt;math&gt;\epsilon N&lt;/math&gt; trials and the exploitation phase &lt;math&gt;(1 - \epsilon) N&lt;/math&gt; trials. During the exploration phase, a lever is randomly selected (with uniform probability); during the exploitation phase, the best lever is always selected.
* '''Epsilon-decreasing strategy'''{{Citation needed|date=March 2015}}: Similar to the epsilon-greedy strategy, except that the value of &lt;math&gt;\epsilon&lt;/math&gt; decreases as the experiment progresses, resulting in highly explorative behaviour at the start and highly exploitative behaviour at the finish.
* '''Adaptive epsilon-greedy strategy based on value differences (VDBE)''': Similar to the epsilon-decreasing strategy, except that  epsilon is reduced on basis of the learning progress instead of manual tuning (Tokic, 2010).&lt;ref name="Tokic2010"/&gt; High fluctuations in the value estimates lead to a high epsilon (high exploration, low exploitation); low fluctuations to a low epsilon (low exploration, high exploitation). Further improvements can be achieved by a [[softmax function|softmax]]-weighted action selection in case of exploratory actions (Tokic &amp; Palm, 2011).&lt;ref name="TokicPalm2011"/&gt;
* '''Adaptive epsilon-greedy strategy based on Bayesian ensembles (Epsilon-BMC)''': An adaptive epsilon adaptation strategy for reinforcement learning similar to VBDE, with monotone convergence guarantees. In this framework, the epsilon parameter is viewed as the expectation of a posterior distribution weighting a greedy agent (that fully trusts the learned reward) and uniform learning agent (that distrusts the learned reward). This posterior is approximated using a suitable Beta distribution under the assumption of normality of observed rewards. In order to address the possible risk of decreasing epsilon too quickly, uncertainty in the variance of the learned reward is also modeled and updated using a normal-gamma model. (Gimelfarb et al., 2019).&lt;ref name="Gimelfarb2019"/&gt;
* '''Contextual-Epsilon-greedy strategy''': Similar to the epsilon-greedy strategy, except that the value of &lt;math&gt;\epsilon&lt;/math&gt; is computed regarding the situation in experiment processes, which lets the algorithm be Context-Aware. It is based on dynamic exploration/exploitation and can adaptively balance the two aspects by deciding which situation is most relevant for exploration or exploitation, resulting in highly explorative behavior when the situation is not critical and highly exploitative behavior at critical situation.&lt;ref name="Bouneffouf2012"/&gt;

====Probability matching strategies====
Probability matching strategies reflect the idea that the number of pulls for a given lever should ''match'' its actual probability of being the optimal lever.  Probability matching strategies are also known as [[Thompson sampling]] or Bayesian Bandits,&lt;ref name="Scott2010"/&gt;&lt;ref name="cl11thompson"/&gt; and are surprisingly easy to implement if you can sample from the posterior for the mean value of each alternative.

Probability matching strategies also admit solutions to so-called contextual bandit problems{{citation needed|date=October 2020}}.

====Pricing strategies====
Pricing strategies establish a ''price'' for each lever. For example, as illustrated with the POKER algorithm,&lt;ref name="Vermorel2005"/&gt; the price can be the sum of the expected reward plus an estimation of extra future rewards that will gain through the additional knowledge. The lever of highest price is always pulled.

====Strategies with ethical constraints====

*'''Behavior Constrained Thompson Sampling (BCTS)''':&lt;ref&gt;{{Cite journal|last=Bouneffouf|first=D.|title=Incorporating Behavioral Constraints in Online AI Systems|journal=The Thirty-Third AAAI Conference on Artificial Intelligence (AAAI-19)|year=2018|pages=270–279|publisher=AAAI.|arxiv=1809.05720}}  https://arxiv.org/abs/1809.05720|year=2019&lt;/ref&gt; In this paper the authors detail a novel online agent that learns a set of behavioral constraints by observation and uses these learned constraints as a guide when making decisions in an online setting while still being reactive to reward feedback. To define this agent, the solution was to adopt a novel extension to the classical contextual multi-armed bandit setting and provide a new algorithm called Behavior Constrained Thompson Sampling (BCTS) that allows for online learning while obeying exogenous constraints. The agent learns a constrained policy that implements the observed behavioral constraints demonstrated by a teacher agent, and then uses this constrained policy to guide the reward-based online exploration and exploitation.  


These strategies minimize the assignment of any patient to an inferior arm ([[Medical ethics|"physician's duty"]]).  In a typical case, they minimize expected successes lost (ESL), that is, the expected number of favorable outcomes that were missed because of assignment to an arm later proved to be inferior.  Another version minimizes resources wasted on any inferior, more expensive, treatment.&lt;ref name="WHP" /&gt;

==Contextual bandit==
A particularly useful version of the multi-armed bandit is the contextual multi-armed bandit problem. In this problem, in each iteration an agent has to choose between arms. Before making the choice, the agent sees a d-dimensional feature vector (context vector),
associated with the current iteration. The learner uses these context vectors along with the rewards of the arms played in the past to make the choice of the arm to play in
the current iteration. Over time, the learner's aim is to collect enough information about how the context vectors and rewards relate to each other, so that it can predict the next best arm to play by looking at the feature vectors.&lt;ref name="Langford2008" /&gt;

===Approximate solutions for contextual bandit===
Many strategies exist that provide an approximate solution to the contextual bandit problem, and can be put into two broad categories detailed below.

====Online linear bandits====
* '''LinUCB ''(Upper Confidence Bound)'' algorithm''': the authors assume a linear dependency between the expected reward of an action and its context and model the representation space using a set of linear predictors.&lt;ref name="lcls10linucb"/&gt;&lt;ref name="clrs11linucb"/&gt;
*'''LinRel (Linear Associative Reinforcement Learning) algorithm''': Similar to LinUCB, but utilizes [[Singular-value decomposition]] rather than [[Ridge regression]] to obtain an estimate of confidence.&lt;ref&gt;{{Cite book|last=Auer|first=P.|chapter=Using upper confidence bounds for online learning|journal=Proceedings 41st Annual Symposium on Foundations of Computer Science|pages=270–279|publisher=IEEE Comput. Soc|doi=10.1109/sfcs.2000.892116|isbn=978-0769508504|year=2000|s2cid=28713091}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|last1=Hong|first1=Tzung-Pei|last2=Song|first2=Wei-Ping|last3=Chiu|first3=Chu-Tien|date=November 2011|title=Evolutionary Composite Attribute Clustering|journal=2011 International Conference on Technologies and Applications of Artificial Intelligence|publisher=IEEE|doi=10.1109/taai.2011.59|isbn=9781457721748|s2cid=14125100}}&lt;/ref&gt;
*'''HLINUCBC (Historic LINUCB with clusters)''': proposed in the paper,&lt;ref&gt;{{Cite book|title=Optimal Exploitation of Clustering and History Information in Multi-Armed Bandit}}&lt;/ref&gt; extends the LinUCB idea with both historical and clustering information.&lt;ref&gt;{{Cite book|last=Bouneffouf|first=D.|title=Optimal Exploitation of Clustering and History Information in Multi-Armed Bandit|journal=Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligen|pages=270–279|publisher=AAAI. Soc|doi=10.1109/sfcs.2000.892116|isbn=978-0769508504|year=2019|s2cid=28713091}}&lt;/ref&gt;

====Online non-linear bandits====
* '''UCBogram algorithm''': The nonlinear reward functions are estimated using a piecewise constant estimator called a ''regressogram'' in [[nonparametric regression]]. Then, UCB is employed on each constant piece. Successive refinements of the partition of the context space are scheduled or chosen adaptively.&lt;ref name="RigZee10"/&gt;&lt;ref name="slivkins11"/&gt;&lt;ref name="PerRig13"/&gt;
* '''Generalized linear algorithms''': The reward distribution follows a generalized linear model, an extension to linear bandits.&lt;ref name="fcgs10glm"/&gt;&lt;ref name="llz17glm"/&gt;&lt;ref name="jbnw17glm"/&gt;&lt;ref name="kzslgb19glm"/&gt;
* '''NeuralBandit algorithm''':  In this algorithm several neural networks are trained to modelize the value of rewards knowing the context, and it uses a multi-experts approach to choose online the parameters of multi-layer perceptrons.&lt;ref name="Robin2014"/&gt;
* '''KernelUCB algorithm''': a kernelized non-linear version of linearUCB, with efficient implementation and finite-time analysis.&lt;ref name="Valko2014"/&gt;
* '''Bandit Forest algorithm''': a [[random forest]] is built and analyzed w.r.t the random forest built knowing the joint distribution of contexts and rewards.&lt;ref&gt;{{Cite journal|last1=Féraud|first1=Raphaël|last2=Allesiardo|first2=Robin|last3=Urvoy|first3=Tanguy|last4=Clérot|first4=Fabrice|date=2016|title=Random Forest for the Contextual Bandit Problem|url=http://jmlr.org/proceedings/papers/v51/feraud16.html|journal=Aistats|pages=93–101}}&lt;/ref&gt;
* '''Oracle-based algorithm''': The algorithm reduces the contextual bandit problem into a series of supervised learning problem, and does not rely on typical realizability assumption on the reward function.&lt;ref name="minimonster"/&gt;

===Constrained contextual bandit===

*''' Context Attentive Bandits or Contextual Bandit with Restricted Context''':&lt;ref&gt;Contextual Bandit with Restricted Context, Djallel Bouneffouf, 2017 &lt;https://www.ijcai.org/Proceedings/2017/0203.pdf&gt;&lt;/ref&gt; The authors consider a novel formulation of the multi-armed  bandit  model,  which  is called  contextual  bandit  with  restricted  context,  where only a limited number of features can be accessed by the learner at every iteration.  This novel formulation is motivated by different online  problems  arising  in  clinical  trials,  recommender systems and attention modeling. Herein, they adapt the standard  multi-armed bandit algorithm known as Thompson Sampling to take advantage of the restricted context setting, and propose two novel algorithms, called the Thompson Sampling with Restricted Context  (TSRC) and  the Windows  Thompson Sampling  with  Restricted  Context (WTSRC),for handling stationary and nonstationary environments, respectively..

In practice, there is usually a cost associated with the resource consumed by each action and the total cost is limited by a budget in many applications such as crowdsourcing and clinical trials. Constrained contextual bandit (CCB) is such a model that considers both the time and budget constraints in a multi-armed bandit setting.
A. Badanidiyuru et al.&lt;ref name="Badanidiyuru2014COLT"/&gt; first studied contextual bandits with budget constraints, also referred to as Resourceful Contextual Bandits, and show that a &lt;math&gt;O(\sqrt{T})&lt;/math&gt; regret is achievable. However, their work focuses on a finite set of policies, and the algorithm is computationally inefficient.

[[File:Framework of UCB-ALP for Constrained Contextual Bandits.jpg|thumbnail|Framework of UCB-ALP for constrained contextual bandits]]
A simple algorithm with logarithmic regret is proposed in:&lt;ref name="Wu2015UCBALP"/&gt;
* '''UCB-ALP algorithm''': The framework of UCB-ALP is shown in the right figure. UCB-ALP is a simple algorithm that combines the UCB method with an Adaptive Linear Programming (ALP) algorithm, and can be easily deployed in practical systems. It is the first work that show how to achieve logarithmic regret in constrained contextual bandits. Although&lt;ref name="Wu2015UCBALP"/&gt; is devoted to a special case with single budget constraint and fixed cost, the results shed light on the design and analysis of algorithms for more general CCB problems.

==Adversarial bandit==
Another variant of the multi-armed bandit problem is called the adversarial bandit, first introduced by Auer and Cesa-Bianchi (1998). In this variant, at each iteration, an agent chooses an arm and an adversary simultaneously chooses the payoff structure for each arm. This is one of the strongest generalizations of the bandit problem&lt;ref&gt;Burtini, Giuseppe, Jason Loeppky, and Ramon Lawrence. "A survey of online experiment design with the stochastic multi-armed bandit." arXiv preprint {{arXiv|1510.00757}} (2015).&lt;/ref&gt; as it removes all assumptions of the distribution and a solution to the adversarial bandit problem is a generalized solution to the more specific bandit problems.

===Example: Iterated prisoner's dilemma===
An example often considered for adversarial bandits is the [[iterated prisoner's dilemma]]. In this example, each adversary has two arms to pull. They can either Deny or Confess. Standard stochastic bandit algorithms don't work very well with these iterations. For example, if the opponent cooperates in the first 100 rounds, defects for the next 200, then cooperate in the following 300, etc. Then algorithms such as UCB won't be able to react very quickly to these changes. This is because after a certain point sub-optimal arms are rarely pulled to limit exploration and focus on exploitation. When the environment changes the algorithm is unable to adapt or may not even detect the change.

===Approximate solutions===
====Exp3&lt;ref&gt;Seldin, Y., Szepesvári, C., Auer, P. and Abbasi-Yadkori, Y., 2012, December. Evaluation and Analysis of the Performance of the EXP3 Algorithm in Stochastic Environments. In EWRL (pp. 103–116).&lt;/ref&gt;====
=====Algorithm=====
  '''Parameters:''' Real &lt;math&gt;\gamma \in (0,1] &lt;/math&gt;
  
  '''Initialisation:''' &lt;math&gt;\omega_i(1) = 1&lt;/math&gt; for &lt;math&gt;i = 1,...,K&lt;/math&gt;
  
  '''For each''' t = 1, 2, ..., T
   1. Set &lt;math&gt;p_i(t) = (1 - \gamma)\frac{\omega_i(t)}{\sum_{j=1}^{K}\omega_j(t)} + \frac{\gamma}{K}&lt;/math&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;math&gt;i = 1,...,K&lt;/math&gt;
   2. Draw &lt;math&gt;i_t&lt;/math&gt; randomly according to the probabilities &lt;math&gt;p_1(t),...,p_K(t)&lt;/math&gt;
   3. Receive reward &lt;math&gt;x_{i_t}(t) \in [0,1]&lt;/math&gt;
   4. For &lt;math&gt;j = 1,...,K&lt;/math&gt; set:
   &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;math&gt;\hat{x}_j(t) = \begin{cases}x_j(t)/p_j(t) &amp; \text{if }j = i_t \\0, &amp; \text{otherwise}\end{cases}&lt;/math&gt;
  
   &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;math&gt;\omega_j(t+1) = \omega_j(t) exp(\gamma\hat{x}_j(t)/K)&lt;/math&gt;

=====Explanation=====
Exp3 chooses an arm at random with probability &lt;math&gt;(1 - \gamma)&lt;/math&gt; it prefers arms with higher weights (exploit), it chooses with probability &amp;gamma; to uniformly randomly explore. After receiving the rewards the weights are updated. The exponential growth significantly increases the weight of good arms.

=====Regret analysis=====
The (external) regret of the Exp3 algorithm is at most
&lt;math&gt;O(\sqrt{KTlog(K)})&lt;/math&gt;

====Follow the perturbed leader (FPL) algorithm====

=====Algorithm=====
  '''Parameters:''' Real &lt;math&gt;\eta&lt;/math&gt;
  
  '''Initialisation:''' &lt;math&gt;\forall i: R_i(1) = 0&lt;/math&gt;
  
  '''For each''' t = 1,2,...,T
   1. For each arm generate a random noise from an exponential distribution &lt;math&gt;\forall i : Z_i(t) \sim Exp(\eta)&lt;/math&gt;
   2. Pull arm &lt;math&gt;I(t)&lt;/math&gt;: &lt;math&gt;I(t)=arg\max_i\{R_i(t) + Z_i(t)\}&lt;/math&gt;
      Add noise to each arm and pull the one with the highest value
   3. Update value: &lt;math&gt;R_{I(t)}(t+1) = R_{I(t)}(t) + x_{I(t)}(t)&lt;/math&gt;
      The rest remains the same

=====Explanation=====
We follow the arm that we think has the best performance so far adding exponential noise to it to provide exploration.&lt;ref&gt;Hutter, M. and Poland, J., 2005. [http://www.jmlr.org/papers/volume6/hutter05a/hutter05a.pdf Adaptive online prediction by following the perturbed leader]. Journal of Machine Learning Research, 6(Apr), pp.639–660.&lt;/ref&gt;

====Exp3 vs FPL====
{| class="wikitable"
|-
! Exp3 !! FPL
|-
| Maintains weights for each arm to calculate pulling probability || Doesn't need to know the pulling probability per arm
|-
| Has efficient theoretical guarantees || The standard FPL does not have good theoretical guarantees
|-
| Might be computationally expensive (calculating the exponential terms) || Computationally quite efficient
|}

==Infinite-armed bandit==
In the original specification and in the above variants, the bandit problem is specified with a discrete and finite number of arms, often indicated by the variable &lt;math&gt;K&lt;/math&gt;. In the infinite armed case, introduced by Agrawal (1995),&lt;ref&gt;Agrawal, Rajeev. The Continuum-Armed Bandit Problem. SIAM J. of Control and Optimization. 1995.&lt;/ref&gt; the "arms" are a continuous variable in &lt;math&gt;K&lt;/math&gt; dimensions.

== Non-stationary bandit ==
Garivier and Moulines derive some of the first results with respect to bandit problems where the underlying model can change during play. A number of algorithms were presented to deal with this case, including Discounted UCB&lt;ref&gt;Discounted UCB, Levente Kocsis, Csaba Szepesvári, 2006&lt;/ref&gt; and Sliding-Window UCB.&lt;ref&gt;On Upper-Confidence Bound Policies for Non-Stationary Bandit Problems, Garivier and Moulines, 2008 &lt;https://arxiv.org/abs/0805.3415&gt;&lt;/ref&gt;

Another work by Burtini et al. introduces a weighted least squares Thompson sampling approach (WLS-TS), which proves beneficial in both the known and unknown non-stationary cases.&lt;ref&gt;Improving Online Marketing Experiments with Drifting Multi-armed Bandits, Giuseppe Burtini, Jason Loeppky, Ramon Lawrence, 2015 &lt;http://www.scitepress.org/DigitalLibrary/PublicationsDetail.aspx?ID=Dx2xXEB0PJE=&amp;t=1&gt;&lt;/ref&gt; In the known non-stationary case, the authors in &lt;ref name="AUCBDB"/&gt; produce an alternative solution, a variant of UCB named Adjusted Upper Confidence Bound (A-UCB) which assumes a stochastic model and provide upper-bounds of the regret.

==Other variants==
Many variants of the problem have been proposed in recent years. 

===Dueling bandit===
The dueling bandit variant was introduced by Yue et al. (2012)&lt;ref name="YueEtAll2012"/&gt; to model the exploration-versus-exploitation tradeoff for relative feedback.
In this variant the gambler is allowed to pull two levers at the same time, but they only get a binary feedback telling which lever provided the best reward. The difficulty of this problem stems from the fact that the gambler has no way of directly observing the reward of their actions.
The earliest algorithms for this problem are InterleaveFiltering,&lt;ref name="YueEtAll2012"/&gt; Beat-The-Mean.&lt;ref name="Yue2011ICML:BTM"/&gt;
The relative feedback of dueling bandits can also lead to [[voting paradoxes]]. A solution is to take the [[Condorcet winner]] as a reference.&lt;ref name = "Urvoy2013ICML:SAVAGE"/&gt;

More recently, researchers have generalized algorithms from traditional MAB to dueling bandits: Relative Upper Confidence Bounds (RUCB),&lt;ref name="Zoghi2014ICML:RUCB"/&gt; Relative EXponential weighing (REX3),&lt;ref name="Gajane2015ICML:REX3"/&gt; 
Copeland Confidence Bounds (CCB),&lt;ref name="Zoghi2015NIPS:CDB"/&gt; Relative Minimum Empirical Divergence (RMED),&lt;ref name="Komiyama2015COLT:DB"/&gt; and Double Thompson Sampling (DTS).&lt;ref name="Wu2016DTS"/&gt;

===Collaborative bandit===
The collaborative filtering bandits (i.e., COFIBA) was introduced by Li and Karatzoglou and Gentile (SIGIR 2016),&lt;ref name="LKG2016COFIBA"/&gt; where the classical collaborative filtering, and content-based filtering methods try to learn a static recommendation model given training data. These approaches are far from ideal in highly dynamic recommendation domains such as news recommendation and computational advertisement, where the set of items and users is very fluid. In this work, they investigate an adaptive clustering technique for content recommendation based on exploration-exploitation strategies in contextual multi-armed bandit settings.&lt;ref name="GLZ2014CLUB"/&gt; Their algorithm (COFIBA, pronounced as "Coffee Bar") takes into account the collaborative effects&lt;ref name="LKG2016COFIBA"/&gt; that arise due to the interaction of the users with the items, by dynamically grouping users based on the items under consideration and, at the same time, grouping items based on the similarity of the clusterings induced over the users. The resulting algorithm thus takes advantage of preference patterns in the data in a way akin to collaborative filtering methods. They provide an empirical analysis on medium-size real-world datasets, showing scalability and increased prediction performance (as measured by click-through rate) over state-of-the-art methods for clustering bandits. They also provide a regret analysis within a standard linear stochastic noise setting.

===Combinatorial bandit===
The Combinatorial Multiarmed Bandit (CMAB) problem&lt;ref name="gai2010learning"/&gt;&lt;ref name="chen2013combinatorial"/&gt;&lt;ref name="ontanon2017combinatorial"/&gt; arises when instead of a single discrete variable to choose from, an agent needs to choose values for a set of variables. Assuming each variable is discrete, the number of possible choices per iteration is exponential in the number of variables. Several CMAB settings have been studied in the literature, from settings where the variables are binary&lt;ref name="chen2013combinatorial"/&gt; to more general setting where each variable can take an arbitrary set of values.&lt;ref name="ontanon2017combinatorial"/&gt;

==See also==
* [[Gittins index]]&amp;nbsp;– a powerful, general strategy for analyzing bandit problems.
* [[Greedy algorithm]]
* [[Optimal stopping]]
* [[Search theory]]
* [[Stochastic scheduling]]

==References==
&lt;references&gt;

&lt;ref name="slivkins11"&gt;
{{citation
 | last   = Slivkins
 | first  =  Aleksandrs
 | series = Conference on Learning Theory, COLT 2011
 | title  = Contextual bandits with similarity information.
 | year   = 2011
 | url=http://www.jmlr.org/papers/volume15/slivkins14a/slivkins14a.pdf
}}
&lt;/ref&gt;

&lt;ref name="RigZee10"&gt;
{{citation
 | last1  = Rigollet
 | first1 = Philippe
 | last2  = Zeevi
 | first2 = Assaf
 | series = Conference on Learning Theory, COLT 2010
 | title  = Nonparametric Bandits with Covariates
 | year   = 2010
| bibcode = 2010arXiv1003.1630R
 | arxiv = 1003.1630
 }}
&lt;/ref&gt;

&lt;ref name="PerRig13"&gt;
{{citation
 | last1   = Perchet
 | first1  =  Vianney
 | last2   = Rigollet
 | first2  = Philippe
 | journal = [[Annals of Statistics]]
 | title  = The multi-armed bandit problem with covariates
 | volume = 41
 | issue  = 2
 | year   = 2013
 | doi=10.1214/13-aos1101
 | pages=693–721
| arxiv=1110.6084
 | s2cid = 14258665
 }}
&lt;/ref&gt;

&lt;ref name="Valko2014"&gt;
{{citation
 | author1 = Michal Valko
 | author2 = Nathan Korda
 | author3 = Rémi Munos
 | author4 = Ilias Flaounas
 | author5 = Nello Cristianini
 | series  = 29th Conference on Uncertainty in Artificial Intelligence (UAI 2013) and (JFPDA 2013).
 | title   = Finite-Time Analysis of Kernelised Contextual Bandits
 | arxiv = 1309.6869| year    = 2013
| bibcode= 2013arXiv1309.6869V
 }}
&lt;/ref&gt;

&lt;ref name="Gittins89"&gt;
{{citation
 | last        = Gittins
 | first       = J. C.
 | author-link = John C. Gittins
 | isbn        = 978-0-471-92059-5
 | location    = Chichester
 | publisher   = John Wiley &amp; Sons, Ltd.
 | series      = Wiley-Interscience Series in Systems and Optimization.
 | title       = Multi-armed bandit allocation indices
 | year        = 1989
}}
&lt;/ref&gt;

&lt;ref name="BF"&gt;
{{citation
 | last1        = Berry
 | first1       = Donald A.
 | author1-link = Don Berry (statistician)
 | last2        = Fristedt
 | first2       = Bert
 | isbn         = 978-0-412-24810-8
 | location     = London
 | publisher    = Chapman &amp; Hall
 | series       = Monographs on Statistics and Applied Probability
 | title        = Bandit problems: Sequential allocation of experiments
 | year         = 1985
}}
&lt;/ref&gt;

&lt;ref name="Whittle79"&gt;
{{citation
 | last        = Whittle
 | first       = Peter
 | author-link = Peter Whittle (mathematician)
 | journal     = [[Journal of the Royal Statistical Society]]
 | series      = Series B
 | title       = Discussion of Dr Gittins' paper
 | volume      = 41
 | issue       = 2
 | pages       = 148–177
 | year        = 1979
 | doi       = 10.1111/j.2517-6161.1979.tb01069.x
}}
&lt;/ref&gt;

&lt;ref name="Whittle81"&gt;
{{citation
 | last        = Whittle
 | first       = Peter
 | author-link = Peter Whittle (mathematician)
 | doi         = 10.1214/aop/1176994469
 | journal     = Annals of Probability
 | pages       = 284–292
 | title       = Arm-acquiring bandits
 | volume      = 9
 | year        = 1981
 | issue       = 2
| doi-access= free
 }}
&lt;/ref&gt;

&lt;ref name="Whittle88"&gt;
{{citation
 | last        = Whittle
 | first       = Peter
 | author-link = Peter Whittle (mathematician)
 | mr          = 974588
 | journal     = Journal of Applied Probability
 | pages       = 287–298
 | title       = Restless bandits: Activity allocation in a changing world
 | volume      = 25A
 | year        = 1988
 | doi=10.2307/3214163
| jstor       = 3214163
 }}
&lt;/ref&gt;

&lt;ref name="WHP"&gt;
{{Citation
 | first      = William H.
 | last       = Press
 | year       = 2009
 | title      = Bandit solutions provide unified ethical models for randomized clinical trials and comparative effectiveness research
 | journal    = Proceedings of the National Academy of Sciences
 | volume     = 106
 | pages      = 22387–22392
 | pmid       = 20018711
 | doi        = 10.1073/pnas.0912378106
 | issue      = 52
 | pmc        = 2793317
 | postscript = .
| bibcode= 2009PNAS..10622387P
 }}
&lt;/ref&gt;

&lt;ref name="Scott2010"&gt;
{{citation
 | last    = Scott
 | first   = S.L.
 | doi     = 10.1002/asmb.874
 | journal = Applied Stochastic Models in Business and Industry
 | pages   = 639–658
 | title   = A modern Bayesian look at the multi-armed bandit
 | volume  = 26
 | year    = 2010
 | issue   = 2
}}
&lt;/ref&gt;

&lt;ref name="Vermorel2005"&gt;
{{citation
 | url       = http://bandit.sourceforge.net/Vermorel2005poker.pdf
 | last1     = Vermorel
 | first1    = Joannes
 | last2     = Mohri
 | first2    = Mehryar
 | publisher = Springer
 | series    = In European Conference on Machine Learning
 | pages     = 437–448
 | title     = Multi-armed bandit algorithms and empirical evaluation
 | year      = 2005
}}
&lt;/ref&gt;

&lt;ref name="Robin2014"&gt;
{{citation
 | last1        = Allesiardo
 | first1       = Robin
 | last2        = Féraud
 | first2       = Raphaël
 | last3        = Djallel
 | first3       = Bouneffouf
 | contribution = A Neural Networks Committee for the Contextual Bandit Problem
 | pages        = 374–381
 | publisher    = Springer
 | series       = [[Lecture Notes in Computer Science]]
 | title        = Neural Information Processing – 21st International Conference, ICONIP 2014, Malaisia, November 03-06,2014, Proceedings
 | volume       = 8834
 | year         = 2014
 | isbn         = 978-3-319-12636-4
 | doi=10.1007/978-3-319-12637-1_47
| arxiv= 1409.8191
 | s2cid = 14155718
 }}
&lt;/ref&gt;

&lt;ref name="Bouneffouf2012"&gt;
{{Cite book | last1 = Bouneffouf | first1 = D. | last2 = Bouzeghoub | first2 = A. | last3 = Gançarski | first3 = A. L. | doi = 10.1007/978-3-642-34487-9_40 | chapter = A Contextual-Bandit Algorithm for Mobile Context-Aware Recommender System | title = Neural Information Processing | series = Lecture Notes in Computer Science | volume = 7665 | pages = 324 | year = 2012 | isbn = 978-3-642-34486-2 }}
&lt;/ref&gt;

&lt;ref name="Tokic2010"&gt;
{{citation
 | last1     = Tokic
 | first1    = Michel
 | chapter   = Adaptive ε-greedy exploration in reinforcement learning based on value differences
 | doi       = 10.1007/978-3-642-16111-7_23
 | pages     = 203–210
 | publisher = Springer-Verlag
 | series    = Lecture Notes in Computer Science
 | title     = KI 2010: Advances in Artificial Intelligence
 | volume    = 6359
 | year      = 2010
 | chapter-url       = http://www.tokic.com/www/tokicm/publikationen/papers/AdaptiveEpsilonGreedyExploration.pdf
 | isbn      = 978-3-642-16110-0| citeseerx    = 10.1.1.458.464
 }}.
&lt;/ref&gt;

&lt;ref name="TokicPalm2011"&gt;
{{citation
 | last1     = Tokic
 | first1    = Michel
 | last2     = Palm
 | first2    = Günther
 | chapter   = Value-Difference Based Exploration: Adaptive Control Between Epsilon-Greedy and Softmax
 | pages     = 335–346
 | publisher = Springer-Verlag
 | series    = Lecture Notes in Computer Science
 | title     = KI 2011: Advances in Artificial Intelligence
 | volume    = 7006
 | year      = 2011
 | chapter-url       = http://www.tokic.com/www/tokicm/publikationen/papers/KI2011.pdf
 | isbn      = 978-3-642-24455-1}}.
&lt;/ref&gt;


&lt;ref name="Gimelfarb2019"&gt;
{{citation
 | last1     = Gimelfarb
 | first1    = Michel
 | last2     = Sanner
 | first2    = Scott
 | last3     = Lee
 | first3    = Chi-Guhn
 | chapter   = ε-BMC: A Bayesian Ensemble Approach to Epsilon-Greedy Exploration in Model-Free Reinforcement Learning
 | pages     = 162
 | publisher = AUAI Press
 | title     = Proceedings of the Thirty-Fifth Conference on Uncertainty in Artificial Intelligence
 | year      = 2019
 | chapter-url       = http://auai.org/uai2019/proceedings/papers/162.pdf}}.
&lt;/ref&gt;

&lt;ref name="BrochuHoffmandeFreitas"&gt;
{{citation
 | last1  = Brochu
 | first1 = Eric
 | last2  = Hoffman
 | first2 = Matthew W.
 | last3  = de Freitas
 | first3 = Nando
 | arxiv    = 1009.5419| date   = September 2010
 | title  = Portfolio Allocation for Bayesian Optimization| bibcode= 2010arXiv1009.5419B
 }}
&lt;/ref&gt;

&lt;ref name="ShenWangJiangZha"&gt;
{{citation
 | last1  = Shen
 | first1 = Weiwei
 | last2  = Wang
 | first2 = Jun
 | last3  = Jiang
 | first3 = Yu-Gang
 | last4  = Zha 
 | first4 = Hongyuan
 | journal = Proceedings of International Joint Conferences on Artificial Intelligence (IJCAI2015)
 | url    = http://www.aaai.org/ocs/index.php/IJCAI/IJCAI15/paper/viewPDFInterstitial/10972/10798
 | date   = 2015
 | title  = Portfolio Choices with Orthogonal Bandit Learning}}
&lt;/ref&gt;
&lt;ref name="Langford2008"&gt;
{{citation
 | chapter-url       = http://papers.nips.cc/paper/3178-the-epoch-greedy-algorithm-for-multi-armed-bandits-with-side-information
 | last1     = Langford
 | first1    = John
 | last2     = Zhang
 | first2    = Tong
 | publisher = Curran Associates, Inc.
 | pages     = 817–824
 | title     = Advances in Neural Information Processing Systems 20
 | chapter   = The Epoch-Greedy Algorithm for Contextual Multi-armed Bandits
 | year      = 2008
}}
&lt;/ref&gt;

&lt;ref name="Badanidiyuru2014COLT"&gt;
{{citation
 | last1     = Badanidiyuru
 | first1    = A.
 | last2     = Langford
 | first2    = J.
 | last3     = Slivkins
 | first3    = A.
 | title     = Proceeding of Conference on Learning Theory (COLT)
 | chapter   = Resourceful contextual bandits
 | year      = 2014
 | chapter-url=http://www.jmlr.org/proceedings/papers/v35/badanidiyuru14.pdf
}}
&lt;/ref&gt;

&lt;ref name="Wu2015UCBALP"&gt;
{{citation
 | url       = https://papers.nips.cc/paper/6008-algorithms-with-logarithmic-or-sublinear-regret-for-constrained-contextual-bandits
 | last1     = Wu
 | first1    = Huasen
 | last2     = Srikant
 | first2    = R.
 | last3     = Liu
 | first3    = Xin
 | last4     = Jiang
 | first4    = Chong
 | title     = Algorithms with Logarithmic or Sublinear Regret for Constrained Contextual Bandits
 | journal   = The 29th Annual Conference on Neural Information Processing Systems (NIPS) 
 | pages     = 433–441
 | year      = 2015
| publisher = Curran Associates
 | bibcode = 2015arXiv150406937W
 | arxiv = 1504.06937
 }}
&lt;/ref&gt;

&lt;ref name="YueEtAll2012"&gt;
{{citation
 | last1   = Yue
 | first1  = Yisong
 | title = The K-armed dueling bandits problem
 | journal = Journal of Computer and System Sciences
 | last2   = Broder
 | first2  = Josef
 | last3   = Kleinberg
 | first3  = Robert
 | last4   = Joachims
 | first4  = Thorsten
 | volume  = 78
 | issue   = 5
 | pages   = 1538–1556
 | year    = 2012
 | doi=10.1016/j.jcss.2011.12.028
| citeseerx   = 10.1.1.162.2764
 }}
&lt;/ref&gt;

&lt;ref name="Yue2011ICML:BTM"&gt;
{{citation
 | last1   = Yue
 | first1  = Yisong
 | last2   = Joachims
 | first2  = Thorsten
 | title   = Proceedings of ICML'11
 | chapter = Beat the Mean Bandit
 | year    = 2011
}}
&lt;/ref&gt;

&lt;ref name="Urvoy2013ICML:SAVAGE"&gt;
{{citation
 | chapter-url     = http://www.jmlr.org/proceedings/papers/v28/urvoy13.pdf
 | last1   = Urvoy
 | first1  = Tanguy
 | last2   =  Clérot
 | first2  = Fabrice
 | last3   = Féraud
 | first3  = Raphaël
 | last4   = Naamane  
 | first4  = Sami
 | title   = Proceedings of the 30th International Conference on Machine Learning (ICML-13)
 | chapter = Generic Exploration and K-armed Voting Bandits
 | year    = 2013
}}
&lt;/ref&gt;

&lt;ref name="Zoghi2014ICML:RUCB"&gt;
{{citation
 | chapter-url     = http://www.jmlr.org/proceedings/papers/v32/zoghi14.pdf
 | last1   = Zoghi
 | first1  = Masrour 
 | last2   =  Whiteson
 | first2  = Shimon
 | last3   = Munos
 | first3  = Remi
 | last4   = Rijke  
 | first4  = Maarten D
 | title   = Proceedings of the 31st International Conference on Machine Learning (ICML-14)
 | chapter = Relative Upper Confidence Bound for the $K$-Armed Dueling Bandit Problem
 | year    = 2014
}}
&lt;/ref&gt;

&lt;ref name="Gajane2015ICML:REX3"&gt;
{{citation
 | chapter-url     = http://jmlr.org/proceedings/papers/v37/gajane15.pdf
 | last1   = Gajane
 | first1  = Pratik
 | last2  = Urvoy
 | first2  = Tanguy
 | last3   =  Clérot
 | first3  = Fabrice
 | title   = Proceedings of the 32nd International Conference on Machine Learning (ICML-15)
 | chapter = A Relative Exponential Weighing Algorithm for Adversarial Utility-based Dueling Bandits
 | year    = 2015
}}
&lt;/ref&gt;

&lt;ref name="Zoghi2015NIPS:CDB"&gt;
{{citation
 | arxiv     = 1506.00312| last1   = Zoghi
 | first1  = Masrour 
 | last2   =  Karnin
 | first2  =  Zohar S
 | last3   = Whiteson
 | first3  =  Shimon
 | last4   =  Rijke 
 | first4  = Maarten D
 | title   = Advances in Neural Information Processing Systems, NIPS'15
 | chapter = Copeland Dueling Bandits
 | year    = 2015
| bibcode=2015arXiv150600312Z}}
&lt;/ref&gt;

&lt;ref name="Komiyama2015COLT:DB"&gt;
{{citation
 | chapter-url     = http://jmlr.org/proceedings/papers/v40/Komiyama15.pdf
 | last1   = Komiyama
 | first1  = Junpei 
 | last2   =  Honda
 | first2  =  Junya
 | last3   =  Kashima
 | first3  = Hisashi
 | last4   =  Nakagawa
 | first4  =  Hiroshi
 | title   = Proceedings of the 28th Conference on Learning Theory
 | chapter = Regret Lower Bound and Optimal Algorithm in Dueling Bandit Problem
 | year    = 2015
}}
&lt;/ref&gt;

&lt;ref name="Wu2016DTS"&gt;
{{citation
 | arxiv       = 1604.07101| last1     = Wu
 | first1    = Huasen
 | last2     = Liu
 | first2    = Xin
 | title     = Double Thompson Sampling for Dueling Bandits
 | journal   = The 30th Annual Conference on Neural Information Processing Systems (NIPS) 
 | year      = 2016
| bibcode= 2016arXiv160407101W}}
&lt;/ref&gt;

&lt;ref name="AUCBDB"&gt;
{{citation
 | last1   = Bouneffouf
 | first1  = Djallel
 | last2   = Feraud
 | first2  = Raphael 
 | title   = Neurocomputing
 | chapter = Multi-armed bandit problem with known trend
 | year    = 2016
}}
&lt;/ref&gt;

&lt;ref name="GLZ2014CLUB"&gt;
{{citation
 | arxiv     = 1401.8257| last1   = Gentile
 | first1  = Claudio
 | last2   =  Li
 | first2  =  Shuai 
 | last3   =  Zappella 
 | first3  = Giovanni 
 | title   = The 31st International Conference on Machine Learning, Journal of Machine Learning Research (ICML 2014)
 | chapter = Online Clustering of Bandits
 | year    = 2014
| bibcode=2014arXiv1401.8257G}}
&lt;/ref&gt;


&lt;ref name="LKG2016COFIBA"&gt;
{{citation
 | arxiv     = 1502.03473| last1   = Li
 | first1  = Shuai
 | last2   =  Alexandros
 | first2  =  Karatzoglou 
 | last3   =  Gentile
 | first3  = Claudio
 | title   = The 39th International ACM SIGIR Conference on Information Retrieval (SIGIR 2016)
 | chapter = Collaborative Filtering Bandits
 | year    = 2016
| bibcode=2015arXiv150203473L}}
&lt;/ref&gt;

&lt;ref name="farias2011irrevocable"&gt;
{{citation
 | title=The irrevocable multiarmed bandit problem
 | last1 = Farias | first1 = Vivek F | first2 = Madan | last2 = Ritesh
 | journal=[[Operations Research (journal)|Operations Research]]
 | volume=59
 | number=2
 | pages=383–399
 | year= 2011
 | doi=10.1287/opre.1100.0891
|citeseerx = 10.1.1.380.6983}}
&lt;/ref&gt;

&lt;ref name="gai2010learning"&gt;
{{citation
|author=Gai, Y. and Krishnamachari, B. and Jain, R.
|title=Learning multiuser channel allocations in cognitive radio networks: A combinatorial multi-armed bandit formulation
|book-title=2010 IEEE Symposium on New Frontiers in Dynamic Spectrum
|pages=1–9
|year=2010
|url=http://www.academia.edu/download/30758682/DySPAN2010.pdf
}}
&lt;/ref&gt;

&lt;ref name="chen2013combinatorial"&gt;
{{citation
|author=Chen, Wei and Wang, Yajun and Yuan, Yang
|title=Combinatorial multi-armed bandit: General framework and applications
|book-title=Proceedings of the 30th International Conference on Machine Learning (ICML 2013)
|pages=151–159
|year=2013
|url=http://www.jmlr.org/proceedings/papers/v28/chen13a.pdf
}}
&lt;/ref&gt;

&lt;ref name="ontanon2017combinatorial"&gt;
{{citation
|author=Santiago Ontañón
|title= Combinatorial Multi-armed Bandits for Real-Time Strategy Games
|journal= Journal of Artificial Intelligence Research
|volume=58
|year=2017
|pages=665–702
|url=https://www.jair.org/index.php/jair/article/download/11053/26230
|doi= 10.1613/jair.5398
|arxiv=1710.04805
|bibcode= 2017arXiv171004805O
|s2cid= 8517525
}}
&lt;/ref&gt;

&lt;ref name="lcls10linucb"&gt;
{{citation
|author= Lihong Li, Wei Chu, John Langford, Robert E. Schapire
|title= A contextual-bandit approach to personalized news article recommendation
|journal= Proceedings of the 19th International Conference on World Wide Web (WWW 2010)
|pages= 661–670
|year= 2010
|doi= 10.1145/1772690.1772758
|arxiv= 1003.0146
|bibcode= 2010arXiv1003.0146L
|isbn= 9781605587998
|s2cid= 207178795
}}

&lt;/ref&gt;
&lt;ref name="cl11thompson"&gt;
{{citation
|author= Olivier Chapelle, Lihong Li
|title= An empirical evaluation of Thompson sampling
|journal= Advances in Neural Information Processing Systems 24 (NIPS)
|pages= 2249–2257
|year= 2011
|publisher= Curran Associates
|url=http://papers.nips.cc/paper/4321-an-empirical-evaluation-of-thompson-sampling
}}
&lt;/ref&gt;

&lt;ref name="fcgs10glm"&gt;
{{citation
|author= Sarah Filippi, Olivier Cappé, Aurélien Garivier, Csaba Szepesvári
|title= Parametric Bandits: The Generalized Linear Case
|journal= Advances in Neural Information Processing Systems 23 (NIPS)
|pages= 586–594
|year= 2010
|publisher= Curran Associates
|url=http://papers.nips.cc/paper/4166-parametric-bandits-the-generalized-linear-case
}}
&lt;/ref&gt;

&lt;ref name="llz17glm"&gt;
{{citation
|author= Lihong Li, Yu Lu, Dengyong Zhou
|title= Provably optimal algorithms for generalized linear contextual bandits
|journal= Proceedings of the 34th International Conference on Machine Learning (ICML)
|pages= 2071–2080
|year= 2017
|arxiv= 1703.00048
|bibcode= 2017arXiv170300048L
|url=http://proceedings.mlr.press/v70/li17c.html
}}
&lt;/ref&gt;

&lt;ref name="kzslgb19glm"&gt;
{{citation
|author=Branislav Kveton, Manzil Zaheer, Csaba Szepesvári, Lihong Li, Mohammad Ghavamzadeh, Craig Boutilier
|title= Randomized exploration in generalized linear bandits
|journal=Proceedings of the 23rd International Conference on Artificial Intelligence and Statistics (AISTATS)
|year= 2020
|arxiv= 1906.08947
|bibcode= 2019arXiv190608947K
}}
&lt;/ref&gt;

&lt;ref name="jbnw17glm"&gt;
{{citation
|author= Kwang-Sung Jun, Aniruddha Bhargava, Robert D. Nowak, Rebecca Willett
|title= Scalable generalized linear bandits: Online computation and hashing
|journal= Advances in Neural Information Processing Systems 30 (NIPS)
|pages= 99–109
|year= 2017
|publisher= Curran Associates
|arxiv= 1706.00136
|bibcode= 2017arXiv170600136J
|url=http://papers.nips.cc/paper/6615-scalable-generalized-linear-bandits-online-computation-and-hashing
}}
&lt;/ref&gt;

&lt;ref name="minimonster"&gt;
{{citation
|author= Alekh Agarwal, Daniel J. Hsu, Satyen Kale, John Langford, Lihong Li, Robert E. Schapire
|title= Taming the monster: A fast and simple algorithm for contextual bandits
|journal= Proceedings of the 31st International Conference on Machine Learning (ICML)
|pages= 1638–1646
|year= 2014
|arxiv= 1402.0555
|bibcode= 2014arXiv1402.0555A
|url=http://proceedings.mlr.press/v32/agarwalb14.html
}}
&lt;/ref&gt;

&lt;ref name="clrs11linucb"&gt;
{{citation
|author= Wei Chu, Lihong Li, Lev Reyzin, Robert E. Schapire
|title= Contextual bandits with linear payoff functions
|journal= Proceedings of the 14th International Conference on Artificial Intelligence and Statistics (AISTATS)
|pages= 208–214
|year= 2011
|url=http://proceedings.mlr.press/v15/chu11a/chu11a.pdf
}}
&lt;/ref&gt;

&lt;/references&gt;

==Further reading==
{{Scholia|topic}}
*{{Cite journal | last1 = Guha | first1 = S. | last2 = Munagala | first2 = K. | last3 = Shi | first3 = P. | title = Approximation algorithms for restless bandit problems | doi = 10.1145/1870103.1870106 | journal = Journal of the ACM | volume = 58 | pages = 1–50 | year = 2010 | arxiv = 0711.3861 | s2cid = 1654066 }}
*{{citation
 | last1 = Dayanik | first1 = S.
 | last2 = Powell | first2 = W.
 | last3 = Yamazaki | first3 = K.
 | doi = 10.1239/aap/1214950209
 | issue = 2
 | journal = Advances in Applied Probability
 | pages = 377–400
 | title = Index policies for discounted bandit problems with availability constraints
 | volume = 40
 | year = 2008| doi-access = free
 }}.
*{{citation
 | last = Powell | first = Warren B.
 | contribution = Chapter 10
 | isbn = 978-0-470-17155-4
 | location = New York
 | publisher = John Wiley and Sons
 | title = Approximate Dynamic Programming: Solving the Curses of Dimensionality
 | year = 2007}}.
*{{citation
 | last = Robbins | first = H. | author-link = Herbert Robbins
 | doi = 10.1090/S0002-9904-1952-09620-8
 | journal = [[Bulletin of the American Mathematical Society]]
 | pages = 527–535
 | title = Some aspects of the sequential design of experiments
 | volume = 58  | year = 1952  | issue = 5| doi-access = free}}.
*{{citation
 |last1       = Sutton
 |first1      = Richard
 |last2       = Barto
 |first2      = Andrew
 |isbn        = 978-0-262-19398-6
 |publisher   = MIT Press
 |title       = Reinforcement Learning
 |url         = http://webdocs.cs.ualberta.ca/~sutton/book/the-book.html
 |year        = 1998
 |url-status     = dead
 |archive-url  = https://web.archive.org/web/20131211192714/http://webdocs.cs.ualberta.ca/~sutton/book/the-book.html
|archive-date = 2013-12-11
 }}.

*{{citation
 | last = Allesiardo  | first = Robin
 | contribution = A Neural Networks Committee for the Contextual Bandit Problem
 | pages = 374–381
 | publisher = Springer
 | series = Lecture Notes in Computer Science
 | title = Neural Information Processing – 21st International Conference, ICONIP 2014, Malaisia, November 03-06,2014, Proceedings
 | volume = 8834
 | year = 2014
 | isbn = 978-3-319-12636-4
 | doi=10.1007/978-3-319-12637-1_47| arxiv = 1409.8191
 | s2cid = 14155718
 }}.

* {{citation
 | last = Weber | first = Richard
 | issue = 4
 | journal = [[Annals of Applied Probability]]
 | pages = 1024–1033
 | title = On the Gittins index for multiarmed bandits
 | volume = 2
 | year = 1992
 | jstor=2959678
 | doi = 10.1214/aoap/1177005588| doi-access = free
 }}.&lt;!-- "The proof from God" according to Whittle's survey of applied probability --&gt;
* {{Citation
|author=[[Michael N. Katehakis|Katehakis, M.]] and C. Derman
|title= Adaptive statistical procedures and related topics
|journal=
|volume=8
|year=1986
|pages=29–39
|jstor= 4355518
|postscript=.
|doi=10.1214/lnms/1215540286
|series=Institute of Mathematical Statistics Lecture Notes - Monograph Series
|isbn=978-0-940600-09-6
|chapter= Computing optimal sequential allocation rules in clinical trials
|doi-access=free
}}
* {{Citation
|author=[[Michael N. Katehakis|Katehakis, M.]] and A. F. Veinott, Jr.
|title=The multi-armed bandit problem: decomposition and computation
|journal=Mathematics of Operations Research
|volume=12
|year=1987
|pages=262–268
|jstor= 3689689
|issue=2
|doi=10.1287/moor.12.2.262
|s2cid=656323
|postscript=.
|url=https://semanticscholar.org/paper/e4fe28113fed71999a0db30a930e0b42d3ce55f1
}}

==External links==
*[https://github.com/fmr-llc/mabwiser MABWiser], [[Open-Source|open source]] Python implementation of bandit strategies that supports context-free, parametric and non-parametric contextual policies with built-in parallelization and simulation capability. 
*[http://mloss.org/software/view/415/ PyMaBandits], [[Open-Source|open source]] implementation of bandit strategies in Python and Matlab.
*[https://github.com/Nth-iteration-labs/contextual Contextual], [[open source]] [[R (programming language)|R]] package facilitating the simulation and evaluation of both context-free and contextual Multi-Armed Bandit policies.
*[http://bandit.sourceforge.net bandit.sourceforge.net Bandit project], open source implementation of bandit strategies.
*[https://github.com/jkomiyama/banditlib Banditlib], [[Open-Source]] implementation of bandit strategies in C++.
*[https://archive.is/20121212095047/http://www.cs.washington.edu/research/jair/volume4/kaelbling96a-html/node6.html Leslie Pack Kaelbling and Michael L. Littman (1996). Exploitation versus Exploration: The Single-State Case].
* Tutorial: Introduction to Bandits: Algorithms and Theory. [http://techtalks.tv/talks/54451/ Part1]. [http://techtalks.tv/talks/54455/ Part2].
* [https://www.feynmanlectures.caltech.edu/info/exercises/Feynmans_restaurant_problem.html Feynman's restaurant problem], a classic example (with known answer) of the exploitation vs. exploration tradeoff.
* [http://www.chrisstucchio.com/blog/2012/bandit_algorithms_vs_ab.html Bandit algorithms vs. A-B testing].
* [http://homes.di.unimi.it/~cesabian/Pubblicazioni/banditSurvey.pdf S. Bubeck and N. Cesa-Bianchi A Survey on Bandits].
* [https://arxiv.org/abs/1508.03326 A Survey on Contextual Multi-armed Bandits], a survey/tutorial for Contextual Bandits.
* [https://mpatacchiola.github.io/blog/2017/08/14/dissecting-reinforcement-learning-6.html Blog post on multi-armed bandit strategies, with Python code].
*[https://pavlov.tech/2019/03/02/animated-multi-armed-bandit-policies/ Animated, interactive plots] illustrating Epsilon-greedy, [[Thompson sampling]], and Upper Confidence Bound exploration/exploitation balancing strategies.

{{DEFAULTSORT:Multi-Armed Bandit}}
[[Category:Sequential methods]]
[[Category:Sequential experiments]]
[[Category:Stochastic optimization]]
[[Category:Machine learning]]</text>
      <sha1>bt9vuchmljn410ml8om3elwc87cbs2m</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Inductive logic programming</title>
    <ns>14</ns>
    <id>29003796</id>
    <revision>
      <id>876210560</id>
      <parentid>846957764</parentid>
      <timestamp>2018-12-31T21:41:54Z</timestamp>
      <contributor>
        <username>BrownHairedGirl</username>
        <id>754619</id>
      </contributor>
      <minor/>
      <comment>{{[[Template:Main|Main]]}} → {{[[Template:Cat main|Cat main]]}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="74" xml:space="preserve">{{Cat main}}

[[Category:Logic programming]]
[[Category:Machine learning]]</text>
      <sha1>1ba9czlhcuukbq9f92wzhfhgc1sw578</sha1>
    </revision>
  </page>
  <page>
    <title>Dimensionality reduction</title>
    <ns>0</ns>
    <id>579867</id>
    <revision>
      <id>1002754996</id>
      <parentid>996224134</parentid>
      <timestamp>2021-01-25T22:28:44Z</timestamp>
      <contributor>
        <username>Comp.arch</username>
        <id>18779361</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="21398" xml:space="preserve">{{Short description|Process of reducing the number of random variables under consideration}}
{{For|dimensional reduction in physics|dimensional reduction}}
{{Machine learning bar}}

'''Dimensionality reduction''', or '''dimension reduction''', is the transformation of data from a high-dimensional space into a low-dimensional space so that the low-dimensional representation retains some meaningful properties of the original data, ideally close to its [[intrinsic dimension]]. Working in high-dimensional spaces can be undesirable for many reasons; raw data are often [[sparse matrix|sparse]] as a consequence of the [[curse of dimensionality]], and analyzing the data is usually [[Computational_complexity_theory#Intractability|computationally intractable]]. Dimensionality reduction is common in fields that deal with large numbers of observations and/or large numbers of variables, such as [[signal processing]], [[speech recognition]], [[neuroinformatics]], and [[bioinformatics]].&lt;ref name = "dr_review"&gt;{{Cite journal|last=van der Maaten|first=Laurens|last2=Postma|first2=Eric|last3=van den Herik|first3=Jaap|date=October 26, 2009|title=Dimensionality Reduction: A Comparative Review|url=https://members.loria.fr/moberger/Enseignement/AVR/Exposes/TR_Dimensiereductie.pdf|journal=J Mach Learn Res|volume=10|pages=66-71}}&lt;/ref&gt;

Methods are commonly divided into linear and non-linear approaches.&lt;ref name = "dr_review"./&gt; Approaches can also be divided into [[feature selection]] and [[feature extraction]].&lt;ref&gt;{{Cite book | last1 = Pudil | first1 = P.| last2 = Novovičová | first2 = J.| editor1-first = Huan | editor1-last = Liu| editor2-first = Hiroshi | editor2-last = Motoda| doi = 10.1007/978-1-4615-5725-8_7 | chapter = Novel Methods for Feature Subset Selection with Respect to Problem Knowledge | title = Feature Extraction, Construction and Selection | pages = 101 | year = 1998 | isbn = 978-1-4613-7622-4 }}&lt;/ref&gt; Dimensionality reduction can be used for [[noise reduction]], [[data visualization]], [[cluster analysis]], or as an intermediate step to facilitate other analyses. 

==Feature selection==
{{main article|Feature selection}}{{See also|Combinatorial optimization}}
[[Feature selection]] approaches try to find a subset of the input variables (also called features or attributes). The three strategies are: the ''filter'' strategy (e.g. [[Information gain in decision trees|information gain]]), the ''wrapper'' strategy (e.g. search guided by accuracy), and the ''embedded'' strategy (selected features add or are removed while building the model based on prediction errors).

[[Data analysis]] such as [[Regression analysis|regression]] or [[Statistical classification|classification]] can be done in the reduced space more accurately than in the original space.&lt;ref&gt;{{cite journal
 |first=Antonio |last=Rico-Sulayes
 |url=http://rielac.cujae.edu.cu/index.php/rieac/article/download/478/278
 |title=Reducing Vector Space Dimensionality in Automatic Classification for Authorship Attribution
 |journal=Revista Ingeniería Electrónica, Automática y Comunicaciones
 |volume=38 |number=3 |pages=26–35 |year=2017
}}&lt;/ref&gt;

==Feature projection==
{{main article|Feature extraction}}

Feature projection (also called Feature extraction) transforms the data from the [[high-dimensional space]] to a space of fewer dimensions. The data transformation may be linear, as in [[principal component analysis]] (PCA), but many [[nonlinear dimensionality reduction]] techniques also exist.&lt;ref&gt;Samet, H. (2006) ''Foundations of Multidimensional and Metric Data Structures''. Morgan Kaufmann. {{ISBN|0-12-369446-9}}&lt;/ref&gt;&lt;ref&gt;C. Ding, X. He, H. Zha, H.D. Simon, [https://cloudfront.escholarship.org/dist/prd/content/qt8pv153t1/qt8pv153t1.pdf Adaptive Dimension Reduction for Clustering High Dimensional Data], Proceedings of International Conference on Data Mining, 2002&lt;/ref&gt; For multidimensional data, [[tensor]] representation can be used in dimensionality reduction through [[multilinear subspace learning]].&lt;ref name="MSLsurvey"&gt;{{cite journal
 |first=Haiping |last=Lu
 |first2=K.N. |last2=Plataniotis
 |first3=A.N. |last3=Venetsanopoulos
 |url=http://www.dsp.utoronto.ca/~haiping/Publication/SurveyMSL_PR2011.pdf
 |title=A Survey of Multilinear Subspace Learning for Tensor Data
 |journal=Pattern Recognition
 |volume=44 |number=7 |pages=1540–1551 |year=2011
 |doi=10.1016/j.patcog.2011.01.004
}}&lt;/ref&gt;

===Principal component analysis (PCA)===
{{main article|Principal component analysis}}

The main linear technique for dimensionality reduction, principal component analysis, performs a linear mapping of the data to a lower-dimensional space in such a way that the variance of the data in the low-dimensional representation is maximized. In practice, the [[covariance]] (and sometimes the [[Correlation and dependence|correlation]]) [[matrix (mathematics)|matrix]] of the data is constructed and the [[Eigenvalue, eigenvector and eigenspace|eigenvectors]] on this matrix are computed. The eigenvectors that correspond to the largest eigenvalues (the principal components) can now be used to reconstruct a large fraction of the variance of the original data. Moreover, the first few eigenvectors can often be interpreted in terms of the large-scale physical behavior of the system, because they often contribute the vast majority of the system's energy, especially in low-dimensional systems. Still, this must be proven on a case-by-case basis as not all systems exhibit this behavior.   The original space (with dimension of the number of points) has been reduced (with data loss, but hopefully retaining the most important variance) to the space spanned by a few eigenvectors.{{Citation needed|date=September 2017}}

===Non-negative matrix factorization (NMF)===
{{main article|Non-negative matrix factorization}}

NMF decomposes a non-negative matrix to the product of two non-negative ones, which has been a promising tool in fields where only non-negative signals exist,&lt;ref name="lee-seung"&gt;{{Cite journal
 | author = Daniel D. Lee
 | author2 = H. Sebastian Seung
 | author2-link = Sebastian Seung
 | name-list-style = amp
 | year = 1999
 | title = Learning the parts of objects by non-negative matrix factorization
 | journal = [[Nature (journal)|Nature]]
 | volume = 401
 | issue = 6755
 | pages = 788&amp;ndash;791
 | doi = 10.1038/44565
 | pmid = 10548103
| bibcode = 1999Natur.401..788L
 }}&lt;/ref&gt;&lt;ref name="lee2001algorithms"&gt;{{Cite conference
 |author1=Daniel D. Lee  |author2=H. Sebastian Seung
  |name-list-style=amp | year = 2001
 | url = http://papers.nips.cc/paper/1861-algorithms-for-non-negative-matrix-factorization.pdf
 | title = Algorithms for Non-negative Matrix Factorization
 | conference = Advances in Neural Information Processing Systems 13: Proceedings of the 2000 Conference
 | pages = 556&amp;ndash;562
 | publisher = [[MIT Press]]
}}&lt;/ref&gt; such as astronomy.&lt;ref name="blantonRoweis07"&gt;{{Cite journal|arxiv=astro-ph/0606170|last1= Blanton|first1= Michael R.|title= K-corrections and filter transformations in the ultraviolet, optical, and near infrared |journal= The Astronomical Journal|volume= 133|issue= 2|pages= 734–754|last2=  Roweis|first2= Sam |year= 2007|doi= 10.1086/510127|bibcode = 2007AJ....133..734B }}&lt;/ref&gt;&lt;ref name = "ren18"&gt;{{Cite journal|arxiv=1712.10317|last1= Ren|first1= Bin |title= Non-negative Matrix Factorization: Robust Extraction of Extended Structures|journal= The Astrophysical Journal|volume= 852|issue= 2|pages= 104|last2=  Pueyo|first2= Laurent|last3= Zhu | first3 = Guangtun B.|last4=  Duchêne|first4= Gaspard |year= 2018|doi= 10.3847/1538-4357/aaa1f2|bibcode = 2018ApJ...852..104R }}&lt;/ref&gt; NMF is well known since the multiplicative update rule by Lee &amp; Seung,&lt;ref name="lee-seung"/&gt; which has been continuously developed: the inclusion of uncertainties,&lt;ref name="blantonRoweis07"/&gt; the consideration of missing data and parallel computation,&lt;ref name="zhu16"&gt; {{Cite arXiv|last=Zhu|first=Guangtun B.|date=2016-12-19|title=Nonnegative Matrix Factorization (NMF) with Heteroscedastic Uncertainties and Missing data |eprint=1612.06037|class=astro-ph.IM}}&lt;/ref&gt; sequential construction&lt;ref name="zhu16"/&gt; which leads to the stability and linearity of NMF,&lt;ref name="ren18"/&gt; as well as other [[Non-negative matrix factorization|updates]] including handling missing data in [[digital image processing]].&lt;ref name = "ren20”&gt;{{Cite journal|arxiv=2001.00563|last1= Ren|first1= Bin |title= Using Data Imputation for Signal Separation in High Contrast Imaging|journal= The Astrophysical Journal|volume= 892|issue= 2|pages= 74|last2=  Pueyo|first2= Laurent|last3= Chen | first3 = Christine|last4=  Choquet|first4= Elodie |last5=  Debes|first5= John H.|last6=  Duechene |first6= Gaspard|last7= Menard|first7=Francois|last8=Perrin|first8=Marshall D.|year= 2020|doi= 10.3847/1538-4357/ab7024 
|bibcode = 2020ApJ...892...74R }}&lt;/ref&gt;

With a stable component basis during construction, and a linear modeling process, [[Non-negative_matrix_factorization#Sequential_NMF|sequential NMF]]&lt;ref name="zhu16"/&gt; is able to preserve the flux in direct imaging of circumstellar structures in astromony,&lt;ref name="ren18"/&gt; as one of the [[methods of detecting exoplanets]], especially for the direct imaging of [[circumstellar disks]]. In comparison with PCA, NMF does not remove the mean of the matrices which leads to unphysical non-negative fluxes, therefore NMF is able to preserve more information than PCA as demonstrated by Ren et al.&lt;ref name="ren18"/&gt;

===Kernel PCA===
{{main article|Kernel PCA}}
Principal component analysis can be employed in a nonlinear way by means of the [[kernel trick]]. The resulting technique is capable of constructing nonlinear mappings that maximize the variance in the data. The resulting technique is entitled [[kernel PCA]].

===Graph-based kernel PCA===
Other prominent nonlinear techniques include [[manifold learning]] techniques such as [[Isomap]], [[locally linear embedding]] (LLE),&lt;ref&gt;{{Cite journal | last1 = Roweis | first1 = S. T. | last2 = Saul | first2 = L. K. | title = Nonlinear Dimensionality Reduction by Locally Linear Embedding | doi = 10.1126/science.290.5500.2323 | journal = Science | volume = 290 | issue = 5500 | pages = 2323–2326 | year = 2000 | pmid =  11125150| bibcode = 2000Sci...290.2323R | citeseerx = 10.1.1.111.3313 }}&lt;/ref&gt; Hessian LLE, Laplacian eigenmaps, and methods based on tangent space analysis.&lt;ref&gt;{{Cite journal|last=Zhang|first=Zhenyue|last2=Zha|first2=Hongyuan|date=2004|title=Principal Manifolds and Nonlinear Dimensionality Reduction via Tangent Space Alignment|journal=SIAM Journal on Scientific Computing|volume=26|issue=1|pages=313–338|doi=10.1137/s1064827502419154}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Bengio|first=Yoshua|last2=Monperrus|first2=Martin|last3=Larochelle|first3=Hugo|date=2006|title=Nonlocal Estimation of Manifold Structure|url=https://hal.archives-ouvertes.fr/hal-01575345/document|journal=Neural Computation|language=en|volume=18|issue=10|pages=2509–2528|doi=10.1162/neco.2006.18.10.2509|pmid=16907635|citeseerx=10.1.1.116.4230}}&lt;/ref&gt; These techniques construct a low-dimensional data representation using a cost function that retains local properties of the data, and can be viewed as defining a graph-based kernel for Kernel PCA.

More recently, techniques have been proposed that, instead of defining a fixed kernel, try to learn the kernel using [[semidefinite programming]]. The most prominent example of such a technique is [[maximum variance unfolding]] (MVU). The central idea of MVU is to exactly preserve all pairwise distances between nearest neighbors (in the inner product space), while maximizing the distances between points that are not nearest neighbors.

An alternative approach to neighborhood preservation is through the minimization of a cost function that measures differences between distances in the input and output spaces. Important examples of such techniques include: classical [[multidimensional scaling]], which is identical to PCA; [[Isomap]], which uses geodesic distances in the data space; [[diffusion map]]s, which use diffusion distances in the data space; [[t-distributed stochastic neighbor embedding]] (t-SNE), which minimizes the divergence between distributions over pairs of points; and curvilinear component analysis.

A different approach to nonlinear dimensionality reduction is through the use of [[autoencoder]]s, a special kind of feed-forward [[neural network]]s with a bottle-neck hidden layer.&lt;ref&gt;Hongbing Hu, Stephen A. Zahorian, (2010) [http://bingweb.binghamton.edu/~hhu1/paper/Hu2010Dimensionality.pdf "Dimensionality Reduction Methods for HMM Phonetic Recognition,"] ICASSP 2010, Dallas, TX&lt;/ref&gt; The training of deep encoders is typically performed using a greedy layer-wise pre-training (e.g., using a stack of [[restricted Boltzmann machine]]s) that is followed by a finetuning stage based on [[backpropagation]].

===Linear discriminant analysis (LDA)===
{{main article|Linear discriminant analysis}}
Linear discriminant analysis (LDA) is a generalization of Fisher's linear discriminant, a method used in statistics, pattern recognition and machine learning to find a linear combination of features that characterizes or separates two or more classes of objects or events.

===Generalized discriminant analysis (GDA)===
GDA deals with nonlinear discriminant analysis using kernel function operator. The underlying theory is close to the [[support vector machine]]s (SVM) insofar as the GDA method provides a mapping of the input vectors into high-dimensional feature space.&lt;ref name="gda"&gt;{{Cite journal |doi = 10.1162/089976600300014980|pmid = 11032039|title = Generalized Discriminant Analysis Using a Kernel Approach|journal = Neural Computation|volume = 12|issue = 10|pages = 2385–2404|year = 2000|last1 = Baudat|first1 = G.|last2 = Anouar|first2 = F.|citeseerx = 10.1.1.412.760}}&lt;/ref&gt;&lt;ref name="cloudid"&gt;{{Cite journal |doi = 10.1016/j.eswa.2015.06.025|title = CloudID: Trustworthy cloud-based and cross-enterprise biometric identification|journal = Expert Systems with Applications|volume = 42|issue = 21|pages = 7905–7916|year = 2015|last1 = Haghighat|first1 = Mohammad|last2 = Zonouz|first2 = Saman|last3 = Abdel-Mottaleb|first3 = Mohamed}}&lt;/ref&gt; Similar to LDA, the objective of GDA is to find a projection for the features into a lower dimensional space by maximizing the ratio of between-class scatter to within-class scatter.

===Autoencoder===
{{main article|Autoencoder}}
Autoencoders can be used to learn non-linear dimension reduction functions and codings together with an inverse function from the coding to the original representation.

===t-SNE===
{{main article|tSNE}}
T-distributed Stochastic Neighbor Embedding (t-SNE) is a non-linear dimensionality reduction technique useful for visualization of high-dimensional datasets. It is not recommended for use in analysis such as clustering or outlier detection since it does not necessarily preserve densities or distances well.&lt;ref&gt;{{Cite journal|last=Schubert|first=Erich|last2=Gertz|first2=Michael|date=2017|editor-last=Beecks|editor-first=Christian|editor2-last=Borutta|editor2-first=Felix|editor3-last=Kröger|editor3-first=Peer|editor4-last=Seidl|editor4-first=Thomas|title=Intrinsic t-Stochastic Neighbor Embedding for Visualization and Outlier Detection|url=https://link.springer.com/chapter/10.1007/978-3-319-68474-1_13|journal=Similarity Search and Applications|series=Lecture Notes in Computer Science|language=en|location=Cham|publisher=Springer International Publishing|pages=188–203|doi=10.1007/978-3-319-68474-1_13|isbn=978-3-319-68474-1}}&lt;/ref&gt;

===UMAP===
{{main article|Uniform Manifold Approximation and Projection}}
[[Uniform manifold approximation and projection]] (UMAP) is a nonlinear dimensionality reduction technique. Visually, it is similar to t-SNE, but it assumes that the data is uniformly distributed on a [[locally connected]] [[Riemannian manifold]] and that the [[Riemannian metric]] is locally constant or approximately locally constant.

==Dimension reduction==
For high-dimensional datasets (i.e. with number of dimensions more than 10), dimension reduction is usually performed prior to applying a [[K-nearest neighbors algorithm]] (k-NN) in order to avoid the effects of the [[curse of dimensionality]].&lt;ref&gt;Kevin Beyer, Jonathan Goldstein, Raghu Ramakrishnan, Uri Shaft (1999) [http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.31.1422 "When is “nearest neighbor” meaningful?"]. ''Database Theory—ICDT99'',  217–235&lt;/ref&gt;

[[Feature extraction]] and  dimension reduction can be combined in one step using [[principal component analysis]] (PCA),  [[linear discriminant analysis]] (LDA), [[canonical correlation analysis]] (CCA), or [[non-negative matrix factorization]] (NMF) techniques as a pre-processing step followed by clustering by K-NN on [[Feature (machine learning)|feature vectors]] in reduced-dimension space. In [[machine learning]] this process is also called low-dimensional [[embedding]].&lt;ref&gt;{{Cite book | last1 = Shaw | first1 = B. | last2 = Jebara | first2 = T. | doi = 10.1145/1553374.1553494 | chapter = Structure preserving embedding | title = Proceedings of the 26th Annual International Conference on Machine Learning – ICML '09 | pages = 1 | year = 2009 | isbn = 9781605585161 | chapter-url = https://www.cs.columbia.edu/~jebara/papers/spe-icml09.pdf| citeseerx = 10.1.1.161.451 }}&lt;/ref&gt;

For very-high-dimensional datasets (e.g. when performing similarity search on live video streams, DNA data or high-dimensional [[time series]]) running a fast '''approximate''' K-NN search using [[locality sensitive hashing]], [[random projection]],&lt;ref&gt;{{Cite book | last1 = Bingham | first1 = E. | last2 = Mannila | first2 = H. | doi = 10.1145/502512.502546 | chapter = Random projection in dimensionality reduction | title = Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining – KDD '01 | pages = 245 | year = 2001 | isbn = 978-1581133912 }}&lt;/ref&gt; "sketches" &lt;ref&gt;Shasha, D High (2004) ''Performance Discovery in Time Series'' Berlin: Springer. {{ISBN|0-387-00857-8}}&lt;/ref&gt; or other high-dimensional similarity search  techniques from the [[VLDB conference|VLDB]] toolbox might be the only feasible option.

==Applications==
A dimensionality reduction technique that is sometimes used in [[neuroscience]] is [[maximally informative dimensions]],{{citation needed|date=June 2017}} which finds a lower-dimensional representation of a dataset such that as much [[mutual information|information]] as possible about the original data is preserved.

==See also==
{{Recommender systems}}
{{div col start|colwidth=20em}}
* [[Nearest neighbor search]]
* [[MinHash]]
* [[Information gain in decision trees]]
* [[Semidefinite embedding]]
* [[Multifactor dimensionality reduction]]
* [[Multilinear subspace learning]]
* [[Multilinear PCA]]
* [[Random projection]]
* [[Singular value decomposition]]
* [[Latent semantic analysis]]
* [[Semantic mapping (statistics)|Semantic mapping]]
* [[Tensorsketch]] 
* [[Topological data analysis]]
* [[Locality sensitive hashing]]
* [[Sufficient dimension reduction]]
* [[Data transformation (statistics)]]
* [[Weighted correlation network analysis]]
* [[Hyperparameter optimization]]
* [[CUR matrix approximation]]
* Envelope model
* [[Nonlinear dimensionality reduction]]
* [[Sammon mapping]]
* [[Johnson–Lindenstrauss lemma]]
* [[Local tangent space alignment]]
{{div col end}}
{{clear}}

==Notes==
{{Reflist}}

==References==
{{refbegin}}
* {{cite book |first=Brad |last=Boehmke |first2=Brandon M. |last2=Greenwell |chapter=Dimension Reduction |title=Hands-On Machine Learning with R |publisher=Chapman &amp; Hall |year=2019 |pages=343–396 |isbn=978-1-138-49568-5 |chapter-url=https://books.google.com/books?id=aXC9DwAAQBAJ&amp;pg=PA343 }}
* {{cite techreport |last=Fodor |first=I. |year=2002 |url=http://citeseerx.ist.psu.edu/viewdoc/versions?doi=10.1.1.8.5098 |title=A survey of dimension reduction techniques |publisher=Center for Applied Scientific Computing, Lawrence Livermore National |id=UCRL-ID-148494 }}
* {{cite techreport |last=Cunningham |first=P. |year=2007 |url=http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.98.1478 |title=Dimension Reduction |publisher=University College Dublin |id=UCD-CSI-2007-7 }}
* {{cite book |last=Lakshmi Padmaja |first=Dhyaram |chapter=Comparative Study of Feature Subset Selection Methods for Dimensionality Reduction on Scientific Data |title=2016 IEEE 6th International Conference on Advanced Computing (IACC) |last2=Vishnuvardhan |first2=B |date=2016 |pages=31–34 |doi=10.1109/IACC.2016.16 |isbn=978-1-4673-8286-1 }}
{{refend}}

==External links==
* [http://jmlr.csail.mit.edu/papers/special/feature03.html JMLR Special Issue on Variable and Feature Selection]
* [http://bioinfo-out.curie.fr/projects/elmap/ ELastic MAPs]
* [http://www.cs.toronto.edu/~roweis/lle Locally Linear Embedding]
* [https://intelligencereborn.com/MachineLearningDimensionalityReduction.html Visual Comparison of various dimensionality reduction methods]
* [https://web.archive.org/web/20040411051530/http://isomap.stanford.edu/ A Global Geometric Framework for Nonlinear Dimensionality Reduction]

{{DEFAULTSORT:Dimension Reduction}}
[[Category:Dimension reduction| ]]
[[Category:Machine learning]]</text>
      <sha1>9wh6z07yhbv3grerglb3g9sznmynr54</sha1>
    </revision>
  </page>
  <page>
    <title>Sequence labeling</title>
    <ns>0</ns>
    <id>29288159</id>
    <revision>
      <id>996578567</id>
      <parentid>760731398</parentid>
      <timestamp>2020-12-27T13:06:47Z</timestamp>
      <contributor>
        <ip>81.98.57.130</ip>
      </contributor>
      <comment>removed empty section</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3473" xml:space="preserve">{{Refimprove|date=November 2016}}
In [[machine learning]], '''sequence labeling''' is a type of [[pattern recognition]] task that involves the algorithmic assignment of a [[categorical data|categorical]] label to each member of a sequence of observed values.  A common example of a sequence labeling task is [[part of speech tagging]], which seeks to assign a [[part of speech]] to each word in an input sentence or document.  Sequence labeling can be treated as a set of independent [[classification (machine learning)|classification]] tasks, one per member of the sequence.  However, accuracy is generally improved by making the optimal label for a given element dependent on the choices of nearby elements, using special algorithms to choose the ''globally'' best set of labels for the entire sequence at once.

As an example of why finding the globally best label sequence might produce better results than labeling one item at a time, consider the part-of-speech tagging task just described.  Frequently, many words are members of multiple parts of speech, and the correct label of such a word can often be deduced from the correct label of the word to the immediate left or right.  For example, the word "sets" can be either a noun or verb.  In a phrase like "he sets the books down", the word "he" is unambiguously a pronoun, and "the" unambiguously a [[determiner (linguistics)|determiner]], and using either of these labels, "sets" can be deduced to be a verb, since nouns very rarely follow pronouns and are less likely to precede determiners than verbs are.  But in other cases, only one of the adjacent words is similarly helpful.  In "he sets and then knocks over the table", only the word "he" to the left is helpful (cf. "...picks up the sets and then knocks over...").  Conversely, in "... and also sets the table" only the word "the" to the right is helpful (cf. "... and also sets of books were ...").  An algorithm that proceeds from left to right, labeling one word at a time, can only use the tags of left-adjacent words and might fail in the second example above; vice versa for an algorithm that proceeds from right to left.

Most sequence labeling algorithms are [[probability theory|probabilistic]] in nature, relying on [[statistical inference]] to find the best sequence.  The most common statistical models in use for sequence labeling make a Markov assumption, i.e. that the choice of label for a particular word is directly dependent only on the immediately adjacent labels; hence the set of labels forms a [[Markov chain]].  This leads naturally to the [[hidden Markov model]] (HMM), one of the most common statistical models used for sequence labeling.  Other common models in use are the [[maximum entropy Markov model]] and [[conditional random field]].

== See also ==
* [[Artificial intelligence]]
* [[Bayesian network]]s (of which HMMs are an example)
* [[Classification (machine learning)]]
* [[Linear dynamical system]], which applies to tasks where the "label" is actually a real number
* [[Machine learning]]
* [[Pattern recognition]]
* [[Sequence mining]]

==References==
{{Reflist}}

==Further reading==

* Erdogan H., [http://www.erdogan.org/publications/erdogan_icmla2010_tutorial_new.pdf]. "Sequence labeling: generative and discriminative approaches, hidden Markov models, conditional random fields and structured SVMs," ICMLA 2010 tutorial, Bethesda, MD (2010)

{{DEFAULTSORT:Sequence Labeling}}
[[Category:Machine learning]]</text>
      <sha1>pknma4lz2c4juxf9xc9a73r912znn03</sha1>
    </revision>
  </page>
  <page>
    <title>Mixture model</title>
    <ns>0</ns>
    <id>871681</id>
    <revision>
      <id>1002271790</id>
      <parentid>1001573643</parentid>
      <timestamp>2021-01-23T17:15:04Z</timestamp>
      <contributor>
        <username>HelpUsStopSpam</username>
        <id>24038232</id>
      </contributor>
      <comment>Undo spammed references</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="57974" xml:space="preserve">{{distinguish|mixed model}}
{{See also|Mixture distribution}}
In [[statistics]], a '''mixture model''' is a [[probabilistic model]] for representing the presence of [[subpopulation]]s within an overall population, without requiring that an observed data set should identify the sub-population to which an individual observation belongs. Formally a mixture model corresponds to the [[mixture distribution]] that represents the [[probability distribution]] of observations in the overall population. However, while problems associated with "mixture distributions" relate to deriving the properties of the overall population from those of the sub-populations, "mixture models" are used to make [[statistical inference]]s about the properties of the sub-populations given only observations on the pooled population, without sub-population identity information.

Mixture models should not be confused with models for [[compositional data]], i.e., data whose components are constrained to sum to a constant value (1, 100%, etc.). However, compositional models can be thought of as mixture models, where members of the population are sampled at random. Conversely, mixture models can be thought of as compositional models, where the [[measure (mathematics)|total size]] reading population has been normalized to 1.

==Structure==

===General mixture model===
A typical finite-dimensional mixture model is a [[hierarchical Bayes model|hierarchical model]] consisting of the following components:

*''N'' random variables that are observed, each distributed according to a mixture of ''K'' components, with the components belonging to the same [[parametric family]] of distributions (e.g., all [[normal distribution|normal]], all [[Zipf's law|Zipfian]], etc.) but with different parameters
*''N'' random [[latent variable]]s specifying the identity of the mixture component of each observation, each distributed according to a ''K''-dimensional [[categorical distribution]]
*A set of ''K'' mixture weights, which are probabilities that sum to 1.
*A set of ''K'' parameters, each specifying the parameter of the corresponding mixture component.  In many cases, each "parameter" is actually a set of parameters.  For example, if the mixture components are [[Gaussian distribution]]s, there will be a [[mean]] and [[variance]] for each component. If the mixture components are [[categorical distribution]]s (e.g., when each observation is a token from a finite alphabet of size ''V''), there will be a vector of ''V'' probabilities summing to 1.

In addition, in a [[Bayesian inference|Bayesian setting]], the mixture weights and parameters will themselves be random variables, and [[prior distribution]]s will be placed over the variables.  In such a case, the weights are typically viewed as a ''K''-dimensional random vector drawn from a [[Dirichlet distribution]] (the [[conjugate prior]] of the categorical distribution), and the parameters will be distributed according to their respective conjugate priors.

Mathematically, a basic parametric mixture model can be described as follows:

:&lt;math&gt;
\begin{array}{lcl}
K &amp;=&amp; \text{number of mixture components} \\
N &amp;=&amp; \text{number of observations} \\
\theta_{i=1 \dots K} &amp;=&amp; \text{parameter of distribution of observation associated with component } i \\
\phi_{i=1 \dots K} &amp;=&amp; \text{mixture weight, i.e., prior probability of a particular component } i \\
\boldsymbol\phi &amp;=&amp; K\text{-dimensional vector composed of all the individual } \phi_{1 \dots K} \text{; must sum to 1} \\
z_{i=1 \dots N} &amp;=&amp; \text{component of observation } i \\
x_{i=1 \dots N} &amp;=&amp; \text{observation } i \\
F(x|\theta) &amp;=&amp; \text{probability distribution of an observation, parametrized on } \theta \\
z_{i=1 \dots N} &amp;\sim&amp; \operatorname{Categorical}(\boldsymbol\phi) \\
x_{i=1 \dots N}|z_{i=1 \dots N} &amp;\sim&amp; F(\theta_{z_i})
\end{array}
&lt;/math&gt;

In a Bayesian setting, all parameters are associated with random variables, as follows:

:&lt;math&gt;
\begin{array}{lcl}
K,N &amp;=&amp; \text{as above} \\
\theta_{i=1 \dots K}, \phi_{i=1 \dots K}, \boldsymbol\phi &amp;=&amp; \text{as above} \\
z_{i=1 \dots N}, x_{i=1 \dots N}, F(x|\theta) &amp;=&amp; \text{as above} \\
\alpha &amp;=&amp; \text{shared hyperparameter for component parameters} \\
\beta &amp;=&amp; \text{shared hyperparameter for mixture weights} \\
H(\theta|\alpha) &amp;=&amp; \text{prior probability distribution of component parameters, parametrized on } \alpha \\
\theta_{i=1 \dots K} &amp;\sim&amp; H(\theta|\alpha) \\
\boldsymbol\phi &amp;\sim&amp; \operatorname{Symmetric-Dirichlet}_K(\beta) \\
z_{i=1 \dots N}|\boldsymbol\phi &amp;\sim&amp; \operatorname{Categorical}(\boldsymbol\phi) \\
x_{i=1 \dots N}|z_{i=1 \dots N},\theta_{i=1 \dots K} &amp;\sim&amp; F(\theta_{z_i})
\end{array}
&lt;/math&gt;

This characterization uses ''F'' and ''H'' to describe arbitrary distributions over observations and parameters, respectively.  Typically ''H'' will be the [[conjugate prior]] of ''F''.  The two most common choices of ''F'' are [[Gaussian distribution|Gaussian]] aka "[[normal distribution|normal]]" (for real-valued observations) and [[categorical distribution|categorical]] (for discrete observations).  Other common possibilities for the distribution of the mixture components are:
*[[Binomial distribution]], for the number of "positive occurrences" (e.g., successes, yes votes, etc.) given a fixed number of total occurrences
*[[Multinomial distribution]], similar to the binomial distribution, but for counts of multi-way occurrences (e.g., yes/no/maybe in a survey)
*[[Negative binomial distribution]], for binomial-type observations but where the quantity of interest is the number of failures before a given number of successes occurs
*[[Poisson distribution]], for the number of occurrences of an event in a given period of time, for an event that is characterized by a fixed rate of occurrence
*[[Exponential distribution]], for the time before the next event occurs, for an event that is characterized by a fixed rate of occurrence
*[[Log-normal distribution]], for positive real numbers that are assumed to grow exponentially, such as incomes or prices
*[[Multivariate normal distribution]] (aka [[multivariate Gaussian distribution]]), for vectors of correlated outcomes that are individually Gaussian-distributed
*[[Multivariate Student's-t distribution]] (aka [[multivariate t-distribution]]), for vectors of heavy-tailed correlated outcomes&lt;ref&gt;Sotirios P. Chatzis, Dimitrios I. Kosmopoulos, Theodora A. Varvarigou, "Signal Modeling and Classification Using a Robust Latent Space Model Based on t Distributions," IEEE Transactions on Signal Processing, vol. 56, no. 3, pp. 949–963, March 2008. [https://ieeexplore.ieee.org/document/4451278/]&lt;/ref&gt;
*A vector of [[Bernoulli distribution|Bernoulli]]-distributed values, corresponding, e.g., to a black-and-white image, with each value representing a pixel; see the handwriting-recognition example below

===Specific examples===

====Gaussian mixture model====
[[File:nonbayesian-gaussian-mixture.svg|right|250px|thumb|Non-Bayesian Gaussian mixture model using [[plate notation]].  Smaller squares indicate fixed parameters; larger circles indicate random variables.  Filled-in shapes indicate known values.  The indication [K] means a vector of size ''K''.]]

A typical non-Bayesian [[Gaussian distribution|Gaussian]] mixture model looks like this:

:&lt;math&gt;
\begin{array}{lcl}
K,N &amp;=&amp; \text{as above} \\
\phi_{i=1 \dots K}, \boldsymbol\phi &amp;=&amp; \text{as above} \\
z_{i=1 \dots N}, x_{i=1 \dots N} &amp;=&amp; \text{as above} \\
\theta_{i=1 \dots K} &amp;=&amp; \{ \mu_{i=1 \dots K}, \sigma^2_{i=1 \dots K} \}  \\
\mu_{i=1 \dots K} &amp;=&amp; \text{mean of component } i \\
\sigma^2_{i=1 \dots K} &amp;=&amp; \text{variance of component } i \\
z_{i=1 \dots N} &amp;\sim&amp; \operatorname{Categorical}(\boldsymbol\phi) \\
x_{i=1 \dots N} &amp;\sim&amp; \mathcal{N}(\mu_{z_i}, \sigma^2_{z_i})
\end{array}
&lt;/math&gt;

{{clear}}
[[File:bayesian-gaussian-mixture.svg|right|300px|thumb|Bayesian Gaussian mixture model using [[plate notation]].  Smaller squares indicate fixed parameters; larger circles indicate random variables.  Filled-in shapes indicate known values.  The indication [K] means a vector of size ''K''.]]

A Bayesian version of a [[Gaussian distribution|Gaussian]] mixture model is as follows:

:&lt;math&gt;
\begin{array}{lcl}
K,N &amp;=&amp; \text{as above} \\
\phi_{i=1 \dots K}, \boldsymbol\phi &amp;=&amp; \text{as above} \\
z_{i=1 \dots N}, x_{i=1 \dots N} &amp;=&amp; \text{as above} \\
\theta_{i=1 \dots K} &amp;=&amp; \{ \mu_{i=1 \dots K}, \sigma^2_{i=1 \dots K} \}  \\
\mu_{i=1 \dots K} &amp;=&amp; \text{mean of component } i \\
\sigma^2_{i=1 \dots K} &amp;=&amp; \text{variance of component } i \\
\mu_0, \lambda, \nu, \sigma_0^2 &amp;=&amp; \text{shared hyperparameters} \\
\mu_{i=1 \dots K} &amp;\sim&amp; \mathcal{N}(\mu_0, \lambda\sigma_i^2) \\
\sigma_{i=1 \dots K}^2 &amp;\sim&amp; \operatorname{Inverse-Gamma}(\nu, \sigma_0^2) \\
\boldsymbol\phi &amp;\sim&amp; \operatorname{Symmetric-Dirichlet}_K(\beta) \\
z_{i=1 \dots N} &amp;\sim&amp; \operatorname{Categorical}(\boldsymbol\phi) \\
x_{i=1 \dots N} &amp;\sim&amp; \mathcal{N}(\mu_{z_i}, \sigma^2_{z_i})
\end{array}
&lt;/math&gt;&lt;math&gt;&lt;/math&gt;
[[File:Parameter estimation process infinite Gaussian mixture model.webm|thumb|end=49|Animation of the clustering process for one-dimensional data using a Bayesian Gaussian mixture model where normal distributions are drawn from a [[Dirichlet process]]. The histograms of the clusters are shown in different colours. During the parameter estimation process, new clusters are created and grow on the data. The legend shows the cluster colours and the number of datapoints assigned to each cluster.]]

====Multivariate Gaussian mixture model====
A Bayesian Gaussian mixture model is commonly extended to fit a vector of unknown parameters (denoted in bold), or multivariate normal distributions.  In a multivariate distribution (i.e. one modelling a vector &lt;math&gt;\boldsymbol{x}&lt;/math&gt; with ''N'' random variables) one may model a vector of parameters (such as several observations of a signal or patches within an image) using a Gaussian mixture model prior distribution on the vector of estimates given by
:&lt;math&gt;
p(\boldsymbol{\theta}) = \sum_{i=1}^K\phi_i \mathcal{N}(\boldsymbol{\mu_i,\Sigma_i})
&lt;/math&gt;
where the ''i&lt;sup&gt;th&lt;/sup&gt;'' vector component is characterized by normal distributions with weights &lt;math&gt;\phi_i&lt;/math&gt;, means &lt;math&gt;\boldsymbol{\mu_i}&lt;/math&gt; and covariance matrices &lt;math&gt;\boldsymbol{\Sigma_i}&lt;/math&gt;.  To incorporate this prior into a Bayesian estimation, the prior is multiplied with the known distribution &lt;math&gt;p(\boldsymbol{x | \theta})&lt;/math&gt; of the data &lt;math&gt;\boldsymbol{x}&lt;/math&gt; conditioned on the parameters &lt;math&gt;\boldsymbol{\theta}&lt;/math&gt; to be estimated.  With this formulation, the [[Posterior probability|posterior distribution]] &lt;math&gt;p(\boldsymbol{\theta | x})&lt;/math&gt; is ''also'' a Gaussian mixture model of the form 
:&lt;math&gt;
p(\boldsymbol{\theta | x}) = \sum_{i=1}^K\tilde{\phi_i} \mathcal{N}(\boldsymbol{\tilde{\mu_i},\tilde{\Sigma_i}})
&lt;/math&gt;
with new parameters &lt;math&gt;\tilde{\phi_i}, \boldsymbol{\tilde{\mu_i}}&lt;/math&gt; and &lt;math&gt;\boldsymbol{\tilde{\Sigma_i}}&lt;/math&gt; that are updated using the [[Expectation-maximization algorithm|EM algorithm]].
&lt;ref&gt;
{{cite journal
|last=Yu |first=Guoshen
|title=Solving Inverse Problems with Piecewise Linear Estimators: From Gaussian Mixture Models to Structured Sparsity
|journal=IEEE Transactions on Image Processing
|volume=21 | date=2012|pages=2481–2499 |issue=5 |doi=10.1109/tip.2011.2176743
|pmid=22180506
|bibcode = 2012ITIP...21.2481G |arxiv=1006.3056|s2cid=479845
}}
&lt;/ref&gt; Although EM-based parameter updates are well-established, providing the initial estimates for these parameters is currently an area of active research.  Note that this formulation yields a closed-form solution to the complete posterior distribution.  Estimations of the random variable &lt;math&gt;\boldsymbol{\theta}&lt;/math&gt; may be obtained via one of several estimators, such as the mean or maximum of the posterior distribution.

Such distributions are useful for assuming patch-wise shapes of images and clusters, for example.  In the case of image representation, each Gaussian may be tilted, expanded, and warped according to the covariance matrices &lt;math&gt;\boldsymbol{\Sigma_i}&lt;/math&gt;.  One Gaussian distribution of the set is fit to each patch (usually of size 8x8 pixels) in the image.  Notably, any distribution of points around a cluster (see [[K-means clustering|''k''-means]]) may be accurately given enough Gaussian components, but scarcely over ''K''=20 components are needed to accurately model a given image distribution or cluster of data.

====Categorical mixture model====
[[File:nonbayesian-categorical-mixture.svg|right|250px|thumb|Non-Bayesian categorical mixture model using [[plate notation]].  Smaller squares indicate fixed parameters; larger circles indicate random variables.  Filled-in shapes indicate known values.  The indication [K] means a vector of size ''K''; likewise for [V].]]

A typical non-Bayesian mixture model with [[categorical distribution|categorical]] observations looks like this:

*&lt;math&gt;K,N:&lt;/math&gt; as above
*&lt;math&gt;\phi_{i=1 \dots K}, \boldsymbol\phi:&lt;/math&gt; as above
*&lt;math&gt;z_{i=1 \dots N}, x_{i=1 \dots N}:&lt;/math&gt; as above
*&lt;math&gt;V:&lt;/math&gt; dimension of categorical observations, e.g., size of word vocabulary
*&lt;math&gt;\theta_{i=1 \dots K, j=1 \dots V}:&lt;/math&gt; probability for component &lt;math&gt;i&lt;/math&gt; of observing item &lt;math&gt;j&lt;/math&gt;
*&lt;math&gt;\boldsymbol\theta_{i=1 \dots K}:&lt;/math&gt; vector of dimension &lt;math&gt;V,&lt;/math&gt; composed of &lt;math&gt;\theta_{i,1 \dots V};&lt;/math&gt; must sum to 1

The random variables:
:&lt;math&gt;
\begin{array}{lcl}
z_{i=1 \dots N} &amp;\sim&amp; \operatorname{Categorical}(\boldsymbol\phi) \\
x_{i=1 \dots N} &amp;\sim&amp; \text{Categorical}(\boldsymbol\theta_{z_i})
\end{array}
&lt;/math&gt;

&lt;!--
The original version, all in LaTeX.
:&lt;math&gt;
\begin{array}{lcl}
K,N &amp;=&amp; \text{as above} \\
\phi_{i=1 \dots K}, \boldsymbol\phi &amp;=&amp; \text{as above} \\
z_{i=1 \dots N}, x_{i=1 \dots N} &amp;=&amp; \text{as above} \\
V &amp;=&amp; \text{dimension of categorical observations, e.g., size of word vocabulary} \\
\theta_{i=1 \dots K, j=1 \dots V} &amp;=&amp; \text{probability for component } i \text{ of observing the } j\text{th item} \\
\boldsymbol\theta_{i=1 \dots K} &amp;=&amp; V\text{-dimensional vector, composed of }\theta_{i,1 \dots V} \text{; must sum to 1} \\
z_{i=1 \dots N} &amp;\sim&amp; \operatorname{Categorical}(\boldsymbol\phi) \\
x_{i=1 \dots N} &amp;\sim&amp; \text{Categorical}(\boldsymbol\theta_{z_i})
\end{array}
&lt;/math&gt;
--&gt;

{{clear}}
[[File:bayesian-categorical-mixture.svg|right|300px|thumb|Bayesian categorical mixture model using [[plate notation]].  Smaller squares indicate fixed parameters; larger circles indicate random variables.  Filled-in shapes indicate known values.  The indication [K] means a vector of size ''K''; likewise for [V].]]

A typical Bayesian mixture model with [[categorical distribution|categorical]] observations looks like this:

*&lt;math&gt;K,N:&lt;/math&gt; as above
*&lt;math&gt;\phi_{i=1 \dots K}, \boldsymbol\phi:&lt;/math&gt; as above
*&lt;math&gt;z_{i=1 \dots N}, x_{i=1 \dots N}:&lt;/math&gt; as above
*&lt;math&gt;V:&lt;/math&gt; dimension of categorical observations, e.g., size of word vocabulary
*&lt;math&gt;\theta_{i=1 \dots K, j=1 \dots V}:&lt;/math&gt; probability for component &lt;math&gt;i&lt;/math&gt; of observing item &lt;math&gt;j&lt;/math&gt;
*&lt;math&gt;\boldsymbol\theta_{i=1 \dots K}:&lt;/math&gt; vector of dimension &lt;math&gt;V,&lt;/math&gt; composed of &lt;math&gt;\theta_{i,1 \dots V};&lt;/math&gt; must sum to 1
*&lt;math&gt;\alpha:&lt;/math&gt; shared concentration hyperparameter of &lt;math&gt;\boldsymbol\theta&lt;/math&gt; for each component
*&lt;math&gt;\beta:&lt;/math&gt; concentration hyperparameter of &lt;math&gt;\boldsymbol\phi&lt;/math&gt;

The random variables:
:&lt;math&gt;
\begin{array}{lcl}
\boldsymbol\phi &amp;\sim&amp; \operatorname{Symmetric-Dirichlet}_K(\beta) \\
\boldsymbol\theta_{i=1 \dots K} &amp;\sim&amp; \text{Symmetric-Dirichlet}_V(\alpha) \\
z_{i=1 \dots N} &amp;\sim&amp; \operatorname{Categorical}(\boldsymbol\phi) \\
x_{i=1 \dots N} &amp;\sim&amp; \text{Categorical}(\boldsymbol\theta_{z_i})
\end{array}
&lt;/math&gt;

&lt;!--
The (beginning of) equivalent of below, using no LaTeX.

*''K'',''N'' = as above
*&amp;phi;&lt;sub&gt;1,...,''K''&lt;/sub&gt;, '''&amp;phi;''' as above
*''z''&lt;sub&gt;''i''=1...''N''&lt;/sub&gt;, ''x''&lt;sub&gt;''i''=1...''N''&lt;/sub&gt; = as above
* ''V'' = dimension of categorical observations, e.g., size of word vocabulary
--&gt;
&lt;!--
The equivalent using full LaTeX.

:&lt;math&gt;
\begin{array}{lcl}
K,N &amp;=&amp; \mbox{as above} \\
\phi_{i=1 \dots K}, \boldsymbol\phi &amp;=&amp; \text{as above} \\
z_{i=1 \dots N}, x_{i=1 \dots N} &amp;=&amp; \text{as above} \\
V &amp;=&amp; \text{dimension of categorical observations, e.g., size of word vocabulary} \\
\theta_{i=1 \dots K, j=1 \dots V} &amp;=&amp; \text{probability for component } i \text{ of observing the } j\text{th item} \\
\boldsymbol\theta_{i=1 \dots K} &amp;=&amp; V\text{-dimensional vector, composed of }\theta_{i,1 \dots V} \text{; must sum to 1} \\
\alpha &amp;=&amp; \text{shared concentration hyperparameter of } \boldsymbol\theta \text{ for each component} \\
\beta &amp;=&amp; \text{concentration hyperparameter of } \boldsymbol\phi \\
\boldsymbol\phi &amp;\sim&amp; \operatorname{Symmetric-Dirichlet}_K(\beta) \\
\boldsymbol\theta_{i=1 \dots K} &amp;\sim&amp; \text{Symmetric-Dirichlet}_V(\alpha) \\
z_{i=1 \dots N} &amp;\sim&amp; \operatorname{Categorical}(\boldsymbol\phi) \\
x_{i=1 \dots N} &amp;\sim&amp; \text{Categorical}(\boldsymbol\theta_{z_i})
\end{array}
&lt;/math&gt;
--&gt;

==Examples==

===A financial model===
[[File:Normal distribution pdf.png|thumb|right|250px|The [[normal distribution]] is plotted using different means and variances]]

Financial returns often behave differently in normal situations and during crisis times. A mixture model&lt;ref&gt;Dinov, ID. "[http://repositories.cdlib.org/socr/EM_MM/ Expectation Maximization and Mixture Modeling Tutorial]". ''[http://repositories.cdlib.org/escholarship California Digital Library]'', Statistics Online Computational Resource, Paper EM_MM, http://repositories.cdlib.org/socr/EM_MM, December 9, 2008&lt;/ref&gt; for return data seems reasonable. Sometimes the model used is a [[jump-diffusion model]], or as a mixture of two normal distributions. See [[Financial economics#Challenges and criticism]] for further context.

===House prices===
Assume that we observe the prices of ''N'' different houses.  Different types of houses in different neighborhoods will have vastly different prices, but the price of a particular type of house in a particular neighborhood (e.g., three-bedroom house in moderately upscale neighborhood) will tend to cluster fairly closely around the mean.  One possible model of such prices would be to assume that the prices are accurately described by a mixture model with ''K'' different components, each distributed as a [[normal distribution]] with unknown mean and variance, with each component specifying a particular combination of house type/neighborhood.  Fitting this model to observed prices, e.g., using the [[expectation-maximization algorithm]], would tend to cluster the prices according to house type/neighborhood and reveal the spread of prices in each type/neighborhood. (Note that for values such as prices or incomes that are guaranteed to be positive and which tend to grow [[exponential growth|exponentially]], a [[log-normal distribution]] might actually be a better model than a normal distribution.)

===Topics in a document===
Assume that a document is composed of ''N'' different words from a total vocabulary of size ''V'', where each word corresponds to one of ''K'' possible topics.  The distribution of such words could be modelled as a mixture of ''K'' different ''V''-dimensional [[categorical distribution]]s.  A model of this sort is commonly termed a [[topic model]].  Note that [[expectation maximization]] applied to such a model will typically fail to produce realistic results, due (among other things) to the [[overfitting|excessive number of parameters]].  Some sorts of additional assumptions are typically necessary to get good results.  Typically two sorts of additional components are added to the model:
#A [[prior distribution]] is placed over the parameters describing the topic distributions, using a [[Dirichlet distribution]] with a [[concentration parameter]] that is set significantly below 1, so as to encourage sparse distributions (where only a small number of words have significantly non-zero probabilities).
#Some sort of additional constraint is placed over the topic identities of words, to take advantage of natural clustering.
:*For example, a [[Markov chain]] could be placed on the topic identities (i.e., the latent variables specifying the mixture component of each observation), corresponding to the fact that nearby words belong to similar topics. (This results in a [[hidden Markov model]], specifically one where a [[prior distribution]] is placed over state transitions that favors transitions that stay in the same state.)
:*Another possibility is the [[latent Dirichlet allocation]] model, which divides up the words into ''D'' different documents and assumes that in each document only a small number of topics occur with any frequency.

===Handwriting recognition===
The following example is based on an example in [[Christopher M. Bishop]], ''Pattern Recognition and Machine Learning''.&lt;ref&gt;{{cite book | last = Bishop | first = Christopher | title = Pattern recognition and machine learning | publisher = Springer | location = New York | year = 2006 | isbn = 978-0-387-31073-2 }}&lt;/ref&gt;

Imagine that we are given an ''N''×''N'' black-and-white image that is known to be a scan of a hand-written digit between 0 and 9, but we don't know which digit is written.  We can create a mixture model with &lt;math&gt;K=10&lt;/math&gt; different components, where each component is a vector of size &lt;math&gt;N^2&lt;/math&gt; of [[Bernoulli distribution]]s (one per pixel).  Such a model can be trained with the [[expectation-maximization algorithm]] on an unlabeled set of hand-written digits, and will effectively cluster the images according to the digit being written.  The same model could then be used to recognize the digit of another image simply by holding the parameters constant, computing the probability of the new image for each possible digit (a trivial calculation), and returning the digit that generated the highest probability.

===Assessing projectile accuracy (a.k.a. circular error probable, CEP)===
Mixture models apply in the problem of directing multiple projectiles at a target (as in air, land, or sea defense applications), where the physical and/or statistical characteristics of the projectiles differ within the multiple projectiles. An example might be shots from multiple munitions types or shots from multiple locations directed at one target. The combination of projectile types may be characterized as a Gaussian mixture model.&lt;ref&gt;Spall, J. C. and Maryak, J. L. (1992). "A feasible Bayesian estimator of quantiles for projectile accuracy from non-i.i.d. data." ''Journal of the American Statistical Association'', vol. 87 (419), pp. 676–681. {{JSTOR|2290205}}&lt;/ref&gt; Further, a well-known measure of accuracy for a group of projectiles is the [[circular error probable]] (CEP), which is the number ''R'' such that, on average, half of the group of projectiles falls within the circle of radius ''R'' about the target point. The mixture model can be used to determine (or estimate) the value ''R''. The mixture model properly captures the different types of projectiles.

===Direct and indirect applications===
The financial example above is one direct application of the mixture model, a situation in which we assume an underlying mechanism so that each observation belongs to one of some number of different sources or categories. This underlying mechanism may or may not, however, be observable. In this form of mixture, each of the sources is described by a component probability density function, and its mixture weight is the probability that an observation comes from this component.

In an indirect application of the mixture model we do not assume such a mechanism. The mixture model is simply used for its mathematical flexibilities. For example, a mixture of two [[normal distribution]]s with different means may result in a density with two [[Mode (statistics)|modes]], which is not modeled by standard parametric distributions. Another example is given by the possibility of mixture distributions to model fatter tails than the basic Gaussian ones, so as to be a candidate for modeling more extreme events. When combined with [[dynamical consistency]], this approach has been applied to [[financial derivatives]] valuation in presence of the [[volatility smile]] in the context of [[local volatility]] models. This defines our application.

===Predictive Maintenance===
The mixture model-based clustering is also predominantly used in identifying the state of the machine in [[predictive maintenance]]. Density plots are used to analyze the density of high dimensional features. If multi-model densities are observed, then it is assumed that a finite set of densities are formed by a finite set of normal mixtures. A multivariate Gaussian mixture model is used to cluster the feature data into k number of groups where k represents each state of the machine. The machine state can be a normal state, power off state, or faulty state.&lt;ref&gt;{{Cite book|url=https://www.researchgate.net/publication/322900854|title=Fault Class Prediction in Unsupervised Learning using Model-Based Clustering Approach|last1=Amruthnath|first1=Nagdev|last2=Gupta|first2=Tarun|date=2018-02-02|doi=10.13140/rg.2.2.22085.14563|publisher=Unpublished}}&lt;/ref&gt; Each formed cluster can be diagnosed using techniques such as spectral analysis. In the recent years, this has also been widely used in other areas such as early fault detection.&lt;ref&gt;{{Cite book|url=https://www.researchgate.net/publication/322869981|title=A Research Study on Unsupervised Machine Learning Algorithms for Fault Detection in Predictive Maintenance|last1=Amruthnath|first1=Nagdev|last2=Gupta|first2=Tarun|date=2018-02-01|doi=10.13140/rg.2.2.28822.24648|publisher=Unpublished}}&lt;/ref&gt;

===Fuzzy image segmentation===
[[File:Movie.gif|thumb|An example of Gaussian Mixture in image segmentation with grey histogram]]
In image processing and computer vision, traditional [[image segmentation]] models often assign to one [[pixel]] only one exclusive pattern. In fuzzy or soft segmentation, any pattern can have certain "ownership" over any single pixel. If the patterns are Gaussian, fuzzy segmentation naturally results in Gaussian mixtures. Combined with other analytic or geometric tools (e.g., phase transitions over diffusive boundaries), such spatially regularized mixture models could lead to more realistic and computationally efficient segmentation methods.&lt;ref&gt;
{{cite journal 
| last = Shen | first = Jianhong (Jackie) 
| title = A stochastic-variational model for soft Mumford-Shah segmentation
| date = 2006 
| volume=2006
| pages=2–16
| journal=International Journal of Biomedical Imaging
| doi=10.1155/IJBI/2006/92329
| pmid = 23165059 
| pmc = 2324060 
| bibcode = 2006IJBI.200649515H 
}}&lt;/ref&gt;

===Point set registration===
Probabilistic mixture models such as [[Gaussian mixture model]]s (GMM) are used to resolve [[point set registration]] problems in image processing and computer vision fields. For pair-wise [[point set registration]], one point set is regarded as the centroids of mixture models, and the other point set is regarded as data points (observations). State-of-the-art methods are e.g. [[Point_set_registration#Point_set_registration_algorithms#Coherent point drift|coherent point drift]] (CPD)&lt;ref&gt;
{{cite journal 
| last1 = Myronenko | first1 = Andriy
| last2 = Song | first2 = Xubo
| title = Point set registration: Coherent point drift
| number=12
| volume=32
| year=2010
| pages=2262–2275
| journal=IEEE Trans. Pattern Anal. Mach. Intell.
| doi=10.1109/TPAMI.2010.46
| pmid = 20975122
| arxiv = 0905.2635
| s2cid = 10809031
}}&lt;/ref&gt; 
and [[Student's t-distribution]] mixture models (TMM).&lt;ref&gt;
{{cite journal 
| last1 = Ravikumar| first1 = Nishant
| last2 = Gooya| first2 = Ali
| last3 = Cimen| first3 = Serkan
| last4 = Frangi| first4 = Alexjandro
| last5 = Taylor| first5 = Zeike
| title = Group-wise similarity registration of point sets using Student's t-mixture model for statistical shape models
| volume=44
| year=2018
| pages=156–176
| journal=Med. Image. Anal.
| doi=10.1016/j.media.2017.11.012
| pmid = 29248842
| doi-access = free
}}&lt;/ref&gt; 
The result of recent research demonstrate the superiority of hybrid mixture models&lt;ref&gt;
{{cite conference 
| url = https://www.miccai2018.org/en/
| title = Intraoperative brain shift compensation using a hybrid mixture model
| last1 = Bayer| first1 = Siming
| last2 = Ravikumar| first2 = Nishant
| last3 = Strumia| first3 = Maddalena
| last4 = Tong| first4 = Xiaoguang
| last5 = Gao| first5 = Ying
| last6 = Ostermeier| first6 = Martin
| last7 = Fahrig| first7 = Rebecca
| last8 = Maier| first8 = Andreas
| date = 2018
| publisher = Springer, Cham
| book-title = Medical Image Computing and Computer Assisted Intervention – MICCAI 2018
| pages = 116–124
| location = Granada, Spain
| doi = 10.1007/978-3-030-00937-3_14
}}
&lt;/ref&gt; 
(e.g. combining Student's t-Distritubtion and Watson distribution/[[Bingham distribution]] to model spatial positions and axes orientations separately) compare to CPD and TMM, in terms of inherent robustness, accuracy and discriminative capacity.

== Identifiability ==

Identifiability refers to the existence of a unique characterization for any one of the models in the class (family) being considered. Estimation procedures may not be well-defined and asymptotic theory may not hold if a model is not identifiable.

=== Example ===
Let ''J'' be the class of all binomial distributions with {{nowrap|''n'' {{=}} 2}}. Then a mixture of two members of ''J'' would have

:&lt;math&gt;p_0=\pi(1-\theta_1)^2+(1-\pi)(1-\theta_2)^2&lt;/math&gt;
:&lt;math&gt;p_1=2\pi\theta_1(1-\theta_1)+2(1-\pi)\theta_2(1-\theta_2)&lt;/math&gt;

and {{nowrap|''p''&lt;sub&gt;2&lt;/sub&gt; {{=}} 1 − ''p''&lt;sub&gt;0&lt;/sub&gt; − ''p''&lt;sub&gt;1&lt;/sub&gt;}}. Clearly, given ''p''&lt;sub&gt;0&lt;/sub&gt; and ''p''&lt;sub&gt;1&lt;/sub&gt;, it is not possible to determine the above mixture model uniquely, as there are three parameters (''π'', ''θ''&lt;sub&gt;1&lt;/sub&gt;, ''θ''&lt;sub&gt;2&lt;/sub&gt;) to be determined.

=== Definition ===
Consider a mixture of parametric distributions of the same class. Let

:&lt;math&gt;J=\{f(\cdot ; \theta):\theta\in\Omega\}&lt;/math&gt;

be the class of all component distributions. Then the [[convex hull]] ''K'' of ''J'' defines the class of all finite mixture of distributions in ''J'':

:&lt;math&gt;K=\left\{p(\cdot):p(\cdot)=\sum_{i=1}^n a_i f_i(\cdot ; \theta_i), a_i&gt;0, \sum_{i=1}^n a_i=1, f_i(\cdot ; \theta_i)\in J\ \forall i,n\right\}&lt;/math&gt;

''K'' is said to be identifiable if all its members are unique, that is, given two members ''p'' and {{nowrap|''p′''}} in ''K'', being mixtures of ''k'' distributions and {{nowrap|''k′''}} distributions respectively in ''J'', we have {{nowrap|''p {{=}} p′''}} if and only if, first of all, {{nowrap|''k {{=}} k′''}} and secondly we can reorder the summations such that {{nowrap|''a&lt;sub&gt;i&lt;/sub&gt; {{=}} a&lt;sub&gt;i&lt;/sub&gt;''′}} and {{nowrap|''ƒ&lt;sub&gt;i&lt;/sub&gt; {{=}} ƒ&lt;sub&gt;i&lt;/sub&gt;''′}} for all ''i''.

== Parameter estimation and system identification ==

Parametric mixture models are often used when we know the distribution ''Y'' and we can sample from ''X'', but we would like to determine the ''a&lt;sub&gt;i&lt;/sub&gt;'' and ''θ&lt;sub&gt;i&lt;/sub&gt;'' values.  Such situations can arise in studies in which we sample from a population that is composed of several distinct subpopulations.

It is common to think of probability mixture modeling as a missing data problem.  One way to understand this is to assume that the data points under consideration have "membership" in one of the distributions we are using to model the data.  When we start, this membership is unknown, or missing.  The job of estimation is to devise appropriate parameters for the model functions we choose, with the connection to the data points being represented as their membership in the individual model distributions.

A variety of approaches to the problem of mixture decomposition have been proposed, many of which focus on maximum likelihood methods such as [[expectation maximization]] (EM) or maximum ''a posteriori'' estimation (MAP).  Generally these methods consider separately the questions of system identification and parameter estimation; methods to determine the number and functional form of components within a mixture are distinguished from methods to estimate the corresponding parameter values.  Some notable departures are the graphical methods as outlined in Tarter and Lock&lt;ref name=tart&gt;{{citation 
|title=Model Free Curve Estimation
|first=Michael E. |last=Tarter
|date=1993
|publisher=Chapman and Hall
}}&lt;/ref&gt; and more recently [[minimum message length]] (MML) techniques such as Figueiredo and Jain&lt;ref name=Jain&gt;{{cite journal |first1=M.A.T. |last1=Figueiredo |first2=A.K. |last2=Jain |title=Unsupervised Learning of Finite Mixture Models |journal=IEEE Transactions on Pattern Analysis and Machine Intelligence |volume=24 |issue=3 |pages=381–396 |date=March 2002 |doi=10.1109/34.990138 |citeseerx=10.1.1.362.9811 }}&lt;/ref&gt; and to some extent the moment matching pattern analysis routines suggested by McWilliam and Loh (2009).&lt;ref name=mcwilli&gt;
{{citation 
|title=Incorporating Multidimensional Tail-Dependencies in the Valuation of Credit Derivatives (Working Paper)
| first1 = N. | last1 = McWilliam | first2 = K. | last2 = Loh
|date = 2008
}} [http://www.misys.com/cds-portlets/digitalAssets/4/2797_CDsAndTailDep_forPublication_final1.pdf]&lt;/ref&gt;

=== Expectation maximization (EM) === &lt;!-- Linked from [[Expectation-maximization algorithm]] --&gt;

[[Expectation-maximization algorithm|Expectation maximization]] (EM) is seemingly the most popular technique used to determine the parameters of a mixture with an ''a priori'' given number of components. This is a particular way of implementing [[maximum likelihood]] estimation for this problem. EM is of particular appeal for finite normal mixtures where closed-form expressions are possible such as in the following iterative algorithm by Dempster ''et al.'' (1977)&lt;ref name=dempster1977&gt;{{cite journal |first1=A.P. |last1=Dempster |first2=N.M. |last2=Laird |first3=D.B. |last3=Rubin |title=Maximum Likelihood from Incomplete Data via the EM Algorithm |journal=Journal of the Royal Statistical Society, Series B |volume=39 |issue=1 |pages=1–38 | date = 1977 |jstor=2984875 |citeseerx = 10.1.1.163.7580 }}
&lt;/ref&gt;

:&lt;math&gt; w_s^{(j+1)} = \frac{1}{N} \sum_{t =1}^N h_s^{(j)}(t) &lt;/math&gt;
:&lt;math&gt; \mu_s^{(j+1)}  =  \frac{\sum_{t =1}^N h_s^{(j)}(t) x^{(t)}}{\sum_{t =1}^N h_s^{(j)}(t)} &lt;/math&gt;
:&lt;math&gt; \Sigma_s^{(j+1)}  =  \frac{\sum_{t =1}^N h_s^{(j)}(t) [x^{(t)}-\mu_s^{(j+1)}][x^{(t)}-\mu_s^{(j+1)}]^{\top}}{\sum_{t =1}^N h_s^{(j)}(t)} &lt;/math&gt;
with the posterior probabilities
:&lt;math&gt; h_s^{(j)}(t) = \frac{w_s^{(j)} p_s(x^{(t)}; \mu_s^{(j)},\Sigma_s^{(j)}) }{ \sum_{i = 1}^n w_i^{(j)} p_i(x^{(t)}; \mu_i^{(j)}, \Sigma_i^{(j)})}. &lt;/math&gt;

Thus on the basis of the current estimate for the parameters, the [[conditional probability]] for a given observation ''x''&lt;sup&gt;(''t'')&lt;/sup&gt; being generated from state ''s'' is determined for each {{nowrap|''t'' {{=}} 1, …, ''N''}} ; ''N'' being the sample size.  The parameters are then updated such that the new component weights correspond to the average conditional probability and each component mean and covariance is the component specific weighted average of the mean and covariance of the entire sample.

Dempster&lt;ref name="dempster1977"/&gt; also showed that each successive EM iteration will not decrease the likelihood, a property not shared by other gradient based maximization techniques.  Moreover, EM naturally embeds within it constraints on the probability vector, and for sufficiently large sample sizes positive definiteness of the covariance iterates.  This is a key advantage since explicitly constrained methods incur extra computational costs to check and maintain appropriate values. Theoretically EM is a first-order algorithm and as such converges slowly to a fixed-point solution. Redner and Walker (1984){{full citation needed|date=November 2012}} make this point arguing in favour of superlinear and second order Newton and quasi-Newton methods and reporting slow convergence in EM on the basis of their empirical tests.  They do concede that convergence in likelihood was rapid even if convergence in the parameter values themselves was not.  The relative merits of EM and other algorithms vis-à-vis convergence have been discussed in other literature.&lt;ref name=XuJordam&gt;{{cite journal |first1=L. |last1=Xu |first2=M.I. |last2=Jordan |title=On Convergence Properties of the EM Algorithm for Gaussian Mixtures |journal=Neural Computation |volume=8 |issue=1 |pages=129–151 |date=January 1996 |doi=10.1162/neco.1996.8.1.129 |hdl=10338.dmlcz/135225 |s2cid=207714252 |hdl-access=free }}&lt;/ref&gt;

Other common objections to the use of EM are that it has a propensity to spuriously identify local maxima, as well as displaying sensitivity to initial values.&lt;ref name="McLachlan_2"/&gt;&lt;ref name="botev2004global"&gt;{{Cite book |author1=Botev, Z.I. |author2=Kroese, D.P. |author-link2=Dirk Kroese|title=Global likelihood optimization via the cross-entropy method with an application to mixture models
|journal=[[Proceedings of the 2004 Winter Simulation Conference]] |volume= 1 |pages=517 |year=2004 |doi=10.1109/WSC.2004.1371358|isbn=978-0-7803-8786-7 |citeseerx=10.1.1.331.2319 |s2cid=6880171 }}&lt;/ref&gt; One may address these problems by evaluating EM at several initial points in the parameter space but this is computationally costly and other approaches, such as the annealing EM method of Udea and Nakano (1998) (in which the initial components are essentially forced to overlap, providing a less heterogeneous basis for initial guesses), may be preferable.

Figueiredo and Jain&lt;ref name="Jain" /&gt; note that convergence to 'meaningless' parameter values obtained at the boundary (where regularity conditions breakdown, e.g., Ghosh and Sen (1985)) is frequently observed when the number of model components exceeds the optimal/true one.  On this basis they suggest a unified approach to estimation and identification in which the initial ''n'' is chosen to greatly exceed the expected optimal value.  Their optimization routine is constructed via a minimum message length (MML) criterion that effectively eliminates a candidate component if there is insufficient information to support it. In this way it is possible to systematize reductions in ''n'' and consider estimation and identification jointly.

The [[Expectation-maximization algorithm]] can be used to compute the parameters of a parametric mixture model distribution (the ''a&lt;sub&gt;i&lt;/sub&gt;'' and ''θ&lt;sub&gt;i&lt;/sub&gt;'').  It is an [[iterative algorithm]] with two steps: an ''expectation step'' and a ''maximization step''. [http://wiki.stat.ucla.edu/socr/index.php/SOCR_EduMaterials_Activities_2D_PointSegmentation_EM_Mixture Practical examples of EM and Mixture Modeling] are included in the [[SOCR]] demonstrations.

==== The expectation step ====
With initial guesses for the parameters of our mixture model, "partial membership" of each data point in each constituent distribution is computed by calculating [[expectation value]]s for the membership variables of each data point.  That is, for each data point ''x&lt;sub&gt;j&lt;/sub&gt;'' and distribution ''Y&lt;sub&gt;i&lt;/sub&gt;'', the membership value ''y''&lt;sub&gt;''i'', ''j''&lt;/sub&gt; is:

:&lt;math&gt; y_{i,j} = \frac{a_i f_Y(x_j;\theta_i)}{f_{X}(x_j)}.&lt;/math&gt;

==== The maximization step ====
With expectation values in hand for group membership, [[plug-in estimates]] are recomputed for the distribution parameters.

The mixing coefficients ''a&lt;sub&gt;i&lt;/sub&gt;'' are the [[arithmetic mean|mean]]s of the membership values over the ''N'' data points.

:&lt;math&gt; a_i = \frac{1}{N}\sum_{j=1}^N y_{i,j}&lt;/math&gt;

The component model parameters ''θ&lt;sub&gt;i&lt;/sub&gt;'' are also calculated by expectation maximization using data points ''x&lt;sub&gt;j&lt;/sub&gt;'' that have been weighted using the membership values.  For example, if ''θ'' is a mean ''μ''

:&lt;math&gt; \mu_{i} = \frac{\sum_{j} y_{i,j}x_{j}}{\sum_{j} y_{i,j}}.&lt;/math&gt;

With new estimates for ''a&lt;sub&gt;i&lt;/sub&gt;'' and the ''θ&lt;sub&gt;i&lt;/sub&gt;'''s, the expectation step is repeated to recompute new membership values.  The entire procedure is repeated until model parameters converge.

=== Markov chain Monte Carlo ===
As an alternative to the EM algorithm, the mixture model parameters can be deduced using [[posterior sampling]] as indicated by [[Bayes' theorem]].  This is still regarded as an incomplete data problem whereby membership of data points is the missing data.  A two-step iterative procedure known as [[Gibbs sampling]] can be used.

The previous example of a mixture of two [[Gaussian distribution]]s can demonstrate how the method works.  As before, initial guesses of the parameters for the mixture model are made.  Instead of computing partial memberships for each elemental distribution, a membership value for each data point is drawn from a [[Bernoulli distribution]] (that is, it will be assigned to either the first or the second Gaussian).  The Bernoulli parameter ''θ'' is determined for each data point on the basis of one of the constituent distributions.{{Vague|What does this mean?|date=March 2008}}  Draws from the distribution generate membership associations for each data point.  Plug-in estimators can then be used as in the M step of EM to generate a new set of mixture model parameters, and the binomial draw step repeated.

=== Moment matching ===
The [[Method of moments (statistics)|method of moment matching]] is one of the oldest techniques for determining the mixture parameters dating back to Karl Pearson's seminal work of 1894.
In this approach the parameters of the mixture are determined such that the composite distribution has moments matching some given value.  In many instances extraction of solutions to the moment equations may present non-trivial algebraic or computational problems.  Moreover, numerical analysis by Day&lt;ref name=day&gt;{{Cite journal | last1 = Day | first1 = N. E. | title = Estimating the Components of a Mixture of Normal Distributions | journal = Biometrika | volume = 56 | issue = 3 | pages = 463–474 | doi = 10.2307/2334652 | jstor = 2334652| year = 1969 }}&lt;/ref&gt; has indicated that such methods may be inefficient compared to EM. Nonetheless there has been renewed interest in this method, e.g., Craigmile and Titterington (1998) and Wang.&lt;ref name=wang&gt;{{citation 
|title=Generating daily changes in market variables using a multivariate mixture of normal distributions
|first = J. | last = Wang
|date = 2001
|journal = Proceedings of the 33rd Winter Conference on Simulation |pages   =283–289
}}&lt;/ref&gt;

McWilliam and Loh (2009) consider the characterisation of a hyper-cuboid normal mixture [[copula (statistics)|copula]] in large dimensional systems for which EM would be computationally prohibitive.  Here a pattern analysis routine is used to generate multivariate tail-dependencies consistent with a set of univariate and (in some sense) bivariate moments.  The performance of this method is then evaluated using equity log-return data with [[Kolmogorov–Smirnov]] test statistics suggesting a good descriptive fit.

===Spectral method===
Some problems in mixture model estimation can be solved using [[spectral method]]s.
In particular it becomes useful if data points ''x&lt;sub&gt;i&lt;/sub&gt;'' are points in high-dimensional [[real coordinate space|real space]], and the hidden distributions are known to be [[Logarithmically concave function|log-concave]] (such as [[Gaussian distribution]] or [[Exponential distribution]]).

Spectral methods of learning mixture models are based on the use of [[Singular Value Decomposition]] of a matrix which contains data points.
The idea is to consider the top ''k'' singular vectors, where ''k'' is the number of distributions to be learned. The projection
of each data point to a [[linear subspace]] spanned by those vectors groups points originating from the same distribution
very close together, while points from different distributions stay far apart.

One distinctive feature of the spectral method is that it allows us to [[Mathematical proof|prove]] that if
distributions satisfy certain separation condition (e.g., not too close), then the estimated mixture will be very close to the true one with high probability.

=== Graphical Methods ===

Tarter and Lock&lt;ref name="tart" /&gt; describe a graphical approach to mixture identification in which a kernel function is applied to an empirical frequency plot so to reduce intra-component variance.  In this way one may more readily identify components having differing means.  While this ''λ''-method does not require prior knowledge of the number or functional form of the components its success does rely on the choice of the kernel parameters which to some extent implicitly embeds assumptions about the component structure.

=== Other methods ===

Some of them can even probably learn mixtures of [[heavy-tailed distribution]]s including those with
infinite [[variance]] (see [[#Recent Papers|links to papers]] below).
In this setting, EM based methods would not work, since the Expectation step would diverge due to presence of
[[outlier]]s.

=== A simulation ===
To simulate a sample of size ''N'' that is from a mixture of distributions ''F''&lt;sub&gt;''i''&lt;/sub&gt;, ''i''=1 to ''n'', with probabilities ''p''&lt;sub&gt;''i''&lt;/sub&gt; (sum=&amp;nbsp;''p''&lt;sub&gt;''i''&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;1):
# Generate ''N'' random numbers from a [[categorical distribution]] of size ''n'' and probabilities ''p''&lt;sub&gt;''i''&lt;/sub&gt; for ''i''=&amp;nbsp;1=&amp;nbsp;to&amp;nbsp;''n''.  These tell you which of the ''F''&lt;sub&gt;''i''&lt;/sub&gt; each of the ''N'' values will come from.  Denote by ''m&lt;sub&gt;i&lt;/sub&gt;'' the quantity of random numbers assigned to the ''i''&lt;sup&gt;th&lt;/sup&gt; category.
# For each ''i'', generate ''m&lt;sub&gt;i&lt;/sub&gt;'' random numbers from the ''F''&lt;sub&gt;''i''&lt;/sub&gt; distribution.

== Extensions ==
In a [[Bayesian inference|Bayesian setting]], additional levels can be added to the [[graphical model]] defining the mixture model.  For example, in the common [[latent Dirichlet allocation]] [[topic model]], the observations are sets of words drawn from ''D'' different documents and the ''K'' mixture components represent topics that are shared across documents.  Each document has a different set of mixture weights, which specify the topics prevalent in that document.  All sets of mixture weights share common [[hyperparameter]]s.

A very common extension is to connect the [[latent variable]]s defining the mixture component identities into a [[Markov chain]], instead of assuming that they are [[independent identically distributed]] random variables.  The resulting model is termed a [[hidden Markov model]] and is one of the most common sequential hierarchical models.  Numerous extensions of hidden Markov models have been developed; see the resulting article for more information.

== History ==
Mixture distributions and the problem of mixture decomposition, that is the identification of its constituent components and the parameters thereof, has been cited in the literature as far back as 1846 (Quetelet in McLachlan, &lt;ref name=McLachlan_2&gt;{{citation 
|title=Finite Mixture Models
|first=G.J. |last=McLachlan
|publisher=Wiley
|date=2000
}}&lt;/ref&gt; 2000) although common reference is made to the work of [[Karl Pearson]] (1894)&lt;ref name=Amendola2015&gt;{{Cite journal |last=Améndola |first=Carlos |display-authors=etal |arxiv=1510.04654 |year=2015 |title=Moment varieties of Gaussian mixtures|doi=10.18409/jas.v7i1.42 |volume=7 |journal=Journal of Algebraic Statistics|bibcode=2015arXiv151004654A |s2cid=88515304 }}&lt;/ref&gt; as the first author to explicitly address the decomposition problem in characterising non-normal attributes of forehead to body length ratios in female shore crab populations.  The motivation for this work was provided by the zoologist [[Walter Frank Raphael Weldon]] who had speculated in 1893 (in Tarter and Lock&lt;ref name="tart" /&gt;) that asymmetry in the histogram of these ratios could signal evolutionary divergence. Pearson's approach was to fit a univariate mixture of two normals to the data by choosing the five parameters of the mixture such that the empirical moments matched that of the model.

While his work was successful in identifying two potentially distinct sub-populations and in demonstrating the flexibility of mixtures as a moment matching tool, the formulation required the solution of a 9th degree (nonic) polynomial which at the time posed a significant computational challenge.

Subsequent works focused on addressing these problems, but it was not until the advent of the modern computer and the popularisation of [[Maximum Likelihood]] (MLE) parameterisation techniques that research really took off.&lt;ref name=McLachlan_1&gt;{{citation 
|title=Mixture Models: inference and applications to clustering
|journal=Statistics: Textbooks and Monographs |first1=G.J. |last1=McLachlan |first2=K.E. |last2=Basford
|date=1988
|bibcode=1988mmia.book.....M }}&lt;/ref&gt; Since that time there has been a vast body of research on the subject spanning areas such as [[Fishery|fisheries research]], [[agriculture]], [[botany]], [[economics]], [[medicine]], [[genetics]], [[psychology]], [[palaeontology]], [[electrophoresis]], [[finance]], [[geology]] and [[zoology]].&lt;ref name=titter_1&gt;{{harvnb|Titterington|Smith|Makov|1985}}&lt;/ref&gt;

== See also ==

=== Mixture ===
* [[Mixture density]]
* [[Mixture (probability)]]
* [[Flexible Mixture Model (FMM)]]

=== Hierarchical models ===
* [[Graphical model]]
* [[Hierarchical Bayes model]]

=== Outlier detection ===
* [[RANSAC]]

== References ==
{{Reflist}}

== Further reading ==

=== Books on mixture models ===
*{{cite book |last1=Everitt |first1=B.S. |last2=Hand |first2=D.J. |title=Finite mixture distributions |publisher=Chapman &amp; Hall |date=1981 |isbn=978-0-412-22420-1 }}
*{{cite book | last = Lindsay | first = B. G. | author-link=Bruce G. Lindsay |date = 1995 | title = Mixture Models: Theory, Geometry, and Applications | series = NSF-CBMS Regional Conference Series in Probability and Statistics | volume = 5 | publisher = Institute of Mathematical Statistics | location = Hayward }}
*{{cite book |last1=Marin |first1=J.M. |last2=Mengersen |first2=K.|author2-link= Kerrie Mengersen |last3=Robert |first3=C.P. |chapter=Bayesian modelling and inference on mixtures of distributions |chapter-url=http://www.ceremade.dauphine.fr/%7Exian/mixo.pdf |editor1-first=D. |editor1-last=Dey |editor2-first=C.R. |editor2-last=Rao |title=Essential Bayesian models |publisher=Elsevier |year=2011 |isbn=9780444537324 |series=Handbook of statistics: Bayesian thinking - modeling and computation |volume=25}}
*{{cite book |last1=McLachlan |first1=G.J. |last2=Peel |first2=D. |title=Finite Mixture Models |publisher=Wiley |year=2000 |isbn=978-0-471-00626-8 |url-access=registration |url=https://archive.org/details/finitemixturemod00geof }}
*{{Cite book | last1=Press | first1=WH | last2=Teukolsky | first2=SA | last3=Vetterling | first3=WT | last4=Flannery | first4=BP | year=2007 | title=Numerical Recipes: The Art of Scientific Computing | edition=3rd | publisher=Cambridge University Press |  location=New York | isbn=978-0-521-88068-8 | chapter=Section 16.1. Gaussian Mixture Models and k-Means Clustering | chapter-url=http://apps.nrbook.com/empanel/index.html#pg=842}}
*{{cite book |last1=Titterington |first1=D. |first2=A. |last2=Smith |first3=U. |last3=Makov |title=Statistical Analysis of Finite Mixture Distributions |publisher=Wiley |year=1985 |isbn=978-0-471-90763-3 }}

===Application of Gaussian mixture models===
#{{cite journal |first1=D.A. |last1=Reynolds |first2=R.C. |last2=Rose |title=Robust text-independent speaker identification using Gaussian mixture speaker models |journal=IEEE Transactions on Speech and Audio Processing |date=January 1995 |volume=3 |issue=1 |pages=72–83 |doi=10.1109/89.365379 }}
#{{cite conference |first1=H. |last1=Permuter |first2=J. |last2=Francos |first3=I.H. |last3=Jermyn |title=Gaussian mixture models of texture and colour for image database retrieval| conference=  IEEE [[International Conference on Acoustics, Speech, and Signal Processing]], 2003. Proceedings (ICASSP '03)| year=2003 |doi=10.1109/ICASSP.2003.1199538 }}
#*{{cite journal|doi=10.1016/j.patcog.2005.10.028|title=A study of Gaussian mixture models of color and texture features for image classification and segmentation|journal=Pattern Recognition|volume=39|issue=4|pages=695–706|year=2006|last1=Permuter|first1=Haim|last2=Francos|first2=Joseph|last3=Jermyn|first3=Ian|url=http://dro.dur.ac.uk/16022/1/16022.pdf}}
#{{cite book|first=Wolfgang|last=Lemke|date=2005|title=Term Structure Modeling and Estimation in a State Space Framework|publisher=Springer Verlag|isbn=978-3-540-28342-3}}
#{{cite conference | first1=Damiano|last1=Brigo|author-link1=Damiano Brigo|first2=Fabio|last2=Mercurio|author-link2=Fabio Mercurio|title=Displaced and Mixture Diffusions for Analytically-Tractable Smile Models| conference=  Mathematical Finance – Bachelier Congress 2000. Proceedings | date = 2001|publisher=Springer Verlag }}
#{{cite journal |first1=Damiano |last1=Brigo |first2=Fabio |last2=Mercurio |title=Lognormal-mixture dynamics and calibration to market volatility smiles |journal=International Journal of Theoretical and Applied Finance |volume=5 |issue=4 |page=427 |date=June 2002 |doi=10.1142/S0219024902001511 |citeseerx=10.1.1.210.4165 }}
#{{cite journal |first1=J. C. |last1=Spall |first2=J. L. |last2=Maryak |title=A feasible Bayesian estimator of quantiles for projectile accuracy from non-i.i.d. data|journal=Journal of the American Statistical Association |volume=87 |issue=419 |pages=676–681 |date=1992 |jstor=2290205 |doi=10.1080/01621459.1992.10475269}}
#{{cite journal |first1=Carol |last1=Alexander |title=Normal mixture diffusion with uncertain volatility: Modelling short- and long-term smile effects |journal=Journal of Banking &amp; Finance |volume=28 |issue=12 |pages=2957–80 |date=December 2004 |doi=10.1016/j.jbankfin.2003.10.017 |url=http://www.carolalexander.org/publish/download/JournalArticles/PDFs/JBF2004.pdf }}
#{{cite conference | first1 = Yannis | last1 = Stylianou | first2 = Yannis | last2 = Pantazis | first3 = Felipe | last3 = Calderero | first4 = Pedro | last4 = Larroy | first5 = Francois | last5 = Severin | first6 = Sascha | last6 = Schimke | first7 = Rolando | last7 = Bonal | first8 = Federico | last8 = Matta | first9 = Athanasios | last9 = Valsamakis |title=GMM-Based Multimodal Biometric Verification| date = 2005 |url=http://www.enterface.net/enterface05/docs/results/reports/project5.pdf}}
#{{cite conference |first1=J. |last1=Chen |first2=0.E. |last2=Adebomi |first3=O.S. |last3=Olusayo |first4=W. |last4=Kulesza |title=The Evaluation of the Gaussian Mixture Probability Hypothesis Density approach for multi-target tracking| conference=  IEEE [[International Conference on Imaging Systems and Techniques]], 2010.| year=2010 |doi=10.1109/IST.2010.5548541 }}

== External links ==
*{{Cite book |first1=Frank |last1=Nielsen |title=''k''-MLE: A fast algorithm for learning statistical mixture models |chapter=K-MLE: A fast algorithm for learning statistical mixture models |date=23 March 2012 |arxiv=1203.5181 |doi=10.1109/ICASSP.2012.6288022 |journal=2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)|pages=869–872 |isbn=978-1-4673-0046-9 |bibcode=2012arXiv1203.5181N |s2cid=935615 }}
* The [http://wiki.stat.ucla.edu/socr/index.php/SOCR_EduMaterials_Activities_2D_PointSegmentation_EM_Mixture SOCR demonstrations of EM and Mixture Modeling]
*[http://www.csse.monash.edu.au/~dld/mixturemodel.html Mixture modelling page] (and the [http://www.csse.monash.edu.au/~dld/Snob.html Snob] program for [[Minimum Message Length]] ([[Minimum Message Length|MML]]) applied to finite mixture models), maintained by D.L. Dowe.
*[http://www.pymix.org PyMix] – Python Mixture Package, algorithms and data structures for a broad variety of mixture model based data mining applications in Python
*[http://scikit-learn.org/stable/modules/mixture.html sklearn.mixture] – A Python package for learning Gaussian Mixture Models (and sampling from them), previously packaged with [[SciPy]] and now packaged as a [https://scikits.appspot.com/ SciKit]
*[http://www.mathworks.com/matlabcentral/fileexchange/loadFile.do?objectId=18785&amp;objectType=FILE GMM.m] Matlab code for GMM Implementation
*[http://stat.duke.edu/gpustatsci/software.html GPUmix] C++ implementation of Bayesian Mixture Models using EM and MCMC with 100x speed acceleration using GPGPU.
*[https://www.cs.ru.nl/~ali/index_files/EM.m] Matlab code for GMM Implementation using EM algorithm
*[https://vincentfpgarcia.github.com/jMEF/] jMEF: A Java open source library for learning and processing mixtures of exponential families (using duality with Bregman divergences). Includes a Matlab wrapper.
* Very Fast and clean C implementation of the [https://github.com/juandavm/em4gmm Expectation Maximization] (EM) algorithm for estimating [https://github.com/juandavm/em4gmm Gaussian Mixture Models] (GMMs).  
* [https://cran.r-project.org/web/packages/mclust/index.html mclust] is an R package for mixture modeling.
* [https://github.com/thaines/helit/tree/master/dpgmm dpgmm] Pure Python Dirichlet process Gaussian mixture model implementation (variational).
* [https://mpatacchiola.github.io/blog/2020/07/31/gaussian-mixture-models.html Gaussian Mixture Models] Blog post on Gaussian Mixture Models trained via Expectation Maximization, with an implementation in Python. 

{{DEFAULTSORT:Mixture Model}}
[[Category:Cluster analysis]]
[[Category:Latent variable models]]
[[Category:Probabilistic models]]
[[Category:Machine learning]]</text>
      <sha1>bod1sylh8lkvlxdpsx1mf7b9dy0vyf1</sha1>
    </revision>
  </page>
  <page>
    <title>Statistical classification</title>
    <ns>0</ns>
    <id>1579244</id>
    <revision>
      <id>991526277</id>
      <parentid>984514201</parentid>
      <timestamp>2020-11-30T14:53:25Z</timestamp>
      <contributor>
        <username>AllenDowney</username>
        <id>2108450</id>
      </contributor>
      <comment>/* Bayesian procedures */ Removing an unnecessary qualification -- these methods *do* provide more information; it is not a matter of "being viewed" as providing more information.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="15853" xml:space="preserve">{{for|the [[unsupervised learning]] approach|Cluster analysis}}
{{short description|Term in statistical learning}}
In [[statistics]], '''classification''' is the problem of identifying to which of a set of [[categorical data|categories]] (sub-populations) a new [[observation]] belongs, on the basis of a [[training set]] of data containing observations (or instances) whose category membership is known.  Examples are assigning a given email to the [[Spam filtering|"spam" or "non-spam"]] class, and assigning a diagnosis to a given patient based on observed characteristics of the patient (sex, blood pressure, presence or absence of certain symptoms, etc.).  Classification is an example of [[pattern recognition]].

In the terminology of machine learning,&lt;ref&gt;{{cite book|last=Alpaydin|first=Ethem|title=Introduction to Machine Learning|date=2010|publisher=MIT Press|isbn=978-0-262-01243-0|page=9|url=https://books.google.com/books?id=7f5bBAAAQBAJ&amp;q=classification}}&lt;/ref&gt; classification is considered an instance of [[supervised learning]], i.e., learning where a training set of correctly identified observations is available.  The corresponding [[unsupervised learning|unsupervised]] procedure is known as [[cluster analysis|clustering]], and involves grouping data into categories based on some measure of inherent similarity or [[distance]].

Often, the individual observations are analyzed into a set of quantifiable properties, known variously as [[explanatory variables]] or ''features''.  These properties may variously be [[categorical data|categorical]] (e.g. "A", "B", "AB" or "O", for [[blood type]]), [[ordinal data|ordinal]] (e.g. "large", "medium" or "small"), [[integer|integer-valued]] (e.g. the number of occurrences of a particular word in an [[email]]) or [[real number|real-valued]] (e.g. a measurement of [[blood pressure]]). Other classifiers work by comparing observations to previous observations by means of a [[similarity function|similarity]] or [[metric (mathematics)|distance]] function.

An [[algorithm]] that implements classification, especially in a concrete implementation, is known as a '''classifier'''.  The term "classifier" sometimes also refers to the mathematical [[function (mathematics)|function]], implemented by a classification algorithm, that maps input data to a category.

Terminology across fields is quite varied. In [[statistics]], where classification is often done with [[logistic regression]] or a similar procedure, the properties of observations are termed [[explanatory variable]]s (or [[independent variable]]s, regressors, etc.), and the categories to be predicted are known as outcomes, which are considered to be possible values of the [[dependent variable]].  In [[machine learning]], the observations are often known as ''instances'', the explanatory variables are termed ''features'' (grouped into a [[feature vector]]), and the possible categories to be predicted are ''classes''.  Other fields may use different terminology: e.g. in [[community ecology]], the term "classification" normally refers to [[cluster analysis]], i.e., a type of [[unsupervised learning]], rather than the supervised learning described in this article.

==Relation to other problems==
Classification and clustering are examples of the more general problem of [[pattern recognition]], which is the assignment of some sort of output value to a given input value.  Other examples are [[regression analysis|regression]], which assigns a real-valued output to each input; [[sequence labeling]], which assigns a class to each member of a sequence of values (for example, [[part of speech tagging]], which assigns a [[part of speech]] to each word in an input sentence); [[parsing]], which assigns a [[parse tree]] to an input sentence, describing the [[syntactic structure]] of the sentence; etc.

A common subclass of classification is [[probabilistic classification]].  Algorithms of this nature use [[statistical inference]] to find the best class for a given instance.  Unlike other algorithms, which simply output a "best" class, probabilistic algorithms output a [[probability]] of the instance being a member of each of the possible classes.  The best class is normally then selected as the one with the highest probability.  However, such an algorithm has numerous advantages over non-probabilistic classifiers:
*It can output a confidence value associated with its choice (in general, a classifier that can do this is known as a ''confidence-weighted classifier'').
*Correspondingly, it can ''abstain'' when its confidence of choosing any particular output is too low.
*Because of the probabilities which are generated, probabilistic classifiers can be more effectively incorporated into larger machine-learning tasks, in a way that partially or completely avoids the problem of ''error propagation''.

==Frequentist procedures==

Early work on statistical classification was undertaken by [[Ronald Fisher|Fisher]],&lt;ref&gt;{{Cite journal |doi = 10.1111/j.1469-1809.1936.tb02137.x|title = The Use of Multiple Measurements in Taxonomic Problems|year = 1936|last1 = Fisher|first1 = R. A.|journal = [[Annals of Eugenics]]|volume = 7|issue = 2|pages = 179–188|hdl = 2440/15227|hdl-access = free}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |doi = 10.1111/j.1469-1809.1938.tb02189.x|title = The Statistical Utilization of Multiple Measurements|year = 1938|last1 = Fisher|first1 = R. A.|journal = [[Annals of Eugenics]]|volume = 8|issue = 4|pages = 376–386|hdl = 2440/15232|hdl-access = free}}&lt;/ref&gt; in the context of two-group problems, leading to [[Fisher's linear discriminant]] function as the rule for assigning a group to a new observation.&lt;ref name=G1977&gt;Gnanadesikan, R. (1977) ''Methods for Statistical Data Analysis of Multivariate Observations'', Wiley. {{ISBN|0-471-30845-5}} (p. 83&amp;ndash;86)&lt;/ref&gt; This early work assumed that data-values within each of the two groups had a [[multivariate normal distribution]]. The extension of this same context to more than two-groups has also been considered with a restriction imposed that the classification rule should be [[linear]].&lt;ref name=G1977/&gt;&lt;ref&gt;[[C. R. Rao|Rao, C.R.]] (1952) ''Advanced Statistical Methods in Multivariate Analysis'', Wiley. (Section 9c)&lt;/ref&gt; Later work for the multivariate normal distribution allowed the classifier to be [[nonlinear]]:&lt;ref&gt;[[T. W. Anderson|Anderson, T.W.]] (1958) ''An Introduction to Multivariate Statistical Analysis'', Wiley.&lt;/ref&gt; several classification rules can be derived based on different adjustments of the [[Mahalanobis distance]], with a new observation being assigned to the group whose centre has the lowest adjusted distance from the observation.

==Bayesian procedures==

Unlike frequentist procedures, Bayesian classification procedures provide a natural way of taking into account any available information about the relative sizes of the different groups within the overall population.&lt;ref&gt;{{Cite journal |doi = 10.1093/biomet/65.1.31|title = Bayesian cluster analysis|year = 1978|last1 = Binder|first1 = D. A.|journal = [[Biometrika]]|volume = 65|pages = 31–38}}&lt;/ref&gt; Bayesian procedures tend to be computationally expensive and, in the days before [[Markov chain Monte Carlo]] computations were developed, approximations for Bayesian clustering rules were devised.&lt;ref&gt;{{Cite journal | doi=10.1093/biomet/68.1.275| title=Approximations to Bayesian clustering rules| year=1981| last1=Binder| first1=David A.| journal=[[Biometrika]]| volume=68| pages=275–285}}&lt;/ref&gt;

Some Bayesian procedures involve the calculation of  [[class membership probabilities|group membership probabilities]]: these provide a more informative outcome than a simple attribution of a single group-label to each new observation.

==Binary and multiclass classification==
Classification can be thought of as two separate problems – [[binary classification]] and [[multiclass classification]]. In binary classification, a better understood task, only two classes are involved, whereas multiclass classification involves assigning an object to one of several classes.&lt;ref&gt;[[Sariel Har-Peled|Har-Peled, S.]], Roth, D., Zimak, D. (2003) "Constraint Classification for Multiclass Classification and Ranking." In: Becker, B., [[Sebastian Thrun|Thrun, S.]], Obermayer, K. (Eds) ''Advances in Neural Information Processing Systems 15: Proceedings of the 2002 Conference'', MIT Press. {{ISBN|0-262-02550-7}}&lt;/ref&gt; Since many classification methods have been developed specifically for binary classification, multiclass classification often requires the combined use of multiple binary classifiers.

== Feature vectors ==
Most algorithms describe an individual instance whose category is to be predicted using a [[feature vector]] of individual, measurable properties of the instance.  Each property is termed a [[feature (pattern recognition)|feature]], also known in statistics as an [[explanatory variable]] (or [[independent variable]], although features may or may not be [[statistically independent]]).  Features may variously be [[binary data|binary]] (e.g. "on" or "off"); [[categorical data|categorical]] (e.g. "A", "B", "AB" or "O", for [[blood type]]); [[ordinal data|ordinal]] (e.g. "large", "medium" or "small"); [[integer|integer-valued]] (e.g. the number of occurrences of a particular word in an email); or [[real number|real-valued]] (e.g. a measurement of blood pressure).  If the instance is an image, the feature values might correspond to the pixels of an image; if the instance is a piece of text, the feature values might be occurrence frequencies of different words.  Some algorithms work only in terms of discrete data and require that real-valued or integer-valued data be ''discretized'' into groups (e.g. less than 5, between 5 and 10, or greater than 10).

== Linear classifiers ==
{{main|Linear classifier}}
A large number of [[algorithm]]s for classification can be phrased in terms of a [[linear function]] that assigns a score to each possible category ''k'' by [[linear combination|combining]] the feature vector of an instance with a vector of weights, using a [[dot product]].  The predicted category is the one with the highest score.  This type of score function is known as a [[linear predictor function]] and has the following general form:

:&lt;math&gt;\operatorname{score}(\mathbf{X}_i,k) = \boldsymbol\beta_k \cdot \mathbf{X}_i,&lt;/math&gt;

where '''X'''&lt;sub&gt;''i''&lt;/sub&gt; is the feature vector for instance ''i'', '''&amp;beta;'''&lt;sub&gt;''k''&lt;/sub&gt; is the vector of weights corresponding to category ''k'', and score('''X'''&lt;sub&gt;''i''&lt;/sub&gt;, ''k'') is the score associated with assigning instance ''i'' to category ''k''.  In [[discrete choice]] theory, where instances represent people and categories represent choices, the score is considered the [[utility]] associated with person ''i'' choosing category ''k''.

Algorithms with this basic setup are known as [[linear classifier]]s.  What distinguishes them is the procedure for determining (training) the optimal weights/coefficients and the way that the score is interpreted.

Examples of such algorithms are
*[[Logistic regression]] and [[Multinomial logistic regression]]
*[[Probit regression]]
*The [[perceptron]] algorithm
*[[Support vector machine]]s
*[[Linear discriminant analysis]].

== Algorithms ==

In [[unsupervised learning]], classifiers form the backbone of cluster analysis and in [[Supervised learning|supervised]] or semi-supervised learning, classifiers are how the system characterizes and evaluates unlabeled data. In all cases though, classifiers have a specific set of dynamic rules, which includes an interpretation procedure to handle vague or unknown values, all tailored to the type of inputs being examined.&lt;ref&gt;{{Cite web|url=https://deepai.org/machine-learning-glossary-and-terms/classifier|title=What is a Classifier in Machine Learning?}}&lt;/ref&gt;

Since no single form of classification is appropriate for all data sets, a large toolkit of classification algorithms have been developed. The most commonly used include:&lt;ref&gt;{{Cite news|url=https://builtin.com/data-science/tour-top-10-algorithms-machine-learning-newbies|title=A Tour of The Top 10 Algorithms for Machine Learning Newbies|date=2018-01-20|work=Built In|access-date=2019-06-10}}&lt;/ref&gt;

* [[Linear classifier]]s
** [[Fisher's linear discriminant]]
** [[Logistic regression]]
** [[Naive Bayes classifier]]
** [[Perceptron]]
*[[Support vector machine]]s
**[[Least squares support vector machine]]s
* [[Quadratic classifier]]s
* [[Variable kernel density estimation#Use for statistical classification|Kernel estimation]]
** [[k-nearest neighbor algorithm|k-nearest neighbor]]
* [[Boosting (meta-algorithm)]]
* [[Decision tree learning|Decision tree]]s
** [[Random forest]]s
* [[Artificial neural networks|Neural network]]s
* [[Learning vector quantization]]

== Evaluation ==
Classifier performance depends greatly on the characteristics of the data to be classified. There is no single classifier that works best on all given problems (a phenomenon that may be explained by the [[No free lunch in search and optimization|no-free-lunch theorem]]). Various empirical tests have been performed to compare classifier performance and to find the characteristics of data that determine classifier performance. Determining a suitable classifier for a given problem is however still more an art than a science.

The measures [[precision and recall]] are popular metrics used to evaluate the quality of a classification system. More recently, [[receiver operating characteristic]] (ROC) curves have been used to evaluate the tradeoff between true- and false-positive rates of classification algorithms.

As a performance metric, the [[uncertainty coefficient]] has the advantage over simple [[accuracy]] in that it is not affected by the relative sizes of the different classes.
&lt;ref name="Mills2010"&gt;
{{Cite journal
 | author = Peter Mills
 | title = Efficient statistical classification of satellite measurements
 | journal = [[International Journal of Remote Sensing]]
 | volume = 32
 | issue = 21
 | pages = 6109–6132
 | doi= 10.1080/01431161.2010.507795
 | year = 2011
| arxiv = 1202.2194
 | bibcode = 2011IJRS...32.6109M
 | s2cid = 88518570
 }}&lt;/ref&gt;
Further, it will not penalize an algorithm for simply ''rearranging'' the classes.

==Application domains==
{{see also|Cluster analysis#Applications}}
Classification has many applications. In some of these it is employed as a [[data mining]] procedure, while in others more detailed statistical modeling is undertaken.

* [[Computer vision]]
** [[Medical imaging]] and medical image analysis
** [[Optical character recognition]]
** [[Video tracking]]
* [[Drug discovery]] and [[Drug development|development]]
** [[Toxicogenomics]]
** [[Quantitative structure-activity relationship]]
* [[Geostatistics]]
* [[Speech recognition]]
* [[Handwriting recognition]]
* [[Biometric]] identification
*[[Biological classification]]
* [[Statistical natural language processing]]
* [[Document classification]]
* Internet [[search engines]]
* [[Credit scoring]]
* [[Pattern recognition]]
* [[Recommender system]]
*Micro-array classification

{{More footnotes|date=January 2010}}

== See also ==
{{Commons category}}
{{Portal|Mathematics}}
{{colbegin}}
* [[Artificial intelligence]]
* [[Binary classification]]
* [[Class membership probabilities]]
* [[Classification rule]]
* [[Compound term processing]]
* [[Data mining]]
* [[Data warehouse]]
* [[Fuzzy logic]]
* [[Information retrieval]]
* [[List of datasets for machine learning research]]
* [[Machine learning]]
* [[Recommender system]]
{{colend}}

==References==
{{Reflist}}

{{Statistics|analysis||state=expanded}}

{{DEFAULTSORT:Statistical Classification}}
[[Category:Statistical classification| ]]
[[Category:Machine learning]]
[[Category:Classification algorithms|*]]</text>
      <sha1>nmjuuzefh0wznl3tfwb8yzyuqankaig</sha1>
    </revision>
  </page>
  <page>
    <title>Apprenticeship learning</title>
    <ns>0</ns>
    <id>19463198</id>
    <revision>
      <id>1000636126</id>
      <parentid>1000181250</parentid>
      <timestamp>2021-01-16T00:39:25Z</timestamp>
      <contributor>
        <username>MrOllie</username>
        <id>6908984</id>
      </contributor>
      <comment>rm coi / selfcite</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="10836" xml:space="preserve">{{about|machine learning via observation of human experts|human learning|Apprenticeship}}

In [[artificial intelligence]], '''apprenticeship learning''' (or '''learning from demonstration''') is the process of learning by observing an expert.&lt;ref name=AIRP&gt;[http://dl.acm.org/citation.cfm?id=1015430 [[Pieter Abbeel]], Andrew Ng, “Apprenticeship learning via inverse reinforcement learning.” In 21st International Conference on Machine Learning (ICML). 2004.]&lt;/ref&gt;&lt;ref name=survey&gt;{{cite journal|last1=Argall|first1=Brenna D.|last2=Chernova|first2=Sonia|last3=Veloso|first3=Manuela|last4=Browning|first4=Brett|title=A survey of robot learning from demonstration|journal=Robotics and Autonomous Systems|date=May 2009|volume=57|issue=5|pages=469–483|doi=10.1016/j.robot.2008.10.024|citeseerx=10.1.1.145.345}}&lt;/ref&gt;  It can be viewed as a form of [[supervised learning]], where the training dataset consists of task executions by a demonstration teacher.&lt;ref name=survey/&gt;

==Mapping function approach==
Mapping methods try to mimic the expert by forming a direct mapping either from states to actions,&lt;ref name=survey/&gt; or from states to reward values.&lt;ref name=AIRP/&gt; For example, in 2002 researchers used such an approach to teach an AIBO robot basic soccer skills.&lt;ref name=survey/&gt;

===Inverse reinforcement learning approach===
'''Inverse reinforcement learning''' (IRL) is the process of deriving a reward function from observed behavior. While ordinary "reinforcement learning" involves using rewards and punishments to learn behavior, in IRL the direction is reversed, and a robot observes a person's behavior to figure out what goal that behavior seems to be trying to achieve.&lt;ref&gt;{{cite news|last1=Wolchover|first1=Natalie|title=This Artificial Intelligence Pioneer Has a Few Concerns|url=https://www.wired.com/2015/05/artificial-intelligence-pioneer-concerns/|access-date=22 January 2018|work=WIRED}}&lt;/ref&gt; The IRL problem can be defined as:&lt;ref name="russell1998learning" /&gt;

&lt;blockquote&gt;Given 1) measurements of an agent's behaviour over time, in a variety of circumstances; 2) measurements of the sensory inputs to that agent; 3) a model of the physical environment (including the agent's body): Determine the reward function that the agent is optimizing.&lt;/blockquote&gt;

IRL researcher [[Stuart J. Russell]] proposes that IRL might be used to observe humans and attempt to codify their complex "ethical values", in an effort to create "ethical robots" that might someday know "not to cook your cat" without needing to be explicitly told.&lt;ref&gt;{{cite news|last1=Havens|first1=John C.|title=The ethics of AI: how to stop your robot cooking your cat|url=https://www.theguardian.com/sustainable-business/2015/jun/23/the-ethics-of-ai-how-to-stop-your-robot-cooking-your-cat|access-date=22 January 2018|work=the Guardian|date=23 June 2015}}&lt;/ref&gt; The scenario can be modeled as a "cooperative inverse reinforcement learning game", where a "person" player and a "robot" player cooperate to secure the person's implicit goals, despite these goals not being explicitly known by either the person nor the robot.&lt;ref&gt;{{cite news|title=Artificial Intelligence And The King Midas Problem|url=https://www.huffingtonpost.com/entry/artificial-intelligence-and-the-king-midas-problem_us_5847198ae4b05236f110601b|access-date=22 January 2018|work=Huffington Post|date=12 December 2016}}&lt;/ref&gt;&lt;ref&gt;Hadfield-Menell, D., Russell, S. J., Abbeel, Pieter &amp; Dragan, A. (2016). Cooperative inverse reinforcement learning. In Advances in neural information processing systems (pp. 3909-3917).&lt;/ref&gt;

In 2017, [[OpenAI]] and [[DeepMind]] applied [[deep learning]] to the cooperative inverse reinforcement learning in simple domains such as Atari games and straightforward robot tasks such as backflips. The human role was limited to answering queries from the robot as to which of two different actions were preferred. The researchers found evidence that the techniques may be economically scalable to modern systems.&lt;ref&gt;{{cite news|title=Two Giants of AI Team Up to Head Off the Robot Apocalypse|url=https://www.wired.com/story/two-giants-of-ai-team-up-to-head-off-the-robot-apocalypse/|access-date=29 January 2018|work=WIRED|date=7 July 2017}}&lt;/ref&gt;&lt;ref&gt;Christiano, P. F., Leike, J., Brown, T., Martic, M., Legg, S., &amp; Amodei, D. (2017). Deep reinforcement learning from human preferences. In Advances in Neural Information Processing Systems (pp. 4302-4310).&lt;/ref&gt;

'''Apprenticeship via inverse reinforcement learning''' (AIRP) was developed by in 2004 [[Pieter Abbeel]], Professor in [[University of California, Berkeley|Berkeley]]'s [[Electrical engineering|EE]][[Computer science|CS]] department, and [[Andrew Ng]], Associate Professor in [[Stanford University]]'s Computer Science Department. AIRP deals with "[[Markov decision process]] where we are not explicitly given a reward function, but where instead we can observe an expert demonstrating the task that we want to learn to perform".&lt;ref name=AIRP/&gt; AIRP has been used to model reward functions of highly dynamic scenarios where there is no obvious reward function intuitively. Take the task of driving for example, there are many different objectives working simultaneously - such as maintaining safe following distance, a good speed, not changing lanes too often, etc. This task, may seem easy at first glance, but a trivial reward function may not converge to the policy wanted.

One domain where AIRP has been used extensively is helicopter control. While simple trajectories can be intuitively derived, complicated tasks like [[aerobatics]] for shows has been successful. These include [[aerobatic maneuver]]s like - in-place flips, in-place rolls, loops, hurricanes and even auto-rotation landings. This work was developed by Pieter Abbeel, Adam Coates, and Andrew Ng - "Autonomous Helicopter Aerobatics through Apprenticeship Learning"&lt;ref&gt;[http://dl.acm.org/citation.cfm?id=1894944 Pieter Abbeel, Adam Coates, Andrew Ng, “Autonomous Helicopter Aerobatics through Apprenticeship Learning.” In Vol. 29, Issue 13 International Journal of Robotics Research. 2010.]&lt;/ref&gt;

===System model approach===
System models try to mimic the expert by modeling world dynamics.&lt;ref name=survey/&gt;

==Plan approach==
The system learns rules to associate preconditions and postconditions with each action. In one 1994 demonstration, a humanoid learns a generalized plan from only two demonstrations of a repetitive ball
collection task.&lt;ref name=survey/&gt;

== Example ==
Learning from demonstration is often explained from a perspective that the working [[Robot software|Robot-control-system]] is available and the human-demonstrator is using it. And indeed, if the software works, the [[Human–machine system|Human operator]] takes the robot-arm, makes a move with it, and the robot will reproduce the action later. For example, he teaches the robot-arm how to put a cup under a coffeemaker and press the start-button. In the replay phase, the robot is imitating this behavior 1:1. But that is not how the system works internally; it is only what the audience can observe. In reality, Learning from demonstration is much more complex.

In 1997, robotics expert [[Stefan Schaal]] was working on the [[Sarcos]] robot-arm. The goal was simple: solve the [[Pendulum (mathematics)|pendulum swingup task]]. The robot itself can execute a movement, and as a result, the pendulum is moving. The problem is, that it is unclear what actions will result into which movement. It is an [[Optimal control]]-problem which can be described with mathematical formulas but is hard to solve. The idea from Schaal was, not to use a [[Brute-force search|Brute-force solver]] but record the movements of a human-demonstration. The angle of the pendulum is logged over the timeperiod of 3 seconds at the y-axis. This results into a diagram which produces a pattern.&lt;ref name="atkeson1997learning" /&gt;

{| class="wikitable"
|+ Trajectory over time
|-
! time (seconds)
! angle (radians)
|-
| 0
| -3.0
|-
| 0.5
| -2.8
|-
| 1.0
| -4.5
|-
| 1.5
| -1.0
|}

In computer animation, the principle is called [[Interpolation (computer graphics)|spline animation]].&lt;ref name="akgun2012keyframe" /&gt; That means, on the x-axis the time is given, for example 0.5 seconds, 1.0 seconds, 1.5 seconds, while on the y-axis is the variable given. In most cases it's the position of an object. In the inverted pendulum it is the angle.

The overall task consists of two parts: recording the angle over time and reproducing the recorded motion. The reproducing step is surprisingly simple. As an input we know, in which time step which angle the pendulum must have. Bringing the system to a state is called “Tracking control” or [[PID controller#PID controller theory|PID control]]. That means, we have a trajectory over time, and must find control actions to map the system to this trajectory. Other authors call the principle “steering behavior”,&lt;ref name="reynolds1999steering" /&gt; because the aim is to bring a robot to a given line.

==See also==
* [[Inverse reinforcement learning]]

==References==
&lt;references&gt;
&lt;ref name="atkeson1997learning"&gt;
{{cite book
| title      = Learning tasks from a single demonstration
| author     = Atkeson, Christopher G., and Stefan Schaal
| year       = 1997
| publisher  = IEEE
| journal    = Proceedings of International Conference on Robotics and Automation
| url        = https://www.cs.cmu.edu/~cga/papers/cga-icra97alt.pdf
| doi        = 10.1109/robot.1997.614389
| volume     = 2
| pages      = 1706–1712
| isbn     = 978-0-7803-3612-4
| citeseerx     = 10.1.1.385.3520
}}
&lt;/ref&gt;

&lt;ref name="russell1998learning"&gt;
{{cite book
| title      = Learning agents for uncertain environments
| author     = Russell, Stuart
| year       = 1998
| book-title  = Proceedings of the eleventh annual conference on Computational learning theory
| doi        = 10.1145/279943.279964
| pages      = 101–103
}}
&lt;/ref&gt;

&lt;ref name="reynolds1999steering"&gt;
{{cite conference
| title      = Steering behaviors for autonomous characters
| author     = Reynolds, Craig W
| year       = 1999
| pages      = 763–782
| conference = Game developers conference
| url        = http://www.red3d.com/cwr/steer/gdc99/
}}
&lt;/ref&gt;

&lt;ref name="akgun2012keyframe"&gt;
{{cite journal
| title      = Keyframe-based Learning from Demonstration
| author     = Baris Akgun and Maya Cakmak and Karl Jiang and Andrea L. Thomaz
| year       = 2012
| journal    = International Journal of Social Robotics
| url        = https://smartech.gatech.edu/bitstream/handle/1853/44594/akgun12-soro.pdf
| doi        = 10.1007/s12369-012-0160-0
| volume     = 4
| number     = 4
| pages      = 343–355
}}
&lt;/ref&gt;
&lt;/references&gt;
{{Use dmy dates|date=September 2018}}

{{DEFAULTSORT:Apprenticeship Learning}}
[[Category:Machine learning]]</text>
      <sha1>4zhameeyfv9si1jnsvass55crs935sk</sha1>
    </revision>
  </page>
  <page>
    <title>Subclass reachability</title>
    <ns>0</ns>
    <id>3119546</id>
    <revision>
      <id>641401945</id>
      <parentid>615987415</parentid>
      <timestamp>2015-01-07T12:10:44Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>Tagging using [[Project:AWB|AWB]] (10703)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="448" xml:space="preserve">{{Multiple issues|
{{unreferenced|date=January 2009}}
{{orphan|date=November 2011}}
{{context|date=February 2011}}
}}

In [[computational learning theory]] in [[mathematics]], given a [[Concept class|class of concepts]] C, a subclass D is '''reachable''' if there exists a partial approximation S of some concept such that D contains exactly those concepts in C that are extensions to S (i.e., D=C|S).

[[Category:Machine learning]]


{{Math-stub}}</text>
      <sha1>ir9sxribicolp4o7wws6l9xetw4cg4p</sha1>
    </revision>
  </page>
  <page>
    <title>Binary classification</title>
    <ns>0</ns>
    <id>205393</id>
    <revision>
      <id>992413365</id>
      <parentid>987134843</parentid>
      <timestamp>2020-12-05T03:50:34Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 2 templates: del empty params (5×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="11074" xml:space="preserve">{{More citations needed|date=May 2011}}
'''Binary classification''' is the task of [[Statistical classification|classifying]] the elements of a [[Set (mathematics)|set]] into two groups on the basis of a [[classification rule]]. Typical binary classification problems include:
* [[Medical test]]ing to determine if a patient has certain disease or not;
* [[Quality control]] in industry, deciding whether a specification has been met;
* In [[information retrieval]], deciding whether a page should be in the [[result set]] of a search or not.

Binary classification is [[dichotomization]] applied to a practical situation. In many practical binary classification problems, the two groups are not symmetric, and rather than overall accuracy, the relative proportion of different [[type I and type II errors|types of errors]] is of interest. For example, in medical testing, detecting a disease when it is not present (a ''[[false positives and false negatives#False positive error|false positive]]'') is considered differently from not detecting a disease when it is present (a ''[[false positives and false negatives#False negative error|false negative]]'').

==Statistical binary classification==
[[Statistical classification]] is a problem studied in [[machine learning]].  It is a type of [[supervised learning]], a method of machine learning where the categories are predefined, and is used to categorize new probabilistic observations into said categories.  When there are only two categories the problem is known as statistical binary classification.

Some of the methods commonly used for binary classification are:
* [[Decision tree learning|Decision trees]]
* [[Random forests]]
* [[Bayesian network]]s
* [[Support vector machine]]s
* [[Neural network]]s
* [[Logistic regression]]
* [[Probit model]]
Each classifier is best in only a select domain based upon the number of observations, the dimensionality of the [[feature vector]], the noise in the data and many other factors. For example, [[random forests]] perform better than [[Support vector machine|SVM]] classifiers for 3D point clouds.&lt;ref&gt;{{Cite journal|title = Automatic Identification of Window Regions on Indoor Point Clouds Using LiDAR and Cameras|last = Zhang &amp; Zakhor|first = Richard &amp; Avideh|date = 2014|journal = VIP Lab Publications|citeseerx = 10.1.1.649.303}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |title = Simplified markov random fields for efficient semantic labeling of 3D point clouds|last = Y. Lu and C. Rasmussen|date = 2012|journal = IROS|url=http://nameless.cis.udel.edu/pubs/2012/LR12/yan_iros2012.pdf}}&lt;/ref&gt;

==Evaluation of binary classifiers==
{{main|Evaluation of binary classifiers}}

[[Image:binary-classification-labeled.svg|thumb|220px|right|In this set of tested instances, the instances left of the divider have the condition being tested; the right half do not. The oval bounds those instances that a test algorithm classifies as having the condition. The green areas highlight the instances that the test algorithm correctly classified. Labels refer to: &lt;br /&gt;TP=true positive; TN=true negative; FP=false positive (type I error); FN=false negative (type II error); TPR=set of instances to determine true positive rate; FPR=set of instances to determine false positive rate; PPV=positive predictive value; NPV=negative predictive value.]]

There are many metrics that can be used to measure the performance of a classifier or predictor; different fields have different preferences for specific metrics due to different goals. In medicine [[sensitivity and specificity]] are often used, while in information retrieval [[precision and recall]] are preferred. An important distinction is between metrics that are independent of how often each category occurs in the population (the ''[[prevalence]]''), and metrics that depend on the prevalence – both types are useful, but they have very different properties.

Given a classification of a specific data set, there are four basic combinations of actual data category and assigned category: [[true positive]]s TP (correct positive assignments), [[true negative]]s TN (correct negative assignments), [[false positive]]s FP (incorrect positive assignments), and [[false negative]]s FN (incorrect negative assignments).

{| class="wikitable"
!
!Condition positive
! 
Condition negative
|-
!
Test outcome positive
| align="center"| True positive
| align="center"| False positive
|-
! Test outcome negative
| align="center"| False negative
| align="center"| True negative
|}
These can be arranged into a 2×2 [[contingency table]], with columns corresponding to actual value – condition positive or condition negative – and rows corresponding to classification value – test outcome positive or test outcome negative. 

===The eight basic ratios===
There are eight basic ratios that one can compute from this table, which come in four complementary pairs (each pair summing to 1). These are obtained by dividing each of the four numbers by the sum of its row or column, yielding eight numbers, which can be referred to generically in the form "true positive row ratio" or "false negative column ratio". 

There are thus two pairs of column ratios and two pairs of row ratios, and one can summarize these with four numbers by choosing one ratio from each pair – the other four numbers are the complements.

The column ratios are:
*[[true positive rate]] (TPR) = (TP/(TP+FN)), aka '''[[Sensitivity (tests)|sensitivity]]''' or [[Recall (information retrieval)|recall]].  These are the proportion of the ''population with the condition'' for which the test is correct.
**with complement the [[false negative rate]] (FNR) = (FN/(TP+FN))
*[[true negative rate]] (TNR) = (TN/(TN+FP), aka '''[[Specificity (tests)|specificity]]''' (SPC),
**with complement [[false positive rate]] (FPR) = (FP/(TN+FP)), also called independent of [[prevalence]]

The row ratios are:
*[[Positive Predictive Value|positive predictive value]] (PPV, aka [[Precision (information retrieval)|precision]]) (TP/(TP+FP)).  These are the proportion of the ''population with a given test result'' for which the test is correct.
**with complement the [[false discovery rate]] (FDR) (FP/(TP+FP))
*[[negative predictive value]] (NPV) (TN/(TN+FN))
**with complement the [[false omission rate]] (FOR) (FN/(TN+FN)), also called dependence on prevalence.

In diagnostic testing, the main ratios used are the true column ratios – true positive rate and true negative rate – where they are known as [[sensitivity and specificity]]. In informational retrieval, the main ratios are the true positive ratios (row and column) – positive predictive value and true positive rate – where they are known as [[precision and recall]].

One can take ratios of a complementary pair of ratios, yielding four [[Likelihood ratios in diagnostic testing|likelihood ratios]] (two column ratio of ratios, two row ratio of ratios). This is primarily done for the column (condition) ratios, yielding [[likelihood ratios in diagnostic testing]]. Taking the ratio of one of these groups of ratios yields a final ratio, the [[diagnostic odds ratio]] (DOR). This can also be defined directly as (TP×TN)/(FP×FN) = (TP/FN)/(FP/TN); this has a useful interpretation – as an [[odds ratio]] – and is prevalence-independent.

There are a number of other metrics, most simply the [[Accuracy and precision#In binary classification|accuracy]] or Fraction Correct (FC), which measures the fraction of all instances that are correctly categorized; the complement is the Fraction Incorrect (FiC). The [[F-score]] combines precision and recall into one number via a choice of weighing, most simply equal weighing, as the balanced F-score ([[F1 score]]). Some metrics come from [[regression coefficient]]s: the [[markedness]] and the [[informedness]], and their [[geometric mean]], the [[Matthews correlation coefficient]]. Other metrics include [[Youden's J statistic]], the [[uncertainty coefficient]], the [[phi coefficient]], and [[Cohen's kappa]].

==Converting continuous values to binary==
{{anchor|artificial}} &lt;!--Artificially binary value redirects here--&gt;
Tests whose results are of continuous values, such as most [[blood values]], can artificially be made binary by defining a [[cutoff (reference value)|cutoff value]], with test results being designated as [[positive or negative test|positive or negative]] depending on whether the resultant value is higher or lower than the cutoff.

However, such conversion causes a loss of information, as the resultant binary classification does not tell ''how much'' above or below the cutoff a value is. As a result, when converting a continuous value that is close to the cutoff to a binary one, the resultant [[Positive predictive value|positive]] or [[negative predictive value]] is generally higher than the [[predictive value]] given directly from the continuous value. In such cases, the designation of the test of being either positive or negative gives the appearance of an inappropriately high certainty, while the value is in fact in an interval of uncertainty. For example, with the urine concentration of [[Human chorionic gonadotropin|hCG]] as a continuous value, a urine [[pregnancy test]] that measured 52 mIU/ml of hCG may show as "positive" with 50 mIU/ml as cutoff, but is in fact in an interval of uncertainty, which may be apparent only by knowing the original continuous value. On the other hand, a test result very far from the cutoff generally has a resultant positive or negative predictive value that is lower than the predictive value given from the continuous value. For example, a urine hCG value of 200,000 mIU/ml confers a very high probability of pregnancy, but conversion to binary values results in that it shows just as "positive" as the one of 52 mIU/ml.

==See also==
{{Portal|Mathematics}}
* [[Bayesian inference#Examples|Examples of Bayesian inference]]
* [[Classification rule]]
* [[Confusion matrix]]
* [[Detection theory]]
* [[Kernel methods]]
* [[Multiclass classification]]
* [[Multi-label classification]]
* [[One-class classification]]
* [[Prosecutor's fallacy]]
* [[Receiver operating characteristic]]
* [[Thresholding (image processing)]]
* [[Uncertainty coefficient]], aka proficiency
* [[Qualitative property]]

==References==
{{reflist}}

== Bibliography ==
* [[Nello Cristianini]] and [[John Shawe-Taylor]]. ''An Introduction to Support Vector Machines and other kernel-based learning methods''. Cambridge University Press, 2000. {{ISBN|0-521-78019-5}} ''([https://web.archive.org/web/20180627015707/https://www.support-vector.net/] SVM Book)''
* John Shawe-Taylor and Nello Cristianini.  ''Kernel Methods for Pattern Analysis''.  Cambridge University Press, 2004.  {{ISBN|0-521-81397-2}} ([https://kernelmethods.blogs.bristol.ac.uk/ Website for the book])
* Bernhard Schölkopf and A. J. Smola: ''Learning with Kernels''. MIT Press, Cambridge, Massachusetts, 2002. {{ISBN|0-262-19475-9}}

{{Statistics|analysis||state=expanded}}

[[Category:Statistical classification]]
[[Category:Machine learning]]</text>
      <sha1>dyo0s75m5z3ojx3e8242qzlr04p9dr1</sha1>
    </revision>
  </page>
  <page>
    <title>Explanation-based learning</title>
    <ns>0</ns>
    <id>21638340</id>
    <revision>
      <id>1005407700</id>
      <parentid>993236504</parentid>
      <timestamp>2021-02-07T14:33:38Z</timestamp>
      <contributor>
        <username>MaD70</username>
        <id>3072933</id>
      </contributor>
      <comment>Clarified the meaning of "domain theory" which has nothing to do with Scott's domain theory.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="8107" xml:space="preserve">{{Cleanup-reorganize|date=December 2012}}
'''Explanation-based learning''' ('''EBL''') is a form of [[machine learning]] that exploits a very strong, or even perfect, [[Domain (software engineering)|domain]] theory (i.e. a formal theory of an application domain akin to a [[domain model]] in [[ontology engineering]], not to be confused with Scott's [[domain theory]]) in order to make generalizations or form concepts from training examples.&lt;ref&gt;{{cite journal|title=Special issue on explanation in case-based reasoning |journal=Artificial Intelligence Review|date=October 2005|volume=24|issue=2}}&lt;/ref&gt;

== Details==
An example of EBL using a perfect domain theory is a program that learns to play [[chess]] through example. A specific chess position that contains an important feature such as "Forced loss of black queen in two moves" includes many irrelevant features, such as the specific scattering of pawns on the board. EBL can take a single training example and determine what are the relevant features in order to form a generalization.&lt;ref&gt;Black-queen example from {{cite book | last = Mitchell | first = Tom | title = Machine Learning | publisher = McGraw-Hill | year = 1997 | pages = [https://archive.org/details/machinelearning00mitc_087/page/n319 308]–309 | url =https://archive.org/details/machinelearning00mitc_087| url-access = limited | isbn = 0-07-042807-7 }}&lt;/ref&gt;

A domain theory is ''perfect'' or ''complete'' if it contains, in principle, all information needed to decide any question about the domain. For example, the domain theory for chess is simply the rules of chess. Knowing the rules, in principle, it is possible to deduce the best move in any situation. However, actually making such a deduction is impossible in practice due to [[combinatoric explosion]]. EBL uses training examples to make searching for deductive consequences of a domain theory efficient in practice.

In essence, an EBL system works by finding a way to deduce each training example from the system's existing database of domain theory. Having a short [[Mathematical proof|proof]] of the training example extends the domain-theory database, enabling the EBL system to find and classify future examples that are similar to the training example very quickly.&lt;ref&gt;{{cite book | last = Mitchell | first = Tom | title = Machine Learning | publisher = McGraw-Hill | year = 1997 | pages = [https://archive.org/details/machinelearning00mitc_087/page/n331 320] | url =https://archive.org/details/machinelearning00mitc_087| url-access = limited | isbn = 0-07-042807-7 | quote = In its pure form, EBL involves reformulating the domain theory to produce general rules that classify examples in a single inference step. }}&lt;/ref&gt;
The main drawback of the method—the cost of applying the learned proof macros, as these become numerous—was analyzed by Minton.&lt;ref&gt;{{cite journal | doi = 10.1016/0004-3702(90)90059-9 | last = Minton | first = Steven | journal = Artificial Intelligence | volume=42 | issue = 2–3 | pages = 363–392 | title = Quantitative Results Concerning the Utility Problem in Explanation-Based Learning | year = 1990 }}&lt;/ref&gt;
 
=== Basic formulation===
EBL software takes four inputs:

* a hypothesis space (the set of all possible conclusions)
* a domain theory (axioms about a domain of interest)
* training examples (specific facts that rule out some possible hypothesis)
* operationality criteria (criteria for determining which features in the domain are efficiently recognizable, e.g. which features are directly detectable using sensors)&lt;ref&gt;{{cite journal|title=Defining operationality for explanation-based learning|journal=Artificial Intelligence|year=1988|first=Richard|last=Keller|volume=35|issue=2|pages=227–241|url=http://www.aaai.org/Papers/AAAI/1987/AAAI87-086.pdf|access-date=2009-02-22 | quote = Current Operationality Defn.: A concept description is ''operational'' if it can be used efficiently to recognize instances of the concept it denotes|doi=10.1016/0004-3702(88)90013-6}} After stating the common definition, the paper actually argues against it in favor of more-refined criteria.&lt;/ref&gt;

== Application ==
An especially good application domain for an EBL is natural language processing (NLP). Here a rich domain theory, i.e., a natural language grammar—although neither perfect nor complete, is tuned to a particular application or particular language usage, using a [[treebank]] (training examples). Rayner pioneered this work.&lt;ref&gt;{{cite news | last = Rayner | first = Manny | title = Applying Explanation-Based Generalization to Natural Language Processing | location = Procs. International Conference on Fifth Generation Computing, Kyoto | pages = 1267–1274 | year = 1988 }}&lt;/ref&gt; The first successful industrial application was to a commercial NL interface to relational databases.&lt;ref&gt;{{cite news | last = Samuelsson | first = Christer |author2=Manny Rayner | title = Quantitative Evaluation of Explanation-Based Learning as an Optimization Tool for a Large-Scale Natural Language System | location = Procs. 12th International Joint Conference on Artificial Intelligence, Sydney | pages = 609–615 | year = 1991 }}&lt;/ref&gt; The method has been successfully applied to several large-scale natural language parsing systems,&lt;ref&gt;{{cite book | last = Samuelsson | first = Christer | title =  Fast Natural-Language Parsing Using Explanation-Based Learning | publisher =  Doctoral Dissertation, Royal Institute of Technology |  location = Stockholm | year = 1994 }}&lt;/ref&gt; where the utility problem was solved by omitting the original grammar (domain theory) and using specialized LR-parsing techniques, resulting in huge speed-ups, at a cost in coverage, but with a gain in disambiguation.
EBL-like techniques have also been applied to surface generation, the converse of parsing.&lt;ref&gt;{{cite news | last = Samuelsson | first = Christer | title = Example-Based Optimization of Surface-Generation Tables | location = in R. Mitkov and N. Nicolov (eds.) "Recent Advances in Natural Language Processing," vol. 136 of "Current Issues in Linguistic Theory" | publisher = John Benjamins, Amsterdam | year = 1996}}&lt;/ref&gt;

When applying EBL to NLP, the operationality criteria can be hand-crafted,&lt;ref&gt;{{cite news | last = Rayner | first = Manny |author2=David Carter | title = Fast Parsing using Pruning and Grammar Specialization | url = https://archive.org/details/arxiv-cmp-lg9604017 | location = Procs. ACL, Santa Cruz | year = 1996 }}&lt;/ref&gt; or can be
inferred from the treebank using either the entropy of its or-nodes&lt;ref&gt;{{cite news | last = Samuelsson | first = Christer | title = Grammar Specialization through Entropy Thresholds | url = https://archive.org/details/arxiv-cmp-lg9405022 | year = 1994 | pages = 188–195 | location = Procs. ACL, Las Cruces }}&lt;/ref&gt;
or a target coverage/disambiguation trade-off (= recall/precision trade-off  = f-score).&lt;ref&gt;{{cite news | last = Cancedda | first = Nicola |author2=Christer Samuelsson | title = Corpus-based Grammar Specialization | year = 2000 | location = Procs 4th Computational Natural Language Learning Workshop }}&lt;/ref&gt;
EBL can also be used to compile grammar-based language models for speech recognition, from general unification grammars.&lt;ref&gt;{{cite book | last = Rayner | first = Manny |author2=Beth Ann Hockey |author3=Pierrette Bouillon| title = Putting Linguistics into Speech Recognition: The Regulus Grammar Compiler | date = n.d. | isbn = 1-57586-526-2 }}&lt;/ref&gt;
Note how the utility problem, first exposed by Minton, was solved by discarding the original grammar/domain theory, and that the quoted articles tend to contain the phrase ''grammar specialization''—quite the opposite of the original term ''explanation-based generalization.'' Perhaps the best name for this technique would be ''data-driven search space reduction.''
Other people who worked on EBL for NLP include Guenther Neumann, Aravind Joshi, Srinivas Bangalore, and Khalil Sima'an.

== See also ==

* [[One-shot learning]]

== References ==
{{reflist}}

{{DEFAULTSORT:Explanation-Based Learning}}
[[Category:Machine learning]]</text>
      <sha1>puszd8yysfxhjske08m4e99eugb9zq9</sha1>
    </revision>
  </page>
  <page>
    <title>Category utility</title>
    <ns>0</ns>
    <id>8964665</id>
    <revision>
      <id>991036800</id>
      <parentid>976243490</parentid>
      <timestamp>2020-11-27T22:46:22Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 17 templates: del empty params (1×); hyphenate params (1×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="23051" xml:space="preserve">'''Category utility''' is a measure of "category goodness" defined in {{Harvtxt|Gluck|Corter|1985}} and {{Harvtxt|Corter|Gluck|1992}}. It attempts to maximize both the probability that two objects in the same category have attribute values in common, and the probability that objects from different categories have different attribute values. It was intended to supersede more limited measures of category goodness such as "[[cue validity]]" ({{Harvnb|Reed|1972}}; {{Harvnb|Rosch|Mervis|1975}}) and "collocation index" {{Harv|Jones|1983}}. It provides a normative [[information-theoretic]] measure of the ''predictive advantage'' gained by the observer who possesses knowledge of the given category structure (i.e., the class labels of instances) over the observer who does ''not'' possess knowledge of the category structure. In this sense the motivation for the category utility measure is similar to the [[Information gain in decision trees|information gain]] metric used in [[decision tree]] learning. In certain presentations, it is also formally equivalent to the [[mutual information]], as discussed below. A review of category utility in its probabilistic incarnation, with applications to [[machine learning]], is provided in {{Harvtxt|Witten|Frank|2005|pp=260–262}}.

==Probability-theoretic definition of category utility==
The [[probability-theoretic]] definition of category utility given in {{Harvtxt|Fisher|1987}} and {{Harvtxt|Witten|Frank|2005}} is as follows:

:&lt;math&gt;
CU(C,F) = \tfrac{1}{p} \sum_{c_j \in C} p(c_j) \left [\sum_{f_i \in F} \sum_{k=1}^m p(f_{ik}|c_j)^2 - \sum_{f_i \in F} \sum_{k=1}^m p(f_{ik})^2\right ]
&lt;/math&gt;

where &lt;math&gt;F = \{f_i\}, \ i=1 \ldots n&lt;/math&gt; is a size-&lt;math&gt;n\ &lt;/math&gt; set of &lt;math&gt;m\ &lt;/math&gt;-ary features, and &lt;math&gt;C = \{c_j\} \ j=1 \ldots p&lt;/math&gt; is a set of &lt;math&gt;p\ &lt;/math&gt; categories. The term &lt;math&gt;p(f_{ik})\ &lt;/math&gt; designates the [[marginal probability]] that feature &lt;math&gt;f_i\ &lt;/math&gt; takes on value &lt;math&gt;k\ &lt;/math&gt;, and the term &lt;math&gt;p(f_{ik}|c_j)\ &lt;/math&gt; designates the category-[[conditional probability]] that feature &lt;math&gt;f_i\ &lt;/math&gt; takes on value &lt;math&gt;k\ &lt;/math&gt; ''given'' that the object in question belongs to category &lt;math&gt;c_j\ &lt;/math&gt;.

The motivation and development of this expression for category utility, and the role of the multiplicand &lt;math&gt;\textstyle \tfrac{1}{p}&lt;/math&gt; as a crude overfitting control, is given in the above sources. Loosely {{Harv|Fisher|1987}}, the term &lt;math&gt;\textstyle p(c_j) \sum_{f_i \in F} \sum_{k=1}^m p(f_{ik}|c_j)^2&lt;/math&gt; is the expected number of attribute values that can be correctly guessed by an observer using a [[probability-matching]] strategy together with knowledge of the category labels, while &lt;math&gt;\textstyle p(c_j) \sum_{f_i \in F} \sum_{k=1}^m p(f_{ik})^2&lt;/math&gt; is the expected number of attribute values that can be correctly guessed by an observer the same strategy but without any knowledge of the category labels. Their difference therefore reflects the relative advantage accruing to the observer by having knowledge of the category structure.

== Information-theoretic definition of category utility ==
The [[information-theoretic]] definition of category utility for a set of entities with size-&lt;math&gt;n\ &lt;/math&gt; binary feature set &lt;math&gt;F = \{f_i\}, \ i=1 \ldots n&lt;/math&gt;, and a binary category &lt;math&gt;C = \{c,\bar{c}\}&lt;/math&gt; is given in {{Harvtxt|Gluck|Corter|1985}} as follows:

:&lt;math&gt;
CU(C,F) = \left [p(c) \sum_{i=1}^n p(f_i|c)\log p(f_i|c) + p(\bar{c}) \sum_{i=1}^n p(f_i|\bar{c})\log p(f_i|\bar{c}) \right ] - \sum_{i=1}^n p(f_i)\log p(f_i)
&lt;/math&gt;

where &lt;math&gt;p(c)\ &lt;/math&gt; is the [[prior probability]] of an entity belonging to the positive category &lt;math&gt;c\ &lt;/math&gt; (in the absence of any feature information), &lt;math&gt;p(f_i|c)\ &lt;/math&gt; is the conditional probability of an entity having feature &lt;math&gt;f_i\ &lt;/math&gt; given that the entity belongs to category &lt;math&gt;c\ &lt;/math&gt;, &lt;math&gt;p(f_i|\bar{c})&lt;/math&gt; is likewise the conditional probability of an entity having feature &lt;math&gt;f_i\ &lt;/math&gt; given that the entity belongs to category &lt;math&gt;\bar{c}&lt;/math&gt;, and &lt;math&gt;p(f_i)\ &lt;/math&gt; is the prior probability of an entity possessing feature &lt;math&gt;f_i\ &lt;/math&gt; (in the absence of any category information).

The intuition behind the above expression is as follows: The term &lt;math&gt;p(c)\textstyle  \sum_{i=1}^n p(f_i|c)\log p(f_i|c)&lt;/math&gt; represents the cost (in bits) of optimally encoding (or transmitting) feature information when it is known that the objects to be described belong to category &lt;math&gt;c\ &lt;/math&gt;. Similarly, the term  &lt;math&gt;p(\bar{c})\textstyle  \sum_{i=1}^n p(f_i|\bar{c})\log p(f_i|\bar{c})&lt;/math&gt; represents the cost (in bits) of optimally encoding (or transmitting) feature information when it is known that the objects to be described belong to category &lt;math&gt;\bar{c}&lt;/math&gt;. The sum of these two terms in the brackets is therefore the [[weighted average]] of these two costs. The final term, &lt;math&gt;\textstyle  \sum_{i=1}^n p(f_i)\log p(f_i)&lt;/math&gt;, represents the cost (in bits) of optimally encoding (or transmitting) feature information when no category information is available. The value of the category utility will, in the above formulation, be negative (???).

=== Category utility and mutual information ===
{{Harvtxt|Gluck|Corter|1985}} and {{Harvtxt|Corter|Gluck|1992}} mention that the category utility is equivalent to the [[mutual information]]. Here is a simple demonstration of the nature of this equivalence. Assume a set of entities each having the same &lt;math&gt;n&lt;/math&gt; features, i.e., feature set &lt;math&gt;F = \{f_i\}, \ i=1 \ldots n&lt;/math&gt;, with each feature variable having cardinality &lt;math&gt;m&lt;/math&gt;. That is, each feature has the capacity to adopt any of &lt;math&gt;m&lt;/math&gt; distinct values (which need ''not'' be ordered; all variables can be nominal); for the special case &lt;math&gt;m=2&lt;/math&gt; these features would be considered ''binary'', but more generally, for any &lt;math&gt;m&lt;/math&gt;, the features are simply ''m-ary''. For the purposes of this demonstration, without loss of generality, feature set &lt;math&gt;F&lt;/math&gt; can be replaced with a single aggregate variable &lt;math&gt;F_a&lt;/math&gt; that has cardinality &lt;math&gt;m^n&lt;/math&gt;, and adopts a unique value &lt;math&gt;v_i, \ i=1 \ldots m^n&lt;/math&gt; corresponding to each feature combination in the [[Cartesian product]] &lt;math&gt;\otimes F&lt;/math&gt;. (Ordinality does ''not'' matter, because the mutual information is not sensitive to ordinality.) In what follows, a term such as &lt;math&gt;p(F_a=v_i)&lt;/math&gt; or simply &lt;math&gt;p(v_i)&lt;/math&gt; refers to the probability with which &lt;math&gt;F_a&lt;/math&gt; adopts the particular value &lt;math&gt;v_i&lt;/math&gt;. (Using the aggregate feature variable &lt;math&gt;F_a&lt;/math&gt; replaces multiple summations, and simplifies the presentation to follow.)

For this demonstration, also assume a single category variable &lt;math&gt;C&lt;/math&gt;, which has cardinality &lt;math&gt;p&lt;/math&gt;. This is equivalent to a classification system in which there are &lt;math&gt;p&lt;/math&gt; non-intersecting categories. In the special case of &lt;math&gt;p=2&lt;/math&gt; there are the two-category case discussed above. From the definition of mutual information for discrete variables, the mutual information &lt;math&gt;I(F_a;C)&lt;/math&gt; between the aggregate feature variable &lt;math&gt;F_a&lt;/math&gt; and the category variable &lt;math&gt;C&lt;/math&gt; is given by:

:&lt;math&gt; 
I(F_a;C) = \sum_{v_i \in F_a} \sum_{c_j \in C} p(v_i,c_j) \log \frac{p(v_i,c_j)}{p(v_i)\,p(c_j)}
&lt;/math&gt;

where &lt;math&gt;p(v_i)&lt;/math&gt; is the [[prior probability]] of feature variable &lt;math&gt;F_a&lt;/math&gt; adopting value &lt;math&gt;v_i&lt;/math&gt;, &lt;math&gt;p(c_j)&lt;/math&gt; is the [[marginal probability]] of category variable &lt;math&gt;C&lt;/math&gt; adopting value &lt;math&gt;c_j&lt;/math&gt;, and &lt;math&gt;p(v_i,c_j)&lt;/math&gt; is the [[joint probability]] of variables &lt;math&gt;F_a&lt;/math&gt; and &lt;math&gt;C&lt;/math&gt; simultaneously adopting those respective values. In terms of the conditional probabilities this can be re-written (or defined) as

:&lt;math&gt; 
\begin{align}
I(F_a;C) &amp; = \sum_{v_i \in F_a} \sum_{c_j \in C} p(v_i,c_j) \log \frac{p(v_i|c_j)}{p(v_i)} \\
 &amp; = \sum_{v_i \in F_a} \sum_{c_j \in C} p(v_i|c_j)p(c_j) \left [\log p(v_i|c_j)- \log p(v_i) \right ] \\
 &amp; = \sum_{v_i \in F_a} \sum_{c_j \in C} p(v_i|c_j)p(c_j) \log p(v_i|c_j)- \sum_{v_i \in F_a} \sum_{c_j \in C} p(v_i|c_j)p(c_j) \log p(v_i) \\
 &amp; = \sum_{v_i \in F_a} \sum_{c_j \in C} p(v_i|c_j)p(c_j) \log p(v_i|c_j)- \sum_{v_i \in F_a} \sum_{c_j \in C} p(v_i,c_j) \log p(v_i) \\
 &amp; = \sum_{v_i \in F_a} \sum_{c_j \in C} p(v_i|c_j)p(c_j) \log p(v_i|c_j)- \sum_{v_i \in F_a} \log p(v_i) \sum_{c_j \in C} p(v_i,c_j) \\
 &amp; = \sum_{v_i \in F_a} \sum_{c_j \in C} p(v_i|c_j)p(c_j) \log p(v_i|c_j)- \sum_{v_i \in F_a} p(v_i) \log p(v_i) \\
\end{align}
&lt;/math&gt;

If the original [[Category utility#Definition of the Category Utility|definition of the category utility]] from above is rewritten with &lt;math&gt;C = \{c,\bar{c}\}&lt;/math&gt;,

:&lt;math&gt;
CU(C,F) = \sum_{f_i \in F} \sum_{c_j \in C} p(f_i|c_j) p(c_j) \log p(f_i|c_j) - \sum_{f_i \in F} p(f_i) \log p(f_i)
&lt;/math&gt;

This equation clearly has the same '''form''' as the (&lt;span style=color:blue;&gt;blue&lt;/span&gt;) equation expressing the mutual information between the feature set and the category variable; the difference is that the sum &lt;math&gt;\textstyle \sum_{f_i \in F}&lt;/math&gt; in the category utility equation runs over independent binary variables &lt;math&gt;F = \{f_i\}, \ i=1 \ldots n&lt;/math&gt;, whereas the sum &lt;math&gt;\textstyle \sum_{v_i \in F_a}&lt;/math&gt; in the mutual information runs over ''values'' of the single &lt;math&gt;m^n&lt;/math&gt;-ary variable &lt;math&gt;F_a&lt;/math&gt;. The two measures are actually equivalent then ''only'' when the features &lt;math&gt;\{f_i\}&lt;/math&gt;, are ''independent'' (and assuming that terms in the sum corresponding to &lt;math&gt;p(\bar{f_i})&lt;/math&gt; are also added).

== Insensitivity of category utility to ordinality ==
Like the mutual information, the category utility is not sensitive to any ''ordering'' in the feature or category variable values. That is, as far as the category utility is concerned, the category set &lt;code&gt;{small,medium,large,jumbo}&lt;/code&gt; is not qualitatively different from the category set &lt;code&gt;{desk,fish,tree,mop}&lt;/code&gt; since the formulation of the category utility does not account for any ordering of the class variable. Similarly, a feature variable adopting values &lt;code&gt;{1,2,3,4,5}&lt;/code&gt; is not qualitatively different from a feature variable adopting values &lt;code&gt;{fred,joe,bob,sue,elaine}&lt;/code&gt;. As far as the category utility or ''mutual information'' are concerned, ''all'' category and feature variables are ''nominal variables.'' For this reason, category utility does not reflect any ''[[Gestalt psychology|gestalt]]'' aspects of "category goodness" that might be based on such ordering effects. One possible adjustment for this insensitivity to ordinality is given by the weighting scheme described in the article for [[mutual information]].

== Category "goodness": models and philosophy==
This section provides some background on the origins of, and need for, formal measures of "category goodness" such as the category utility, and some of the history that lead to the development of this particular metric.

===What makes a good category?===
At least since the time of [[Aristotle]] there has been a tremendous fascination in philosophy with the nature of [[concept]]s and [[universals]]. What kind of ''entity'' is a concept such as "horse"? Such abstractions do not designate any particular individual in the world, and yet we can scarcely imagine being able to comprehend the world without their use. Does the concept "horse" therefore have an independent existence outside of the mind? If it does, then what is the locus of this independent existence? The question of locus was an important issue on which the classical schools of [[Plato]] and [[Aristotle]] famously differed. However, they remained in agreement that universals ''did'' indeed have a mind-independent existence. There was, therefore, always a ''fact to the matter'' about which concepts and universals exist in the world.

In the late [[Middle Ages]] (perhaps beginning with [[William of Ockham|Occam]], although [[Porphyry (philosopher)|Porphyry]] also makes a much earlier remark indicating a certain discomfort with the status quo), however, the certainty that existed on this issue began to erode, and it became acceptable among the so-called [[nominalists]] and [[empiricists]] to consider concepts and universals as strictly mental entities or conventions of language. On this view of concepts—that they are purely representational constructs—a new question then comes to the fore: "Why do we possess one set of concepts rather than another?" What makes one set of concepts "good" and another set of concepts "bad"? This is a question that modern philosophers, and subsequently [[machine learning]] theorists and cognitive scientists, have struggled with for many decades.

===What purpose do concepts serve?===
One approach to answering such questions is to investigate the "role" or "purpose" of concepts in cognition. Thus the answer to "What are concepts good for in the first place?" by {{Harvtxt|Mill|1843/1936|p=425}} and many others is that classification (conception) is a precursor to ''[[Inductive reasoning|induction]]'': By imposing a particular categorization on the universe, an organism gains the ability to deal with physically non-identical objects or situations in an identical fashion, thereby gaining substantial predictive leverage ({{Harvnb|Smith|Medin|1981}}; {{Harvnb|Harnad|2005}}). As [[J.S. Mill]] puts it {{Harv|Mill|1843/1936|pp=466–468}},

{{quotation|The general problem of classification... [is] to provide that things shall be thought of in such groups, and those groups in such an order, as will best conduce to the remembrance and to the ascertainment of their laws... [and] one of the uses of such a classification that by drawing attention to the properties on which it is founded, and which, if the classification be good, are marks of many others, it facilitates the discovery of those others.}}

From this base, [[J.S. Mill|Mill]] reaches the following conclusion, which foreshadows much subsequent thinking about category goodness, including the notion of category utility:

{{quotation|The ends of scientific classification are best answered when the objects are formed into groups respecting which a greater number of general propositions can be made, and those propositions more important, than could be made respecting any other groups into which the same things could be distributed. The properties, therefore, according to which objects are classified should, if possible, be those which are causes of many other properties; or, at any rate, which are sure marks of them.}}

One may compare this to the "category utility hypothesis" proposed by {{Harvtxt|Corter|Gluck|1992}}: "A category is useful to the extent that it can be expected to improve the ability of a person to accurately predict the features of instances of that category." Mill here seems to be suggesting that the best category structure is one in which object features (properties) are maximally informative about the object's class, and, simultaneously, the object class is maximally informative about the object's features. In other words, a useful classification scheme is one in which category knowledge can be used to accurately infer object properties, and property knowledge can be used to accurately infer object classes. One may also compare this idea to [[Aristotle]]'s criterion of ''counter-predication'' for definitional predicates, as well as to the notion of concepts described in [[formal concept analysis]].

===Attempts at formalization===
A variety of different measures have been suggested with an aim of formally capturing this notion of "category goodness," the best known of which is probably the "[[cue validity]]". Cue validity of a feature &lt;math&gt;f_i\ &lt;/math&gt; with respect to category &lt;math&gt;c_j\ &lt;/math&gt; is defined as the conditional probability of the category given the feature ({{Harvnb|Reed|1972}};{{Harvnb|Rosch|Mervis|1975}};{{Harvnb|Rosch|1978}}), &lt;math&gt;p(c_j|f_i)\ &lt;/math&gt;, or as the deviation of the conditional probability from the category base rate ({{Harvnb|Edgell|1993}};{{Harvnb|Kruschke|Johansen|1999}}), &lt;math&gt;p(c_j|f_i)-p(c_j)\ &lt;/math&gt;. Clearly, these measures quantify only inference from feature to category (i.e., ''cue validity''), but not from category to feature, i.e., the ''category validity'' &lt;math&gt;p(f_i|c_j)\ &lt;/math&gt;. Also, while the cue validity was originally intended to account for the demonstrable appearance of ''[[basic categories]]'' in human cognition—categories of a particular level of generality that are evidently preferred by human learners—a number of major flaws in the cue validity quickly emerged in this regard ({{Harvnb|Jones|1983}};{{Harvnb|Murphy|1982}};{{Harvnb|Corter|Gluck|1992}}, and others).

One attempt to address both problems by simultaneously maximizing both feature validity and category validity was made by {{Harvtxt|Jones|1983}} in defining the "collocation index" as the product &lt;math&gt;p(c_j|f_i) p(f_i|c_j)\ &lt;/math&gt;, but this construction was fairly ad hoc (see {{Harvnb|Corter|Gluck|1992}}). The category utility was introduced as a more sophisticated refinement of the cue validity, which attempts to more rigorously quantify the full inferential power of a class structure. As shown above, on a certain view the category utility is equivalent to the mutual information between the feature variable and the category variable. It has been suggested that categories having the greatest overall category utility are those that are not only those "best" in a normative sense, but also those human learners prefer to use, e.g., "basic" categories {{Harv|Corter|Gluck|1992}}. Other related measures of category goodness are "cohesion" ({{Harvnb|Hanson|Bauer|1989}};{{Harvnb|Gennari|Langley|Fisher|1989}}) and "salience" {{Harv|Gennari|1989}}.

== Applications ==
* Category utilility is used as the category evaluation measure in the popular [[conceptual clustering]] algorithm called COBWEB {{Harv|Fisher|1987}}.

== See also ==
* [[Abstraction]]
* [[Concept learning]]
* [[Universals]]
* [[Unsupervised learning]]

== References ==
{{refbegin|2}}
* {{Citation | last2=Gluck | first2=Mark A. | last1=Corter | first1=James E. | title=Explaining basic categories: Feature predictability and information | journal=Psychological Bulletin | volume=111 | issue=2 | year=1992 | pages=291–303 | url=http://128.83.97.10/HomePage/Group/LoveLAB/love/classes/concepts/CorterGluck1992.pdf | archive-url=https://web.archive.org/web/20110810135319/http://128.83.97.10/HomePage/Group/LoveLAB/love/classes/concepts/CorterGluck1992.pdf | url-status=dead | archive-date=2011-08-10 | doi=10.1037/0033-2909.111.2.291 }}
* {{Citation | last=Edgell| first=Stephen E.| year= 1993| chapter=Using configural and dimensional information | editor= N. John Castellan | title=Individual and Group Decision Making: Current Issues | publisher=Lawrence Erlbaum| place=[[Hillsdale, New Jersey]]| pages=43–64}}
* {{Citation | last=Fisher| first=Douglas H. | title=Knowledge acquisition via incremental conceptual clustering | journal=Machine Learning |volume=2 |issue=2 | year=1987| pages=139–172 | doi=10.1007/BF00114265| doi-access=free }}
* {{Citation | last=Gennari| first=John H.| year=1989| chapter=Focused concept formation | editor= Alberto Maria Segre | title=Proceedings of the Sixth International Workshop on Machine Learning | publisher=Morgan Kaufmann| place=[[Ithaca, NY]]| pages=379–382}}
* {{Citation | last1=Gennari| first1=John H. | last2=Langley| first2=Pat |last3=Fisher| first3=Doug | title=Models of incremental concept formation | journal=Artificial Intelligence |volume=40 |issue=1–3 | year=1989| pages=11–61 | doi=10.1016/0004-3702(89)90046-5| url=https://escholarship.org/uc/item/5r51t42n }}
* {{Citation | last1=Gluck| first1=Mark A. | last2=Corter| first2=James E. | year= 1985 | chapter=Information, uncertainty, and the utility of categories | title=Program of the Seventh Annual Conference of the Cognitive Science Society |pages=283–287 }}
* {{Citation | last1=Hanson| first1=Stephen José | last2=Bauer| first2=Malcolm | title=Conceptual clustering, categorization, and polymorphy | journal=Machine Learning |volume=3 |issue=4 | year=1989| pages=343–372 | doi=10.1007/BF00116838| doi-access=free }}
* {{Citation | last=Harnad| first=Stevan | year= 2005| chapter=To cognize is to categorize: Cognition is categorization | editor= Henri Cohen &amp; Claire Lefebvre | title=Handbook of Categorization in Cognitive Science | publisher=Elsevier | place=Amsterdam | chapter-url=http://eprints.ecs.soton.ac.uk/11725/| pages=19–43 }}
* {{Citation | last=Jones| first=Gregory V. | title=Identifying basic categories | journal=Psychological Bulletin |volume=94 |issue=3 | year=1983 | pages=423–428 | doi=10.1037/0033-2909.94.3.423}}
* {{Citation | last1=Kruschke| first1=John K. | last2=Johansen| first2=Mark K. | title=A model of probabilistic category learning | journal=Journal of Experimental Psychology: Learning, Memory, and Cognition |volume=25 |issue=5 | year=1999| pages=1083–1119 | doi=10.1037/0278-7393.25.5.1083| pmid=10505339 }}
* {{Citation | last=Mill| first=John Stuart | title=A System of Logic, Ratiocinative and Inductive: Being a Connected View of the Principles of Evidence and the Methods of Scientific Investigation | publisher=Longmans, Green and Co. | place=London | year=1843| author-link=John Stuart Mill}}.
* {{Citation | last=Murphy| first=Gregory L. | title=Cue validity and levels of categorization | journal=Psychological Bulletin |volume=91 |issue=1 | year=1982| pages=174–177 | doi=10.1037/0033-2909.91.1.174}}
* {{Citation | last=Reed| first=Stephen K. | title=Pattern recognition and categorization | journal=Cognitive Psychology |volume=3 |issue=3 | year=1972 | pages=382–407 | doi=10.1016/0010-0285(72)90014-x}}
* {{Citation | last=Rosch| first=Eleanor| year= 1978| chapter=Principles of categorization | editor= Eleanor Rosch &amp; Barbara B. Lloyd | title=Cognition and Categorization | publisher=Lawrence Erlbaum| place=[[Hillsdale, New Jersey]]| pages=27–48}}
* {{Citation | last1=Rosch| first1=Eleanor | last2=Mervis| first2=Carolyn B.| title=Family Resemblances: Studies in the Internal Structure of Categories | journal=Cognitive Psychology |volume=7 |issue=4 | year=1975 | pages=573–605 | doi=10.1016/0010-0285(75)90024-9| s2cid=17258322 }}
* {{Citation | last1=Smith| first1=Edward E. | last2=Medin| first2=Douglas L. |title=Categories and Concepts | publisher=Harvard University Press | place=[[Cambridge, MA]] | year=1981}}
* {{Citation | last1=Witten| first1=Ian H. | last2=Frank| first2=Eibe |title=Data Mining: Practical Machine Learning Tools and Techniques | publisher=Morgan Kaufmann | place=Amsterdam | year=2005| url=http://www.cs.waikato.ac.nz/~ml/weka/book.html}}
{{refend}}

[[Category:Machine learning|Category utility]]
[[Category:Cognitive science|Category utility]]</text>
      <sha1>2v8ix47dkn1x0qhcaz7qftrz82qhybf</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Support vector machines</title>
    <ns>14</ns>
    <id>31176997</id>
    <revision>
      <id>418738709</id>
      <parentid>418738637</parentid>
      <timestamp>2011-03-14T06:13:17Z</timestamp>
      <contributor>
        <username>X7q</username>
        <id>9215724</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="114" xml:space="preserve">{{catmain|Support vector machine}}

[[Category:Machine learning]]
[[Category:Kernel methods for machine learning]]</text>
      <sha1>se85tg5oezeg6i7yvgollp30luatj65</sha1>
    </revision>
  </page>
  <page>
    <title>Nearest neighbor search</title>
    <ns>0</ns>
    <id>7309022</id>
    <revision>
      <id>992435077</id>
      <parentid>989008109</parentid>
      <timestamp>2020-12-05T07:12:26Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 29 templates: del empty params (1×); hyphenate params (1×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="24829" xml:space="preserve">'''Nearest neighbor search''' ('''NNS'''), as a form of '''proximity search''',  is the [[optimization problem]] of finding the point in a given set that is closest (or most similar) to a given point. Closeness is typically expressed in terms of a dissimilarity function: the less similar the objects, the larger the function values. 

Formally, the nearest-neighbor (NN) search problem is defined as follows: given a set ''S'' of points in a space ''M'' and a query point ''q''&amp;nbsp;∈&amp;nbsp;''M'', find the closest point in ''S'' to ''q''. [[Donald Knuth]] in vol. 3 of ''[[The Art of Computer Programming]]'' (1973) called it the '''post-office problem''', referring to an application of assigning to a residence the nearest post office. A direct generalization of this problem is a ''k''-NN search, where we need to find the ''k'' closest points.

Most commonly ''M'' is a  [[metric space]] and dissimilarity is expressed as a [[distance metric]], which is symmetric and satisfies the [[triangle inequality]]. Even more common, ''M'' is taken to be the ''d''-dimensional [[vector space]] where dissimilarity is measured using the [[Euclidean distance]], [[Taxicab geometry|Manhattan distance]] or other [[Statistical distance|distance metric]]. However, the dissimilarity function can be arbitrary. One example is asymmetric [[Bregman divergence]], for which the triangle inequality does not hold.&lt;ref name=Cayton2008&gt;{{Cite journal
 | last1 = Cayton | first1 = Lawerence
 | year = 2008
 | title =  Fast nearest neighbor retrieval for bregman divergences
 | journal = Proceedings of the 25th International Conference on Machine Learning
 | pages = 112–119
 | doi = 10.1145/1390156.1390171
| isbn = 9781605582054
 }}&lt;/ref&gt;

==Applications==
The nearest neighbour search problem arises in numerous fields of application, including:
* [[Pattern recognition]] – in particular for [[optical character recognition]]
* [[Statistical classification]] – see [[k-nearest neighbor algorithm]]
* [[Computer vision]]
* [[Computational geometry]] – see [[Closest pair of points problem]]
* [[Database]]s – e.g. [[content-based image retrieval]]
* [[Coding theory]] – see [[Decoding methods|maximum likelihood decoding]]
* [[Data compression]] – see [[MPEG-2]] standard
* [[Robotic]] sensing&lt;ref name=panSearch&gt;{{cite conference|last1=Bewley|first1=A.|last2=Upcroft|first2=B.|date=2013|title=Advantages of Exploiting Projection Structure for Segmenting Dense 3D Point Clouds|conference=Australian Conference on Robotics and Automation |url=http://www.araa.asn.au/acra/acra2013/papers/pap148s1-file1.pdf}}&lt;/ref&gt;
* [[Recommender system|Recommendation systems]], e.g. see [[Collaborative filtering]]
* [[Internet marketing]] – see [[contextual advertising]] and [[behavioral targeting]]
* [[DNA sequencing]]
* [[Spell checking]] – suggesting correct spelling
* [[Plagiarism detection]]
* [[Similarity score]]s for predicting career paths of professional athletes.
* [[Cluster analysis]] – assignment of a set of observations into subsets (called clusters) so that observations in the same cluster are similar in some sense, usually based on [[Euclidean distance]]
* [[Chemical similarity]]
* [[Motion planning#Sampling-based algorithms|Sampling-based motion planning]]

==Methods==

Various solutions to the NNS problem have been proposed.  The quality and usefulness of the algorithms are determined by the time complexity of queries as well as the space complexity of any search data structures that must be maintained. The informal observation usually referred to as the [[curse of dimensionality]] states that there is no general-purpose exact solution for NNS in high-dimensional Euclidean space using polynomial preprocessing and polylogarithmic search time.

=== Exact methods ===

====Linear search====
The simplest solution to the NNS problem is to compute the distance from the query point to every other point in the database, keeping track of the "best so far".  This algorithm, sometimes referred to as the naive approach, has a [[running time]] of ''O''(''dN''), where ''N'' is the [[cardinality]] of ''S'' and ''d'' is the dimensionality of ''M''.  There are no search data structures to maintain, so linear search has no space complexity beyond the storage of the database. Naive search can, on average, outperform space partitioning approaches on higher dimensional spaces.&lt;ref&gt;{{cite journal|title=A quantitative analysis and performance study for similarity search methods in high dimensional spaces|last1=Weber|first1=Roger|last2=Schek|first2=Hans-J.|last3=Blott|first3=Stephen | journal=VLDB '98 Proceedings of the 24rd International Conference on Very Large Data Bases | pages=194–205 | year=1998 | url=http://www.vldb.org/conf/1998/p194.pdf}}&lt;/ref&gt;

====Space partitioning====
Since the 1970s, the [[branch and bound]] methodology has been applied to the problem. In the case of Euclidean space this approach encompasses [[spatial index]] or spatial access methods. Several [[Space partitioning|space-partitioning]] methods have been developed for solving the NNS problem.  Perhaps the simplest is the [[k-d tree]], which iteratively bisects the search space into two regions containing half of the points of the parent region.  Queries are performed via traversal of the tree from the root to a leaf by evaluating the query point at each split. Depending on the distance specified in the query, neighboring branches that might contain hits may also need to be evaluated. For constant dimension query time, average complexity is ''O''(log&amp;nbsp;''N'') &lt;ref&gt;{{cite web|title=An introductory tutorial on KD trees|author=Andrew Moore|url=http://www.autonlab.com/autonweb/14665/version/2/part/5/data/moore-tutorial.pdf?branch=main&amp;language=en|access-date=2008-10-03|archive-url=https://web.archive.org/web/20160303203122/http://www.autonlab.com/autonweb/14665/version/2/part/5/data/moore-tutorial.pdf?branch=main&amp;language=en|archive-date=2016-03-03|url-status=dead}}&lt;/ref&gt; in the case of randomly distributed points, worst case complexity is ''O''(''kN''^(1-1/''k''))&lt;ref name=Lee1977&gt;{{Cite journal
 | last1 = Lee | first1 = D. T. | author1-link = Der-Tsai Lee
 | last2 = Wong | first2 = C. K.
 | year = 1977
 | title = Worst-case analysis for region and partial region searches in multidimensional binary search trees and balanced quad trees
 | journal = [[Acta Informatica]]
 | volume = 9
 | issue = 1
 | pages = 23–29
 | doi = 10.1007/BF00263763
 }}&lt;/ref&gt;
Alternatively the [[R-tree]] data structure was designed to support nearest neighbor search in dynamic context, as it has efficient algorithms for insertions and deletions such as the [[R* tree]].&lt;ref&gt;{{Cite conference | doi = 10.1145/223784.223794| chapter = Nearest neighbor queries| title = Proceedings of the 1995 ACM SIGMOD international conference on Management of data – SIGMOD '95| pages = 71| year = 1995| last1 = Roussopoulos | first1 = N. | last2 = Kelley | first2 = S. | last3 = Vincent | first3 = F. D. R. | isbn = 0897917316}}&lt;/ref&gt; R-trees can yield nearest neighbors not only for Euclidean distance, but can also be used with other distances.

In the case of general metric space, the branch-and-bound approach is known as the [[metric tree]] approach. Particular examples include [[vp-tree]] and [[BK-tree]] methods.

Using a set of points taken from a 3-dimensional space and put into a [[Binary space partitioning|BSP tree]], and given a query point taken from the same space, a possible solution to the problem of finding the nearest point-cloud point to the query point is given in the following description of an algorithm.  (Strictly speaking, no such point may exist, because it may not be unique.  But in practice, usually we only care about finding any one of the subset of all point-cloud points that exist at the shortest distance to a given query point.)  The idea is, for each branching of the tree, guess that the closest point in the cloud resides in the half-space containing the query point.  This may not be the case, but it is a good heuristic.  After having recursively gone through all the trouble of solving the problem for the guessed half-space, now compare the distance returned by this result with the shortest distance from the query point to the partitioning plane.  This latter distance is that between the query point and the closest possible point that could exist in the half-space not searched.  If this distance is greater than that returned in the earlier result, then clearly there is no need to search the other half-space.  If there is such a need, then you must go through the trouble of solving the problem for the other half space, and then compare its result to the former result, and then return the proper result.  The performance of this algorithm is nearer to logarithmic time than linear time when the query point is near the cloud, because as the distance between the query point and the closest point-cloud point nears zero, the algorithm needs only perform a look-up using the query point as a key to get the correct result.

=== Approximation methods ===
An approximate nearest neighbor search algorithm is allowed to return points, whose distance from the query is at most &lt;math&gt;c&lt;/math&gt; times the distance from the query to its nearest points. The appeal of this approach is that, in many cases, an approximate nearest neighbor is almost as good as the exact one. In particular, if the distance measure accurately captures the notion of user quality, then small differences in the distance should not matter.&lt;ref&gt;{{Cite book|last=Andoni|first=A.|last2=Indyk|first2=P.|date=2006-10-01|title=Near-Optimal Hashing Algorithms for Approximate Nearest Neighbor in High Dimensions|journal=2006 47th Annual IEEE Symposium on Foundations of Computer Science (FOCS'06)|pages=459–468|doi=10.1109/FOCS.2006.49|isbn=978-0-7695-2720-8|citeseerx=10.1.1.142.3471}}&lt;/ref&gt;

====Greedy search in proximity neighborhood graphs====
Proximity graph methods (such as HNSW&lt;ref name=":0"&gt;{{cite arxiv|last=Malkov|first=Yury|last2=Yashunin|first2=Dmitry|date=2016|title=Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs|eprint=1603.09320|class=cs.DS}}&lt;/ref&gt;) are considered the current state-of-the-art for the approximate nearest neighbors search.&lt;ref name=":0" /&gt;&lt;ref&gt;{{Cite web|url=https://erikbern.com/2018/06/17/new-approximate-nearest-neighbor-benchmarks.html|title=New approximate nearest neighbor benchmarks}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.benfrederickson.com/approximate-nearest-neighbours-for-recommender-systems/|title=Approximate Nearest Neighbours for Recommender Systems}}&lt;/ref&gt;

The methods are based on greedy traversing in proximity neighborhood graphs &lt;math&gt;G(V,E)&lt;/math&gt;in which every point &lt;math&gt;x_i \in S &lt;/math&gt; is uniquely associated with vertex &lt;math&gt;v_i \in V &lt;/math&gt;. The search for the nearest neighbors to a query ''q'' in the set ''S'' takes the form of searching for the vertex in the graph &lt;math&gt;G(V,E)&lt;/math&gt;.
The basic algorithm – greedy search – works as follows: search starts from an enter-point vertex &lt;math&gt;v_i \in V &lt;/math&gt; by computing the distances from the query q to each vertex of its neighborhood &lt;math&gt;\{v_j:(v_i,v_j) \in E\}&lt;/math&gt;, and then finds a vertex with the minimal distance value. If the distance value between the query and the selected vertex is smaller than the one between the query and the current element, then the algorithm moves to the selected vertex, and it becomes new enter-point. The algorithm stops when it reaches a local minimum: a vertex whose neighborhood does not contain a vertex that is closer to the query than the vertex itself.

The idea of proximity neighborhood graphs was exploited in multiple publications, including the seminal paper by Arya and Mount,&lt;ref&gt;{{cite journal|last1=Arya|first1=Sunil|last2=Mount|first2=David|date=1993|title=Approximate Nearest Neighbor Queries in Fixed Dimensions|journal=Proceedings of the Fourth Annual {ACM/SIGACT-SIAM} Symposium on Discrete Algorithms, 25–27 January 1993, Austin, Texas.|pages=271–280}}&lt;/ref&gt; in the VoroNet system for the plane,&lt;ref name="voroNet"&gt;{{Cite journal|last1=Olivier|first1=Beaumont|last2=Kermarrec|first2=Anne-Marie|last3=Marchal|first3=Loris|last4=Rivière|first4=Etienne|year=2006|title=VoroNet: A scalable object network based on Voronoi tessellations|journal=INRIA|volume=RR-5833|issue=1|pages=23–29|doi=10.1109/IPDPS.2007.370210|url=https://hal.inria.fr/inria-00071210/PDF/RR-5833.pdf}}&lt;/ref&gt; in the RayNet system for the &lt;math&gt;\mathbb{E}^n&lt;/math&gt;,&lt;ref name="rayNet"&gt;{{Cite book|last1=Olivier|first1=Beaumont|last2=Kermarrec|first2=Anne-Marie|last3=Rivière|first3=Etienne|year=2007|title=Peer to Peer Multidimensional Overlays: Approximating Complex Structures|journal=Principles of Distributed Systems|volume=4878|pages=315–328|doi=10.1007/978-3-540-77096-1_23|isbn=978-3-540-77095-4|citeseerx=10.1.1.626.2980}}&lt;/ref&gt; and in the Metrized Small World&lt;ref name="msw2014"&gt;{{Cite journal|last1=Malkov|first1=Yury|last2=Ponomarenko|first2=Alexander|last3=Krylov|first3=Vladimir|last4=Logvinov|first4=Andrey|year=2014|title=Approximate nearest neighbor algorithm based on navigable small world graphs|journal=Information Systems|volume=45|pages=61–68|doi=10.1016/j.is.2013.10.006}}&lt;/ref&gt;  and HNSW&lt;ref name=":0" /&gt; algorithms for the general case of spaces with a distance function. These works were preceded by a pioneering paper by Toussaint, in which he introduced the concept of a ''relative neighborhood'' graph.&lt;ref&gt;{{cite journal|last1=Toussaint|first1=Godfried|date=1980|title=The relative neighbourhood graph of a finite planar set|journal=Pattern Recognition|volume=12|issue=4|pages=261–268|doi=10.1016/0031-3203(80)90066-7}}&lt;/ref&gt;

====Locality sensitive hashing====

[[Locality sensitive hashing]] (LSH) is a technique for grouping points in space into 'buckets' based on some distance metric operating on the points. Points that are close to each other under the chosen metric are mapped to the same bucket with high probability.&lt;ref&gt;{{cite web|author1=A. Rajaraman  |author2=J. Ullman |name-list-style=amp | url=http://infolab.stanford.edu/~ullman/mmds.html |title=Mining of Massive Datasets, Ch. 3 |year=2010}}&lt;/ref&gt;

====Nearest neighbor search in spaces with small intrinsic dimension====

The [[cover tree]] has a theoretical bound that is based on the dataset's [[doubling constant]]. The bound on search time is ''O''(''c''&lt;sup&gt;12&lt;/sup&gt;&amp;nbsp;log&amp;nbsp;''n'') where ''c''  is the [[Expansivity constant|expansion constant]] of the dataset.

====Projected radial search====

In the special case where the data is a dense 3D map of geometric points, the projection geometry of the sensing technique can be used to dramatically simplify the search problem.
This approach requires that the 3D data is organized by a projection to a two-dimensional grid and assumes that the data is spatially smooth across neighboring grid cells with the exception of object boundaries.
These assumptions are valid when dealing with 3D sensor data in applications such as surveying, robotics and stereo vision but may not hold for unorganized data in general.
In practice this technique has an average search time of ''O''(''1'')  or ''O''(''K'')  for the ''k''-nearest neighbor problem when applied to real world stereo vision data.
&lt;ref name=panSearch/&gt;

====Vector approximation files====

In high-dimensional spaces, tree indexing structures become useless because an increasing percentage of the nodes need to be examined anyway. To speed up linear search, a compressed version of the feature vectors stored in RAM is used to prefilter the datasets in a first run. The final candidates are determined in a second stage using the uncompressed data from the disk for distance calculation.&lt;ref&gt;{{cite journal|title=An Approximation-Based Data Structure for Similarity Search|last1=Weber|first1=Roger|last2=Blott|first2=Stephen|url=https://pdfs.semanticscholar.org/83e4/e3281411ffef40654a4b5d29dae48130aefb.pdf}}&lt;/ref&gt;

====Compression/clustering based search====
The VA-file approach is a special case of a compression based search, where each feature component is compressed uniformly and independently. The optimal compression technique in multidimensional spaces is [[Vector Quantization]] (VQ), implemented through clustering. The database is clustered and the most "promising" clusters are retrieved. Huge gains over VA-File, tree-based indexes and sequential scan have been observed.&lt;ref&gt;{{cite journal|title=Adaptive cluster-distance bounding for similarity search in image databases|last1=Ramaswamy|first1=Sharadh|last2=Rose|first2=Kenneth|journal=ICIP|date=2007}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|title=Adaptive cluster-distance bounding for high-dimensional indexing|last1=Ramaswamy|first1=Sharadh|last2=Rose|first2=Kenneth|journal=TKDE|date=2010}}&lt;/ref&gt; Also note the parallels between clustering and LSH.

==Variants==

There are numerous variants of the NNS problem and the two most well-known are the [[K-nearest neighbor algorithm|''k''-nearest neighbor search]] and the [[ε-approximate nearest neighbor search]].

===&lt;span id="K-nearest neighbor"&gt; ''k''-nearest neighbors &lt;/span&gt;===

[[K-nearest neighbor algorithm|''k''-nearest neighbor search]] identifies the top ''k'' nearest neighbors to the query.  This technique is commonly used in [[predictive analytics]] to estimate or classify a point based on the consensus of its neighbors. ''k''-nearest neighbor graphs are graphs in which every point is connected to its ''k'' nearest neighbors.

===Approximate nearest neighbor===
In some applications it may be acceptable to retrieve a "good guess" of the nearest neighbor. In those cases, we can use an algorithm which doesn't guarantee to return the actual nearest neighbor in every case, in return for improved speed or memory savings. Often such an algorithm will find the nearest neighbor in a majority of cases, but this depends strongly on the dataset being queried.

Algorithms that support the approximate nearest neighbor search include [[Locality-sensitive hashing#LSH algorithm for nearest neighbor search|locality-sensitive hashing]], [[best bin first]] and [[balanced box-decomposition tree]] based search.&lt;ref&gt;{{cite journal|first1=S.|last1=Arya|author2-link=David Mount|first2=D. M.|last2=Mount|author3-link=Nathan Netanyahu|first3=N. S.|last3=Netanyahu|first4=R.|last4=Silverman|first5=A.|last5=Wu|title=An optimal algorithm for approximate nearest neighbor searching|journal=Journal of the ACM|volume=45|number=6|pages=891–923|date=1998|url=http://www.cse.ust.hk/faculty/arya/pub/JACM.pdf|doi=10.1145/293347.293348|citeseerx=10.1.1.15.3125|access-date=2009-05-29|archive-url=https://web.archive.org/web/20160303232202/http://www.cse.ust.hk/faculty/arya/pub/JACM.pdf|archive-date=2016-03-03|url-status=dead}}&lt;/ref&gt;

===Nearest neighbor distance ratio===

[[Nearest neighbor distance ratio]] does not apply the threshold on the direct distance from the original point to the challenger neighbor but on a ratio of it depending on the distance to the previous neighbor. It is used in [[Content-based image retrieval|CBIR]] to retrieve pictures through a "query by example" using the similarity between local features. More generally it is involved in several [[Pattern matching|matching]] problems.

===Fixed-radius near neighbors===

[[Fixed-radius near neighbors]] is the problem where one wants to efficiently find all points given in [[Euclidean space]] within a given fixed distance from a specified point. The distance is assumed to be fixed, but the query point is arbitrary.

===All nearest neighbors===

For some applications (e.g. [[entropy estimation]]), we may have ''N'' data-points and wish to know which is the nearest neighbor ''for every one of those N points''. This could, of course, be achieved by running a nearest-neighbor search once for every point, but an improved strategy would be an algorithm that exploits the information redundancy between these ''N'' queries to produce a more efficient search. As a simple example: when we find the distance from point ''X'' to point ''Y'', that also tells us the distance from point ''Y'' to point ''X'', so the same calculation can be reused in two different queries.

Given a fixed dimension, a semi-definite positive norm (thereby including every  [[lp space|L&lt;sup&gt;p&lt;/sup&gt; norm]]), and ''n'' points in this space, the nearest neighbour of every point can be found in ''O''(''n''&amp;nbsp;log&amp;nbsp;''n'') time and the ''m'' nearest neighbours of every point can be found in ''O''(''mn''&amp;nbsp;log&amp;nbsp;''n'') time.&lt;ref&gt;{{citation
 | last = Clarkson | first = Kenneth L. | author-link = Kenneth L. Clarkson
 | contribution = Fast algorithms for the all nearest neighbors problem
 | doi = 10.1109/SFCS.1983.16
 | pages = 226–232
 | title = 24th IEEE Symp. Foundations of Computer Science, (FOCS '83)
 | year = 1983| isbn = 978-0-8186-0508-6 }}.&lt;/ref&gt;&lt;ref name=Vaidya&gt;{{Cite journal
 | doi = 10.1007/BF02187718
 | last1 = Vaidya | first1 = P. M.
 | year = 1989
 | title = An ''O''(''n''&amp;nbsp;log&amp;nbsp;''n'') Algorithm for the All-Nearest-Neighbors Problem
 | journal = [[Discrete and Computational Geometry]]
 | volume = 4
 | issue = 1
 | pages = 101–115
 | doi-access = free
 }}&lt;/ref&gt;

==See also==
{{div col|colwidth=20em}}
* [[Ball tree]]
* [[Closest pair of points problem]]
* [[Cluster analysis]]
* [[Content-based image retrieval]]
* [[Curse of dimensionality]]
* [[Digital signal processing]]
* [[Dimension reduction]]
* [[Fixed-radius near neighbors]]
* [[Fourier analysis]]
* [[Instance-based learning]]
* [[k-nearest neighbor algorithm|''k''-nearest neighbor algorithm]]
* [[Linear least squares (mathematics)|Linear least squares]]
* [[Locality sensitive hashing]]
* [[MinHash]]
* [[Multidimensional analysis]]
* [[Nearest-neighbor interpolation]]
* [[Neighbor joining]]
* [[Principal component analysis]]
* [[Range search]]
* [[Similarity learning]]
* [[Singular value decomposition]]
* [[Sparse distributed memory]]
* [[Statistical distance]]
* [[Time series]]
* [[Voronoi diagram]]
* [[Wavelet]]

{{div col end}}

== References ==
=== Citations ===
{{Reflist}}

=== Sources ===
* {{cite journal |last= Andrews |first=L. |title= A template for the nearest neighbor problem |journal = C/C++ Users Journal |volume=19 |number=11 |date= November 2001 |pages=40–49 |issn = 1075-2838 |url = http://www.ddj.com/architect/184401449}}
* {{cite journal |last1=Arya|first1=S. |first2=D.M. |last2=Mount|author2-link=David Mount |first3=N. S. |last3=Netanyahu|author3-link=Nathan Netanyahu |first4=R. |last4=Silverman|author4-link=Ruth Silverman |first5=A. Y. |last5=Wu|author5-link=Angela Y. Wu |title = An Optimal Algorithm for Approximate Nearest Neighbor Searching in Fixed Dimensions |journal= Journal of the ACM |volume = 45 |number=6 |pages= 891–923 |doi=10.1145/293347.293348|year=1998 |citeseerx=10.1.1.15.3125 }}
* {{cite journal |last1=Beyer |first1=K. |last2= Goldstein |first2=J. |last3= Ramakrishnan |first3=R. |last4=Shaft |first4=U. |year = 1999 |title=When is nearest neighbor meaningful? |journal=Proceedings of the 7th ICDT }}
* {{cite journal |first1=Chung-Min |last1= Chen |first2=Yibei |last2=Ling|title=A Sampling-Based Estimator for Top-k Query |journal=ICDE |date=2002 |pages = 617–627 }}
* {{cite book |last=Samet |first=H.|author-link=Hanan Samet |year = 2006 |title= Foundations of Multidimensional and Metric Data Structures |publisher= Morgan Kaufmann |isbn = 978-0-12-369446-1 }}
* {{cite book |last1=Zezula |first1=P. |last2= Amato |first2=G. |last3=Dohnal |first3=V. |last4=Batko |first4=M. |title= Similarity Search – The Metric Space Approach|publisher=Springer |year=2006 |isbn = 978-0-387-29146-8 }}

==Further reading==
* {{cite book | last = Shasha | first = Dennis | title = High Performance Discovery in Time Series | publisher = Springer | location = Berlin | year = 2004 | isbn = 978-0-387-00857-8 }}

==External links==
{{commons category|Nearest neighbours search}}
* [http://simsearch.yury.name/tutorial.html Nearest Neighbors and Similarity Search] – a website dedicated to educational materials, software, literature, researchers, open problems and events related to NN searching. Maintained by Yury Lifshits
* [https://archive.today/20130222061350/http://sswiki.tierra-aoi.net/ Similarity Search Wiki] – a collection of links, people, ideas, keywords, papers, slides, code and data sets on nearest neighbours

{{DEFAULTSORT:Nearest Neighbor Search}}
[[Category:Approximation algorithms]]
[[Category:Classification algorithms]]
[[Category:Data mining]]
[[Category:Discrete geometry]]
[[Category:Geometric algorithms]]
[[Category:Machine learning]]
[[Category:Mathematical optimization]]
[[Category:Search algorithms]]</text>
      <sha1>ru7z7saronyqg8lzcdabxiutiu5rc1n</sha1>
    </revision>
  </page>
  <page>
    <title>Multivariate adaptive regression spline</title>
    <ns>0</ns>
    <id>18475546</id>
    <revision>
      <id>998882621</id>
      <parentid>998882553</parentid>
      <timestamp>2021-01-07T13:17:32Z</timestamp>
      <contributor>
        <username>DigitalChutney</username>
        <id>40350835</id>
      </contributor>
      <comment>Undid revision 998882553 by [[Special:Contributions/103.192.75.64|103.192.75.64]] ([[User talk:103.192.75.64|talk]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="22782" xml:space="preserve">In [[statistics]], '''multivariate adaptive regression splines''' ('''MARS''') is a form of [[regression analysis]] introduced by [[Jerome H. Friedman]] in 1991.&lt;ref&gt;{{Cite journal | last1 = Friedman | first1 = J. H. | doi = 10.1214/aos/1176347963 | title = Multivariate Adaptive Regression Splines | journal = The Annals of Statistics | volume = 19 | issue = 1 | pages = 1–67 | year = 1991 |mr=1091842 | zbl = 0765.62064 | jstor = 2241837| citeseerx = 10.1.1.382.970 }}&lt;/ref&gt; It is a [[non-parametric regression]] technique and can be seen as an extension of [[linear model]]s that automatically models nonlinearities and interactions between variables.

The term "MARS" is trademarked and licensed to Salford Systems. In order to avoid trademark infringements, many open-source implementations of MARS are called "Earth".&lt;ref&gt;[https://cran.r-project.org/web/packages/earth/index.html CRAN Package earth]&lt;/ref&gt;&lt;ref&gt;[http://orange.biolab.si/blog/2011/12/20/earth-multivariate-adaptive-regression-splines/ Earth – Multivariate adaptive regression splines in Orange (Python machine learning library)]&lt;/ref&gt;

== The basics ==

This section introduces MARS using a few examples.  We start with a set of data: a matrix of input variables ''x'', and a vector of the observed responses ''y'', with a response for each row in ''x''. For example, the data could be:

{|
! ''x''    !!  ''y''    
|-
| 10.5 ||  16.4 
|-
| 10.7 ||  18.8 
|-
| 10.8 ||  19.7 
|-
| ...  ||  ...  
|-
| 20.6 ||  77.0
|}

Here there is only one [[Dependent and independent variables|independent variable]], so the ''x'' matrix is just a single column. Given these measurements, we would like to build a model which predicts the expected ''y'' for a given ''x''.

[[File:Friedmans mars linear model.png|frame|right|A linear model]]
A [[linear model]] for the above data is

: &lt;math&gt;
\widehat{y} = -37 + 5.1 x
&lt;/math&gt;
The hat on the &lt;math&gt;\widehat{y}&lt;/math&gt; indicates that &lt;math&gt;\widehat{y}&lt;/math&gt; is estimated from the data.  The figure on the right shows a plot of this function: 
a line giving the predicted &lt;math&gt;\widehat{y}&lt;/math&gt; versus ''x'', with the original values of ''y'' shown as red dots.

The data at the extremes of ''x'' indicates that  the relationship between ''y'' and ''x'' may be non-linear (look at the red dots relative to the regression line at low and high values of ''x'').  We thus turn to MARS to automatically build a model taking into account non-linearities.  MARS software constructs a model from the given ''x'' and ''y'' as follows

: &lt;math&gt;
\begin{align}
\widehat{y} = &amp;\ 25 \\
&amp; {} + 6.1 \max(0, x  - 13) \\
&amp; {} - 3.1 \max(0, 13 - x)
\end{align}
&lt;/math&gt;

[[File:Friedmans mars simple model.png|frame|right|A simple MARS model of the same data]]

The figure on the right shows a plot of this function: the predicted &lt;math&gt;\widehat{y}&lt;/math&gt; versus ''x'', with the original values of ''y'' once again shown as red dots.  The predicted response is now a better fit to the original ''y'' values.

MARS has automatically produced a kink in the predicted ''y'' to take into account non-linearity. The kink is produced by ''hinge functions''. The hinge functions are the expressions starting with &lt;math&gt;\max&lt;/math&gt; (where &lt;math&gt;\max(a,b)&lt;/math&gt; is &lt;math&gt;a&lt;/math&gt; if &lt;math&gt;a &gt; b&lt;/math&gt;, else &lt;math&gt;b&lt;/math&gt;). Hinge functions are described in more detail below.

In this simple example, we can easily see from the plot that ''y'' has a non-linear relationship with ''x'' (and might perhaps guess that y varies with the square of ''x''). However, in general there will be multiple [[Dependent and independent variables|independent variables]], and the relationship between ''y'' and these variables will be unclear and not easily visible by plotting. We can use MARS to discover that non-linear relationship.

An example MARS expression with multiple variables is

: &lt;math&gt;
\begin{align}
  \mathrm{ozone} = &amp;\ 5.2 \\
&amp; {} + 0.93 \max(0, \mathrm{temp} - 58)  \\
&amp; {} - 0.64 \max(0, \mathrm{temp} - 68)  \\
&amp; {} - 0.046 \max(0,  234 - \mathrm{ibt})  \\
&amp; {} - 0.016 \max(0, \mathrm{wind} - 7) \max(0, 200 - \mathrm{vis})
\end{align}
&lt;/math&gt;
[[File:Friedmans mars ozone model.png|frame|right|Variable interaction in a MARS model]]

This expression models air pollution (the ozone level) as a function of the temperature and a few other variables. Note that the last term in the formula (on the last line) incorporates an interaction between &lt;math&gt;\mathrm{wind} &lt;/math&gt; and &lt;math&gt;\mathrm{vis}&lt;/math&gt;.

The figure on the right plots the predicted &lt;math&gt;\mathrm{ozone}&lt;/math&gt; as &lt;math&gt;\mathrm{wind}&lt;/math&gt; and &lt;math&gt;\mathrm{vis}&lt;/math&gt; vary, with the other variables fixed at their median values. The figure shows that wind does not affect the ozone level unless visibility is low. We see that MARS can build quite flexible regression surfaces by combining hinge functions.

To obtain the above expression, the MARS model building procedure automatically selects which variables to use (some variables are important, others not), the positions of the kinks in the hinge functions, and how the hinge functions are combined.

== The MARS model ==

MARS builds models of the form

: &lt;math&gt;\widehat{f}(x) = \sum_{i=1}^k c_i B_i(x). &lt;/math&gt;

The model is a weighted sum of basis functions
&lt;math&gt;B_i(x)&lt;/math&gt;.
Each &lt;math&gt;c_i&lt;/math&gt; is a constant coefficient.
For example, each line in the formula for ozone above is one basis function
multiplied by its coefficient.

Each [[basis function]] &lt;math&gt;B_i(x)&lt;/math&gt; takes one of the following three forms:

1) a constant 1. There is just one such term, the intercept.
In the ozone formula above, the intercept term is 5.2.

2) a ''hinge'' function. A hinge function has the form  &lt;math&gt; \max(0, x - \text{constant}) &lt;/math&gt; or  &lt;math&gt; \max(0, \text{constant} - x) &lt;/math&gt;. MARS automatically selects variables and values of those variables for knots of the hinge functions. Examples of such basis functions can be seen in the middle three lines of the ozone formula.

3) a product of two or more hinge functions.
These basis functions can model interaction between two or more variables.
An example is the last line of the ozone formula.

== Hinge functions ==

[[File:Friedmans mars hinge functions.png|frame|right|A mirrored pair of hinge functions with a knot at x=3.1]]

Hinge functions are a key part of MARS models. A hinge function takes the form
: &lt;math&gt;\max(0,x-c)&lt;/math&gt;
or 
: &lt;math&gt;\max(0,c-x)&lt;/math&gt;
where &lt;math&gt;c&lt;/math&gt; is a constant, called the ''knot''.
The figure on the right shows a mirrored pair of hinge functions with a knot at 3.1.

A hinge function is zero for part of its range, so  can be used to partition the data into disjoint regions, each of which can be treated independently. Thus for example a mirrored pair of hinge functions in the expression
: &lt;math&gt;
6.1 \max(0, x  - 13)
- 3.1 \max(0, 13 - x)
&lt;/math&gt;
creates the [[piecewise]] linear graph shown for the simple MARS model in the previous section.

One might assume that only piecewise linear functions can be formed from hinge functions, but hinge functions can be multiplied together to form non-linear functions.

Hinge functions are also called [[ramp function|ramp]], [[Ice hockey stick|hockey stick]], or [[Rectifier (neural networks)|rectifier]] functions. Instead of the &lt;math&gt;\max&lt;/math&gt; notation used in this article, hinge functions are often represented by &lt;math&gt;[\pm(x_i - c)]_+&lt;/math&gt; where &lt;math&gt;[\cdot]_+&lt;/math&gt; means take the positive part.

== The model building process ==
{{see also|Stepwise regression}}

MARS builds a model in two phases:
the forward and the backward pass.
This two-stage approach is the same as that used by 
[[recursive partitioning]] trees.

=== The forward pass ===

MARS starts with a model which consists of just the intercept term
(which is the mean of the response values).

MARS then repeatedly adds basis function in pairs to the model. At each step it finds the pair of basis functions that gives the maximum reduction in sum-of-squares [[Errors and residuals in statistics|residual]] error (it is a [[greedy algorithm]]). The two basis functions in the pair are identical except that a different side of a mirrored hinge function is used for each function. Each new basis function consists of a term already in the model (which could perhaps be the intercept term) multiplied by a new hinge function. A hinge function is defined by a variable and a knot, so to add a new basis function, MARS must search over all combinations of the following:

1) existing terms (called ''parent terms'' in this context)

2) all variables (to select one for the new basis function)

3) all values of each variable (for the knot of the new hinge function).

To calculate the coefficient of each term MARS applies a linear regression over the terms.

This process of adding terms continues until the change in residual error is too small to continue or until the maximum number of terms is reached. The maximum number of terms is specified by the user before model building starts.

The search at each step is done in a [[Brute-force search|brute-force]] fashion, but a key aspect of MARS is that because of the nature of hinge functions the search can be done relatively quickly using a fast least-squares update technique. Actually, the search is not quite brute force. The search can be sped up with  a [[Heuristics|heuristic]]  that reduces the number of parent terms to consider at each step ("Fast MARS"&lt;ref&gt;[[Friedman, J. H.]] (1993) ''Fast MARS'', Stanford University Department of Statistics, Technical Report 110&lt;/ref&gt;).

=== The backward pass ===

The forward pass usually builds an [[overfit]] model. (An overfit model has a good fit to the data used to build the model but will not generalize well to new data.) To build a model with better generalization ability, the backward pass prunes the model. It removes terms one by one, deleting the least effective term at each step until it finds the best submodel. Model subsets are compared using the GCV criterion described below.

The backward pass has an advantage over the forward pass: at any step it can choose any term to delete, whereas the forward pass at each step can only see the next pair of terms.

The forward pass adds terms in pairs, but the backward pass typically discards one side of the pair and so terms are often not seen in pairs in the final model. A paired hinge can be seen in the equation for &lt;math&gt;\widehat{y}&lt;/math&gt; in the first MARS example above; there are no complete pairs retained in the ozone example.

==== Generalized cross validation ====
{{further|Cross-validation (statistics)|Model selection}}

The backward pass uses generalized cross validation (GCV) to compare the performance of model subsets in order to choose the best subset: lower values of GCV are better. The GCV is a form of [[Regularization (machine learning)|regularization]]: it trades off goodness-of-fit against model complexity.

(We want to estimate how well a model performs on ''new'' data, not on the training data.  Such new data is usually not available at the time of model building, so instead we use GCV to estimate what performance would be on new data.  The raw [[Residual sum of squares|residual sum-of-squares]] (RSS) on the training data is inadequate for comparing models, because the RSS always increases as MARS terms are dropped.  In other words, if the RSS were used to compare models, the backward pass would always choose the largest model—but the largest model typically does not have the best generalization performance.)

The formula for the GCV is

: GCV = RSS / (''N'' · (1 − (effective number of parameters) / ''N'')&lt;sup&gt;2&lt;/sup&gt;)

where RSS is the residual sum-of-squares measured on the training data and ''N'' is the number of observations (the number of rows in the '''x''' matrix).

The ''EffectiveNumberOfParameters'' is defined in
the MARS context as

: (effective number of parameters) = (number of mars terms) + (penalty) · ((number of Mars terms) − 1 ) / 2

where '''penalty''' is about 2 or 3 (the MARS software allows the user to preset penalty).

Note that 

: (number of Mars terms − 1 ) / 2

is the number of hinge-function knots, so the formula penalizes the addition of knots. Thus the GCV formula adjusts (i.e. increases) the training RSS to take into account the flexibility of the model. We penalize flexibility because models that are too flexible will model the specific realization of noise in the data instead of just the systematic structure of the data.

Generalized cross-validation is so named because it uses a formula to approximate the error that would be determined by leave-one-out validation. It is just an approximation but works well in practice. GCVs were introduced by Craven and [[Grace Wahba|Wahba]] and extended by Friedman for MARS.

=== Constraints ===

One constraint has already been mentioned: the user
can specify the maximum number of terms in the forward pass.

A further constraint can be placed on the forward pass
by specifying a maximum allowable degree of interaction.
Typically only one or two degrees of interaction are allowed,
but higher degrees can be used when the data warrants it.
The maximum degree of interaction in the first MARS example
above is one (i.e. no interactions or an ''additive model''); 
in the ozone example it is two.

Other constraints on the forward pass are possible.
For example, the user can specify that interactions are allowed 
only for certain input variables.
Such constraints could make sense because of knowledge
of the process that generated the data.

== Pros and cons ==
{{original research|date=October 2016}}

No regression modeling technique is best for all situations.
The guidelines below are intended to give an idea of the pros and cons of MARS, 
but there will be exceptions to the guidelines.
It is useful to compare MARS to [[recursive partitioning]] and this is done below.
(Recursive partitioning is also commonly called ''regression trees'',
''decision trees'', or [[Predictive analytics#Classification and regression trees|CART]];
see the [[Decision tree learning|recursive partitioning]] article for details).

*MARS models are more flexible than [[linear regression]] models.
*MARS models are simple to understand and interpret.&lt;ref name=":0"&gt;{{Cite book|title=Applied Predictive Modeling|last=Kuhn|first=Max|last2=Johnson|first2=Kjell|date=2013|publisher=Springer New York|isbn=9781461468486|location=New York, NY|language=en|doi=10.1007/978-1-4614-6849-3}}&lt;/ref&gt; Compare the equation for ozone concentration above to, say, the innards of a trained [[Artificial neural network|neural network]] or a [[random forest]].
*MARS can handle both continuous and categorical data.&lt;ref&gt;[[Friedman, J. H.]] (1993) ''Estimating Functions of Mixed Ordinal and Categorical Variables Using Adaptive Splines'', New Directions in Statistical Data Analysis and Robustness (Morgenthaler, Ronchetti, Stahel, eds.), Birkhauser&lt;/ref&gt; MARS tends to be better than recursive partitioning for numeric data because hinges are more appropriate for numeric variables than the piecewise constant segmentation used by recursive partitioning.
*Building MARS models often requires little or no data preparation.&lt;ref name=":0" /&gt; The hinge functions automatically partition the input data, so the effect of outliers is contained. In this respect MARS is similar to [[recursive partitioning]] which also partitions the data into disjoint regions, although using a different method. (Nevertheless, as with most statistical modeling techniques, known outliers should be considered for removal before training a MARS model.{{Citation needed|date=March 2019}})
*MARS (like recursive partitioning) does automatic [[Feature selection|variable selection]] (meaning it includes important variables in the model and excludes unimportant ones). However, there can be some arbitrariness in the selection, especially when there are correlated predictors, and this can affect interpretability&lt;ref name=":0" /&gt;
*MARS models tend to have a good bias-variance trade-off. The models are flexible enough to model non-linearity and variable interactions (thus MARS models have fairly low bias), yet the constrained form of MARS basis functions prevents too much flexibility (thus MARS models have fairly low variance).
*MARS is suitable for handling fairly large datasets. It is a routine matter to build a MARS model from an input matrix with, say, 100 predictors and 10&lt;sup&gt;5&lt;/sup&gt; observations.  Such a model can be built in about a minute on a 1&amp;nbsp;GHz machine, assuming the maximum degree of interaction of MARS terms is limited to one (i.e. additive terms only).  A degree two model with the same data on the same 1&amp;nbsp;GHz machine takes longer—about 12 minutes.  Be aware that these times are highly data dependent. Recursive partitioning is much faster than MARS.{{Citation needed|date=March 2019}}
*With MARS models, as with any non-parametric regression, parameter confidence intervals and other checks on the model cannot be calculated directly (unlike [[linear regression]] models). [[Cross-validation (statistics)|Cross-validation]] and related techniques must be used for validating the model instead.
*MARS models do not give as good fits as [[Boosting (meta-algorithm)|boosted]] trees, but can be built much more quickly and are more interpretable. (An 'interpretable' model is in a form that makes it clear what the effect of each predictor is.)
*The &lt;code&gt;earth&lt;/code&gt;, &lt;code&gt;mda&lt;/code&gt;, and &lt;code&gt;polspline&lt;/code&gt; implementations do not allow missing values in predictors, but free implementations of regression trees (such as &lt;code&gt;rpart&lt;/code&gt; and &lt;code&gt;party&lt;/code&gt;) do allow missing values using a technique called surrogate splits.
*MARS models can make predictions quickly.  The prediction function simply has to evaluate the MARS model formula.  Compare that to making a prediction with say a [[Support Vector Machine]], where every variable has to be multiplied by the corresponding element of every support vector.  That can be a slow process if there are many variables and many support vectors.
*The resulting fitted function is not smooth (not differentiable along hinges).

== Extensions and related concepts ==
* [[Generalized linear model]]s (GLMs) can be incorporated into MARS models by applying a link function after the MARS model is built. Thus, for example, MARS models can incorporate [[logistic regression]] to predict probabilities.
* [[Nonlinear regression|Non-linear regression]] is used when the underlying form of the function is known and regression is used only to estimate the parameters of that function. MARS, on the other hand, estimates the functions themselves, albeit with severe constraints on the nature of the functions. (These constraints are necessary because discovering a model from the data is an [[inverse problem]] that is not [[Well-posed problem|well-posed]] without constraints on the model.)
* [[Recursive partitioning]] (commonly called CART). MARS can be seen as a generalization of recursive partitioning that allows the model to better handle numerical (i.e. non-categorical) data.
* [[Generalized additive model]]s. From the user's perspective GAMs are similar to MARS but (a) fit smooth [[Local regression|loess]] or polynomial [[Spline (mathematics)|splines]] instead of MARS basis functions, and (b) do not automatically model variable interactions. The fitting method used internally by GAMs is very different from that of MARS.  For models that do not require automatic discovery of variable interactions GAMs often compete favorably with MARS.
* [[TSMARS]]. Time Series Mars is the term used when MARS models are applied in a time series context. Typically in this set up the predictors are the lagged time series values resulting in autoregressive spline models. These models and extensions to include moving average spline models are described in "Univariate Time Series Modelling and Forecasting using TSMARS: A study of threshold time series autoregressive, seasonal and moving average models using TSMARS".

== See also ==
* [[Linear regression]]
* [[Local regression]]
* [[Rational function modeling]]
* [[Segmented regression]]
* [[Spline interpolation]]
* [[Spline regression]]

== References ==
{{reflist}}

== Further reading ==
* Hastie T., Tibshirani R., and Friedman J.H. (2009) [http://www-stat.stanford.edu/~tibs/ElemStatLearn ''The Elements of Statistical Learning''], 2nd edition. Springer, {{ISBN|978-0-387-84857-0}} (has a section on MARS)
* Faraway J. (2005) [http://www.maths.bath.ac.uk/~jjf23 ''Extending the Linear Model with R''], CRC, {{ISBN|978-1-58488-424-8}} (has an example using MARS with R)
* Heping Zhang and Burton H. Singer (2010) [https://www.amazon.com/Recursive-Partitioning-Applications-Springer-Statistics/dp/1441968237 ''Recursive Partitioning and Applications''], 2nd edition. Springer, {{ISBN|978-1-4419-6823-4}} (has a chapter on MARS and discusses some tweaks to the algorithm)
* Denison D.G.T., Holmes C.C., Mallick B.K., and Smith A.F.M. (2004) [http://www.stat.tamu.edu/~bmallick/wileybook/book_code.html ''Bayesian Methods for Nonlinear Classification and Regression''], Wiley, {{ISBN|978-0-471-49036-4}}
* Berk R.A. (2008) ''Statistical learning from a regression perspective'', Springer, {{ISBN|978-0-387-77500-5}}

== External links ==
{{external cleanup|date=October 2016}}
Several free and commercial software packages are available for fitting MARS-type models.

; Free software:
* [[R (programming language)|R]] packages:
** &lt;code&gt;earth&lt;/code&gt; function in the &lt;code&gt;[https://cran.r-project.org/web/packages/earth/index.html earth]&lt;/code&gt; package
** &lt;code&gt;mars&lt;/code&gt; function in the &lt;code&gt;[https://cran.r-project.org/web/packages/mda/index.html mda]&lt;/code&gt; package
** &lt;code&gt;polymars&lt;/code&gt; function in the &lt;code&gt;[https://cran.r-project.org/web/packages/polspline/index.html polspline]&lt;/code&gt; package.  Not Friedman's MARS.
* Matlab code:
** [http://www.cs.rtu.lv/jekabsons/regression.html ARESLab: Adaptive Regression Splines toolbox for Matlab]
* Python
** [http://orange.biolab.si/blog/2011/12/20/earth-multivariate-adaptive-regression-splines/ Earth – Multivariate adaptive regression splines]
** [https://github.com/jcrudy/py-earth/ py-earth]

; Commercial software:
* [http://www.salford-systems.com/mars.php MARS] from Salford Systems. Based on Friedman's implementation.
* [https://web.archive.org/web/20101203023609/http://www.statsoft.com/products/data-mining-solutions/ STATISTICA Data Miner] from StatSoft
* [http://support.sas.com/documentation/cdl/en/statug/65328/HTML/default/viewer.htm#statug_adaptivereg_overview.htm ADAPTIVEREG] from SAS.

[[Category:Nonparametric regression]]
[[Category:Machine learning]]</text>
      <sha1>190je0is5gqbs9pdb64l831ji9twgji</sha1>
    </revision>
  </page>
  <page>
    <title>Statistical relational learning</title>
    <ns>0</ns>
    <id>19667111</id>
    <revision>
      <id>1000489546</id>
      <parentid>972513950</parentid>
      <timestamp>2021-01-15T08:52:52Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>References after punctuation per [[WP:REFPUNCT]], [[WP:CITEFOOT]], [[WP:PAIC]] + other fixes</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="6806" xml:space="preserve">{{short description|Subdiscipline of artificial intelligence}}
'''Statistical relational learning''' ('''SRL''') is a subdiscipline of [[artificial intelligence]] and [[machine learning]] that is concerned with [[domain model]]s that exhibit both [[uncertainty]] (which can be dealt with using statistical methods) and complex, [[relation (mathematics)|relational]] structure.
&lt;ref name=getoor:book07 /&gt;
&lt;ref name=rossi:jair12 /&gt;
Note that SRL is sometimes called Relational Machine Learning (RML) in the literature. Typically, the [[knowledge representation]] formalisms developed in SRL use (a subset of) [[first-order logic]] to describe relational properties of a domain in a general manner ([[universal quantification]]) and draw upon [[probabilistic graphical model]]s (such as [[Bayesian network]]s or [[Markov network]]s) to model the uncertainty; some also build upon the methods of [[inductive logic programming]]. Significant contributions to the field have been made since the late 1990s.
&lt;ref name=getoor:book07 /&gt;

As is evident from the characterization above, the field is not strictly limited to learning aspects; it is equally concerned with [[Semantic reasoner|reasoning]] (specifically [[statistical inference|probabilistic inference]]) and [[knowledge representation]]. Therefore, alternative terms that reflect the main foci of the field include ''statistical relational learning and reasoning'' (emphasizing the importance of reasoning) and ''first-order probabilistic languages'' (emphasizing the key properties of the languages with which models are represented).

== Canonical tasks ==
A number of canonical tasks are associated with statistical relational learning, the most common ones being.&lt;ref name=richardson:ml06 /&gt;

* [[collective classification]], i.e. the (simultaneous) [[classification (machine learning)|prediction of the class]] of several objects given objects' attributes and their relations
* [[link prediction]], i.e. predicting whether or not two or more objects are related
* [[link-based clustering]], i.e. the [[cluster analysis|grouping]] of similar objects, where similarity is determined according to the links of an object, and the related task of [[collaborative filtering]], i.e. the filtering for information that is relevant to an entity (where a piece of information is considered relevant to an entity if it is known to be relevant to a similar entity).
* [[social network]] modelling
* [[record linkage|object identification/entity resolution/record linkage]], i.e. the identification of equivalent entries in two or more separate databases/datasets

== Representation formalisms ==
{{More footnotes|date=June 2011}}

One of the fundamental design goals of the representation formalisms developed in SRL is to abstract away from concrete entities and to represent instead general principles that are intended to be universally applicable. Since there are countless ways in which such principles can be represented, many representation formalisms have been proposed in recent years.&lt;ref name=getoor:book07 /&gt; In the following, some of the more common ones are listed in alphabetical order:

* [[Bayesian logic program]]
* [[BLOG model]]
* Logic programs with annotated disjunctions
* [[Markov logic network]]s
* [[Multi-entity Bayesian network]]
* Probabilistic relational model – a Probabilistic Relational Model (PRM) is the counterpart of a [[Bayesian network]] in statistical relational learning.&lt;ref name=friedman:ijcai99 /&gt;&lt;ref name=sommestad:compsec10 /&gt;
* [[Probabilistic soft logic]]
* [[Recursive random field]]
* [[Relational Bayesian network]]
* [[Relational dependency network]]
* [[Relational Markov network]]
* [[Relational Kalman filtering]]

== See also ==
* [[Association rule learning]]
* [[Formal concept analysis]]
* [[Fuzzy logic]]
* [[Grammar induction]]

== Resources ==
* Brian Milch, and [[Stuart J. Russell]]: ''[ftp://nozdr.ru/biblio/kolxo3/Cs/CsLn/Inductive%20Logic%20Programming,%2016%20conf.,%20ILP%202006(LNCS4455,%20Springer,%202006)(ISBN%203540738460)(466s).pdf#page=20 First-Order Probabilistic Languages: Into the Unknown]'', Inductive Logic Programming, volume 4455 of [[Lecture Notes in Computer Science]], page 10–24. Springer, 2006
* Rodrigo de Salvo Braz, Eyal Amir, and [[Dan Roth]]: ''[http://www.ai.sri.com/~braz/papers/sci-chapter.pdf A Survey of First-Order Probabilistic Models]'', Innovations in Bayesian Networks, volume 156 of Studies in Computational Intelligence, Springer, 2008
* Hassan Khosravi and Bahareh Bina: ''[http://www.cs.ubc.ca/~hkhosrav/pub/survey.pdf A Survey on Statistical Relational Learning]'', Advances in Artificial Intelligence, Lecture Notes in Computer Science, Volume 6085/2010, 256–268, Springer, 2010
* Ryan A. Rossi, Luke K. McDowell, David W. Aha, and [[Jennifer Neville]]: ''[http://www.jair.org/media/3659/live-3659-6589-jair.pdf Transforming Graph Data for Statistical Relational Learning]'', Journal of Artificial Intelligence Research (JAIR), Volume 45, page 363-441, 2012
*  [[Luc De Raedt]], [[Kristian Kersting]], [[Sriraam Natarajan]] and [[David Poole (researcher)|David Poole]], "Statistical Relational Artificial Intelligence: Logic, Probability, and Computation", Synthesis Lectures on Artificial Intelligence and Machine Learning" March 2016 {{ISBN|9781627058414}}.

== References ==
{{reflist|
refs=
&lt;ref name=getoor:book07&gt;
   {{cite book |last1=Getoor |first1=Lise |last2=Taskar |first2=Ben |author-link1=Lise Getoor |author-link2=Ben Taskar |date=2007 |title=Introduction to Statistical Relational Learning |url=https://linqs.github.io/linqs-website/publications/#id:getoor-book07 |publisher=MIT Press |isbn=978-0262072885}}
&lt;/ref&gt;
&lt;ref name=rossi:jair12&gt;
   Ryan A. Rossi, Luke K. McDowell, David W. Aha, and Jennifer Neville, "[http://www.jair.org/media/3659/live-3659-6589-jair.pdf  Transforming Graph Data for Statistical Relational Learning.]"  ''Journal of Artificial Intelligence Research (JAIR)'', '''Volume 45''' (2012), pp. 363-441.
&lt;/ref&gt;
&lt;ref name=richardson:ml06&gt;
   Matthew Richardson and [[Pedro Domingos]], [http://www.cs.washington.edu/homes/pedrod/papers/mlj05.pdf  "Markov Logic Networks.]"  ''Machine Learning'', '''62''' (2006), pp. 107–136.
&lt;/ref&gt;
&lt;ref name=friedman:ijcai99&gt;
   Friedman N, Getoor L, Koller D, Pfeffer A. (1999) [https://www.biostat.wisc.edu/~page/lprm-ijcai99.pdf "Learning probabilistic relational models"]. In: ''International joint conferences on artificial intelligence'', 1300–09
&lt;/ref&gt;
&lt;ref name=sommestad:compsec10&gt;
   Teodor Sommestad, Mathias Ekstedt, Pontus Johnson (2010) "A probabilistic relational model for security risk analysis", ''Computers &amp; Security'', 29 (6), 659-679 {{DOI|10.1016/j.cose.2010.02.002}}
&lt;/ref&gt;
}}

[[Category:Computational statistics]]
[[Category:Machine learning]]</text>
      <sha1>jgdpp1cyte5tszoo6zry9fejchwgakj</sha1>
    </revision>
  </page>
  <page>
    <title>Hyperparameter (machine learning)</title>
    <ns>0</ns>
    <id>32402755</id>
    <revision>
      <id>984957886</id>
      <parentid>976052404</parentid>
      <timestamp>2020-10-23T03:14:49Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <comment>Alter: template type. Add: s2cid. | You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | Suggested by AManWithNoPlan | All pages linked from cached copy of User:AManWithNoPlan/sandbox3 | via #UCB_webform_linked 1245/1471</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="11973" xml:space="preserve">{{distinguish|Hyperparameter (Bayesian)}}

In [[machine learning]], a '''hyperparameter''' is a [[parameter]] whose value is used to control the learning process. By contrast, the values of other parameters (typically node weights) are derived via training.

Hyperparameters can be classified as model hyperparameters, that cannot be inferred while [[Model fitting|fitting the machine to the training set]] because they refer to the [[model selection]] task, or algorithm hyperparameters, that in principle have no influence on the performance of the model but affect the speed and quality of the learning process. An example of a model hyperparameter is the topology and size of a neural network. Examples of algorithm hyperparameters are [[learning rate]] and mini-[[batch size]].{{clarify|date=April 2020}}

Different model training algorithms require different hyperparameters, some simple algorithms (such as [[ordinary least squares]] regression) require none. Given these hyperparameters, the training algorithm learns the parameters from the data. For instance, [[LASSO]] is an algorithm that adds a [[Regularization (mathematics)|regularization]] hyperparameter to [[ordinary least squares]] regression, which has to be set before estimating the parameters through the training algorithm.

== Considerations ==
The time required to train and test a model can depend upon the choice of its hyperparameters.&lt;ref name=abs1502.02127&gt;{{cite news |arxiv=1502.02127 |title=Claesen, Marc, and Bart De Moor. "Hyperparameter Search in Machine Learning." arXiv preprint arXiv:1502.02127 (2015).|bibcode=2015arXiv150202127C}}&lt;/ref&gt; A hyperparameter is usually of continuous or integer type, leading to mixed-type optimization problems.&lt;ref name=abs1502.02127/&gt; The existence of some hyperparameters is conditional upon the value of others, e.g. the size of each hidden layer in a neural network can be conditional upon the number of layers.&lt;ref name=abs1502.02127/&gt;

=== Difficulty learnable parameters ===

Usually, but not always, hyperparameters cannot be learned using well known gradient based methods (such as gradient descent, LBFGS) - which are commonly employed to learn parameters. These hyperparameters are those parameters describing a model representation that cannot be learned by common optimization methods but nonetheless affect the loss function. An example would be the tolerance hyperparameter for errors in support vector machines.

=== Untrainable parameters ===

Sometimes, hyperparameters cannot be learned from the training data because they aggressively increase the capacity of a model and can push the loss function to a bad minimum - overfitting to, and picking up noise, in the data - as opposed to correctly mapping the richness of the structure in the data. For example - if we treat the degree of a polynomial equation fitting a regression model as a [[trainable parameter]] - this would just raise the degree up until the model perfectly fit the data, giving small training error - but bad generalization performance.

=== Tunability ===
Most performance variation can be attributed to just a few hyperparameters.&lt;ref name=hutter14&gt;{{Cite journal|url=http://proceedings.mlr.press/v32/hutter14.html|title=An Efficient Approach for Assessing Hyperparameter Importance|first1=Kevin|last1=Leyton-Brown|first2=Holger|last2=Hoos|first3=Frank|last3=Hutter|date=January 27, 2014|pages=754–762|via=proceedings.mlr.press}}&lt;/ref&gt;&lt;ref name=abs1502.02127/&gt;&lt;ref name=abs1710.04725&gt;{{cite news |arxiv=1710.04725 |title=van Rijn, Jan N., and Frank Hutter. "Hyperparameter Importance Across Datasets." arXiv preprint arXiv:1710.04725 (2017).|bibcode=2017arXiv171004725V}}&lt;/ref&gt; The tunability of an algorithm, hyperparameter, or interacting hyperparameters is a measure of how much performance can be gained by tuning it.&lt;ref name=arXiv:1802.09596&gt;{{cite news |arxiv=1802.09596 |title=Probst, Philipp, Bernd Bischl, and Anne-Laure Boulesteix. "Tunability: Importance of Hyperparameters of Machine Learning Algorithms." arXiv preprint arXiv:1802.09596 (2018).|bibcode=2018arXiv180209596P}}&lt;/ref&gt; For an [[Long short-term memory|LSTM]], while the [[learning rate]] followed by the network size are its most crucial hyperparameters,&lt;ref name=pmid27411231&gt;{{Cite journal|title=LSTM: A Search Space Odyssey|first1=K.|last1=Greff|first2=R. K.|last2=Srivastava|first3=J.|last3=Koutník|first4=B. R.|last4=Steunebrink|first5=J.|last5=Schmidhuber|date=October 23, 2017|journal=IEEE Transactions on Neural Networks and Learning Systems|volume=28|issue=10|pages=2222–2232|doi=10.1109/TNNLS.2016.2582924|pmid=27411231|arxiv=1503.04069|s2cid=3356463}}&lt;/ref&gt; batching and momentum have no significant effect on its performance.&lt;ref name=abs1508.02774&gt;{{cite news |arxiv=1508.02774 |title=Breuel, Thomas M. "Benchmarking of LSTM networks." arXiv preprint arXiv:1508.02774 (2015).|bibcode=2015arXiv150802774B}}&lt;/ref&gt;

Although some research has advocated the use of mini-batch sizes in the thousands, other work has found the best performance with mini-batch sizes between 2 and 32.&lt;ref name=arXiv:1804.07612&gt;{{cite news |arxiv=1804.07612 |title=Revisiting Small Batch Training for Deep Neural Networks (2018).|bibcode=2018arXiv180407612M}}&lt;/ref&gt;

=== Robustness ===
An inherent stochasticity in learning directly implies that the empirical hyperparameter performance is not necessarily its true performance.&lt;ref name=abs1502.02127/&gt; Methods that are not robust to simple changes in hyperparameters, [[random seed]]s, or even different implementations of the same algorithm cannot be integrated into mission critical control systems without significant simplification and robustification.&lt;ref name=arXiv:1803.07055&gt;{{cite news |arxiv=1803.07055 |title=Mania, Horia, Aurelia Guy, and Benjamin Recht. "Simple random search provides a competitive approach to reinforcement learning." arXiv preprint arXiv:1803.07055 (2018).|bibcode=2018arXiv180307055M}}&lt;/ref&gt;

[[Reinforcement learning]] algorithms, in particular, require measuring their performance over a large number of random seeds, and also measuring their sensitivity to choices of hyperparameters.&lt;ref name=arXiv:1803.07055/&gt; Their evaluation with a small number of random seeds does not capture performance adequately due to high variance.&lt;ref name=arXiv:1803.07055/&gt; Some reinforcement learning methods, e.g. DDPG (Deep Deterministic Policy Gradient), are more sensitive to hyperparameter choices than others.&lt;ref name=arXiv:1803.07055/&gt;

== Optimization ==
{{main|Hyperparameter optimization}}

Hyperparameter optimization finds a tuple of hyperparameters that yields an optimal model which minimizes a predefined [[loss function]] on given test data.&lt;ref name=abs1502.02127/&gt;  The objective function takes a tuple of hyperparameters and returns the associated loss.&lt;ref name=abs1502.02127/&gt;

== Reproducibility ==
Apart from tuning hyperparameters, machine learning involves storing and organizing the parameters and results, and making sure they are reproducible.&lt;ref name=sacred2015&gt;{{cite news |url=https://indico.lal.in2p3.fr/event/2914/contributions/6476/subcontributions/169/attachments/6034/7159/Sacred_3.pdf |title=Greff, Klaus, and Jürgen Schmidhuber. "Introducing Sacred: A Tool to Facilitate Reproducible Research." |year=2015}}&lt;/ref&gt; In the absence of a robust infrastructure for this purpose, research code often evolves quickly and compromises essential aspects like bookkeeping and [[reproducibility]].&lt;ref name=sacred2017&gt;{{cite news |url=http://conference.scipy.org/proceedings/scipy2017/pdfs/klaus_greff.pdf |title=Greff, Klaus, et al. "The Sacred Infrastructure for Computational Research." |year=2017}}&lt;/ref&gt; Online collaboration platforms for machine learning go further by allowing scientists to automatically share, organize and discuss experiments, data, and algorithms.&lt;ref name=arXiv:1407.7722&gt;{{cite news |arxiv=1407.7722 |title=Vanschoren, Joaquin, et al. "OpenML: networked science in machine learning." arXiv preprint arXiv:1407.7722 (2014).|bibcode=2014arXiv1407.7722V}}&lt;/ref&gt; Reproducibility can be particularly difficult for [[deep learning]] models.&lt;ref&gt;{{cite web |url=https://determined.ai/blog/reproducibility-in-ml/ |title=Reproducibility in ML: why it matters and how to achieve it |last1=Villa |first1=Jennifer |last2= Zimmerman |first2=Yoav |date=25 May 2018 |website=Determined AI Blog |access-date=31 August 2020}}&lt;/ref&gt;

A number of relevant services and open source software exist:

=== Services ===
&lt;!--Add in alphabetical order.--&gt;
{| class="wikitable sortable"
|-
! Name !! Interfaces
|-
| [https://www.comet.ml/ Comet.ml]&lt;ref name=kdn-cometml&gt;{{Cite web|url=https://www.kdnuggets.com/2018/04/comet-ml-machine-learning-experiment-management.html|title=Comet.ml – Machine Learning Experiment Management}}&lt;/ref&gt; || Python&lt;ref name=pypi_cometml&gt;{{Cite web|url=https://www.comet.ml/|title=comet-ml: Supercharging Machine Learning|first=Comet ML|last=Inc|via=PyPI}}&lt;/ref&gt;
|-
| [https://www.openml.org/ OpenML]&lt;ref name=openml2013&gt;{{cite book |title=Van Rijn, Jan N., et al. "OpenML: A collaborative science platform." Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, Berlin, Heidelberg, 2013.|volume=7908|pages=645–649|doi=10.1007/978-3-642-40994-3_46|chapter = OpenML: A Collaborative Science Platform|series = Lecture Notes in Computer Science|year = 2013|last1 = Van Rijn|first1 = Jan N.|last2=Bischl|first2=Bernd|last3=Torgo|first3=Luis|last4=Gao|first4=Bo|last5=Umaashankar|first5=Venkatesh|last6=Fischer|first6=Simon|last7=Winter|first7=Patrick|last8=Wiswedel|first8=Bernd|last9=Berthold|first9=Michael R.|last10=Vanschoren|first10=Joaquin|isbn=978-3-642-38708-1}}&lt;/ref&gt;&lt;ref name=arXiv:1407.7722/&gt;&lt;ref name=openml2015&gt;{{Cite web|url=http://www.jmlr.org/proceedings/papers/v41/vanschoren15.pdf|title=Vanschoren, Joaquin, Jan N. van Rijn, and Bernd Bischl. "Taking machine learning research online with OpenML." Proceedings of the 4th International Conference on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications-Volume 41. JMLR. org, 2015.}}&lt;/ref&gt;&lt;ref name=openml2016&gt;{{cite web |url=https://openaccess.leidenuniv.nl/handle/1887/44814 |title=van Rijn, J. N. Massively collaborative machine learning. Diss. 2016.|date=2016-12-19}}&lt;/ref&gt; || REST, Python, Java, R&lt;ref name=gh_openml&gt;{{Cite web|url=https://github.com/openml|title=OpenML|website=GitHub}}&lt;/ref&gt;
|-
|[https://wandb.com Weights &amp; Biases]&lt;ref&gt;{{Cite web|url=https://www.wandb.com/articles/h-weights-biases-for-experiment-tracking-and-collaboration-a-case-study|title=Weights &amp; Biases for Experiment Tracking and Collaboration|last=|first=|date=|website=|url-status=live|archive-url=|archive-date=|access-date=}}&lt;/ref&gt;
|Python&lt;ref&gt;{{Cite web|url=https://www.wandb.com/articles/pyenv-for-ml|title=Monitor your Machine Learning models with PyEnv|last=|first=|date=|website=|url-status=live|archive-url=|archive-date=|access-date=}}&lt;/ref&gt;
|}

=== Software ===
&lt;!--Add in alphabetical order. Remove entries that have been unmaintained for the last three years.--&gt;
{| class="wikitable sortable"
|-
! Name !! Interfaces !! Store
|-
| [https://determined.ai Determined] || REST, Python || [[PostgreSQL]]
|-
| [https://github.com/openml/openml-docker-dev OpenML Docker]&lt;ref name=openml2013/&gt;&lt;ref name=arXiv:1407.7722/&gt;&lt;ref name=openml2015/&gt;&lt;ref name=openml2016/&gt; || REST, Python, Java, R&lt;ref name=gh_openml/&gt; || MySQL
|-
| [https://github.com/IDSIA/sacred sacred]&lt;ref name=sacred2015/&gt;&lt;ref name=sacred2017/&gt; || Python&lt;ref name=pypi_sacred&gt;{{Cite web|url=https://github.com/IDSIA/sacred|title=sacred: Facilitates automated and reproducible experimental research|first=Klaus|last=Greff|via=PyPI|date=2020-01-03}}&lt;/ref&gt; || file, [[MongoDB]], TinyDB, SQL
|}

== See also ==
* [[Hyper-heuristic]]
* [[Replication crisis]]

== References ==
{{Reflist}}

[[Category:Machine learning]]
[[Category:Model selection]]</text>
      <sha1>r0dmrvkg5iqz3yx470ye22sxlalgopw</sha1>
    </revision>
  </page>
  <page>
    <title>Elastic matching</title>
    <ns>0</ns>
    <id>13750669</id>
    <revision>
      <id>948377395</id>
      <parentid>944912781</parentid>
      <timestamp>2020-03-31T18:28:13Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <comment>Add: bibcode, doi, pages. Formatted [[WP:ENDASH|dashes]]. | You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | Activated by [[User:Zppix]] | [[Category:Machine learning‎]] | via #UCB_Category</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1189" xml:space="preserve">{{expert needed|Computer science|date=February 2012}}
'''Elastic matching''' is one of the [[pattern recognition]] techniques in [[computer science]]. Elastic matching (EM) is also known as '''deformable template''', '''flexible matching''', or '''nonlinear template matching'''.&lt;ref&gt;{{Cite arxiv |eprint=1612.02190|last1=Talmi|first1=Itamar|title=Template Matching with Deformable Diversity Similarity|last2=Mechrez|first2=Roey|last3=Zelnik-Manor|first3=Lihi|class=cs.CV|year=2016}}&lt;/ref&gt;

Elastic matching can be defined as an [[optimization problem]] of two-dimensional warping specifying corresponding [[pixel]]s between subjected images.

==References==
{{Reflist}}
*{{cite journal |last=Uchida |first=Seiichi |title=A Survey of Elastic Matching Techniques for Handwritten Character Recognition |journal=IEICE Trans. Inf. &amp; Syst. |volume=E88-D |issue= 8 |date=August 2005|pages=1781–1790 |doi=10.1093/ietisy/e88-d.8.1781 |bibcode=2005IEITI..88.1781U |url=http://human.ait.kyushu-u.ac.jp/publications/e88-d_8_1781.pdf}}

==See also==
* [[Dynamic time warping]]

{{DEFAULTSORT:Elastic Matching}}
[[Category:Classification algorithms]]
[[Category:Machine learning]]


{{Comp-sci-stub}}</text>
      <sha1>asxl4g819596gjrvsm5l5wmffh8b5h3</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Data mining and machine learning software</title>
    <ns>14</ns>
    <id>33542714</id>
    <revision>
      <id>814530060</id>
      <parentid>809515029</parentid>
      <timestamp>2017-12-09T10:19:19Z</timestamp>
      <contributor>
        <username>PRehse</username>
        <id>410898</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="299" xml:space="preserve">{{See also|Comparison of deep learning software}}

Some products in [[:Category:Data analysis software]] and [[:Category:Statistical software]] also include [[data mining]] and [[machine learning]] facilities.

[[Category:Machine learning]]
[[Category:Data mining]]
[[Category:Statistical software]]</text>
      <sha1>8mzrb68p7miibagnjp84onhmic1drha</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Machine learning algorithms</title>
    <ns>14</ns>
    <id>33547228</id>
    <revision>
      <id>902071604</id>
      <parentid>675167466</parentid>
      <timestamp>2019-06-16T10:25:47Z</timestamp>
      <contributor>
        <username>Filipović Zoran</username>
        <id>20294490</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="173" xml:space="preserve">{{Commons category|Machine learning algorithms}}
{{Cat see also|Data mining|Classification algorithms|Decision trees}}

[[Category:Machine learning]]
[[Category:Algorithms]]</text>
      <sha1>szf1u1gkghgzc0vayyuhhby8e77fthe</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Applied machine learning</title>
    <ns>14</ns>
    <id>33547387</id>
    <revision>
      <id>906099709</id>
      <parentid>457675041</parentid>
      <timestamp>2019-07-13T16:36:10Z</timestamp>
      <contributor>
        <username>Heptametru</username>
        <id>31090467</id>
      </contributor>
      <comment>a little order</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="108" xml:space="preserve">{{catmain|Machine learning}}
[[Category:Artificial intelligence applications]]
[[Category:Machine learning]]</text>
      <sha1>17fhlj1rg0krssat6n5pdn2y3mt9drg</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Markov models</title>
    <ns>14</ns>
    <id>24059390</id>
    <revision>
      <id>833795444</id>
      <parentid>757550836</parentid>
      <timestamp>2018-04-02T13:29:21Z</timestamp>
      <contributor>
        <username>JarBot</username>
        <id>27077959</id>
      </contributor>
      <minor/>
      <comment>Bot:add Commons category</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="151" xml:space="preserve">{{Commons category|Markov models}}
{{Cat main|Markov model}}
[[Category:Stochastic models]]
[[Category:Machine learning]]
[[Category:Markov processes]]</text>
      <sha1>4sjim3t5c5svbjzcltykjzspm50jprq</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Dimension reduction</title>
    <ns>14</ns>
    <id>29549713</id>
    <revision>
      <id>912080814</id>
      <parentid>546037650</parentid>
      <timestamp>2019-08-23T03:38:48Z</timestamp>
      <contributor>
        <username>Chongkian</username>
        <id>8766034</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="162" xml:space="preserve">{{catmain|Dimensionality reduction}}

[[Category:Multivariate statistics]]
[[Category:Dimension|Reduction]]
[[Category:Machine learning]]
[[Category:Data mining]]</text>
      <sha1>3pi48edjv3s631kaomlduamwtjz8g1a</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Latent variable models</title>
    <ns>14</ns>
    <id>20924581</id>
    <revision>
      <id>545529298</id>
      <parentid>536757088</parentid>
      <timestamp>2013-03-19T22:14:56Z</timestamp>
      <contributor>
        <username>Addbot</username>
        <id>6569922</id>
      </contributor>
      <minor/>
      <comment>[[User:Addbot|Bot:]] Migrating 2 interwiki links, now provided by [[Wikipedia:Wikidata|Wikidata]] on [[d:q7483206]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="91" xml:space="preserve">[[Category:Statistical models]]
[[Category:Hidden variables]]
[[Category:Machine learning]]</text>
      <sha1>n1ve8pmonc96twpw7a1czs4iigng2bx</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Cluster analysis</title>
    <ns>14</ns>
    <id>22532673</id>
    <revision>
      <id>901955337</id>
      <parentid>870619096</parentid>
      <timestamp>2019-06-15T13:10:45Z</timestamp>
      <contributor>
        <username>Filipović Zoran</username>
        <id>20294490</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="192" xml:space="preserve">{{Commons cat|Cluster analysis}}
{{catmain|Cluster analysis}}

[[Category:Data mining]]
[[Category:Statistical classification]]
[[Category:Machine learning]]
[[Category:Spatial data analysis]]</text>
      <sha1>d1wzor4joxqebe1canodlxjlc74rnnc</sha1>
    </revision>
  </page>
  <page>
    <title>Multilinear principal component analysis</title>
    <ns>0</ns>
    <id>30928751</id>
    <revision>
      <id>983988386</id>
      <parentid>971033426</parentid>
      <timestamp>2020-10-17T13:53:57Z</timestamp>
      <contributor>
        <username>Lennart97</username>
        <id>14423028</id>
      </contributor>
      <minor/>
      <comment>fixed link to DAB page</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="10592" xml:space="preserve">{{context|date=June 2012}}
'''Multilinear principal component analysis''' ('''MPCA''')  is a [[Multilinear algebra|multilinear]] extension of [[principal component analysis]] (PCA). MPCA is employed in the analysis of n-way arrays, i.e. a cube or hyper-cube of numbers, also informally referred to as a "data tensor".  N-way arrays may be decomposed, analyzed, or modeled by 
* linear tensor models such as CANDECOMP/Parafac, or 
* multilinear tensor models, such as multilinear principal component analysis (MPCA), or multilinear independent component analysis (MICA), etc.
The origin of MPCA can be traced back to the [[Tucker decomposition]]&lt;ref&gt;{{Cite journal|last1=Tucker| first1=Ledyard R
 | authorlink1 = Ledyard R Tucker
 | title = Some mathematical notes on three-mode factor analysis
 | journal = [[Psychometrika]]
 | volume = 31 | issue = 3 | pages = 279–311
 |date=September 1966
 | doi = 10.1007/BF02289464 | pmid = 5221127 
}}&lt;/ref&gt; and Peter Kroonenberg's "M-mode PCA/3-mode PCA" work.&lt;ref name="Kroonenberg1980"&gt;P. M. Kroonenberg and J. de Leeuw, [https://doi.org/10.1007%2FBF02293599 Principal component analysis of three-mode data by means of alternating least squares algorithms], Psychometrika, 45 (1980), pp. 69–97.&lt;/ref&gt; In 2000, De Lathauwer et al. restated Tucker and Kroonenberg's work in clear and concise numerical computational terms in their SIAM paper entitled "[[Multilinear Singular Value Decomposition]]",&lt;ref name="DeLathauwer2000a"&gt;{{cite journal | last1 = Lathauwer | first1 = L.D. | last2 = Moor | first2 = B.D. | last3 = Vandewalle | first3 = J. | year = 2000 | title = A multilinear singular value decomposition | url = http://portal.acm.org/citation.cfm?id=354398 | journal = SIAM Journal on Matrix Analysis and Applications | volume = 21 | issue = 4| pages = 1253–1278 | doi = 10.1137/s0895479896305696 }}&lt;/ref&gt; (HOSVD) and in their paper "On the Best Rank-1 and Rank-(R&lt;sub&gt;1&lt;/sub&gt;, R&lt;sub&gt;2&lt;/sub&gt;, ..., R&lt;sub&gt;N&lt;/sub&gt; ) Approximation of Higher-order Tensors".&lt;ref name=DeLathauwer2000b&gt;{{cite journal | last1 = Lathauwer | first1 = L. D. | last2 = Moor | first2 = B. D. | last3 = Vandewalle | first3 = J. | year = 2000 | title = On the best rank-1 and rank-(R1, R2, ..., RN ) approximation of higher-order tensors | url = http://portal.acm.org/citation.cfm?id=354405 | journal = SIAM Journal on Matrix Analysis and Applications | volume = 21 | issue = 4| pages = 1324–1342 | doi = 10.1137/s0895479898346995 }}&lt;/ref&gt;

Circa 2001, Vasilescu reframed the data analysis, recognition and synthesis problems as multilinear tensor problems based on the insight that most observed data are the compositional consequence of several causal factors of data formation, and are well suited for multi-modal data tensor analysis.  The power of the tensor framework was showcased by analyzing human motion joint angles, facial images or textures in terms of their causal factors of data formation in the following works: Human Motion Signatures&lt;ref name="Vasilescu2002b"&gt;M.A.O. Vasilescu (2002) [http://www.media.mit.edu/~maov/motionsignatures/hms_icpr02_corrected.pdf  "Human Motion Signatures: Analysis, Synthesis, Recognition," Proceedings of International Conference on Pattern Recognition (ICPR 2002), Vol. 3, Quebec City, Canada, Aug, 2002, 456–460.]&lt;/ref&gt;
(CVPR 2001, ICPR 2002), face recognition – [[TensorFaces]],&lt;ref name="Vasilescu2002a"/&gt;&lt;ref name="Vasilescu2003"/&gt;
(ECCV 2002, CVPR 2003, etc.) and computer graphics – [[TensorTextures]]&lt;ref name="Vasilescu2004"/&gt; (Siggraph 2004).

Historically, MPCA has been referred to as "M-mode PCA", a terminology which was coined by Peter Kroonenberg in 1980.&lt;ref name="Kroonenberg1980"/&gt; In 2005, Vasilescu and [[Demetri Terzopoulos|Terzopoulos]] introduced the Multilinear PCA&lt;ref name="MPCA-MICA2005"&gt;M. A. O. Vasilescu, D. Terzopoulos (2005) [http://www.media.mit.edu/~maov/mica/mica05.pdf "Multilinear Independent Component Analysis"], "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR’05), San Diego, CA, June 2005, vol.1, 547–553."&lt;/ref&gt; terminology as a way to better differentiate between linear and multilinear tensor decomposition, as well as, to better differentiate between the work&lt;ref name="Vasilescu2002b"/&gt;&lt;ref name="Vasilescu2002a"/&gt;&lt;ref name="Vasilescu2003"/&gt;&lt;ref name="Vasilescu2004"/&gt; that computed 2nd order statistics associated with each data tensor mode(axis), and subsequent work on Multilinear Independent Component Analysis&lt;ref name="MPCA-MICA2005"/&gt; that computed higher order statistics associated with each tensor mode/axis.

Multilinear PCA may be applied to compute the causal factors of data formation, or as signal processing tool on data tensors whose individual observation have either been vectorized,&lt;ref name="Vasilescu2002b"/&gt;&lt;ref name="Vasilescu2002a"&gt;M.A.O. Vasilescu, [[Demetri Terzopoulos|D. Terzopoulos]] (2002) [http://www.media.mit.edu/~maov/tensorfaces/eccv02_corrected.pdf "Multilinear Analysis of Image Ensembles: TensorFaces," Proc. 7th European Conference on Computer Vision (ECCV'02), Copenhagen, Denmark, May, 2002, in Computer Vision – ECCV 2002, Lecture Notes in Computer Science, Vol. 2350, A. Heyden et al. (Eds.), Springer-Verlag, Berlin, 2002, 447–460. ]&lt;/ref&gt;&lt;ref name="Vasilescu2003"&gt;M.A.O. Vasilescu, D. Terzopoulos (2003) [http://www.media.mit.edu/~maov/tensorfaces/cvpr03.pdf "Multilinear Subspace Analysis for Image Ensembles,'' M. A. O. Vasilescu, D. Terzopoulos, Proc. Computer Vision and Pattern Recognition Conf. (CVPR '03), Vol.2, Madison, WI, June, 2003, 93–99.]&lt;/ref&gt;&lt;ref name="Vasilescu2004"&gt;M.A.O. Vasilescu, D. Terzopoulos (2004) [http://www.media.mit.edu/~maov/tensortextures/Vasilescu_siggraph04.pdf "TensorTextures: Multilinear Image-Based Rendering", M. A. O. Vasilescu and D. Terzopoulos, Proc. ACM SIGGRAPH 2004 Conference Los Angeles, CA, August, 2004, in Computer Graphics Proceedings, Annual Conference Series, 2004, 336–342. ]&lt;/ref&gt; or whose observations are treated as matrix&lt;ref name="MPCA2008"&gt;{{cite journal | last1 = Lu | first1 = H. | last2 = Plataniotis | first2 = K. N. | last3 = Venetsanopoulos | first3 = A. N. | year = 2008 | title = MPCA: Multilinear principal component analysis of tensor objects | url = http://www.dsp.utoronto.ca/~haiping/Publication/MPCA_TNN08_rev2010.pdf | journal = IEEE Trans. Neural Netw. | volume = 19 | issue = 1| pages = 18–39 | doi = 10.1109/tnn.2007.901277 | pmid = 18269936 | citeseerx = 10.1.1.331.5543 }}&lt;/ref&gt; and concatenated into a data tensor.

MPCA computes a set of orthonormal matrices associated with each mode of the data tensor which are analogous to the orthonormal row and column space of a matrix computed by the matrix SVD.  This transformation aims to capture as high a variance as possible, accounting for as much of the variability in the data associated with each data tensor mode(axis).

== The algorithm ==
The MPCA solution follows the alternating least square (ALS) approach.&lt;ref name="Kroonenberg1980"/&gt; It is iterative in nature.
As in PCA, MPCA works on centered data. Centering is a little more complicated for tensors, and it is problem dependent.

== Feature selection ==
MPCA features:  Supervised MPCA feature selection is used in object recognition&lt;ref name="MPCA"&gt;M. A. O. Vasilescu, D. Terzopoulos (2003) [http://www.cs.toronto.edu/~maov/tensorfaces/cvpr03.pdf "Multilinear Subspace Analysis of Image Ensembles"], "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR’03), Madison, WI, June, 2003"&lt;/ref&gt; while unsupervised MPCA feature selection is employed in visualization task.&lt;ref&gt;H.  Lu,  H.-L. Eng, M. Thida, and K.N. Plataniotis,  "[http://www.dsp.utoronto.ca/~haiping/Publication/CrowdMPCA_CIKM2010.pdf Visualization and Clustering of Crowd Video Content in MPCA Subspace]," in Proceedings of the 19th ACM Conference on Information and Knowledge Management (CIKM 2010), Toronto, ON, Canada, October, 2010.&lt;/ref&gt;

== Extensions ==
Various extensions of MPCA have been developed:&lt;ref&gt;{{cite journal
 |first=Haiping |last=Lu
 |first2=K.N. |last2=Plataniotis
 |first3=A.N. |last3=Venetsanopoulos
 |url=http://www.dsp.utoronto.ca/~haiping/Publication/SurveyMSL_PR2011.pdf
 |title=A Survey of Multilinear Subspace Learning for Tensor Data
 |journal=Pattern Recognition
 |volume=44 |number=7 |pages=1540–1551 |year=2011
 |doi=10.1016/j.patcog.2011.01.004
}}&lt;/ref&gt;
*Uncorrelated MPCA (UMPCA)&lt;ref name="UMPCA"&gt;H.  Lu,  K.  N.  Plataniotis,  and A.  N.  Venetsanopoulos,  "[http://www.dsp.utoronto.ca/~haiping/Publication/UMPCA_TNN09.pdf Uncorrelated multilinear principal component analysis for unsupervised multilinear subspace learning]," IEEE Trans. Neural Netw., vol. 20, no. 11, pp. 1820–1836, Nov. 2009.&lt;/ref&gt; In contrast, the uncorrelated MPCA (UMPCA) generates uncorrelated multilinear features.&lt;ref name="UMPCA"/&gt;
*[[Boosting (meta-algorithm)|Boosting]]+MPCA&lt;ref&gt;H. Lu, K. N. Plataniotis and A. N. Venetsanopoulos, "[http://www.hindawi.com/journals/ivp/2009/713183.html Boosting Discriminant Learners for Gait Recognition using MPCA Features] {{webarchive|url=https://web.archive.org/web/20101022214324/http://www.hindawi.com/journals/ivp/2009/713183.html |date=2010-10-22 }}", EURASIP Journal on Image and Video Processing, Volume 2009, Article ID 713183, 11 pages, 2009. {{doi|10.1155/2009/713183}}.&lt;/ref&gt;
*Non-negative MPCA (NMPCA)&lt;ref&gt;Y. Panagakis, C. Kotropoulos, G. R. Arce, "Non-negative multilinear principal component analysis of auditory temporal modulations for music genre classification", IEEE Trans. on Audio, Speech, and Language Processing, vol. 18, no. 3, pp. 576–588, 2010.&lt;/ref&gt;
*Robust MPCA (RMPCA)&lt;ref&gt;K.  Inoue,  K.  Hara,  K.  Urahama,  "Robust multilinear principal component analysis", Proc. IEEE Conference on Computer Vision, 2009, pp. 591–597.&lt;/ref&gt;
*Multi-Tensor Factorization, that also finds the number of components automatically (MTF)&lt;ref&gt;{{Cite journal|last=Khan|first=Suleiman A.|last2=Leppäaho|first2=Eemeli|last3=Kaski|first3=Samuel|date=2016-06-10|title=Bayesian multi-tensor factorization|journal=Machine Learning|language=en|volume=105|issue=2|pages=233–253|doi=10.1007/s10994-016-5563-y|issn=0885-6125|arxiv=1412.4679}}&lt;/ref&gt;

==References==
{{Reflist}}

== External links ==
* ''Matlab code'': [http://www.mathworks.com/matlabcentral/fileexchange/26168 MPCA].
* ''Matlab code'': [http://www.mathworks.com/matlabcentral/fileexchange/35432 UMPCA (including data)].
* ''R code:'' [http://research.cs.aalto.fi/pml/software/mtf/ MTF]

[[Category:Dimension reduction]]
[[Category:Machine learning]]</text>
      <sha1>aj9ro4h0giin6yggab85xpthe3b051g</sha1>
    </revision>
  </page>
  <page>
    <title>Base rate</title>
    <ns>0</ns>
    <id>9732182</id>
    <revision>
      <id>981673244</id>
      <parentid>981673184</parentid>
      <timestamp>2020-10-03T19:20:08Z</timestamp>
      <contributor>
        <username>YuriSanCa</username>
        <id>5334595</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3371" xml:space="preserve">{{about|the statistical term|interest rates|Central bank}}
{{more citations needed|date=March 2016}}
In [[probability]] and [[statistics]], '''base rate''' generally refers to the (base) class probabilities unconditioned on featural evidence, frequently also known as [[prior probabilities]]. For example, if it were the case that 1% of the public were "medical professionals", and 99% of the public were ''not'' "medical professionals", then the base rate of medical professionals is simply 1%.
 
In the [[sciences]], including [[medicine]], the base rate is critical for comparison. It may at first seem impressive that 1,000 people beat their winter cold while using 'Treatment X', until we look at the entire 'Treatment X' population and find that the base rate of success is only 1/100 (i.e. 100,000 people tried the treatment, but the other 99,000 people never really beat their winter cold). The treatment's effectiveness is clearer when such base rate information (i.e. "1,000 people... out of how many?") is available. Note that controls may likewise offer further information for comparison; maybe the [[control group]]s, who were using no treatment at all, had their own base rate success of 5/100. Controls thus indicate that 'Treatment X' makes things worse, despite that initial proud claim about 1,000 people.

The normative method for integrating base rates ([[prior probabilities]]) and featural evidence ([[likelihood]]s) is given by [[Bayes' theorem|Bayes' rule]].

==The base rate fallacy==

A large number of psychological studies have examined a phenomenon called '''[[Base rate fallacy|base-rate neglect]]'' or ''[[base rate fallacy]]''' in which category base rates are not integrated with featural evidence in the normative manner. Mathematician [[Keith Devlin]] provides an illustration of the risks of this: He asks us to imagine that there is a type of cancer that afflicts 1% of all people. A doctor then says there is a test for that cancer which is about 80% [[reliability (statistics)|reliable]]. He also says that the test provides a positive result for 100% of people who have the cancer, but it also results in a 'false positive' for 20% of people - who do not have the cancer. Now, if we test positive, we may be tempted to think it is 80% likely that we have the cancer. Devlin explains that, in fact, our odds are less than 5%. What is missing from the jumble of statistics is the most relevant base rate information. We should ask the doctor, ''"Out of the number of people who test positive (this is the base rate group that we care about), how many have the cancer?"''&lt;ref&gt;http://www.edge.org/responses/what-scientific-concept-would-improve-everybodys-cognitive-toolkit&lt;/ref&gt;  In assessing the probability that a given individual is a member of a particular class, we must account for other information besides the base rate. In particular, we must account for featural evidence. For example, when we see a person wearing a white doctor's coat and [[stethoscope]], and prescribing medication, we have evidence which may allow us to conclude that the probability of this ''particular'' individual being a "medical professional" is considerably greater than the category base rate of 1%.

==References==
{{Reflist}}

[[Category:Epidemiology]]
[[Category:Psychometrics]]
[[Category:Bayesian statistics]]
[[Category:Machine learning]]</text>
      <sha1>kakxb9wy5a6zcczve5j33krzmlm69dp</sha1>
    </revision>
  </page>
  <page>
    <title>Inferential theory of learning</title>
    <ns>0</ns>
    <id>33762888</id>
    <revision>
      <id>950961215</id>
      <parentid>884425883</parentid>
      <timestamp>2020-04-14T19:27:14Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: doi added to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3738" xml:space="preserve">==Overview==
[[File:Inferential Theory.gif|thumb|'''''Inferences are kept in the middle of all categories.'''''|alt=]]
'''Inferential Theory of Learning''' ('''ITL''') is an area of [[machine learning]] which describes inferential processes performed by learning agents. ITL has been continuously developed by [[Ryszard S. Michalski]], starting in the 1980s. The first known publication of ITL was in 1983.&lt;ref&gt;{{Cite journal|last=Michalski|first=Ryszard S.|date=1993|title=Inferential theory of learning as a conceptual basis for multistrategy learning|journal=Machine Learning|volume=11|issue=2–3|pages=111–151|doi=10.1007/bf00993074|issn=0885-6125|doi-access=free}}&lt;/ref&gt; In ITL [[Learning|learning process]] is viewed as a search ([[inference]]) through hypotheses space guided by a specific goal. Results of learning need to be [[Data storage device|stored]]. Stored information will later be used by the learner for future [[Inference|inferences]].&lt;ref&gt;{{Cite web|url=https://www.mli.gmu.edu/index.php/research/inferential-theory-of-learning/|title=Inferential Theory of Learning – GMU Machine Learning and Inference Laboratory|last=User|first=Super|website=www.mli.gmu.edu|language=en-US|access-date=2018-12-04}}&lt;/ref&gt; Inferences are split into multiple categories including [https://www.mli.gmu.edu/index.php/research/inferential-theory-of-learning/ conclusive, deduction, and induction.] In order for an inference to be considered complete it was required that all categories must be taken into account.&lt;ref&gt;{{Cite book|title=Machine learning methods for commonsense reasoning processes : interactive models|last=1940-|first=Naidenova, Xenia|date=2010|publisher=Information Science Reference|isbn=9781605668109|location=Hershey, PA|oclc=606360112}}&lt;/ref&gt; This is how the ITL varies from other machine learning theories like [[Computational learning theory|Computational Learning Theory]] and [[Statistical learning theory|Statistical Learning Theory]]; which both use singular forms of inference.

==Usage==

The most relevant published usage of ITL was in scientific journal published in 2012 and used ITL as a way to describe how agent-based learning works. According to the journal "The Inferential Theory of Learning (ITL) provides an elegant way of describing learning processes by agents".&lt;ref&gt;{{Cite journal|last=Wojtusiak|first=Janusz|last2=Warden|first2=Tobias|last3=Herzog|first3=Otthein|date=December 2012|title=Machine learning in agent-based stochastic simulation: Inferential theory and evaluation in transportation logistics|journal=Computers &amp; Mathematics with Applications|volume=64|issue=12|pages=3658–3665|doi=10.1016/j.camwa.2012.01.079|issn=0898-1221|doi-access=free}}&lt;/ref&gt;

==References==
{{Reflist}}

==Further reading==
{{Refbegin|}}
* Ryszard S. Michalski, Jaime G. Carbonell, Tom M. Mitchell (1983), ''Machine Learning: An Artificial Intelligence Approach'', Tioga Publishing Company, {{ISBN|0-935382-05-4}}.
** Ryszard S. Michalski, Jaime G. Carbonell, Tom M. Mitchell (1986), ''Machine Learning: An Artificial Intelligence Approach, Volume II'', Morgan Kaufmann, {{ISBN|0-934613-00-1}}.
** Yves Kodratoff, Ryszard S. Michalski (1990), ''Machine Learning: An Artificial Intelligence Approach, Volume III'', Morgan Kaufmann, {{ISBN|1-55860-119-8}}.
** Ryszard S. Michalski, George Tecuci (1994), ''Machine Learning: A Multistrategy Approach'', Volume IV, Morgan Kaufmann, {{ISBN|1-55860-251-8}}.
** Naidenova, X. (Ed.),(2009), Machine Learning Methods for Commonsense Reasoning Processes: Interactive Models: Interactive Models, IGI Global,{{ISBN|9781605668116}}.{{Refend}}

[[Category:Cybernetics]]
[[Category:Learning]]
[[Category:Machine learning]]


{{Compu-AI-stub}}
{{Systemstheory-stub}}</text>
      <sha1>im9ptpui9wewpuovroope0dy2qc70g0</sha1>
    </revision>
  </page>
  <page>
    <title>Coupled pattern learner</title>
    <ns>0</ns>
    <id>34042707</id>
    <revision>
      <id>993345797</id>
      <parentid>968607261</parentid>
      <timestamp>2020-12-10T03:15:05Z</timestamp>
      <contributor>
        <username>Michaelwallace22</username>
        <id>39374154</id>
      </contributor>
      <comment>deorphan</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="9287" xml:space="preserve">Coupled Pattern Learner (CPL) is a [[machine learning]] algorithm which couples the [[semi-supervised learning]] of categories and relations to forestall the problem of semantic drift associated with boot-strap learning methods.

== Coupled Pattern Learner ==
[[Semi-supervised learning]] approaches using a small number of labeled examples with many unlabeled examples are usually unreliable as they produce an internally consistent, but incorrect set of extractions. CPL solves this problem by simultaneously learning classifiers for many different categories and relations in the presence of an [[ontology]] defining constraints that couple the training of these classifiers. It was introduced by Andrew Carlson, Justin Betteridge, Estevam R. Hruschka Jr. and Tom M. Mitchell in 2009.&lt;ref name=cbl2009&gt;{{cite journal|last=Carlson|first=Andrew|author2=Justin Betteridge |author3=Estevam R. Hruschka Jr. |author4= Tom M. Mitchell |year=2009|title=Coupling semi-supervised learning of categories and relations|journal=Proceedings of the NAACL HLT 2009 Workshop on Semi-Supervised Learning for Natural Language Processing |publisher=Association for Computational Linguistics|location=Colorado, USA|pages=1–9|url=http://dl.acm.org/citation.cfm?id=1621829.1621830}}&lt;/ref&gt;&lt;ref name=cpl2010&gt;{{cite journal|last=Carlson|first=Andrew|author2=Justin Betteridge |author3=Richard C. Wang |author4=Estevam R. Hruschka Jr. |author5= Tom M. Mitchell |year=2010|title=Coupled semi-supervised learning for information extraction|journal=Proceedings of the Third ACM International Conference on Web Search and Data Mining |publisher=ACM|location=NY, USA|pages=101–110|url=http://dl.acm.org/citation.cfm?doid=1718487.1718501|doi=10.1145/1718487.1718501|isbn=9781605588896|doi-access=free}}&lt;/ref&gt;

== CPL overview==
CPL is an approach to [[semi-supervised learning]] that yields more accurate results by coupling the training of many information extractors. Basic idea behind CPL is that semi-supervised training of a single type of extractor such as ‘coach’ is much more difficult than simultaneously training many extractors that cover a variety of inter-related entity and relation types. Using prior knowledge about the relationships between these different entities and relations CPL makes unlabeled data as a useful constraint during training. For e.g., ‘coach(x)’ implies ‘person(x)’ and ‘not sport(x)’.

== CPL description ==
=== Coupling of predicates ===
CPL primarily relies on the notion of coupling the [[learning]] of multiple functions so as to constrain the semi-supervised learning problem. CPL constrains the learned function in two ways.
# Sharing among same-arity predicates according to logical relations
# Relation argument type-checking

=== Sharing among same-arity predicates ===
Each predicate P in the ontology has a list of other same-arity predicates with which P is mutually exclusive. If A is [[mutually exclusive]] with predicate B, A’s positive instances and patterns become negative instances and negative patterns for B. For example, if ‘city’, having an instance ‘Boston’ and a pattern ‘mayor of arg1’, is mutually exclusive with ‘scientist’, then ‘Boston’ and ‘mayor of arg1’ will become a negative instance and a negative pattern respectively for ‘scientist.’  Further, Some categories are declared to be a subset of another category.  For e.g., ‘athlete’ is a subset of ‘person’.

=== Relation argument type-checking ===
This is a type checking information used to couple the learning of relations and categories. For example, the arguments of the ‘ceoOf’ relation are declared to be of the categories ‘person’ and ‘company’. CPL does not promote a pair of noun phrases as an instance of a relation unless the two noun phrases are classified as belonging to the correct argument types.

=== Algorithm description ===

Following is a quick summary of the CPL algorithm.&lt;ref name=cpl2010 /&gt;  
 Input: An ontology O, and a text corpus C 
 Output: Trusted instances/patterns for each predicate
 '''for''' i=1,2,...,∞ '''do'''
     '''foreach''' predicate p in O '''do'''
         EXTRACT candidate instances/contextual patterns using recently promoted patterns/instances;
         FILTER candidates that violate coupling;
         RANK candidate instances/patterns;
         PROMOTE top candidates;
     '''end'''
 '''end'''

==== Inputs ====
A large [[Text corpus|corpus]] of Part-Of-Speech tagged sentences and an initial ontology with predefined categories, relations, mutually exclusive relationships between same-arity predicates, subset relationships between some categories, seed instances for all predicates, and seed patterns for the categories.

==== Candidate extraction ====
CPL finds new candidate instances by using newly promoted patterns to extract the noun phrases that co-occur with those patterns in the text corpus. CPL extracts,
* Category Instances
* Category Patterns
* Relation Instances
* Relation Patterns

==== Candidate filtering ====
Candidate instances and patterns are filtered to maintain high precision, and to avoid extremely specific patterns. An instance is only considered for assessment if it co-occurs with at least two promoted patterns in the text corpus, and if its co-occurrence count with all promoted patterns is at least three times greater than its co-occurrence count with negative patterns.

==== Candidate ranking ====
CPL ranks candidate instances using the number of promoted patterns that they co-occur with so that candidates that occur with more patterns are ranked higher. Patterns are ranked using an estimate of the precision of each pattern.

==== Candidate promotion ====
CPL ranks the candidates according to their assessment scores and promotes at most 100 instances and 5 patterns for each predicate. Instances and patterns are only promoted if they co-occur with at least two promoted patterns or instances, respectively.

== Meta-Bootstrap Learner ==
Meta-Bootstrap Learner (MBL) was also proposed by the authors of CPL in.&lt;ref name=cpl2010 /&gt; Meta-Bootstrap learner couples the training of multiple extraction techniques with a multi-view constraint, which requires the extractors to agree. It makes addition of coupling constraints on top of existing extraction algorithms, while treating them as black boxes, feasible. MBL assumes that the errors made by different extraction techniques are independent. Following is a quick summary of MBL.

 '''Input''': An ontology O, a set of extractors ε
 '''Output''': Trusted instances for each predicate
 '''for''' i=1,2,...,∞ '''do'''
     '''foreach''' predicate p in O '''do'''
         '''foreach''' extractor e in ε '''do'''
             Extract new candidates for p using e with recently promoted instances;
         '''end'''
         FILTER candidates that violate mutual-exclusion or type-checking constraints;
         PROMOTE candidates that were extracted by all extractors;
     '''end'''
 '''end'''

Subordinate algorithms used with MBL do not promote any instance on their own, they report the evidence about each candidate to MBL and MBL is responsible for promoting instances.

== Applications ==
In their paper &lt;ref name=cbl2009 /&gt; authors have presented results showing the potential of CPL to contribute new facts to existing repository of semantic knowledge, Freebase &lt;ref&gt;{{cite journal|year=2009 |title=Freebase data dumps |publisher=Metaweb Technologies |url=http://download.freebase.com/datadumps/ |url-status=dead |archiveurl=https://web.archive.org/web/20111206102101/http://download.freebase.com/datadumps/ |archivedate=December 6, 2011 }}&lt;/ref&gt;

== See also ==
* [[Co-training]]
* [[Never-Ending Language Learning]]

== Notes ==
{{reflist}}

==References==
* {{cite journal|last=Liu|first=Qiuhua |author2=Xuejun Liao |author3=Lawrence Carin |year=2008|title=Semi-supervised multitask learning|journal=NIPS}}
* {{cite journal|last=Shinyama|first=Yusuke|author2=Satoshi Sekine|year=2006|title=Preemptive information extraction using unrestricted relation discovery|journal=HLT-Naacl}}
* {{cite journal|last=Chang|first=Ming-Wei|author2=Lev-Arie Ratinov |author3=Dan Roth |year=2007|title=Guiding semi-supervision with constraint driven learning|journal=ACL}}
*  {{cite journal|last=Banko|first=Michele|author2=Michael J. Cafarella |author3=Stephen Soderland |author4=Matt Broadhead |author5=Oren Etzioni |author5-link=Oren Etzioni |year=2007|title=Open information extraction from the web|journal=IJCAI}}
* {{cite journal|last=Blum|first=Avrim|author2=Tom Mitchell|year=1998|title=Combining labeled and unlabeled data with co-training|journal=COLT|pages=92–100|doi=10.1145/279943.279962|isbn=1581130570}}
* {{cite journal|last=Riloff|first=Ellen|author2=Rosie Jones|year=1999|title=Learning dictionaries for information extraction by multi-level bootstrapping|journal=AAAI}}
* {{cite journal|last=Rosenfeld|first=Benjamin|author2=Ronen Feldman|year=2007|title=Using corpus statistics on entities to improve semi-supervised relation extraction from the web|journal=ACL}}
* {{cite journal|last=Wang|first=Richard C.|author2=William W. Cohen|year=2008|title=Iterative set expansion of named entities using the web|journal=ICDM}}

[[Category:Machine learning]]</text>
      <sha1>s4xpu4jy338i9nnjqhsatgrhqjgbp39</sha1>
    </revision>
  </page>
  <page>
    <title>Feature scaling</title>
    <ns>0</ns>
    <id>34061548</id>
    <revision>
      <id>1001781300</id>
      <parentid>1000053783</parentid>
      <timestamp>2021-01-21T08:50:17Z</timestamp>
      <contributor>
        <username>Ernesto Fernandez Saenz</username>
        <id>41033796</id>
      </contributor>
      <minor/>
      <comment>In this formula I cannot see the "-" in the lower line. I removed the spaces around it: : &lt;math&gt;x' = \frac{x - \text{min}(x)}{\text{max}(x)-\text{min}(x)}&lt;/math&gt; , as this is how it is edited in the next formula. According to preview, this works.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="6339" xml:space="preserve">{{Machine learning bar}}

'''Feature scaling''' is a method used to normalize the range of independent variables or features of data. In [[data processing]], it is also known as data normalization and is generally performed during the data preprocessing step.

==Motivation==
Since the range of values of raw data varies widely, in some [[machine learning]] algorithms, objective functions will not work properly without [[Normalization (statistics)|normalization]]. For example, many [[Statistical classification|classifiers]] calculate the distance between two points by the [[Euclidean distance]]. If one of the features has a broad range of values, the distance will be governed by this particular feature. Therefore, the range of all features should be normalized so that each feature contributes approximately proportionately to the final distance.

Another reason why feature scaling is applied is that [[gradient descent]] converges much faster with feature scaling than without it.&lt;ref&gt;{{cite arxiv|last=Ioffe|first=Sergey|author2=Christian Szegedy|year=2015|title=Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift|eprint=1502.03167|class=cs.LG}}&lt;/ref&gt;

It's also important to apply feature scaling if [[Regularization (mathematics)|regularization]] is used as part of the loss function (so that coefficients are penalized appropriately).
&lt;!-- {|
Deleted image removed: [[Image:Before FS.png|thumb|300px|A convergence of the Gradient Descent algorithm before applying feature scaling]]
Deleted image removed: [[Image:After FS.png|thumb|300px|A convergence of the Gradient Descent algorithm after applying feature scaling]]
|} --&gt;

==Methods==

===Rescaling (min-max normalization)===
Also known as min-max scaling or min-max normalization, is the simplest method and consists in rescaling the range of features to scale the range in [0, 1] or [−1, 1]. Selecting the target range depends on the nature of the data. The general formula for a min-max of [0, 1] is given as:

: &lt;math&gt;x' = \frac{x - \text{min}(x)}{\text{max}(x)-\text{min}(x)}&lt;/math&gt;

where &lt;math&gt;x&lt;/math&gt; is an original value, &lt;math&gt;x'&lt;/math&gt; is the normalized value. For example, suppose that we have the students' weight data, and the students' weights span [160 pounds, 200 pounds]. To rescale this data, we first subtract 160 from each student's weight and divide the result by 40 (the difference between the maximum and minimum weights).

To rescale a range between an arbitrary set of values [a, b], the formula becomes:

: &lt;math&gt;x' = a + \frac{(x - \text{min}(x))(b-a)}{\text{max}(x)-\text{min}(x)}&lt;/math&gt;

where &lt;math&gt;a,b&lt;/math&gt; are the min-max values.

===Mean normalization===

: &lt;math&gt;x' = \frac{x - \text{average}(x)}{\text{max}(x)-\text{min}(x)}&lt;/math&gt;

where &lt;math&gt;x&lt;/math&gt; is an original value, &lt;math&gt;x'&lt;/math&gt; is the normalized value. There is another form of the means normalization which is when we divide by the standard deviation which is also called standardization.

===Standardization (Z-score Normalization)===
{{see also|Standard score}}
In machine learning, we can handle various types of data, e.g. audio signals and pixel values for image data, and this data can include multiple [[dimensions]]. Feature standardization makes the values of each feature in the data have zero-mean (when subtracting the mean in the numerator) and unit-variance. This method is widely used for normalization in many machine learning algorithms (e.g., [[support vector machine]]s, [[logistic regression]], and [[artificial neural network]]s).&lt;ref name=":0"&gt;{{Cite book|title = Data Science from Scratch|last = Grus|first = Joel|publisher = O'Reilly|year = 2015|isbn = 978-1-491-90142-7|location = Sebastopol, CA|pages = 99, 100}}&lt;/ref&gt;{{Citation needed|date=September 2014}} The general method of calculation is to determine the distribution [[mean]] and [[standard deviation]] for each feature. Next we subtract the mean from each feature. Then we divide the values (mean is already subtracted) of each feature by its standard deviation.

: &lt;math&gt;x' = \frac{x - \bar{x}}{\sigma}&lt;/math&gt;

Where &lt;math&gt;x&lt;/math&gt; is the original feature vector, &lt;math&gt;\bar{x}=\text{average}(x)&lt;/math&gt; is the mean of that feature vector, and &lt;math&gt;\sigma&lt;/math&gt; is its standard deviation.

===Scaling to unit length===
Another option that is widely used in machine-learning is to scale the components of a feature vector such that the complete vector has length one. This usually means dividing each component by the [[Euclidean length]] of the vector: 
:&lt;math&gt;x' = \frac{x}{\left\|{x}\right\|}&lt;/math&gt;

In some applications (e.g., histogram features) it can be more practical to use the L&lt;sub&gt;1&lt;/sub&gt; norm (i.e., [[taxicab geometry]]) of the feature vector. This is especially important if in the following learning steps the scalar metric is used as a distance measure.{{why|date=January 2020}}

== Application ==
In [[stochastic gradient descent]], feature scaling can sometimes improve the convergence speed of the algorithm&lt;ref name=":0" /&gt; {{Citation needed|date=September 2014}}. In support vector machines,&lt;ref&gt;{{cite journal|last=Juszczak|first=P.|author2=D. M. J. Tax |author3=R. P. W. Dui |year=2002|title=Feature scaling in support vector data descriptions|journal=Proc. 8th Annu. Conf. Adv. School Comput. Imaging|pages=25–30|citeseerx=10.1.1.100.2524}}&lt;/ref&gt; it can reduce the time to find support vectors. Note that feature scaling changes the SVM result {{Citation needed|date=September 2014}}.

==See also==
* [[Normalization (statistics)]]
* [[Standard score]]
* [[fMLLR]], Feature space Maximum Likelihood Linear Regression

==References==
{{reflist}}

== Further reading ==
* {{cite book |first=Jiawei |last=Han |first2=Micheline |last2=Kamber |first3=Jian |last3=Pei |title=Data Mining: Concepts and Techniques |publisher=Elsevier |year=2011 |chapter=Data Transformation and Data Discretization |pages=111–118 |chapter-url=https://www.google.com/books/edition/Data_Mining_Concepts_and_Techniques/pQws07tdpjoC?hl=en&amp;gbpv=1&amp;pg=PA111 }}

== External links ==
*[http://openclassroom.stanford.edu/MainFolder/VideoPage.php?course=MachineLearning&amp;video=03.1-LinearRegressionII-FeatureScaling&amp;speed=100/ Lecture by Andrew Ng on feature scaling]

[[Category:Machine learning]]
[[Category:Statistical data transformation]]</text>
      <sha1>c77b2hulhiqne9ugv29mt94ajjr0kjy</sha1>
    </revision>
  </page>
  <page>
    <title>Preference learning</title>
    <ns>0</ns>
    <id>34072838</id>
    <revision>
      <id>1000116968</id>
      <parentid>999787840</parentid>
      <timestamp>2021-01-13T17:32:44Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 8 templates: hyphenate params (1×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="9039" xml:space="preserve">'''Preference learning''' is a subfield in [[machine learning]], which is a classification method based on observed preference information.&lt;ref&gt;{{Cite Mehryar Afshin Ameet 2012}}&lt;/ref&gt; In the view of [[supervised learning]], preference learning trains on a set of items which have preferences toward labels or other items and predicts the preferences for all items.

While the concept of preference learning has been emerged for some time in many fields such as [[economics]],&lt;ref name="SHOG00" /&gt; it's a relatively new topic in [[Artificial Intelligence]] research. Several workshops have been discussing preference learning and related topics in the past decade.&lt;ref name="WEB:WORKSHOP" /&gt;

==Tasks==

The main task in preference learning concerns problems in "[[learning to rank]]". According to different types of preference information observed, the tasks are categorized as three main problems in the book ''Preference Learning'':&lt;ref name="FURN11" /&gt;

===Label ranking===

In label ranking, the model has an instance space &lt;math&gt;X=\{x_i\}\,\!&lt;/math&gt; and a finite set of labels &lt;math&gt;Y=\{y_i|i=1,2,\cdots,k\}\,\!&lt;/math&gt;. The preference information is given in the form &lt;math&gt;y_i \succ_{x} y_j\,\!&lt;/math&gt; indicating instance &lt;math&gt;x\,\!&lt;/math&gt; shows preference in &lt;math&gt;y_i\,\!&lt;/math&gt; rather than &lt;math&gt;y_j\,\!&lt;/math&gt;. A set of preference information is used as training data in the model. The task of this model is to find a preference ranking among the labels for any instance.

It was observed some conventional [[Classification in machine learning|classification]] problems can be generalized in the framework of label ranking problem:&lt;ref name="HARP03" /&gt; if a training instance &lt;math&gt;x\,\!&lt;/math&gt; is labeled as class &lt;math&gt;y_i\,\!&lt;/math&gt;, it implies that &lt;math&gt;\forall j \neq i, y_i \succ_{x} y_j\,\!&lt;/math&gt;. In the [[Multi-label classification|multi-label]] case, &lt;math&gt;x\,\!&lt;/math&gt; is associated with a set of labels &lt;math&gt;L \subseteq Y\,\!&lt;/math&gt; and thus the model can extract a set of preference information &lt;math&gt;\{y_i \succ_{x} y_j | y_i \in L, y_j \in Y\backslash L\}\,\!&lt;/math&gt;. Training a preference model on this preference information and the classification result of an instance is just the corresponding top ranking label.

===Instance ranking===

Instance ranking also has the instance space &lt;math&gt;X\,\!&lt;/math&gt; and label set &lt;math&gt;Y\,\!&lt;/math&gt;. In this task, labels are defined to have a fixed order &lt;math&gt;y_1 \succ y_2 \succ \cdots \succ y_k\,\!&lt;/math&gt; and each instance &lt;math&gt;x_l\,\!&lt;/math&gt; is associated with a label &lt;math&gt;y_l\,\!&lt;/math&gt;. Giving a set of instances as training data, the goal of this task is to find the ranking order for a new set of instances.

===Object ranking===

Object ranking is similar to instance ranking except that no labels are associated with instances. Given a set of pairwise preference information in the form &lt;math&gt;x_i \succ x_j\,\!&lt;/math&gt; and the model should find out a ranking order among instances.

==Techniques==

There are two practical representations of the preference information &lt;math&gt;A \succ B\,\!&lt;/math&gt;. One is assigning &lt;math&gt;A\,\!&lt;/math&gt; and &lt;math&gt;B\,\!&lt;/math&gt; with two real numbers &lt;math&gt;a\,\!&lt;/math&gt; and &lt;math&gt;b\,\!&lt;/math&gt; respectively such that &lt;math&gt;a &gt; b\,\!&lt;/math&gt;. Another one is assigning a binary value &lt;math&gt;V(A,B) \in \{0,1\}\,\!&lt;/math&gt; for all pairs &lt;math&gt;(A,B)\,\!&lt;/math&gt; denoting whether &lt;math&gt;A \succ B\,\!&lt;/math&gt; or &lt;math&gt;B \succ A\,\!&lt;/math&gt;. Corresponding to these two different representations, there are two different techniques applied to the learning process.

===Utility function===

If we can find a mapping from data to real numbers, ranking the data can be solved by ranking the real numbers. This mapping is called [[utility function]]. For label ranking the mapping is a function &lt;math&gt;f: X \times Y \rightarrow \mathbb{R}\,\!&lt;/math&gt; such that &lt;math&gt;y_i \succ_x y_j \Rightarrow f(x,y_i) &gt; f(x,y_j)\,\!&lt;/math&gt;. For instance ranking and object ranking, the mapping is a function &lt;math&gt;f: X \rightarrow \mathbb{R}\,\!&lt;/math&gt;.

Finding the utility function is a [[Regression analysis|regression]] learning problem which is well developed in machine learning.

===Preference relations===

The binary representation of preference information is called preference relation. For each pair of alternatives (instances or labels), a binary predicate can be learned by conventional supervising learning approach. Fürnkranz and Hüllermeier proposed this approach in label ranking problem.&lt;ref name="FURN03" /&gt; For object ranking, there is an early approach by Cohen et al.&lt;ref name="COHE98" /&gt;

Using preference relations to predict the ranking will not be so intuitive. Since preference relation is not transitive, it implies that the solution of ranking satisfying those relations would sometimes be unreachable, or there could be more than one solution. A more common approach is to find a ranking solution which is maximally consistent with the preference relations. This approach is a natural extension of pairwise classification.&lt;ref name="FURN03" /&gt;

==Uses==

Preference learning can be used in ranking search results according to feedback of user preference. Given a query and a set of documents, a learning model is used to find the ranking of documents corresponding to the relevance with this query. More discussions on research in this field can be found in Tie-Yan Liu's survey paper.&lt;ref name="LIU09" /&gt;

Another application of preference learning is [[recommender systems]].&lt;ref name="GEMM09" /&gt; Online store may analyze customer's purchase record to learn a preference model and then recommend similar products to customers. Internet content providers can make use of user's ratings to provide more user preferred contents.

==See also==
*[[Learning to rank]]

==References==

{{Reflist|
refs=

&lt;ref name="SHOG00"&gt;{{
cite journal
|last       = Shogren
|first      = Jason F. |author2=List, John A. |author3=Hayes, Dermot J.
|year       = 2000
|title      = Preference Learning in Consecutive Experimental Auctions
|url        = http://econpapers.repec.org/article/oupajagec/v_3a82_3ay_3a2000_3ai_3a4_3ap_3a1016-1021.htm
|journal    = American Journal of Agricultural Economics
|volume     = 82
|issue = 4 |pages      = 1016–1021
|doi=10.1111/0002-9092.00099
}}&lt;/ref&gt;

&lt;ref name="WEB:WORKSHOP"&gt;{{
cite web
|title      = Preference learning workshops
|url        = http://www.preference-learning.org/#Workshops
}}&lt;/ref&gt;

&lt;ref name="FURN11"&gt;{{
cite book
|last       = Fürnkranz
|first      = Johannes
 |author2=Hüllermeier, Eyke
|year       = 2011
|title      = Preference Learning
|url        = https://books.google.com/books?id=nc3XcH9XSgYC
|chapter    = Preference Learning: An Introduction
|chapter-url = https://books.google.com/books?id=nc3XcH9XSgYC&amp;pg=PA4
|publisher  = Springer-Verlag New York, Inc.
|pages      = 3–8
|isbn       = 978-3-642-14124-9
}}&lt;/ref&gt;

&lt;ref name="HARP03"&gt;{{
cite journal
|last       = Har-peled | author1-link = Sariel Har-Peled
|first      = Sariel |author2=Roth, Dan |author3=Zimak, Dav
|year       = 2003
|title      = Constraint classification for multiclass classification and ranking
|journal    = In Proceedings of the 16th Annual Conference on Neural Information Processing Systems, NIPS-02
|pages      = 785–792
}}&lt;/ref&gt;

&lt;ref name="FURN03"&gt;{{
cite journal
|last       = Fürnkranz
|first      = Johannes
 |author2=Hüllermeier, Eyke
|year       = 2003
|title      = Pairwise Preference Learning and Ranking
|journal    = Proceedings of the 14th European Conference on Machine Learning
|pages      = 145–156
}}&lt;/ref&gt;

&lt;ref name="COHE98"&gt;{{
cite journal
|last       = Cohen
|first      = William W. |author2=Schapire, Robert E. |author3=Singer, Yoram
|year       = 1998
|title      = Learning to order things
|url        = http://dl.acm.org/citation.cfm?id=302528.302736
|journal    = In Proceedings of the 1997 Conference on Advances in Neural Information Processing Systems
|pages      = 451–457
}}&lt;/ref&gt;

&lt;ref name="LIU09"&gt;{{
cite journal
|last       = Liu
|first      = Tie-Yan
|year       = 2009
|title      = Learning to Rank for Information Retrieval
|url        = http://dl.acm.org/citation.cfm?id=1618303.1618304
|journal    = Foundations and Trends in Information Retrieval
|volume     = 3
|issue      = 3
|pages      = 225–331
|doi        = 10.1561/1500000016
}}&lt;/ref&gt;

&lt;ref name="GEMM09"&gt;{{
cite journal
|last       = Gemmis
|first      = Marco De
|author2=Iaquinta, Leo |author3=Lops, Pasquale |author4=Musto, Cataldo |author5=Narducci, Fedelucio |author6= Semeraro, Giovanni 
|year       = 2009
|title      = Preference Learning in Recommender Systems
|url        = http://www.ecmlpkdd2009.net/wp-content/uploads/2008/09/preference-learning.pdf#page=45
|journal    = Preference Learning
|volume     = 41
|pages      = 387–407
|doi=10.1007/978-3-642-14125-6_18
|isbn = 978-3-642-14124-9
}}&lt;/ref&gt;

}}

==External links==
*[http://www.preference-learning.org/ Preference Learning site]

[[Category:Information retrieval techniques]]
[[Category:Machine learning]]</text>
      <sha1>m8uy7iu8aw11pj2fzgtx2bgovhcqvys</sha1>
    </revision>
  </page>
  <page>
    <title>Proactive learning</title>
    <ns>0</ns>
    <id>21985449</id>
    <revision>
      <id>913090816</id>
      <parentid>725955118</parentid>
      <timestamp>2019-08-29T20:32:13Z</timestamp>
      <contributor>
        <username>Bender the Bot</username>
        <id>28903366</id>
      </contributor>
      <minor/>
      <comment>/* top */HTTP → HTTPS for Carnegie Mellon CS, replaced: http://www.cs.cmu.edu/ → https://www.cs.cmu.edu/</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2179" xml:space="preserve">'''Proactive learning'''&lt;ref name=donmez08/&gt; is a generalization of [[active learning]] designed to relax unrealistic assumptions and thereby reach practical applications.

"Active learning seeks to select the most informative unlabeled instances and ask an omniscient [[oracle (computer science)|oracle]] for their labels, so as to retrain a [[machine learning|learning]] algorithm maximizing accuracy. However, the oracle is assumed to be infallible (never wrong), indefatigable (always answers), individual (only one oracle), and insensitive to costs (always free or always charges the same)."&lt;ref name=donmez08&gt;Donmez, P., Carbonell, J.G.: Proactive Learning: Cost-Sensitive [[Active learning|Active Learning]] with Multiple Imperfect Oracles, in Proceedings of the 17th ACM Conference on Information and [[Knowledge management|Knowledge Management]] (CIKM '08), [[Napa County, California|Napa Valley]] 2008. https://www.cs.cmu.edu/~pinard/Papers/cikm0613-donmez.pdf&lt;/ref&gt;

"In real life, it is possible and more general to have multiple sources of information with differing reliabilities or areas of expertise. Active learning also assumes that the single oracle is perfect, always providing a correct answer when requested. In reality, though, an "oracle" (if we generalize the term to mean any source of expert information) may be incorrect (fallible) 
with a probability that should be a function of the difficulty of the question. Moreover, an oracle may be reluctant – it may refuse to answer if it is too uncertain or too busy. Finally, active learning presumes the oracle is either free or charges uniform cost in label elicitation.
Such an assumption is naive since cost is likely to be regulated by difficulty (amount of work required to formulate an answer) or other factors."&lt;ref  name=donmez08/&gt;

Proactive learning relaxes all four of these assumptions, relying on a decision-theoretic approach to jointly select the optimal oracle and instance, by casting the problem as a utility [[optimization problem]] subject to a [[budget constraint]].

==References==
{{Reflist}}

{{DEFAULTSORT:Proactive Learning}}
[[Category:Learning]]
[[Category:Machine learning]]</text>
      <sha1>o9gypqd1sqc6jrjxode6l801zswvb67</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Computational learning theory</title>
    <ns>14</ns>
    <id>34310097</id>
    <revision>
      <id>550844741</id>
      <parentid>535928176</parentid>
      <timestamp>2013-04-17T17:50:18Z</timestamp>
      <contributor>
        <username>Addbot</username>
        <id>6569922</id>
      </contributor>
      <minor/>
      <comment>[[User:Addbot|Bot:]] Migrating 1 interwiki links, now provided by [[Wikipedia:Wikidata|Wikidata]] on [[d:q11275242]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="115" xml:space="preserve">{{cat main|computational learning theory}}

[[Category:Theoretical computer science]]
[[Category:Machine learning]]</text>
      <sha1>ttbudu344a7sbrn53d0c99jgnl0uxp1</sha1>
    </revision>
  </page>
  <page>
    <title>Computational learning theory</title>
    <ns>0</ns>
    <id>387537</id>
    <revision>
      <id>992485093</id>
      <parentid>986017567</parentid>
      <timestamp>2020-12-05T14:37:13Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 3 templates: del empty params (4×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="7660" xml:space="preserve">{{see also|Statistical learning theory}}
{{Short description|Theory of machine learning}}{{more citations needed|date=November 2018}}
{{Machine learning bar}}

In [[computer science]], '''computational learning theory''' (or just '''learning theory''') is a subfield of [[artificial intelligence]] devoted to studying the design and analysis of [[machine learning]] algorithms.&lt;ref name="ACL"&gt;{{Cite web | url=http://www.learningtheory.org/ | title=ACL - Association for Computational Learning}}&lt;/ref&gt;

==Overview==
Theoretical results in machine learning mainly deal with a type of inductive learning called [[supervised learning]].  In supervised learning, an algorithm is given samples that are labeled in some useful way.  For example, the samples might be descriptions of mushrooms, and the labels could be whether or not the mushrooms are edible.  The algorithm takes these previously labeled samples and uses them to induce a classifier.  This classifier is a function that assigns labels to samples, including samples that have not been seen previously by the algorithm.  The goal of the supervised learning algorithm is to optimize some measure of performance such as minimizing the number of mistakes made on new samples.

In addition to performance bounds, computational learning theory studies the time complexity and feasibility of learning.{{citation needed|date=October 2017}} In
computational learning theory, a computation is considered feasible if it can be done in [[polynomial time]].{{citation needed|date=October 2017}} There are two kinds of time
complexity results:

* Positive results{{spaced ndash}}Showing that a certain class of functions is learnable in polynomial time.
* Negative results{{spaced ndash}}Showing that certain classes cannot be learned in polynomial time.

Negative results often rely on commonly believed, but yet unproven assumptions,{{citation needed|date=October 2017}} such as:

* Computational complexity – [[P versus NP problem|P &amp;ne; NP (the P versus NP problem)]];
* [[cryptography|Cryptographic]] – [[One-way function]]s exist.

There are several different approaches to computational learning theory based on making different assumptions about the
[[inference]] principles used to generalize from limited data. This includes different definitions of [[probability]] (see [[frequency probability]], [[Bayesian probability]]) and different assumptions on the generation of samples.{{citation needed|date=October 2017}} The different approaches include:{{citation needed|date=October 2017}}

* Exact learning, proposed by [[Dana Angluin]];
* [[Probably approximately correct learning]] (PAC learning), proposed by [[Leslie Valiant]];
* [[VC theory]], proposed by [[Vladimir Vapnik]] and [[Alexey Chervonenkis]];
* [[Bayesian inference]];
* [[Algorithmic learning theory]], from the work of [[E. Mark Gold]];
* [[Online machine learning]], from the work of Nick Littlestone.

While its primary goal is to understand learning abstractly, computational learning theory has led to the development of practical algorithms. For example, PAC theory inspired [[Boosting (meta-algorithm)|boosting]], VC theory led to [[support vector machine]]s, and Bayesian inference led to [[belief networks]].

==See also==
* [[Grammar induction]]
* [[Information theory]]
* [[Stability (learning theory)]]
* [[Error Tolerance (PAC learning)]]

==References==
{{Reflist}}

===Surveys===
* Angluin, D. 1992. Computational learning theory: Survey and selected bibliography. In Proceedings of the Twenty-Fourth Annual ACM Symposium on Theory of Computing (May 1992), pages&amp;nbsp;351–369. http://portal.acm.org/citation.cfm?id=129712.129746
* D. Haussler. Probably approximately correct learning. In AAAI-90 Proceedings of the Eight National Conference on Artificial Intelligence, Boston, MA, pages 1101–1108. American Association for Artificial Intelligence, 1990. http://citeseer.ist.psu.edu/haussler90probably.html

===[[VC dimension]]===
* V. Vapnik and A. Chervonenkis. [https://courses.engr.illinois.edu/ece544na/fa2014/vapnik71.pdf On the uniform convergence of relative frequencies of events to their probabilities]. Theory of Probability and Its Applications, 16(2):264–280, 1971.

===Feature selection===
* A. Dhagat and L. Hellerstein, "PAC learning with irrelevant attributes", in 'Proceedings of the IEEE Symp. on Foundation of Computer Science', 1994. http://citeseer.ist.psu.edu/dhagat94pac.html

===Inductive inference===
* {{Cite journal | last1 = Gold | first1 = E. Mark | year = 1967 | title = Language identification in the limit | journal = Information and Control | volume = 10 | issue = 5 | pages = 447–474 | doi = 10.1016/S0019-9958(67)91165-5 | url=http://web.mit.edu/~6.863/www/spring2009/readings/gold67limit.pdf }}

===Optimal O notation learning===
* [[Oded Goldreich]], [[Dana Ron]]. ''[http://www.eng.tau.ac.il/~danar/Public-pdf/ul.pdf On universal learning algorithms]''. http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.47.2224

===Negative results===
*  M. Kearns and [[Leslie Valiant]]. 1989. Cryptographic limitations on learning boolean formulae and finite automata. In Proceedings of the 21st Annual ACM Symposium on Theory of Computing, pages 433–444, New York. ACM. http://citeseer.ist.psu.edu/kearns89cryptographic.html

===[[Boosting (machine learning)]]===
* Robert E. Schapire. The strength of weak learnability. Machine Learning, 5(2):197–227, 1990 http://citeseer.ist.psu.edu/schapire90strength.html

===[[Occam Learning]]===
* Blumer, A.; Ehrenfeucht, A.; Haussler, D.; Warmuth, M. K. [http://www.cse.buffalo.edu/~hungngo/classes/2008/694/papers/occam.pdf Occam's razor] Inf.Proc.Lett. 24, 377–380, 1987.
* Blumer, A.; Ehrenfeucht, A.; Haussler, D.; Warmuth, M. K. [http://www.trhvidsten.com/docs/classics/Blumer-1989.pdf Learnability and the Vapnik-Chervonenkis dimension]. Journal of the ACM, 36(4):929–865, 1989.

===[[Probably approximately correct learning]]===
* L. Valiant. [http://www.montefiore.ulg.ac.be/~geurts/Cours/AML/Readings/Valiant.pdf A Theory of the Learnable]. Communications of the ACM, 27(11):1134–1142, 1984.

===Error tolerance===
* Michael Kearns and Ming Li. Learning in the presence of malicious errors. SIAM Journal on Computing, 22(4):807–837, August 1993. http://citeseer.ist.psu.edu/kearns93learning.html
* Kearns, M. (1993). Efficient noise-tolerant learning from statistical queries. In Proceedings of the Twenty-Fifth Annual ACM Symposium on Theory of Computing, pages 392–401. http://citeseer.ist.psu.edu/kearns93efficient.html

===Equivalence===
* D.Haussler, M.Kearns, N.Littlestone and [[Manfred K. Warmuth|M. Warmuth]], Equivalence of models for polynomial learnability, Proc. 1st ACM Workshop on Computational Learning Theory, (1988) 42-55. 
* {{Cite journal | last1 = Pitt | first1 = L. | last2 = Warmuth | first2 = M. K. | year = 1990 | title = Prediction-Preserving Reducibility | journal = Journal of Computer and System Sciences | volume = 41 | issue =  3| pages = 430–467 | doi = 10.1016/0022-0000(90)90028-J }}

A description of some of these publications is given at [[list of important publications in computer science#Machine learning|important publications in machine learning]].

===[[Distribution learning theory|Distribution Learning Theory]]===

==External links==
* [http://research.microsoft.com/adapt/MSBNx/msbnx/Basics_of_Bayesian_Inference.htm Basics of Bayesian inference]

{{Differentiable computing}}

[[Category:Computational learning theory| ]]
[[Category:Theoretical computer science]]
[[Category:Machine learning]]
[[Category:Computational fields of study]]

[[de:Maschinelles Lernen]]</text>
      <sha1>5tdb3ehwc0cqtwo4ritamtbmhtowq66</sha1>
    </revision>
  </page>
  <page>
    <title>Mountain car problem</title>
    <ns>0</ns>
    <id>33998310</id>
    <revision>
      <id>997721562</id>
      <parentid>994531916</parentid>
      <timestamp>2021-01-01T22:39:46Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 6 templates: del empty params (2×); cvt lang vals (1×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="8582" xml:space="preserve">{{Use dmy dates|date=September 2017}}
&lt;!-- Please leave this line alone! --&gt;

[[Image:Diagram of the mountain car problem.png|thumb|300px| The mountain car problem]]

'''Mountain Car''', a standard testing domain in [[Reinforcement Learning]], is a problem in which an under-powered car must drive up a steep hill. Since gravity is stronger than the car's engine, even at full throttle, the car cannot simply accelerate up the steep slope. The car is situated in a valley and must learn to leverage potential energy by driving up the opposite hill before the car is able to make it to the goal at the top of the rightmost hill. The domain has been used as a [[test bed]] in various [[Reinforcement Learning]] papers.

==Introduction==
The mountain car problem, although fairly simple, is commonly applied because it requires a reinforcement learning agent to learn on two continuous variables: position and velocity. For any given state (position and velocity) of the car, the agent is given the possibility of driving left, driving right, or not using the engine at all. In the standard version of the problem, the agent receives a negative reward at every time step when the goal is not reached; the agent has no information about the goal until an initial success.

==History==
The mountain car problem appeared first in Andrew Moore's PhD Thesis (1990).&lt;ref&gt;[Moore, 1990] A. Moore, Efficient Memory-Based Learning for Robot Control, PhD thesis, University of Cambridge, November 1990.&lt;/ref&gt; It was later more strictly defined in Singh and Sutton's Reinforcement Leaning paper with [[eligibility traces]].&lt;ref&gt;[Singh and Sutton, 1996] Singh, S.P. and Sutton, R.S. (1996) Reinforcement learning with replacing eligibility traces. Machine Learning 22(1/2/3):123-158.&lt;/ref&gt; The problem became more widely studied when Sutton and Barto added it to their book Reinforcement Learning: An Introduction (1998).&lt;ref&gt;[Sutton and Barto, 1998] Reinforcement Learning: An Introduction. Richard S. Sutton and Andrew G. Barto. A Bradford Book. The MIT Press Cambridge, Massachusetts London, England, 1998&lt;/ref&gt; Throughout the years many versions of the problem have been used, such as those which modify the [[reward function]], termination condition, and/or the [[start state]].

==Techniques used to solve mountain car==
[[Q-learning]] and similar techniques for mapping discrete states to discrete actions need to be extended to be able to deal with the continuous state space of the problem. Approaches often fall into one of two categories, state space [[discretization]] or [[function approximation]].

===Discretization===

In this approach, two continuous state variables are pushed into discrete states by bucketing each continuous variable into multiple discrete states. This approach works with properly tuned parameters but a disadvantage is information gathered from one state is not used to evaluate another state. [[Tile coding]] can be used to improve discretization and involves continuous variables mapping into sets of buckets offset from one another. Each step of training has a wider impact on the value function approximation because when the offset grids are summed, the information is diffused.&lt;ref&gt;{{Cite web |url=http://webdocs.cs.ualberta.ca/~sutton/book/8/node6.html#SECTION00132000000000000000 |title=Archived copy |access-date=14 December 2011 |archive-url=https://web.archive.org/web/20120428052811/http://webdocs.cs.ualberta.ca/~sutton/book/8/node6.html#SECTION00132000000000000000 |archive-date=28 April 2012 |url-status=dead }}&lt;/ref&gt;

===Function approximation===

Function approximation is another way to solve the mountain car. By choosing a set of basis functions beforehand, or by generating them as the car drives, the agent can approximate the value function at each state. Unlike the step-wise version of the value function created with discretization, function approximation can more cleanly estimate the true smooth function of the mountain car domain.&lt;ref&gt;{{Cite web |url=http://webdocs.cs.ualberta.ca/~sutton/book/8/node9.html#SECTION00140000000000000000 |title=Archived copy |access-date=14 December 2011 |archive-url=https://web.archive.org/web/20120430105833/http://webdocs.cs.ualberta.ca/~sutton/book/8/node9.html#SECTION00140000000000000000 |archive-date=30 April 2012 |url-status=dead }}&lt;/ref&gt;

===Eligibility Traces===

An interesting aspect of the problem involves the delay of actual reward. The agent isn't able to learn about the goal until a successful completion. Given a naive approach for each trial the car can only backup the reward of the goal slightly. This is a problem for naive discretization because each discrete state will only be backed up once, taking a larger number of episodes to learn the problem. This problem can be alleviated via the mechanism of eligibility traces, which will automatically backup the reward given to states before, dramatically increasing the speed of learning. Eligibility traces can be viewed as a bridge from [[temporal difference learning]] methods to [[Monte Carlo method|Monte Carlo]] methods.&lt;ref&gt;{{Cite book|title=Reinforcement Learning: An Introduction|last=Sutton|first=Richard S.|last2=Barto|first2=Andrew G.|last3=Bach|first3=Francis|date=2018-11-13|publisher=A Bradford Book|isbn=9780262039246|edition= Second |language=en|chapter=7. Eligibility Traces|chapter-url=http://www.incompleteideas.net/book/ebook/node72.html}}&lt;/ref&gt;

==Technical details==
The mountain car problem has undergone many iterations. This section will focus on the standard well defined version from Sutton (2008).&lt;ref name=":2"&gt;[Sutton, 2008] Mountain Car Software. Richard s. Sutton. http://www.cs.ualberta.ca/~sutton/MountainCar/MountainCar.html {{Webarchive|url=https://web.archive.org/web/20091012074554/http://www.cs.ualberta.ca/~sutton/MountainCar/MountainCar.html |date=12 October 2009 }}&lt;/ref&gt;

===State variables===

Two-dimensional continuous state space.

&lt;math&gt;Velocity = (-0.07,0.07)&lt;/math&gt;

&lt;math&gt;Position = (-1.2,0.6)&lt;/math&gt;

===Actions===

One-dimensional discrete action space.

&lt;math&gt;motor = (left, neutral, right)&lt;/math&gt;

===Reward===

For every time step:

&lt;math&gt;reward = -1&lt;/math&gt;

===Update function===

For every time step:

&lt;math&gt;Action = [-1,0,1]&lt;/math&gt;

&lt;math&gt;Velocity = Velocity + (Action) *0.001+\cos(3*Position)*(-0.0025)&lt;/math&gt;

&lt;math&gt;Position = Position + Velocity&lt;/math&gt;

===Starting condition===

Optionally, many implementations include randomness in both parameters to show better generalized learning.

&lt;math&gt;Position = -0.5&lt;/math&gt;

&lt;math&gt;Velocity = 0.0&lt;/math&gt;

===Termination condition===

End the simulation when:

&lt;math&gt;Position \ge 0.6&lt;/math&gt;

==Variations==
There are many versions of the mountain car which deviate in different ways from the standard model. Variables that vary include but are not limited to changing the constants (gravity and steepness) of the problem so specific tuning for specific policies become irrelevant and altering the reward function to affect the agent's ability to learn in a different manner. An example is changing the reward to be equal to the distance from the goal, or changing the reward to zero everywhere and one at the goal. Additionally we can use a 3D mountain car with a 4D continuous state space.&lt;ref&gt;{{Cite web |url=http://library.rl-community.org/wiki/Mountain_Car_3D_(CPP) |title=Archived copy |access-date=14 December 2011 |archive-url=https://web.archive.org/web/20120426050959/http://library.rl-community.org/wiki/Mountain_Car_3D_(CPP) |archive-date=26 April 2012 |url-status=dead }}&lt;/ref&gt;

== References ==
{{Reflist}}

==Implementations==
* [https://web.archive.org/web/20170812005447/http://incompleteideas.net/sutton/MountainCar/MountainCar.html C++ Mountain Car Software. Richard s. Sutton.]
* [http://library.rl-community.org/wiki/Mountain_Car_(Java) Java Mountain Car with support for RL Glue]
* [https://mpatacchiola.github.io/blog/2017/08/14/dissecting-reinforcement-learning-6.html Python, with good discussion (blog post - down page)]

== Further reading ==
* {{cite paper | citeseerx = 10.1.1.51.4764 | title = Mountain Car with Sparse Coarse Coding | year = 1996 | pages = 1038–1044 }}
* [http://www-all.cs.umass.edu/pubs/1995_96/singh_s_ML96.pdf Mountain Car with Replacing Eligibility Traces]
* {{cite paper | citeseerx = 10.1.1.97.9314 | title = More discussion on Continuous State Spaces | year = 2000 | pages = 903–910 }}
* [http://www.mendeley.com/research/reinforcement-learning-with-gaussian-processes/ Gaussian Processes with Mountain Car]

&lt;!--- Categories ---&gt;
[[Category:Machine learning]]</text>
      <sha1>2jj4ex7ladwyxucfqbxj81wzmvryqf8</sha1>
    </revision>
  </page>
  <page>
    <title>Leave-one-out error</title>
    <ns>0</ns>
    <id>33890474</id>
    <revision>
      <id>972228787</id>
      <parentid>950368685</parentid>
      <timestamp>2020-08-10T22:59:43Z</timestamp>
      <contributor>
        <username>Habil zare</username>
        <id>13869869</id>
      </contributor>
      <minor/>
      <comment>/* References */ Jackknife resampling</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3314" xml:space="preserve">{{Multiple issues|
{{confusing|date=November 2011}}
{{context|date=November 2011}}
}}
{{broader|Cross-validation (statistics)}}
'''Leave-one-out error''' can refer to the following:

* '''Leave-one-out cross-validation Stability''' ('''CVloo''', for ''stability of Cross Validation with leave one out''): An [[algorithm]] f has CVloo stability β with respect to the [[loss function]] V if the following holds:

&lt;math&gt;\forall i\in\{1,...,m\}, \mathbb{P}_S\{\sup_{z\in Z}|V(f_S,z_i)-V(f_{S^{|i}},z_i)|\leq\beta_{CV}\}\geq1-\delta_{CV}&lt;/math&gt;
* '''Expected-to-leave-one-out error Stability''' (&lt;math&gt;Eloo_{err}&lt;/math&gt;, for ''Expected error from leaving one out''): An algorithm f has &lt;math&gt;Eloo_{err}&lt;/math&gt; stability if for each n there exists a&lt;math&gt;\beta_{EL}^m&lt;/math&gt; and a &lt;math&gt;\delta_{EL}^m&lt;/math&gt; such that:

&lt;math&gt;\forall i\in\{1,...,m\}, \mathbb{P}_S\{|I[f_S]-\frac{1}{m}\sum_{i=1}^m V(f_{S^{|i}},z_i)|\leq\beta_{EL}^m\}\geq1-\delta_{EL}^m&lt;/math&gt;, with &lt;math&gt;\beta_{EL}^m&lt;/math&gt;and &lt;math&gt;\delta_{EL}^m&lt;/math&gt; going to zero for &lt;math&gt;n\rightarrow\inf&lt;/math&gt;

==Preliminary notations==
With X and Y being a [[subset]] of the [[real number]]s R, or X and Y ⊂ R, being respectively an input space X and an output space Y, we consider a [[training set]]:

&lt;math&gt;S = \{z_1 = (x_1,\ y_1)\ ,..,\ z_m = (x_m,\ y_m)\}&lt;/math&gt;
of size m in &lt;math&gt;Z = X \times Y&lt;/math&gt; drawn [[Independent and identically distributed random variables|independently and identically distributed]] (i.i.d.) from an unknown distribution, here called "D". Then a [[Learning algorithms|learning algorithm]] is a function &lt;math&gt;f &lt;/math&gt; from &lt;math&gt;Z_m&lt;/math&gt; into &lt;math&gt; F \subset YX &lt;/math&gt; which [[Map (mathematics)|maps]] a [[Training, validation, and test sets|learning set]] S onto a function &lt;math&gt;f_S&lt;/math&gt; from the input space X to the output space Y. To avoid complex notation, we consider only [[deterministic algorithm]]s. It is also assumed that the algorithm &lt;math&gt;f&lt;/math&gt; is symmetric with respect to S, i.e. it does not depend on the order of the elements in the [[Training, validation, and test sets|training set]]. Furthermore, we assume that all functions are measurable and all sets are countable which does not limit the interest of the results presented here.

The loss of an [[hypothesis]] '''&lt;big&gt;f&lt;/big&gt;''' with respect to an example &lt;math&gt;z = (x,y)&lt;/math&gt; is then defined as &lt;math&gt;V(f,z) = V(f(x),y)&lt;/math&gt;.
The [[Generalization error|empirical error]] of '''&lt;big&gt;f&lt;/big&gt;''' can then be written as &lt;math&gt;I_S[f] = \frac{1}{n}\sum V(f,z_i)&lt;/math&gt;.

The [[Approximation error|true error]] of '''&lt;big&gt;f&lt;/big&gt;''' is &lt;math&gt;I[f] = \mathbb{E}_z V(f,z)&lt;/math&gt;

Given a training set S of size m, we will build, for all i = 1....,m, modified training sets as follows:
* By removing the i-th element
&lt;math&gt;S^{|i} = \{z_1 ,...,\ z_{i-1},\ z_{i+1},...,\ z_m\}&lt;/math&gt;
* and/or{{clarify|date=April 2020}} by replacing the i-th element
&lt;math&gt;S^i = \{z_1 ,...,\ z_{i-1},\ z_i',\ z_{i+1},...,\ z_m\}&lt;/math&gt;

== See also ==
* [[Jackknife resampling]]

==References==
*S. Mukherjee, P. Niyogi, T. Poggio, and R. M. Rifkin. Learning theory: stability is sufficient for generalization and necessary and sufficient for consistency of empirical risk minimization. Adv. Comput. Math., 25(1-3):161–193, 2006

[[Category:Machine learning]]</text>
      <sha1>swq4x0c0nvpyruk9j762o39lg96f69v</sha1>
    </revision>
  </page>
  <page>
    <title>Representer theorem</title>
    <ns>0</ns>
    <id>35887507</id>
    <revision>
      <id>978070843</id>
      <parentid>976897545</parentid>
      <timestamp>2020-09-12T18:39:16Z</timestamp>
      <contributor>
        <ip>98.248.96.29</ip>
      </contributor>
      <comment>/* Formal statement */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="13654" xml:space="preserve">{{context|date=June 2012}}

In [[Computational learning theory|statistical learning theory]], a '''representer theorem''' is any of several related results stating that a minimizer &lt;math&gt;f^{*}&lt;/math&gt; of a regularized [[Empirical risk minimization|empirical risk functional]] defined over a [[reproducing kernel Hilbert space]] can be represented as a finite linear combination of kernel products evaluated on the input points in the training set data.

==Formal statement==
The following Representer Theorem and its proof are due to [[Bernhard Schölkopf|Schölkopf]], Herbrich, and Smola:

'''Theorem:''' Consider a positive-definite real-valued kernel &lt;math&gt;k : \mathcal{X} \times \mathcal{X} \to \R&lt;/math&gt; on a non-empty set &lt;math&gt;\mathcal{X}&lt;/math&gt; with a corresponding reproducing kernel Hilbert space &lt;math&gt;H_k&lt;/math&gt;.  Let there be given
* a training sample &lt;math&gt;(x_1, y_1), \dotsc, (x_n, y_n) \in \mathcal{X} \times \R&lt;/math&gt;,
* a strictly increasing real-valued function &lt;math&gt;g \colon [0, \infty) \to \R&lt;/math&gt;, and
* an arbitrary error function &lt;math&gt;E \colon (\mathcal{X} \times \R^2)^n \to \R \cup \lbrace \infty \rbrace&lt;/math&gt;, 
which together define the following regularized empirical risk functional on &lt;math&gt;H_k&lt;/math&gt;:

:&lt;math&gt;
 f \mapsto E\left( (x_1, y_1, f(x_1)), ..., (x_n, y_n, f(x_n)) \right) + g\left( \lVert f \rVert \right).
&lt;/math&gt;

Then, any minimizer of the empirical risk

:&lt;math&gt;
 f^{*} = \operatorname{arg min}_{f \in H_k} \left\lbrace E\left( (x_1, y_1, f(x_1)), ..., (x_n, y_n, f(x_n)) \right) + g\left( \lVert f \rVert \right) \right \rbrace, \quad (*)
&lt;/math&gt;

admits a representation of the form:

:&lt;math&gt;
 f^{*}(\cdot) = \sum_{i = 1}^n \alpha_i k(\cdot, x_i),
&lt;/math&gt;

where &lt;math&gt;\alpha_i \in \R&lt;/math&gt; for all &lt;math&gt;1 \le i \le n&lt;/math&gt;.

'''Proof:'''
Define a mapping

:&lt;math&gt;
\begin{align}
 \varphi \colon \mathcal{X} &amp;\to \R\\
\varphi(x) &amp;= k(\cdot, x)
\end{align}
&lt;/math&gt;

(so that &lt;math&gt;\varphi(x) = k(\cdot, x)&lt;/math&gt; is itself a map &lt;math&gt;\mathcal{X} \to \R&lt;/math&gt;).  Since &lt;math&gt;k&lt;/math&gt; is a reproducing kernel, then

:&lt;math&gt;
 \varphi(x)(x') = k(x', x) = \langle \varphi(x'), \varphi(x) \rangle,
&lt;/math&gt;
where &lt;math&gt;\langle \cdot, \cdot \rangle&lt;/math&gt; is the inner product on &lt;math&gt;H_k&lt;/math&gt;.

Given any &lt;math&gt;x_1, ..., x_n&lt;/math&gt;, one can use orthogonal projection to decompose any &lt;math&gt;f \in H_k&lt;/math&gt; into a sum of two functions, one lying in &lt;math&gt;\operatorname{span} \left \lbrace \varphi(x_1), ..., \varphi(x_n) \right \rbrace&lt;/math&gt;, and the other lying in the orthogonal complement:

:&lt;math&gt;
 f = \sum_{i = 1}^n \alpha_i \varphi(x_i) + v,
&lt;/math&gt;
where &lt;math&gt;\langle v, \varphi(x_i) \rangle = 0&lt;/math&gt; for all &lt;math&gt;i&lt;/math&gt;.

The above orthogonal decomposition and the [[Reproducing kernel Hilbert space#The Reproducing Property|reproducing property]] together show that applying &lt;math&gt;f&lt;/math&gt; to any training point &lt;math&gt;x_j&lt;/math&gt; produces

:&lt;math&gt;
 f(x_j) = \left \langle \sum_{i = 1}^n \alpha_i \varphi(x_i) + v, \varphi(x_j) \right \rangle = \sum_{i = 1}^n \alpha_i \langle \varphi(x_i), \varphi(x_j) \rangle,
&lt;/math&gt;

which we observe is independent of &lt;math&gt;v&lt;/math&gt;.  Consequently, the value of the error function &lt;math&gt;E&lt;/math&gt; in (*) is likewise independent of &lt;math&gt;v&lt;/math&gt;.  For the second term (the regularization term), since &lt;math&gt;v&lt;/math&gt; is orthogonal to &lt;math&gt;\sum_{i = 1}^n \alpha_i \varphi(x_i)&lt;/math&gt; and &lt;math&gt;g&lt;/math&gt; is strictly monotonic, we have

:&lt;math&gt;
\begin{align}
 g\left( \lVert f \rVert \right) &amp;= g \left(  \lVert \sum_{i = 1}^n \alpha_i \varphi(x_i) + v \rVert \right) \\
&amp;= g \left( \sqrt{  \lVert \sum_{i = 1}^n \alpha_i \varphi(x_i)  \rVert^2 + \lVert v \rVert^2} \right) \\
&amp;\ge g \left(  \lVert \sum_{i = 1}^n \alpha_i \varphi(x_i) \rVert \right).
\end{align}
&lt;/math&gt;

Therefore setting &lt;math&gt;v = 0&lt;/math&gt; does not affect the first term of (*), while it strictly decreases the second term.  Consequently, any minimizer &lt;math&gt;f^{*}&lt;/math&gt; in (*) must have &lt;math&gt;v = 0&lt;/math&gt;, i.e., it must be of the form

:&lt;math&gt;
 f^{*}(\cdot) = \sum_{i = 1}^n \alpha_i \varphi(x_i) = \sum_{i = 1}^n \alpha_i k(\cdot, x_i),
&lt;/math&gt;

which is the desired result.

==Generalizations==
The Theorem stated above is a particular example of a family of results that are collectively referred to as "representer theorems"; here we describe several such.

The first statement of a representer theorem was due to Kimeldorf and Wahba for the special case in which

:&lt;math&gt;
\begin{align}
E\left( (x_1, y_1, f(x_1)), ...,  (x_n, y_n, f(x_n)) \right) &amp;= \frac{1}{n} \sum_{i = 1}^n (f(x_i) - y_i)^2, \\
g(\lVert f \rVert) &amp;= \lambda \lVert f \rVert^2
\end{align}
&lt;/math&gt;

for &lt;math&gt;\lambda &gt; 0&lt;/math&gt;.  Schölkopf, Herbrich, and Smola generalized this result by relaxing the assumption of the squared-loss cost and allowing the regularizer to be any strictly monotonically increasing function &lt;math&gt;g(\cdot)&lt;/math&gt; of the Hilbert space norm.

It is possible to generalize further by augmenting the regularized empirical risk functional through the addition of unpenalized offset terms.  For example, Schölkopf, Herbrich, and Smola also consider the minimization

:&lt;math&gt;
 \tilde{f}^{*} = \operatorname{arg min} \left\lbrace E\left( (x_1, y_1, \tilde{f}(x_1)),  ...,  (x_n, y_n, \tilde{f}(x_n)) \right) + g\left( \lVert f \rVert \right) \mid \tilde{f} = f  + h \in H_k \oplus  \operatorname{span} \lbrace \psi_p \mid 1 \le p \le M \rbrace  \right \rbrace, \quad (\dagger)
&lt;/math&gt;

i.e., we consider functions of the form &lt;math&gt;\tilde{f} = f + h&lt;/math&gt;, where &lt;math&gt;f \in H_k&lt;/math&gt; and &lt;math&gt;h&lt;/math&gt; is an unpenalized function lying in the span of a finite set of real-valued functions &lt;math&gt;\lbrace \psi_p \colon \mathcal{X} \to \R \mid 1 \le p \le M \rbrace&lt;/math&gt;.  Under the assumption that the &lt;math&gt;m \times M&lt;/math&gt; matrix &lt;math&gt;\left( \psi_p(x_i) \right)_{ip}&lt;/math&gt; has rank &lt;math&gt;M&lt;/math&gt;, they show that the minimizer &lt;math&gt;\tilde{f}^{*}&lt;/math&gt; in &lt;math&gt;(\dagger)&lt;/math&gt;
admits a representation of the form

:&lt;math&gt;
 \tilde{f}^{*}(\cdot) = \sum_{i = 1}^n \alpha_i k(\cdot, x_i) + \sum_{p = 1}^M \beta_p \psi_p(\cdot)
&lt;/math&gt;

where &lt;math&gt;\alpha_i, \beta_p \in \R&lt;/math&gt; and the &lt;math&gt;\beta_p&lt;/math&gt; are all uniquely determined.

The conditions under which a representer theorem exists were investigated by Argyriou, Micchelli, and Pontil, who proved the following:

'''Theorem:''' Let &lt;math&gt;\mathcal{X}&lt;/math&gt; be a nonempty set, &lt;math&gt;k&lt;/math&gt; a positive-definite real-valued kernel on &lt;math&gt;\mathcal{X} \times \mathcal{X}&lt;/math&gt; with corresponding reproducing kernel Hilbert space &lt;math&gt;H_k&lt;/math&gt;, and let &lt;math&gt;R \colon H_k \to \R&lt;/math&gt; be a differentiable regularization function.  Then given a training sample &lt;math&gt;(x_1, y_1), ..., (x_n, y_n) \in \mathcal{X} \times \R&lt;/math&gt; and an arbitrary error function &lt;math&gt;E \colon (\mathcal{X} \times \R^2)^m \to \R \cup \lbrace \infty \rbrace&lt;/math&gt;, a minimizer

:&lt;math&gt;
f^{*} =  \operatorname{arg min}_{f \in H_k} \left\lbrace E\left( (x_1, y_1, f(x_1)), ...,  (x_n, y_n, f(x_n)) \right) + R(f) \right \rbrace \quad (\ddagger)
&lt;/math&gt;

of the regularized empirical risk admits a representation of the form

:&lt;math&gt;
 f^{*}(\cdot) = \sum_{i = 1}^n \alpha_i k(\cdot, x_i),
&lt;/math&gt;

where &lt;math&gt;\alpha_i \in \R&lt;/math&gt; for all &lt;math&gt;1 \le i \le n&lt;/math&gt;, if and only if there exists a nondecreasing function &lt;math&gt;h \colon [0, \infty) \to \R&lt;/math&gt; for which

:&lt;math&gt;
R(f) = h(\lVert f \rVert).
&lt;/math&gt;

Effectively, this result provides a necessary and sufficient condition on a differentiable regularizer &lt;math&gt;R(\cdot)&lt;/math&gt; under which the corresponding regularized empirical risk minimization &lt;math&gt;(\ddagger)&lt;/math&gt; will have a representer theorem.  In particular, this shows that a broad class of regularized risk minimizations (much broader than those originally considered by Kimeldorf and Wahba) have representer theorems.

==Applications==
Representer theorems are useful from a practical standpoint because they dramatically simplify the regularized [[Empirical risk minimization|empirical risk minimization]] problem &lt;math&gt;(\ddagger)&lt;/math&gt;.  In most interesting applications, the search domain &lt;math&gt;H_k&lt;/math&gt; for the minimization will be an infinite-dimensional subspace of &lt;math&gt;L^2(\mathcal{X})&lt;/math&gt;, and therefore the search (as written) does not admit implementation on finite-memory and finite-precision computers.  In contrast, the representation of &lt;math&gt;f^{*}(\cdot)&lt;/math&gt; afforded by a representer theorem reduces the original (infinite-dimensional) minimization problem to a search for the optimal &lt;math&gt;n&lt;/math&gt;-dimensional vector of coefficients &lt;math&gt;\alpha = (\alpha_1, ..., \alpha_n) \in \R^n&lt;/math&gt;; &lt;math&gt;\alpha&lt;/math&gt; can then be obtained by applying any standard function minimization algorithm.  Consequently, representer theorems provide the theoretical basis for the reduction of the general machine learning problem to algorithms that can actually be implemented on computers in practice.

{{no footnotes|date=June 2012}}

The following provides an example of how to solve for the minimizer whose existence is guaranteed by the representer theorem. This method works for any positive definite kernel &lt;math&gt;K&lt;/math&gt;, and allows us to transform a complicated (possibly infinite dimensional) optimization problem into a simple linear system that can be solved numerically. 

Assume that we are using a least squares error function 

&lt;center&gt;&lt;math&gt;
    E[(x_1, y_1, f(x_1)), \dots, (x_n, y_n, f(x_n))] := \sum_{j=1}^n (y_i - f(x_i))^2
&lt;/math&gt; &lt;/center&gt;

and a regularization function &lt;math&gt;
    g(x) = \lambda x^2
&lt;/math&gt;
for some &lt;math&gt;\lambda &gt; 0&lt;/math&gt;. By the representer theorem, the minimizer

&lt;center&gt;&lt;math&gt;
    f^* = \mathrm{argmin}_{f \in \mathcal{H}} \Big\{ E[(x_1, y_1, f(x_1)), \dots, (x_n, y_n, f(x_n))] + g(||f||_{\mathcal{H}}) \Big\} = \mathrm{argmin}_{f \in \mathcal{H}} \left\{ \sum_{i=1}^n (y_i - f(x_i))^2 + \lambda ||f||_{\mathcal{H}}^2 \right\}
&lt;/math&gt;&lt;/center&gt;

has the form

&lt;center&gt;&lt;math&gt;
    f^*(x) = \sum_{i=1}^{n} \alpha_i^* k(x, x_i)
&lt;/math&gt;&lt;/center&gt;

for some &lt;math&gt;\alpha^* = (\alpha_1^*, \dots, \alpha_n^*) \in \mathbb{R}^n&lt;/math&gt;. Noting that

&lt;center&gt;&lt;math&gt;
    ||f||_{\mathcal{H}}^2 
    = \Big\langle \sum_{i=1}^{n} \alpha_i^* k(\cdot, x_i), \sum_{j=1}^{n} \alpha_j^* k(\cdot, x_j) \Big\rangle_{\mathcal{H}}
    = \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i^* \alpha_j^* \big\langle  k(\cdot, x_i), k(\cdot, x_j) \big\rangle_{\mathcal{H}} 
    = \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i^* \alpha_j^* k(x_i, x_j),
&lt;/math&gt;&lt;/center&gt;

we see that &lt;math&gt;\alpha^*&lt;/math&gt; has the form

&lt;center&gt;&lt;math&gt;
    \alpha^* 
    = \mathrm{argmin}_{\alpha \in \mathbb{R}^n} \left\{ \sum_{i=1}^n \left(y_i - \sum_{j=1}^n \alpha_i k(x_j, x_i)\right)^2 + \lambda ||f||_{\mathcal{H}}^2 \right\} 
    = \mathrm{argmin}_{\alpha \in \mathbb{R}^n} \left\{ ||y - A \alpha||^2 + \lambda \alpha^\intercal A \alpha \right\}.
&lt;/math&gt;&lt;/center&gt;


where &lt;math&gt;A_{ij} = k(x_j, x_i)&lt;/math&gt; and &lt;math&gt;y = (y_1, \dots, y_n)&lt;/math&gt;. This can be factored out and simplified to
 
&lt;center&gt;&lt;math&gt;
    \alpha^* = \mathrm{argmin}_{\alpha \in \mathbb{R}^n}\left\{ \alpha^\intercal(A^\intercal A + \lambda A)\alpha - 2 \alpha^\intercal A y \right\}.
&lt;/math&gt;&lt;/center&gt;


Since &lt;math&gt;A^\intercal A + \lambda A&lt;/math&gt; is positive definite, there is indeed a single global minima for this expression. Let &lt;math&gt;F(\alpha) = \alpha^\intercal(A^\intercal A + \lambda A)\alpha - 2 \alpha^\intercal A y &lt;/math&gt; and note that &lt;math&gt;F&lt;/math&gt; is convex. Then &lt;math&gt;\alpha^*&lt;/math&gt;, the global minima, can be solved by setting &lt;math&gt;\nabla_{\alpha} F = 0&lt;/math&gt;. Recalling that all positive definite matricies are invertible, we see that

&lt;center&gt;&lt;math&gt;
    \nabla_{\alpha} F = 2(A^\intercal A + \lambda A)\alpha^* - 2Ay = 0 \Longrightarrow \alpha^* = (A^\intercal A + \lambda A)^{-1}Ay,
&lt;/math&gt;&lt;/center&gt;

so the minimizer may be found via a linear solve.

==See also==
* [[Mercer's theorem]]
* [[Kernel methods]]

==References==
{{reflist}}
&lt;!--- After listing your sources please cite them using inline citations and place them after the information they cite. Please see http://en.wikipedia.org/wiki/Wikipedia:REFB for instructions on how to add citations. ---&gt;
*{{cite journal
 |first1=Andreas |last1=Argyriou
 |first2=Charles A. |last2=Micchelli
 |first3=Massimiliano |last3=Pontil
 |title=When Is There a Representer Theorem? Vector Versus Matrix Regularizers
 |journal=Journal of Machine Learning Research
 |volume=10 |issue=Dec |pages=2507–2529  |year=2009
}}
*{{cite journal
 |first1=Felipe |last1=Cucker
 |first2=Steve |last2=Smale
 |title=On the Mathematical Foundations of Learning
 |journal=[[Bulletin of the American Mathematical Society]]
 |volume=39 |issue=1 |pages=1&amp;ndash;49 |year=2002
 |doi=10.1090/S0273-0979-01-00923-5
 |mr=1864085
|doi-access=free}}
*{{cite journal
 |first1=George S. |last1=Kimeldorf
 |first2=Grace |last2=Wahba
 |title=A correspondence between Bayesian estimation on stochastic processes and smoothing by splines
 |journal=The Annals of Mathematical Statistics
 |volume=41 |issue=2 |pages=495&amp;ndash;502 |year=1970
 |doi=10.1214/aoms/1177697089
|doi-access=free}}
*{{cite book
 |first1=Bernhard |last1=Schölkopf
 |first2=Ralf |last2=Herbrich
 |first3=Alex J. |last3=Smola
 |title=A Generalized Representer Theorem
 |journal=Computational Learning Theory
 |volume=2111 |pages=416&amp;ndash;426 |year=2001
 |doi=10.1007/3-540-44581-1_27
 |series=Lecture Notes in Computer Science
 |isbn=978-3-540-42343-0
|citeseerx=10.1.1.42.8617
 }}

[[Category:Computational learning theory]]
[[Category:Theoretical computer science]]
[[Category:Machine learning]]
[[Category:Hilbert space]]</text>
      <sha1>5dn3tqobx7z4pd5vnwmme0c27pvf7hu</sha1>
    </revision>
  </page>
  <page>
    <title>Parity learning</title>
    <ns>0</ns>
    <id>23864280</id>
    <revision>
      <id>989538871</id>
      <parentid>947099910</parentid>
      <timestamp>2020-11-19T15:50:25Z</timestamp>
      <contributor>
        <ip>84.245.121.159</ip>
      </contributor>
      <comment>/* {{Anchor|LPN}} Noisy version ("Learning Parity with Noise") */ fullstop</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2102" xml:space="preserve">'''Parity learning''' is a problem in [[machine learning]]. An algorithm that solves this problem must find a function ''ƒ'', given some samples (''x'',&amp;nbsp;''ƒ''(''x'')) and the assurance that ''ƒ'' computes the [[Parity function|parity]] of bits at some fixed locations. The samples are generated using some distribution over the input. The problem is easy to solve using [[Gaussian elimination]] provided that a sufficient number of samples (from a distribution which is not too skewed) are provided to the algorithm.

== {{Anchor|LPN}} Noisy version ("Learning Parity with Noise") ==
In Learning Parity with Noise (LPN), the samples may contain some error. Instead of samples (''x'',&amp;nbsp;''ƒ''(''x'')), the algorithm is provided with (''x'',&amp;nbsp;''y''), where for random boolean &lt;math&gt;b \in \{0,1\}&lt;/math&gt;

&lt;math&gt;y = \begin{cases} f(x), &amp; \text{if }b \\ 1-f(x), &amp; \text{otherwise} \end{cases}&lt;/math&gt;

The noisy version of the parity learning problem is conjectured to be hard.&lt;ref&gt;{{Cite arxiv|last=Wasserman|first=Hal|last2=Kalai|first2=Adam|last3=Blum|first3=Avrim|date=2000-10-15|title=Noise-Tolerant Learning, the Parity Problem, and the Statistical Query Model|eprint=cs/0010022|language=en}}&lt;/ref&gt;

== See also ==
* [[Learning with errors]]

== References ==
{{Reflist}}
* Avrim Blum, Adam Kalai, and Hal Wasserman, “Noise-tolerant learning, the parity problem, and the statistical query model,” J. ACM 50, no. 4 (2003): 506&amp;ndash;519.
* Adam Tauman Kalai, Yishay Mansour, and Elad Verbin, “On agnostic boosting and parity learning,” in Proceedings of the 40th annual ACM symposium on Theory of computing (Victoria, British Columbia, Canada: ACM, 2008), 629&amp;ndash;638, http://portal.acm.org/citation.cfm?id=1374466.
* Oded Regev, “On lattices, learning with errors, random linear codes, and cryptography,” in Proceedings of the thirty-seventh annual ACM symposium on Theory of computing (Baltimore, MD, USA: ACM, 2005), 84&amp;ndash;93, http://portal.acm.org/citation.cfm?id=1060590.1060603.

{{DEFAULTSORT:Parity Learning}}
[[Category:Machine learning]]


{{Mathapplied-stub}}</text>
      <sha1>941y24d20hbfuw0decp29luganpvds1</sha1>
    </revision>
  </page>
  <page>
    <title>Feature (machine learning)</title>
    <ns>0</ns>
    <id>1299404</id>
    <revision>
      <id>993569874</id>
      <parentid>993412520</parentid>
      <timestamp>2020-12-11T08:12:09Z</timestamp>
      <contributor>
        <ip>87.94.228.49</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="7219" xml:space="preserve">In [[machine learning]] and [[pattern recognition]], a '''feature''' is an individual measurable property or characteristic of a phenomenon being observed. &lt;ref name="ml"&gt;{{cite book |author=Bishop, Christopher |title=Pattern recognition and machine learning |publisher=Springer |location=Berlin |year=2006 |isbn=0-387-31073-8 }}&lt;/ref&gt; Choosing informative, discriminating and independent features is a crucial step for effective algorithms in [[pattern recognition]],  [[classification (machine learning)|classification]] and [[Regression analysis|regression]]. Features are usually numeric, but structural features such as [[string (computer science)|strings]] and [[Graph (discrete mathematics)|graphs]] are used in [[syntactic pattern recognition]].
The concept of "feature" is related to that of [[explanatory variable]] used in [[statistics|statistical]] techniques such as [[linear regression]].

==Classification==

A set of numeric features can be conveniently described by a feature vector.
One of the ways of achieving [[binary classification]] is using a [[linear predictor function]] (related to the [[perceptron]]) with a feature vector as input. The method consists of calculating the [[Dot product|scalar product]] between the feature vector and a vector of weights,
comparing the result with a threshold, and deciding the class based on the comparison.
 
Algorithms for classification from a feature vector include [[k-nearest neighbor algorithm|nearest neighbor classification]], [[neural networks]], and [[statistical classification|statistical techniques]] such as [[Bayesian inference|Bayesian approaches]].

==Examples==
{{also|Feature (computer vision)}}
In [[character recognition]], features may include [[histogram]]s counting the number of black pixels along horizontal and vertical directions, number of internal holes, stroke detection and many others.

In [[speech recognition]], features for recognizing [[phonemes]] can include noise ratios, length of sounds, relative power, filter matches and many others.

In [[spam (electronic)|spam]] detection algorithms, features may include the presence or absence of certain email headers, 
the email structure, the language, the frequency of specific terms, the grammatical correctness of the text.

In [[computer vision]], there are a large number of possible [[feature (computer vision)|features]], such as edges and objects.

==Extensions==
{{Redirect|Feature space|feature spaces in kernel machines|Kernel method}}
In [[pattern recognition]] and [[machine learning]], a '''feature vector''' is an n-dimensional [[vector (geometric)|vector]] of numerical features that represent some object. Many [[algorithm]]s in machine learning require a numerical representation of objects, since such representations facilitate processing and statistical analysis. When representing images, the feature values might correspond to the pixels of an image, while when representing texts the features might be the frequencies of occurrence of textual terms. Feature vectors are equivalent to the vectors of [[explanatory variable]]s used in [[statistics|statistical]] procedures such as [[linear regression]].  Feature vectors are often combined with weights using a [[dot product]] in order to construct a [[linear predictor function]] that is used to determine a score for making a prediction.

The [[vector space]] associated with these vectors is often called the '''feature space'''. In order to reduce the dimensionality of the feature space, a number of [[dimensionality reduction]] techniques can be employed.

Higher-level features can be obtained from already available features and added to the feature vector; for example, for the study of diseases the feature 'Age' is useful and is defined as ''Age = 'Year of death' minus 'Year of birth' ''. This process is referred to as '''feature construction'''.&lt;ref name=Liu1998&gt;Liu, H., Motoda H. (1998) ''[https://books.google.com/books?id=aaDbBwAAQBAJ&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false Feature Selection for Knowledge Discovery and Data Mining].'', Kluwer Academic Publishers. Norwell, MA, USA. 1998.&lt;/ref&gt;&lt;ref name=Piramithu2009&gt;Piramuthu, S., Sikora R. T. [https://www.sciencedirect.com/science/article/pii/S0957417408001309 Iterative feature construction for improving inductive learning algorithms]. In Journal of Expert Systems with Applications. Vol. 36 , Iss. 2 (March 2009), pp. 3401-3406, 2009&lt;/ref&gt; Feature construction is the application of a set of constructive operators to a set of existing features resulting in construction of new features. Examples of such constructive operators include checking for the equality conditions {=, ≠}, the arithmetic operators {+,−,×, /}, the array operators {max(S), min(S), average(S)} as well as other more sophisticated operators, for example count(S,C)&lt;ref name=bloedorn1998&gt;Bloedorn, E., Michalski, R. Data-driven constructive induction: a methodology and its applications. IEEE Intelligent Systems, Special issue on Feature Transformation and Subset Selection, pp. 30-37, March/April, 1998&lt;/ref&gt; that counts the number of features in the feature vector S satisfying some condition C or, for example, distances to other recognition classes generalized by some accepting device. Feature construction has long been considered a powerful tool for increasing both accuracy and understanding of structure, particularly in high-dimensional problems.&lt;ref name=breinman1984&gt;Breiman, L. Friedman, T., Olshen, R., Stone, C. (1984) ''Classification and regression trees'', Wadsworth&lt;/ref&gt; Applications include studies of disease and [[emotion recognition]] from speech.&lt;ref name=Sidorova2009&gt;Sidorova, J., Badia T. [https://ieeexplore.ieee.org/abstract/document/5402574/ Syntactic learning for ESEDA.1, tool for enhanced speech emotion detection and analysis]. Internet Technology and Secured Transactions Conference 2009 (ICITST-2009), London, November 9–12. IEEE&lt;/ref&gt;

==Selection and extraction==
The initial set of raw features can be redundant and too large to be managed. Therefore, a preliminary step in many applications of [[machine learning]] and [[pattern recognition]] consists of [[Feature selection|selecting]] a subset of features, or [[Feature extraction|constructing]] a new and reduced set of features to facilitate learning, and to improve generalization and interpretability{{Citation needed|date=October 2017}}.

[[feature extraction|Extracting]] or [[Feature selection|selecting]] features is a combination of art and science; developing systems to do so is known as [[feature engineering]]. It requires the experimentation of multiple possibilities and the combination of automated techniques with the intuition and knowledge of the [[domain expert]]. Automating this process is [[feature learning]], where a machine not only uses features for learning, but learns the features itself.

== See also ==
* [[Covariate]]
* [[Dimensionality reduction]]
* [[Feature engineering]]
* [[Hashing trick]]
* [[Statistical classification]]
*[[Explainable Artificial Intelligence]]

==References==
{{Reflist}}
{{Refimprove|date=December 2014}}

[[Category:Data mining]]
[[Category:Machine learning]]
[[Category:Pattern recognition]]</text>
      <sha1>00vbrge77lupqqf444b5tet05naez5r</sha1>
    </revision>
  </page>
  <page>
    <title>Feature hashing</title>
    <ns>0</ns>
    <id>36126852</id>
    <revision>
      <id>964491404</id>
      <parentid>956134498</parentid>
      <timestamp>2020-06-25T20:21:53Z</timestamp>
      <contributor>
        <username>Ira Leviton</username>
        <id>25046916</id>
      </contributor>
      <minor/>
      <comment>Replaced outdated html codes with wikicodes.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="12189" xml:space="preserve">In [[machine learning]], '''feature hashing''', also known as the '''hashing trick''' (by analogy to the [[kernel trick]]), is a fast and space-efficient way of vectorizing [[Feature (machine learning)|features]], i.e. turning arbitrary features into indices in a vector or matrix.&lt;ref name="Moody"&gt;{{cite journal |last1=Moody |first1=John |title=Fast learning in multi-resolution hierarchies |journal=Advances in Neural Information Processing Systems |date=1989 |url=http://papers.nips.cc/paper/175-fast-learning-in-multi-resolution-hierarchies.pdf}}&lt;/ref&gt;&lt;ref name="Weinberger"/&gt; It works by applying a [[hash function]] to the features and using their hash values as indices directly, rather than looking the indices up in an [[associative array]]. This trick is often attributed to Weinberger et al., but there exists a much earlier description of this method published by John Moody in 1989.&lt;ref name="Weinberger"/&gt;&lt;ref name="Moody"/&gt;

==Motivating example==
In a typical [[document classification]] task, the input to the machine learning algorithm (both during learning and classification) is free text. From this, a [[bag of words]] (BOW) representation is constructed: the individual [[Type–token distinction|tokens]] are extracted and counted, and each distinct token in the training set defines a [[Feature (machine learning)|feature]] (independent variable) of each of the documents in both the training and test sets.

Machine learning algorithms, however, are typically defined in terms of numerical vectors. Therefore, the bags of words for a set of documents is regarded as a [[term-document matrix]] where each row is a single document, and each column is a single feature/word; the entry {{math|''i'', ''j''}} in such a matrix captures the frequency (or weight) of the {{mvar|j}}'th term of the ''vocabulary'' in document {{mvar|i}}. (An alternative convention swaps the rows and columns of the matrix, but this difference is immaterial.)
Typically, these vectors are extremely [[sparse matrix|sparse]]—according to [[Zipf's law]].

The common approach is to construct, at learning time or prior to that, a ''dictionary'' representation of the vocabulary of the training set, and use that to map words to indices. [[Hash table]]s and [[trie]]s are common candidates for dictionary implementation. E.g., the three documents

* ''John likes to watch movies. ''
* ''Mary likes movies too.''
* ''John also likes football.''

can be converted, using the dictionary

{| class="wikitable"
|-
! Term !! Index
|-
| John || 1
|-
| likes || 2
|-
| to || 3
|-
| watch || 4
|-
| movies || 5
|-
| Mary || 6
|-
| too || 7
|-
| also || 8
|-
| football || 9
|}

to the term-document matrix

:&lt;math&gt;
\begin{pmatrix}
\textrm{John} &amp; \textrm{likes} &amp; \textrm{to} &amp; \textrm{watch} &amp; \textrm{movies} &amp; \textrm{Mary} &amp; \textrm{too} &amp; \textrm{also} &amp; \textrm{football} \\
1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 \\
1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 1
\end{pmatrix}
&lt;/math&gt;

(Punctuation was removed, as is usual in document classification and clustering.)

The problem with this process is that such dictionaries take up a large amount of storage space and grow in size as the training set grows.&lt;ref name="mobilenlp"&gt;{{cite conference |author1=K. Ganchev |author2=M. Dredze |year=2008 |url=http://www.cs.jhu.edu/~mdredze/publications/mobile_nlp_feature_mixing.pdf |title=Small statistical models by random feature mixing |conference=Proc. ACL08 HLT Workshop on Mobile Language Processing}}&lt;/ref&gt;  On the contrary, if the vocabulary is kept fixed and not increased with a growing training set, an adversary may try to invent new words or misspellings that are not in the stored vocabulary so as to circumvent a machine learned filter.  This difficulty is why feature hashing has been tried for [[spam filtering]] at [[Yahoo! Research]].&lt;ref&gt;{{cite journal |author1=Josh Attenberg |author2=Kilian Weinberger |author3=Alex Smola |author4=Anirban Dasgupta |author5=Martin Zinkevich |title=Collaborative spam filtering with the hashing trick |journal=Virus Bulletin |year=2009|url=https://www.virusbulletin.com/virusbulletin/2009/11/collaborative-spam-filtering-hashing-trick}}&lt;/ref&gt;

Note that the hashing trick isn't limited to text classification and similar tasks at the document level, but can be applied to any problem that involves large (perhaps unbounded) numbers of features.

==Feature vectorization using hashing trick==
Instead of maintaining a dictionary, a feature vectorizer that uses the hashing trick can build a vector of a pre-defined length by applying a hash function {{mvar|h}} to the features (e.g., words), then using the hash values directly as feature indices and updating the resulting vector at those indices. Here, we assume that feature actually means feature vector. 
&lt;syntaxhighlight lang="pascal"&gt;
 function hashing_vectorizer(features : array of string, N : integer):
     x := new vector[N]
     for f in features:
         h := hash(f)
         x[h mod N] += 1
     return x
&lt;/syntaxhighlight&gt;
Thus, if our feature vector is ["cat","dog","cat"] and hash function is &lt;math&gt; hash(x_f)=1&lt;/math&gt; if &lt;math&gt;x_f&lt;/math&gt; is "cat" and &lt;math&gt;2&lt;/math&gt; if &lt;math&gt;x_f&lt;/math&gt; is "dog". Let us take the output feature vector dimension ({{mono|N}}) to be 4. Then output {{mono|x}} will be [0,2,1,0].
It has been suggested that a second, single-bit output hash function {{mvar|ξ}} be used to determine the sign of the update value, to counter the effect of [[Hash table#Collision resolution|hash collision]]s.&lt;ref name="Weinberger"&gt;{{cite conference |author1=Kilian Weinberger |author2=Anirban Dasgupta |author3=John Langford |author4=Alex Smola |author5=Josh Attenberg |year=2009 |url=http://alex.smola.org/papers/2009/Weinbergeretal09.pdf |title=Feature Hashing for Large Scale Multitask Learning |conference=Proc. ICML}}&lt;/ref&gt; If such a hash function is used, the algorithm becomes
&lt;syntaxhighlight lang="pascal"&gt;
 function hashing_vectorizer(features : array of string, N : integer):
     x := new vector[N]
     for f in features:
         h := hash(f)
         idx := h mod N
         if ξ(f) == 1:
             x[idx] += 1
         else:
             x[idx] -= 1
     return x
&lt;/syntaxhighlight&gt;

The above pseudocode actually converts each sample into a vector. An optimized version would instead only generate a stream of ({{mvar|h}},{{mvar|ξ}}) pairs and let the learning and prediction algorithms consume such streams; a [[linear model]] can then be implemented as a single hash table representing the coefficient vector.

===Properties===
{| class="wikitable" style="float: right; margin-left: 1.5em; margin-right: 0; margin-top: 0;"
|-
! ''ξ''(''f''₁) !! ''ξ''(''f''₂) !! Final value, ''ξ''(''f''₁) + ''ξ''(''f''₂)
|-
| -1 || -1 || -2
|-
| -1 || 1 || 0
|-
| 1 || -1 || 0
|-
| 1 || 1 || 2
|}

When a second hash function ''ξ'' is used to determine the sign of a feature's value, the [[Expected value|expected]] [[mean]] of each column in the output array becomes zero because ''ξ'' causes some collisions to cancel out.&lt;ref name="Weinberger"/&gt; E.g., suppose an input contains two symbolic features ''f''₁ and ''f''₂ that collide with each other, but not with any other features in the same input; then there are four possibilities which, if we make no assumptions about ''ξ'', have equal probability, as listed in the table on the right.

In this example, there is a 50% probability that the hash collision cancels out. Multiple hash functions can be used to further reduce the risk of collisions.&lt;ref name="mahout"&gt;{{cite book
|last1 = Owen
|first1 = Sean
|last2 = Anil
|first2 = Robin
|last3 = Dunning
|first3 = Ted
|last4 = Friedman
|first4 = Ellen
|title=Mahout in Action
|pages=261–265
|publisher = Manning
|year = 2012
}}&lt;/ref&gt;

Furthermore, if ''φ'' is the transformation implemented by a hashing trick with a sign hash ''ξ'' (i.e. ''φ''(''x'') is the feature vector produced for a sample ''x''), then [[inner product]]s in the hashed space are unbiased:

:&lt;math&gt; \mathbb{E}[\langle \varphi(x), \varphi(x') \rangle] = \langle x, x' \rangle&lt;/math&gt;

where the expectation is taken over the hashing function ''φ''.&lt;ref name="Weinberger"/&gt; It can be verified that&lt;math&gt;\langle \varphi(x), \varphi(x') \rangle&lt;/math&gt; is a [[Positive-definite matrix|positive semi-definite]] [[Kernel trick|kernel]].&lt;ref name="Weinberger"/&gt;&lt;ref&gt;{{cite conference|last=Shi|first=Q.|author2=Petterson J. |author3=Dror G. |author4=Langford J. |author5=Smola A. |author6=Strehl A. |author7=Vishwanathan V. |title=Hash Kernels|conference=AISTATS|year=2009}}&lt;/ref&gt;

===Extensions and variations===
Recent work extends the hashing trick to supervised mappings from words to indices,&lt;ref&gt;{{cite conference|last=Bai|first=B.|author2=Weston J. |author3=Grangier D. |author4=Collobert R. |author5=Sadamasa K. |author6=Qi Y. |author7=Chapelle O. |author8=Weinberger K. |title=Supervised semantic indexing|conference=CIKM|year=2009|pages=187–196|url=http://www.cs.cornell.edu/~kilian/papers/ssi-cikm.pdf}}&lt;/ref&gt;
which are explicitly learned to avoid collisions of important terms.

===Applications and practical performance===
Ganchev and Dredze showed that in text classification applications with random hash functions and several tens of thousands of columns in the output vectors, feature hashing need not have an adverse effect on classification performance, even without the signed hash function.&lt;ref name="mobilenlp"/&gt;
Weinberger et al. applied their variant of hashing to the problem of [[spam filter]]ing, formulating this as a [[multi-task learning]] problem where the input features are pairs (user, feature) so that a single parameter vector captured per-user spam filters as well as a global filter for several hundred thousand users, and found that the accuracy of the filter went up.&lt;ref name="Weinberger"/&gt;

==Implementations==
Implementations of the hashing trick are present in:

* [[Apache Mahout]]&lt;ref name="mahout" /&gt;
* [[Gensim]]&lt;ref&gt;{{cite web|url=http://radimrehurek.com/gensim/corpora/hashdictionary.html |title=gensim: corpora.hashdictionary – Construct word&lt;-&gt;id mappings |publisher=Radimrehurek.com |accessdate=2014-02-13}}&lt;/ref&gt;
* [[scikit-learn]]&lt;ref&gt;{{cite web|url=http://scikit-learn.org/stable/modules/feature_extraction.html#feature-hashing |title=4.1. Feature extraction — scikit-learn 0.14 documentation |publisher=Scikit-learn.org |accessdate=2014-02-13}}&lt;/ref&gt;
* sofia-ml&lt;ref&gt;{{cite web|url=https://code.google.com/p/sofia-ml/ |title=sofia-ml - Suite of Fast Incremental Algorithms for Machine Learning. Includes methods for learning classification and ranking models, using Pegasos SVM, SGD-SVM, ROMMA, Passive-Aggressive Perceptron, Perceptron with Margins, and Logistic Regression |accessdate=2014-02-13}}&lt;/ref&gt;
* [[Vowpal Wabbit]]
* [[Apache Spark]]&lt;ref&gt;{{cite web|url=https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.feature.HashingTF|title=Hashing TF|quote=Maps a sequence of terms to their term frequencies using the hashing trick.|accessdate=4 September 2015}}&lt;/ref&gt;
* [[R (programming language)|R]]&lt;ref&gt;{{cite web|url=https://cran.r-project.org/web/packages/FeatureHashing/index.html |title=FeatureHashing: Creates a Model Matrix via Feature Hashing With a Formula Interface}}&lt;/ref&gt;
* [[TensorFlow]]&lt;ref&gt;{{cite web|url=https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/hashing_trick |title=tf.keras.preprocessing.text.hashing_trick — TensorFlow Core v2.0.1 |quote=Converts a text to a sequence of indexes in a fixed-size hashing space. |accessdate=2020-04-29}}&lt;/ref&gt;

==See also==
* [[Bloom filter]]
* [[Count–min sketch]]
* [[Heaps' law]]
* [[Locality-sensitive hashing]]
* [[MinHash]]

==References==
{{Reflist|30em}}

==External links==
* [http://hunch.net/~jl/projects/hash_reps/index.html Hashing Representations for Machine Learning] on John Langford's website
* [https://web.archive.org/web/20120609232923/http://metaoptimize.com/qa/questions/6943/what-is-the-hashing-trick What is the "hashing trick"? - MetaOptimize Q+A]

[[Category:Hashing]]
[[Category:Machine learning]]
[[Category:Articles with example pseudocode]]</text>
      <sha1>4ih0bkcgf6wcjzc73np8dcjenc7re76</sha1>
    </revision>
  </page>
  <page>
    <title>Large margin nearest neighbor</title>
    <ns>0</ns>
    <id>28037054</id>
    <revision>
      <id>968622978</id>
      <parentid>962863539</parentid>
      <timestamp>2020-07-20T14:17:15Z</timestamp>
      <contributor>
        <username>Narky Blert</username>
        <id>22041646</id>
      </contributor>
      <comment>Link to DAB page repaired</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="9774" xml:space="preserve">'''Large margin nearest neighbor''' ('''LMNN''')&lt;ref name="Weinberger05"&gt;{{cite journal
 | last = Weinberger
 | first = K. Q.
 |author2=Blitzer J. C. |author3=Saul L. K.
 | title = Distance Metric Learning for Large Margin Nearest Neighbor Classification
 | journal = Advances in Neural Information Processing Systems |volume=18
 | year=2006
 | pages=1473–1480
 | url=http://papers.nips.cc/paper/2795-distance-metric-learning-for-large-margin-nearest-neighbor-classification
}}&lt;/ref&gt; '''classification''' is a statistical [[machine learning]] [[algorithm]] for [[similarity learning|metric learning]]. It learns a [[Pseudometric space|pseudometric]] designed for [[k-nearest neighbor]] classification. The algorithm is based on [[semidefinite programming]], a sub-class of [[convex optimization]].

The goal of [[supervised learning]] (more specifically classification) is to learn a decision rule that can categorize data instances into pre-defined classes. The  [[k-nearest neighbor]] rule assumes a ''training'' data set of labeled instances (i.e. the classes are known). It classifies a new data instance with the class obtained from the majority vote of the k closest (labeled) training instances. Closeness is measured with a pre-defined [[metric (mathematics)|metric]]. Large margin nearest neighbors is an algorithm that learns this global (pseudo-)metric in a supervised fashion to improve the classification accuracy of the k-nearest neighbor rule.

==Setup==

The main intuition behind LMNN is to learn a pseudometric under which all data instances in the training set are surrounded by at least k instances that share the same class label. If this is achieved, the [[leave-one-out error]] (a special case of [[Cross-validation (statistics)|cross validation]]) is minimized. Let the training data consist of a data set &lt;math&gt; D=\{(\vec x_1,y_1),\dots,(\vec x_n,y_n)\}\subset R^d\times C&lt;/math&gt;, where the set of possible class categories is &lt;math&gt;C=\{1,\dots,c\}&lt;/math&gt;.

The algorithm learns a pseudometric of the type 
:&lt;math&gt;d(\vec x_i,\vec x_j)=(\vec x_i-\vec x_j)^\top\mathbf{M}(\vec x_i-\vec x_j)&lt;/math&gt;.
For &lt;math&gt;d(\cdot,\cdot)&lt;/math&gt; to be well defined, the matrix &lt;math&gt;\mathbf{M}&lt;/math&gt; needs to be [[Positive semidefinite matrix|positive semi-definite]]. The Euclidean metric is a special case, where  &lt;math&gt;\mathbf{M}&lt;/math&gt; is the identity matrix. This generalization is often (falsely{{Citation needed|date=July 2019}}) referred  to as [[Mahalanobis metric]].

Figure 1 illustrates the effect of the metric under varying &lt;math&gt;\mathbf{M}&lt;/math&gt;. The two circles show the set of points with equal distance to the center &lt;math&gt;\vec x_i&lt;/math&gt;. In the Euclidean case this set is a circle, whereas under the modified (Mahalanobis) metric it becomes an [[ellipsoid]].

[[File:Lmnn.png|thumb|300px|Figure 1: Schematic illustration of LMNN.]]

The algorithm distinguishes between two types of special data points: ''target neighbors'' and ''impostors''.

===Target neighbors===

Target neighbors are selected before learning. Each instance &lt;math&gt;\vec x_i&lt;/math&gt; has exactly &lt;math&gt;k&lt;/math&gt; different target neighbors within &lt;math&gt;D&lt;/math&gt;, which all share the same class label &lt;math&gt;y_i&lt;/math&gt;. The target neighbors are the data points that ''should become'' nearest neighbors ''under the learned metric''. Let us denote the set of target neighbors for a data point &lt;math&gt;\vec x_i&lt;/math&gt; as &lt;math&gt;N_i&lt;/math&gt;.

===Impostors===

An impostor of a data point &lt;math&gt;\vec x_i&lt;/math&gt; is another data point &lt;math&gt;\vec x_j&lt;/math&gt; with a different class label (i.e. &lt;math&gt;y_i\neq y_j&lt;/math&gt;) which is one of the nearest neighbors of &lt;math&gt;\vec x_i&lt;/math&gt;. During learning the algorithm tries to minimize the number of impostors for all data instances in the training set.

==Algorithm==

Large margin nearest neighbors optimizes the matrix &lt;math&gt;\mathbf{M}&lt;/math&gt; with the help of [[semidefinite programming]]. The objective is twofold: For every data point &lt;math&gt;\vec x_i&lt;/math&gt;, the ''target neighbors'' should be ''close'' and  the ''impostors'' should be ''far away''. Figure 1 shows the effect of such an optimization on an illustrative example. The learned metric causes the input vector &lt;math&gt;\vec x_i&lt;/math&gt; to be surrounded by training instances of the same class.  If it was a test point, it would be classified correctly under the &lt;math&gt;k=3&lt;/math&gt; nearest neighbor rule.

The first optimization goal is achieved by minimizing the average distance between instances and their target neighbors
:&lt;math&gt;\sum_{i,j\in N_i} d(\vec x_i,\vec x_j)&lt;/math&gt;.

The second goal is achieved by penalizing distances to impostors &lt;math&gt;\vec x_l&lt;/math&gt; that are less than one unit further away than target neighbors &lt;math&gt;\vec x_j&lt;/math&gt; (and therefore pushing them out of the local neighborhood of &lt;math&gt;\vec x_i&lt;/math&gt;). The resulting value to be minimized can be stated as:
:&lt;math&gt;\sum_{i,j \in N_i,l, y_l\neq y_i}[d(\vec x_i,\vec x_j)+1-d(\vec x_i,\vec x_l)]_{+}&lt;/math&gt;

With a [[Hinge loss|hinge loss]] function &lt;math display="inline"&gt;[\cdot]_{+}=\max(\cdot,0)&lt;/math&gt;, which ensures that impostor proximity is not penalized when outside the margin. The margin of exactly one unit fixes the scale of the matrix &lt;math&gt;M&lt;/math&gt;. Any alternative choice &lt;math&gt;c&gt;0&lt;/math&gt; would result in a rescaling of &lt;math&gt;M&lt;/math&gt; by a factor of &lt;math&gt;1/c&lt;/math&gt;.

The final optimization problem becomes:
:&lt;math&gt; \min_{\mathbf{M}} \sum_{i,j\in N_i} d(\vec x_i,\vec x_j) + \lambda\sum_{i,j,l} \xi_{ijl}&lt;/math&gt;
:&lt;math&gt;\forall_{i,j \in N_i,l, y_l\neq y_i} &lt;/math&gt;
:&lt;math&gt;   d(\vec x_i,\vec x_j)+1-d(\vec x_i,\vec x_l)\leq \xi_{ijl}&lt;/math&gt;
:&lt;math&gt; \xi_{ijl}\geq 0&lt;/math&gt;
:&lt;math&gt; \mathbf{M}\succeq 0&lt;/math&gt;

The hyperparameter &lt;math display="inline"&gt;\lambda&gt;0&lt;/math&gt; is some positive constant (typically set through cross-validation). Here the variables &lt;math&gt;\xi_{ijl}&lt;/math&gt; (together with two types of constraints) replace the term in the cost function. They play a role similar to [[slack variable]]s to absorb the extent of violations of the impostor constraints. The last constraint ensures that &lt;math&gt;\mathbf{M}&lt;/math&gt; is positive semi-definite. The optimization problem is an instance of [[semidefinite programming]] (SDP). Although SDPs tend to suffer from high computational complexity, this particular SDP instance can be solved very efficiently due to the underlying geometric properties of the problem. In particular, most impostor constraints are naturally satisfied and do not need to be enforced during runtime (i.e.  the set of variables &lt;math&gt;\xi_{ijl}&lt;/math&gt;is sparse). A particularly well suited solver technique is the [[working set]] method, which keeps a small set of constraints that are actively enforced and monitors the remaining (likely satisfied) constraints only occasionally to ensure correctness.

==Extensions and efficient solvers==

LMNN was extended to multiple local metrics in the 2008 paper.&lt;ref name="Weinberger08"&gt;{{cite journal
 | last = Weinberger
 | first = K. Q.
 | author2 = Saul L. K.
 | title = Fast solvers and efficient implementations for distance metric learning
 | journal = [[Proceedings of International Conference on Machine Learning]]
 | year = 2008
 | pages = 1160–1167
 | url = http://research.yahoo.net/files/icml2008a.pdf
 | access-date = 2010-07-14
 | archive-url = https://web.archive.org/web/20110724135244/http://research.yahoo.net/files/icml2008a.pdf
 | archive-date = 2011-07-24
 | url-status = dead
 }}&lt;/ref&gt; 
This extension significantly improves the classification error, but involves a more expensive optimization problem. In their 2009 publication in the Journal of Machine Learning Research,&lt;ref name="Weinberger09"&gt;{{cite journal
 | last = Weinberger
 | first = K. Q.
 |author2=Saul L. K.
  | title = Distance Metric Learning for Large Margin Classification
 | journal = [[Journal of Machine Learning Research]]
 | year=2009
 | volume = 10 | pages = 207–244
 | url=http://www.jmlr.org/papers/volume10/weinberger09a/weinberger09a.pdf
}}&lt;/ref&gt; Weinberger and Saul derive an efficient solver for the semi-definite program. It can learn a metric for the [http://yann.lecun.com/exdb/mnist/ MNIST handwritten digit data set] in several hours, involving billions of pairwise constraints. An [[Open-source software|open source]] [[Matlab]] implementation is freely available at the [https://web.archive.org/web/20120313162120/http://www.cse.wustl.edu/~kilian/code/code.html authors web page].

Kumal et al.&lt;ref name="kumar07"&gt;{{cite journal
 | last = Kumar
 | first= M.P.
 |author2=Torr P.H.S. |author3=Zisserman A.
  | title =An invariant large margin nearest neighbour classifier
 | journal= IEEE 11th International Conference on Computer Vision (ICCV), 2007 
 | year=2007
 | pages= 1–8
 | doi= 10.1109/ICCV.2007.4409041
 | isbn= 978-1-4244-1630-1
 }}&lt;/ref&gt; extended the algorithm to incorporate local invariances to multivariate [[polynomial transformations]] and improved regularization.

==See also==
{{div col}}
* [[Similarity learning]]
* [[Linear discriminant analysis]]
* [[Learning vector quantization]]
* [[Pseudometric space]]
* [[Nearest neighbor search]]
* [[Cluster analysis]]
* [[Classification (machine learning)|Data classification]]
* [[Data mining]]
* [[Machine learning]]
* [[Pattern recognition]]
* [[Predictive analytics]]
* [[Dimension reduction]]
* [[Neighbourhood components analysis]]
{{div col end}}

==References==
{{reflist}}

==External links==
* [https://web.archive.org/web/20120313162120/http://www.cse.wustl.edu/~kilian/code/code.html Matlab Implementation]
* [https://compscicenter.ru/media/slides/machine_learning_1_2012_spring/2012_05_03_machine_learning_1_2012_spring.pdf ICML 2010 Tutorial on Metric Learning]

[[Category:Classification algorithms]]
[[Category:Machine learning]]</text>
      <sha1>qcdu0gwml50bx3y2xmfahm9tfsj6jph</sha1>
    </revision>
  </page>
  <page>
    <title>Statistical learning theory</title>
    <ns>0</ns>
    <id>1053303</id>
    <revision>
      <id>967208509</id>
      <parentid>964324640</parentid>
      <timestamp>2020-07-11T20:44:36Z</timestamp>
      <contributor>
        <username>Omnipaedista</username>
        <id>8524693</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="9431" xml:space="preserve">{{about|statistical learning in machine learning|its use in psychology|Statistical learning in language acquisition}}
{{see also|Computational learning theory}}
{{machine learning bar}}
'''Statistical learning theory''' is a framework for [[machine learning]]
drawing from the fields of [[statistics]] and [[functional analysis]].&lt;ref&gt;[[Trevor Hastie]], Robert Tibshirani, Jerome Friedman (2009) ''The Elements of Statistical Learning'', Springer-Verlag {{isbn|978-0-387-84857-0}}.&lt;/ref&gt;&lt;ref&gt;{{Cite Mehryar Afshin Ameet 2012}}&lt;/ref&gt; Statistical learning theory deals with the problem of finding a predictive function based on data. Statistical learning theory has led to successful applications in fields such as [[computer vision]], [[speech recognition]], and [[bioinformatics]].

==Introduction==
The goals of learning are understanding and prediction. Learning falls into many categories, including [[supervised learning]], [[unsupervised learning]], [[Online machine learning|online learning]], and [[reinforcement learning]]. From the perspective of statistical learning theory, supervised learning is best understood.&lt;ref&gt;Tomaso Poggio, Lorenzo Rosasco, et al. ''Statistical Learning Theory and Applications'', 2012, [https://www.mit.edu/~9.520/spring12/slides/class01/class01.pdf Class 1]&lt;/ref&gt; Supervised learning involves learning from a [[training set]] of data. Every point in the training is an input-output pair, where the input maps to an output. The learning problem consists of inferring the function that maps between the input and the output, such that the learned function can be used to predict the output from future input.

Depending on the type of output, supervised learning problems are either problems of [[regression analysis|regression]] or problems of [[Statistical classification|classification]]. If the output takes a continuous range of values, it is a regression problem. Using [[Ohm's Law]] as an example, a regression could be performed with voltage as input and current as an output. The regression would find the functional relationship between voltage and current to be {{nowrap|&lt;math&gt;R&lt;/math&gt;}}, such that
:&lt;math&gt;
V = I R
&lt;/math&gt;
Classification problems are those for which the output will be an element from a discrete set of labels. Classification is very common for machine learning applications. In [[facial recognition system|facial recognition]], for instance, a picture of a person's face would be the input, and the output label would be that person's name. The input would be represented by a large multidimensional vector whose elements represent pixels in the picture.

After learning a function based on the training set data, that function is validated on a test set of data, data that did not appear in the training set.

==Formal description==
Take &lt;math&gt;X&lt;/math&gt; to be the [[vector space]] of all possible inputs, and &lt;math&gt;Y&lt;/math&gt; to be
the vector space of all possible outputs. Statistical learning theory takes the perspective that there is some unknown [[probability distribution]] over the product space &lt;math&gt;Z = X \times Y&lt;/math&gt;, i.e. there exists some unknown &lt;math&gt;p(z) = p(\vec{x},y)&lt;/math&gt;. The training set is made up of &lt;math&gt;n&lt;/math&gt; samples from this probability distribution, and is notated 
:&lt;math&gt;S = \{(\vec{x}_1,y_1), \dots ,(\vec{x}_n,y_n)\} = \{\vec{z}_1, \dots ,\vec{z}_n\}&lt;/math&gt;
Every &lt;math&gt;\vec{x}_i&lt;/math&gt; is an input vector from the training data, and &lt;math&gt;y_i&lt;/math&gt;
is the output that corresponds to it.

In this formalism, the inference problem consists of finding a function &lt;math&gt;f: X \to Y&lt;/math&gt; such that &lt;math&gt;f(\vec{x}) \sim y&lt;/math&gt;. Let &lt;math&gt;\mathcal{H}&lt;/math&gt; be a space of functions &lt;math&gt;f: X \to Y&lt;/math&gt; called the hypothesis space. The hypothesis space is the space of functions the algorithm will search through. Let &lt;math&gt;V(f(\vec{x}),y)&lt;/math&gt; be the [[loss function]], a metric for the difference between the predicted value &lt;math&gt;f(\vec{x})&lt;/math&gt; and the actual value &lt;math&gt;y&lt;/math&gt;. The [[expected risk]] is defined to be
:&lt;math&gt;I[f] = \displaystyle \int_{X \times Y} V(f(\vec{x}),y)\, p(\vec{x},y) \,d\vec{x} \,dy&lt;/math&gt;
The target function, the best possible function &lt;math&gt;f&lt;/math&gt; that can be
chosen, is given by the &lt;math&gt;f&lt;/math&gt; that satisfies
:&lt;math&gt;f = \inf_{h \in \mathcal{H}} I[h]&lt;/math&gt;

Because the probability distribution &lt;math&gt;p(\vec{x},y)&lt;/math&gt; is unknown, a
proxy measure for the expected risk must be used. This measure is based on the training set, a sample from this unknown probability distribution. It is called the [[empirical risk]]
:&lt;math&gt;I_S[f] = \frac{1}{n} \displaystyle \sum_{i=1}^n V( f(\vec{x}_i),y_i)&lt;/math&gt;
A learning algorithm that chooses the function &lt;math&gt;f_S&lt;/math&gt; that minimizes
the empirical risk is called [[empirical risk minimization]].

==Loss functions==
The choice of loss function is a determining factor on the function &lt;math&gt;f_S&lt;/math&gt; that will be chosen by the learning algorithm. The loss function
also affects the convergence rate for an algorithm. It is important for the loss function to be convex.&lt;ref&gt;Rosasco, L., Vito, E.D., Caponnetto, A., Fiana, M., and Verri A. 2004. ''Neural computation'' Vol 16, pp 1063-1076&lt;/ref&gt;

Different loss functions are used depending on whether the problem is
one of regression or one of classification.

===Regression===
The most common loss function for regression is the square loss function (also known as the [[L2-norm]]). This familiar loss function is used in [[Ordinary Least Squares regression]]. The form is:
:&lt;math&gt;V(f(\vec{x}),y) = (y - f(\vec{x}))^2&lt;/math&gt;

The absolute value loss (also known as the [[L1-norm]]) is also sometimes used:
:&lt;math&gt;V(f(\vec{x}),y) = |y - f(\vec{x})|&lt;/math&gt;

===Classification===
{{main|Statistical classification}}
In some sense the 0-1 [[indicator function]] is the most natural loss function for classification. It takes the value 0 if the predicted output is the same as the actual output, and it takes the value 1 if the predicted output is different from the actual output. For binary classification with &lt;math&gt;Y = \{-1, 1\}&lt;/math&gt;, this is:
:&lt;math&gt;V(f(\vec{x}),y) = \theta(- y f(\vec{x}))&lt;/math&gt;
where &lt;math&gt;\theta&lt;/math&gt; is the [[Heaviside step function]].

==Regularization==
[[File:Overfitting on Training Set Data.pdf|thumb|This image represents an example of overfitting in machine learning. The red dots represent training set data. The green line represents the true functional relationship, while the blue line shows the learned function, which has fallen victim to overfitting.]]

In machine learning problems, a major problem that arises is that of [[overfitting]]. Because learning is a prediction problem, the goal is not to find a function that most closely fits the (previously observed) data, but to find one that will most accurately predict output from future input. [[Empirical risk minimization]] runs this risk of overfitting: finding a function that matches the data exactly but does not predict future output well.

Overfitting is symptomatic of unstable solutions; a small perturbation in the training set data would cause a large variation in the learned function. It can be shown that if the stability for the solution can be guaranteed, generalization and consistency are guaranteed as well.&lt;ref&gt;Vapnik, V.N. and Chervonenkis, A.Y. 1971. [http://ai2-s2-pdfs.s3.amazonaws.com/a36b/028d024bf358c4af1a5e1dc3ca0aed23b553.pdf On the uniform convergence of relative frequencies of events to their probabilities]. ''Theory of Probability and Its Applications'' Vol 16, pp 264-280.&lt;/ref&gt;&lt;ref&gt;Mukherjee, S., Niyogi, P. Poggio, T., and Rifkin, R. 2006. [https://link.springer.com/article/10.1007/s10444-004-7634-z Learning theory: stability is sufficient for generalization and necessary and sufficient for consistency of empirical risk minimization]. ''Advances in Computational Mathematics''. Vol 25, pp 161-193.&lt;/ref&gt; [[Regularization (mathematics)|Regularization]] can solve the overfitting problem and give
the problem stability.

Regularization can be accomplished by restricting the hypothesis space &lt;math&gt;\mathcal{H}&lt;/math&gt;. A common example would be restricting &lt;math&gt;\mathcal{H}&lt;/math&gt; to linear functions: this can be seen as a reduction to the standard problem of [[linear regression]]. &lt;math&gt;\mathcal{H}&lt;/math&gt; could also be restricted to polynomial of degree &lt;math&gt;p&lt;/math&gt;, exponentials, or bounded functions on [[Lp space|L1]]. Restriction of the hypothesis space avoids overfitting because the form of the potential functions are limited, and so does not allow for the choice of a function that gives empirical risk arbitrarily close to zero.

One example of regularization is [[Tikhonov regularization]]. This consists of minimizing
:&lt;math&gt;\frac{1}{n} \displaystyle \sum_{i=1}^n V(f(\vec{x}_i),y_i) + \gamma
\|f\|_{\mathcal{H}}^2&lt;/math&gt;
where &lt;math&gt;\gamma&lt;/math&gt; is a fixed and positive parameter, the regularization parameter. Tikhonov regularization ensures existence, uniqueness, and stability of the solution.&lt;ref&gt;Tomaso Poggio, Lorenzo Rosasco, et al. ''Statistical Learning Theory and Applications'', 2012, [https://www.mit.edu/~9.520/spring12/slides/class02/class02.pdf Class 2]&lt;/ref&gt;

{{clear}}

==See also==
* [[Reproducing kernel Hilbert spaces]] are a useful choice for &lt;math&gt;\mathcal{H}&lt;/math&gt;.
* [[Proximal gradient methods for learning]]

==References==
{{reflist}}

[[Category:Machine learning]]
[[Category:Estimation theory]]</text>
      <sha1>2x9mgebcqwyhm9e9xo5qgt3mmzp5hcj</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Log-linear models</title>
    <ns>14</ns>
    <id>36407925</id>
    <revision>
      <id>750277203</id>
      <parentid>750276518</parentid>
      <timestamp>2016-11-18T20:03:15Z</timestamp>
      <contributor>
        <username>Marcocapelle</username>
        <id>14965160</id>
      </contributor>
      <comment>header</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="149" xml:space="preserve">Not to be confused with [[Logistic regression]] models.

[[Category:Generalized linear models]]
[[Category:Machine learning]]
[[Category:Logarithms]]</text>
      <sha1>6gkzzu0ml6s1151yek6e5paz9ledyne</sha1>
    </revision>
  </page>
  <page>
    <title>Pattern recognition</title>
    <ns>0</ns>
    <id>126706</id>
    <revision>
      <id>1001993739</id>
      <parentid>997795931</parentid>
      <timestamp>2021-01-22T08:59:11Z</timestamp>
      <contributor>
        <ip>92.221.95.160</ip>
      </contributor>
      <comment>/* Sequence labeling methods (predicting sequences of categorical labels) */Removed duplicate entry for Hidden Markov models in the list</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="35746" xml:space="preserve">{{About|pattern recognition as a branch of engineering|the cognitive process|Pattern recognition (psychology)|other uses}}
{{More citations needed|date=May 2019}}

'''Pattern recognition''' is the automated recognition of [[pattern]]s and regularities in [[data]]. It has applications in statistical [[data analysis]], [[signal processing]], [[image analysis]], [[information retrieval]], [[bioinformatics]], [[data compression]], [[computer graphics]] and [[machine learning]]. Pattern recognition has its origins in statistics and engineering; some modern approaches to pattern recognition include the use of [[machine learning]], due to the increased availability of [[big data]] and a new abundance of [[processing power]]. However, these activities can be viewed as two facets of the same field of application, and together they have undergone substantial development over the past few decades. A modern definition of pattern recognition is:

{{quote
|The field of pattern recognition is concerned with the automatic discovery of regularities in data through the use of computer algorithms and with the use of these regularities to take actions such as classifying the data into different categories.&lt;ref name="Bishop2006"&gt;
{{cite book |first=Christopher M. |last=Bishop |year=2006 |title=Pattern Recognition and Machine Learning |publisher=Springer}}&lt;/ref&gt;}}

Pattern recognition systems are in many cases trained from labeled "training" data, but when no [[labeled data]] are available other algorithms can be used to discover previously unknown patterns. [[Data mining|KDD]] and data mining have a larger focus on unsupervised methods and stronger connection to business use. Pattern recognition focuses more on the signal and also takes acquisition and [[Signal Processing]] into consideration. It originated in [[engineering]], and the term is popular in the context of [[computer vision]]: a leading computer vision conference is named [[Conference on Computer Vision and Pattern Recognition]].

In [[machine learning]], pattern recognition is the assignment of a label to a given input value. In statistics, [[Linear discriminant analysis|discriminant analysis]] was introduced for this same purpose in 1936. An example of pattern recognition is [[classification (machine learning)|classification]], which attempts to assign each input value to one of a given set of ''classes'' (for example, determine whether a given email is "spam" or "non-spam"). However, pattern recognition is a more general problem that encompasses other types of output as well. Other examples are [[regression analysis|regression]], which assigns a [[real number|real-valued]] output to each input;&lt;ref&gt;{{Cite journal|last=Howard|first=W.R.|date=2007-02-20|title=Pattern Recognition and Machine Learning|journal=Kybernetes|volume=36|issue=2|pages=275|doi=10.1108/03684920710743466|issn=0368-492X}}&lt;/ref&gt; [[sequence labeling]], which assigns a class to each member of a sequence of values&lt;ref&gt;{{Cite web|url=https://pubweb.eng.utah.edu/~cs6961/slides/seq-labeling1.4ps.pdf|title=Sequence Labeling|website=utah.edu|access-date=2018-11-06|archive-date=2018-11-06|archive-url=https://web.archive.org/web/20181106171837/https://pubweb.eng.utah.edu/~cs6961/slides/seq-labeling1.4ps.pdf|url-status=live}}&lt;/ref&gt; (for example, [[part of speech tagging]], which assigns a [[part of speech]] to each word in an input sentence); and [[parsing]], which assigns a [[parse tree]] to an input sentence, describing the [[syntactic structure]] of the sentence.&lt;ref&gt;{{Cite book|title=Mathematical logic, p. 34|last=Ian.|first=Chiswell|date=2007|publisher=Oxford University Press|isbn=9780199215621|oclc=799802313}}&lt;/ref&gt;

Pattern recognition algorithms generally aim to provide a reasonable answer for all possible inputs and to perform "most likely" matching of the inputs, taking into account their statistical variation. This is opposed to ''[[pattern matching]]'' algorithms, which look for exact matches in the input with pre-existing patterns. A common example of a pattern-matching algorithm is [[regular expression]] matching, which looks for patterns of a given sort in textual data and is included in the search capabilities of many [[text editor]]s and [[word processor]]s.

==Overview==
Pattern recognition is generally categorized according to the type of learning procedure used to generate the output value. ''[[Supervised learning]]'' assumes that a set of ''training data'' (the ''[[training set]]'') has been provided, consisting of a set of instances that have been properly labeled by hand with the correct output. A learning procedure then generates a ''model'' that attempts to meet two sometimes conflicting objectives: Perform as well as possible on the training data, and generalize as well as possible to new data (usually, this means being as simple as possible, for some technical definition of "simple", in accordance with [[Occam's Razor]], discussed below). [[Unsupervised learning]], on the other hand, assumes training data that has not been hand-labeled, and attempts to find inherent patterns in the data that can then be used to determine the correct output value for new data instances.&lt;ref&gt;{{Cite journal| author= Carvalko, J.R., Preston K. | year=1972 |title= On Determining Optimum Simple Golay Marking Transforms for Binary Image Processing | journal= IEEE Transactions on Computers  | volume=21 | issue=12 | pages=1430–33  | doi = 10.1109/T-C.1972.223519| s2cid=21050445 }}.&lt;/ref&gt; A combination of the two that has recently been explored is [[semi-supervised learning]], which uses a combination of labeled and unlabeled data (typically a small set of labeled data combined with a large amount of unlabeled data). Note that in cases of unsupervised learning, there may be no training data at all to speak of; in other words, the data to be labeled ''is'' the training data.

Note that sometimes different terms are used to describe the corresponding supervised and unsupervised learning procedures for the same type of output. For example, the unsupervised equivalent of classification is normally known as ''[[data clustering|clustering]]'', based on the common perception of the task as involving no training data to speak of, and of grouping the input data into ''clusters'' based on some inherent [[similarity measure]] (e.g. the [[distance]] between instances, considered as vectors in a multi-dimensional [[vector space]]), rather than assigning each input instance into one of a set of pre-defined classes. In some fields, the terminology is different: For example, in [[community ecology]], the term "classification" is used to refer to what is commonly known as "clustering".

The piece of input data for which an output value is generated is formally termed an ''instance''. The instance is formally described by a [[feature vector|vector]] of ''features'', which together constitute a description of all known characteristics of the instance. (These feature vectors can be seen as defining points in an appropriate [[space (mathematics)|multidimensional space]], and methods for manipulating vectors in [[vector space]]s can be correspondingly applied to them, such as computing the [[dot product]] or the angle between two vectors.) Typically, features are either [[categorical data|categorical]] (also known as [[nominal data|nominal]], i.e., consisting of one of a set of unordered items, such as a gender of "male" or "female", or a blood type of "A", "B", "AB" or "O"), [[ordinal data|ordinal]] (consisting of one of a set of ordered items, e.g., "large", "medium" or "small"), [[integer|integer-valued]] (e.g., a count of the number of occurrences of a particular word in an email) or [[real number|real-valued]] (e.g., a measurement of blood pressure). Often, categorical and ordinal data are grouped together; likewise for integer-valued and real-valued data. Furthermore, many algorithms work only in terms of categorical data and require that real-valued or integer-valued data be ''discretized'' into groups (e.g., less than 5, between 5 and 10, or greater than 10).

===Probabilistic classifiers===
{{Main|Probabilistic classifier}}
Many common pattern recognition algorithms are ''probabilistic'' in nature, in that they use [[statistical inference]] to find the best label for a given instance. Unlike other algorithms, which simply output a "best" label, often probabilistic algorithms also output a [[probability]] of the instance being described by the given label. In addition, many probabilistic algorithms output a list of the ''N''-best labels with associated probabilities, for some value of ''N'', instead of simply a single best label. When the number of possible labels is fairly small (e.g., in the case of [[classification (machine learning)|classification]]), ''N'' may be set so that the probability of all possible labels is output. Probabilistic algorithms have many advantages over non-probabilistic algorithms:
*They output a confidence value associated with their choice. (Note that some other algorithms may also output confidence values, but in general, only for probabilistic algorithms is this value mathematically grounded in [[probability theory]]. Non-probabilistic confidence values can in general not be given any specific meaning, and only used to compare against other confidence values output by the same algorithm.)
*Correspondingly, they can ''abstain'' when the confidence of choosing any particular output is too low.
*Because of the probabilities output, probabilistic pattern-recognition algorithms can be more effectively incorporated into larger machine-learning tasks, in a way that partially or completely avoids the problem of ''error propagation''.

===Number of important feature variables===
[[Feature selection]] algorithms attempt to directly prune out redundant or irrelevant features. A general introduction to [[feature selection]] which summarizes approaches and challenges, has been given.&lt;ref&gt;Isabelle Guyon Clopinet, André Elisseeff (2003). ''An Introduction to Variable and Feature Selection''. The Journal of Machine Learning Research, Vol. 3, 1157-1182. [http://www-vis.lbl.gov/~romano/mlgroup/papers/guyon03a.pdf Link] {{Webarchive|url=https://web.archive.org/web/20160304035940/http://www-vis.lbl.gov/~romano/mlgroup/papers/guyon03a.pdf |date=2016-03-04 }}&lt;/ref&gt; The complexity of feature-selection is, because of its non-monotonous character, an [[optimization problem]] where given a total of &lt;math&gt;n&lt;/math&gt; features the [[powerset]] consisting of all &lt;math&gt;2^n-1&lt;/math&gt; subsets of features need to be explored. The [[Branch and bound|Branch-and-Bound algorithm]]&lt;ref&gt;
{{Cite journal|author1=Iman Foroutan |author2=Jack Sklansky | year=1987 |
title=Feature Selection for Automatic Classification of Non-Gaussian Data | journal=IEEE Transactions on Systems, Man and Cybernetics | volume=17 | pages=187&amp;ndash;198 | doi = 10.1109/TSMC.1987.4309029 | issue=2
|s2cid=9871395 }}.&lt;/ref&gt; does reduce this complexity but is intractable for medium to large values of the number of available features &lt;math&gt;n&lt;/math&gt;. For a large-scale comparison of feature-selection algorithms see 
.&lt;ref&gt;
{{Cite journal|author1=Mineichi Kudo |author2=Jack Sklansky | year=2000 |
title=Comparison of algorithms that select features for pattern classifiers | journal=[[Pattern Recognition (journal)|Pattern Recognition]] | volume=33 | pages=25&amp;ndash;41 | doi = 10.1016/S0031-3203(99)00041-2 | issue=1|citeseerx=10.1.1.55.1718 }}.&lt;/ref&gt;

Techniques to transform the raw feature vectors ('''feature extraction''') are sometimes used prior to application of the pattern-matching algorithm. For example, [[feature extraction]] algorithms attempt to reduce a large-dimensionality feature vector into a smaller-dimensionality vector that is easier to work with and encodes less redundancy, using mathematical techniques such as [[principal components analysis]] (PCA). The distinction between '''feature selection''' and '''feature extraction''' is that the resulting features after feature extraction has taken place are of a different sort than the original features and may not easily be interpretable, while the features left after feature selection are simply a subset of the original features.

==Problem statement==
Formally, the problem of pattern recognition can be stated as follows: Given an unknown function &lt;math&gt;g:\mathcal{X}\rightarrow\mathcal{Y}&lt;/math&gt; (the ''ground truth'') that maps input instances &lt;math&gt;\boldsymbol{x} \in \mathcal{X}&lt;/math&gt; to output labels &lt;math&gt;y \in \mathcal{Y}&lt;/math&gt;, along with training data &lt;math&gt;\mathbf{D} = \{(\boldsymbol{x}_1,y_1),\dots,(\boldsymbol{x}_n, y_n)\}&lt;/math&gt; assumed to represent accurate examples of the mapping, produce a function &lt;math&gt;h:\mathcal{X}\rightarrow\mathcal{Y}&lt;/math&gt; that approximates as closely as possible the correct mapping &lt;math&gt;g&lt;/math&gt;. (For example, if the problem is filtering spam, then &lt;math&gt;\boldsymbol{x}_i&lt;/math&gt; is some representation of an email and &lt;math&gt;y&lt;/math&gt; is either "spam" or "non-spam"). In order for this to be a well-defined problem, "approximates as closely as possible" needs to be defined rigorously. In [[decision theory]], this is defined by specifying a [[loss function]] or cost function that assigns a specific value to "loss" resulting from producing an incorrect label. The goal then is to minimize the [[expected value|expected]] loss, with the expectation taken over the [[probability distribution]] of &lt;math&gt;\mathcal{X}&lt;/math&gt;. In practice, neither the distribution of &lt;math&gt;\mathcal{X}&lt;/math&gt; nor the ground truth function &lt;math&gt;g:\mathcal{X}\rightarrow\mathcal{Y}&lt;/math&gt; are known exactly, but can be computed only empirically by collecting a large number of samples of &lt;math&gt;\mathcal{X}&lt;/math&gt; and hand-labeling them using the correct value of &lt;math&gt;\mathcal{Y}&lt;/math&gt; (a time-consuming process, which is typically the limiting factor in the amount of data of this sort that can be collected). The particular loss function depends on the type of label being predicted. For example, in the case of [[classification (machine learning)|classification]], the simple [[zero-one loss function]] is often sufficient. This corresponds simply to assigning a loss of 1 to any incorrect labeling and implies that the optimal classifier minimizes the [[Bayes error rate|error rate]] on independent test data (i.e. counting up the fraction of instances that the learned function &lt;math&gt;h:\mathcal{X}\rightarrow\mathcal{Y}&lt;/math&gt; labels wrongly, which is equivalent to maximizing the number of correctly classified instances). The goal of the learning procedure is then to minimize the error rate (maximize the [[correctness (computer science)|correctness]]) on a "typical" test set.

For a probabilistic pattern recognizer, the problem is instead to estimate the probability of each possible output label given a particular input instance, i.e., to estimate a function of the form
:&lt;math&gt;p({\rm label}|\boldsymbol{x},\boldsymbol\theta) = f\left(\boldsymbol{x};\boldsymbol{\theta}\right)&lt;/math&gt;
where the [[feature vector]] input is &lt;math&gt;\boldsymbol{x}&lt;/math&gt;, and the function ''f'' is typically parameterized by some parameters &lt;math&gt;\boldsymbol{\theta}&lt;/math&gt;.&lt;ref&gt;For [[linear discriminant analysis]] the parameter vector &lt;math&gt;\boldsymbol\theta&lt;/math&gt; consists of the two mean vectors &lt;math&gt;\boldsymbol\mu_1&lt;/math&gt; and &lt;math&gt;\boldsymbol\mu_2&lt;/math&gt; and the common [[covariance matrix]] &lt;math&gt;\boldsymbol\Sigma&lt;/math&gt;.&lt;/ref&gt; In a [[discriminative model|discriminative]] approach to the problem, ''f'' is estimated directly. In a [[generative model|generative]] approach, however, the inverse probability &lt;math&gt;p({\boldsymbol{x}|\rm label})&lt;/math&gt; is instead estimated and combined with the [[prior probability]] &lt;math&gt;p({\rm label}|\boldsymbol\theta)&lt;/math&gt; using [[Bayes' rule]], as follows:
:&lt;math&gt;p({\rm label}|\boldsymbol{x},\boldsymbol\theta) = \frac{p({\boldsymbol{x}|\rm label,\boldsymbol\theta}) p({\rm label|\boldsymbol\theta})}{\sum_{L \in \text{all labels}} p(\boldsymbol{x}|L) p(L|\boldsymbol\theta)}.&lt;/math&gt;

When the labels are [[continuous distribution|continuously distributed]] (e.g., in [[regression analysis]]), the denominator involves [[integral|integration]] rather than summation:

:&lt;math&gt;p({\rm label}|\boldsymbol{x},\boldsymbol\theta) = \frac{p({\boldsymbol{x}|\rm label,\boldsymbol\theta}) p({\rm label|\boldsymbol\theta})}{\int_{L \in \text{all labels}} p(\boldsymbol{x}|L) p(L|\boldsymbol\theta) \operatorname{d}L}.&lt;/math&gt;

The value of &lt;math&gt;\boldsymbol\theta&lt;/math&gt; is typically learned using [[maximum a posteriori]] (MAP) estimation. This finds the best value that simultaneously meets two conflicting objects: To perform as well as possible on the training data (smallest [[Bayes error rate|error-rate]]) and to find the simplest possible model. Essentially, this combines [[maximum likelihood]] estimation with a [[regularization (mathematics)|regularization]] procedure that favors simpler models over more complex models. In a [[Bayesian inference|Bayesian]] context, the regularization procedure can be viewed as placing a [[prior probability]] &lt;math&gt;p(\boldsymbol\theta)&lt;/math&gt; on different values of &lt;math&gt;\boldsymbol\theta&lt;/math&gt;. Mathematically:

:&lt;math&gt;\boldsymbol\theta^* = \arg \max_{\boldsymbol\theta} p(\boldsymbol\theta|\mathbf{D})&lt;/math&gt;

where &lt;math&gt;\boldsymbol\theta^*&lt;/math&gt; is the value used for &lt;math&gt;\boldsymbol\theta&lt;/math&gt; in the subsequent evaluation procedure, and &lt;math&gt;p(\boldsymbol\theta|\mathbf{D})&lt;/math&gt;, the [[posterior probability]] of &lt;math&gt;\boldsymbol\theta&lt;/math&gt;, is given by

:&lt;math&gt;p(\boldsymbol\theta|\mathbf{D}) = \left[\prod_{i=1}^n p(y_i|\boldsymbol{x}_i,\boldsymbol\theta) \right] p(\boldsymbol\theta).&lt;/math&gt;

In the [[Bayesian statistics|Bayesian]] approach to this problem, instead of choosing a single parameter vector &lt;math&gt;\boldsymbol{\theta}^*&lt;/math&gt;, the probability of a given label for a new instance &lt;math&gt;\boldsymbol{x}&lt;/math&gt; is computed by integrating over all possible values of &lt;math&gt;\boldsymbol\theta&lt;/math&gt;, weighted according to the posterior probability:

:&lt;math&gt;p({\rm label}|\boldsymbol{x}) = \int p({\rm label}|\boldsymbol{x},\boldsymbol\theta)p(\boldsymbol{\theta}|\mathbf{D}) \operatorname{d}\boldsymbol{\theta}.&lt;/math&gt;

===Frequentist or Bayesian approach to pattern recognition===
The first pattern classifier – the linear discriminant presented by [[Fisher discriminant analysis|Fisher]] – was developed in the [[Frequentist inference|frequentist]] tradition. The frequentist approach entails that the model parameters are considered unknown, but objective. The parameters are then computed (estimated) from the collected data. For the linear discriminant, these parameters are precisely the mean vectors and the [[covariance matrix]]. Also the probability of each class &lt;math&gt;p({\rm label}|\boldsymbol\theta)&lt;/math&gt; is estimated from the collected dataset. Note that the usage of '[[Bayes rule]]' in a pattern classifier does not make the classification approach Bayesian.

[[Bayesian inference|Bayesian statistics]] has its origin in Greek philosophy where a distinction was already made between the '[[A priori and a posteriori|a priori]]' and the '[[A priori and a posteriori|a posteriori]]' knowledge. Later [[A priori and a posteriori#Immanuel Kant|Kant]] defined his distinction between what is a priori known – before observation – and the empirical knowledge gained from observations. In a Bayesian pattern classifier, the class probabilities &lt;math&gt;p({\rm label}|\boldsymbol\theta)&lt;/math&gt; can be chosen by the user, which are then a priori. Moreover, experience quantified as a priori parameter values can be weighted with empirical observations – using e.g., the [[Beta distribution|Beta-]] ([[Conjugate prior distribution|conjugate prior]]) and [[Dirichlet distribution|Dirichlet-distributions]]. The Bayesian approach facilitates a seamless intermixing between expert knowledge in the form of subjective probabilities, and objective observations.

Probabilistic pattern classifiers can be used according to a frequentist or a Bayesian approach.

==Uses==
[[File:800px-Cool Kids of Death Off Festival p 146-face selected.jpg|thumb|200px|[[Face recognition|The face was automatically detected]] by special software.]]
Within medical science, pattern recognition is the basis for [[computer-aided diagnosis]] (CAD) systems. CAD describes a procedure that supports the doctor's interpretations and findings.
Other typical applications of pattern recognition techniques are automatic [[speech recognition]], [[speaker identification]], [[document classification|classification of text into several categories]] (e.g., spam/non-spam email messages), the [[handwriting recognition|automatic recognition of handwriting]] on postal envelopes, automatic [[image recognition|recognition of images]] of human faces, or handwriting image extraction from medical forms.&lt;ref&gt;{{cite journal|last=Milewski|first=Robert|author2=Govindaraju, Venu|title=Binarization and cleanup of handwritten text from carbon copy medical form images|journal=Pattern Recognition|date=31 March 2008|volume=41|issue=4|pages=1308–1315|doi=10.1016/j.patcog.2007.08.018|url=http://dl.acm.org/citation.cfm?id=1324656|access-date=26 October 2011|archive-date=10 September 2020|archive-url=https://web.archive.org/web/20200910174840/https://dl.acm.org/doi/10.1016/j.patcog.2007.08.018|url-status=live}}&lt;/ref&gt;&lt;ref&gt;{{cite journal
  |last=Sarangi|first=Susanta |author2=Sahidullah, Md |author3=Saha, Goutam
  |title=Optimization of data-driven filterbank for automatic speaker verification
  |journal=Digital Signal Processing |date=September 2020 |volume=104 
  |page=102795 |doi= 10.1016/j.dsp.2020.102795|arxiv=2007.10729|s2cid=220665533 }}&lt;/ref&gt; The last two examples form the subtopic [[image analysis]] of pattern recognition that deals with digital images as input to pattern recognition systems.&lt;ref name=duda2001&gt;{{cite book|author=[[Richard O. Duda]], [[Peter E. Hart]], [[David G. Stork]]|year=2001|title=Pattern classification|edition=2nd|publisher=Wiley, New York|isbn=978-0-471-05669-0|url=https://books.google.com/books?id=Br33IRC3PkQC|access-date=2019-11-26|archive-date=2020-08-19|archive-url=https://web.archive.org/web/20200819004737/https://books.google.com/books?id=Br33IRC3PkQC|url-status=live}}&lt;/ref&gt;&lt;ref&gt;R. Brunelli, ''Template Matching Techniques in Computer Vision: Theory and Practice'', Wiley, {{ISBN|978-0-470-51706-2}}, 2009&lt;/ref&gt;

Optical character recognition is a classic example of the application of a pattern classifier, see [http://cmp.felk.cvut.cz/cmp/software/stprtool/examples/ocr_system.gif OCR-example]. The method of signing one's name was captured with stylus and overlay starting in 1990.{{citation needed|date=January 2011}} The strokes, speed, relative min, relative max, acceleration and pressure is used to uniquely identify and confirm identity. Banks were first offered this technology, but were content to collect from the FDIC for any bank fraud and did not want to inconvenience customers.{{citation needed|date=January 2011}}

Pattern recognition has many real-world applications in image processing, some examples include:
* identification and authentication: e.g., [[license plate recognition]],&lt;ref&gt;[http://anpr-tutorial.com/ THE AUTOMATIC NUMBER PLATE RECOGNITION TUTORIAL] {{Webarchive|url=https://web.archive.org/web/20060820175245/http://www.anpr-tutorial.com/ |date=2006-08-20 }} http://anpr-tutorial.com/ {{Webarchive|url=https://web.archive.org/web/20060820175245/http://www.anpr-tutorial.com/ |date=2006-08-20 }}&lt;/ref&gt; fingerprint analysis, [[face detection]]/verification;,&lt;ref&gt;[https://www.cs.cmu.edu/afs/cs.cmu.edu/usr/mitchell/ftp/faces.html Neural Networks for Face Recognition] {{Webarchive|url=https://web.archive.org/web/20160304065030/http://www.cs.cmu.edu/afs/cs.cmu.edu/usr/mitchell/ftp/faces.html |date=2016-03-04 }} Companion to Chapter 4 of the textbook Machine Learning.&lt;/ref&gt; and voice-based authentication.&lt;ref&gt;{{cite journal|last=Poddar|first=Arnab|author2=Sahidullah, Md|author3=Saha, Goutam|title=Speaker Verification with Short Utterances: A Review of Challenges, Trends and Opportunities|journal=IET Biometrics|date=March 2018|volume=7|issue=2|pages=91–101|doi=10.1049/iet-bmt.2017.0065|url=https://ieeexplore.ieee.org/document/8302747|access-date=2019-08-27|archive-date=2019-09-03|archive-url=https://web.archive.org/web/20190903174139/https://ieeexplore.ieee.org/document/8302747/|url-status=live}}&lt;/ref&gt;
* medical diagnosis: e.g., screening for cervical cancer (Papnet),&lt;ref&gt;[http://health-asia.org/papnet-for-cervical-screening/ PAPNET For Cervical Screening] {{webarchive|url=https://archive.today/20120708211332/http://health-asia.org/papnet-for-cervical-screening/ |date=2012-07-08 }}&lt;/ref&gt; breast tumors or heart sounds;
* defence: various navigation and guidance systems, target recognition systems, shape recognition technology etc.
* mobility: [[Advanced driver-assistance systems|advanced driver assistance systems]], [[Self-driving car|autonomous vehicle technology]], etc.&lt;ref&gt;{{Cite web|url=https://saemobilus.sae.org/content/2018-01-0035|title=Development of an Autonomous Vehicle Control&amp;nbsp;Strategy Using a Single Camera and Deep Neural Networks (2018-01-0035 Technical Paper)- SAE Mobilus|website=saemobilus.sae.org|language=en|access-date=2019-09-06|archive-date=2019-09-06|archive-url=https://web.archive.org/web/20190906084436/https://saemobilus.sae.org/content/2018-01-0035|url-status=live}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last1=Gerdes|first1=J. Christian|last2=Kegelman|first2=John C.|last3=Kapania|first3=Nitin R.|last4=Brown|first4=Matthew|last5=Spielberg|first5=Nathan A.|date=2019-03-27|title=Neural network vehicle models for high-performance automated driving|journal=Science Robotics|language=en|volume=4|issue=28|pages=eaaw1975|doi=10.1126/scirobotics.aaw1975|pmid=33137751|s2cid=89616974|issn=2470-9476|doi-access=free}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.theengineer.co.uk/ai-autonomous-cars/|title=How AI is paving the way for fully autonomous cars|last=Pickering|first=Chris|date=2017-08-15|website=The Engineer|language=en-UK|access-date=2019-09-06|archive-date=2019-09-06|archive-url=https://web.archive.org/web/20190906084433/https://www.theengineer.co.uk/ai-autonomous-cars/|url-status=live}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last1=Ray|first1=Baishakhi|last2=Jana|first2=Suman|last3=Pei|first3=Kexin|last4=Tian|first4=Yuchi|date=2017-08-28|title=DeepTest: Automated Testing of Deep-Neural-Network-driven Autonomous Cars|language=en|arxiv=1708.08559|bibcode=2017arXiv170808559T}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last1=Sinha|first1=P. K.|last2=Hadjiiski|first2=L. M.|last3=Mutib|first3=K.|date=1993-04-01|title=Neural Networks in Autonomous Vehicle Control|journal=IFAC Proceedings Volumes|series=1st IFAC International Workshop on Intelligent Autonomous Vehicles, Hampshire, UK, 18–21 April|volume=26|issue=1|pages=335–340|doi=10.1016/S1474-6670(17)49322-0|issn=1474-6670}}&lt;/ref&gt;

In psychology, [[pattern recognition (psychology)|pattern recognition]] (making sense of and identifying objects) is closely related to perception, which explains how the sensory inputs humans receive are made meaningful. Pattern recognition can be thought of in two different ways: the first being template matching and the second being feature detection. A template is a pattern used to produce items of the same proportions. The template-matching hypothesis suggests that incoming stimuli are compared with templates in the long-term memory. If there is a match, the stimulus is identified. Feature detection models, such as the Pandemonium system for classifying letters (Selfridge, 1959), suggest that the stimuli are broken down into their component parts for identification. For example, a capital E has three horizontal lines and one vertical line.&lt;ref&gt;{{cite web |url=http://www.s-cool.co.uk/a-level/psychology/attention/revise-it/pattern-recognition |title=A-level Psychology Attention Revision - Pattern recognition &amp;#124; S-cool, the revision website |publisher=S-cool.co.uk |access-date=2012-09-17 |archive-date=2013-06-22 |archive-url=https://web.archive.org/web/20130622023719/http://www.s-cool.co.uk/a-level/psychology/attention/revise-it/pattern-recognition |url-status=live }}&lt;/ref&gt;

==Algorithms==
Algorithms for pattern recognition depend on the type of label output, on whether learning is supervised or unsupervised, and on whether the algorithm is statistical or non-statistical in nature. Statistical algorithms can further be categorized as [[generative model|generative]] or [[discriminative model|discriminative]].

{{cleanup list|date=May 2014}}

===[[Classification]] methods (methods predicting [[categorical data|categorical]] labels)===
{{Main|Statistical classification}}
Parametric:&lt;ref&gt;Assuming known distributional shape of feature distributions per class, such as the [[Gaussian distribution|Gaussian]] shape.&lt;/ref&gt;
*[[Linear discriminant analysis]]
*[[Quadratic classifier|Quadratic discriminant analysis]]
*[[Maximum entropy classifier]] (aka [[logistic regression]], [[multinomial logistic regression]]): Note that logistic regression is an algorithm for classification, despite its name. (The name comes from the fact that logistic regression uses an extension of a linear regression model to model the probability of an input being in a particular class.)
Nonparametric:&lt;ref&gt;No distributional assumption regarding shape of feature distributions per class.&lt;/ref&gt;
*[[Decision tree]]s, [[decision list]]s
*[[Variable kernel density estimation#Use for statistical classification|Kernel estimation]] and [[K-nearest-neighbor]] algorithms
*[[Naive Bayes classifier]]
*[[Neural network]]s (multi-layer perceptrons)
*[[Perceptron]]s
*[[Support vector machine]]s
*[[Gene expression programming]]

===[[Cluster analysis|Clustering]] methods (methods for classifying and predicting [[categorical data|categorical]] labels)===
{{Main|Cluster analysis}}
*Categorical [[mixture model]]s
*[[Hierarchical clustering]] (agglomerative or divisive)
*[[K-means clustering]]
*[[Correlation clustering]]&lt;!-- not an algorithm --&gt;
*[[Kernel principal component analysis]] (Kernel PCA)&lt;!-- but not PCA? --&gt;

===[[Ensemble learning]] algorithms (supervised [[meta-algorithm]]s for combining multiple learning algorithms together)===
{{Main|Ensemble learning}}
*[[Boosting (meta-algorithm)]]
*[[Bootstrap aggregating]] ("bagging")
*[[Ensemble averaging]]
*[[Mixture of experts]], [[hierarchical mixture of experts]]

===General methods for predicting arbitrarily-structured (sets of) labels===
*[[Bayesian network]]s
*[[Markov random field]]s

===[[Multilinear subspace learning]] algorithms (predicting labels of multidimensional data using [[tensor]] representations)===
Unsupervised:
*[[Multilinear principal component analysis]] (MPCA)

===Real-valued [[sequence labeling]] methods (predicting sequences of [[real number|real-valued]] labels)===
{{Main|sequence labeling}}
*[[Kalman filter]]s
*[[Particle filter]]s

===[[Regression analysis|Regression]] methods (predicting [[real number|real-valued]] labels)===
{{Main|Regression analysis}}
*[[Gaussian process regression]] (kriging)
*[[Linear regression]] and extensions
*[[Independent component analysis]] (ICA)
*[[Principal components analysis]] (PCA)

===[[Sequence labeling]] methods (predicting sequences of [[categorical data|categorical]] labels)===
*[[Conditional random field]]s (CRFs)
*[[Hidden Markov model]]s (HMMs)
*[[Maximum entropy Markov model]]s (MEMMs)
*[[Recurrent neural networks]] (RNNs)
*[[Dynamic time warping]] (DTW)

==See also==
{{Div col|colwidth=30em}}
* [[Adaptive resonance theory]]
* [[Black box]]
* [[Cache language model]]
* [[Compound-term processing]]
* [[Computer-aided diagnosis]]
* [[Data mining]]
* [[Deep Learning]]
* [[Information theory]]
* [[List of numerical analysis software]]
* [[List of numerical libraries]]
* [[Multilinear subspace learning]]
* [[Neocognitron]]
* [[Perception]]
* [[Perceptual learning]]
* [[Predictive analytics]]
* [[Prior knowledge for pattern recognition]]
* [[Sequence mining]]
* [[Template matching]]
* [[Contextual image classification]]
* [[List of datasets for machine learning research]]
{{div col end}}

==References==
{{FOLDOC}}
{{reflist}}

==Further reading==
*{{cite book|last=Fukunaga|first=Keinosuke|title=Introduction to Statistical Pattern Recognition|url=https://archive.org/details/introductiontost1990fuku|url-access=registration|edition=2nd|year=1990|publisher=Academic Press|location=Boston|isbn=978-0-12-269851-4}}
*{{cite book|last1=Hornegger|first1=Joachim|last2=Paulus|first2=Dietrich W. R.|title=Applied Pattern Recognition: A Practical Introduction to Image and Speech Processing in C++|edition=2nd|year=1999|publisher=Morgan Kaufmann Publishers|location=San Francisco|isbn=978-3-528-15558-2}}
*{{cite book|last=Schuermann|first=Juergen|title=Pattern Classification: A Unified View of Statistical and Neural Approaches|year=1996|publisher=Wiley|location=New York|isbn=978-0-471-13534-0}}
*{{cite book|editor=Godfried T. Toussaint|title=Computational Morphology|year=1988|publisher=North-Holland Publishing Company|location=Amsterdam|url=https://books.google.com/books?id=ObOjBQAAQBAJ|isbn=9781483296722}}
*{{cite book|last1=Kulikowski|first1=Casimir A.|last2=Weiss|first2=Sholom M.|title=Computer Systems That Learn: Classification and Prediction Methods from Statistics, Neural Nets, Machine Learning, and Expert Systems|series=Machine Learning|year=1991|publisher=Morgan Kaufmann Publishers|location=San Francisco|isbn=978-1-55860-065-2}}
*{{cite book|last1=Duda|first1=Richard O.|last2=Hart|first2=Peter E.|last3=Stork|first3=David G.|title=Pattern Classification|edition=2nd|year=2000|publisher=Wiley-Interscience|isbn=978-0471056690|url=https://books.google.com/books?id=Br33IRC3PkQC}}
*{{cite journal|last1=Jain|first1=Anil.K.|last2=Duin|first2=Robert.P.W.|last3=Mao|first3=Jianchang|title=Statistical pattern recognition: a review|year=2000|journal=IEEE Transactions on Pattern Analysis and Machine Intelligence | volume=22 | pages=4&amp;ndash;37 | doi = 10.1109/34.824819 | issue=1|citeseerx=10.1.1.123.8151}}
*[https://web.archive.org/web/20140911114525/http://egmont-petersen.nl/classifiers.htm An introductory tutorial to classifiers (introducing the basic terms, with numeric example)]

==External links==
* [http://www.iapr.org The International Association for Pattern Recognition]
* [http://cgm.cs.mcgill.ca/~godfried/teaching/pr-web.html List of Pattern Recognition web sites]
* [http://www.jprr.org Journal of Pattern Recognition Research]
* [https://web.archive.org/web/20120302040520/http://www.docentes.unal.edu.co/morozcoa/docs/pr.php Pattern Recognition Info]
* [http://www.sciencedirect.com/science/journal/00313203 Pattern Recognition] (Journal of the Pattern Recognition Society)
* [http://www.worldscinet.com/ijprai/mkt/archive.shtml International Journal of Pattern Recognition and Artificial Intelligence]
* [http://www.inderscience.com/ijapr International Journal of Applied Pattern Recognition]
* [https://web.archive.org/web/20150215163124/http://www.openpr.org.cn/ Open Pattern Recognition Project], intended to be an open source platform for sharing algorithms of pattern recognition
* [https://www.academia.edu/31957815/Improved_Pattern_Matching_Applied_to_Surface_Mounting_Devices_Components_Localization_on_Automated_Optical_Inspection Improved Fast Pattern Matching] Improved Fast Pattern Matching

{{Differentiable computing}}

{{Authority control}}

[[Category:Pattern recognition| ]]
[[Category:Machine learning]]
[[Category:Formal sciences]]
[[Category:Computational fields of study]]</text>
      <sha1>4bqz4ix8xoz630zfce3cbqr341737rl</sha1>
    </revision>
  </page>
  <page>
    <title>Linear predictor function</title>
    <ns>0</ns>
    <id>35272263</id>
    <revision>
      <id>992098633</id>
      <parentid>984271318</parentid>
      <timestamp>2020-12-03T14:09:52Z</timestamp>
      <contributor>
        <username>WikiCleanerBot</username>
        <id>18872885</id>
      </contributor>
      <minor/>
      <comment>v2.04b - [[User:WikiCleanerBot#T20|Bot T20 CW#61]] - Fix errors for [[WP:WCW|CW project]] (Reference before punctuation)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="14165" xml:space="preserve">In [[statistics]] and in [[machine learning]], a '''linear predictor function''' is a [[linear function]] ([[linear combination]]) of a set of coefficients and explanatory variables ([[independent variable]]s), whose value is used to predict the outcome of a [[dependent variable]].&lt;ref&gt;{{Cite journal|last=Makhoul|first=J.|date=1975|title=Linear prediction: A tutorial review|journal=Proceedings of the IEEE|volume=63|issue=4|pages=561–580|doi=10.1109/PROC.1975.9792|bibcode=1975IEEEP..63..561M|issn=0018-9219}}&lt;/ref&gt;  This sort of function usually comes in [[linear regression]], where the coefficients are called [[regression coefficient]]s. However, they also occur in various types of [[linear classifier]]s (e.g. [[logistic regression]],&lt;ref name="Freedman09"&gt;{{cite book|title=Statistical Models: Theory and Practice|url=https://archive.org/details/statisticalmodel00free|url-access=limited|author=David A. Freedman|publisher=[[Cambridge University Press]]|year=2009|page=[https://archive.org/details/statisticalmodel00free/page/n41 26]|quote=A simple regression equation has on the right hand side an intercept and an explanatory variable with a slope coefficient. A multiple regression equation has two or more explanatory variables on the right hand side, each with its own slope coefficient|author-link=David A. Freedman}}&lt;/ref&gt; [[perceptron]]s,&lt;ref&gt;Rosenblatt, Frank (1957), The Perceptron--a perceiving and recognizing automaton. Report 85-460-1, Cornell Aeronautical Laboratory.&lt;/ref&gt; [[support vector machine]]s,&lt;ref name="CorinnaCortes"&gt;{{Cite journal|last1=Cortes|first1=Corinna|last2=Vapnik|first2=Vladimir N.|year=1995|title=Support-vector networks|url=http://image.diku.dk/imagecanon/material/cortes_vapnik95.pdf|journal=[[Machine Learning (journal)|Machine Learning]]|volume=20|issue=3|pages=273–297|citeseerx=10.1.1.15.9362|doi=10.1007/BF00994018|authorlink1=Corinna Cortes}}&lt;/ref&gt; and [[linear discriminant analysis]]&lt;ref name="McLachlan:2004"&gt;{{cite book|title=Discriminant Analysis and Statistical Pattern Recognition|last1=McLachlan|first1=G. J.|publisher=Wiley Interscience|year=2004|isbn=978-0-471-69115-0|mr=1190469}}&lt;/ref&gt;), as well as in various other models, such as [[principal component analysis]]&lt;ref name="Principal Component Analysis"&gt;Jolliffe I.T. ''Principal Component Analysis'', Series: Springer Series in Statistics, 2nd ed., Springer, NY, 2002, XXIX, 487 p. 28 illus. {{isbn|978-0-387-95442-4}}&lt;/ref&gt; and [[factor analysis]].  In many of these models, the coefficients are referred to as "weights".

== Definition ==
The basic form of a linear predictor function &lt;math&gt;f(i)&lt;/math&gt; for data point ''i'' (consisting of ''p'' [[Dependent and independent variables|explanatory variables]]), for ''i'' = 1, ..., ''n'', is

:&lt;math&gt; f(i) = \beta_0 + \beta_1 x_{i1} + \cdots + \beta_p x_{ip},&lt;/math&gt;

where &lt;math&gt;x_{ik}&lt;/math&gt;, for ''k'' = 1, ..., ''p'', is the value of the ''k''-th explanatory variable for data point ''i'', and &lt;math&gt;\beta_0, \ldots, \beta_p&lt;/math&gt; are the ''coefficients'' (regression coefficients, weights, etc.) indicating the relative effect of a particular ''explanatory variable'' on the ''outcome''.

=== Notations ===

It is common to write the predictor function in a more compact form as follows:
*The coefficients ''β''&lt;sub&gt;0&lt;/sub&gt;, ''β''&lt;sub&gt;1&lt;/sub&gt;, ..., ''β''&lt;sub&gt;''p''&lt;/sub&gt; are grouped into a single vector '''''β''''' of size ''p''&amp;nbsp;+&amp;nbsp;1.
*For each data point ''i'', an additional explanatory pseudo-variable ''x''&lt;sub&gt;''i''0&lt;/sub&gt; is added, with a fixed value of 1, corresponding to the [[Y-intercept|intercept]] coefficient ''β''&lt;sub&gt;0&lt;/sub&gt;.
*The resulting explanatory variables ''x''&lt;sub&gt;''i0''&lt;/sub&gt;(= 1), ''x''&lt;sub&gt;''i''1&lt;/sub&gt;, ..., ''x''&lt;sub&gt;''ip''&lt;/sub&gt; are then grouped into a single vector '''''x&lt;sub&gt;i&lt;/sub&gt;''''' of size ''p''&amp;nbsp;+&amp;nbsp;1.

==== Vector Notation ====

This makes it possible to write the linear predictor function as follows:

:&lt;math&gt;f(i)= \boldsymbol\beta \cdot \mathbf{x}_i&lt;/math&gt;

using the notation for a [[dot product]] between two vectors.

==== Matrix Notation ==== 

An equivalent form using matrix notation is as follows:

:&lt;math&gt;f(i)= \boldsymbol\beta^{\mathrm T} \mathbf{x}_i = \mathbf{x}^{\mathrm T}_i \boldsymbol\beta&lt;/math&gt;

where &lt;math&gt;\boldsymbol\beta&lt;/math&gt; and &lt;math&gt;\mathbf{x}_i&lt;/math&gt; are assumed to be a ''(p+1)''-by-1 [[column vector]]s, &lt;math&gt;\boldsymbol\beta^{\mathrm T}&lt;/math&gt; is the [[matrix transpose]] of &lt;math&gt;\boldsymbol\beta&lt;/math&gt; (so &lt;math&gt;\boldsymbol\beta^{\mathrm T}&lt;/math&gt; is a 1-by-''(p+1)'' [[row vector]]), and &lt;math&gt;\boldsymbol\beta^{\mathrm T} \mathbf{x}_i&lt;/math&gt; indicates [[matrix multiplication]] between the 1-by-''(p+1)'' row vector and the ''(p+1)''-by-1 column vector, producing a 1-by-1 matrix that is taken to be a [[scalar (mathematics)|scalar]].

== Linear regression ==

An example of the usage of a linear predictor function is in [[linear regression]], where each data point is associated with a [[continuous variable|continuous]] outcome ''y''&lt;sub&gt;''i''&lt;/sub&gt;, and the relationship written

:&lt;math&gt;y_i = f(i) + \varepsilon_i = \boldsymbol\beta^{\mathrm T}\mathbf{x}_i\ + \varepsilon_i,&lt;/math&gt;

where &lt;math&gt;\varepsilon_i&lt;/math&gt; is a ''disturbance term'' or ''[[error variable]]'' — an ''unobserved'' [[random variable]] that adds noise to the linear relationship between the dependent variable and predictor function.

==Stacking==

In some models (standard linear regression, in particular), the equations for each of the data points ''i'' = 1, ..., ''n'' are stacked together and written in vector form as

: &lt;math&gt;
 \mathbf{y} = \mathbf{X}\boldsymbol\beta + \boldsymbol\varepsilon, \,
 &lt;/math&gt;
where
: &lt;math&gt;
 \mathbf{y} = \begin{pmatrix} y_1 \\ y_2 \\ \vdots \\ y_n \end{pmatrix}, \quad
 \mathbf{X} = \begin{pmatrix} \mathbf{x}'_1 \\ \mathbf{x}'_2 \\ \vdots \\ \mathbf{x}'_n \end{pmatrix}
 = \begin{pmatrix} x_{11} &amp; \cdots &amp; x_{1p} \\
 x_{21} &amp; \cdots &amp; x_{2p} \\
 \vdots &amp; \ddots &amp; \vdots \\
 x_{n1} &amp; \cdots &amp; x_{np}
 \end{pmatrix}, \quad
 \boldsymbol\beta = \begin{pmatrix} \beta_1 \\ \vdots \\ \beta_p \end{pmatrix}, \quad
 \boldsymbol\varepsilon = \begin{pmatrix} \varepsilon_1 \\ \varepsilon_2 \\ \vdots \\ \varepsilon_n \end{pmatrix}.
 &lt;/math&gt;

The matrix ''X'' is known as the [[design matrix]] and encodes all known information about the [[independent variables]].  The variables &lt;math&gt;\varepsilon_i&lt;/math&gt; are [[random variable]]s, which in standard linear regression are distributed according to a [[standard normal distribution]]; they express the influence of any unknown factors on the outcome.

This makes it possible to find optimal coefficients through the [[method of least squares]] using simple matrix operations.  In particular, the optimal coefficients &lt;math&gt;\boldsymbol{\hat\beta}&lt;/math&gt; as estimated by least squares can be written as follows:

:&lt;math&gt;\boldsymbol{\hat\beta} =( X^\mathrm T X)^{-1}X^{\mathrm T}\mathbf{y}.&lt;/math&gt;

The matrix &lt;math&gt;( X^\mathrm T X)^{-1}X^{\mathrm T}&lt;/math&gt; is known as the [[Moore-Penrose pseudoinverse]] of ''X''.  The use of the [[matrix inverse]] in this formula requires that ''X'' is of [[full rank]], i.e. there is not perfect [[multicollinearity]] among different explanatory variables (i.e. no explanatory variable can be perfectly predicted from the others).  In such cases, the [[singular value decomposition]] can be used to compute the pseudoinverse.

==The explanatory variables==
Although the outcomes (dependent variables) to be predicted are assumed to be [[random variable]]s, the explanatory variables themselves are usually not assumed to be random{{citation needed|date=April 2018}}.  Instead, they are assumed to be fixed values, and any random variables (e.g. the outcomes) are assumed to be [[conditional probability|conditional]] on them{{citation needed|date=April 2018}}.  As a result, the [[data analyst]] is free to transform the explanatory variables in arbitrary ways, including creating multiple copies of a given explanatory variable, each transformed using a different function.  Other common techniques are to create new explanatory variables in the form of [[interaction variable]]s by taking products of two (or sometimes more) existing explanatory variables.

When a fixed set of nonlinear functions are used to transform the value(s) of a data point, these functions are known as [[basis function]]s.  An example is [[polynomial regression]], which uses a linear predictor function to fit an arbitrary degree [[polynomial]] relationship (up to a given order) between two sets of data points (i.e. a single [[real-valued]] explanatory variable and a related real-valued dependent variable), by adding multiple explanatory variables corresponding to various powers of the existing explanatory variable.  Mathematically, the form looks like this:

:&lt;math&gt;y_i = \beta_0 + \beta_1 x_i + \beta_2 x_i^2 + \cdots + \beta_p x_i^p.&lt;/math&gt;

In this case, for each data point ''i'', a set of explanatory variables is created as follows:

:&lt;math&gt;(x_{i1} = x_i,\quad x_{i2} = x_i^2,\quad \ldots,\quad x_{ip} = x_i^p)&lt;/math&gt;

and then standard [[linear regression]] is run.  The basis functions in this example would be
:&lt;math&gt;\boldsymbol\phi(x) = (\phi_1(x), \phi_2(x), \ldots, \phi_p(x)) = (x, x^2, \ldots, x^p).&lt;/math&gt;

This example shows that a linear predictor function can actually be much more powerful than it first appears: It only really needs to be linear in the ''coefficients''.  All sorts of non-linear functions of the explanatory variables can be fit by the model.

There is no particular need for the inputs to basis functions to be univariate or single-dimensional (or their outputs, for that matter, although in such a case, a ''K''-dimensional output value is likely to be treated as ''K'' separate scalar-output basis functions).  An example of this is [[radial basis function]]s (RBF's), which compute some transformed version of the distance to some fixed point:

:&lt;math&gt;\phi(\mathbf{x};\mathbf{c}) = \phi(||\mathbf{x} - \mathbf{c}||) = \phi(\sqrt{(x_1 - c_1)^2 + \ldots + (x_K - c_K)^2})&lt;/math&gt;

An example is the [[Gaussian function|Gaussian]] RBF, which has the same functional form as the [[normal distribution]]:

:&lt;math&gt;\phi(\mathbf{x};\mathbf{c}) = e^{-b||\mathbf{x} - \mathbf{c}||^2}&lt;/math&gt;

which drops off rapidly as the distance from '''''c''''' increases.

A possible usage of RBF's is to create one for every observed data point.  This means that the result of an RBF applied to a new data point will be close to 0 unless the new point is near to the point around which the RBF was applied.  That is, the application of the radial basis functions will pick out the nearest point, and its regression coefficient will dominate.  The result will be a form of [[nearest neighbor interpolation]], where predictions are made by simply using the prediction of the nearest observed data point, possibly interpolating between multiple nearby data points when they are all similar distances away.  This type of [[k-nearest neighbor algorithm|nearest neighbor method]] for prediction is often considered diametrically opposed to the type of prediction used in standard linear regression: But in fact, the transformations that can be applied to the explanatory variables in a linear predictor function are so powerful that even the nearest neighbor method can be implemented as a type of linear regression.

It is even possible to fit some functions that appear non-linear in the coefficients by transforming the coefficients into new coefficients that do appear linear.  For example, a function of the form &lt;math&gt;a + b^2x_{i1} + \sqrt{c}x_{i2}&lt;/math&gt; for coefficients &lt;math&gt;a,b,c&lt;/math&gt; could be transformed into the appropriate linear function by applying the substitutions &lt;math&gt;b' = b^2, c' = \sqrt{c},&lt;/math&gt; leading to &lt;math&gt;a + b'x_{i1} + c'x_{i2},&lt;/math&gt; which is linear.  Linear regression and similar techniques could be applied and will often still find the optimal coefficients, but their error estimates and such will be wrong.

The explanatory variables may be of any [[statistical data type|type]]: [[real-valued]], [[binary variable|binary]], [[categorical variable|categorical]], etc.  The main distinction is between [[continuous variable]]s (e.g. income, age, [[blood pressure]], etc.) and [[discrete variable]]s (e.g. sex, race, political party, etc.).  Discrete variables referring to more than two possible choices are typically coded using [[dummy variable (statistics)|dummy variable]]s (or [[indicator variable]]s), i.e. separate explanatory variables taking the value 0 or 1 are created for each possible value of the discrete variable, with a 1 meaning "variable does have the given value" and a 0 meaning "variable does not have the given value".  For example, a four-way discrete variable of [[blood type]] with the possible values "A, B, AB, O" would be converted to separate two-way dummy variables, "is-A, is-B, is-AB, is-O", where only one of them has the value 1 and all the rest have the value 0.  This allows for separate regression coefficients to be matched for each possible value of the discrete variable.

Note that, for ''K'' categories, not all ''K'' dummy variables are independent of each other.  For example, in the above blood type example, only three of the four dummy variables are independent, in the sense that once the values of three of the variables are known, the fourth is automatically determined.  Thus, it's really only necessary to encode three of the four possibilities as dummy variables, and in fact if all four possibilities are encoded, the overall model becomes non-[[identifiable]].  This causes problems for a number of methods, such as the simple closed-form solution used in linear regression.  The solution is either to avoid such cases by eliminating one of the dummy variables, and/or introduce a [[regularization (mathematics)|regularization]] constraint (which necessitates a more powerful, typically iterative, method for finding the optimal coefficients).

==See also==
*[[Linear model]]
*[[Linear regression]]

== References ==
{{Reflist}}

[[Category:Regression analysis]]
[[Category:Machine learning]]</text>
      <sha1>sa8vjt2qakj2sb3d3jzvshtkehgk7v1</sha1>
    </revision>
  </page>
  <page>
    <title>Random indexing</title>
    <ns>0</ns>
    <id>37697003</id>
    <revision>
      <id>960033055</id>
      <parentid>915172080</parentid>
      <timestamp>2020-05-31T20:00:45Z</timestamp>
      <contributor>
        <username>Bender235</username>
        <id>88026</id>
      </contributor>
      <minor/>
      <comment>/* top */Replaced [[arXiv]] PDF link with more mobile-friendly abstract link, replaced: https://arxiv.org/pdf/ → https://arxiv.org/abs/</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="5346" xml:space="preserve">'''Random indexing''' is a [[dimensionality reduction]] method and computational framework for [[distributional semantics]], based on the insight that very-high-dimensional [[vector space model]] implementations are impractical, that models need not grow in dimensionality when new items (e.g. new terminology) are encountered, and that a high-dimensional model can be projected into a space of lower dimensionality without compromising L2 distance metrics if the resulting dimensions are chosen appropriately.

This is the original point of the [[random projection]] approach to dimension reduction first formulated as the [[Johnson–Lindenstrauss lemma]], and [[locality-sensitive hashing]] has some of the same starting points. Random indexing, as used in representation of language, originates from the work of [[Pentti Kanerva]]&lt;ref&gt;Kanerva, Pentti, Kristoferson, Jan and Holst, Anders (2000): [https://cloudfront.escholarship.org/dist/prd/content/qt5644k0w6/qt5644k0w6.pdf Random Indexing of Text Samples for Latent Semantic Analysis], Proceedings of the 22nd Annual Conference of the Cognitive Science Society, p.&amp;nbsp;1036. Mahwah, New Jersey: Erlbaum, 2000.&lt;/ref&gt;&lt;ref&gt;Sahlgren, Magnus (2005) [http://eprints.sics.se/221/1/RI_intro.pdf An Introduction to Random Indexing], Proceedings of the Methods and Applications of Semantic Indexing Workshop at the 7th International Conference on Terminology and Knowledge Engineering, TKE 2005, August 16, Copenhagen, Denmark&lt;/ref&gt;&lt;ref&gt;Sahlgren, Magnus, Holst, Anders and Pentti Kanerva (2008) [http://eprints.sics.se/3436/01/permutationsCogSci08.pdf Permutations as a Means to Encode Order in Word Space], In Proceedings of the 30th Annual Conference of the Cognitive Science Society: 1300-1305.&lt;/ref&gt;&lt;ref&gt;Kanerva, Pentti (2009) [http://www.rctn.org/vs265/kanerva09-hyperdimensional.pdf Hyperdimensional Computing: An Introduction to Computing in Distributed Representation with High-Dimensional Random Vectors], Cognitive Computation, Volume 1, Issue 2, pp. 139–159.&lt;/ref&gt;&lt;ref&gt;Joshi, Aditya, Johan Halseth, and Pentti Kanerva. "[https://arxiv.org/abs/1412.7026 Language Recognition using Random Indexing]." arXiv preprint arXiv:1412.7026 (2014).&lt;/ref&gt; on [[sparse distributed memory]], and can be described as an incremental formulation of a random projection.&lt;ref&gt;Recchia, Gabriel, et al. "[https://cloudfront.escholarship.org/dist/prd/content/qt7wc694rn/qt7wc694rn.pdf Encoding sequential information in vector space models of semantics: Comparing holographic reduced representation and random permutation]." (2010): 865-870.&lt;/ref&gt;

It can be also verified that random indexing is a random projection technique for the construction of Euclidean spaces—i.e. L2 normed vector spaces.&lt;ref&gt;Qasemi Zadeh, Behrang &amp; Handschuh, Siegrfied. (2014) [http://aran.library.nuigalway.ie/xmlui/bitstream/handle/10379/4389/tir-rmi.pdf?sequence=1 Random Manhattan Indexing], In Proceedings of the 25th International Workshop on Database and Expert Systems Applications.&lt;/ref&gt; In Euclidean spaces, random projections are elucidated using the Johnson–Lindenstrauss lemma.&lt;ref&gt;
Johnson, W. and Lindenstrauss, J. (1984) [https://www.researchgate.net/profile/William_Johnson16/publication/235008656_Extensions_of_Lipschitz_maps_into_a_Hilbert_space/links/55e9abf908aeb65162649527.pdf Extensions of Lipschitz mappings into a Hilbert space], in Contemporary Mathematics. American Mathematical Society, vol. 26, pp. 189–206.
&lt;/ref&gt;

The TopSig technique&lt;ref&gt;Geva, S. &amp; De Vries, C.M. (2011) [http://eprints.qut.edu.au/43451/ TopSig: Topology Preserving Document Signatures], In Proceedings of Conference on Information and Knowledge Management 2011, 24-28 October 2011, Glasgow, Scotland.&lt;/ref&gt; extends the random indexing model to produce [[bit vector]]s for comparison with the [[Hamming distance]] similarity function. It is used for improving the performance of [[information retrieval]] and [[document clustering]]. In a similar line of research, Random Manhattan Integer Indexing (RMII)&lt;ref&gt;Qasemi Zadeh, Behrang. &amp; Handschuh, Siegfried. (2014) [http://emnlp2014.org/papers/pdf/EMNLP2014178.pdf random Manhattan integer indexing: Incremental L1 Normed Vector Space Construction], In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1713–1723,
October 25-29, 2014, Doha, Qatar.&lt;/ref&gt; is proposed for improving the performance of the methods that employ the [[Manhattan distance]] between text units. Many random indexing methods primarily generate similarity from co-occurrence of items in a corpus. Reflexive Random Indexing (RRI)&lt;ref&gt; Cohen T., [[Roger W. Schvaneveldt|Schvaneveldt]] Roger &amp; Widdows Dominic (2009) [https://www.sciencedirect.com/science/article/pii/S1532046409001208 Reflective Random Indexing and indirect inference: a scalable method for discovery of implicit connections], Journal of Biomedical Informatics, 43(2):240-56.&lt;/ref&gt; generates similarity from co-occurrence and from shared occurrence with other items.

== Weblinks ==
* Zadeh Behrang Qasemi, Handschuh Siegfried. (2015) [http://pars.ie/publications/papers/pre-prints/random-indexing-dr-explained.pdf Random indexing explained with high probability], TSD.

== References ==
{{Reflist}}

[[Category:Machine learning]]
[[Category:Dimension reduction]]


{{compsci-stub}}</text>
      <sha1>eqzx6rql1m85c9nohhmqi1h2apj91nc</sha1>
    </revision>
  </page>
  <page>
    <title>Bag-of-words model</title>
    <ns>0</ns>
    <id>14003441</id>
    <revision>
      <id>998080237</id>
      <parentid>996980615</parentid>
      <timestamp>2021-01-03T18:40:41Z</timestamp>
      <contributor>
        <username>Javiercmh</username>
        <id>2996764</id>
      </contributor>
      <comment>/* Python implementation */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="10394" xml:space="preserve">{{for|Bag-of-words model in computer vision|Bag-of-words model in computer vision}}

The '''bag-of-words model''' is a simplifying representation used in [[natural language processing]] and [[information retrieval]] (IR). In this model, a text (such as a sentence or a document) is represented as the [[multiset|bag (multiset)]] of its words, disregarding grammar and even word order but keeping [[Multiplicity (mathematics)|multiplicity]]. The bag-of-words model has also been [[Bag-of-words model in computer vision|used for computer vision]].&lt;ref name=sivic&gt;{{cite conference
  | first = Josef
  | last = Sivic
  | title = Efficient visual search of videos cast as text retrieval
  | book-title = IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 31, NO. 4
  | pages = 591–605
  | publisher = IEEE
  | date = April 2009
  | url = https://www.di.ens.fr/~josef/publications/sivic09a.pdf}}&lt;/ref&gt;

The bag-of-words model is commonly used in methods of [[document classification]] where the (frequency of) occurrence of each word is used as a [[Feature (machine learning)|feature]] for training a [[Statistical classification|classifier]].&lt;ref&gt;McTear et al 2016, p. 167.&lt;/ref&gt;

An early reference to "bag of words" in a linguistic context can be found in [[Zellig Harris]]'s 1954 article on ''Distributional Structure''.&lt;ref&gt;{{cite journal
  |last= Harris
  |first= Zellig
  |author-link= Zellig Harris
  |year= 1954
  |title= Distributional Structure
  |journal= Word
  |volume= 10
  |issue= 2/3
  |pages= 146–62
  |doi= 10.1080/00437956.1954.11659520
 |quote= And this stock of combinations of elements becomes a factor in the way later choices are made ... for language is not merely a bag of words but a tool with particular properties which have been fashioned in the course of its use}}&lt;/ref&gt;

== Example implementation ==

The following models a text document using bag-of-words. Here are two simple text documents:

&lt;syntaxhighlight lang="text"&gt;
(1) John likes to watch movies. Mary likes movies too.
&lt;/syntaxhighlight&gt;

&lt;syntaxhighlight lang="text"&gt;
(2) Mary also likes to watch football games.
&lt;/syntaxhighlight&gt;

Based on these two text documents, a list is constructed as follows for each document:
&lt;syntaxhighlight lang="javascript"&gt;
"John","likes","to","watch","movies","Mary","likes","movies","too"

"Mary","also","likes","to","watch","football","games"
&lt;/syntaxhighlight&gt;

Representing each bag-of-words as a [[JSON|JSON object]], and attributing to the respective [[JavaScript]] variable:
&lt;syntaxhighlight lang="javascript"&gt;
BoW1 = {"John":1,"likes":2,"to":1,"watch":1,"movies":2,"Mary":1,"too":1};
BoW2 = {"Mary":1,"also":1,"likes":1,"to":1,"watch":1,"football":1,"games":1};
&lt;/syntaxhighlight&gt;
Each key is the word, and each value is the number of occurrences of that word in the given text document.

The order of elements is free, so, for example &lt;code&gt;{"too":1,"Mary":1,"movies":2,"John":1,"watch":1,"likes":2,"to":1}&lt;/code&gt; is also equivalent to ''BoW1''. It is also what we expect from a strict ''JSON object'' representation.

Note: if another document is like a union of these two, 

&lt;syntaxhighlight lang="text"&gt;
(3) John likes to watch movies. Mary likes movies too. Mary also likes to watch football games.
&lt;/syntaxhighlight&gt;

its JavaScript representation will be:
&lt;syntaxhighlight lang="javascript"&gt;
BoW3 = {"John":1,"likes":3,"to":2,"watch":2,"movies":2,"Mary":2,"too":1,"also":1,"football":1,"games":1};
&lt;/syntaxhighlight&gt;

So, as we see in the [[multiset|bag algebra]], the "union" of two documents in the bags-of-words representation is, formally, the [[disjoint union]], summing the multiplicities of each element.

&lt;br /&gt; &lt;math&gt;BoW3 = BoW1 \biguplus BoW2&lt;/math&gt;.

== Application ==
In practice, the Bag-of-words model is mainly used as a tool of feature generation. After transforming the text into a "bag of words", we can calculate various measures to characterize the text. The most common type of characteristics, or features calculated from the Bag-of-words model is term frequency, namely, the number of times a term appears in the text. For the example above, we can construct the following two lists to record the term frequencies of all the distinct words (BoW1 and BoW2 ordered as in BoW3):
&lt;syntaxhighlight lang="javascript"&gt;
(1) [1, 2, 1, 1, 2, 1, 1, 0, 0, 0]
(2) [0, 1, 1, 1, 0, 1, 0, 1, 1, 1]
&lt;/syntaxhighlight&gt;

Each entry of the lists refers to the count of the corresponding entry in the list (this is also the histogram representation). For example, in the first list (which represents document 1), the first two entries are "1,2":

* The first entry corresponds to the word "John" which is the first word in the list, and its value is "1" because "John" appears in the first document once.
* The second entry corresponds to the word "likes", which is the second word in the list, and its value is "2" because "likes" appears in the first document twice.

This list (or vector) representation does not preserve the order of the words in the original sentences. This is just the main feature of the Bag-of-words model. This kind of representation has several successful applications, such as [[email filtering]].&lt;ref name="sivic" /&gt;
 
However, term frequencies are not necessarily the best representation for the text. Common words like "the", "a", "to" are almost always the terms with highest frequency in the text. Thus, having a high raw count does not necessarily mean that the corresponding word is more important. To address this problem, one of the most popular ways to "normalize" the term frequencies is to weight a term by the inverse of document frequency, or [[tf–idf]]. Additionally, for the specific purpose of classification, [[Supervised learning|supervised]] alternatives have been developed to account for the class label of a document.&lt;ref&gt;{{cite conference
|title = A study of term weighting schemes using class information for text classification
|author = Youngjoong Ko
|year = 2012
|book-title = [[Special Interest Group on Information Retrieval|SIGIR'12]]
|publisher=[[Association for Computing Machinery|ACM]]
}}&lt;/ref&gt; Lastly, binary (presence/absence or 1/0) weighting is used in place of frequencies for some problems (e.g., this option is implemented in the [[Weka (machine learning)|WEKA]] machine learning software system).

== ''n''-gram model ==
The Bag-of-words model is an orderless document representation — only the counts of words matter. For instance, in the above example "John likes to watch movies. Mary likes movies too", the bag-of-words representation will not reveal that the verb "likes" always follows a person's name in this text. As an alternative, the [[n-gram|''n''-gram]] model can store this spatial information. Applying to the same example above, a '''bigram''' model will parse the text into the following units and store the term frequency of each unit as before.

&lt;syntaxhighlight lang="javascript"&gt;
[
    "John likes",
    "likes to",
    "to watch",
    "watch movies",
    "Mary likes",
    "likes movies",
    "movies too",
]
&lt;/syntaxhighlight&gt;

Conceptually, we can view bag-of-word model as a special case of the n-gram model, with n=1. For n&amp;gt;1 the model is named [[w-shingling]] (where ''w'' is equivalent to ''n'' denoting the number of grouped words). See [[language model]] for a more detailed discussion.

== Python implementation ==
&lt;syntaxhighlight lang="python"&gt;
from keras.preprocessing.text import Tokenizer

sentence = ["John likes to watch movies. Mary likes movies too."]

def print_bow(sentence: str) -&gt; None:
    tokenizer = Tokenizer()
    tokenizer.fit_on_texts(sentence)
    sequences = tokenizer.texts_to_sequences(sentence)
    word_index = tokenizer.word_index 
    bow = {}
    for key in word_index:
        bow[key] = sequences[0].count(word_index[key])

    print(f"Bag of word sentence 1:\n{bow}")
    print(f'We found {len(word_index)} unique tokens.')

print_bow(sentence)
&lt;/syntaxhighlight&gt;

== Hashing trick ==

A common alternative to using dictionaries is the [[hashing trick]], where words are mapped directly to indices with a hashing function.&lt;ref name="Weinberger05"&gt;{{cite journal
 | last = Weinberger
 | first = K. Q.
 |author2=Dasgupta A. |author3=Langford J. |author4=Smola A. |author5=Attenberg, J.
 | title = Feature hashing for large scale multitask learning
 | journal = Proceedings of the 26th Annual International Conference on Machine Learning
 | year=2009
 | pages=1113–1120
 | arxiv=0902.2206|bibcode=2009arXiv0902.2206W}}&lt;/ref&gt; Thus, no memory is required to store a dictionary. Hash collisions are typically dealt via freed-up memory to increase the number of hash buckets. In practice, hashing simplifies the implementation of bag-of-words models and improves scalability.

== Example usage: spam filtering ==
In [[Bayesian spam filtering]], an e-mail message is modeled as an unordered collection of words selected from one of two probability distributions: one representing [[Spam e-mail|spam]] and one representing legitimate e-mail ("ham"). 
Imagine there are two literal bags full of words. One bag is filled with words found in spam messages, and the other with words found in legitimate e-mail. While any given word is likely to be somewhere in both bags, the "spam" bag will contain spam-related words such as "stock", "Viagra", and "buy" significantly more frequently, while the "ham" bag will contain more words related to the user's friends or workplace.

To classify an e-mail message, the Bayesian spam filter assumes that the message is a pile of words that has been poured out randomly from one of the two bags, and uses [[Bayesian probability]] to determine which bag it is more likely to be in.

== See also ==
* [[Additive smoothing]]
* [[Bag-of-words model in computer vision]]
* [[Document classification]]
* [[Document-term matrix]]
* [[Feature extraction]]
* [[Hashing trick]]
* [[Machine learning]]
* [[MinHash]]
* [[n-gram]]
* [[Natural language processing]]
* [[Vector space model]]
* [[w-shingling]]
* [[tf-idf]]

== Notes ==
{{Reflist}}

== References ==
*McTear, Michael (et al) (2016). ''The Conversational Interface''. Springer International Publishing.

{{Natural Language Processing}}

{{DEFAULTSORT:Bag-of-words model}}
[[Category:Natural language processing]]
[[Category:Machine learning]]
[[Category:Articles with example Python (programming language) code]]</text>
      <sha1>420klfcwcyk6721le4bvznj9o9lzodq</sha1>
    </revision>
  </page>
  <page>
    <title>Similarity learning</title>
    <ns>0</ns>
    <id>38059657</id>
    <revision>
      <id>1004930015</id>
      <parentid>1001756524</parentid>
      <timestamp>2021-02-05T03:33:22Z</timestamp>
      <contributor>
        <username>Bernie74</username>
        <id>765621</id>
      </contributor>
      <minor/>
      <comment>Link to supervised and unsupervised learning articles.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="10365" xml:space="preserve">'''Similarity learning''' is an area of [[Supervised learning|supervised machine learning]] in [[artificial intelligence]]. It is closely related to [[regression (machine learning)|regression]] and [[classification in machine learning|classification]], but the goal is to learn a similarity function that measures how [[Similarity (philosophy)|similar]] or related two objects are. It has applications in [[ranking]], in [[recommendation systems]], visual identity tracking, face verification, and speaker verification.

== Learning setup ==

There are four common setups for similarity and metric distance learning.

; ''[[Regression (machine learning)|Regression]] similarity learning''
: In this setup, pairs of objects are given &lt;math&gt; (x_i^1, x_i^2) &lt;/math&gt; together with a measure of their similarity &lt;math&gt; y_i \in R &lt;/math&gt;. The goal is to learn a function that approximates &lt;math&gt; f(x_i^1, x_i^2) \sim y_i &lt;/math&gt; for every new labeled triplet example &lt;math&gt;(x_i^1, x_i^2, y_i)&lt;/math&gt;. This is typically achieved by  minimizing a regularized loss &lt;math&gt; \min_W \sum_i loss(w;x_i^1, x_i^2,y_i) + reg(w)&lt;/math&gt;.
; ''[[Classification in machine learning|Classification]] similarity learning''
: Given are pairs of similar objects &lt;math&gt;(x_i, x_i^+) &lt;/math&gt; and non similar objects &lt;math&gt;(x_i, x_i^-)&lt;/math&gt;. An equivalent formulation is that every pair &lt;math&gt;(x_i^1, x_i^2)&lt;/math&gt; is given together with a binary label &lt;math&gt;y_i \in \{0,1\}&lt;/math&gt; that determines if the two objects are similar or not. The goal is again to learn a classifier that can decide if a new pair of objects is similar or not.
; ''Ranking similarity learning''
: Given are triplets of objects &lt;math&gt;(x_i, x_i^+, x_i^-)&lt;/math&gt; whose relative similarity obey a predefined order: &lt;math&gt;x_i&lt;/math&gt; is known to be more similar to &lt;math&gt;x_i^+&lt;/math&gt; than to &lt;math&gt;x_i^-&lt;/math&gt;. The goal is to learn a function &lt;math&gt;f&lt;/math&gt; such that for any new triplet of objects &lt;math&gt;(x, x^+, x^-)&lt;/math&gt;, it obeys &lt;math&gt;f(x, x^+) &gt; f(x, x^-)&lt;/math&gt; ([[contrastive learning]]). This setup assumes a weaker form of supervision than in regression, because instead of providing an exact [[Similarity measure|measure of similarity]], one only has to provide the relative order of similarity. For this reason, ranking-based similarity learning is easier to apply in real large-scale applications.&lt;ref&gt;{{cite journal| last1 = Chechik | first1 = G. | last2 = Sharma | first2 = V. | last3 = Shalit | first3 = U. | last4 = Bengio | first4 = S. | title=Large Scale Online Learning of Image Similarity Through Ranking|journal=Journal of Machine Learning Research|year=2010|volume=11|pages=1109–1135|url=http://www.jmlr.org/papers/volume11/chechik10a/chechik10a.pdf}}&lt;/ref&gt;
; [[Locality sensitive hashing]] (LSH)&lt;ref&gt;Gionis, Aristides, Piotr Indyk, and Rajeev Motwani. "Similarity search in high dimensions via hashing." VLDB. Vol. 99. No. 6. 1999.&lt;/ref&gt;
: [[Hash Function|Hashes]] input items so that similar items map to the same "buckets" in memory with high probability (the number of buckets being much smaller than the universe of possible input items). It is often applied in nearest neighbor search on large-scale high-dimensional data, e.g., image databases, document collections, time-series databases, and genome databases.&lt;ref&gt;{{cite web
| first1 = A.|last1=Rajaraman |first2= J.|last2=Ullman|author2-link=Jeffrey Ullman
| url = http://infolab.stanford.edu/~ullman/mmds.html
| title=Mining of Massive Datasets, Ch. 3.
| year = 2010
}}&lt;/ref&gt;

A common approach for learning similarity, is to model the similarity function as a [[bilinear form]]. For example, in the case of ranking similarity learning, one aims to learn a matrix W that parametrizes the similarity function &lt;math&gt; f_W(x, z)  = x^T W z &lt;/math&gt;. When data is abundant, a common approach is to learn a [[siamese network]] - A deep network model with parameter sharing.

== Metric learning ==

Similarity learning is closely related to ''distance metric learning''. Metric learning is the task of learning a distance function over objects. A [[Metric (mathematics)|metric]] or [[distance function]] has to obey four axioms: [[non-negative|non-negativity]], [[identity of indiscernibles]], [[symmetry]] and [[subadditivity]] (or the triangle inequality). In practice, metric learning algorithms ignore the condition of identity of indiscernibles and learn a pseudo-metric.

When the objects &lt;math&gt;x_i&lt;/math&gt; are vectors in &lt;math&gt;R^d&lt;/math&gt;, then any matrix &lt;math&gt;W&lt;/math&gt; in the symmetric positive semi-definite cone &lt;math&gt;S_+^d&lt;/math&gt; defines a distance pseudo-metric of the space of x through the form &lt;math&gt;D_W(x_1, x_2)^2 = (x_1-x_2)^{\top} W (x_1-x_2)&lt;/math&gt;. When &lt;math&gt;W&lt;/math&gt; is a symmetric positive definite matrix, &lt;math&gt;D_W&lt;/math&gt; is a metric. Moreover, as any symmetric positive semi-definite matrix &lt;math&gt;W \in S_+^d&lt;/math&gt; can be decomposed as &lt;math&gt;W = L^{\top}L&lt;/math&gt; where &lt;math&gt;L \in R^{e \times d}&lt;/math&gt; and &lt;math&gt;e \geq rank(W)&lt;/math&gt;, the distance function &lt;math&gt;D_W&lt;/math&gt; can be rewritten equivalently &lt;math&gt;D_W(x_1, x_2)^2 = (x_1-x_2)^{\top} L^{\top}L (x_1-x_2) = \| L (x_1-x_2) \|_2^2&lt;/math&gt;. The distance &lt;math&gt;D_W(x_1, x_2)^2=\| x_1' - x_2' \|_2^2&lt;/math&gt; corresponds to the Euclidean distance between the transformed [[feature vector]]s &lt;math&gt;x_1'= Lx_1&lt;/math&gt; and &lt;math&gt;x_2'= Lx_2&lt;/math&gt;.

Many formulations for metric learning have been proposed.&lt;ref name="survey"&gt;{{cite arXiv | last1 = Bellet | first1 = A. | last2 = Habrard | first2 = A. | last3 = Sebban | first3 = M. |eprint=1306.6709 |class=cs.LG |title=A Survey on Metric Learning for Feature Vectors and Structured Data |year=2013}}&lt;/ref&gt;&lt;ref name="survey2"&gt;{{cite journal| last = Kulis | first = B.| title=Metric Learning: A Survey | journal=Foundations and Trends in Machine Learning | volume = 5| issue = 4| pages = 287–364| year=2012 | url=https://www.nowpublishers.com/article/Details/MAL-019| doi = 10.1561/2200000019}}&lt;/ref&gt; Some well-known approaches for metric learning include Learning from relative comparisons&lt;ref name="SchultzJoachims"&gt;{{cite journal| last1 = Schultz | first1 = M. | last2 = Joachims | first2 = T. | title=Learning a distance metric from relative comparisons|journal=Advances in Neural Information Processing Systems |volume=16|year=2004|pages=41–48|url=https://papers.nips.cc/paper/2366-learning-a-distance-metric-from-relative-comparisons.pdf}}&lt;/ref&gt; which is based on the [[Triplet loss]], [[Large margin nearest neighbor]],&lt;ref name="LMNN"&gt;{{cite journal| last1 = Weinberger | first1 = K. Q. | last2 = Blitzer | first2 = J. C. | last3 = Saul | first3 = L. K. | title=Distance Metric Learning for Large Margin Nearest Neighbor Classification|journal=Advances in Neural Information Processing Systems |volume=18|year=2006|pages=1473–1480|url=http://books.nips.cc/papers/files/nips18/NIPS2005_0265.pdf}}&lt;/ref&gt; Information theoretic metric learning (ITML).&lt;ref name="ITML"&gt;{{cite journal | last1 = Davis | first1 = J. V. | last2 = Kulis | first2 = B. | last3 = Jain | first3 = P. | last4 = Sra | first4 = S. | last5 = Dhillon | first5 = I. S. | title=Information-theoretic metric learning | journal=International Conference in Machine Learning (ICML) | year=2007 | pages=209–216 | url=http://www.cs.utexas.edu/users/pjain/itml/}}&lt;/ref&gt;

In [[statistics]], the [[covariance]] matrix of the data is sometimes used to define a distance metric called [[Mahalanobis distance]].

== Applications ==
Similarity learning is used in information retrieval for [[learning to rank]], in face verification or face identification,&lt;ref name=GUILLAUMIN&gt;{{cite journal| last1 = Guillaumin | first1 = M.  | last2 = Verbeek | first2 = J. | last3 = Schmid | first3 = C. | title=Is that you? Metric learning approaches for face identification|url=http://hal.inria.fr/docs/00/58/50/36/PDF/verbeek09iccv2.pdf|journal=IEEE International Conference on Computer Vision (ICCV)|year=2009}}&lt;/ref&gt;&lt;ref name=MIGNON&gt;{{cite journal| last1 = Mignon | first1 = A. | last2 = Jurie | first2 = F. | title=PCCA: A new approach for distance learning from sparse pairwise constraints|journal=IEEE Conference on Computer Vision and Pattern Recognition|year=2012|url=http://hal.archives-ouvertes.fr/docs/00/80/60/07/PDF/12_cvpr_ldca.pdf}}&lt;/ref&gt; and in [[recommendation systems]]. Also, many machine learning approaches rely on some metric. This includes [[unsupervised learning]] such as [[cluster analysis|clustering]], which groups together close or similar objects. It also includes supervised approaches like [[K-nearest neighbor algorithm]] which rely on labels of nearby objects to decide on the label of a new object. Metric learning has been proposed as a preprocessing step for many of these approaches.&lt;ref name=XING&gt;{{cite journal| last1 = Xing | first1 = E. P. | last2 = Ng | first2 = A. Y. | last3 = Jordan | first3 = M. I. | last4 = Russell | first4 = S. | title=Distance Metric Learning, with Application to Clustering with Side-information | journal=Advances in Neural Information Processing Systems |volume=15 | year=2002| pages = 505–512 | url=https://ai.stanford.edu/~ang/papers/nips02-metric.pdf}}&lt;/ref&gt;

== Scalability ==

Metric and similarity learning naively scale quadratically with the dimension of the input space, as can easily see when the learned metric has a bilinear form &lt;math&gt; f_W(x, z)  = x^T W z &lt;/math&gt;. Scaling to higher dimensions can be achieved by enforcing a sparseness structure over the matrix model, as done with HDSL,&lt;ref name=Liu&gt;{{Cite journal| last1=Liu | last2=Bellet | last3=Sha| title=Similarity Learning for High-Dimensional Sparse Data|year=2015|journal=International Conference on Artificial Intelligence and Statistics (AISTATS)| arxiv=1411.2374 | bibcode=2014arXiv1411.2374L |url=http://jmlr.org/proceedings/papers/v38/liu15.pdf}}&lt;/ref&gt; and with COMET.&lt;ref&gt;{{Cite journal | last1=Atzmon | last2=Shalit | last3=Chechik | title=Learning Sparse Metrics, One Feature at a Time | journal=J. Mach. Learn. Research (JMLR)|year=2015|url=http://jmlr.org/proceedings/papers/v44/atzmon2015.pdf}}&lt;/ref&gt;

==See also==
*[[Learning to rank]]
*[[Latent semantic analysis]]

== Further reading ==
For further information on this topic, see the surveys on metric and similarity learning by Bellet et al.&lt;ref name=survey/&gt; and Kulis.&lt;ref name=survey2/&gt;

== References ==
{{reflist}}

[[Category:Machine learning]]</text>
      <sha1>7rnx4f22nsqq9zm91szauumhti9y1qv</sha1>
    </revision>
  </page>
  <page>
    <title>Feature learning</title>
    <ns>0</ns>
    <id>38870173</id>
    <revision>
      <id>1002889657</id>
      <parentid>1002888994</parentid>
      <timestamp>2021-01-26T14:13:14Z</timestamp>
      <contributor>
        <username>Ception</username>
        <id>28716747</id>
      </contributor>
      <minor/>
      <comment>Clarifying that example is just that</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="21266" xml:space="preserve">{{Machine learning bar}}
In [[machine learning]], '''feature learning''' or '''representation learning'''&lt;ref name="pami"&gt;{{cite journal |author1=Y. Bengio |author2=A. Courville |author3=P. Vincent |title=Representation Learning: A Review and New Perspectives |journal= IEEE Transactions on Pattern Analysis and Machine Intelligence|year=2013|doi=10.1109/tpami.2013.50 |pmid=23787338 |volume=35 |issue=8 |pages=1798–1828|arxiv=1206.5538 }}&lt;/ref&gt; is a set of techniques that allows a system to automatically discover the representations needed for [[Feature (machine learning)|feature]] detection or classification from raw data. This replaces manual [[feature engineering]] and allows a machine to both learn the features  and use them to perform  a specific task.

Feature learning is motivated by the fact that machine learning tasks such as [[statistical classification|classification]] often require input that is mathematically and computationally convenient to process. However, real-world data such as images, video, and sensor data has not yielded to attempts to algorithmically define specific features. An alternative is to discover such features or representations through examination, without relying on explicit algorithms.

Feature learning can be either supervised or unsupervised.
*In [[Supervised learning|supervised feature learning]], features are learned using labeled input data. Examples include [[artificial neural network|supervised neural networks]], [[multilayer perceptron]] and (supervised) [[dictionary learning]].
*In [[Unsupervised learning|unsupervised feature learning]], features are learned with unlabeled input data.  Examples include dictionary learning, [[independent component analysis]], [[autoencoder]]s, [[Matrix decomposition|matrix factorization]]&lt;ref&gt;{{cite conference
|author1=Nathan Srebro |author2=Jason D. M. Rennie |author3=Tommi S. Jaakkola
|title=Maximum-Margin Matrix Factorization
|conference=[[Conference on Neural Information Processing Systems|NIPS]]
|year=2004
}}&lt;/ref&gt; and various forms of [[Cluster analysis|clustering]].&lt;ref name="coates2011"/&gt;&lt;ref&gt;{{cite conference
|last1 = Csurka |first1 = Gabriella
|last2 = Dance |first2 = Christopher C.
|last3 = Fan |first3 = Lixin
|last4 = Willamowski |first4 = Jutta
|last5 = Bray |first5 = Cédric
|title = Visual categorization with bags of keypoints
|conference = ECCV Workshop on Statistical Learning in Computer Vision
|year = 2004
|url = https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/csurka-eccv-04.pdf
}}&lt;/ref&gt;&lt;ref name="jurafsky"&gt;{{cite book |title=Speech and Language Processing |author1=Daniel Jurafsky|author-link=Daniel Jurafsky|author2=James H. Martin |publisher=Pearson Education International |year=2009 |pages=145–146}}&lt;/ref&gt;

== Supervised  ==
Supervised feature learning is learning features from labeled data. The data label allows the system to compute an error term, the degree to which the system fails to produce the label, which can then be used as feedback to correct the learning process (reduce/minimize the error). Approaches include:

=== Supervised dictionary learning ===
Dictionary learning develops a set (dictionary) of representative elements from the input data such that each data point can be represented as a weighted sum of the representative elements. The dictionary elements and the weights may be found by minimizing the average representation error  (over the input data), together with [[Regularization (mathematics)|''L1'' regularization]] on the weights to enable sparsity (i.e., the representation of each data point has only a few nonzero weights).

Supervised dictionary learning exploits both the structure underlying the input data and the labels for optimizing the dictionary elements. For example, this&lt;ref&gt;{{cite journal|last1=Mairal|first1=Julien|last2=Bach|first2=Francis|last3=Ponce|first3=Jean|last4=Sapiro|first4=Guillermo|last5=Zisserman|first5=Andrew|title=Supervised Dictionary Learning|journal=Advances in Neural Information Processing Systems|date=2009}}&lt;/ref&gt; supervised dictionary learning technique applies dictionary learning on classification problems by jointly optimizing the dictionary elements, weights for representing data points, and parameters of the classifier based on the input data. In particular, a minimization problem is formulated, where the objective function consists of the classification error, the representation error, an ''L1'' regularization on the representing weights for each data point (to enable sparse representation of data), and an ''L2'' regularization on the parameters of the classifier.

=== Neural networks===
[[Artificial neural networks|Neural networks]] are a family of learning algorithms that use a "network" consisting of multiple layers of inter-connected nodes. It is inspired by the animal nervous system, where the nodes are viewed as neurons and edges are viewed as synapses. Each edge has an associated weight, and the network defines computational rules for passing input data from the network's input layer to the output layer. A network function associated with a neural network characterizes the relationship between input and output layers, which is parameterized by the weights. With appropriately defined network functions, various learning tasks can be performed by minimizing a cost function over the network function (weights).

Multilayer [[neural network]]s can be used to perform feature learning, since they learn a representation of their input at the hidden layer(s) which is subsequently used for classification or regression at the output layer. The most popular network architecture of this type is [[Siamese neural network|Siamese networks]].

== Unsupervised{{anchor|Unsupervised_feature_learning}}  ==
Unsupervised feature learning is learning features from unlabeled data. The goal of unsupervised feature learning is often to discover low-dimensional features that capture some structure underlying the high-dimensional input data. When the feature learning is performed in an unsupervised way, it enables a form of [[semisupervised learning]] where features learned from an unlabeled dataset are then employed to improve performance in a supervised setting with labeled data.&lt;ref name="liang"&gt;{{cite thesis |type=M. Eng. |author=Percy Liang |year=2005 |title=Semi-Supervised Learning for Natural Language |publisher=[[Massachusetts Institute of Technology|MIT]] |url=http://people.csail.mit.edu/pliang/papers/meng-thesis.pdf |pages=44–52}}&lt;/ref&gt;&lt;ref name="turian"/&gt; Several approaches are introduced in the following.

=== ''K''-means clustering ===
[[K-means clustering|''K''-means clustering]] is an approach for vector quantization. In particular, given a set of ''n'' vectors, ''k''-means clustering groups them into k clusters (i.e., subsets) in such a way that each vector belongs to the cluster with the closest mean. The problem is computationally [[NP-hard]], although suboptimal [[greedy algorithm]]s have been developed.

K-means clustering can be used to group an unlabeled set of inputs into ''k'' clusters, and then use the [[centroid]]s of these clusters to produce features. These features can be produced in several ways. The simplest is to add ''k'' binary features to each sample, where each feature ''j'' has value one [[if and only if|iff]] the ''j''th centroid learned by ''k''-means is the closest to the sample under consideration.&lt;ref name="coates2011"/&gt; It is also possible to use the distances to the clusters as features, perhaps after transforming them through a [[radial basis function]] (a technique that has been used to train [[Radial basis function network|RBF network]]s&lt;ref name="schwenker"&gt;{{cite journal |last1=Schwenker |first1=Friedhelm |last2=Kestler |first2=Hans A. |last3=Palm |first3=Günther |title=Three learning phases for radial-basis-function networks |journal=Neural Networks |volume=14 |issue=4–5 |pages=439–458 |year=2001 |citeseerx = 10.1.1.109.312 |doi=10.1016/s0893-6080(01)00027-2|pmid=11411631 }}&lt;/ref&gt;). Coates and [[Andrew Ng|Ng]] note that certain variants of ''k''-means behave similarly to [[sparse coding]] algorithms.&lt;ref name=Coates2012&gt;{{cite encyclopedia |last1 = Coates |first1 = Adam |last2 = Ng |first2 = Andrew Y. |title=Learning feature representations with k-means |encyclopedia=Neural Networks: Tricks of the Trade |year = 2012 |publisher=Springer |editor=G. Montavon, G. B. Orr and K.-R. Müller}}&lt;/ref&gt;

In a comparative evaluation of unsupervised feature learning methods, Coates, Lee and Ng found that ''k''-means clustering with an appropriate transformation outperforms the more recently invented auto-encoders and RBMs on an image classification task.&lt;ref name="coates2011"/&gt; ''K''-means also improves performance in the domain of [[Natural language processing|NLP]], specifically for [[named-entity recognition]];&lt;ref&gt;{{cite conference |title=Phrase clustering for discriminative learning |author1=Dekang Lin |author2=Xiaoyun Wu |conference=Proc. J. Conf. of the ACL and 4th Int'l J. Conf. on Natural Language Processing of the AFNLP |pages=1030–1038 |year=2009 |url=http://wmmks.csie.ncku.edu.tw/ACL-IJCNLP-2009/ACLIJCNLP/pdf/ACLIJCNLP116.pdf}}&lt;/ref&gt; there, it competes with [[Brown clustering]], as well as with distributed word representations (also known as neural word embeddings).&lt;ref name="turian"&gt;{{cite conference |author1=Joseph Turian |author2=Lev Ratinov |author3=Yoshua Bengio |title=Word representations: a simple and general method for semi-supervised learning |conference=Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics |year=2010 |url=http://www.newdesign.aclweb.org/anthology/P/P10/P10-1040.pdf |access-date=2014-02-22 |archive-url=https://web.archive.org/web/20140226202823/http://www.newdesign.aclweb.org/anthology/P/P10/P10-1040.pdf |archive-date=2014-02-26 |url-status=dead }}&lt;/ref&gt;

=== Principal component analysis ===
[[Principal component analysis]] (PCA) is often used for dimension reduction. Given an unlabeled set of ''n'' input data vectors, PCA generates ''p'' (which is much smaller than the dimension of the input data) [[Singular value decomposition|right singular vectors]] corresponding to the ''p'' largest singular values of the data matrix, where the ''k''th row of the data matrix is the ''k''th input data vector shifted by the [[Sample mean and sample covariance|sample mean]] of the input (i.e., subtracting the sample mean from the data vector). Equivalently, these singular vectors are the [[eigenvector]]s corresponding to the ''p'' largest eigenvalues of the [[Sample mean and sample covariance|sample covariance matrix]] of the input vectors. These ''p'' singular vectors are the feature vectors learned from the input data, and they represent directions along which the data has the largest variations.

PCA is a linear feature learning approach since the ''p'' singular vectors are linear functions of the data matrix. The singular vectors can be generated via a simple algorithm with ''p'' iterations. In the ''i''th iteration, the projection of the data matrix on the ''(i-1)''th eigenvector is subtracted, and the ''i''th singular vector is found as the right singular vector corresponding to the largest singular of the residual data matrix.

PCA has several limitations. First, it assumes that the directions with large variance are of most interest, which may not be the case. PCA only relies on orthogonal transformations of the original data, and it exploits only the first- and second-order [[Moment (mathematics)|moments]] of the data, which may not well characterize the data distribution. Furthermore, PCA can effectively reduce dimension only when the input data vectors are correlated (which results in a few dominant eigenvalues).

=== Local linear embedding ===
[[Nonlinear dimensionality reduction|Local linear embedding]] (LLE) is a nonlinear learning approach for generating low-dimensional neighbor-preserving representations from (unlabeled) high-dimension input. The approach was proposed by Roweis and Saul (2000).&lt;ref name="RowSau00"&gt;{{cite journal|last1=Roweis|first1=Sam T|last2=Saul|first2=Lawrence K|title=Nonlinear Dimensionality Reduction by Locally Linear Embedding|journal=Science |series=New Series|date=2000|volume=290|issue=5500|pages=2323–2326|doi=10.1126/science.290.5500.2323|jstor=3081722|pmid=11125150|bibcode=2000Sci...290.2323R}}&lt;/ref&gt;&lt;ref name="SauRow00"&gt;{{cite journal|last1=Saul|first1=Lawrence K|last2=Roweis|first2=Sam T|title=An Introduction to Locally Linear Embedding|date=2000|url=http://www.cs.toronto.edu/~roweis/lle/publications.html}}&lt;/ref&gt; The general idea of LLE is to reconstruct the original high-dimensional data using lower-dimensional points while maintaining some geometric properties of the neighborhoods in the original data set.

LLE consists of two major steps. The first step is for "neighbor-preserving", where each input data point ''Xi'' is reconstructed as a weighted sum of [[K-nearest neighbors algorithm|''K'' nearest neighbor]] data points, and the optimal weights are found by minimizing the average squared reconstruction error (i.e., difference between an input point and its reconstruction) under the constraint that the weights associated with each point sum up to one. The second step is for "dimension reduction," by looking for vectors in a lower-dimensional space that minimizes the representation error using the optimized weights in the first step. Note that in the first step, the weights are optimized with fixed data, which can be solved as a [[least squares]] problem. In the second step, lower-dimensional points are optimized with fixed weights, which can be solved via sparse eigenvalue decomposition.

The reconstruction weights obtained in the first step capture the "intrinsic geometric properties" of a neighborhood in the input data.&lt;ref name="SauRow00"/&gt; It is assumed that original data lie on a smooth lower-dimensional [[manifold]], and the "intrinsic geometric properties" captured by the weights of the original data are also expected to be on the manifold. This is why the same weights are used in the second step of LLE. Compared with PCA, LLE is more powerful in exploiting the underlying data structure.

=== Independent component analysis ===
[[Independent component analysis]] (ICA) is a technique for forming a data representation using a weighted sum of independent non-Gaussian components.&lt;ref&gt;{{cite journal|last1=Hyvärinen|first1=Aapo|last2=Oja|first2=Erkki|title=Independent Component Analysis: Algorithms and Applications|journal=Neural Networks|date=2000|volume=13|issue=4|pages=411–430|doi= 10.1016/s0893-6080(00)00026-5|pmid=10946390}}&lt;/ref&gt; The assumption of non-Gaussian is imposed since the weights cannot be uniquely determined when all the components follow [[Normal distribution|Gaussian]] distribution.

=== Unsupervised dictionary learning ===

Unsupervised dictionary learning does not utilize data labels and exploits the structure underlying the data for optimizing dictionary elements. An example of unsupervised dictionary learning is sparse coding, which aims to learn basis functions (dictionary elements) for data representation from unlabeled input data. Sparse coding can be applied to learn overcomplete dictionaries, where the number of dictionary elements is larger than the dimension of the input data.&lt;ref&gt;{{cite journal|last1=Lee|first1=Honglak|last2=Battle|first2=Alexis|last3=Raina|first3=Rajat|last4=Ng|first4=Andrew Y|title=Efficient sparse coding algorithms|journal=Advances in Neural Information Processing Systems|date=2007}}&lt;/ref&gt; Aharon et al. proposed algorithm [[K-SVD]] for learning a dictionary of elements that enables sparse representation.&lt;ref&gt;{{cite journal|last1=Aharon|first1=Michal|last2=Elad|first2=Michael|last3=Bruckstein|first3=Alfred|title=K-SVD: An Algorithm for Designing Overcomplete Dictionaries for Sparse Representation|journal=IEEE Trans. Signal Process.|date=2006|volume=54|issue=11|pages=4311–4322|doi=10.1109/TSP.2006.881199|bibcode=2006ITSP...54.4311A}}&lt;/ref&gt;

== Multilayer/deep architectures ==

The hierarchical architecture of the biological neural system inspires [[deep learning]] architectures for feature learning by stacking multiple layers of learning nodes.&lt;ref&gt;{{cite journal|last1=Bengio|first1=Yoshua|title=Learning Deep Architectures for AI|journal=Foundations and Trends in Machine Learning|date=2009|volume=2|issue=1|pages=1–127|doi=10.1561/2200000006}}&lt;/ref&gt; These architectures are often designed based on the assumption of [[distributed representation]]: observed data is generated by the interactions of many different factors on multiple levels. In a deep learning architecture, the output of each intermediate layer can be viewed as a representation of the original input data. Each level uses the representation produced by previous level as input, and produces new representations as output, which is then fed to higher levels. The input at the bottom layer is raw data, and the output of the final layer is the final low-dimensional feature or representation.

=== Restricted Boltzmann machine ===
[[Restricted Boltzmann machine]]s (RBMs) are often used as a building block for multilayer learning architectures.&lt;ref name="coates2011"&gt;{{cite conference
|last1 = Coates
|first1 = Adam
|last2 = Lee
|first2 = Honglak
|last3 = Ng
|first3 = Andrew Y.
|title = An analysis of single-layer networks in unsupervised feature learning
|conference = Int'l Conf. on AI and Statistics (AISTATS)
|year = 2011
|url = http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2011_CoatesNL11.pdf
|access-date = 2014-11-24
|archive-url = https://web.archive.org/web/20170813153615/http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2011_CoatesNL11.pdf
|archive-date = 2017-08-13
|url-status = dead
}}&lt;/ref&gt;&lt;ref name = Hinton2006&gt;{{Cite journal | last1 = Hinton | first1 = G. E. | last2 = Salakhutdinov | first2 = R. R. | title = Reducing the Dimensionality of Data with Neural Networks | doi = 10.1126/science.1127647 | journal = Science | volume = 313 | issue = 5786 | pages = 504–507 | year = 2006 | pmid =  16873662| url  = http://www.cs.toronto.edu/~hinton/science.pdf| bibcode = 2006Sci...313..504H }}&lt;/ref&gt; An RBM can be represented by an undirected bipartite graph consisting of a group of [[Binary variable|binary]] [[Latent variable|hidden variables]], a group of visible variables, and edges connecting the hidden and visible nodes. It is a special case of the more general [[Boltzmann machine]]s with the constraint of no intra-node connections. Each edge in an RBM is associated with a weight. The weights together with the connections define an [[energy function]], based on which a [[joint distribution]] of visible and hidden nodes can be devised. Based on the topology of the RBM, the hidden (visible) variables are independent, conditioned on the visible (hidden) variables.{{Clarify|reason=visible hidden?|date=June 2017}} Such conditional independence facilitates computations.

An RBM can be viewed as a single layer architecture for unsupervised feature learning. In particular, the visible variables correspond to input data, and the hidden variables correspond to feature detectors. The weights can be trained by maximizing the probability of visible variables using [[Geoffrey Hinton|Hinton]]'s [[contrastive divergence]] (CD) algorithm.&lt;ref name = Hinton2006/&gt;

In general training RBM by solving the maximization problem tends to result in non-sparse representations. Sparse RBM&lt;ref name = Lee2008&gt;{{cite journal|last1=Lee|first1=Honglak|last2=Ekanadham|first2=Chaitanya|last3=Andrew|first3=Ng|title=Sparse deep belief net model for visual area V2|journal=Advances in Neural Information Processing Systems|date=2008}}&lt;/ref&gt; was proposed to enable sparse representations. The idea is to add a [[Regularization (mathematics)|regularization]] term in the objective function of data likelihood, which penalizes the deviation of the expected hidden variables from a small constant &lt;math&gt;p&lt;/math&gt;.

=== Autoencoder ===
An [[autoencoder]] consisting of an encoder and a decoder is a paradigm for deep learning architectures. An example is provided by Hinton and Salakhutdinov&lt;ref name = Hinton2006/&gt; where the encoder uses raw data (e.g., image) as input and produces feature or representation as output and the decoder uses the extracted feature from the encoder as input and reconstructs the original input raw data as output. The encoder and decoder are constructed by stacking multiple layers of RBMs. The parameters involved in the architecture were originally trained in a [[Greedy algorithm|greedy]] layer-by-layer manner: after one layer of feature detectors is learned, they are fed up as visible variables for training the corresponding RBM. Current approaches typically apply end-to-end training with [[stochastic gradient descent]] methods. Training can be repeated until some stopping criteria are satisfied.

==See also==
* [[Automated machine learning]] (AutoML)
* [[Basis function]]
* [[Deep learning]]
* [[Feature detection (computer vision)]]
* [[Feature extraction]]
* [[Kernel trick]]
* [[Vector quantization]]

==References==
{{Reflist|30em}}

[[Category:Machine learning]]</text>
      <sha1>q3iawvll869yr7181lk54tw666zjxj4</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Statistical natural language processing</title>
    <ns>14</ns>
    <id>11737376</id>
    <revision>
      <id>958675419</id>
      <parentid>712166798</parentid>
      <timestamp>2020-05-25T03:53:54Z</timestamp>
      <contributor>
        <username>Jarble</username>
        <id>7226930</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="115" xml:space="preserve">{{cat main}}
[[Category:Applied statistics]]
[[Category:Machine learning]]
[[Category:Natural language processing]]</text>
      <sha1>9enqiyxn9ghzau9jii82txj4qn2xz5n</sha1>
    </revision>
  </page>
  <page>
    <title>Catastrophic interference</title>
    <ns>0</ns>
    <id>39182554</id>
    <revision>
      <id>1004638215</id>
      <parentid>1003656592</parentid>
      <timestamp>2021-02-03T16:43:19Z</timestamp>
      <contributor>
        <username>Th.dubach</username>
        <id>23403137</id>
      </contributor>
      <comment>citation</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="29097" xml:space="preserve">'''Catastrophic interference''', also known as '''catastrophic forgetting''', is the tendency of an [[artificial neural network]] to completely and abruptly forget previously learned information upon learning new information.&lt;ref name="McCloskey1989"&gt;{{cite book |doi=10.1016/S0079-7421(08)60536-8 |title=Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem |series=Psychology of Learning and Motivation |year=1989 |last1=McCloskey |first1=Michael |last2=Cohen |first2=Neal J. |volume=24 |pages=109–165 |isbn=978-0-12-543324-2 }}&lt;/ref&gt;&lt;ref name="Ratcliff1990"&gt;{{cite journal |last1=Ratcliff |first1=Roger |title=Connectionist models of recognition memory: Constraints imposed by learning and forgetting functions. |journal=Psychological Review |date=1990 |volume=97 |issue=2 |pages=285–308 |doi=10.1037/0033-295x.97.2.285 |pmid=2186426 }}&lt;/ref&gt; Neural networks are an important part of the [[Connectionism|network approach and connectionist approach]] to [[cognitive science]]. With these networks, human capabilities such as memory and learning can be modeled using computer simulations. Catastrophic interference is an important issue to consider when creating connectionist models of memory. It was originally brought to the attention of the scientific community by research from McCloskey and Cohen (1989),&lt;ref name="McCloskey1989" /&gt; and Ratcliff (1990).&lt;ref name="Ratcliff1990" /&gt; It is a radical manifestation of the 'sensitivity-stability' dilemma&lt;ref&gt;{{cite book |last1=Hebb |first1=Donald Olding |title=The Organization of Behavior: A Neuropsychological Theory |date=1949 |publisher=Wiley |isbn=978-0-471-36727-7 |oclc=569043119 }}{{pn|date=September 2020}}&lt;/ref&gt; or the 'stability-plasticity' dilemma.&lt;ref&gt;{{cite journal |last1=Carpenter |first1=Gail A. |last2=Grossberg |first2=Stephen |title=ART 2: self-organization of stable category recognition codes for analog input patterns |journal=Applied Optics |date=1 December 1987 |volume=26 |issue=23 |pages=4919–4930 |doi=10.1364/AO.26.004919 |pmid=20523470 |bibcode=1987ApOpt..26.4919C }}&lt;/ref&gt; Specifically, these problems refer to the challenge of making an artificial neural network that is sensitive to, but not disrupted by, new information. [[Lookup table]]s and connectionist networks lie on the opposite sides of the stability plasticity spectrum.&lt;ref name ="French1997"&gt;{{cite journal |last1=French |first1=Robert M |title=Pseudo-recurrent Connectionist Networks: An Approach to the 'Sensitivity-Stability' Dilemma |journal=Connection Science |date=December 1997 |volume=9 |issue=4 |pages=353–380 |doi=10.1080/095400997116595 }}&lt;/ref&gt; The former remains completely stable in the presence of new information but lacks the ability to [[machine learning#Generalization|generalize]], i.e. infer general principles, from new inputs. On the other hand, connectionist networks like the [[backpropagation|standard backpropagation network]] can generalize to unseen inputs, but they are very sensitive to new information. Backpropagation models can be considered good models of [[human memory]] insofar as they mirror the human ability to generalize{{according to whom|date=September 2020}}{{citation needed|date=September 2020}} but these networks often exhibit less stability than human memory. Notably, these backpropagation networks are susceptible to catastrophic interference. This is an issue when modelling human memory, because unlike these networks, humans typically do not show catastrophic forgetting.&lt;ref&gt;{{cite journal |last1=González |first1=Oscar C |last2=Sokolov |first2=Yury |last3=Krishnan |first3=Giri P |last4=Delanois |first4=Jean Erik |last5=Bazhenov |first5=Maxim |title=Can sleep protect memories from catastrophic forgetting? |journal=eLife |date=4 August 2020 |volume=9 |pages=e51005 |doi=10.7554/eLife.51005 |url=https://elifesciences.org/articles/51005 |access-date=3 February 2021}}&lt;/ref&gt;

==History of catastrophic interference==

The term catastrophic interference was originally coined by McCloskey and Cohen (1989) but was also brought to the attention of the scientific community by research from Ratcliff (1990).&lt;ref name="Ratcliff1990" /&gt;

=== ''The Sequential Learning Problem'': McCloskey and Cohen (1989)===

McCloskey and Cohen (1989) noted the problem of catastrophic interference during two different experiments with backpropagation neural network modelling.

* Experiment 1: ''Learning the ones and twos addition facts''
In their first experiment they trained a standard backpropagation neural network on a single training set consisting of 17 single-digit ones problems (i.e., 1 + 1 through 9 + 1, and 1 + 2 through 1 + 9) until the network could represent and respond properly to all of them. The error between the actual output and the desired output steadily declined across training sessions, which reflected that the network learned to represent the target outputs better across trials.  Next, they trained the network on a single training set consisting of 17 single-digit twos problems (i.e., 2 + 1 through 2 + 9, and 1 + 2 through 9 + 2) until the network could represent, respond properly to all of them. They noted that their procedure was similar to how a child would learn their addition facts. Following each learning trial on the twos facts, the network was tested for its knowledge on both the ones and twos addition facts. Like the ones facts, the twos facts were readily learned by the network. However, McCloskey and Cohen noted the network was no longer able to properly answer the ones addition problems even after one learning trial of the twos addition problems. The output pattern produced in response to the ones facts often resembled an output pattern for an incorrect number more closely than the output pattern for a correct number. This is considered to be a drastic amount of error. Furthermore, the problems 2+1 and 2+1, which were included in both training sets, even showed dramatic disruption during the first learning trials of the twos facts.

* Experiment 2: ''Replication of Barnes and Underwood (1959) study''&lt;ref name="Barnes1959"&gt;{{cite journal |last1=Barnes |first1=Jean M. |last2=Underwood |first2=Benton J. |title='Fate' of first-list associations in transfer theory. |journal=Journal of Experimental Psychology |date=August 1959 |volume=58 |issue=2 |pages=97–105 |doi=10.1037/h0047507 |pmid=13796886 }}&lt;/ref&gt; In their second connectionist model, McCloskey and Cohen attempted to replicate the study on retroactive interference in humans by Barnes and Underwood (1959). They trained the model on A-B and A-C lists and used a context pattern in the input vector (input pattern), to differentiate between the lists. Specifically the network was trained to responds with the right B response when shown the A stimulus and A-B context pattern and to respond with the correct C response when shown the A stimulus and the A-C context pattern. When the model was trained concurrently on the A-B and A-C items then the network readily learned all of the associations correctly. In sequential training the A-B list was trained first, followed by the A-C list. After each presentation of the A-C list, performance was measured for both the A-B and A-C lists. They found that the amount of training on the A-C list in Barnes and Underwood study that lead to 50% correct responses, lead to nearly 0% correct responses by the backpropagation network. Furthermore, they found that the network tended to show responses that looked like the C response pattern when the network was prompted to give the B response pattern. This indicated that the A-C list apparently had overwritten the A-B list. This could be likened to learning the word dog, followed by learning the word stool and then finding that you cannot recognize the word cat well but instead think of the word stool when presented with the word dog.

McCloskey and Cohen tried to reduce interference through a number of manipulations including changing the number of hidden units, changing the value of the learning rate parameter, overtraining on the A-B list, freezing certain connection weights, changing target values 0 and 1 instead 0.1 and 0.9. However none of these manipulations satisfactorily reduced the catastrophic interference exhibited by the networks.

Overall, McCloskey and Cohen (1989) concluded that: 
*at least some interference will occur whenever new learning alters the weights involved representing 
*the greater the amount of new learning, the greater the disruption in old knowledge 
*interference was catastrophic in the backpropagation networks when learning was sequential but not concurrent

===''Constraints Imposed by Learning and Forgetting Functions'': Ratcliff (1990)===

Ratcliff (1990) used multiple sets of backpropagation models applied to standard recognition memory procedures, in which the items were sequentially learned.&lt;ref name="Ratcliff1990" /&gt; After inspecting the recognition performance models he found two major problems:
* Well-learned information was catastrophically forgotten as new information was learned in both small and large backpropagation networks. 
Even one learning trial with new information resulted in a significant loss of the old information, paralleling the findings of McCloskey and Cohen (1989).&lt;ref name="McCloskey1989" /&gt; Ratcliff also found that the resulting outputs were often a blend of the previous input and the new input. In larger networks, items learned in groups (e.g. AB then CD) were more resistant to forgetting than were items learned singly (e.g. A then B then C…). However, the forgetting for items learned in groups was still large. Adding new hidden units to the network did not reduce interference. 
* Discrimination between the studied items and previously unseen items decreased as the network learned more. 
This finding contradicts with studies on human memory, which indicated that discrimination increases with learning. Ratcliff attempted to alleviate this problem by adding 'response nodes' that would selectively respond to old and new inputs. However, this method did not work as these response nodes would become active for all inputs. A model which used a context pattern also failed to increase discrimination between new and old items.

==Proposed solutions==

The main cause of catastrophic interference seems to be overlap in the representations at the hidden layer of distributed neural networks.&lt;ref name="French1991"&gt;{{cite conference |last1=French |first1=Robert M. |year=1991 |url=http://www.aaai.org/Papers/Symposia/Spring/1993/SS-93-06/SS93-06-007.pdf |title=Using Semi-Distributed Representations to Overcome Catastrophic Forgetting in Connectionist Networks |conference=Proceedings of the 13th Annual Cognitive Science Society Conference |pages=173–178 |location=New Jersey |publisher=Lawrence Erlbaum |citeseerx=10.1.1.1040.3564 }}&lt;/ref&gt;&lt;ref name="McRae1993"&gt;{{cite book |chapter=Catastrophic Interference is Eliminated in Pre-Trained Networks |pages=723–728 |chapter-url=https://books.google.com/books?id=Cw-eIm3e2FoC&amp;pg=PA723 |title=Proceedings of the Fifteenth Annual Conference of the Cognitive Science Society: June 18 to 21, 1993, Institute of Cognitive Science, University of Colorado-Boulder |year=1993 |publisher=Psychology Press |isbn=978-0-8058-1487-3 }}&lt;/ref&gt;&lt;ref name="French1999"&gt;{{cite journal |last1=French |first1=R |title=Catastrophic forgetting in connectionist networks |journal=Trends in Cognitive Sciences |date=1 April 1999 |volume=3 |issue=4 |pages=128–135 |doi=10.1016/S1364-6613(99)01294-2 |pmid=10322466 |s2cid=2691726 }}&lt;/ref&gt; In a distributed representation, each input tends to create changes in the weights of many of the nodes. Catastrophic forgetting occurs because when many of the weights where "knowledge is stored" are changed, it is unlikely for prior knowledge to be kept intact. During sequential learning, the inputs become mixed, with the new inputs being superimposed on top of the old ones.&lt;ref name="McRae1993" /&gt; Another way to conceptualize this is by visualizing learning as a movement through a weight space.&lt;ref name="Lewandowsky1991"&gt;{{cite book |last1=Lewandowsky |first1=Stephan |chapter=Gradual unlearning and catastrophic interference: a comparison of distributed architectures |pages=445–476 |chapter-url=https://books.google.com/books?id=LQh7AgAAQBAJ&amp;pg=PA445 |editor1-last=Hockley |editor1-first=William E. |editor2-last=Lewandowsky |editor2-first=Stephan |year=1991 |title=Relating Theory and Data: Essays on Human Memory in Honor of Bennet B. Murdock |publisher=Psychology Press |isbn=978-1-317-76013-9 }}&lt;/ref&gt; This weight space can be likened to a spatial representation of all of the possible combinations of weights that the network could possess. When a network first learns to represent a set of patterns, it finds a point in the weight space that allows it to recognize all of those patterns.&lt;ref name=French1999 /&gt; However, when the network then learns a new set of patterns, it will move to a place in the weight space for which the only concern is the recognition of the new patterns.&lt;ref name=French1999 /&gt; To recognize both sets of patterns, the network must find a place in the weight space suitable for recognizing both the new and the old patterns.

Below are a number of techniques which have empirical support in successfully reducing catastrophic interference in backpropagation neural networks:

===Orthogonality===
Many of the early techniques in reducing representational overlap involved making either the input vectors or the hidden unit activation patterns [[orthogonality#Definitions|orthogonal]] to one another. Lewandowsky and Li (1995)&lt;ref name="Lewandowsky1995"&gt;{{cite book |doi=10.1016/B978-012208930-5/50011-8 |chapter=Catastrophic interference in neural networks |title=Interference and Inhibition in Cognition |year=1995 |last1=Lewandowsky |first1=Stephan |last2=Li |first2=Shu-Chen |pages=329–361 |isbn=978-0-12-208930-5 }}&lt;/ref&gt; noted that the interference between sequentially learned patterns is minimized if the input vectors are orthogonal to each other. Input vectors are said to be orthogonal to each other if the pairwise product of their elements across the two vectors sum to zero. For example, the patterns [0,0,1,0] and [0,1,0,0] are said to be orthogonal because (0&amp;times;0 + 0&amp;times;1 + 1&amp;times;0 + 0&amp;times;0) = 0. One of the techniques which can create orthogonal representations at the hidden layers involves bipolar feature coding (i.e., coding using -1 and 1 rather than 0 and 1).&lt;ref name="French1999" /&gt; Orthogonal patterns tend to produce less interference with each other. However, not all learning problems can be represented using these types of vectors and some studies report that the degree of interference is still problematic with orthogonal vectors.&lt;ref name="Ratcliff1990" /&gt;

===Node sharpening technique===
According to French (1991),&lt;ref name="French1991" /&gt; catastrophic interference arises in [[feedforward neural network|feedforward]] backpropagation networks due to the interaction of node activations, or activation overlap, that occurs in distributed representations at the hidden layer. [[Neural network]]s that employ very localized representations do not show catastrophic interference because of the lack of overlap at the hidden layer. French therefore suggested that reducing the value of activation overlap at the hidden layer would reduce catastrophic interference in distributed networks. Specifically he proposed that this could be done through changing the distributed representations at the hidden layer to 'semi-distributed' representations. A 'semi-distributed' representation has fewer hidden nodes that are active, and/or a lower activation value for these nodes, for each representation, which will make the representations of the different inputs overlap less at the hidden layer.  French recommended that this could be done through 'activation sharpening', a technique which slightly increases the activation of a certain number of the most active nodes in the hidden layer, slightly reduces the activation of all the other units and then changes the input-to-hidden layer weights to reflect these activation changes (similar to error backpropagation).

===Novelty rule===
Kortge (1990)&lt;ref name="Kortge1990"&gt;Kortge, C. A. (1990). Episodic memory in connectionist networks. In: ''The Twelfth Annual Conference of the Cognitive Science Society'', (pp. 764-771). Hillsdale, NJ: Lawrence Erlbaum.&lt;/ref&gt; proposed a learning rule for training neural networks, called the 'novelty rule', to help alleviate catastrophic interference. As its name suggests, this rule helps the neural network to learn only the components of a new input that differ from an old input. Consequently, the novelty rule changes only the weights that were not previously dedicated to storing information, thereby reducing the overlap in representations at the hidden units. In order to apply the novelty rule, during learning the input pattern is replaced by a novelty vector that represents the components that differ. When the novelty rule is used in a standard backpropagation network there is no, or lessened, forgetting of old items when new items are presented sequentially.&lt;ref name="Kortge1990" /&gt; However, a limitation is that this rule can only be used with auto-encoder or auto-associative networks, in which the target response for the output layer is identical to the input pattern.

===Pre-training networks===
McRae and Hetherington (1993)&lt;ref name="McRae1993" /&gt; argued that humans, unlike most neural networks, do not take on new learning tasks with a random set of weights. Rather, people tend to bring a wealth of prior knowledge to a task and this helps to avoid the problem of interference. They showed that when a network is pre-trained on a random sample of data prior to starting a sequential learning task that this prior knowledge will naturally constrain how the new information can be incorporated. This would occur because a random sample of data from a domain that has a high degree of internal structure, such as the English language, training would capture the regularities, or recurring patterns, found within that domain. Since the domain is based on regularities, a newly learned item will tend to be similar to the previously learned information, which will allow the network to incorporate new data with little interference with existing data. Specifically, an input vector that follows the same pattern of regularities as the previously trained data should not cause a drastically different pattern of activation at the hidden layer or drastically alter weights.

===Rehearsal===
Robins (1995)&lt;ref name ="Robins1995"&gt;{{cite journal |last1=Robins |first1=Anthony |title=Catastrophic Forgetting, Rehearsal and Pseudorehearsal |journal=Connection Science |date=June 1995 |volume=7 |issue=2 |pages=123–146 |doi=10.1080/09540099550039318 }}&lt;/ref&gt; described that catastrophic forgetting can be prevented by rehearsal mechanisms. This means that when new information is added, the neural network is retrained on some of the previously learned information. In general, however, previously learned information&amp;nbsp;may not be available for such retraining. A solution for this is "pseudo-rehearsal", in which the network is not retrained on the actual previous data but on representations of them. Several methods are based upon this general mechanism.

 [[File:Pseudorecurrentnetwork.jpg|thumbnail|Figure 2: The architecture of a pseudo-recurrent network]]

====Pseudo-recurrent networks====
French (1997) proposed a pseudo-recurrent backpropagation network (see Figure 2).&lt;ref name ="French1997" /&gt; In this model the network is separated into two functionally distinct but interacting sub-networks. This model is biologically inspired and is based on research from McClelland et al. (1995)&lt;ref name="McClelland1995"&gt;{{cite journal |last1=McClelland |first1=James L. |last2=McNaughton |first2=Bruce L. |last3=O'Reilly |first3=Randall C. |title=Why there are complementary learning systems in the hippocampus and neocortex: Insights from the successes and failures of connectionist models of learning and memory. |journal=Psychological Review |date=July 1995 |volume=102 |issue=3 |pages=419–457 |doi=10.1037/0033-295X.102.3.419 |pmid=7624455 }}&lt;/ref&gt; McClelland and colleagues suggested that the [[hippocampus]] and [[neocortex]] act as separable but complementary memory systems, with the hippocampus for [[short term memory]] storage and the neocortex for [[long term memory]] storage. Information initially stored in the hippocampus can be "transferred" to the neocortex by means of reactivation or replay. In the pseudo-recurrent network, one of the sub-networks acts as an early processing area, akin to the hippocampus, and functions to learn new input patterns. The other sub-network acts as a final-storage area, akin to the neocortex. However, unlike in the McClelland et al. (1995) model, the final-storage area sends internally generated representation back to the early processing area. This creates a recurrent network. French proposed that this interleaving of old representations with new representations is the only way to reduce radical forgetting. Since the brain would most likely not have access to the original input patterns, the patterns that would be fed back to the neocortex would be internally generated representations called ''pseudo-patterns''.  These pseudo-patterns are approximations of previous inputs&lt;ref name ="Robins1995"&gt;{{cite journal |last1=Robins |first1=Anthony |title=Catastrophic Forgetting, Rehearsal and Pseudorehearsal |journal=Connection Science |date=June 1995 |volume=7 |issue=2 |pages=123–146 |doi=10.1080/09540099550039318 }}&lt;/ref&gt; and they can be interleaved with the learning of new inputs.

====Self-refreshing memory====
Ans and Rousset (1997)&lt;ref&gt;{{cite journal |last1=Ans |first1=Bernard |last2=Rousset |first2=Stéphane |title=Avoiding catastrophic forgetting by coupling two reverberating neural networks |journal=Comptes Rendus de l'Académie des Sciences - Series III - Sciences de la Vie |date=December 1997 |volume=320 |issue=12 |pages=989–997 |doi=10.1016/S0764-4469(97)82472-9 |bibcode=1997CRASG.320..989A }}&lt;/ref&gt; also proposed a two-network artificial neural architecture with ''memory self-refreshing'' that overcomes catastrophic interference when sequential learning tasks are carried out in distributed networks trained by backpropagation. The principle is to interleave, at the time when new external patterns are learned, those to-be-learned new external patterns with internally generated pseudopatterns, or 'pseudo-memories', that reflect the previously learned information. What mainly distinguishes this model from those that use classical pseudorehearsal in feedforward multilayer networks is a ''reverberating'' process{{explain|date=September 2020}} that is used for generating pseudopatterns. After a number of activity re-injections from a single random seed, this process tends to go up to nonlinear network ''attractors''.

====Generative replay====
In recent years, pseudo-rehearsal has re-gained in popularity thanks to the progress in the capabilities of deep [[generative model]]s. When such deep generative models are used to generate the "pseudo-data" to be rehearsed, this method is typically referred to as generative replay.&lt;ref name="Mocanu2016"&gt;{{cite arXiv |last1=Mocanu |first1=Decebal Constantin |last2=Torres Vega |first2=Maria |last3=Eaton |first3=Eric |last4=Stone |first4=Peter | last5=Liotta |first5=Antonio | date= 18 October 2016 |title=Online Contrastive Divergence with Generative Replay: Experience Replay without Storing Data | eprint=1610.05555 | class=cs.LG |url=https://arxiv.org/abs/1610.05555 }}&lt;/ref&gt; Such generative replay can effectively prevent catastrophic forgetting, especially when the replay is performed in the hidden layers rather than at the input level.&lt;ref name="Shin2017"&gt;{{cite conference |last1=Shin |first1=Hanul |last2=Lee |first2=Jung Kwon |last3=Kim |first3=Jaehong |last4=Kim |first4=Jiwon |date=December 2017 |title=Continual learning with deep generative replay |conference=NIPS'17: Proceedings of the 31st International Conference on Neural Information Processing Systems |publisher=Curran Associates |isbn=978-1-5108-6096-4 |pages=2994–3003 |url=https://dl.acm.org/doi/abs/10.5555/3294996.3295059 }}&lt;/ref&gt;&lt;ref name="vandeVen2020"&gt;{{cite journal |last1=van de Ven |first1=Gido M. |last2=Siegelmann |first2=Hava T. |last3=Tolias |first3=Andreas S. |title=Brain-inspired replay for continual learning with artificial neural networks |journal=Nature Communications |date=13 August 2020 |volume=11 |issue=1 |pages=4069 |doi=10.1038/s41467-020-17866-2 |pmid=32792531 |pmc=7426273 |bibcode=2020NatCo..11.4069V }}&lt;/ref&gt;

===Latent learning===
Latent Learning is a technique used by Gutstein &amp; Stump (2015)&lt;ref&gt;{{cite book |doi=10.1109/IJCNN.2015.7280416 |chapter=Reduction of catastrophic forgetting with transfer learning and ternary output codes |title=2015 International Joint Conference on Neural Networks (IJCNN) |year=2015 |last1=Gutstein |first1=Steven |last2=Stump |first2=Ethan |pages=1–8 |isbn=978-1-4799-1960-4 |s2cid=18745466 }}&lt;/ref&gt; to mitigate catastrophic interference by taking advantage of [[transfer learning]]. This approach tries to find optimal encodings for any new classes to be learned, so that they are least likely to catastrophically interfere with existing responses. Given a network that has learned to discriminate among one set of classes using Error Correcting Output Codes (ECOC)&lt;ref&gt;{{cite journal |last1=Dietterich |first1=T. G. |last2=Bakiri |first2=G. |title=Solving Multiclass Learning Problems via Error-Correcting Output Codes |journal=Journal of Artificial Intelligence Research |date=1 January 1995 |volume=2 |pages=263–286 |doi=10.1613/jair.105 |s2cid=47109072 |doi-access=free }}&lt;/ref&gt; (as opposed to [[one-hot|1 hot codes]]), optimal encodings for new classes are chosen by observing the network's average responses to them. Since these average responses arose while learning the original set of classes ''without any exposure to the new classes'', they are referred to as 'Latently Learned Encodings'. This terminology borrows from the concept of [[Latent Learning]], as introduced by Tolman in 1930.&lt;ref&gt;{{cite journal |last1=Tolman |first1=E.C. |last2=Honzik |first2=C.H. |year=1930 |title='Insight' in Rats |publisher=University of California |journal=Publications in Psychology |volume=4 |pages=215–232 }}&lt;/ref&gt; In effect, this technique uses transfer learning to avoid catastrophic interference, by making a network's responses to new classes as consistent as possible with existing responses to classes already learned.

===Elastic weight consolidation===
Kirkpatrick et al. (2017)&lt;ref&gt;{{cite journal |last1=Kirkpatrick |first1=James |last2=Pascanu |first2=Razvan |last3=Rabinowitz |first3=Neil |last4=Veness |first4=Joel |last5=Desjardins |first5=Guillaume |last6=Rusu |first6=Andrei A. |last7=Milan |first7=Kieran |last8=Quan |first8=John |last9=Ramalho |first9=Tiago |last10=Grabska-Barwinska |first10=Agnieszka |last11=Hassabis |first11=Demis |last12=Clopath |first12=Claudia |last13=Kumaran |first13=Dharshan |last14=Hadsell |first14=Raia |title=Overcoming catastrophic forgetting in neural networks |journal=Proceedings of the National Academy of Sciences |date=14 March 2017 |volume=114 |issue=13 |pages=3521–3526 |doi=10.1073/pnas.1611835114 |pmid=28292907 |pmc=5380101 }}&lt;/ref&gt; proposed elastic weight consolidation (EWC), a method to sequentially train a single artificial neural network on multiple tasks. This technique supposes that some weights of the trained neural network are more important for previously learned tasks than others. During training of the neural network on a new task, changes to the weights of the network are made less likely the greater their importance. To estimate the importance of the network weights, EWC uses probabilistic mechanisms, in particular the Fisher information matrix, but this can be done in other ways as well.&lt;ref&gt;{{cite journal |last1=Zenke |first1=Friedemann |last2=Poole |first2=Ben |last3=Ganguli |first3=Surya |title=Continual Learning Through Synaptic Intelligence |journal=Proceedings of Machine Learning Research |date=2017 |volume=70 |pages=3987–3995 |pmid=31909397 |pmc=6944509 |arxiv=1703.04200 }}&lt;/ref&gt;&lt;ref&gt;{{cite book |doi=10.1007/978-3-030-01219-9_9 |chapter=Memory Aware Synapses: Learning What (Not) to Forget |title=Computer Vision – ECCV 2018 |series=Lecture Notes in Computer Science |year=2018 |last1=Aljundi |first1=Rahaf |last2=Babiloni |first2=Francesca |last3=Elhoseiny |first3=Mohamed |last4=Rohrbach |first4=Marcus |last5=Tuytelaars |first5=Tinne |volume=11207 |pages=144–161 |arxiv=1711.09601 |isbn=978-3-030-01218-2 |s2cid=4254748 }}&lt;/ref&gt;


==References==
{{reflist|30em}}

[[Category:Artificial neural networks]]
[[Category:Artificial intelligence]]
[[Category:Machine learning]]</text>
      <sha1>r1p71dk6ik3o6dbv4n6v427p771veia</sha1>
    </revision>
  </page>
  <page>
    <title>Developmental robotics</title>
    <ns>0</ns>
    <id>1422176</id>
    <revision>
      <id>1004378752</id>
      <parentid>984844137</parentid>
      <timestamp>2021-02-02T09:22:27Z</timestamp>
      <contributor>
        <username>Cmorganluce</username>
        <id>41130799</id>
      </contributor>
      <minor/>
      <comment>/* Academic institutions and researchers in the field */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="22025" xml:space="preserve">{{Use mdy dates|date=October 2014}}
'''Developmental robotics''' ('''DevRob'''), sometimes called '''[[epigenetics|epigenetic]] robotics''', is a scientific field which aims at studying the developmental mechanisms, architectures and constraints that allow lifelong and open-ended learning of new skills and new knowledge in embodied [[machine]]s. As in human children, [[learning]] is expected to be cumulative and of progressively increasing complexity, and to result from self-exploration of the world in combination with [[social relation|social interaction]]. The typical methodological approach consists in starting from theories of human and animal development elaborated in fields such as [[developmental psychology]], [[neuroscience]], [[developmental biology|developmental]] and [[evolutionary biology]], and [[linguistics]], then to formalize and implement them in robots, sometimes exploring extensions or variants of them. The experimentation of those models in robots allows researchers to confront them with reality, and as a consequence, developmental robotics also provides feedback and novel hypotheses on theories of human and animal development.

Developmental robotics is related to but differs from [[evolutionary robotics]] (ER).  ER uses populations of robots that evolve over time, whereas DevRob is interested in how the organization of a single robot's control system develops through experience, over time.

DevRob is also related to work done in the domains of [[robotics]] and [[artificial life]].

== Background ==

Can a robot learn like a child? Can it learn a variety of new skills and new knowledge unspecified at design time and in a partially unknown and changing environment? How can it discover its body and its relationships with the physical and social environment? How can its cognitive capacities continuously develop without the intervention of an engineer once it is "out of the factory"? What can it learn through natural social interactions with humans? These are the questions at the center of developmental robotics. Alan Turing, as well as a number of other pioneers of cybernetics, already formulated those questions and the general approach in 1950,&lt;ref name="Turing50"&gt;{{cite journal
| last = Turing | first = A.M. | date = 1950 | url = http://www.csee.umbc.edu/courses/471/papers/turing.pdf | title = Computing machinery and intelligence | journal = Mind | publisher = LIX | issue = 236 | pages = 433–460 | doi = 10.1093/mind/LIX.236.433 }}&lt;/ref&gt;
but it is only since the end of the 20th century that they began to be investigated systematically.&lt;ref name="Weng01"&gt;{{cite journal
| last1 = Weng | first1 = J. | last2 = McClelland | last3 = Pentland | first3 = A. | last4 = Sporns | first4 = O. | last5 = Stockman | first5 = I. | last6 = Sur | first6 = M. | first7 = E. | last7 = Thelen | date = 2001 | url = http://www.cse.msu.edu/dl/SciencePaper.pdf | title = Autonomous mental development by robots and animals | journal = Science | volume = 291 | issue = 5504 | pages = 599–600 | doi=10.1126/science.291.5504.599| pmid = 11229402 }}&lt;/ref&gt;&lt;ref name="Lungarella03"&gt;{{cite journal
| last1 = Lungarella | first1 = M. | last2 = Metta | first2 = G. | last3 = Pfeifer | first3 = R. | first4 = G. | last4 = Sandini | date = 2003 | title =  Developmental robotics: a survey | citeseerx = 10.1.1.83.7615 | journal = Connection Science | volume = 15 | issue = 4 | pages = 151–190 | doi=10.1080/09540090310001655110}}&lt;/ref&gt;&lt;ref name="Asada09"&gt;{{cite journal
| last1 = Asada | first1 = M. | last2 = Hosoda | first2 = K. | last3 = Kuniyoshi | first3 = Y. | last4 = Ishiguro | first4 = H. | last5 = Inui | first5 = T. | last6 = Yoshikawa | first6 = Y. | last7 = Ogino | first7 = M. | first8 = C. | last8 = Yoshida | date = 2009 | title = Cognitive developmental robotics: a survey | journal = IEEE Transactions on Autonomous Mental Development | volume = 1 | issue = 1 | pages = 12–34 | doi=10.1109/tamd.2009.2021702}}&lt;/ref&gt;&lt;ref name="Oudeyer10"&gt;{{cite journal
| authorlink1 = Pierre-Yves Oudeyer | last1 = Oudeyer | first1 = P-Y. | date = 2010 | url = http://www.pyoudeyer.com/IEEETAMDOudeyer10.pdf | title = On the impact of robotics in behavioral and cognitive sciences: from insect navigation to human cognitive development | journal = IEEE Transactions on Autonomous Mental Development | volume = 2 | issue = 1 | pages = 2–16 | doi=10.1109/tamd.2009.2039057}}&lt;/ref&gt;

Because the concept of adaptive intelligent machines is central to developmental robotics, it has relationships with fields such as artificial intelligence, machine learning, [[cognitive robotics]] or [[computational neuroscience]]. Yet, while it may reuse some of the techniques elaborated in these fields, it differs from them from many perspectives. It differs from classical artificial intelligence because it does not assume the capability of advanced symbolic reasoning and focuses on embodied and situated sensorimotor and social skills rather than on abstract symbolic problems. It differs from traditional machine learning because it targets task-independent self-determined learning rather than task-specific inference over "spoon-fed human-edited sensory data" (Weng et al., 2001). It differs from cognitive robotics because it focuses on the processes that allow the formation of cognitive capabilities rather than these capabilities themselves. It differs from computational neuroscience because it focuses on functional modeling of integrated architectures of development and learning. More generally, developmental robotics is uniquely characterized by the following three features:
# It targets task-independent architectures and learning mechanisms, i.e. the machine/robot has to be able to learn new tasks that are unknown by the engineer;
# It emphasizes open-ended development and lifelong learning, i.e. the capacity of an organism to acquire continuously novel skills. This should not be understood as a capacity for learning "anything" or even “everything”, but just that the set of skills that is acquired can be infinitely extended at least in some (not all) directions;
# The complexity of acquired knowledge and skills shall increase (and the increase be controlled) progressively.

Developmental robotics emerged at the crossroads of several research communities including embodied artificial intelligence, enactive and dynamical systems cognitive science, connectionism. Starting from the essential idea that learning and development happen as the self-organized result of the dynamical interactions among brains, bodies and their physical and social environment, and trying to understand how this self-organization can be harnessed to provide task-independent lifelong learning of skills of increasing complexity, developmental robotics strongly interacts with fields such as developmental psychology, developmental and cognitive neuroscience, developmental biology (embryology), evolutionary biology, and cognitive linguistics. As many of the theories coming from these sciences are verbal and/or descriptive, this implies a crucial formalization and computational modeling activity in developmental robotics. These computational models are then not only used as ways to explore how to build more versatile and adaptive machines but also as a way to evaluate their coherence and possibly explore alternative explanations for understanding biological development.&lt;ref name="Oudeyer10" /&gt;

== Research directions ==

=== Skill domains ===
Due to the general approach and methodology, developmental robotics projects typically focus on having robots develop the same types of skills as human infants. A first category that is important being investigated is the acquisition of sensorimotor skills. These include the discovery of one's own body, including its structure and dynamics such as hand-eye coordination, locomotion, and interaction with objects as well as tool use, with a particular focus on the discovery and learning of affordances. A second category of skills targeted by developmental robots are social and linguistic skills: the acquisition of simple social behavioural games such as turn-taking, coordinated interaction, lexicons, syntax and grammar, and the grounding of these linguistic skills into sensorimotor skills (sometimes referred as symbol grounding). In parallel, the acquisition of associated cognitive skills are being investigated such as the emergence of the self/non-self distinction, the development of attentional capabilities, of categorization systems and higher-level representations of affordances or social constructs, of the emergence of values, empathy, or theories of mind.

=== Mechanisms and constraints ===
The sensorimotor and social spaces in which humans and robot live are so large and complex that only a small part of potentially learnable skills can actually be explored and learnt within a life-time. Thus, mechanisms and constraints are necessary to guide developmental organisms in their development and control of the growth of complexity. There are several important families of these guiding mechanisms and constraints which are studied in developmental robotics, all inspired by human development:
# Motivational systems, generating internal reward signals that drive exploration and learning, which can be of two main types:
#* extrinsic motivations push robots/organisms to maintain basic specific internal properties such as food and water level, physical integrity, or light (e.g. in phototropic systems);
#* [[intrinsic motivation (artificial intelligence) | intrinsic motivations]] push robot to search for novelty, challenge, compression or learning progress per se, thus generating what is sometimes called curiosity-driven learning and exploration, or alternatively active learning and exploration;
#Social guidance: as humans learn a lot by interacting with their peers, developmental robotics investigates mechanisms that can allow robots to participate to human-like social interaction. By perceiving and interpreting social cues, this may allow robots both to learn from humans (through diverse means such as imitation, emulation, stimulus enhancement, demonstration, etc. ...) and to trigger natural human pedagogy. Thus, social acceptance of developmental robots is also investigated;
# Statistical inference biases and cumulative knowledge/skill reuse: biases characterizing both representations/encodings and inference mechanisms can typically allow considerable improvement of the efficiency of learning and are thus studied. Related to this, mechanisms allowing to infer new knowledge and acquire new skills by reusing previously learnt structures is also an essential field of study;
#The properties of embodiment, including geometry, materials, or innate motor primitives/synergies often encoded as dynamical systems, can considerably simplify the acquisition of sensorimotor or social skills, and is sometimes referred as morphological computation. The interaction of these constraints with other constraints is an important axis of investigation;
#Maturational constraints: In human infants, both the body and the neural system grow progressively, rather than being full-fledged already at birth. This implies, for example, that new degrees of freedom, as well as increases of the volume and resolution of available sensorimotor signals, may appear as learning and development unfold. Transposing these mechanisms in developmental robots, and understanding how it may hinder or on the contrary ease the acquisition of novel complex skills is a central question in developmental robotics.

=== From bio-mimetic development to functional inspiration. ===
While most developmental robotics projects interact closely with theories of animal and human development, the degrees of similarities and inspiration between identified biological mechanisms and their counterpart in robots, as well as the abstraction levels of modeling, may vary a lot. While some projects aim at modeling precisely both the function and biological implementation (neural or morphological models), such as in [[Neurorobotics]], some other projects only focus on functional modeling of the mechanisms and constraints described above, and might for example reuse in their architectures techniques coming from applied mathematics or engineering fields.

== Open questions ==

As developmental robotics is a relatively new research field and at the same time very ambitious, many fundamental open challenges remain to be solved.

First of all, existing techniques are far from allowing real-world high-dimensional robots to learn an open-ended repertoire of increasingly complex skills over a life-time period. High-dimensional continuous sensorimotor spaces constitute a significant obstacle to be solved. Lifelong [[cumulative learning]] is another one. Actually, no experiments lasting more than a few days have been set up so far, which contrasts severely with the time needed by human infants to learn basic sensorimotor skills while equipped with brains and morphologies which are tremendously more powerful than existing computational mechanisms.

Among the strategies to explore to progress towards this target, the interaction between the mechanisms and constraints described in the previous section shall be investigated more systematically. Indeed, they have so far mainly been studied in isolation. For example, the interaction of intrinsically motivated learning and socially guided learning, possibly constrained by maturation, is an essential issue to be investigated.

Another important challenge is to allow robots to perceive, interpret and leverage the diversity of [[Multimodal_interaction|multimodal]] social cues provided by non-engineer humans during human-robot interaction. These capacities are so far, mostly too limited to allow efficient general-purpose teaching from humans.

A fundamental scientific issue to be understood and resolved, which applied equally to human development, is how compositionality, functional hierarchies, primitives, and modularity, at all levels of sensorimotor and social structures, can be formed and leveraged during development. This is deeply linked with the problem of the emergence of symbols, sometimes referred to as the "[[symbol grounding problem]]" when it comes to language acquisition. Actually, the very existence and need for symbols in the brain are actively questioned, and alternative concepts, still allowing for compositionality and functional hierarchies are being investigated.

During biological epigenesis, morphology is not fixed but rather develops in constant interaction with the development of sensorimotor and social skills. The development of morphology poses obvious practical problems with robots, but it may be a crucial mechanism that should be further explored, at least in simulation, such as in morphogenetic robotics.

Another open problem is the understanding of the relation between the key phenomena investigated by developmental robotics (e.g., hierarchical and modular sensorimotor systems, intrinsic/extrinsic/social motivations, and open-ended learning) and the underlying brain mechanisms.

Similarly, in biology, developmental mechanisms (operating at the ontogenetic time scale) interact closely with evolutionary mechanisms (operating at the phylogenetic time scale) as shown in the flourishing "[[evo-devo]]" scientific literature.&lt;ref name="Muller07"&gt;{{cite journal
| last1 = Müller | first1 = G. B. | date = 2007 | title = Evo-devo: extending the evolutionary synthesis | journal = Nature Reviews Genetics | volume = 8 | issue = 12 | pages = 943–949 | doi=10.1038/nrg2219 | pmid=17984972}}&lt;/ref&gt;
However, the interaction of those mechanisms in artificial organisms, developmental robots, in particular, is still vastly understudied. The interaction of evolutionary mechanisms, unfolding morphologies and developing sensorimotor and social skills will thus be a highly stimulating topic for the future of developmental robotics.

==Main journals==
* IEEE Transactions on Cognitive and Developmental Systems (previously known as IEEE Transactions on Autonomous Mental Development): https://cis.ieee.org/publications/t-cognitive-and-developmental-systems

==Main conferences==
* International Conference on Development and Learning: http://www.cogsci.ucsd.edu/~triesch/icdl/
* Epigenetic Robotics: https://www.lucs.lu.se/epirob/
* ICDL-EpiRob: http://www.icdl-epirob.org/ (the two above joined since 2011)
* Developmental Robotics: http://cs.brynmawr.edu/DevRob05/
The NSF/DARPA funded [http://www.cse.msu.edu/dl/ Workshop on Development and Learning] was held April 5–7, 2000 at Michigan State University. It was the first international meeting devoted to computational understanding of mental development by robots and animals. The term "by" was used since the agents are active during development.

==See also==
* [[Evolutionary developmental robotics]]
* [[Robot learning]]

== References ==
{{reflist}}

==External links==

=== Technical committees ===
*IEEE Technical Committee on Cognitive and Developmental Systems (CDSTC), previously known as IEEE Technical Committee on Autonomous Mental Development, https://cis.ieee.org/technical-committees/cognitive-and-developmental-systems-technical-committee
*IEEE Technical Committee on Cognitive Robotics, https://www.ieee-ras.org/cognitive-robotics
*IEEE Technical Committee on Robot Learning, https://www.ieee-ras.org/robot-learning/

=== Academic institutions and researchers in the field ===
*[https://www.lucs.lu.se/lucs-robotics-group/ Lund University Cognitive Science - Robotics Group]
* [http://www.iub.edu/~cogdev/ Cognitive Development Lab, University of Indiana, US]
* [[Michigan State University]] – [http://www.cse.msu.edu/ei Embodied Intelligence Lab]
* [http://flowers.inria.Fr Inria and Ensta ParisTech FLOWERS team, France]: Exploration, interaction and learning in developmental robotics
* [http://www.isi.imi.i.u-tokyo.ac.jp/ University of Tokyo—Intelligent Systems and Informatics Lab]
* [http://www.idsia.ch/~juergen/cogbotlab.html Cognitive Robotics Lab] of [[Juergen Schmidhuber]] at [[IDSIA]] and [[Technical University of Munich]]
* [https://web.archive.org/web/20190420191303/http://www.liralab.it/ LIRA-Lab], University of Genova, Italy
* [https://www.cit-ec.de/ CITEC at University of Bielefeld, Germany]
* [http://matthew.siu.edu/ Vision Lab], Psychology Department, Southern Illinois University Carbondale
* [http://fias.uni-frankfurt.de/~triesch/ FIAS (J. Triesch lab.)]
* [http://nivea.psycho.univ-paris5.fr/ LPP, CNRS (K. Oregan lab.)]
* AI Lab, SoftBank Robotics Europe, France
* [http://homepages.abdn.ac.uk/f.guerin/pages/ Departement of Computer Science, University of Aberdeen]
* [https://web.archive.org/web/20130601122743/http://www.er.ams.eng.osaka-u.ac.jp/asadalab/index_en.html Asada Laboratory], Department of Adaptive Machine Systems, Graduate School of Engineering, Osaka University, Japan
* The University of Texas at Austin, [http://www.cs.utexas.edu/users/qr/robotics/bootstrap-learning.html UTCS Intelligent Robotics Lab]
* [[Bryn Mawr College]]'s [http://cs.brynmawr.edu/devrob/ Developmental Robotics Project]: research projects by faculty and students at Swarthmore and Bryn Mawr Colleges, Philadelphia, PA, USA
* [https://web.archive.org/web/20070222045437/http://eksl.isi.edu/cgi-bin/page.cgi?page=project-jean.html Jean Project]: Information Sciences Institute of the University of Southern California
* [http://www.nrl.navy.mil/aic/iss/aas/CognitiveRobots.php Cognitive Robotics (including Hide and Seek) at the Naval Research Laboratory]
* [http://www-robotics.cs.umass.edu/index.php The Laboratory for Perceptual Robotics], [[University of Massachusetts Amherst]] Amherst, USA
* [https://web.archive.org/web/20170714151253/http://www.tech.plym.ac.uk/SoCCE/CRNS/ Centre for Robotics and Neural Systems], [http://www.plymouth.ac.uk/ Plymouth University] Plymouth, United Kingdom
* [http://www.istc.cnr.it/group/locen Laboratory of Computational Embodied Neuroscience], [http://www.istc.cnr.it/ Institute of Cognitive Science and Technologies] [https://web.archive.org/web/20140209072327/http://www.cnr.it/sitocnr/home.html National Research Council], Rome, Italy
* [https://web.archive.org/web/20141006074808/http://www-etis.ensea.fr/index.php/neuro-neurocybernetics.html Neurocybernetic team], ETIS Lab., ENSEA – University of Cergy-Pontoise – CNRS, France
* [http://mpcrlab.com Machine Perception and Cognitive Robotics Lab], Florida Atlantic University,  Boca Raton, Florida
* [http://adapt.informatik.hu-berlin.de/ Adaptive Systems Group], Department of Computer Science, Humboldt University of Berlin, Germany
* [http://developmental-robotics.jp/en/ Cognitive Developmental Robotics Lab (Nagai Lab)], The University of Tokyo, Japan

=== Related large-scale projects ===
* [http://www.robotdoc.org RobotDoC Project] (funded by European Commission)
* [http://www.italkproject.org/ Italk Project] (funded by European Commission)
* [https://web.archive.org/web/20130728113632/http://www.im-clever.eu/ IM-CLeVeR Project] (funded by European Commission)
* [http://flowers.inria.Fr ERC Grant EXPLORERS Project] (funded by European Research Council)
* [http://www.robotcub.org/ RobotCub Project] (funded by European Commission)
* [[Feelix Growing Project]] (funded by European Commission)

=== Courses ===
The first undergraduate [https://web.archive.org/web/20061013103459/http://dangermouse.brynmawr.edu/cs380/ courses] in DevRob were offered at [[Bryn Mawr College]] and [[Swarthmore College]] in the Spring of 2003 by Douglas Blank and Lisa Meeden, respectively.
The [https://web.archive.org/web/20061012010522/http://www.cs.iastate.edu/~alex/classes/2005_Fall_610as/ first graduate course] in DevRob was offered at [[Iowa State University]] by Alexander Stoytchev in the Fall of 2005.

{{Robotics}}

[[Category:Robotics]]
[[Category:Robot control|Learning]]
[[Category:Machine learning]]</text>
      <sha1>6wqjtjbyo1at3vse2o2wpgqcciqcfns</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Structured prediction</title>
    <ns>14</ns>
    <id>40149461</id>
    <revision>
      <id>567084110</id>
      <timestamp>2013-08-04T07:33:48Z</timestamp>
      <contributor>
        <username>Qwertyus</username>
        <id>196471</id>
      </contributor>
      <comment>[[WP:AES|←]]Created page with '{{cat main|Structured prediction}} [[Category:Machine learning]]'</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="64" xml:space="preserve">{{cat main|Structured prediction}}
[[Category:Machine learning]]</text>
      <sha1>gqjsv6psdxhbe20duug11vfb17hxj5d</sha1>
    </revision>
  </page>
  <page>
    <title>Confusion matrix</title>
    <ns>0</ns>
    <id>847558</id>
    <revision>
      <id>999451492</id>
      <parentid>999451259</parentid>
      <timestamp>2021-01-10T06:57:38Z</timestamp>
      <contributor>
        <username>Mikhail Ryazanov</username>
        <id>13263935</id>
      </contributor>
      <minor/>
      <comment>/* Table of confusion */ [[MOS:CAPS]], fmt.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="6250" xml:space="preserve">{{short description|Table layout for visualizing performance; also called an error matrix}}
{{Confusion matrix terms|recall=}}
In the field of [[machine learning]] and specifically the problem of [[statistical classification]], a '''confusion matrix''', also known as an error matrix,&lt;ref&gt;{{cite journal |last1=Stehman |first1= Stephen V. |year= 1997|title=Selecting and interpreting measures of thematic classification accuracy |journal=Remote Sensing of Environment |volume=62 |issue=1 |pages=77–89 |doi=10.1016/S0034-4257(97)00083-7 |bibcode= 1997RSEnv..62...77S }}&lt;/ref&gt; is a specific table layout that allows visualization of the performance of an algorithm, typically a [[supervised learning]] one (in [[unsupervised learning]] it is usually called a '''matching matrix'''). Each row of the [[matrix (mathematics)|matrix]] represents the instances in a predicted class, while each column represents the instances in an actual class (or vice versa).&lt;ref name="Powers2011"&gt;{{cite journal |first=David M. W. |last=Powers |date=2011 |title=Evaluation: From Precision, Recall and F-Measure to ROC, Informedness, Markedness &amp; Correlation |journal=Journal of Machine Learning Technologies |volume=2 |issue=1 |pages=37–63 |url=https://www.researchgate.net/publication/228529307 |s2cid=55767944 }}&lt;/ref&gt; The name stems from the fact that it makes it easy to see whether the system is confusing two classes (i.e. commonly mislabeling one as another).

It is a special kind of [[contingency table]], with two dimensions ("actual" and "predicted"), and identical sets of "classes" in both dimensions (each combination of dimension and class is a variable in the contingency table).

__TOC__

==Example==
Given a sample of 13 pictures, 8 of cats and 5 of dogs, where cats belong to class 1 and dogs belong to class 0, 

:actual = [1,1,1,1,1,1,1,1,0,0,0,0,0],

assume that a classifier that distinguishes between cats and dogs is trained, and we take the 13 pictures and run them through the classifier, and the classifier makes 8 accurate predictions and misses 5: 3 cats wrongly predicted as dogs (first 3 predictions) and 2 dogs wrongly predicted as cats (last 2 predictions).

:prediction = [0,0,0,1,1,1,1,1,0,0,0,1,1]

With these two labelled sets (actual and predictions) we can create a confusion matrix that will summarize the results of testing the classifier:
{|
|-
|
{| class="wikitable" style="border:none; float:left; margin-top:0; text-align:center;"
!style="background:white; border:none;" colspan="2" rowspan="2"|
!colspan="2" style="background:none;"| Actual class
|-
!Cat
!Dog
|-
!rowspan="2" style="height:6em;background:none;"|&lt;div&gt;Predicted&lt;br&gt;class&lt;/div&gt;
!Cat
|'''5'''
|2
|-
!Dog
|3
|'''3'''
|-
|}
|
|}
In this confusion matrix, of the 8 cat pictures, the system judged that 3 were dogs, and of the 5 dog pictures, it predicted that 2 were cats. All correct predictions are located in the diagonal of the table (highlighted in bold), so it is easy to visually inspect the table for prediction errors, as they will be represented by values outside the diagonal.

In abstract terms, the confusion matrix is as follows:
{|
|-
|
{| class="wikitable" style="border:none; float:left; margin-top:0; text-align:center"
!style="background:white; border:none;" colspan="2" rowspan="2"|
!colspan="2" style="background:none;"| Actual class
|-
!P
!N
|-
!rowspan="2" style="height:6em;background:none;"|&lt;div&gt;Predicted&lt;br&gt;class&lt;/div&gt;
!P
|'''TP'''
|FP
|-
!N
|FN
|'''TN'''
|-
|}
|
|}
where: P = Positive; N = Negative; TP = True Positive; FP = False Positive; TN = True Negative; FN = False Negative.

==Table of confusion==
In [[predictive analytics]], a '''table of confusion''' (sometimes also called a '''confusion matrix''') is a table with two rows and two columns that reports the number of ''false positives'', ''false negatives'', ''true positives'', and ''true negatives''. This allows more detailed analysis than mere proportion of correct classifications (accuracy). Accuracy will yield misleading results if the data set is unbalanced; that is, when the numbers of observations in different classes vary greatly. For example, if there were 95 cats and only 5 dogs in the data, a particular classifier might classify all the observations as cats. The overall accuracy would be 95%, but in more detail the classifier would have a 100% recognition rate ([[sensitivity (test)|sensitivity]]) for the cat class but a 0% recognition rate for the dog class. [[F1 score]] is even more unreliable in such cases, and here would yield over 97.4%, whereas [[informedness]] removes such bias and yields 0 as the probability of an informed decision for any form of guessing (here always guessing cat).

According to Davide Chicco and Giuseppe Jurman, the most informative metric to evaluate a confusion matrix is the [[Matthews correlation coefficient|Matthews correlation coefficient (MCC)]].&lt;ref&gt;{{cite journal |authors = Chicco D., Jurman G. |title = The advantages of the Matthews correlation coefficient (MCC) over F1 score and accuracy in binary classification evaluation |journal = BMC Genomics |volume = 21 |issue = 1 |date = January 2020 |page = 6-1–6-13 |pmid = 31898477 |doi = 10.1186/s12864-019-6413-7 |pmc = 6941312}}&lt;/ref&gt;

Assuming the confusion matrix above, its corresponding table of confusion, for the cat class, would be:

{| class="wikitable" style="border:none; margin-top:0;"
!style="background:white; border:none;" colspan="2" rowspan="2"|
!colspan="3" style="background:none;"| Actual class
|-
! Cat
! Non-cat
|-
!rowspan="3" style="height:6em;background:none;"| &lt;div style="{{rotate|-90}}"&gt;Predicted&lt;br&gt;class&lt;/div&gt;
! Cat
| '''5 true positives'''
| 2 false positives
|-
! Non-cat
| 3 false negatives
| '''3 true negatives'''
|-
|}

The final table of confusion would contain the average values for all classes combined.

Let us define an experiment from '''P''' positive instances and '''N''' negative instances for some condition. The four outcomes can be formulated in a 2×2 ''confusion matrix'', as follows:
{{DiagnosticTesting Diagram}}

== See also ==

* [[Positive and negative predictive values]]

==References==
{{Reflist}}


{{Matrix classes}}

[[Category:Machine learning]]
[[Category:Statistical classification]]</text>
      <sha1>prorzo8pr5s5vhjjhjw3cvwkvybtv12</sha1>
    </revision>
  </page>
  <page>
    <title>Active learning (machine learning)</title>
    <ns>0</ns>
    <id>28801798</id>
    <revision>
      <id>1002975767</id>
      <parentid>1000052592</parentid>
      <timestamp>2021-01-26T22:13:24Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 13 templates: hyphenate params (1×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="12281" xml:space="preserve">{{about|a machine learning method|active learning in the context of education|active learning}}
{{Machine learning bar}}
'''Active learning''' is a special case of [[machine learning]] in which a learning algorithm can interactively query a user (or some other information source) to label new data points with the desired outputs.&lt;ref name="settles"&gt;{{cite document
 | title = Active Learning Literature Survey
 | url = http://pages.cs.wisc.edu/~bsettles/pub/settles.activelearning.pdf
 | author = Settles, Burr
 | series= Computer Sciences Technical Report 1648
 | publisher= University of Wisconsin–Madison
 | year = 2010
 | access-date = 2014-11-18
}}&lt;/ref&gt;&lt;ref name="rubens2016"&gt;{{cite book
 |last1=Rubens |first1=Neil
 |last2=Elahi |first2=Mehdi
 |last3=Sugiyama |first3=Masashi |last4=Kaplan |first4=Dain |editor1-last=Ricci
 |editor1-first=Francesco
 |editor2-last=Rokach |editor2-first=Lior
 |editor3-last=Shapira |editor3-first=Bracha
 |title=Recommender Systems Handbook
 |date=2016
 |publisher=Springer US
 |isbn=978-1-4899-7637-6
 |edition=2
 |chapter=Active Learning in Recommender Systems
 |doi=10.1007/978-1-4899-7637-6
|hdl=11311/1006123
|s2cid=11569603
 }}&lt;/ref&gt;&lt;ref name="das2016"&gt;{{cite book
 |last1=Das |first1=Shubhomoy
 |last2= Wong |first2=Weng-Keen
 |last3=Dietterich |first3=Thomas
 |last4=Fern |first4=Alan
 |last5=Emmott |first5=Andrew
 |editor1-last=Bonchi |editor1-first=Francesco
 |editor2-last=Domingo-Ferrer |editor2-first=Josep
 |editor3-last=Baeza-Yates |editor3-first=Ricardo
 |editor4-last=Zhou |editor4-first=Zhi-Hua
 |editor5-last=Wu |editor5-first=Xindong
 |chapter=Incorporating Expert Feedback into Active Anomaly Discovery
 |title=IEEE 16th International Conference on Data Mining
 |pages=853–858
|date=2016
 |publisher=IEEE
 |doi=10.1109/ICDM.2016.0102
|isbn=978-1-5090-5473-2
|s2cid=15285595
 }}&lt;/ref&gt; In statistics literature, it is sometimes also called [[optimal experimental design]].&lt;ref name="olsson"&gt;{{cite document | url=http://eprints.sics.se/3600/ | title=A literature survey of active machine learning in the context of natural language processing |series=SICS Technical Report T2009:06 | author=Olsson, Fredrik| date=April 2009 }}&lt;/ref&gt; The information source is also called ''teacher'' or ''oracle''.

There are situations in which unlabeled data is abundant but manual labeling is expensive. In such a scenario, learning algorithms can actively query the user/teacher for labels. This type of iterative supervised learning is called active learning. Since the learner chooses the examples, the number of examples to learn a concept can often be much lower than the number required in normal supervised learning. With this approach, there is a risk that the algorithm is overwhelmed by uninformative examples.  Recent developments are dedicated to multi-label active learning,&lt;ref name="multi"/&gt; hybrid active learning&lt;ref name="hybrid"/&gt; and active learning in a single-pass (on-line) context,&lt;ref name="single-pass"/&gt; combining concepts from the field of machine learning (e.g. conflict and ignorance) with adaptive, [[incremental learning]] policies in the field of [[online machine learning]].

==Definitions==
Let {{mvar|T}} be the total set of all data under consideration. For example, in a protein engineering problem, {{mvar|T}} would include all proteins that are known to have a certain interesting activity and all additional proteins that one might want to test for that activity.

During each iteration, {{mvar|i}}, {{mvar|T}} is broken up into three subsets
#&lt;math&gt;\mathbf{T}_{K,i}&lt;/math&gt;: Data points where the label is '''known'''.
#&lt;math&gt;\mathbf{T}_{U,i}&lt;/math&gt;: Data points where the label is '''unknown'''.
#&lt;math&gt;\mathbf{T}_{C,i}&lt;/math&gt;: A subset of {{mvar|T{{sub|U,i}}}} that is '''chosen''' to be labeled.

Most of the current research in active learning involves the best method to choose the data points for {{mvar|T{{sub|C,i}}}}.

== Scenarios ==

*'''Membership Query Synthesis''': This is where the learner generates its own instance from an underlying natural distribution. For example, if the dataset are pictures of humans and animals, the learner could send a clipped image of a leg to the teacher and query if this appendage belongs to an animal or human. This is particularly useful if the dataset is small.&lt;ref&gt;{{Cite journal|last1=Wang|first1=Liantao|last2=Hu|first2=Xuelei|last3=Yuan|first3=Bo|last4=Lu|first4=Jianfeng|date=2015-01-05|title=Active learning via query synthesis and nearest neighbour search|url=http://espace.library.uq.edu.au/view/UQ:344582/UQ344582_OA.pdf|journal=Neurocomputing|volume=147|pages=426–434|doi=10.1016/j.neucom.2014.06.042}}&lt;/ref&gt;
*'''Pool-Based Sampling''': In this scenario, instances are drawn from the entire data pool and assigned an informative score, a measurement of how well the learner “understands” the data. The system then selects the most informative instances and queries the teacher for the labels.
*'''Stream-Based Selective Sampling''': Here, each unlabeled data point is examined one at a time with the machine evaluating the informativeness of each item against its query parameters. The learner decides for itself whether to assign a label or query the teacher for each datapoint.

==Query strategies==
Algorithms for determining which data points should be labeled can be organized into a number of different categories, based upon their purpose:&lt;ref name="settles" /&gt;

*'''Balance exploration and exploitation''': the choice of examples to label is seen as a dilemma between the exploration and the exploitation over the data space representation. This strategy manages this compromise by modelling the active learning problem as a contextual bandit problem. For example, Bouneffouf et al.&lt;ref name="Bouneffouf(2014)" /&gt; propose a sequential algorithm named Active Thompson Sampling (ATS), which, in each round, assigns a sampling distribution on the pool, samples one point from this distribution, and queries the oracle for this sample point label.
*'''Expected model change''': label those points that would most change the current model.
*'''Expected error reduction''': label those points that would most reduce the model's [[generalization error]].
*'''Exponentiated Gradient Exploration for Active Learning''':&lt;ref name="Bouneffouf(2016)" /&gt; In this paper, the author proposes a sequential algorithm named exponentiated gradient (EG)-active that can improve any active learning algorithm by an optimal random exploration.
*'''Uncertainty sampling''': label those points for which the current model is least certain as to what the correct output should be.
*'''Query by committee''': a variety of models are trained on the current labeled data, and vote on the output for unlabeled data; label those points for which the "committee" disagrees the most
*'''Querying from diverse subspaces or partitions''':&lt;ref name="shubhomoydas_github"/&gt; When the underlying model is a forest of trees, the leaf nodes might represent (overlapping) partitions of the original [[feature (machine learning)|feature space]]. This offers the possibility of selecting instances from non-overlapping or minimally overlapping partitions for labeling.
*'''Variance reduction''': label those points that would minimize output variance, which is one of the components of error.
*'''Conformal Predictors''': This method predicts that a new data point will have a label similar to old data points in some specified way and degree of the similarity within the old examples is used to estimate the confidence in the prediction.&lt;ref&gt;{{Cite journal|last1=Makili|first1=Lázaro Emílio|last2=Sánchez|first2=Jesús A. Vega|last3=Dormido-Canto|first3=Sebastián|date=2012-10-01|title=Active Learning Using Conformal Predictors: Application to Image Classification|journal=Fusion Science and Technology|volume=62|issue=2|pages=347–355|doi=10.13182/FST12-A14626|s2cid=115384000|issn=1536-1055}}&lt;/ref&gt;
*'''Mismatch-first farthest-traversal''': The primary selection criteria is the prediction mismatch between the current model and nearest-neighbour prediction. It targets on wrongly predicted data points. The second selection criteria is the distance to previously selected data, the farthest first. It aims at optimizing the diversity of selected data.&lt;ref name='zhaos' /&gt;

A wide variety of algorithms have been studied that fall into these categories.&lt;ref name="settles" /&gt;&lt;ref name="olsson" /&gt;

==Minimum Marginal Hyperplane==
Some active learning algorithms are built upon [[support-vector machine]]s (SVMs) and exploit the structure of the SVM to determine which data points to label. Such methods usually calculate the [[margin (machine learning)|margin]], {{mvar|W}}, of each unlabeled datum in {{mvar|T{{sub|U,i}}}} and treat {{mvar|W}} as an {{mvar|n}}-dimensional distance from that datum to the separating hyperplane.

Minimum Marginal Hyperplane methods assume that the data with the smallest {{mvar|W}} are those that the SVM is most uncertain about and therefore should be placed in {{mvar|T{{sub|C,i}}}} to be labeled. Other similar methods, such as Maximum Marginal Hyperplane, choose data with the largest {{mvar|W}}. Tradeoff methods choose a mix of the smallest and largest {{mvar|W}}s.

==See also==
* [[List of datasets for machine learning research]]

==Notes==
{{reflist |refs=
&lt;ref name="hybrid"&gt;{{cite journal |last1=Lughofer |first1=Edwin |title=Hybrid active learning for reducing the annotation effort of operators in classification systems |journal=Pattern Recognition |date=February 2012 |volume=45 |issue=2 |pages=884–896 |doi=10.1016/j.patcog.2011.08.009}}&lt;/ref&gt;
&lt;ref name="Bouneffouf(2014)"&gt;{{cite book |first1=Djallel |last1=Bouneffouf |first2=Romain |last2=Laroche |first3=Tanguy |last3=Urvoy |first4=Raphael |last4=Féraud |first5=Robin |last5=Allesiardo |year=2014 |chapter-url=https://hal.archives-ouvertes.fr/hal-01069802 |chapter=Contextual Bandit for Active Learning: Active Thompson |doi=10.1007/978-3-319-12637-1_51 |isbn=978-3-319-12636-4 |id=HAL Id: hal-01069802 |editor=Loo, C. K. |editor2=Yap, K. S. |editor3=Wong, K. W. |editor4=Teoh, A. |editor5=Huang, K. |title=Neural Information Processing |volume=8834 |pages=405–412 |series=Lecture Notes in Computer Science |url=https://hal.archives-ouvertes.fr/hal-01069802/file/Contextual_Bandit_for_Active_Learning.pdf }}&lt;/ref&gt;
&lt;ref name="multi"&gt;{{cite book |doi=10.1145/1557019.1557119 |isbn=978-1-60558-495-9 |chapter-url=https://www.microsoft.com/en-us/research/wp-content/uploads/2009/01/sigkdd09-yang.pdf|chapter=Effective multi-label active learning for text classification |title=Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '09 |pages=917 |year=2009 |last1=Yang |first1=Bishan |last2=Sun |first2=Jian-Tao |last3=Wang |first3=Tengjiao |last4=Chen |first4=Zheng |citeseerx=10.1.1.546.9358 |s2cid=1979173 }}&lt;/ref&gt;
&lt;ref name="single-pass"&gt;{{Cite journal | doi=10.1007/s12530-012-9060-7 |title = Single-pass active learning with conflict and ignorance| journal=Evolving Systems| volume=3| issue=4| pages=251–271|year = 2012|last1 = Lughofer|first1 = Edwin|s2cid = 43844282}}&lt;/ref&gt;
&lt;ref name="Bouneffouf(2016)"&gt;{{cite journal |last1=Bouneffouf |first1=Djallel |title=Exponentiated Gradient Exploration for Active Learning |journal=Computers |date=8 January 2016 |volume=5 |issue=1 |pages=1 |doi=10.3390/computers5010001|arxiv=1408.2196 |s2cid=14313852 }}&lt;/ref&gt;
&lt;ref name="shubhomoydas_github"&gt;{{Cite web|url=https://github.com/shubhomoydas/ad_examples#query-diversity-with-compact-descriptions|title=shubhomoydas/ad_examples|website=GitHub|language=en|access-date=2018-12-04}}&lt;/ref&gt;
&lt;ref name="zhaos"&gt;{{Cite arxiv|eprint=2002.05033|title=Active learning for sound event detection|language=en|last1=Zhao|first1=Shuyang|last2=Heittola|first2=Toni|last3=Virtanen|first3=Tuomas|year=2020|class=eess.AS}}&lt;/ref&gt;
}}

==Other references==
* [http://hunch.net/~active_learning/ Active Learning Tutorial], S. Dasgupta and J. Langford.
* [https://www.lighttag.io/blog/active-learning-manager/ ALMA] (Software) Open source tool for implementing online active learning 
* [https://github.com/modAL-python/modAL modAL] (Software) Spen source Modular Active Learning toolkit

[[Category:Machine learning]]</text>
      <sha1>rxz98vacm5i4vyfar7hel551px36sp8</sha1>
    </revision>
  </page>
  <page>
    <title>Grammar induction</title>
    <ns>0</ns>
    <id>4375576</id>
    <revision>
      <id>955741291</id>
      <parentid>951194298</parentid>
      <timestamp>2020-05-09T14:53:58Z</timestamp>
      <contributor>
        <username>Omnipaedista</username>
        <id>8524693</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="16666" xml:space="preserve">{{Machine learning bar}}
'''Grammar induction''' (or '''grammatical inference''')&lt;ref name="Grammatical Inference"&gt;{{cite book|last=de la Higuera|first=Colin|title=Grammatical Inference: Learning Automata and Grammars|date=2010|publisher=Cambridge University Press|location=Cambridge|url=http://bootcamp.lif.univ-mrs.fr/de-la-higuera.pdf}}&lt;/ref&gt; is the process in [[machine learning]] of learning a [[formal grammar]] (usually as a collection of ''re-write rules'' or ''[[productions (computer science)|productions]]'' or alternatively as a [[finite state machine]] or automaton of some kind) from a set of observations, thus constructing a model which accounts for the characteristics of the observed objects. More generally, grammatical inference is that branch of machine learning where the instance space consists of discrete combinatorial objects such as strings, trees and graphs.

==Grammar classes==

Grammatical inference has often been very focused on the problem of learning finite state machines of various types (see the article [[Induction of regular languages]] for details on these approaches), since there have been efficient algorithms for this problem since the 1980s.

Since the beginning of the century, these approaches have been extended to the problem of inference of [[context-free grammars]] and richer formalisms, such as multiple context-free grammars and parallel multiple context-free grammars.
Other classes of grammars for which grammatical inference has been studied are [[combinatory categorial grammar]]s,&lt;ref name="Kwiatkowski"/&gt; [[stochastic context-free grammar]]s,&lt;ref&gt;Clark, Alexander. "[https://www.aclweb.org/anthology/W01-0713 Unsupervised induction of stochastic context-free grammars using distributional clustering]." Proceedings of the 2001 workshop on Computational Natural Language Learning-Volume 7. Association for Computational Linguistics, 2001.&lt;/ref&gt; contextual grammars and pattern languages.

==Learning models==

The simplest form of learning is where the learning algorithm merely receives a set of examples drawn from the language in question: the aim is to learn the language from examples of it (and, rarely, from counter-examples, that is, example that do not belong to the language).
However, other learning models have been studied. One frequently studied alternative is the case where the learner can ask membership queries as in the exact query learning model or minimally adequate teacher model introduced by Angluin.&lt;ref&gt;{{cite journal|author=Dana Angluin |title=Learning Regular Sets from Queries and Counter-Examples |journal=[[Information and Control]] |year=1987 |volume=75 |issue=2 |pages=87–106 |url=http://www.cse.iitk.ac.in/users/chitti/thesis/references/learningRegSetsFromQueriesAndCounterExamples.pdf |doi=10.1016/0890-5401(87)90052-6 |citeseerx=10.1.1.187.9414 |url-status=dead |archiveurl=https://web.archive.org/web/20131202232143/http://www.cse.iitk.ac.in/users/chitti/thesis/references/learningRegSetsFromQueriesAndCounterExamples.pdf |archivedate=2013-12-02 }}&lt;/ref&gt;

==Methodologies==
There is a wide variety of methods for grammatical inference.  Two of the classic sources are {{Harvtxt|Fu|1977}} and {{Harvtxt|Fu|1982}}. {{Harvtxt|Duda|Hart|Stork|2001}} also devote a brief section to the problem, and cite a number of references.  The basic trial-and-error method they present is discussed below. For approaches to infer subclasses of [[regular languages]] in particular, see ''[[Induction of regular languages]]''. A more recent textbook is de la Higuera (2010),&lt;ref name = "Grammatical Inference"/&gt; which covers the theory of grammatical inference of regular languages and finite state automata. D'Ulizia, Ferri and Grifoni&lt;ref&gt;D’Ulizia, A., Ferri, F., Grifoni, P. (2011) "[https://www.academia.edu/download/41900378/A_survey_of_grammatical_inference_method20160202-5760-79hwcu.pdf A Survey of Grammatical Inference Methods for Natural Language Learning]{{Dead link|date=September 2018 |bot=InternetArchiveBot |fix-attempted=yes }}", ''Artificial Intelligence Review'', Vol. 36, No. 1, pp. 1–27.&lt;/ref&gt; provide a survey that explores grammatical inference methods for natural languages.

===Grammatical inference by trial-and-error===
The method proposed in Section 8.7 of {{Harvtxt|Duda|Hart|Stork|2001}} suggests successively guessing grammar rules (productions) and testing them against positive and negative observations.  The rule set is expanded so as to be able to generate each positive example, but if a given rule set also generates a negative example, it must be discarded.  This particular approach can be characterized as "hypothesis testing" and bears some similarity to Mitchel's [[version space]] algorithm. The {{Harvtxt|Duda|Hart|Stork|2001}} text provide a simple example which nicely illustrates the process, but the feasibility of such an unguided trial-and-error approach for more substantial problems is dubious.

=== Grammatical inference by genetic algorithms ===
Grammatical induction using [[evolutionary algorithm]]s is the process of evolving a representation of the grammar of a target language through some evolutionary process. [[Formal grammar]]s can easily be represented as [[tree (data structure)|tree structures]] of production rules that can be subjected to evolutionary operators. [[Algorithm]]s of this sort stem from the [[genetic programming]] paradigm pioneered by [[John Koza]].{{Citation needed|date=August 2007}} Other early work on simple formal languages used the binary string representation of genetic algorithms, but the inherently hierarchical structure of grammars couched in the [[Extended Backus–Naur form|EBNF]] language made trees a more flexible approach.

Koza represented [[Lisp (programming language)|Lisp]] programs as trees. He was able to find analogues to the genetic operators within the standard set of tree operators. For example, swapping sub-trees is equivalent to the corresponding process of genetic crossover, where sub-strings of a genetic code are transplanted into an individual of the next generation. Fitness is measured by scoring the output from the [[grammatical function|functions]] of the Lisp code. Similar analogues between the tree structured lisp representation and the representation of grammars as trees, made the application of genetic programming techniques possible for grammar induction.

In the case of grammar induction, the transplantation of sub-trees corresponds to the swapping of production rules that enable the parsing of phrases from some language. The fitness operator for the grammar is based upon some measure of how well it performed in parsing some group of sentences from the target language. In a tree representation of a grammar, a [[terminal symbol]] of a production rule corresponds to a leaf node of the tree. Its parent nodes corresponds to a non-terminal symbol (e.g. a [[noun phrase]] or a [[verb phrase]]) in the rule set. Ultimately, the root node might correspond to a sentence non-terminal.

===Grammatical inference by greedy algorithms===
Like all [[greedy algorithm]]s, greedy grammar inference algorithms make, in iterative manner, decisions that seem to be the best at that stage.
The decisions made usually deal with things like the creation of new rules, the removal of existing rules, the choice of a rule to be applied or the merging of some existing rules.
Because there are several ways to define 'the stage' and 'the best', there are also several greedy grammar inference algorithms.

These [[context-free grammar]] generating algorithms make the decision after every read symbol:
* [[LZW|Lempel-Ziv-Welch algorithm]] creates a context-free grammar in a deterministic way such that it is necessary to store only the start rule of the generated grammar.
* [[Sequitur algorithm|Sequitur]] and its modifications.

These context-free grammar generating algorithms first read the whole given symbol-sequence and then start to make decisions:
* [[Byte pair encoding]] and its optimizations.

===Distributional learning===
A more recent approach is based on distributional learning. Algorithms using these approaches have been applied to learning [[context-free grammars]] and [[mildly context-sensitive language]]s and have been proven to be correct and efficient for large subclasses of these grammars.&lt;ref&gt;Clark and Eyraud (2007) ''Journal of Machine Learning Research''; Ryo Yoshinaka (2011) ''Theoretical Computer Science''&lt;/ref&gt;

===Learning of [[Pattern language (formal languages)|pattern languages]]===

Angluin defines a ''pattern'' to be "a string of constant symbols from Σ and '''variable symbols''' from a disjoint set".
The language of such a pattern is the set of all its nonempty ground instances  i.e. all strings resulting from consistent replacement of its variable symbols by nonempty strings of constant symbols.&lt;ref group=note&gt;The language of a pattern with at least two occurrences of the same variable is not regular due to the [[Pumping lemma for regular languages|pumping lemma]].&lt;/ref&gt;
A pattern is called '''descriptive''' for a finite input set of strings if its language is minimal (with respect to set inclusion) among all pattern languages subsuming the input set.

Angluin gives a polynomial algorithm to compute, for a given input string set, all descriptive patterns in one variable ''x''.&lt;ref group=note&gt;''x'' may occur several times, but no other variable ''y'' may occur&lt;/ref&gt;
To this end, she builds an automaton representing all possibly relevant patterns; using sophisticated arguments about word lengths, which rely on ''x'' being the only variable, the state count can be drastically reduced.&lt;ref&gt;{{cite journal| author=Dana Angluin| title=Finding Patterns Common to a Set of Strings| journal=Journal of Computer and System Sciences| year=1980| volume=21| pages=46–62| doi=10.1016/0022-0000(80)90041-0}}&lt;/ref&gt;

Erlebach et al. give a more efficient version of Angluin's pattern learning algorithm, as well as a parallelized version.&lt;ref&gt;{{cite book|author1=T. Erlebach |author2=P. Rossmanith |author3=H. Stadtherr |author4=A. Steger |author4-link=Angelika Steger|author5=T. Zeugmann | chapter=Learning One-Variable Pattern Languages Very Efficiently on Average, in Parallel, and by Asking Queries| title=Proc. 8th International Workshop on Algorithmic Learning Theory — ALT'97| year=1997| volume=1316| pages=260–276| publisher=Springer|editor1=M. Li |editor2=A. Maruoka | series=LNAI}}&lt;/ref&gt;

Arimura et al. show that a language class  obtained from limited unions of patterns can be learned in polynomial time.&lt;ref&gt;{{cite book|author1=Hiroki Arimura |author2=Takeshi Shinohara |author3=Setsuko Otsuki | chapter=Finding Minimal Generalizations for Unions of Pattern Languages and Its Application to Inductive Inference from Positive Data| title=Proc. STACS 11| year=1994| volume=775| pages=649–660| publisher=Springer| series=LNCS|chapter-url=http://ai2-s2-pdfs.s3.amazonaws.com/6a4c/0482e0030b0e5791cf75b0edd9f55fdfc10e.pdf}}{{dead link|date=February 2018}}&lt;/ref&gt;

===Pattern theory===
[[Pattern theory]], formulated by [[Ulf Grenander]],&lt;ref&gt;Grenander, Ulf, and Michael I. Miller. ''[http://www.ulb.tu-darmstadt.de/tocs/185410162.pdf Pattern theory: from representation to inference]''.{{dead link|date=March 2018}} Vol. 1. Oxford: Oxford university press, 2007.&lt;/ref&gt; is a mathematical [[Formalism (mathematics)|formalism]] to describe knowledge of the world as patterns. It differs from other approaches to [[artificial intelligence]] in that it does not begin by prescribing algorithms and machinery to recognize and classify patterns; rather, it prescribes a vocabulary to articulate and recast the pattern concepts in precise language.

In addition to the new algebraic vocabulary, its statistical approach was novel in its aim to:
* Identify the [[Latent variable|hidden variables]] of a data set using real world data rather than artificial stimuli, which was commonplace at the time.
* Formulate prior distributions for hidden variables and models for the observed variables that form the vertices of a Gibbs-like graph.
* Study the randomness and variability of these graphs.
* Create the basic classes of stochastic models applied by listing the deformations of the patterns.
* Synthesize (sample) from the models, not just analyze signals with it.
Broad in its mathematical coverage, pattern theory spans algebra and statistics, as well as local topological and global entropic properties.

== Applications ==
The principle of grammar induction has been applied to other aspects of [[natural language processing]], and has been applied (among many other problems) to [[semantic parsing]],&lt;ref name="Kwiatkowski"&gt;Kwiatkowski, Tom, et al. "[http://homes.cs.washington.edu/~lsz/papers/kzgs-emnlp2011.pdf Lexical generalization in CCG grammar induction for semantic parsing]." Proceedings of the conference on empirical methods in natural language processing. [[Association for Computational Linguistics]], 2011.&lt;/ref&gt; [[natural language understanding]],&lt;ref&gt;Miller, Scott, et al. "[http://www.aclweb.org/anthology/P94-1004 Hidden understanding models of natural language]." Proceedings of the 32nd annual meeting on Association for Computational Linguistics. Association for Computational Linguistics, 1994.&lt;/ref&gt; [[example-based translation]],&lt;ref&gt;Brown, Ralf D. "[https://pdfs.semanticscholar.org/c537/ac8bac9d83651e0ce6b37333034a5f572e39.pdf#page=5 Transfer-rule induction for example-based translation]." Proceedings of the MT Summit VIII Workshop on Example-Based Machine Translation. 2001.&lt;/ref&gt; [[morpheme]] analysis, and place name derivations.{{citation needed|date=February 2018}} Grammar induction has also been used for [[lossless data compression]]&lt;ref&gt;Cherniavsky, Neva, and Richard Ladner. "[https://pdfs.semanticscholar.org/1be9/0a2f40d10acd17d5910eb21fb3b4a117d08b.pdf Grammar-based compression of DNA sequences]." DIMACS Working Group on The Burrows-Wheeler Transform 21 (2004).&lt;/ref&gt; and [[statistical inference]] via [[minimum message length]] (MML) and [[minimum description length]] (MDL) principles.{{citation needed|date=August 2017}} Grammar induction has also been used in some [[probabilistic models of language acquisition]].&lt;ref&gt;Chater, Nick, and Christopher D. Manning. "[https://www.stanford.edu/class/linguist1/Rdgs/chater.pdf Probabilistic models of language processing and acquisition]." Trends in cognitive sciences 10.7 (2006): 335-344.&lt;/ref&gt;

==See also==
* [[Artificial grammar learning#Artificial intelligence]]
* [[Example-based machine translation]]
* [[Inductive programming]]
* [[Kolmogorov complexity]]
* [[Language identification in the limit]]
* [[Straight-line grammar]]
* [[Syntactic pattern recognition]]

==Notes==
{{reflist|group=note}}

==References==
{{Reflist}}

==Sources==
* {{Citation
  | last=Duda | first=Richard O.| last2=Hart| first2=Peter E.
  | last3=Stork| first3=David G.
  | title=Pattern Classification | publisher=John Wiley &amp; Sons
  | place=[[New York City|New York]] | year=2001| edition=2
  | url=http://www.wiley.com/WileyCDA/WileyTitle/productCd-0471056693.html}}
* {{Citation
  | last=Fu | first=King Sun
  | title=Syntactic Pattern Recognition and Applications
  | publisher=Prentice-Hall | place=[[Englewood Cliffs, NJ]]
  | year=1982}}
* {{Citation
  | last=Fu | first=King Sun
  | title=Syntactic Pattern Recognition, Applications
  | publisher=Springer-Verlag | place=[[Berlin]] | year=1977}}
* {{Citation
  | last=Horning | first=James Jay
  | title=A Study of Grammatical Inference
  | publisher=Stanford University Computer Science Department
  | place=[[Stanford]] | year=1969 | edition=Ph.D. Thesis
  | id={{ProQuest|302483145}}
 }}
* {{Citation
 |last         = Gold
 |first        = E. Mark
 |title        = Language Identification in the Limit
 |url          = http://groups.lis.illinois.edu/amag/langev/paper/gold67limit.html
 |year         = 1967
 |volume       = 10
 |pages        = 447–474
 |publisher    = [[Information and Control]]
 |access-date  = 2016-09-04
 |archive-url  = https://web.archive.org/web/20160828171937/http://groups.lis.illinois.edu/amag/langev/paper/gold67limit.html
 |archive-date = 2016-08-28
 |url-status     = dead
}}
* {{Citation
  | last=Gold | first=E. Mark
  | title=Language Identification in the Limit
  | volume=10
  | pages=447–474
  | url=http://web.mit.edu/~6.863/www/spring2009/readings/gold67limit.pdf
  | publisher=[[Information and Control]] | year=1967}}

[[Category:Genetic programming]]
[[Category:Natural language processing]]
[[Category:Computational linguistics]]
[[Category:Grammar]]
[[Category:Inference]]
[[Category:Machine learning]]</text>
      <sha1>fjlquwqebjsz0bdyosfszrovhva7gts</sha1>
    </revision>
  </page>
  <page>
    <title>Pattern language (formal languages)</title>
    <ns>0</ns>
    <id>40946774</id>
    <revision>
      <id>994725903</id>
      <parentid>948370366</parentid>
      <timestamp>2020-12-17T06:23:38Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 2 templates: del empty params (1×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="15195" xml:space="preserve">In [[theoretical computer science]], a '''pattern language''' is a [[formal language]] that can be defined as the set of all particular instances of a [[string (formal languages)|string]] of constants and variables. Pattern Languages were introduced by [[Dana Angluin]] in the context of [[machine learning]].&lt;ref&gt;{{cite journal| author=Dana Angluin| title=Finding Patterns Common to a Set of Strings| journal=Journal of Computer and System Sciences| year=1980| volume=21| pages=46–62| doi=10.1016/0022-0000(80)90041-0}}&lt;/ref&gt;

== Definition ==
Given a finite set Σ of '''[[Term (logic)#Formal definition|constant]]''' symbols and a countable set ''X'' of '''[[Term (logic)#Formal definition|variable]]''' symbols disjoint from Σ, a '''pattern''' is a finite [[empty string|non-empty]] [[String (computer science)|string]] of symbols from Σ∪''X''.
The '''length''' of a pattern ''p'', denoted by |''p''|, is just the number of its symbols.
The set of all patterns containing exactly ''n'' distinct variables (each of which may occur several times) is denoted by ''P''&lt;sub&gt;''n''&lt;/sub&gt;, the set of all patterns at all by ''P''&lt;sub&gt;*&lt;/sub&gt;.
A '''substitution''' is a mapping ''f'': ''P''&lt;sub&gt;*&lt;/sub&gt; → ''P''&lt;sub&gt;*&lt;/sub&gt; such that&lt;ref group=note&gt;Angluin's notion of substitution differs from the usual notion of [[string substitution]].&lt;/ref&gt;
* ''f'' is a [[monoid homomorphism|homomorphism]] with respect to [[String_(computer_science)#Concatenation_and_substrings|string concatenation]] (⋅), formally: ∀''p'',''q''∈''P''&lt;sub&gt;*&lt;/sub&gt;. ''f''(''p''⋅''q'') = ''f''(''p'')⋅''f''(''q'');
* ''f'' is non-erasing, formally: ∀''p''∈''P''&lt;sub&gt;*&lt;/sub&gt;. ''f''(''p'') ≠ ε, where ε denotes the [[empty string]]; and
* ''f'' respects constants, formally: ∀''s''∈Σ. ''f''(''s'') = ''s''.
If ''p'' = ''f''(''q'') for some patterns ''p'', ''q'' ∈ ''P''&lt;sub&gt;*&lt;/sub&gt; and some substitution ''f'', then ''p'' is said to be '''less general than''' ''q'', written ''p''≤''q'';
in that case, necessarily |''p''| ≥ |''q''| holds.
For a pattern ''p'', its '''language''' is defined as the set of all less general patterns that are built from constants only, formally: ''L''(''p'') = { ''s'' ∈ Σ&lt;sup&gt;+&lt;/sup&gt; : ''s'' ≤ ''p'' }, where [[Kleene plus|Σ&lt;sup&gt;+&lt;/sup&gt;]] denotes the set of all finite non-empty strings of symbols from Σ.

For example, using the constants Σ = { 0, 1 } and the variables ''X'' = { ''x'', ''y'', ''z'', ... }, the pattern 0''x''10''xx''1 ∈''P''&lt;sub&gt;1&lt;/sub&gt; and ''xxy'' ∈''P''&lt;sub&gt;2&lt;/sub&gt; has length 7 and 3, respectively.
An instance of the former pattern is 00''z''100''z''0''z''1 and 01''z''101''z''1''z''1, it is obtained by the substitution that maps ''x'' to 0''z'' and to 1''z'', respectively, and each other symbol to itself. Both 00''z''100''z''0''z''1 and 01''z''101''z''1''z''1 are also instances of ''xxy''. In fact, ''L''(0''x''10''xx''1) is a subset of ''L''(''xxy''). The language of the pattern ''x''0 and ''x''1 is the set of all bit strings which denote an even and odd [[binary number]], respectively. The language of ''xx'' is the set of all strings obtainable by concatenating a bit string with itself, e.g. 00, 11, 0101, 1010, 11101110 ∈ ''L''(''xx'').

== Properties ==
{| style="float:right"
| [[File:NP-hardness of pattern language membership svg.svg|thumb|600px|NP-hardness of pattern language membership, by [[Reduction (complexity)|reduction]] from the [[NP-complete]] [[Boolean_satisfiability_problem#Exactly-1_3-satisfiability|1-in-3-SAT problem]]: Given a [[Conjunctive normal form|CNF]] of ''m'' clauses with ''n'' variables, a pattern of length 3''n''+4''m''+1 with 2''n'' variables and a string of length ''4''n+5''m''+1 can be constructed as shown (''m''=3 and ''n''=4 in the example). Upper-case variables in the pattern correspond to negated variables in the CNF.  The string matches the pattern if and only if an assignment exists such that in each clause exactly one literal is 1 (meaning "''true''" in the CNF). In the left part, e.g. "0''wW''0" is matched by "01110" just if one of ''w'',''W'' is matched by "1" (corresponding to "''false''") and the other by "11" (corresponding to "''true''"), i.e. if ''w'' corresponds to the negation of ''W''. In the right part, e.g. "0''xYZ''0" is matched by "011110" just if exactly one of ''x'',''Y'',''Z'' is matched by "11" and the others by "1", i.e. if exactly one literal corresponds to "''true''".]]
|}
The problem of deciding whether ''s'' ∈ ''L''(''p'') for an arbitrary string ''s'' ∈ Σ&lt;sup&gt;+&lt;/sup&gt; and pattern ''p'' is [[NP-complete]] (see picture),
and so is hence the problem of deciding ''p'' ≤ ''q'' for arbitrary patterns ''p'', ''q''.&lt;ref&gt;Theorem 3.6, p.50; Corollary 3.7, p.52&lt;/ref&gt;

The class of pattern languages is '''not closed''' under ...
* union: e.g. for Σ = {0,1} as [[#Definition|above]], ''L''(01)∪''L''(10) is not a pattern language;
* complement: Σ&lt;sup&gt;+&lt;/sup&gt; \ ''L''(0) is not a pattern language;
* intersection: ''L''(''x''0''y'')∩''L''(''x''1''y'') is not a pattern language;
* [[Kleene plus]]: ''L''(0)&lt;sup&gt;+&lt;/sup&gt; is not a pattern language;
* homomorphism: ''f''(''L''(''x'')) = ''L''(0)&lt;sup&gt;+&lt;/sup&gt; is not a pattern language, assuming ''f''(0) = 0 = ''f''(1);
* [[String_operations#String_homomorphism|inverse homomorphism]]: ''f''&lt;sup&gt;−1&lt;/sup&gt;(111) = { 01, 10, 000 } is not a pattern language, assuming ''f''(0) = 1 and ''f''(1) = 11.
The class of pattern languages is '''closed''' under ...
* concatenation: ''L''(''p'')⋅''L''(''q'') = ''L''(''p''⋅''q'');
* reversal: ''L''(''p'')&lt;sup&gt;rev&lt;/sup&gt; = ''L''(''p''&lt;sup&gt;rev&lt;/sup&gt;).&lt;ref&gt;Theorem 3.10, p.53&lt;/ref&gt;

If ''p'', ''q'' ∈ ''P''&lt;sub&gt;1&lt;/sub&gt; are patterns containing exactly one variable, then ''p'' ≤ ''q'' if and only if ''L''(''p'') ⊆ ''L''(''q'');
the same equivalence holds for patterns of equal length.&lt;ref&gt;Lemma 3.9, p.52; Corollary 3.4, p.50&lt;/ref&gt;
For patterns of different length, the [[#Definition|above]] example ''p'' = 0''x''10''xx''1 and ''q'' = ''xxy'' shows that ''L''(''p'') ⊆ ''L''(''q'') may hold without implying ''p'' ≤ ''q''.
However, any two patterns ''p'' and ''q'', of arbitrary lengths, generate the same language if and only if they are equal up to consistent variable renaming.&lt;ref&gt;Theorem 3.5, p.50&lt;/ref&gt;
Each pattern ''p'' is a [[Anti-unification_(computer_science)#Anti-unification_problem.2C_generalization_set|common generalization]] of all strings in its generated language ''L''(''p''), modulo associativity of (⋅).

==Location in the Chomsky hierarchy==
In a refined [[Chomsky hierarchy]], the class of pattern languages is a proper superclass and subclass of the singleton&lt;ref group=note&gt;i.e. languages consisting of a single string; they correspond to [[straight-line grammar]]s&lt;/ref&gt; and the [[indexed language]]s, respectively, but incomparable to the language classes in between; due to the latter, the pattern language class is not explicitly shown in the table [[#References|below]].

The class of pattern languages is incomparable with the class of [[finite language]]s, with the class of [[regular language]]s, and with the class of [[context-free language]]s:
* the pattern language ''L''(''xx'') is not context-free (hence neither [[Regular language#Deciding whether a language is regular|regular]] nor [[Regular language#Formal definition|finite]]) due to the [[pumping lemma for context-free languages|pumping lemma]];
* the finite (hence also regular and context-free) language { 01, 10 } is not a pattern language.
Each singleton language is trivially a pattern language, generated by a pattern without variables.

Each pattern language can be produced by an [[indexed grammar]]:
For example, using Σ = { ''a'', ''b'', ''c'' } and ''X'' = { '''''x''''', '''''y''''' },
the pattern ''a'' '''''x''''' ''b'' '''''y''''' ''c'' '''''x''''' ''a'' '''''y''''' ''b'' is generated by a grammar with nonterminal symbols ''N'' = { ''S''&lt;sub&gt;'''''x'''''&lt;/sub&gt;, ''S''&lt;sub&gt;'''''y'''''&lt;/sub&gt;, ''S'' } ∪ ''X'', terminal symbols ''T'' = Σ, index symbols ''F'' = { ''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt;, ''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt;, ''c''&lt;sub&gt;'''''x'''''&lt;/sub&gt;, ''a''&lt;sub&gt;'''''y'''''&lt;/sub&gt;, ''b''&lt;sub&gt;'''''y'''''&lt;/sub&gt;, ''c''&lt;sub&gt;'''''y'''''&lt;/sub&gt; }, start symbol ''S''&lt;sub&gt;'''''x'''''&lt;/sub&gt;, and the following production rules:
{|
|-
| ''S''&lt;sub&gt;'''''x'''''&lt;/sub&gt;[σ] 
| →   ''S''&lt;sub&gt;'''''x'''''&lt;/sub&gt;[''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt; σ]
| | | ''S''&lt;sub&gt;'''''x'''''&lt;/sub&gt;[''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt; σ]
| | | ''S''&lt;sub&gt;'''''x'''''&lt;/sub&gt;[''c''&lt;sub&gt;'''''x'''''&lt;/sub&gt; σ]
| | | ''S''&lt;sub&gt;'''''y'''''&lt;/sub&gt;[σ]
|-
| ''S''&lt;sub&gt;'''''y'''''&lt;/sub&gt;[σ] 
| →   ''S''&lt;sub&gt;'''''y'''''&lt;/sub&gt;[''a''&lt;sub&gt;'''''y'''''&lt;/sub&gt; σ]
| | | ''S''&lt;sub&gt;'''''y'''''&lt;/sub&gt;[''b''&lt;sub&gt;'''''y'''''&lt;/sub&gt; σ]
| | | ''S''&lt;sub&gt;'''''y'''''&lt;/sub&gt;[''c''&lt;sub&gt;'''''y'''''&lt;/sub&gt; σ]
| | | ''S''[σ] 
|-
| ''S''[σ] 
| colspan=4 | → ''a'' '''''x'''''[σ] ''b'' '''''y'''''[σ] ''c'' '''''x'''''[σ] ''a'' '''''y'''''[σ] ''b''
|}
{|
|-
| '''''x'''''[''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt; σ] || → ''a'' || '''''x'''''[σ] &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 
| '''''y'''''[''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt; σ] || →       || '''''y'''''[σ] &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; 
|-
| '''''x'''''[''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt; σ] || → ''b'' || '''''x'''''[σ]
| '''''y'''''[''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt; σ] || →       || '''''y'''''[σ]
|-
| '''''x'''''[''c''&lt;sub&gt;'''''x'''''&lt;/sub&gt; σ] || → ''c'' || '''''x'''''[σ]
| '''''y'''''[''c''&lt;sub&gt;'''''x'''''&lt;/sub&gt; σ] || →       || '''''y'''''[σ]
|-
| '''''x'''''[''a''&lt;sub&gt;'''''y'''''&lt;/sub&gt; σ] || →       || '''''x'''''[σ]
| '''''y'''''[''a''&lt;sub&gt;'''''y'''''&lt;/sub&gt; σ] || → ''a'' || '''''y'''''[σ]
|-
| '''''x'''''[''b''&lt;sub&gt;'''''y'''''&lt;/sub&gt; σ] || →       || '''''x'''''[σ]
| '''''y'''''[''b''&lt;sub&gt;'''''y'''''&lt;/sub&gt; σ] || → ''b'' || '''''y'''''[σ]
|-
| '''''x'''''[''c''&lt;sub&gt;'''''y'''''&lt;/sub&gt; σ] || →       || '''''x'''''[σ]
| '''''y'''''[''c''&lt;sub&gt;'''''y'''''&lt;/sub&gt; σ] || → ''c'' || '''''y'''''[σ]
|-
| '''''x'''''[] || → ε ||
| '''''y'''''[] || → ε
|}

An example derivation is:

{{nowrap|''S''&lt;sub&gt;'''''x'''''&lt;/sub&gt;[]}}
&amp;nbsp; ⇒ &amp;nbsp; {{nowrap|''S''&lt;sub&gt;'''''x'''''&lt;/sub&gt;[''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt;]}}
&amp;nbsp; ⇒ &amp;nbsp; {{nowrap|''S''&lt;sub&gt;'''''x'''''&lt;/sub&gt;[''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt; ''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt;]}}
&amp;nbsp; ⇒ &amp;nbsp; {{nowrap|''S''&lt;sub&gt;'''''y'''''&lt;/sub&gt;[''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt; ''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt;]}}
&amp;nbsp; ⇒ &amp;nbsp; {{nowrap|''S''&lt;sub&gt;'''''y'''''&lt;/sub&gt;[''c''&lt;sub&gt;'''''y'''''&lt;/sub&gt; ''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt; ''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt;]}}
&amp;nbsp; ⇒ &amp;nbsp; {{nowrap|''S''[''c''&lt;sub&gt;'''''y'''''&lt;/sub&gt; ''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt; ''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt;]}}
&amp;nbsp; ⇒  &amp;nbsp; {{nowrap|''a'' '''''x'''''[''c''&lt;sub&gt;'''''y'''''&lt;/sub&gt; ''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt; ''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt;] ''b'' '''''y'''''[''c''&lt;sub&gt;'''''y'''''&lt;/sub&gt; ''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt; ''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt;] ''c'' '''''x'''''[''c''&lt;sub&gt;'''''y'''''&lt;/sub&gt; ''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt; ''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt;] ''a'' '''''y'''''[''c''&lt;sub&gt;'''''y'''''&lt;/sub&gt; ''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt; ''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt;] ''b''}}
&amp;nbsp; ⇒  &amp;nbsp; {{nowrap|''a'' '''''x'''''[''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt; ''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt;] ''b'' '''''y'''''[''c''&lt;sub&gt;'''''y'''''&lt;/sub&gt; ''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt; ''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt;] ''c'' '''''x'''''[''c''&lt;sub&gt;'''''y'''''&lt;/sub&gt; ''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt; ''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt;] ''a'' '''''y'''''[''c''&lt;sub&gt;'''''y'''''&lt;/sub&gt; ''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt; ''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt;] ''b''}}
&amp;nbsp; ⇒  &amp;nbsp; {{nowrap|''a'' ''a'' '''''x'''''[''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt;] ''b'' '''''y'''''[''c''&lt;sub&gt;'''''y'''''&lt;/sub&gt; ''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt; ''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt;] ''c'' '''''x'''''[''c''&lt;sub&gt;'''''y'''''&lt;/sub&gt; ''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt; ''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt;] ''a'' '''''y'''''[''c''&lt;sub&gt;'''''y'''''&lt;/sub&gt; ''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt; ''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt;] ''b''}}
&amp;nbsp; ⇒  &amp;nbsp; {{nowrap|''a'' ''ab'' '''''x'''''[] ''b'' '''''y'''''[''c''&lt;sub&gt;'''''y'''''&lt;/sub&gt; ''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt; ''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt;] ''c'' '''''x'''''[''c''&lt;sub&gt;'''''y'''''&lt;/sub&gt; ''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt; ''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt;] ''a'' '''''y'''''[''c''&lt;sub&gt;'''''y'''''&lt;/sub&gt; ''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt; ''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt;] ''b''}}
&amp;nbsp; ⇒  &amp;nbsp; {{nowrap|''a'' ''ab'' ''b'' '''''y'''''[''c''&lt;sub&gt;'''''y'''''&lt;/sub&gt; ''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt; ''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt;] ''c'' '''''x'''''[''c''&lt;sub&gt;'''''y'''''&lt;/sub&gt; ''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt; ''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt;] ''a'' '''''y'''''[''c''&lt;sub&gt;'''''y'''''&lt;/sub&gt; ''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt; ''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt;] ''b''}}
&amp;nbsp; ⇒ ... ⇒ &amp;nbsp; {{nowrap|''a'' ''ab'' ''b'' ''c'' '''''y'''''[] ''c'' '''''x'''''[''c''&lt;sub&gt;'''''y'''''&lt;/sub&gt; ''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt; ''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt;] ''a'' '''''y'''''[''c''&lt;sub&gt;'''''y'''''&lt;/sub&gt; ''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt; ''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt;] ''b''}}
&amp;nbsp; ⇒ &amp;nbsp; {{nowrap|''a'' ''ab'' ''b'' ''c'' ''c'' '''''x'''''[''c''&lt;sub&gt;'''''y'''''&lt;/sub&gt; ''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt; ''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt;] ''a'' '''''y'''''[''c''&lt;sub&gt;'''''y'''''&lt;/sub&gt; ''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt; ''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt;] ''b''}}
&amp;nbsp; ⇒ ... ⇒ &amp;nbsp; {{nowrap|''a'' ''ab'' ''b'' ''c'' ''c'' ''ab'' '''''x'''''[] ''a'' '''''y'''''[''c''&lt;sub&gt;'''''y'''''&lt;/sub&gt; ''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt; ''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt;] ''b''}}
&amp;nbsp; ⇒ &amp;nbsp; {{nowrap|''a'' ''ab'' ''b'' ''c'' ''c'' ''ab'' ''a'' '''''y'''''[''c''&lt;sub&gt;'''''y'''''&lt;/sub&gt; ''a''&lt;sub&gt;'''''x'''''&lt;/sub&gt; ''b''&lt;sub&gt;'''''x'''''&lt;/sub&gt;] ''b''}}
&amp;nbsp; ⇒ ... ⇒ &amp;nbsp; {{nowrap|''a'' ''ab'' ''b'' ''c'' ''c'' ''ab'' ''a'' ''c'' '''''y'''''[] ''b''}}
&amp;nbsp; ⇒ &amp;nbsp; {{nowrap|''a'' ''ab'' ''b'' ''c'' ''c'' ''ab'' ''a'' ''c'' ''b''}}

In a similar way, an index grammar can be constructed from any pattern.

== Learning patterns ==
Given a sample set ''S'' of strings, a pattern ''p'' is called '''descriptive''' of ''S'' if ''S'' ⊆ ''L''(''p''), but not ''S'' ⊆ ''L''(''q'') ⊂ ''L''(''p'') for any other pattern ''q''.

Given any sample set ''S'', a descriptive pattern for ''S'' can be computed by 
* enumerating all patterns (up to variable renaming) not longer than the shortest string in ''S'',
* selecting from them the patterns that generate a superset of ''S'',
* selecting from them the patterns of maximal length, and 
* selecting from them a pattern that is minimal with respect to ≤.&lt;ref&gt;Theorem 4.1, p.53&lt;/ref&gt;
Based on this algorithm, the class of pattern languages can be [[Language identification in the limit|identified in the limit]] from positive examples.&lt;ref&gt;{{cite journal| author=Dana Angluin| title=Inductive Inference of Formal Languages from Positive Data| journal=Information and Control| year=1980| volume=45| issue=2| pages=117–135| url=http://www-personal.umich.edu/~yinw/papers/Angluin80.pdf| doi=10.1016/s0019-9958(80)90285-5}}; here: Example 1, p.125&lt;/ref&gt;

==Notes==
{{reflist|group=note}}
== References ==
{{reflist}}
{{formal languages and grammars}}

[[Category:Formal languages]]
[[Category:Theoretical computer science]]
[[Category:Machine learning]]</text>
      <sha1>hmfz43k1m6hgp3fhwuy0zi5r2gvxd51</sha1>
    </revision>
  </page>
  <page>
    <title>Bayesian optimization</title>
    <ns>0</ns>
    <id>40973765</id>
    <revision>
      <id>997493491</id>
      <parentid>994520673</parentid>
      <timestamp>2020-12-31T19:47:34Z</timestamp>
      <contributor>
        <username>AnnaWoodard</username>
        <id>40886702</id>
      </contributor>
      <minor/>
      <comment>/* Strategy */ Fix error: a blackbox has unknown structure, not known structure.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="12375" xml:space="preserve">'''Bayesian optimization''' is a [[sequential analysis|sequential design]] strategy for [[global optimization]] of [[Black box|black-box]] functions&lt;ref&gt;Jonas Mockus (2012). [https://books.google.com/books?id=VuKoCAAAQBAJ&amp;printsec=frontcover#v=onepage&amp;q=%22global%20optimization%22&amp;f=false Bayesian approach to global optimization: theory and applications]. Kluwer Academic.&lt;/ref&gt; that does not assume any functional forms. It is usually employed to optimize expensive-to-evaluate functions.

==History==
The term is generally attributed to Jonas Mockus and is coined in his work from a series of publications on global optimization in the 1970s and 1980s.&lt;ref&gt;Jonas Mockus: [https://link.springer.com/content/pdf/10.1007/3-540-07165-2_55.pdf On Bayesian Methods for Seeking the Extremum]. Optimization Techniques 1974: 400-404&lt;/ref&gt;&lt;ref&gt;Jonas Mockus: On Bayesian Methods for Seeking the Extremum and their Application. IFIP Congress 1977: 195-200&lt;/ref&gt;&lt;ref&gt;J. Mockus, Bayesian Approach to Global Optimization. Kluwer Academic Publishers, Dordrecht, 1989&lt;/ref&gt;

==Strategy==
[[File:GpParBayesAnimationSmall.gif|thumb|440x330px|Bayesian optimization of a function (black) with Gaussian processes (purple). Three acquisition functions (blue) are shown at the bottom.&lt;ref&gt;{{Citation|last=Wilson|first=Samuel|title=ParBayesianOptimization R package|date=2019-11-22|url=https://github.com/AnotherSamWilson/ParBayesianOptimization|access-date=2019-12-12}}&lt;/ref&gt;]]
Bayesian optimization is typically used on problems of the form &lt;math display="inline"&gt;\max_{x \in A} f(x)&lt;/math&gt;, where &lt;math display="inline"&gt;A&lt;/math&gt; is a set of points whose membership can easily be evaluated. Bayesian optimization is particularly advantageous for problems where &lt;math display="inline"&gt;f(x)&lt;/math&gt; is difficult to evaluate, is a black box with some unknown structure, relies upon less than 20 [[dimension]]s, and where [[derivative]]s are not evaluated.&lt;ref name=":0"&gt;{{cite arxiv|last=Frazier|first=Peter I.|date=2018-07-08|title=A Tutorial on Bayesian Optimization|class=stat.ML|eprint=1807.02811}}&lt;/ref&gt;

Since the objective function is unknown, the Bayesian strategy is to treat it as a random function and place a [[Prior distribution|prior]] over it. The prior captures beliefs about the behavior of the function. After gathering the function evaluations, which are treated as data, the prior is updated to form the [[posterior distribution]] over the objective function. The posterior distribution, in turn, is used to construct an acquisition function (often also referred to as infill sampling criteria) that determines the next query point.

There are several methods used to define the prior/posterior distribution over the objective function. The most common two methods use [[Gaussian process|Gaussian Processes]] in a method called [[Kriging]]. Another less expensive method uses the Parzen-Tree Estimator to construct two distributions for 'high' and 'low' points, and then finds the location that maximizes the expected improvement.&lt;ref&gt;J. S. Bergstra, R. Bardenet, Y. Bengio, B.  Kégl: [http://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf Algorithms for Hyper-Parameter Optimization]. Advances in Neural Information Processing Systems: 2546–2554 (2011)&lt;/ref&gt;

Standard Bayesian optimization relies upon each &lt;math&gt;x \in A&lt;/math&gt; being easy to evaluate, and problems that deviate from this assumption are known as ''exotic Bayesian optimization'' problems. Optimization problems can become exotic if it is known that there is noise, the evaluations are being done in parallel, the quality of evaluations relies upon a tradeoff between difficulty and accuracy, the presence of random environmental conditions, or if the evaluation involves derivatives.&lt;ref name=":0" /&gt;

==Examples==
Examples of acquisition functions include probability of improvement, expected improvement, Bayesian expected losses, upper confidence bounds (UCB), [[Thompson sampling]] and hybrids of these.&lt;ref&gt;Matthew W. Hoffman, Eric Brochu, [[Nando de Freitas]]: Portfolio Allocation for Bayesian Optimization. Uncertainty in Artificial Intelligence: 327–336 (2011)&lt;/ref&gt; They all trade-off exploration and exploitation so as to minimize the number of function queries. As such, Bayesian optimization is well suited for functions that are expensive to evaluate.

==Solution methods==
The maximum of the acquisition function is typically found by resorting to discretization or by means of an auxiliary optimizer. Acquisition functions are typically well-behaved and are often maximized with implementations of [[Newton's method in optimization|Newton's Method]] such as [[Broyden–Fletcher–Goldfarb–Shanno algorithm]] or the [[Nelder–Mead method|Nelder-Mead method]].

==Applications==
The approach has been applied to solve a wide range of problems,&lt;ref&gt;Eric Brochu, Vlad M. Cora, Nando de Freitas: [https://arxiv.org/abs/1012.2599 A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning]. CoRR abs/1012.2599 (2010)&lt;/ref&gt; including learning to rank,&lt;ref&gt;Eric Brochu, Nando de Freitas, Abhijeet Ghosh: [http://papers.nips.cc/paper/3219-active-preference-learning-with-discrete-choice-data.pdf Active Preference Learning with Discrete Choice Data]. Advances in Neural Information Processing Systems: 409-416 (2007)&lt;/ref&gt; [[computer graphics]] and visual design,&lt;ref&gt;Eric Brochu, Tyson Brochu, Nando de Freitas: [http://haikufactory.com/files/sca2010.pdf A Bayesian Interactive Optimization Approach to Procedural Animation Design]. Symposium on Computer Animation 2010: 103–112&lt;/ref&gt;&lt;ref&gt;Yuki Koyama, Issei Sato, Daisuke Sakamoto, Takeo Igarashi: [https://koyama.xyz/project/sequential_line_search/download/preprint.pdf Sequential Line Search for Efficient Visual Design Optimization by Crowds]. ACM Transactions on Graphics, Volume 36, Issue 4, pp.48:1–48:11 (2017). DOI: https://doi.org/10.1145/3072959.3073598&lt;/ref&gt; [[robotics]],&lt;ref&gt;Daniel J. Lizotte, Tao Wang, Michael H. Bowling, Dale Schuurmans: [https://www.aaai.org/Papers/IJCAI/2007/IJCAI07-152.pdf Automatic Gait Optimization with Gaussian Process Regression]. International Joint Conference on Artificial Intelligence: 944–949 (2007)&lt;/ref&gt;&lt;ref&gt;Ruben Martinez-Cantin, Nando de Freitas, Eric Brochu, Jose Castellanos and Arnaud Doucet. [https://link.springer.com/article/10.1007%2Fs10514-009-9130-2# A Bayesian exploration-exploitation approach for optimal online sensing and planning with a visually guided mobile robot]. Autonomous Robots. Volume 27, Issue 2, pp 93–103 (2009)&lt;/ref&gt;&lt;ref&gt;Scott Kuindersma, Roderic Grupen, and Andrew Barto. [http://ijr.sagepub.com/content/32/7/806.abstract# Variable Risk Control via Stochastic Optimization]. International Journal of Robotics Research, volume 32, number 7, pp 806–825 (2013)&lt;/ref&gt;&lt;ref&gt;Roberto Calandra, André Seyfarth, Jan Peters, and Marc P. Deisenroth [https://link.springer.com/article/10.1007%2Fs10472-015-9463-9 Bayesian optimization for learning gaits under uncertainty]. Ann. Math. Artif. Intell. Volume 76, Issue 1, pp 5-23 (2016) DOI:10.1007/s10472-015-9463-9&lt;/ref&gt; [[sensor networks]],&lt;ref&gt;Niranjan Srinivas, Andreas Krause, Sham M. Kakade, Matthias W. Seeger: [https://infoscience.epfl.ch/record/177246/files/srinivas_ieeeit2012.pdf Information-Theoretic Regret Bounds for Gaussian Process Optimization in the Bandit Setting]. IEEE Transactions on Information Theory 58(5):3250–3265 (2012)&lt;/ref&gt;&lt;ref&gt;Roman Garnett, Michael A. Osborne, Stephen J. Roberts: [http://www.academia.edu/download/30681076/ipsn673-garnett.pdf Bayesian optimization for sensor set selection]. ACM/IEEE International Conference on Information Processing in Sensor Networks: 209–219 (2010)&lt;/ref&gt; automatic algorithm configuration,&lt;ref&gt;Frank Hutter, Holger Hoos, and Kevin Leyton-Brown (2011). [http://www.cs.ubc.ca/labs/beta/Projects/SMAC/papers/11-LION5-SMAC.pdf Sequential model-based optimization for general algorithm configuration], Learning and Intelligent Optimization&lt;/ref&gt;&lt;ref&gt;J. Snoek, H. Larochelle, R. P. Adams [https://papers.nips.cc/paper/4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf Practical Bayesian Optimization of Machine Learning Algorithms]. Advances in Neural Information Processing Systems: 2951-2959 (2012)&lt;/ref&gt; automatic [[machine learning]] toolboxes,&lt;ref&gt;J. Bergstra, D. Yamins, D. D. Cox (2013).
[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.704.3494&amp;rep=rep1&amp;type=pdf Hyperopt: A Python Library for Optimizing the Hyperparameters of Machine Learning Algorithms].
Proc. SciPy 2013.&lt;/ref&gt;&lt;ref&gt;Chris Thornton, Frank Hutter, Holger H. Hoos, Kevin Leyton-Brown: [https://arxiv.org/abs/1208.3719 Auto-WEKA: combined selection and hyperparameter optimization of classification algorithms]. KDD 2013: 847–855&lt;/ref&gt;&lt;ref&gt;Jasper Snoek, Hugo Larochelle and Ryan Prescott Adams. [https://papers.nips.cc/paper/4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf Practical Bayesian Optimization of Machine Learning Algorithms]. Advances in Neural Information Processing Systems, 2012&lt;/ref&gt; [[reinforcement learning]], planning, visual attention, architecture configuration in [[deep learning]], static program analysis, experimental [[particle physics]],&lt;ref&gt;Philip Ilten, Mike Williams, Yunjie Yang. [https://arxiv.org/abs/1610.08328 Event generator tuning using Bayesian optimization]. 2017 JINST 12 P04028. DOI: 10.1088/1748-0221/12/04/P04028&lt;/ref&gt;&lt;ref&gt;Evaristo Cisbani et al. [https://iopscience.iop.org/article/10.1088/1748-0221/15/05/P05009 AI-optimized detector design for the future Electron-Ion Collider: the dual-radiator RICH case] 2020 JINST 15 P05009. DOI: 10.1088/1748-0221/15/05/P05009&lt;/ref&gt; chemistry, material design, and drug development.&lt;ref name=":0" /&gt;&lt;ref&gt;Gomez-Bombarelli et al. [https://pubs.acs.org/doi/10.1021/acscentsci.7b00572 Automatic Chemical Design using a Data-Driven Continuous Representation of Molecules]. ACS Central Science, Volume 4, Issue 2, 268-276 (2018)&lt;/ref&gt;&lt;ref&gt;Griffiths et al. [https://pubs.rsc.org/en/content/articlehtml/2020/sc/c9sc04026a Constrained Bayesian Optimization for Automatic Chemical Design using Variational Autoencoders] Chemical Science: 11, 577-586 (2020)&lt;/ref&gt;

==See also==
* [[Multi-armed bandit]]
* [[Thompson sampling]]
* [[Global optimization]]
* [[Bayesian experimental design]]

==References==
{{reflist}}

==External links==
* [https://sheffieldml.github.io/GPyOpt/ GPyOpt], Python open-source library for Bayesian Optimization based on [https://github.com/SheffieldML/GPy GPy].
* [https://rmcantin.bitbucket.io/html/ Bayesopt], an efficient implementation in C/C++ with support for Python, Matlab and Octave.
* [https://github.com/HIPS/Spearmint Spearmint], a Python implementation focused on parallel and cluster computing.
* [http://www.cs.ubc.ca/labs/beta/Projects/SMAC/ SMAC], a Java implementation of random-forest-based Bayesian optimization for general algorithm configuration.
* [https://github.com/AnotherSamWilson/ParBayesianOptimization ParBayesianOptimization], A high performance, parallel implementation of Bayesian optimization with Gaussian processes in R.
* [https://github.com/mwhoffman/pybo pybo], a Python implementation of modular Bayesian optimization.
* [https://bitbucket.org/mlcircus/bayesopt.m Bayesopt.m], a Matlab implementation of Bayesian optimization with or without constraints.
* [https://github.com/yelp/MOE MOE] MOE is a Python/C++/CUDA implementation of Bayesian Global Optimization using Gaussian Processes.
* [https://sigopt.com/ SigOpt] SigOpt offers Bayesian Global Optimization as a SaaS service focused on enterprise use cases.
* [https://mindfoundry.ai/optaas Mind Foundry] OPTaaS offers Bayesian Global Optimization via web-services with flexible parameter constraints.
* [http://bayeso.org bayeso], a Python implementation of Bayesian optimization.
* [https://botorch.org BoTorch], a modular and modern PyTorch-based open-source library for Bayesian optimization research with support for [http://gpytorch.ai GPyTorch].
* [https://github.com/GPflow/GPflowOpt GPflowOpt], a TensorFlow-based open-source package for Bayesian optimization.

[[Category:Sequential methods]]
[[Category:Sequential experiments]]
[[Category:Stochastic optimization]]
[[Category:Machine learning]]</text>
      <sha1>17ee95zlqt8c1uqa5xjf72k1f3nsk5p</sha1>
    </revision>
  </page>
  <page>
    <title>Early stopping</title>
    <ns>0</ns>
    <id>213214</id>
    <revision>
      <id>1000170322</id>
      <parentid>995187771</parentid>
      <timestamp>2021-01-13T23:00:13Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 8 templates: hyphenate params (1×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="13330" xml:space="preserve">In [[machine learning]], '''early stopping''' is a form of [[regularization (mathematics)|regularization]] used to avoid [[overfitting]] when training a learner with an iterative method, such as [[gradient descent]]. Such methods update the learner so as to make it better fit the training data with each iteration. Up to a point, this improves the learner's performance on data outside of the training set. Past that point, however, improving the learner's fit to the training data comes at the expense of increased [[generalization error]]. Early stopping rules provide guidance as to how many iterations can be run before the learner begins to over-fit. Early stopping rules have been employed in many different machine learning methods, with varying amounts of theoretical foundation.

==Background==
This section presents some of the basic machine-learning concepts required for a description of early stopping methods.

===Overfitting===
{{Main|Overfitting}}
[[File:Overfitting on Training Set Data.pdf|thumb|This image represents the problem of overfitting in machine learning. The red dots represent training set data. The green line represents the true functional relationship, while the blue line shows the learned function, which has fallen victim to overfitting.]]

[[Machine learning]] algorithms train a model based on a finite set of training data. During this training, the model is evaluated based on how well it predicts the observations contained in the training set. In general, however, the goal of a machine learning scheme is to produce a model that generalizes, that is, that predicts previously unseen observations. Overfitting occurs when a model fits the data in the training set well, while incurring larger [[generalization error]].

===Regularization===
{{Main|Regularization (mathematics)}}
Regularization, in the context of machine learning, refers to the process of modifying a learning algorithm so as to prevent overfitting. This generally involves imposing some sort of smoothness constraint on the learned model.&lt;ref&gt;{{Cite journal
| doi = 10.1162/neco.1995.7.2.219
| issn = 0899-7667
| volume = 7
| issue = 2
| pages = 219–269
| last = Girosi
| first = Federico
|author2=Michael Jones |author3=Tomaso Poggio
 | title = Regularization Theory and Neural Networks Architectures
| journal = Neural Computation
| date = 1995-03-01
| citeseerx = 10.1.1.48.9258
| s2cid = 49743910
}}&lt;/ref&gt;
This smoothness may be enforced explicitly, by fixing the number of parameters in the model, or by augmenting the cost function as in [[Tikhonov regularization]]. Tikhonov regularization, along with [[principal component regression]] and many other regularization schemes, fall under the umbrella of spectral regularization, regularization characterized by the application of a filter. Early stopping also belongs to this class of methods.

===Gradient descent methods===
{{Main|Gradient descent}}
Gradient descent methods are first-order, iterative, optimization methods. Each iteration updates an approximate solution to the optimization problem by taking a step in the direction of the negative of the gradient of the objective function. By choosing the step-size appropriately, such a method can be made to converge to a local minimum of the objective function. Gradient descent is used in machine-learning by defining a ''[[loss function]]'' that reflects the error of the learner on the training set and then minimizing that function.

==Early stopping based on analytical results==

===Early stopping in [[statistical learning theory]]===
Early-stopping can be used to regularize [[non-parametric regression]] problems encountered in [[machine learning]]. For a given input space, &lt;math&gt;X&lt;/math&gt;, output space, &lt;math&gt;Y&lt;/math&gt;, and samples drawn from an unknown probability measure, &lt;math&gt;\rho&lt;/math&gt;, on &lt;math&gt;Z = X \times Y&lt;/math&gt;, the goal of such problems is to approximate a ''regression function'', &lt;math&gt;f_{\rho}&lt;/math&gt;, given by

:&lt;math&gt; f_{\rho}(x) = \int_{Y} y d\rho(y|x), x \in X&lt;/math&gt;,

where &lt;math&gt;\rho(y|x)&lt;/math&gt; is the conditional distribution at &lt;math&gt;x&lt;/math&gt; induced by &lt;math&gt;\rho&lt;/math&gt;.&lt;ref name="smale_learning_2007"&gt;{{Cite journal
| doi = 10.1007/s00365-006-0659-y
| issn = 0176-4276
| volume = 26
| issue = 2
| pages = 153–172
| last = Smale
| first = Steve
|author2=Ding-Xuan Zhou
| title = Learning Theory Estimates via Integral Operators and Their Approximations
| journal = Constructive Approximation
| date = 2007-08-01
| citeseerx = 10.1.1.210.722
| s2cid = 5977083
}}&lt;/ref&gt;
One common choice for approximating the regression function is to use functions from a [[reproducing kernel Hilbert space]].&lt;ref name="smale_learning_2007"/&gt; These spaces can be infinite dimensional, in which they can supply solutions that overfit training sets of arbitrary size. Regularization is, therefore, especially important for these methods. One way to regularize non-parametric regression problems is to apply an early stopping rule to an iterative procedure such as gradient descent.

The early stopping rules proposed for these problems are based on analysis of upper bounds on the generalization error as a function of the iteration number. They yield prescriptions for the number of iterations to run that can be computed prior to starting the solution process.&lt;ref name="yao_early_2007"&gt;{{Cite journal
| doi = 10.1007/s00365-006-0663-2
| issn = 0176-4276
| volume = 26
| issue = 2
| pages = 289–315
| last = Yao
| first = Yuan
|author2=Lorenzo Rosasco |author3=Andrea Caponnetto
 | title = On Early Stopping in Gradient Descent Learning
| journal = Constructive Approximation
| date = 2007-08-01
| citeseerx = 10.1.1.329.2482
| s2cid = 8323954
}}&lt;/ref&gt;
&lt;ref name="raskutti_early_2011"&gt;{{Cite conference
| doi = 10.1109/Allerton.2011.6120320
| conference = 2011 49th Annual Allerton Conference on Communication, Control, and Computing (Allerton)
| pages = 1318–1325
| last = Raskutti
| first = G. |author2=M.J. Wainwright |author3=Bin Yu
| title = Early stopping for non-parametric regression: An optimal data-dependent stopping rule
| book-title = 2011 49th Annual Allerton Conference on Communication, Control, and Computing (Allerton)
| year = 2011
}}&lt;/ref&gt;

====Example: Least-squares loss====
(Adapted from Yao, Rosasco and Caponnetto, 2007&lt;ref name="yao_early_2007"/&gt;)

Let &lt;math&gt;X\subseteq\mathbb{R}^{n}&lt;/math&gt; and &lt;math&gt;Y=\mathbb{R}&lt;/math&gt;. Given a set of samples

:&lt;math&gt;\mathbf{z} = \left \{(x_{i},y_{i}) \in X \times Y: i = 1, \dots, m\right\} \in Z^{m}&lt;/math&gt;,

drawn independently from &lt;math&gt;\rho&lt;/math&gt;, minimize the functional

:&lt;math&gt;
\mathcal{E}(f) = \int_{X\times Y}\left(f(x) - y\right)^2 d\rho
&lt;/math&gt;

where, &lt;math&gt;f&lt;/math&gt; is a member of the reproducing kernel Hilbert space &lt;math&gt;\mathcal{H}&lt;/math&gt;. That is, minimize the expected risk for a Least-squares loss function. Since &lt;math&gt;\mathcal{E}&lt;/math&gt; depends on the unknown probability measure &lt;math&gt;\rho&lt;/math&gt;, it cannot be used for computation. Instead, consider the following empirical risk

:&lt;math&gt;
\mathcal{E}_{\mathbf{z}}(f) = \frac{1}{m} \sum_{i=1}^{m} \left(f(x_{i}) - y_{i}\right)^{2}.
&lt;/math&gt;

Let &lt;math&gt;f_{t}&lt;/math&gt; and &lt;math&gt;f_{t}^{\mathbf{z}}&lt;/math&gt; be the ''t''-th iterates of gradient descent applied to the expected and empirical risks, respectively, where both iterations are initialized at the origin, and both use the step size &lt;math&gt;\gamma_{t}&lt;/math&gt;. The &lt;math&gt;f_{t}&lt;/math&gt; form the ''population iteration'', which converges to &lt;math&gt;f_{\rho}&lt;/math&gt;, but cannot be used  in computation, while the &lt;math&gt;f_{t}^{\mathbf{z}}&lt;/math&gt; form the ''sample iteration'' which usually converges to an overfitting solution.

We want to control the difference between the expected risk of the sample iteration and the minimum expected risk, that is, the expected risk of the regression function:

:&lt;math&gt;\mathcal{E}(f_{t}^{\mathbf{z}}) - \mathcal{E}(f_{\rho})&lt;/math&gt;

This difference can be rewritten as the sum of two terms: the difference in expected risk between the sample and population iterations and that between the population iteration and the regression function:

:&lt;math&gt;\mathcal{E}(f_{t}^{\mathbf{z}}) - \mathcal{E}(f_{\rho}) = \left[ \mathcal{E}(f_{t}^{\mathbf{z}}) - \mathcal{E}(f_{t})\right] + \left[ \mathcal{E}(f_{t}) - \mathcal{E}(f_{\rho})\right]&lt;/math&gt;

This equation presents a [[Bias-variance dilemma|bias-variance tradeoff]], which is then solved to give an optimal stopping rule that may depend on the unknown probability distribution. That rule has associated probabilistic bounds on the generalization error. For the analysis leading to the early stopping rule and bounds, the reader is referred to the original article.&lt;ref name="yao_early_2007"/&gt; In practice, data-driven methods, e.g. cross-validation can be used to obtain an adaptive stopping rule.

===Early stopping in boosting===
[[Boosting (machine learning)|Boosting]] refers to a family of algorithms in which a set of '''weak learners''' (learners that are only slightly correlated with the true process) are combined to produce a '''strong learner'''. It has been shown, for several boosting algorithms (including [[AdaBoost]]), that regularization via early stopping can provide guarantees of [[consistency (statistics)|consistency]], that is, that the result of the algorithm approaches the true solution as the number of samples goes to infinity.&lt;ref&gt;{{Cite journal
| doi = 10.1214/aos/1079120128
| issn = 0090-5364
| volume = 32
| issue = 1
| pages = 13–29
| last = Wenxin Jiang
| title = Process consistency for AdaBoost
| journal = The Annals of Statistics
| date = February 2004
| doi-access = free
}}&lt;/ref&gt;
&lt;ref&gt;{{Cite journal
| issn = 0162-1459
| volume = 98
| issue = 462
| pages = 324–339
| last = Bühlmann
| first = Peter
|author2=Bin Yu
| title = Boosting with the L₂ Loss: Regression and Classification
| journal = Journal of the American Statistical Association
| date = 2003-06-01
| jstor = 30045243
| doi=10.1198/016214503000125
| s2cid = 123059267
}}&lt;/ref&gt;
&lt;ref&gt;{{Cite journal
| issn = 0090-5364
| volume = 33
| issue = 4
| pages = 1538–1579
| last = Tong Zhang
|author2=Bin Yu
| title = Boosting with Early Stopping: Convergence and Consistency
| journal = The Annals of Statistics
| date = 2005-08-01
| jstor = 3448617
| doi=10.1214/009053605000000255
| arxiv = math/0508276
| bibcode = 2005math......8276Z
| s2cid = 13158356
}}&lt;/ref&gt;

====L{{sub|2}}-boosting====
Boosting methods have close ties to the gradient descent methods described [[#Early stopping in non-parametric regression|above]] can be regarded as a boosting method based on the &lt;math&gt;L_{2}&lt;/math&gt; loss: ''L{{sub|2}}Boost''.&lt;ref name="yao_early_2007"/&gt;

==Validation-based early stopping==
These early stopping rules work by splitting the original training set into a new training set and a [[validation set]]. The error on the validation set is used as a proxy for the [[generalization error]] in determining when overfitting has begun. These methods are most commonly employed in the training of [[artificial neural network|neural networks]]. Prechelt gives the following summary of a naive implementation of [[holdout method|holdout]]-based early stopping as follows:&lt;ref name="prechelt_early_2012"&gt;{{Cite book
| publisher = Springer Berlin Heidelberg
| isbn = 978-3-642-35289-8
| pages = [https://archive.org/details/neuralnetworkstr00mlle/page/n60 53]–67
|editor= Grégoire Montavon |editor2=Klaus-Robert Müller |editor2-link=Klaus-Robert Müller | last = Prechelt
| first = Lutz
|author2=Geneviève B. Orr
| title = Neural Networks: Tricks of the Trade
| url = https://archive.org/details/neuralnetworkstr00mlle
| url-access = limited
| chapter = Early Stopping — But When?
| series = Lecture Notes in Computer Science
| date = 2012-01-01
| doi = 10.1007/978-3-642-35289-8_5
}}&lt;/ref&gt;

{{Quotation|1=&lt;nowiki /&gt;
# Split the training data into a training set and a validation set, e.g. in a 2-to-1 proportion.
# Train only on the training set and evaluate the per-example error on the validation set once in a while, e.g. after every fifth epoch.
# Stop training as soon as the error on the validation set is higher than it was the last time it was checked.
# Use the weights the network had in that previous step as the result of the training run.|2=Lutz Prechelt|3=''Early Stopping – But When?''}}

More sophisticated forms use [[cross-validation (statistics)|cross-validation]]&amp;nbsp;– multiple partitions of the data into training set and validation set&amp;nbsp;– instead of a single partition into a training set and validation set. Even this simple procedure is complicated in practice by the fact that the validation error may fluctuate during training, producing multiple local minima. This complication has led to the creation of many ad-hoc rules for deciding when overfitting has truly begun.&lt;ref name="prechelt_early_2012"/&gt;

==See also==
* [[Overfitting]], early stopping is one of methods used to prevent overfitting
* [[Generalization error]]
* [[Regularization (mathematics)]]
* [[Statistical learning theory]]
* [[Boosting (machine learning)]]
* [[Cross-validation (statistics)|Cross-validation]], in particular using a "validation set"
* [[Artificial neural network|Neural networks]]

==References==
{{Reflist}}

[[Category:Machine learning]]
[[Category:Artificial neural networks]]</text>
      <sha1>6yayhfe1zytz76kty49vpjxz9jwae4a</sha1>
    </revision>
  </page>
  <page>
    <title>Inductive programming</title>
    <ns>0</ns>
    <id>41644056</id>
    <revision>
      <id>992629965</id>
      <parentid>990522582</parentid>
      <timestamp>2020-12-06T08:28:00Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 50 templates: del empty params (7×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="23501" xml:space="preserve">{{Programming paradigms}}
'''Inductive programming''' ('''IP''') is a special area of [[automatic programming]], covering research from [[artificial intelligence]] and [[Computer programming|programming]], which addresses [[machine learning|learning]] of typically [[declarative programming|declarative]] ([[logic programming|logic]] or [[functional programming|functional]]) and often [[recursion|recursive]] programs from incomplete specifications, such as input/output examples or constraints.

Depending on the programming language used, there are several kinds of inductive programming. '''Inductive functional programming''', which uses functional programming languages such as [[Lisp (programming language)|Lisp]] or [[Haskell (programming language)|Haskell]], and most especially [[inductive logic programming]], which uses logic programming languages such as [[Prolog]] and other logical representations  such as [[description logics]], have been more prominent, but other (programming) language paradigms have also been used, such as [[constraint programming]] or [[probabilistic programming language|probabilistic programming]].

== Definition ==

Inductive programming incorporates all approaches which are concerned with learning programs or algorithms from incomplete ([[formal specification|formal]]) specifications. Possible inputs in an IP system are a set of training inputs and corresponding outputs or an output evaluation function, describing the desired behavior of the intended program, [[Tracing (software)|traces]] or action sequences which describe the process of calculating specific outputs, [[Constraint (mathematics)|constraints]] for the program to be induced concerning its time efficiency or its complexity, various kinds of background knowledge such as standard [[data type]]s, predefined functions to be used, program schemes or templates describing the data flow of the intended program, heuristics for guiding the search for a solution or other biases.

Output of an IP system is a program in some arbitrary programming language containing conditionals and loop or recursive control structures, or any other kind of [[Turing completeness|Turing-complete]] [[Knowledge representation and reasoning|representation]] language.

In many applications the output program must be correct with respect to the examples and partial specification,  and this leads to the consideration of inductive programming as a special area inside automatic programming or [[program synthesis]],&lt;ref&gt;{{cite journal|first1=A.W.|last1=Biermann|title=Automatic programming|editor1-first=S.C.|editor1-last=Shapiro|journal=Encyclopedia of Artificial Intelligence|pages=18–35|year=1992}}&lt;/ref&gt;&lt;ref&gt;{{cite book|first1=C.|last1=Rich|first2=R.C.|last2=Waters|title=Approaches to automatic programming|editor1-first=M.C.|editor1-last=Yovits|journal=Advances in Computers|volume=37|pages=1–57|year=1993|url=http://www.merl.com/publications/docs/TR92-04.pdf|doi=10.1016/S0065-2458(08)60402-7|isbn=9780120121373}}&lt;/ref&gt; usually opposed to 'deductive' program synthesis,&lt;ref&gt;{{cite book|editor1-first=M.L.|editor1-last=Lowry|editor2-first=R.D.|editor2-last=McCarthy|title=Automatic software design|year=1991}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|first1=Z.|last1=Manna|first2=R.|last2=Waldinger|title=Fundamentals of deductive program synthesis|journal=IEEE Trans Softw Eng|volume=18 | issue = 8|pages=674–704|year=1992|doi=10.1109/32.153379|citeseerx=10.1.1.51.817}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|first1=P.|last1=Flener|title=Achievements and prospects of program synthesis|editor1-first=A.|editor1-last=Kakas|editor2-first=F.|editor2-last=Sadri|journal=Computational Logic: Logic Programming and Beyond; Essays in Honour of Robert A. Kowalski|volume=LNAI 2407|pages=310–346|year=2002|doi=10.1007/3-540-45628-7_13|series=Lecture Notes in Computer Science|isbn=978-3-540-43959-2}}&lt;/ref&gt; where the specification is usually complete.

In other cases, inductive programming is seen as a more general area where any declarative programming or representation language can be used and we may even have some degree of error in the examples, as in general [[machine learning]], the more specific area of [[structure mining]] or the area of [[symbolic artificial intelligence]]. A distinctive feature is the number of examples or partial specification needed. Typically, inductive programming techniques can learn from just a few examples.

The diversity of inductive programming usually comes from the applications and the languages that are used: apart from logic programming and functional programming, other programming paradigms and representation languages have been used or suggested in inductive programming, such as [[functional logic programming]], [[constraint programming]], [[probabilistic programming language|probabilistic programming]], [[abductive logic programming]], [[modal logic]], [[action language]]s, agent languages and many types of [[imperative languages]].

== History ==

Research on the inductive synthesis of recursive functional programs started in the early 1970s and was brought onto firm theoretical foundations with the seminal THESIS system of Summers&lt;ref&gt;{{cite journal|first1=P.D.|last1=Summers|title=A methodology for LISP program construction from examples|journal=J ACM|volume=24 | issue = 1|pages=161–175|year=1977|doi=10.1145/321992.322002}}&lt;/ref&gt; and work of Biermann.&lt;ref&gt;{{cite journal|first1=A.W.|last1=Biermann|title=The inference of regular LISP programs from examples|journal=IEEE Trans Syst Man Cybern|volume=8 | issue = 8|pages=585–600|year=1978|doi=10.1109/tsmc.1978.4310035}}&lt;/ref&gt;
These approaches were split into two phases: first, input-output examples are transformed into non-recursive programs (traces) using a small set of basic operators; second, regularities in the traces are searched for and used to fold them into a recursive program.  The main results until the mid 1980s are surveyed by Smith.&lt;ref&gt;{{cite journal|first1=D.R.|last1=Smith|title=The synthesis of LISP programs from examples: a survey|editor1-first=A.W.|editor1-last=Biermann|editor2-first=G.|editor2-last=Guiho|journal=Automatic Program Construction Techniques|pages=307–324|year=1984|url=https://www.researchgate.net/publication/239059541}}&lt;/ref&gt; Due to limited progress with respect to the range of programs that could be synthesized, research activities decreased significantly in the next decade.

The advent of logic programming brought a new elan but also a new direction in the early 1980s, especially due to the MIS system of Shapiro&lt;ref&gt;{{cite book|first1=E.Y.|last1=Shapiro|title=Algorithmic program debugging|publisher=The MIT Press|year=1983}}&lt;/ref&gt; eventually spawning the new field of inductive logic programming (ILP).&lt;ref&gt;{{Cite journal | last1 = Muggleton | first1 = S. | title = Inductive logic programming | doi = 10.1007/BF03037089 | journal = New Generation Computing | volume = 8 | issue = 4 | pages = 295–318 | year = 1991 | citeseerx = 10.1.1.329.5312 }}&lt;/ref&gt; The early works of Plotkin,&lt;ref&gt;{{cite journal|first1=Gordon D.|last1=Plotkin|title=A Note on Inductive Generalization|editor1-first=B.|editor1-last=Meltzer|editor2-first=D.|editor2-last=Michie|journal=Machine Intelligence|volume=5|pages=153–163|year=1970|url=http://homepages.inf.ed.ac.uk/gdp/publications/MI5_note_ind_gen.pdf}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|first1=Gordon D.|last1=Plotkin|title=A Further Note on Inductive Generalization|editor1-first=B.|editor1-last=Meltzer|editor2-first=D.|editor2-last=Michie|journal=Machine Intelligence|volume=6|pages=101–124|year=1971}}&lt;/ref&gt; and his "''relative least general generalization (rlgg)''", had an enormous impact in inductive logic programming. Most of ILP work addresses a wider class of problems, as the focus is not only on recursive logic programs but on machine learning of symbolic hypotheses from logical representations. However, there were some encouraging results on learning recursive Prolog programs such as quicksort from examples together with suitable background knowledge, for example with GOLEM.&lt;ref&gt;{{cite journal|first1=S.H.|last1=Muggleton|first2=C.|last2=Feng|s2cid=14992676|title=Efficient induction of logic programs|journal=Proceedings of the Workshop on Algorithmic Learning Theory|volume=6|pages=368–381|year=1990}}&lt;/ref&gt; But again, after initial success, the community got disappointed by limited progress about the induction of recursive programs&lt;ref&gt;{{cite journal
|first1=J.R.|last1=Quinlan|first2=R.M.|last2=Cameron-Jones
|s2cid=11138624|title=Avoiding Pitfalls When Learning Recursive Theories
|journal=IJCAI
|pages=1050–1057
|year=1993
}}
&lt;/ref&gt;&lt;ref&gt;
{{cite journal
|first1=J.R.|last1=Quinlan|first2=R.M.|last2=Cameron-Jones
|title=Induction of logic programs: FOIL and related systems
|publisher=Springer
|volume=13 |issue=3–4|pages=287–312
|year=1995
|url=http://dottorato.di.uniba.it/dottoratoXXVI/dm/FOILvsRelatedSystems.pdf}}
&lt;/ref&gt;&lt;ref&gt;
{{cite journal
|first1=P.|last1=Flener|first2=S.|last2=Yilmaz
|title=Inductive synthesis of recursive logic programs: Achievements and prospects
|journal=The Journal of Logic Programming
|volume=41 | issue = 2
|pages=141–195
|year=1999|doi=10.1016/s0743-1066(99)00028-x}}
&lt;/ref&gt; with ILP less and less focusing on recursive programs and leaning more and more towards a machine learning setting with applications in [[relational data mining]] and knowledge discovery.&lt;ref&gt;{{citation|first1=Sašo|last1=Džeroski|contribution=Inductive Logic Programming and Knowledge Discovery in Databases|pages=117–152|editor1-first=U.M.|editor1-last=Fayyad|editor2-first=G.|editor2-last=Piatetsky-Shapiro|editor3-first=P.|editor3-last=Smith|editor4-first=R.|editor4-last=Uthurusamy|title=Advances in Knowledge Discovery and Data Mining|publisher=MIT Press|year=1996}}&lt;/ref&gt;

In parallel to work in ILP, Koza&lt;ref&gt;
{{cite book
|first1=J.R.|last1=Koza
|title=Genetic Programming: vol. 1, On the programming of computers by means of natural selection
|publisher=MIT Press
|year=1992
|url=https://books.google.com/books?id=Bhtxo60BV0EC|isbn=9780262111706
}}
&lt;/ref&gt; proposed [[genetic programming]] in the early 1990s as a generate-and-test based approach to learning programs. The idea of genetic programming was further developed into the inductive programming system ADATE&lt;ref&gt;
{{cite journal
|first1=J.R.|last1=Olsson
|title=Inductive functional programming using incremental program transformation
|journal=Artificial Intelligence
|volume=74 | issue = 1|pages=55–83
|year=1995|doi=10.1016/0004-3702(94)00042-y}}
&lt;/ref&gt; and the systematic-search-based system MagicHaskeller.&lt;ref&gt;
{{cite book
|first1=Susumu|last1=Katayama
|title=Efficient exhaustive generation of functional programs using Monte-Carlo search with iterative deepening
|journal=PRICAI 2008: Trends in Artificial Intelligence
|volume=5351
|pages=199–210
|year=2008
|url=http://nautilus.cs.miyazaki-u.ac.jp/~skata/skatayama_pricai2008.pdf|doi=10.1007/978-3-540-89197-0_21
|citeseerx=10.1.1.606.1447
|series=Lecture Notes in Computer Science
|isbn=978-3-540-89196-3
}}
&lt;/ref&gt; Here again, functional programs are learned from sets of positive examples together with an output evaluation (fitness) function which specifies the desired input/output behavior of the program to be learned.

The early work in [[grammar induction]] (also known as grammatical inference) is related to inductive programming, as rewriting systems or logic programs can be used to represent production rules. In fact, early works in inductive inference considered grammar induction and Lisp program inference as basically the same problem.&lt;ref&gt;
{{cite journal
|first1=D.|last1=Angluin|first2=Smith|last2=C.H.
|title=Inductive inference: Theory and methods
|journal=ACM Computing Surveys
|volume=15|issue=3|pages=237–269
|year=1983|doi=10.1145/356914.356918}}
&lt;/ref&gt; The results in terms of learnability were related to classical concepts, such as identification-in-the-limit, as introduced in the seminal work of Gold.&lt;ref&gt;
{{cite journal
 |first1=E.M. 
 |last1=Gold 
 |title=Language identification in the limit 
 |journal=Information and Control 
 |volume=10 
 |issue=5 
 |pages=447–474 
 |year=1967 
 |doi=10.1016/s0019-9958(67)91165-5 
 |doi-access=free 
 }}
&lt;/ref&gt; More recently, the language learning problem was addressed by the inductive programming community.&lt;ref&gt;{{cite journal|first1=Stephen|last1=Muggleton|title=Inductive Logic Programming: Issues, Results and the Challenge of Learning Language in Logic|journal=Artificial Intelligence|volume=114|issue=1–2|pages=283–296|year=1999|doi=10.1016/s0004-3702(99)00067-3}}; here: Sect.2.1&lt;/ref&gt;&lt;ref&gt;
{{cite journal
|first1=J.R.|last1=Olsson|first2=D.M.W.|last2=Powers
|title=Machine learning of human language through automatic programming
|journal=Proceedings of the International Conference on Cognitive Science
|pages=507–512
|year=2003}}
&lt;/ref&gt;

In the recent years, the classical approaches have been resumed and advanced with great success. Therefore, the synthesis problem has been reformulated on the background of constructor-based term rewriting systems taking into account modern techniques of functional programming, as well as moderate use of search-based strategies and usage of background knowledge as well as automatic invention of subprograms. Many new and successful applications have recently appeared beyond program synthesis, most especially in the area of data manipulation, programming by example and cognitive modelling (see below).

Other ideas have also been explored with the common characteristic of using declarative languages for the representation of hypotheses. For instance, the use of higher-order features, schemes or structured distances have been advocated for a better handling of [[recursive data type]]s and structures;&lt;ref&gt;
{{cite journal
|first1=J.W.|last1=Lloyd
|title=Knowledge Representation, Computation, and Learning in Higher-order Logic
|year=2001
|url=http://users.cecs.anu.edu.au/~jwl/logic.pdf}}
&lt;/ref&gt;&lt;ref&gt;
{{cite book
|first1=J.W.|last1=Lloyd
|title=Logic for learning: learning comprehensible theories from structured data
|publisher=Springer
|year=2003
|url=https://books.google.com/books?id=8dioCAAAQBAJ|isbn=9783662084069
}}
&lt;/ref&gt;&lt;ref&gt;
{{cite journal
|first1=V.|last1=Estruch|first2=C.|last2=Ferri|first3=J.|last3=Hernandez-Orallo|first4=M.J.|last4=Ramirez-Quintana
|s2cid=7255690|title=Bridging the gap between distance and generalization
|journal=Computational Intelligence
|volume=30|issue=3|pages=473–513|year=2014
|doi=10.1111/coin.12004}}
&lt;/ref&gt; abstraction has also been explored as a more powerful approach to [[cumulative learning]] and function invention.&lt;ref&gt;
{{cite journal
|first1=R.J.|last1=Henderson|first2=S.H.|last2=Muggleton
|title=Automatic invention of functional abstractions
|journal=Advances in Inductive Logic Programming
|year=2012
|url=http://ilp11.doc.ic.ac.uk/short_papers/ilp2011_submission_62.pdf}}
&lt;/ref&gt;&lt;ref&gt;
{{cite arXiv
|first1=H.|last1=Irvin|first2=A.|last2=Stuhlmuller|first3=N.D.|last3=Goodman
|title=Inducing probabilistic programs by Bayesian program merging|eprint=1110.5667
|year=2011|class=cs.AI}}
&lt;/ref&gt;

One powerful paradigm that has been recently used for the representation of hypotheses in inductive programming (generally in the form of [[generative model]]s) is [[probabilistic programming language|probabilistic programming]] (and related paradigms, such as stochastic logic programs and Bayesian logic programming).&lt;ref&gt;
{{cite journal
|first1=S.|last1=Muggleton
|title=Learning stochastic logic programs
|journal=Electron. Trans. Artif. Intell.
|volume=4(B)
|pages=141–153
|year=2000
|url=https://ocs.aaai.org/Papers/Workshops/2000/WS-00-06/WS00-06-006.pdf}}
&lt;/ref&gt;&lt;ref&gt;
{{cite book
|first1=L.|last1=De Raedt|first2=K.|last2=Kersting
|title=Probabilistic inductive logic programming
|publisher=Springer
|year=2008}}
&lt;/ref&gt;&lt;ref&gt;
{{cite arXiv
|first1=H.|last1=Irvin|first2=A.|last2=Stuhlmuller|first3=N.D.|last3=Goodman
|title=Inducing probabilistic programs by Bayesian program merging|eprint=1110.5667
|year=2011|class=cs.AI}}
&lt;/ref&gt;&lt;ref name="Reasoning about reasoning by nested conditioning: Modeling theory of mind with probabilistic programs"&gt;
{{cite journal
|first1=A.|last1=Stuhlmuller|first2=N.D.|last2=Goodman
|s2cid=7602205|title=Reasoning about reasoning by nested conditioning: Modeling theory of mind with probabilistic programs
|journal=Cognitive Systems Research
|year=2012
|volume=28|pages=80–99|doi=10.1016/j.cogsys.2013.07.003}}
&lt;/ref&gt;

== Application areas ==

The [http://www.cogsys.wiai.uni-bamberg.de/aaip05/objectives.html first workshop on Approaches and Applications of Inductive Programming (AAIP) ] held in conjunction with [[ICML]] 2005 identified all applications where "learning of programs or recursive rules are called for, [...] first in the domain of software engineering where structural learning, software assistants and software agents can help to relieve programmers from routine tasks, give programming support for end users, or support of novice programmers and programming tutor systems. Further areas of application are language learning, learning recursive control rules for AI-planning, learning recursive concepts in web-mining or for data-format transformations".

Since then, these and many other areas have shown to be successful application niches for inductive programming, such as [[End-user development|end-user programming]],&lt;ref&gt;
{{cite book
|first1=H.|last1=Lieberman|first2=F.|last2=Paternò|first3=V.|last3=Wulf
|title=End user development
|publisher=Springer
|year=2006}}
&lt;/ref&gt; the related areas of [[programming by example]]&lt;ref&gt;
{{cite book
|first1=H.|last1=Lieberman
|title=Your wish is my command: Programming by example
|publisher=Morgan Kaufmann
|year=2001
|url=https://books.google.com/books?id=wM2JYafw11gC|isbn=9781558606883
}}
&lt;/ref&gt; and [[programming by demonstration]],&lt;ref&gt;
{{Cite book
|first1=E.|last1=Cypher|first2=D.C.|last2=Halbert
|title=Watch what I do: programming by demonstration 
|year=1993
|url=https://books.google.com/books?id=Ggzjo0-W1y0C|isbn=9780262032131}}
&lt;/ref&gt; and [[intelligent tutoring system]]s.

Other areas where inductive inference has been recently applied are [[knowledge acquisition]],&lt;ref&gt;
{{cite journal
|first1=U.|last1=Schmid|first2=M.|last2=Hofmann|first3=E.|last3=Kitzelmann
|title=Analytical inductive programming as a cognitive rule acquisition devise
|journal=Proceedings of the Second Conference on Artificial General Intelligence
|pages=162–167
|year=2009
|url=http://www.cogsys.wiai.uni-bamberg.de/publications/cognigor-final.pdf}}
&lt;/ref&gt; [[artificial general intelligence]],&lt;ref&gt;
{{cite journal
|first1=N.|last1=Crossley|first2=E.|last2=Kitzelmann|first3=M.|last3=Hofmann|first4=U.|last4=Schmid
|title=Combining analytical and evolutionary inductive programming
|journal=Proceedings of the Second Conference on Artificial General Intelligence
|pages=19–24
|year=2009
|url=https://download.atlantis-press.com/article/1824.pdf}}
&lt;/ref&gt; [[reinforcement learning]] and theory evaluation,&lt;ref&gt;
{{cite journal
|first1=J.|last1=Hernandez-Orallo
|title=Constructive reinforcement learning
|journal=International Journal of Intelligent Systems
|volume=15 | issue = 3|pages=241–264
|year=2000
|doi=10.1002/(sici)1098-111x(200003)15:3&lt;241::aid-int6&gt;3.0.co;2-z|citeseerx=10.1.1.34.8877
}}
&lt;/ref&gt;&lt;ref&gt;
{{cite journal
|first1=C.|last1=Kemp|first2=N.|last2=Goodman|first3=J.B.|last3=Tenenbaum
|title=Learning and using relational theories
|journal=Advances in Neural Information Processing Systems
|pages=753–760
|year=2007
|url=http://papers.nips.cc/paper/3332-learning-and-using-relational-theories.pdf}}
&lt;/ref&gt; and [[cognitive science]] in general.&lt;ref&gt;
{{cite journal
|first1=U.|last1=Schmid|first2=E.|last2=Kitzelmann
|title=Inductive rule learning on the knowledge level
|journal=Cognitive Systems Research
|volume=12 | issue = 3
|pages=237–248
|year=2011|doi=10.1016/j.cogsys.2010.12.002}}
&lt;/ref&gt;&lt;ref name="Reasoning about reasoning by nested conditioning: Modeling theory of mind with probabilistic programs"/&gt; There may also be prospective applications in intelligent agents, games, robotics, personalisation, ambient intelligence and human interfaces.

== See also ==
* [[Evolutionary programming]]
* [[Inductive reasoning]]
* [[Test-driven development]]&lt;!-- starting with input/output examples and manually producing a program that satisfies them --&gt;

== References ==
{{reflist}}

== Further reading ==
{{Refbegin}}

* {{cite journal|first1=P.|last1=Flener|first2=U.|last2=Schmid|title=An introduction to inductive programming|journal=Artificial Intelligence Review|volume=29 | issue = 1|pages=45–62|year=2008|doi=10.1007/s10462-009-9108-7}}
* {{cite book|first1=E.|last1=Kitzelmann|title=Inductive programming: A survey of program synthesis techniques|journal=Approaches and Applications of Inductive Programming|volume=5812|pages=50–73|year=2010|url=http://emanuel.kitzelmann.org/documents/publications/Kitzelmann2010.pdf|doi=10.1007/978-3-642-11931-6_3|citeseerx=10.1.1.180.1237|series=Lecture Notes in Computer Science|isbn=978-3-642-11930-9}}
* {{cite journal|first1=D.|last1=Partridge|title=The case for inductive programming|journal=Computer|volume=30 | issue = 1|pages=36–41|year=1997|doi=10.1109/2.562924}}
* {{cite journal|first1=P.|last1=Flener|first2=D.|last2=Partridge|title=Inductive Programming|journal=Automated Software Engineering|volume=8 | issue = 2|pages=131–137|year=2001|doi=10.1023/a:1008797606116}}
* {{cite journal|first1=M.|last1=Hofmann|first2=E.|last2=Kitzelmann|title=A unifying framework for analysis and evaluation of inductive programming systems|journal=Proceedings of the Second Conference on Artificial General Intelligence|pages=55–60|year=2009|url=http://www.atlantis-press.com/php/download_paper.php?id=1839}}
* {{Cite journal | last1 = Muggleton | first1 = S. | last2 = De Raedt | doi = 10.1016/0743-1066(94)90035-3 | first2 = L. | title = Inductive Logic Programming: Theory and methods | journal = The Journal of Logic Programming | volume = 19-20 | pages = 629–679 | year = 1994 }}
* {{cite book | first1 = N. | last1 = Lavrac | first2 = S. | last2 = Dzeroski | title = Inductive Logic Programming: Techniques and Applications | publisher = Ellis Horwood | location = New York | year = 1994 | isbn = 978-0-13-457870-5  }} https://web.archive.org/web/20040906084947/http://www-ai.ijs.si/SasoDzeroski/ILPBook/
* {{cite journal|first1=S.|last1=Muggleton|first2=Luc.|last2=De Raedt|first3=D.|last3=Poole|first4=I.|last4=Bratko|first5=P.|last5=Flach|first6=K.|last6=Inoue|first7=A.|last7=Srinivasan|title=ILP turns 20|journal=Machine Learning|volume=86 | issue = 1|pages=3–23|year=2012|doi=10.1007/s10994-011-5259-2|doi-access=free}}
* {{cite journal|first1=S.|last1=Gulwani|first2=J.|last2=Hernandez-Orallo|first3=E.|last3=Kitzelmann|first4=S.H.|last4=Muggleton|first5=U.|last5=Schmid|first6=B.|last6=Zorn|title=Inductive Programming Meets the Real World|journal=Communications of the ACM|volume=58 | issue = 11|pages=90–99|year=2015|doi=10.1145/2736282|url=http://cacm.acm.org/magazines/2015/11/193326-inductive-programming-meets-the-real-world/abstract|citeseerx=10.1.1.696.3800|hdl=10251/64984}}

== External links ==
* [http://www.inductive-programming.org/ Inductive Programming community page], hosted by the University of Bamberg.

[[Category:Programming paradigms]]
[[Category:Machine learning]]
[[Category:Logic programming]]
[[Category:Artificial intelligence]]</text>
      <sha1>ckqnc1e6pvbme4rjljnen3j7256if2c</sha1>
    </revision>
  </page>
  <page>
    <title>Proximal gradient methods for learning</title>
    <ns>0</ns>
    <id>41200806</id>
    <revision>
      <id>976430106</id>
      <parentid>950342601</parentid>
      <timestamp>2020-09-02T21:30:08Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>[[Christine De Mol]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="20195" xml:space="preserve">'''Proximal gradient''' (forward backward splitting) '''methods for learning''' is an area of research in [[optimization]] and [[statistical learning theory]] which studies algorithms for a general class of [[Convex function#Definition|convex]] [[Regularization (mathematics)|regularization]] problems where the regularization penalty may not be [[Differentiable function|differentiable]]. One such example is &lt;math&gt;\ell_1&lt;/math&gt; regularization (also known as Lasso) of the form
:&lt;math&gt;\min_{w\in\mathbb{R}^d} \frac{1}{n}\sum_{i=1}^n (y_i- \langle w,x_i\rangle)^2+ \lambda \|w\|_1, \quad \text{ where } x_i\in \mathbb{R}^d\text{ and } y_i\in\mathbb{R}.&lt;/math&gt;

Proximal gradient methods offer a general framework for solving regularization problems from statistical learning theory with penalties that are tailored to a specific problem application.&lt;ref name=combettes&gt;{{cite journal|last=Combettes|first=Patrick L.|author2=Wajs, Valérie R. |title=Signal Recovering by Proximal Forward-Backward Splitting|journal=Multiscale Model. Simul.|year=2005|volume=4|issue=4|pages=1168–1200|doi=10.1137/050626090|url=https://semanticscholar.org/paper/56974187b4d9a8757f4d8a6fd6facc8b4ad08240}}&lt;/ref&gt;&lt;ref name=structSparse&gt;{{cite journal|last=Mosci|first=S.|author2=Rosasco, L. |author3=Matteo, S. |author4=Verri, A. |author5=Villa, S. |title=Solving Structured Sparsity Regularization with Proximal Methods|journal=Machine Learning and Knowledge Discovery in Databases|year=2010|volume=6322|pages=418–433 |doi=10.1007/978-3-642-15883-4_27|series=Lecture Notes in Computer Science|isbn=978-3-642-15882-7|doi-access=free}}&lt;/ref&gt; Such customized penalties can help to induce certain structure in problem solutions, such as ''sparsity'' (in the case of [[Lasso (statistics)|lasso]]) or ''group structure'' (in the case of  [[Lasso (statistics)#Group LASSO|group lasso]]).

== Relevant background ==

[[Proximal gradient method]]s are applicable in a wide variety of scenarios for solving [[convex optimization]] problems of the form
:&lt;math&gt; \min_{x\in \mathcal{H}} F(x)+R(x),&lt;/math&gt;
where &lt;math&gt;F&lt;/math&gt; is [[Convex function|convex]] and differentiable with [[Lipschitz continuity|Lipschitz continuous]] [[gradient]], &lt;math&gt; R&lt;/math&gt; is a [[Convex function|convex]], [[Semicontinuous function|lower semicontinuous]] function which is possibly nondifferentiable, and &lt;math&gt;\mathcal{H}&lt;/math&gt; is some set, typically a [[Hilbert space]]. The usual criterion of &lt;math&gt; x&lt;/math&gt; minimizes &lt;math&gt; F(x)+R(x)&lt;/math&gt; if and only if &lt;math&gt; \nabla (F+R)(x) = 0&lt;/math&gt; in the convex, differentiable setting is now replaced by
:&lt;math&gt; 0\in \partial (F+R)(x), &lt;/math&gt;
where &lt;math&gt;\partial \varphi&lt;/math&gt; denotes the [[subdifferential]] of a real-valued, convex function &lt;math&gt; \varphi&lt;/math&gt;.

Given a convex function &lt;math&gt;\varphi:\mathcal{H} \to \mathbb{R}&lt;/math&gt; an important operator to consider is its '''proximity operator''' &lt;math&gt;\operatorname{prox}_{\varphi}:\mathcal{H}\to\mathcal{H} &lt;/math&gt; defined by
:&lt;math&gt; \operatorname{prox}_{\varphi}(u) = \operatorname{arg}\min_{x\in\mathcal{H}} \varphi(x)+\frac{1}{2}\|u-x\|_2^2,&lt;/math&gt;
which is well-defined because of the strict convexity of the &lt;math&gt; \ell_2&lt;/math&gt; norm. The proximity operator can be seen as a generalization of a [[Projection (linear algebra)|projection]].&lt;ref name=combettes /&gt;&lt;ref name=moreau /&gt;&lt;ref name=bauschke&gt;{{cite book|last=Bauschke|first=H.H., and Combettes, P.L.|title=Convex analysis and monotone operator theory in Hilbert spaces|year=2011|publisher=Springer}}&lt;/ref&gt;
We see that the proximity operator is important because &lt;math&gt; x^* &lt;/math&gt; is a minimizer to the problem &lt;math&gt; \min_{x\in\mathcal{H}} F(x)+R(x)&lt;/math&gt; if and only if
:&lt;math&gt;x^* = \operatorname{prox}_{\gamma R}\left(x^*-\gamma\nabla F(x^*)\right),&lt;/math&gt; where &lt;math&gt;\gamma&gt;0&lt;/math&gt; is any positive real number.&lt;ref name=combettes /&gt;

=== Moreau decomposition ===

One important technique related to proximal gradient methods is the '''Moreau decomposition,''' which decomposes the identity operator as the sum of two proximity operators.&lt;ref name=combettes /&gt; Namely, let &lt;math&gt;\varphi:\mathcal{X}\to\mathbb{R}&lt;/math&gt; be a [[Semi-continuity|lower semicontinuous]], convex function on a vector space &lt;math&gt;\mathcal{X}&lt;/math&gt;. We define its [[Convex conjugate|Fenchel conjugate]] &lt;math&gt;\varphi^*:\mathcal{X}\to\mathbb{R}&lt;/math&gt; to be the function
:&lt;math&gt;\varphi^*(u) := \sup_{x\in\mathcal{X}} \langle x,u\rangle - \varphi(x).&lt;/math&gt;
The general form of Moreau's decomposition states that for any &lt;math&gt;x\in\mathcal{X}&lt;/math&gt; and any &lt;math&gt;\gamma&gt;0&lt;/math&gt; that
:&lt;math&gt;x = \operatorname{prox}_{\gamma \varphi}(x) + \gamma\operatorname{prox}_{\varphi^*/\gamma}(x/\gamma),&lt;/math&gt;
which for &lt;math&gt;\gamma=1&lt;/math&gt; implies that &lt;math&gt;x = \operatorname{prox}_{\varphi}(x)+\operatorname{prox}_{\varphi^*}(x)&lt;/math&gt;.&lt;ref name=combettes /&gt;&lt;ref name=moreau&gt;{{cite journal|last=Moreau|first=J.-J.|title=Fonctions convexes duales et points proximaux dans un espace hilbertien|journal=Comptes Rendus de l'Académie des Sciences, Série A|year=1962|volume=255|pages=2897–2899|mr=144188|zbl=0118.10502}}&lt;/ref&gt; The Moreau decomposition can be seen to be a generalization of the usual orthogonal decomposition of a vector space, analogous with the fact that proximity operators are generalizations of projections.&lt;ref name=combettes /&gt;

In certain situations it may be easier to compute the proximity operator for the conjugate &lt;math&gt;\varphi^*&lt;/math&gt; instead of the function &lt;math&gt;\varphi&lt;/math&gt;, and therefore the Moreau decomposition can be applied. This is the case for  [[Lasso (statistics)#Group LASSO|group lasso]].

== Lasso regularization ==

Consider the [[Regularization (mathematics)|regularized]] [[empirical risk minimization]] problem with square loss and with the [[L1-norm|&lt;math&gt;\ell_1&lt;/math&gt; norm]] as the regularization penalty:
:&lt;math&gt;\min_{w\in\mathbb{R}^d} \frac{1}{n}\sum_{i=1}^n (y_i- \langle w,x_i\rangle)^2+ \lambda \|w\|_1, &lt;/math&gt;
where &lt;math&gt;x_i\in \mathbb{R}^d\text{ and } y_i\in\mathbb{R}.&lt;/math&gt; The &lt;math&gt;\ell_1&lt;/math&gt; regularization problem is sometimes referred to as ''lasso'' ([[Lasso (statistics)|least absolute shrinkage and selection operator]]).&lt;ref name=tibshirani /&gt; Such &lt;math&gt;\ell_1&lt;/math&gt; regularization problems are interesting because they induce '' sparse'' solutions, that is, solutions &lt;math&gt;w&lt;/math&gt; to the minimization problem have relatively few nonzero components. Lasso can be seen to be a convex relaxation of the non-convex problem
:&lt;math&gt;\min_{w\in\mathbb{R}^d} \frac{1}{n}\sum_{i=1}^n (y_i- \langle w,x_i\rangle)^2+ \lambda \|w\|_0, &lt;/math&gt;
where &lt;math&gt;\|w\|_0&lt;/math&gt; denotes the &lt;math&gt;\ell_0&lt;/math&gt; "norm", which is the number of nonzero entries of the vector &lt;math&gt;w&lt;/math&gt;. Sparse solutions are of particular interest in learning theory for interpretability of results: a sparse solution can identify a small number of important factors.&lt;ref name=tibshirani&gt;{{cite journal|last=Tibshirani|first=R.|title=Regression shrinkage and selection via the lasso|journal=J. R. Stat. Soc. Ser. B|year=1996|volume=58|series=1|issue=1|pages=267–288}}&lt;/ref&gt;

=== Solving for &lt;math&gt;\ell_1&lt;/math&gt; proximity operator ===

For simplicity we restrict our attention to the problem where &lt;math&gt;\lambda=1&lt;/math&gt;. To solve the problem
:&lt;math&gt;\min_{w\in\mathbb{R}^d} \frac{1}{n}\sum_{i=1}^n (y_i- \langle w,x_i\rangle)^2+  \|w\|_1, &lt;/math&gt;
we consider our objective function in two parts: a convex, differentiable term &lt;math&gt;F(w) = \frac{1}{n}\sum_{i=1}^n (y_i- \langle w,x_i\rangle)^2&lt;/math&gt; and a convex function &lt;math&gt;R(w) = \|w\|_1&lt;/math&gt;. Note that &lt;math&gt;R&lt;/math&gt; is not strictly convex.

Let us compute the proximity operator for &lt;math&gt;R(w)&lt;/math&gt;. First we find an alternative characterization of the proximity operator &lt;math&gt;\operatorname{prox}_{R}(x)&lt;/math&gt; as follows:

&lt;math&gt;
\begin{align}
u = \operatorname{prox}_R(x) \iff &amp; 0\in \partial \left(R(u)+\frac{1}{2}\|u-x\|_2^2\right)\\
\iff &amp; 0\in \partial R(u) + u-x\\
\iff &amp; x-u\in \partial R(u).
\end{align}
&lt;/math&gt;

For &lt;math&gt;R(w) = \|w\|_1&lt;/math&gt; it is easy to compute &lt;math&gt;\partial R(w)&lt;/math&gt;: the &lt;math&gt;i&lt;/math&gt;th entry of &lt;math&gt;\partial R(w)&lt;/math&gt; is precisely

:&lt;math&gt; \partial |w_i| = \begin{cases}
1,&amp;w_i&gt;0\\
-1,&amp;w_i&lt;0\\
\left[-1,1\right],&amp;w_i = 0.
\end{cases}&lt;/math&gt;

Using the recharacterization of the proximity operator given above, for the choice of &lt;math&gt;R(w) = \|w\|_1&lt;/math&gt; and &lt;math&gt;\gamma&gt;0&lt;/math&gt; we have that &lt;math&gt;\operatorname{prox}_{\gamma R}(x)&lt;/math&gt; is defined entrywise by

::&lt;math&gt;\left(\operatorname{prox}_{\gamma R}(x)\right)_i = \begin{cases}
x_i-\gamma,&amp;x_i&gt;\gamma\\
0,&amp;|x_i|\leq\gamma\\
x_i+\gamma,&amp;x_i&lt;-\gamma,
\end{cases}&lt;/math&gt;

which is known as the [[Thresholding (image processing)|soft thresholding]] operator &lt;math&gt;S_{\gamma}(x)=\operatorname{prox}_{\gamma \|\cdot\|_1}(x)&lt;/math&gt;.&lt;ref name=combettes /&gt;&lt;ref name=daubechies&gt;{{cite journal|last=Daubechies|first=I. |author2=Defrise, M. |author3=De Mol, C.|author3-link= Christine De Mol |title=An iterative thresholding algorithm for linear inverse problem with a sparsity constraint|journal=Comm. Pure Appl. Math.|year=2004|volume=57|issue=11|pages=1413–1457|doi=10.1002/cpa.20042|arxiv=math/0307152}}&lt;/ref&gt;

=== Fixed point iterative schemes ===

To finally solve the lasso problem we consider the fixed point equation shown earlier:
:&lt;math&gt;x^* = \operatorname{prox}_{\gamma R}\left(x^*-\gamma\nabla F(x^*)\right).&lt;/math&gt;

Given that we have computed the form of the proximity operator explicitly, then we can define a standard fixed point iteration procedure. Namely, fix some initial &lt;math&gt;w^0\in\mathbb{R}^d&lt;/math&gt;, and for &lt;math&gt;k=1,2,\ldots&lt;/math&gt; define
:&lt;math&gt;w^{k+1} = S_{\gamma}\left(w^k - \gamma \nabla F\left(w^k\right)\right).&lt;/math&gt;
Note here the effective trade-off between the empirical error term &lt;math&gt;F(w) &lt;/math&gt; and the regularization penalty &lt;math&gt;R(w)&lt;/math&gt;. This  fixed point method has decoupled the effect of the two different convex functions which comprise the objective function into a gradient descent step (&lt;math&gt; w^k - \gamma \nabla F\left(w^k\right)&lt;/math&gt;) and a soft thresholding step (via &lt;math&gt;S_\gamma&lt;/math&gt;).

Convergence of this fixed point scheme is well-studied in the literature&lt;ref name=combettes /&gt;&lt;ref name=daubechies /&gt; and is guaranteed under appropriate choice of step size &lt;math&gt;\gamma&lt;/math&gt; and loss function (such as the square loss taken here). [[Gradient descent#Extensions|Accelerated methods]] were introduced by Nesterov in 1983 which improve the rate of convergence under certain regularity assumptions on &lt;math&gt;F&lt;/math&gt;.&lt;ref name=nesterov&gt;{{cite journal|last=Nesterov|first=Yurii|title=A method of solving a convex programming problem with convergence rate &lt;math&gt;O(1/k^2)&lt;/math&gt;|journal=Soviet Mathematics - Doklady|year=1983|volume=27|issue=2|pages=372–376}}&lt;/ref&gt; Such methods have been studied extensively in previous years.&lt;ref&gt;{{cite book|last=Nesterov|first=Yurii|title=Introductory Lectures on Convex Optimization|year=2004|publisher=Kluwer Academic Publisher}}&lt;/ref&gt;
For more general learning problems where the proximity operator cannot be computed explicitly for some regularization term &lt;math&gt;R&lt;/math&gt;, such fixed point schemes can still be carried out using approximations to both the gradient and the proximity operator.&lt;ref name=bauschke /&gt;&lt;ref&gt;{{cite journal|last=Villa|first=S.|author2=Salzo, S. |author3=Baldassarre, L. |author4=Verri, A. |title=Accelerated and inexact forward-backward algorithms|journal=SIAM J. Optim.|year=2013|volume=23|issue=3|pages=1607–1633|doi=10.1137/110844805|citeseerx=10.1.1.416.3633}}&lt;/ref&gt;

== Practical considerations ==

There have been numerous developments within the past decade in [[convex optimization]] techniques which have influenced the application of proximal gradient methods in statistical learning theory. Here we survey a few important topics which can greatly improve practical algorithmic performance of these methods.&lt;ref name=structSparse /&gt;&lt;ref name=bach&gt;{{cite journal|last=Bach|first=F.|author2=Jenatton, R. |author3=Mairal, J. |author4=Obozinski, Gl. |title=Optimization with sparsity-inducing penalties|journal= Foundations and Trends in Machine Learning|year=2011|volume=4|issue=1|pages=1–106|doi=10.1561/2200000015|arxiv=1108.0775|bibcode=2011arXiv1108.0775B}}&lt;/ref&gt;

=== Adaptive step size ===

In the fixed point iteration scheme
:&lt;math&gt;w^{k+1} = \operatorname{prox}_{\gamma R}\left(w^k-\gamma \nabla F\left(w^k\right)\right),&lt;/math&gt;
one can allow variable step size &lt;math&gt;\gamma_k&lt;/math&gt; instead of a constant &lt;math&gt;\gamma&lt;/math&gt;. Numerous adaptive step size schemes have been proposed throughout the literature.&lt;ref name=combettes /&gt;&lt;ref name=bauschke /&gt;&lt;ref&gt;{{cite journal|last=Loris|first=I. |author2=Bertero, M. |author3=De Mol, C. |author4=Zanella, R. |author5=Zanni, L. |title=Accelerating gradient projection methods for &lt;math&gt;\ell_1&lt;/math&gt;-constrained signal recovery by steplength selection rules|journal=Applied &amp; Comp. Harmonic Analysis|volume=27|issue=2|pages=247–254|year=2009|doi=10.1016/j.acha.2009.02.003|arxiv=0902.4424 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last=Wright|first=S.J.|author2=Nowak, R.D. |author3=Figueiredo, M.A.T. |title=Sparse reconstruction by separable approximation|journal=IEEE Trans. Image Process.|year=2009|volume=57|issue=7|pages=2479–2493|doi=10.1109/TSP.2009.2016892|bibcode=2009ITSP...57.2479W}}&lt;/ref&gt; Applications of these schemes&lt;ref name=structSparse /&gt;&lt;ref&gt;{{cite journal|last=Loris|first=Ignace|title=On the performance of algorithms for the minimization of &lt;math&gt;\ell_1&lt;/math&gt;-penalized functionals|journal=Inverse Problems|year=2009|volume=25|issue=3|doi=10.1088/0266-5611/25/3/035008|page=035008|arxiv=0710.4082|bibcode=2009InvPr..25c5008L}}&lt;/ref&gt;  suggest that these can offer substantial improvement in number of iterations required for fixed point convergence.

=== Elastic net (mixed norm regularization) ===

[[Elastic net regularization]] offers an alternative to pure &lt;math&gt;\ell_1&lt;/math&gt; regularization. The problem of lasso (&lt;math&gt;\ell_1&lt;/math&gt;) regularization involves the penalty term &lt;math&gt;R(w) = \|w\|_1&lt;/math&gt;, which is not strictly convex. Hence, solutions to &lt;math&gt;\min_w F(w) + R(w),&lt;/math&gt; where &lt;math&gt;F&lt;/math&gt; is some empirical loss function, need not be unique. This is often avoided by the inclusion of an additional strictly convex term, such as an &lt;math&gt;\ell_2&lt;/math&gt; norm regularization penalty. For example, one can consider the problem
:&lt;math&gt;\min_{w\in\mathbb{R}^d} \frac{1}{n}\sum_{i=1}^n (y_i- \langle w,x_i\rangle)^2+ \lambda \left((1-\mu)\|w\|_1+\mu \|w\|_2^2\right), &lt;/math&gt;
where &lt;math&gt;x_i\in \mathbb{R}^d\text{ and } y_i\in\mathbb{R}.&lt;/math&gt;
For &lt;math&gt;0&lt;\mu\leq 1&lt;/math&gt; the penalty term &lt;math&gt;\lambda \left((1-\mu)\|w\|_1+\mu \|w\|_2^2\right)&lt;/math&gt; is now strictly convex, and hence the minimization problem now admits a unique solution. It has been observed that for sufficiently small &lt;math&gt;\mu &gt; 0&lt;/math&gt;, the additional penalty term &lt;math&gt;\mu \|w\|_2^2&lt;/math&gt; acts as a preconditioner and can substantially improve convergence while not adversely affecting the sparsity of solutions.&lt;ref name=structSparse /&gt;&lt;ref name=deMolElasticNet&gt;{{cite journal|last=De Mol|first=C. |author2=De Vito, E. |author3=Rosasco, L.|title=Elastic-net regularization in learning theory|journal=J. Complexity|year=2009|volume=25|issue=2|pages=201–230|doi=10.1016/j.jco.2009.01.002|arxiv=0807.3423}}&lt;/ref&gt;

== Exploiting group structure ==

Proximal gradient methods provide a general framework which is applicable to a wide variety of problems in [[statistical learning theory]]. Certain problems in learning can often involve data which has additional structure that is known '' a priori''. In the past several years there have been new developments which incorporate information about group structure to provide methods which are tailored to different applications. Here we survey a few such methods.

=== Group lasso ===

Group lasso is a generalization of the [[Lasso (statistics)|lasso method]] when features are grouped into disjoint blocks.&lt;ref name=groupLasso&gt;{{cite journal|last=Yuan|first=M.|author2=Lin, Y. |title=Model selection and estimation in regression with grouped variables|journal=J. R. Stat. Soc. B|year=2006|volume=68|issue=1|pages=49–67|doi=10.1111/j.1467-9868.2005.00532.x|url=https://semanticscholar.org/paper/d98ef875e2cbde3e2cc8fad521e3cbfe1bddbd69}}&lt;/ref&gt; Suppose the features are grouped into blocks &lt;math&gt;\{w_1,\ldots,w_G\}&lt;/math&gt;. Here we take as a regularization penalty

:&lt;math&gt;R(w) =\sum_{g=1}^G \|w_g\|_2,&lt;/math&gt;

which is the sum of the &lt;math&gt;\ell_2&lt;/math&gt; norm on corresponding feature vectors for the different groups. A similar proximity operator analysis as above can be used to compute the proximity operator for this penalty. Where the lasso penalty has a proximity operator which is soft thresholding on each individual component, the proximity operator for the group lasso is soft thresholding on each group. For the group &lt;math&gt;w_g&lt;/math&gt; we have that proximity operator of &lt;math&gt;\lambda\gamma\left(\sum_{g=1}^G \|w_g\|_2\right) &lt;/math&gt; is given by

:&lt;math&gt;\widetilde{S}_{\lambda\gamma }(w_g) =  \begin{cases}
w_g-\lambda\gamma \frac{w_g}{\|w_g\|_2}, &amp; \|w_g\|_2&gt;\lambda\gamma \\
0, &amp; \|w_g\|_2\leq \lambda\gamma
\end{cases}&lt;/math&gt;

where &lt;math&gt;w_g&lt;/math&gt; is the &lt;math&gt;g&lt;/math&gt;th group.

In contrast to lasso, the derivation of the proximity operator for group lasso relies on the [[#Moreau decomposition|Moreau decomposition]]. Here the proximity operator of the conjugate of the group lasso penalty becomes a projection onto the [[Ball (mathematics)|ball]] of a [[dual norm]].&lt;ref name=structSparse /&gt;

=== Other group structures ===

In contrast to the group lasso problem, where features are grouped into disjoint blocks, it may be the case that grouped features are overlapping or have a nested structure.  Such generalizations of group lasso have been considered in a variety of contexts.&lt;ref&gt;{{cite journal|last=Chen|first=X.|author2=Lin, Q. |author3=Kim, S. |author4=Carbonell, J.G. |author5=Xing, E.P. |title=Smoothing proximal gradient method for general structured sparse regression|journal=Ann. Appl. Stat.|year=2012|volume=6|issue=2|pages=719–752|doi=10.1214/11-AOAS514|arxiv=1005.4717}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last=Mosci|first=S.|author2=Villa, S. |author3=Verri, A. |author4=Rosasco, L. |title=A primal-dual algorithm for group sparse regularization with overlapping groups|journal=NIPS|year=2010|volume=23|pages=2604–2612}}&lt;/ref&gt;&lt;ref name=nest&gt;{{cite journal|last=Jenatton|first=R. |author2=Audibert, J.-Y. |author3=Bach, F. |title=Structured variable selection with sparsity-inducing norms|journal=J. Mach. Learn. Res.|year=2011|volume=12|pages=2777–2824|bibcode=2009arXiv0904.3523J |arxiv=0904.3523 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last=Zhao|first=P.|author2=Rocha, G. |author3=Yu, B. |title=The composite absolute penalties family for grouped and hierarchical variable selection|journal=Ann. Stat.|year=2009|volume=37|issue=6A|pages=3468–3497|doi=10.1214/07-AOS584|arxiv=0909.0411|bibcode=2009arXiv0909.0411Z}}&lt;/ref&gt; For overlapping groups one common approach is known as ''latent group lasso'' which introduces latent variables to account for overlap.&lt;ref&gt;{{cite arxiv |eprint=1110.0413 |last1=Obozinski |first1=Guillaume |title=Group Lasso with Overlaps: The Latent Group Lasso approach |last2=Jacob |first2=Laurent |last3=Vert |first3=Jean-Philippe |class=stat.ML |year=2011 }}&lt;/ref&gt;&lt;ref&gt;{{cite arxiv |eprint=1209.0368|last1=Villa|first1=Silvia|title=Proximal methods for the latent group lasso penalty|last2=Rosasco|first2=Lorenzo|last3=Mosci|first3=Sofia|last4=Verri|first4=Alessandro|class=math.OC|year=2012}}&lt;/ref&gt; Nested group structures are studied in ''hierarchical structure prediction'' and with [[directed acyclic graph]]s.&lt;ref name=nest /&gt;

== See also ==
* [[Convex analysis]]
* [[Proximal gradient method]]
* [[Regularization (mathematics)#Regularization in statistics and machine learning|Regularization]]
* [[Statistical learning theory]]

== References ==

{{reflist}}

[[Category:First order methods|First order methods]]
[[Category:Convex optimization]]
[[Category:Machine learning]]</text>
      <sha1>hg4gtnysh1meawpijvlioe2z6iq4c3d</sha1>
    </revision>
  </page>
  <page>
    <title>Kernel density estimation</title>
    <ns>0</ns>
    <id>2090057</id>
    <revision>
      <id>1002901910</id>
      <parentid>1000717979</parentid>
      <timestamp>2021-01-26T15:27:47Z</timestamp>
      <contributor>
        <ip>2A02:8108:D40:1A4:31B1:1A25:A084:5EAF</ip>
      </contributor>
      <comment>ParetoDensityEstimation moved in R to another package</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="36989" xml:space="preserve">{{broader|Kernel estimation}}
[[File:Kernel density.svg|thumb|right|250px|Kernel density estimation of 100 [[normal distribution|normally distributed]] [[random number generator|random numbers]] using different smoothing bandwidths.]]
In [[statistics]], '''kernel density estimation''' ('''KDE''') is a [[non-parametric statistics|non-parametric]] way to [[density estimation|estimate]] the [[probability density function]] of a [[random variable]].  Kernel density estimation is a fundamental data smoothing problem where inferences about the [[statistical population|population]] are made, based on a finite data [[statistical sample|sample]]. In some fields such as [[signal processing]] and [[econometrics]] it is also termed the '''Parzen–Rosenblatt window''' method,  after [[Emanuel Parzen]] and [[Murray Rosenblatt]], who are usually credited with independently creating it in its current form.&lt;ref name="Ros1956"&gt;{{Cite journal | last1 = Rosenblatt | first1 = M. |author-link = Murray Rosenblatt| title = Remarks on Some Nonparametric Estimates of a Density Function | doi = 10.1214/aoms/1177728190 | journal = The Annals of Mathematical Statistics | volume = 27 | issue = 3 | pages = 832–837 | year = 1956 | doi-access = free }}&lt;/ref&gt;&lt;ref name="Par1962"&gt;{{Cite journal | last1 = Parzen | first1 = E. | author-link = Emanuel Parzen| title = On Estimation of a Probability Density Function and Mode | doi = 10.1214/aoms/1177704472 | journal = [[The Annals of Mathematical Statistics]]| volume = 33 | issue = 3 | pages = 1065–1076 | year = 1962 | jstor = 2237880| doi-access = free }}&lt;/ref&gt; One of the famous applications of kernel density estimation is in estimating the class-conditional marginal densities of data when using a [[naive Bayes classifier]],&lt;ref name=":0"&gt;{{Cite journal|last=Piryonesi S. Madeh|last2=El-Diraby Tamer E.|date=2020-06-01|title=Role of Data Analytics in Infrastructure Asset Management: Overcoming Data Size and Quality Problems|journal=Journal of Transportation Engineering, Part B: Pavements|volume=146|issue=2|pages=04020022|doi=10.1061/JPEODX.0000175}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|last=Hastie, Trevor.|title=The elements of statistical learning : data mining, inference, and prediction : with 200 full-color illustrations|date=2001|publisher=Springer|others=Tibshirani, Robert., Friedman, J. H. (Jerome H.)|isbn=0-387-95284-5|location=New York|oclc=46809224}}&lt;/ref&gt; which can improve its prediction accuracy.&lt;ref name=":0" /&gt; 

==Definition==
Let (''x''&lt;sub&gt;1&lt;/sub&gt;, ''x''&lt;sub&gt;2&lt;/sub&gt;, …, ''x&lt;sub&gt;n&lt;/sub&gt;'') be a univariate [[Independent and identically distributed random variables|independent and identically distributed]] sample drawn from some distribution with an unknown [[probability density function|density]] ''ƒ'' at any given point ''x''. We are interested in estimating the shape of this function ''ƒ''. Its ''kernel density estimator'' is
: &lt;math&gt;
    \widehat{f}_h(x) = \frac{1}{n}\sum_{i=1}^n K_h (x - x_i) = \frac{1}{nh} \sum_{i=1}^n K\Big(\frac{x-x_i}{h}\Big),
  &lt;/math&gt;
where ''K'' is the [[kernel (statistics)#In non-parametric statistics|kernel]] — a non-negative function — and {{nowrap|''h'' &gt; 0}} is a [[smoothing]] parameter called the ''bandwidth''. A kernel with subscript ''h'' is called the ''scaled kernel'' and defined as {{nowrap|''K&lt;sub&gt;h&lt;/sub&gt;''(''x'') {{=}} 1/''h K''(''x''/''h'')}}. Intuitively one wants to choose ''h'' as small as the data will allow; however, there is always a trade-off between the bias of the estimator and its variance. The choice of bandwidth is discussed in more detail below.

A range of [[kernel (statistics)#Kernel functions in common use|kernel functions]] are commonly used: uniform, triangular, biweight, triweight, Epanechnikov, normal, and others. The Epanechnikov kernel is optimal in a mean square error sense,&lt;ref&gt;{{cite journal |doi=10.1137/1114019 |author=Epanechnikov, V.A. |title=Non-parametric estimation of a multivariate probability density |journal=Theory of Probability and Its Applications |volume=14 |pages=153–158 |year=1969}}&lt;/ref&gt; though the loss of efficiency is small for the kernels listed previously.&lt;ref name="WJ1995"&gt;{{Cite book| author1=Wand, M.P |author2=Jones, M.C. |title=Kernel Smoothing |publisher=Chapman &amp; Hall/CRC |location=London |year=1995 |isbn=978-0-412-55270-0}}&lt;/ref&gt; Due to its convenient mathematical properties, the normal kernel is often used, which means {{nowrap|''K''(''x'') {{=}} ''ϕ''(''x'')}}, where ''ϕ'' is the [[standard normal]] density function.

The construction of a kernel density estimate finds interpretations in fields outside of density estimation.&lt;ref name="bo07"&gt;{{cite techreport |first=Zdravko |last=Botev |title=Nonparametric Density Estimation via Diffusion Mixing |url=https://espace.library.uq.edu.au/view/UQ:120006 |institution=University of Queensland |year=2007 }}&lt;/ref&gt; For example, in [[thermodynamics]], this is equivalent to the amount of heat generated when [[heat kernel]]s (the fundamental solution to the [[heat equation]]) are placed at each data point locations ''x&lt;sub&gt;i&lt;/sub&gt;''. Similar methods are used to construct [[discrete Laplace operator]]s on point clouds for [[manifold learning]] (e.g. [[diffusion map]]).

==Example==
Kernel density estimates are closely related to [[histograms]], but can be endowed with properties such as smoothness or continuity by using a suitable kernel. An example using 6 data points illustrates this difference between histogram and kernel density estimators:

{| class="wikitable"
|-
! Sample 
| 1 
| 2 
| 3 
| 4 
| 5 
| 6
|-
! Value 
| -2.1 
| -1.3 
| -0.4 
| 1.9 
| 5.1 
| 6.2
|}

For the histogram, first the horizontal axis is divided into sub-intervals or bins which cover the range of the data: In this case, six bins each of width 2. Whenever a data point falls inside this interval, a box of height 1/12 is placed there. If more than one data point falls inside the same bin, the boxes are stacked on top of each other.

For the kernel density estimate, a normal kernel with standard deviation 2.25 (indicated by the red dashed lines) is placed on each of the data points ''x&lt;sub&gt;i&lt;/sub&gt;''. The kernels are summed to make the kernel density estimate (solid blue curve). The smoothness of the kernel density estimate (compared to the discreteness of the histogram) illustrates how kernel density estimates converge faster to the true underlying density for continuous random variables.&lt;ref&gt;{{cite journal |author=Scott, D. |title=On optimal and data-based histograms |journal=Biometrika |year=1979 |volume=66 |pages=605–610 |doi=10.1093/biomet/66.3.605 |issue=3}}&lt;/ref&gt;

[[File:Comparison of 1D histogram and KDE.png|thumb|center|500px|alt=Comparison of the histogram (left) and kernel density estimate (right) constructed using the same data. The six individual kernels are the red dashed curves, the kernel density estimate the blue curves. The data points are the rug plot on the horizontal axis.|Comparison of the histogram (left) and kernel density estimate (right) constructed using the same data. The six individual kernels are the red dashed curves, the kernel density estimate the blue curves. The data points are the rug plot on the horizontal axis.]]

==Bandwidth selection==

[[File:Comparison of 1D bandwidth selectors.png|thumb|Kernel density estimate (KDE) with different bandwidths of a random sample of 100 points from a standard normal distribution. Grey: true density (standard normal). Red: KDE with h=0.05. Black: KDE with h=0.337. Green: KDE with h=2.]]

The bandwidth of the kernel is a [[free parameter]] which exhibits a strong influence on the resulting estimate. To illustrate its effect, we take a simulated [[Random number generator|random sample]] from the standard [[normal distribution]] (plotted at the blue spikes in the [[rug plot]] on the horizontal axis). The grey curve is the true density (a normal density with mean 0 and variance 1). In comparison, the red curve is ''undersmoothed'' since it contains too many spurious data artifacts arising from using a bandwidth ''h'' = 0.05, which is too small. The green curve is ''oversmoothed'' since using the bandwidth ''h'' = 2 obscures much of the underlying structure. The black curve with a bandwidth of ''h'' = 0.337 is considered to be optimally smoothed since its density estimate is close to the true density. An extreme situation is encountered in the limit &lt;math&gt;h \to 0&lt;/math&gt; (no smoothing), where the estimate is a sum of ''n'' [[Dirac delta function|delta functions]] centered at the coordinates of analyzed samples. In the other extreme limit &lt;math&gt;h \to \infty&lt;/math&gt; the estimate retains the shape of the used kernel, centered on the mean of the samples (completely smooth).

The most common optimality criterion used to select this parameter is the expected ''L''&lt;sub&gt;2&lt;/sub&gt; [[risk function]], also termed the [[mean integrated squared error]]:

: &lt;math&gt;\operatorname{MISE} (h) = \operatorname{E}\!\left[\, \int (\hat{f}_h(x) - f(x))^2 \, dx \right].&lt;/math&gt;

Under weak assumptions on ''ƒ''  and ''K'', (''ƒ'' is the, generally unknown, real density function),&lt;ref name="Ros1956"/&gt;&lt;ref name="Par1962"/&gt;
MISE (''h'') = AMISE(''h'') + ''o(1/(nh) + h&lt;sup&gt;4&lt;/sup&gt;)'' where ''o'' is the [[little o notation]].
The AMISE is the Asymptotic MISE which consists of the two leading terms

:&lt;math&gt;\operatorname{AMISE}(h) = \frac{R(K)}{nh} + \frac{1}{4} m_2(K)^2 h^4 R(f'')&lt;/math&gt;

where &lt;math&gt;R(g) = \int g(x)^2 \, dx&lt;/math&gt; for a function ''g'', &lt;math&gt;m_2(K) = \int x^2 K(x) \, dx&lt;/math&gt;
and ''ƒ'''' is the second derivative of ''ƒ''. The minimum of this AMISE is the solution to this differential equation

:&lt;math&gt; \frac{\partial}{\partial h} \operatorname{AMISE}(h) = -\frac{R(K)}{nh^2} +  m_2(K)^2 h^3 R(f'') = 0 &lt;/math&gt;

or

:&lt;math&gt;h_{\operatorname{AMISE}} = \frac{ R(K)^{1/5}}{m_2(K)^{2/5}R(f'')^{1/5} n^{1/5}}.&lt;/math&gt;

Neither the AMISE nor the ''h''&lt;sub&gt;AMISE&lt;/sub&gt; formulas are able to be used directly since they involve the unknown density function ''ƒ'' or its second derivative ''ƒ'''', so a variety of automatic, data-based methods have been developed for selecting the bandwidth. Many review studies have been carried out to compare their efficacies,&lt;ref&gt;{{cite journal |author1=Park, B.U. |author2=Marron, J.S. |year=1990 |title=Comparison of data-driven bandwidth selectors |journal=Journal of the American Statistical Association |volume=85 |issue=409 |pages=66–72 |jstor=2289526 |doi=10.1080/01621459.1990.10475307|citeseerx=10.1.1.154.7321 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal |author1=Park, B.U. |author2=Turlach, B.A. |year=1992 |title=Practical performance of several data driven bandwidth selectors (with discussion) |journal=Computational Statistics |volume=7 |pages=251–270|url=https://ideas.repec.org/p/cor/louvco/1992005.html}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|author1=Cao, R. |author2=Cuevas, A. |author3=Manteiga, W. G. |year=1994 |title=A comparative study of several smoothing methods in density estimation |journal=Computational Statistics and Data Analysis |volume=17 |pages=153–176 |doi=10.1016/0167-9473(92)00066-Z|issue=2}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |doi=10.2307/2291420 |author1=Jones, M.C. |author2=Marron, J.S. |author3=Sheather, S. J. |year=1996 |title=A brief survey of bandwidth selection for density estimation| journal=Journal of the American Statistical Association |volume=91 |issue=433 |pages=401–407 |jstor=2291420}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |author=Sheather, S.J. |year=1992 |title=The performance of six popular bandwidth selection methods on some real data sets (with discussion) |journal=Computational Statistics |volume=7 |pages=225–250, 271–281}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |author1=Agarwal, N. |author2=Aluru, N.R. |year=2010 |title=A data-driven stochastic collocation approach for uncertainty quantification in MEMS |journal=International Journal for Numerical Methods in Engineering |volume=83 |issue=5 |pages=575–597 |url=https://webhost.engr.illinois.edu/~aluru/Journals/IJNME10.pdf}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |author1=Xu, X. |author2=Yan, Z. |author3=Xu, S. |year=2015 |title=Estimating wind speed probability distribution by diffusion-based kernel density method |journal=Electric Power Systems Research|volume=121 |pages=28–37 |doi=10.1016/j.epsr.2014.11.029 }}&lt;/ref&gt; with the general consensus that the plug-in selectors&lt;ref name="bo07"/&gt;&lt;ref name="bo10"&gt;{{Cite journal |author1=Botev, Z.I. |author2=Grotowski, J.F. |author3=Kroese, D.P. |title=Kernel density estimation via diffusion |journal=[[Annals of Statistics]] |volume= 38 |issue=5 |pages=2916–2957 |year=2010 |doi=10.1214/10-AOS799|arxiv=1011.2602 }}&lt;/ref&gt;&lt;ref name="SJ91"&gt;{{cite journal |author1=Sheather, S.J. |author2=Jones, M.C. |year=1991 |title=A reliable data-based bandwidth selection method for kernel density estimation |journal=Journal of the Royal Statistical Society, Series B |volume=53 |issue=3 |pages=683–690 |jstor=2345597 |doi=10.1111/j.2517-6161.1991.tb01857.x}}&lt;/ref&gt; and [[Cross-validation (statistics)|cross validation]] selectors&lt;ref&gt;{{cite journal |author=Rudemo, M. |year=1982 |title=Empirical choice of histograms and kernel density estimators |journal=Scandinavian Journal of Statistics |volume=9 |issue=2 |pages=65–78 |jstor=4615859}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |author=Bowman, A.W. |year=1984 |title=An alternative method of cross-validation for the smoothing of density estimates |journal=Biometrika |volume=71 |pages=353–360 |doi=10.1093/biomet/71.2.353 |issue=2}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |author1=Hall, P. |author2=Marron, J.S. |author3=Park, B.U. |year=1992 |title=Smoothed cross-validation |journal=Probability Theory and Related Fields |volume=92 |pages=1–20 |doi=10.1007/BF01205233}}&lt;/ref&gt; are the most useful over a wide range of data sets.

Substituting any bandwidth ''h'' which has the same asymptotic order ''n''&lt;sup&gt;−1/5&lt;/sup&gt; as ''h''&lt;sub&gt;AMISE&lt;/sub&gt; into the AMISE
gives that AMISE(''h'') = ''O''(''n''&lt;sup&gt;−4/5&lt;/sup&gt;), where ''O'' is the [[big o notation]]. It can be shown that, under weak assumptions, there cannot exist a non-parametric estimator that converges at a faster rate than the kernel estimator.&lt;ref&gt;{{Cite journal|doi=10.1214/aos/1176342997|last=Wahba|first=G.|title=Optimal convergence properties of variable knot, kernel, and orthogonal series methods for density estimation|journal=[[Annals of Statistics]]|year=1975|volume=3|issue=1|pages=15–29|doi-access=free}}&lt;/ref&gt; Note that the ''n''&lt;sup&gt;−4/5&lt;/sup&gt; rate is slower than the typical ''n''&lt;sup&gt;−1&lt;/sup&gt; convergence rate of parametric methods.

If the bandwidth is not held fixed, but is varied depending upon the location of either the estimate (balloon estimator) or the samples (pointwise estimator), this produces a particularly powerful method termed [[variable kernel density estimation|adaptive or variable bandwidth kernel density estimation]].

Bandwidth selection for kernel density estimation of heavy-tailed distributions is relatively difficult.&lt;ref name="Buch2005"&gt;{{Cite journal | last1 = Buch-Larsen | first1 = TINE | title = Kernel density estimation for heavy-tailed distributions using the Champernowne transformation | doi = 10.1080/02331880500439782 | journal = Statistics | volume = 39 | issue = 6 | pages = 503–518 | year = 2005 | citeseerx = 10.1.1.457.1544 }}&lt;/ref&gt;

===A rule-of-thumb bandwidth estimator===

If Gaussian basis functions are used to approximate [[univariate]] data, and the underlying density being estimated is Gaussian, the optimal choice for ''h'' (that is, the bandwidth that minimises the [[mean integrated squared error]]) is:&lt;ref name="SI1998"&gt;{{Cite book |last=Silverman |first=B.W. |author-link=Bernard Silverman |title=Density Estimation for Statistics and Data Analysis |publisher=Chapman &amp; Hall/CRC |location=London |year=1986 |isbn=978-0-412-24620-3 |page=[https://archive.org/details/densityestimatio00silv_0/page/45 45] |url-access=registration |url=https://archive.org/details/densityestimatio00silv_0/page/45 }}&lt;/ref&gt;

:&lt;math&gt;h = \left(\frac{4\hat{\sigma}^5}{3n}\right)^{\frac{1}{5}} \approx 1.06 \, \hat{\sigma}\, n^{-1/5},&lt;/math&gt;

In order to make the h value more robust to make the fitness well for both long-tailed and skew distribution and bimodal mixture distribution, it is better to substitute the value of &lt;math&gt;\hat{\sigma}&lt;/math&gt; with another parameter A, which is given by:

:A = min(standard deviation, [[interquartile range]]/1.34).

Another modification that will improve the model is to reduce the factor from 1.06 to 0.9. Then the final formula would be:

:&lt;math&gt;h = 0.9\, \min\left(\hat{\sigma}, \frac{IQR}{1.34}\right)\, n^{\frac{-1}{5}}&lt;/math&gt;

where &lt;math&gt;\hat{\sigma}&lt;/math&gt; is the [[standard deviation]] of the samples, n is the sample size. [[Interquartile range|IQR]] is the interquartile range.
This approximation is termed the ''normal distribution approximation'', Gaussian approximation, or ''[[Bernard Silverman|Silverman]]'s rule of thumb''.&lt;ref name="SI1998" /&gt; While this rule of thumb is easy to compute, it should be used with caution as it can yield widely inaccurate estimates when the density is not close to being normal. For example,  when estimating the bimodal [[Gaussian mixture model]][[File:Kernel density estimation, comparison between rule of thumb and solve-the-equation bandwidth.png|thumb|250px|alt=Comparison between rule of thumb and solve-the-equation bandwidth|Comparison between rule of thumb and solve-the-equation bandwidth.]]
:&lt;math&gt;\textstyle\frac{1}{2\sqrt{2\pi}}e^{-\frac{1}{2}(x-10)^2}+\frac{1}{2\sqrt{2\pi}}e^{-\frac{1}{2}(x+10)^2}&lt;/math&gt;

from a sample of 200 points. The figure on the right shows the true density and two kernel density estimates—one using the rule-of-thumb bandwidth, and the other using a solve-the-equation bandwidth.&lt;ref name="bo07" /&gt;&lt;ref name="SJ91" /&gt; The estimate based on the rule-of-thumb bandwidth is significantly oversmoothed.

==Relation to the characteristic function density estimator==
Given the sample (''x''&lt;sub&gt;1&lt;/sub&gt;, ''x''&lt;sub&gt;2&lt;/sub&gt;, …, ''x&lt;sub&gt;n&lt;/sub&gt;''), it is natural to estimate the [[characteristic function (probability theory)|characteristic function]] {{nowrap|''φ''(''t'') {{=}} E[''e''&lt;sup&gt;''itX''&lt;/sup&gt;]}} as
: &lt;math&gt;
    \widehat\varphi(t) = \frac{1}{n} \sum_{j=1}^n e^{itx_j}
  &lt;/math&gt;
Knowing the characteristic function, it is possible to find the corresponding probability density function through the [[Fourier transform]] formula. One difficulty with applying this inversion formula is that it leads to a diverging integral, since the estimate &lt;math style="vertical-align:-.3em"&gt;\scriptstyle\widehat\varphi(t)&lt;/math&gt; is unreliable for large ''t''’s. To circumvent this problem, the estimator &lt;math style="vertical-align:-.3em"&gt;\scriptstyle\widehat\varphi(t)&lt;/math&gt; is multiplied by a damping function {{nowrap|''ψ&lt;sub&gt;h&lt;/sub&gt;''(''t'') {{=}} ''ψ''(''ht'')}}, which is equal to 1 at the origin and then falls to 0 at infinity. The “bandwidth parameter” ''h'' controls how fast we try to dampen the function &lt;math style="vertical-align:-.3em"&gt;\scriptstyle\widehat\varphi(t)&lt;/math&gt;. In particular when ''h'' is small, then ''ψ&lt;sub&gt;h&lt;/sub&gt;''(''t'') will be approximately one for a large range of ''t''’s, which means that &lt;math style="vertical-align:-.3em"&gt;\scriptstyle\widehat\varphi(t)&lt;/math&gt; remains practically unaltered in the most important region of ''t''’s.

The most common choice for function ''ψ'' is either the uniform function {{nowrap|''ψ''(''t'') {{=}} '''1'''{−1 ≤ ''t'' ≤ 1}}}, which effectively means truncating the interval of integration in the inversion formula to {{nowrap|[−1/''h'', 1/''h'']}}, or the [[Gaussian function]] {{nowrap|''ψ''(''t'') {{=}} ''e''&lt;sup&gt;''−{{pi}}t''&lt;sup&gt;2&lt;/sup&gt;&lt;/sup&gt;}}. Once the function ''ψ'' has been chosen, the inversion formula may be applied, and the density estimator will be
: &lt;math&gt;\begin{align}
    \widehat{f}(x) &amp;= \frac{1}{2\pi} \int_{-\infty}^{+\infty} \widehat\varphi(t)\psi_h(t) e^{-itx} \, dt
                = \frac{1}{2\pi} \int_{-\infty}^{+\infty} \frac{1}{n} \sum_{j=1}^n e^{it(x_j-x)} \psi(ht) \, dt \\[5pt]
               &amp;= \frac{1}{nh} \sum_{j=1}^n \frac{1}{2\pi} \int_{-\infty}^{+\infty} e^{-i(ht)\frac{x-x_j}{h}} \psi(ht) \, d(ht)
                = \frac{1}{nh} \sum_{j=1}^n K\Big(\frac{x-x_j}{h}\Big),
  \end{align}&lt;/math&gt;

where ''K'' is the [[Fourier transform]] of the damping function ''ψ''. Thus the kernel density estimator coincides with the characteristic function density estimator.

== Geometric and topological features ==

We can extend the definition of the (global) mode to a local sense and define the local modes:

:&lt;math&gt;M = \{ x:g(x)=0, \lambda_1(x)&lt;0 \}&lt;/math&gt;

Namely, &lt;math&gt;M&lt;/math&gt; is the collection of points for which the density function is locally maximized. A natural estimator of &lt;math&gt;M&lt;/math&gt; is a plug-in from KDE,&lt;ref&gt;{{Cite journal|last=Chen|first=Yen-Chi|last2=Genovese|first2=Christopher R.|last3=Wasserman|first3=Larry|date=2016|title=A comprehensive approach to mode clustering|journal=Electronic Journal of Statistics|volume=10|issue=1|pages=210–241|doi=10.1214/15-ejs1102|issn=1935-7524|doi-access=free}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Chazal|first=Frédéric|last2=Fasy|first2=Brittany Terese|last3=Lecci|first3=Fabrizio|last4=Rinaldo|first4=Alessandro|last5=Wasserman|first5=Larry|date=2014|title=Stochastic Convergence of Persistence Landscapes and Silhouettes|journal=Annual Symposium on Computational Geometry - SOCG'14|pages=474–483|location=New York, New York, USA|publisher=ACM Press|doi=10.1145/2582112.2582128|isbn=978-1-4503-2594-3}}&lt;/ref&gt; where &lt;math&gt;g(x)&lt;/math&gt; and &lt;math&gt;\lambda_1(x)
&lt;/math&gt; are KDE version of &lt;math&gt;g(x)&lt;/math&gt; and &lt;math&gt;\lambda_1(x)&lt;/math&gt;. Under mild assumptions, &lt;math&gt;M_c&lt;/math&gt; is a consistent estimator of &lt;math&gt;M&lt;/math&gt;. Note that one can use the mean shift algorithm&lt;ref&gt;{{Cite journal|last=Fukunaga|first=K.|last2=Hostetler|first2=L.|date=January 1975|title=The estimation of the gradient of a density function, with applications in pattern recognition|journal=IEEE Transactions on Information Theory|volume=21|issue=1|pages=32–40|doi=10.1109/tit.1975.1055330|issn=0018-9448}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Yizong Cheng|date=1995|title=Mean shift, mode seeking, and clustering|journal=IEEE Transactions on Pattern Analysis and Machine Intelligence|volume=17|issue=8|pages=790–799|doi=10.1109/34.400568|issn=0162-8828}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Comaniciu|first=D.|last2=Meer|first2=P.|date=May 2002|title=Mean shift: a robust approach toward feature space analysis|journal=IEEE Transactions on Pattern Analysis and Machine Intelligence|volume=24|issue=5|pages=603–619|doi=10.1109/34.1000236|issn=0162-8828}}&lt;/ref&gt; to compute the estimator &lt;math&gt;M_c&lt;/math&gt; numerically.

== Statistical implementation ==

A non-exhaustive list of software implementations of kernel density estimators includes:
* In [[Analytica (software)|Analytica]] release 4.4, the ''Smoothing'' option for PDF results uses KDE, and from expressions it is available via the built-in &lt;code&gt;Pdf&lt;/code&gt; function.
* In [[C (programming language)|C]]/[[C++]], [http://www.umiacs.umd.edu/~morariu/figtree/ FIGTree] is a library that can be used to compute kernel density estimates using normal kernels. MATLAB interface available.
* In [[C++]], [http://libagf.sf.net libagf] is a library for [[variable kernel density estimation]].
* In [[C++]], [[mlpack]] is a library that can compute KDE using many different kernels. It allows to set an error tolerance for faster computation. [[Python (programming language)|Python]] and [[R (programming language)|R]] interfaces are available.
* in [[C Sharp (programming language)|C#]] and [[F Sharp (programming language)|F#]], [[Math.NET Numerics]] is an open source library for numerical computation which includes [https://numerics.mathdotnet.com/api/MathNet.Numerics.Statistics/KernelDensity.htm kernel density estimation]
* In [[CrimeStat]], kernel density estimation is implemented using five different kernel functions – normal, uniform, quartic, negative exponential, and triangular. Both single- and dual-kernel density estimate routines are available.  Kernel density estimation is also used in interpolating a Head Bang routine, in estimating a two-dimensional Journey-to-crime density function, and in estimating a three-dimensional Bayesian Journey-to-crime estimate.
* In [[ELKI]], kernel density functions can be found in the package &lt;code&gt;de.lmu.ifi.dbs.elki.math.statistics.kernelfunctions&lt;/code&gt;
* In [[Environmental Systems Research Institute|ESRI]] products, kernel density mapping is managed out of the Spatial Analyst toolbox and uses the Quartic(biweight) kernel.
* In [[Microsoft Excel|Excel]], the Royal Society of Chemistry has created an add-in to run kernel density estimation based on their [http://www.rsc.org/Membership/Networking/InterestGroups/Analytical/AMC/Software/kerneldensities.asp Analytical Methods Committee Technical Brief 4].
* In [[gnuplot]], kernel density estimation is implemented by the &lt;code&gt;smooth kdensity&lt;/code&gt; option, the datafile can contain a weight and bandwidth for each point, or the bandwidth can be set automatically&lt;ref&gt;{{cite book |last=Janert |first=Philipp K |title=Gnuplot in action : understanding data with graphs |year=2009 |publisher=Manning Publications |location=Connecticut, USA |isbn=978-1-933988-39-9 }} See section 13.2.2 entitled ''Kernel density estimates''.&lt;/ref&gt; according to "Silverman's rule of thumb" (see above).
* In [[Haskell (programming language)|Haskell]], kernel density is implemented in the [http://hackage.haskell.org/package/statistics statistics] package.
* In [[IGOR Pro]], kernel density estimation is implemented by the &lt;code&gt;StatsKDE&lt;/code&gt; operation (added in Igor Pro 7.00).  Bandwidth can be user specified or estimated by means of Silverman, Scott or Bowmann and Azzalini. Kernel types are: Epanechnikov, Bi-weight, Tri-weight, Triangular, Gaussian and Rectangular.
* In [[Java (programming language)|Java]], the [[Weka (machine learning)]] package provides [http://weka.sourceforge.net/doc.stable/weka/estimators/KernelEstimator.html weka.estimators.KernelEstimator], among others.
* In [[JavaScript]], the visualization package [[D3js|D3.js]] offers a KDE package in its science.stats package.
* In [[JMP (statistical software)|JMP]], the Graph Builder platform utilizes kernel density estimation to provide contour plots and high density regions (HDRs) for bivariate densities, and violin plots and HDRs for univariate densities. Sliders allow the user to vary the bandwidth.  Bivariate and univariate kernel density estimates are also provided by the Fit Y by X and Distribution platforms, respectively.  
* In [[Julia (programming language)|Julia]], kernel density estimation is implemented in the [https://github.com/JuliaStats/KernelDensity.jl KernelDensity.jl] package.
* In [[MATLAB]], kernel density estimation is implemented through the &lt;code&gt;ksdensity&lt;/code&gt; function (Statistics Toolbox). As of the 2018a release of MATLAB, both the bandwidth and kernel smoother can be specified, including other options such as specifying the range of the kernel density.&lt;ref&gt;{{Cite web|title=Kernel smoothing function estimate for univariate and bivariate data - MATLAB ksdensity|url=https://www.mathworks.com/help/stats/ksdensity.html|access-date=2020-11-05|website=www.mathworks.com}}&lt;/ref&gt; Alternatively, a free MATLAB software package which implements an automatic bandwidth selection method&lt;ref name="bo07"/&gt; is available from the MATLAB Central File Exchange for
** [http://www.mathworks.com/matlabcentral/fileexchange/14034-kernel-density-estimator 1-dimensional data]
** [http://www.mathworks.com/matlabcentral/fileexchange/17204-kernel-density-estimation 2-dimensional data]
** [http://www.mathworks.com/matlabcentral/fileexchange/58312-kernel-density-estimator-for-high-dimensions n-dimensional data] &lt;br /&gt; A free MATLAB toolbox with implementation of kernel regression, kernel density estimation, kernel estimation of hazard function and many others is available on [http://www.math.muni.cz/english/science-and-research/developed-software/232-matlab-toolbox.html these pages] (this toolbox is a part of the book &lt;ref name="HorKolZel"&gt;{{cite book|last1=Horová|first1=I.|last2=Koláček|first2=J.|last3=Zelinka|first3=J.|title=Kernel Smoothing in MATLAB: Theory and Practice of Kernel Smoothing|date=2012|publisher=World Scientific Publishing|location=Singapore|isbn=978-981-4405-48-5}}&lt;/ref&gt;).
* In [[Mathematica]], numeric kernel density estimation is implemented by the function &lt;code&gt;SmoothKernelDistribution&lt;/code&gt;&lt;ref&gt;{{Cite web|title=SmoothKernelDistribution—Wolfram Language Documentation|url=https://reference.wolfram.com/language/ref/SmoothKernelDistribution.html.en|access-date=2020-11-05|website=reference.wolfram.com}}&lt;/ref&gt; and symbolic estimation is implemented using the function &lt;code&gt;KernelMixtureDistribution&lt;/code&gt;&lt;ref&gt;{{Cite web|title=KernelMixtureDistribution—Wolfram Language Documentation|url=https://reference.wolfram.com/language/ref/KernelMixtureDistribution.html.en|access-date=2020-11-05|website=reference.wolfram.com}}&lt;/ref&gt; both of which provide data-driven bandwidths.
* In [[Minitab]], the Royal Society of Chemistry has created a macro to run kernel density estimation based on their Analytical Methods Committee Technical Brief 4.&lt;ref&gt;{{Cite web|title=Software for calculating kernel densities|url=https://www.rsc.org/Membership/Networking/InterestGroups/Analytical/AMC/Software/kerneldensities.asp|access-date=2020-11-05|website=www.rsc.org}}&lt;/ref&gt;
* In the [[NAG Numerical Library|NAG Library]], kernel density estimation is implemented via the &lt;code&gt;g10ba&lt;/code&gt; routine (available in both the Fortran&lt;ref&gt;{{cite web |last=The Numerical Algorithms Group |title=NAG Library Routine Document: nagf_smooth_kerndens_gauss (g10baf) |work=NAG Library Manual, Mark 23 |url=http://www.nag.co.uk/numeric/fl/nagdoc_fl23/pdf/G10/g10baf.pdf |access-date=2012-02-16 }}&lt;/ref&gt; and the C&lt;ref&gt;{{cite web |last=The Numerical Algorithms Group |title=NAG Library Routine Document: nag_kernel_density_estim (g10bac) |work=NAG Library Manual, Mark 9 |url=http://www.nag.co.uk/numeric/CL/nagdoc_cl09/pdf/G10/g10bac.pdf |access-date=2012-02-16 |archive-url=https://web.archive.org/web/20111124062333/http://nag.co.uk/numeric/cl/nagdoc_cl09/pdf/G10/g10bac.pdf |archive-date=2011-11-24 |url-status=dead }}&lt;/ref&gt; versions of the Library).
* In [http://nuklei.sourceforge.net/ Nuklei], [[C++]] kernel density methods focus on data from the Special Euclidean group &lt;math&gt;SE(3)&lt;/math&gt;.
* In [[GNU Octave|Octave]], kernel density estimation is implemented by the &lt;code&gt;kernel_density&lt;/code&gt; option (econometrics package).
* In [[Origin (data analysis software)|Origin]], 2D kernel density plot can be made from its user interface, and two functions, Ksdensity for 1D and Ks2density for 2D can be used from its [http://wiki.originlab.com/~originla/ltwiki/index.php?title=Category:LabTalk_Programming LabTalk], [[Python (programming language)|Python]], or [[C (programming language)|C]] code.
* In [[Perl]], an implementation can be found in the [http://search.cpan.org/~janert/Statistics-KernelEstimation-0.05 Statistics-KernelEstimation module]
* In [[PHP]], an implementation can be found in the [https://github.com/markrogoyski/math-php MathPHP library]
* In [[Python (programming language)|Python]], many implementations exist:  [http://pythonhosted.org/PyQt-Fit/mod_kde.html pyqt_fit.kde Module] in the [https://pypi.python.org/packages/source/P/PyQt-Fit/PyQt-Fit-1.3.4.tar.gz PyQt-Fit package], SciPy (&lt;code&gt;scipy.stats.gaussian_kde&lt;/code&gt;), Statsmodels (&lt;code&gt;KDEUnivariate&lt;/code&gt; and &lt;code&gt;KDEMultivariate&lt;/code&gt;), and Scikit-learn (&lt;code&gt;KernelDensity&lt;/code&gt;) (see comparison&lt;ref&gt;{{cite web |last=Vanderplas|first=Jake|title=Kernel Density Estimation in Python|date=2013-12-01|url=https://jakevdp.github.io/blog/2013/12/01/kernel-density-estimation/|access-date=2014-03-12}}&lt;/ref&gt;). [https://kdepy.readthedocs.io/en/latest/ KDEpy] supports weighted data and its FFT implementation is orders of magnitude faster than the other implementations. The commonly used pandas library [https://pandas.pydata.org/] offers support for kde plotting through the plot method (&lt;code&gt;df.plot(kind='kde')&lt;/code&gt;[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.kde.html]). The [https://getdist.readthedocs.io getdist] package for weighted and correlated MCMC samples supports optimized bandwidth, boundary correction and higher-order methods for 1D and 2D distributions. One newly used package for kernel density estimation is seaborn ( &lt;code&gt;import seaborn as sns&lt;/code&gt; , &lt;code&gt;sns.kdeplot()&lt;/code&gt; ).&lt;ref&gt;{{Cite web|title=seaborn.kdeplot — seaborn 0.10.1 documentation|url=https://seaborn.pydata.org/generated/seaborn.kdeplot.html|website=seaborn.pydata.org|access-date=2020-05-12}}&lt;/ref&gt; A GPU implementation of KDE also exists.&lt;ref&gt;https://pypi.org/project/kde-gpu/#description&lt;/ref&gt;
* In [[R (programming language)|R]], it is implemented through &lt;code&gt;density&lt;/code&gt; in the base distribution, and &lt;code&gt;bw.nrd0&lt;/code&gt; function is used in stats package, this function uses the optimized formula in Silverman's book. &lt;code&gt;bkde&lt;/code&gt; in the [https://cran.r-project.org/web/packages/KernSmooth/index.html KernSmooth library],  &lt;code&gt;ParetoDensityEstimation&lt;/code&gt; in the [https://CRAN.R-project.org/package=DataVisualizations DataVisualizations library] (for pareto distribution density estimation), &lt;code&gt;kde&lt;/code&gt; in the [https://cran.r-project.org/web/packages/ks/index.html ks library], &lt;code&gt;dkden&lt;/code&gt; and &lt;code&gt;dbckden&lt;/code&gt; in the [https://cran.r-project.org/web/packages/evmix/index.html evmix library] (latter for boundary corrected kernel density estimation for bounded support), &lt;code&gt;npudens&lt;/code&gt; in the [https://cran.r-project.org/web/packages/np/index.html np library] (numeric and categorical data), &lt;code&gt;sm.density&lt;/code&gt; in the [https://cran.r-project.org/web/packages/sm/index.html sm library]. For an implementation of the &lt;code&gt;kde.R&lt;/code&gt; function, which does not require installing any packages or libraries, see [http://web.maths.unsw.edu.au/~zdravkobotev/kde.R kde.R]. The [https://cran.r-project.org/web/packages/btb/index.html btb library], dedicated to urban analysis, implements kernel density estimation through &lt;code&gt;kernel_smoothing&lt;/code&gt;.
* In [[SAS (software)|SAS]], &lt;code&gt;proc kde&lt;/code&gt; can be used to estimate univariate and bivariate kernel densities.
* In [[Apache Spark]], the &lt;code&gt;KernelDensity()&lt;/code&gt; class&lt;ref&gt;{{Cite web|title=Basic Statistics - RDD-based API - Spark 3.0.1 Documentation|url=http://spark.apache.org/docs/latest/mllib-statistics.html#kernel-density-estimation|access-date=2020-11-05|website=spark.apache.org}}&lt;/ref&gt; 
* In [[Stata]], it is implemented through &lt;code&gt;kdensity&lt;/code&gt;;&lt;ref&gt;https://www.stata.com/manuals15/rkdensity.pdf&lt;/ref&gt; for example &lt;code&gt;histogram x, kdensity&lt;/code&gt;. Alternatively a free Stata module KDENS is available from [https://ideas.repec.org/c/boc/bocode/s456410.html here] allowing a user to estimate 1D or 2D density functions.
* In [[Swift (programming language)|Swift]], it is implemented through &lt;code&gt;SwiftStats.KernelDensityEstimation&lt;/code&gt; in the open-source statistics library [https://github.com/r0fls/swiftstats SwiftStats].

==See also==
{{Commons category|Kernel density estimation}}
* [[Kernel (statistics)]]
* [[Kernel smoothing]]
* [[Kernel regression]]
* [[Density estimation]] (with presentation of other examples)
* [[Mean-shift]]
* [[Scale space]]: The triplets {(''x'', ''h'', KDE with bandwidth ''h'' evaluated at ''x'': all ''x'', ''h'' &gt; 0} form a [[scale space]] representation of the data.
* [[Multivariate kernel density estimation]]
* [[Variable kernel density estimation]]
* [[Head/tail Breaks|Head/tail breaks]]

==References==
{{Reflist|30em}}

==External links==
* [http://www.mvstat.net/tduong/research/seminars/seminar-2001-05 Introduction to kernel density estimation] A short tutorial which motivates kernel density estimators as an improvement over histograms.
* [http://2000.jukuin.keio.ac.jp/shimazaki/res/kernel.html Kernel Bandwidth Optimization] A free online tool that generates an optimized kernel density estimate.
* [http://www.wessa.net/rwasp_density.wasp Free Online Software (Calculator)] computes the Kernel Density Estimation for a data series according to the following Kernels: Gaussian, Epanechnikov, Rectangular, Triangular, Biweight, Cosine, and Optcosine.
* [http://pcarvalho.com/things/kerneldensityestimation/index.html Kernel Density Estimation Applet] An online interactive example of kernel density estimation. Requires .NET 3.0 or later.

{{DEFAULTSORT:Kernel density estimation}}
[[Category:Estimation of densities]]
[[Category:Nonparametric statistics]]
[[Category:Machine learning]]
[[Category:Articles with example MATLAB/Octave code]]
[[Category:Articles with example R code]]</text>
      <sha1>cg4gvo0lycnif0hc65u95b4kfk4kuqe</sha1>
    </revision>
  </page>
  <page>
    <title>Linear separability</title>
    <ns>0</ns>
    <id>523173</id>
    <revision>
      <id>994852281</id>
      <parentid>989728103</parentid>
      <timestamp>2020-12-17T21:34:27Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 2 templates: del empty params (1×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="6933" xml:space="preserve">[[File:Linearly separable red-blue cropped .svg|thumb|211x211px|The existence of a line separating the two types of points means that the data is linearly separable]]
In [[Euclidean geometry]], '''linear separability''' is a property of two sets of [[point (geometry)|points]]. This is most easily visualized in two dimensions (the [[Euclidean plane]]) by thinking of one set of points as being colored blue and the other set of points as being colored red. These two sets are ''linearly separable'' if there exists at least one [[line (geometry)|line]] in the plane with all of the blue points on one side of the line and all the red points on the other side. This idea immediately generalizes to higher-dimensional Euclidean spaces if the line is replaced by a [[hyperplane]].

The problem of determining if a pair of sets is linearly separable and finding a separating hyperplane if they are, arises in several areas.  In [[statistics]] and [[machine learning]], classifying certain types of data is a problem for which good algorithms exist that are based on this concept.

==Mathematical definition==

Let &lt;math&gt;X_{0}&lt;/math&gt; and &lt;math&gt;X_{1}&lt;/math&gt; be two sets of points in an ''n''-dimensional Euclidean space. Then &lt;math&gt;X_{0}&lt;/math&gt; and &lt;math&gt;X_{1}&lt;/math&gt; are ''linearly separable'' if there exist ''n'' + 1 real numbers &lt;math&gt;w_{1}, w_{2},..,w_{n}, k&lt;/math&gt;, such that every point &lt;math&gt;x \in X_{0}&lt;/math&gt; satisfies &lt;math&gt;\sum^{n}_{i=1} w_{i}x_{i} &gt; k&lt;/math&gt; and every point &lt;math&gt;x \in X_{1}&lt;/math&gt; satisfies &lt;math&gt;\sum^{n}_{i=1} w_{i}x_{i} &lt; k&lt;/math&gt;, where &lt;math&gt;x_{i}&lt;/math&gt; is the &lt;math&gt;i&lt;/math&gt;-th component of &lt;math&gt;x&lt;/math&gt;.

Equivalently, two sets are linearly separable precisely when their respective [[convex hull]]s are [[disjoint sets|disjoint]] (colloquially, do not overlap).{{Citation needed|reason=It is unclear that this is equivalent|date=September 2017}}

== Examples ==

Three non-[[collinear]] points in two classes ('+' and '-') are always linearly separable in two dimensions. This is illustrated by the three examples in the following figure (the all '+' case is not shown, but is similar to the all '-' case):

{| align="center" border="0" cellpadding="4" cellspacing="10"
| align="center" | [[File:VC1.svg]]
| align="center" | [[File:VC2.svg]]
| align="center" | [[File:VC3.svg]]
|}

However, not all sets of four points, no three collinear, are linearly separable in two dimensions. The following example would need ''two'' straight lines and thus is not linearly separable:

{| align="center" border="0" cellpadding="4" cellspacing="0"
| [[File:VC4.svg]]
|}

Notice that three points which are collinear and of the form "+ ⋅⋅⋅ &amp;mdash; ⋅⋅⋅ +" are also not linearly separable.

== Linear separability of Boolean functions in ''n'' variables ==

A [[Boolean function]] in ''n'' variables can be thought of as an assignment of ''0'' or ''1'' to each vertex of a Boolean [[hypercube]] in ''n'' dimensions. This gives a natural division of the vertices into two sets. The Boolean function is said to be ''linearly separable'' provided these two sets of points are linearly separable. The number of distinct Boolean functions is &lt;math&gt;2^{2^{n}}&lt;/math&gt;where ''n'' is the number of variables passed into the function.&lt;ref&gt;{{Cite book|title=Artificial intelligence a modern approach|last=1962-|first=Russell, Stuart J.|others=Norvig, Peter 1956-|year=2016|isbn=978-1292153964|edition= Third|location=Boston|pages=766|oclc=945899984}}&lt;/ref&gt;

{| class="wikitable"
|+&lt;small&gt;Number of linearly separable Boolean functions in each dimension&lt;/small&gt;&lt;ref&gt;
{{cite paper
| last=Gruzling
| first=Nicolle
| title=Linear separability of the vertices of an n-dimensional hypercube. M.Sc Thesis
| publisher= University of Northern British Columbia
| year=2006
}}&lt;/ref&gt; {{OEIS|id=A000609}}
!Number of variables
!Boolean functions
!Linearly separable Boolean functions
|-
|  2 
|16|| 14
|-
|  3 
|256|| 104
|-
|  4 
|65536|| 1882
|-
|  5 
|4294967296|| 94572
|-
|  6 
|18446744073709552000|| 15028134
|-
|  7 
|3.402823669 ×10^38
| 8378070864
|-
|  8 
|1.157920892 ×10^77|| 17561539552946
|-
|  9 
|1.340780792 ×10^154|| 144130531453121108
|}

== Support vector machines==
{{main|Support vector machine}}

[[Image:Svm separating hyperplanes (SVG).svg|thumb|right|H&lt;sub&gt;1&lt;/sub&gt; does not separate the sets. H&lt;sub&gt;2&lt;/sub&gt; does, but only with a small margin.  H&lt;sub&gt;3&lt;/sub&gt; separates them with the maximum margin.]]
[[Statistical classification|Classifying data]] is a common task in [[machine learning]].
Suppose some data points, each belonging to one of two sets, are given and we wish to create a model that will decide which set a ''new'' data point will be in. In the case of [[support vector machine]]s, a data point is viewed as a ''p''-dimensional vector (a list of ''p'' numbers), and we want to know whether we can separate such points with a (''p''&amp;nbsp;&amp;minus;&amp;nbsp;1)-dimensional [[hyperplane]]. This is called a [[linear classifier]]. There are many hyperplanes that might classify (separate) the data. One reasonable choice as the best hyperplane is the one that represents the largest separation, or margin, between the two sets. So we choose the hyperplane so that the distance from it to the nearest data point on each side is maximized. If such a hyperplane exists, it is known as the ''[[maximum-margin hyperplane]]'' and the linear classifier it defines is known as a ''maximum [[margin classifier]]''.

More formally, given some training data &lt;math&gt;\mathcal{D}&lt;/math&gt;, a set of ''n'' points of the form

:&lt;math&gt;\mathcal{D} = \left\{ (\mathbf{x}_i, y_i)\mid\mathbf{x}_i \in \mathbb{R}^p,\, y_i \in \{-1,1\}\right\}_{i=1}^n&lt;/math&gt;

where the ''y''&lt;sub&gt;''i''&lt;/sub&gt; is either 1 or −1, indicating the set to which the point &lt;math&gt;\mathbf{x}_i &lt;/math&gt; belongs. Each &lt;math&gt; \mathbf{x}_i &lt;/math&gt; is a ''p''-dimensional [[real number|real]] vector. We want to find the maximum-margin hyperplane that divides the points having &lt;math&gt;y_i=1&lt;/math&gt; from those having &lt;math&gt;y_i=-1&lt;/math&gt;. Any hyperplane can be written as the set of points &lt;math&gt;\mathbf{x}&lt;/math&gt; satisfying

: &lt;math&gt;\mathbf{w}\cdot\mathbf{x} - b=0,&lt;/math&gt;

where &lt;math&gt;\cdot&lt;/math&gt; denotes the [[dot product]] and &lt;math&gt;{\mathbf{w}}&lt;/math&gt; the (not necessarily normalized) [[Normal (geometry)|normal vector]] to the hyperplane. The parameter &lt;math&gt;\tfrac{b}{\|\mathbf{w}\|}&lt;/math&gt; determines the offset of the hyperplane from the origin along the normal vector &lt;math&gt;{\mathbf{w}}&lt;/math&gt;.

If the training data are linearly separable, we can select two hyperplanes in such a way that they separate the data and there are no points between them, and then try to maximize their distance.

== See also ==
* [[Hyperplane separation theorem]]
* [[Kirchberger's theorem]]
* [[Perceptron]]
* [[Vapnik–Chervonenkis dimension]]

== References ==
{{reflist}}

[[Category:Geometry]]
[[Category:Convex analysis]]
[[Category:Machine learning]]</text>
      <sha1>fss3tfp3m3jvbucjtek6zsl5k99wzk9</sha1>
    </revision>
  </page>
  <page>
    <title>Bias–variance tradeoff</title>
    <ns>0</ns>
    <id>40678189</id>
    <revision>
      <id>1005053445</id>
      <parentid>996197234</parentid>
      <timestamp>2021-02-05T19:16:37Z</timestamp>
      <contributor>
        <ip>109.24.204.11</ip>
      </contributor>
      <comment>Removed what I believe to be an author trying to promote its own unpublished work.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="22663" xml:space="preserve">{{Machine learning bar}}
{{multiple image| align=right|direction=vertical|width=200
|image1=Test function and noisy data.png|caption1=Function and noisy data.
|image2=Radial basis function fit, spread=5.png|caption2=spread=5
|image3=Radial basis function fit, spread=1.png|caption3=spread=1
|image4=Radial basis function fit, spread=0.1.png|caption4=spread=0.1
|footer=A function (red) is approximated using [[radial basis functions]] (blue). Several trials are shown in each graph. For each trial, a few noisy data points are provided as a training set (top). For a wide spread (image 2) the bias is high: the RBFs cannot fully approximate the function (especially the central dip), but the variance between different trials is low. As spread decreases (image 3 and 4) the bias decreases: the blue curves more closely approximate the red. However, depending on the noise in different trials the variance between trials increases. In the lowermost image the approximated values for x=0 varies wildly depending on where the data points were located.}}

In [[statistics]] and [[machine learning]], the '''bias–variance tradeoff''' is the property of a model that the [[variance]] of the parameter estimates across [[sample (statistics)|samples]] can be reduced by increasing the [[Bias_of_an_estimator|bias]] in the [[estimation theory|estimated]] [[statistical parameter|parameters]].
The '''bias–variance dilemma''' or '''bias–variance problem''' is the conflict in trying to simultaneously minimize these two sources of [[Errors and residuals in statistics|error]] that prevent [[supervised learning]] algorithms from generalizing beyond their [[training set]]:&lt;ref&gt;{{cite journal |last1=Kohavi |first1=Ron |last2=Wolpert |first2=David H. |title=Bias Plus Variance Decomposition for Zero-One Loss Functions |journal=ICML |date=1996 |volume=96}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last1=Luxburg |first1=Ulrike V. |last2=Schölkopf |first2=B. |title=Statistical learning theory: Models, concepts, and results |journal=Handbook of the History of Logic |date=2011 |volume=10|  page=Section 2.4}}&lt;/ref&gt;
* The [[Bias of an estimator|''bias error'']] is an error from erroneous assumptions in the learning [[algorithm]]. High bias can cause an algorithm to miss the relevant relations between features and target outputs (underfitting).
* The ''[[variance]]'' is an error from sensitivity to small fluctuations in the training set. High variance can cause an algorithm to model the random [[Noise (signal processing)|noise]] in the training data, rather than the intended outputs ([[overfitting]]).

The '''bias–variance decomposition''' is a way of analyzing a learning algorithm's [[expected value|expected]] [[generalization error]] with respect to a particular problem as a sum of three terms, the bias, variance, and a quantity called the ''irreducible error'', resulting from noise in the problem itself.

==Motivation==
The bias-variance tradeoff is a central problem in supervised learning. Ideally, one wants to [[Model selection|choose a model]] that both accurately captures the regularities in its training data, but also [[Generalization|generalizes]] well to unseen data. Unfortunately, it is typically impossible to do both simultaneously. High-variance learning methods may be able to represent their training set well but are at risk of overfitting to noisy or unrepresentative training data. In contrast, algorithms with high bias typically produce simpler models that don't tend to overfit but may ''underfit'' their training data, failing to capture important regularities.

It is an often made [[Affirming the consequent|fallacy]]&lt;ref name="nealThesis2019"&gt;{{cite arXiv |last=Neal |first=Brady |eprint=1912.08286 |title=On the Bias-Variance Tradeoff: Textbooks Need an Update |class=cs.LG |date=2019}}&lt;/ref&gt;&lt;ref name="neal2018"&gt;{{cite arXiv |first1=Brady |last1=Neal |first2=Sarthak |last2=Mittal |first3=Aristide |last3=Baratin |first4=Vinayak |last4=Tantia |first5=Matthew |last5=Scicluna |first6=Simon |last6=Lacoste-Julien |first7=Ioannis |last7=Mitliagkas |eprint=1810.08591 |title=A Modern Take on the Bias-Variance Tradeoff in Neural Networks |class=cs.LG |date=2018}}&lt;/ref&gt; to assume that complex models must have high variance; High variance models are 'complex' in some sense, but the reverse needs not be true.
In addition one has to be careful how to define complexity: In particular, the number of parameters used to describe the model is a poor measure of complexity. This is illustrated by an example adapted from:&lt;ref&gt;{{cite book |last1=Vapnik |first1=Vladimir |title=The nature of statistical learning theory |date=2000 |publisher=Springer-Verlag |location=New York |isbn=978-1-4757-3264-1 |url=https://dx.doi.org/10.1007/978-1-4757-3264-1}}&lt;/ref&gt; The model &lt;math&gt;f_{a,b}(x)=a\sin(bx)&lt;/math&gt; has only two parameters (&lt;math&gt;a,b&lt;/math&gt;) but it can interpolate any number of points by oscillating with a high enough frequency, resulting in both a high bias and high variance.

Intuitively, bias is reduced by using only local information, whereas variance can only be reduced by averaging over multiple observations, which inherently means using information from a larger region. For an enlightening example, see the section on k-nearest neighbors or the figure on the right.
To balance how much information is used from neighboring observations, a model can be [[smoothing|smoothed]] via explicit [[Regularization (mathematics)|regularization]], such as [[shrinkage (statistics)|shrinkage]].

==Bias–variance decomposition of mean squared error==
{{main|Mean squared error}}
Suppose that we have a training set consisting of a set of points &lt;math&gt;x_1, \dots, x_n&lt;/math&gt; and real values &lt;math&gt;y_i&lt;/math&gt; associated with each point &lt;math&gt;x_i&lt;/math&gt;. We assume that there is a function with noise &lt;math&gt;y = f(x) + \varepsilon&lt;/math&gt;, where the noise, &lt;math&gt;\varepsilon&lt;/math&gt;, has zero mean and variance &lt;math&gt;\sigma^2&lt;/math&gt;.

We want to find a function &lt;math&gt;\hat{f}(x;D)&lt;/math&gt;, that approximates the true function &lt;math&gt;f(x)&lt;/math&gt; as well as possible, by means of some learning algorithm based on a training dataset (sample) &lt;math&gt;D=\{(x_1,y_1) \dots, (x_n, y_n)\}&lt;/math&gt;. We make "as well as possible" precise by measuring the [[mean squared error]] between &lt;math&gt;y&lt;/math&gt; and &lt;math&gt;\hat{f}(x;D)&lt;/math&gt;: we want &lt;math&gt;(y - \hat{f}(x;D))^2&lt;/math&gt; to be minimal, both for &lt;math&gt;x_1, \dots, x_n&lt;/math&gt; ''and for points outside of our sample''. Of course, we cannot hope to do so perfectly, since the &lt;math&gt;y_i&lt;/math&gt; contain noise &lt;math&gt;\varepsilon&lt;/math&gt;; this means we must be prepared to accept an ''irreducible error'' in any function we come up with.

Finding an &lt;math&gt;\hat{f}&lt;/math&gt; that generalizes to points outside of the training set can be done with any of the countless algorithms used for supervised learning. It turns out that whichever function &lt;math&gt;\hat{f}&lt;/math&gt; we select, we can decompose its [[expected value|expected]] error on an unseen sample &lt;math&gt;x&lt;/math&gt; as follows:&lt;ref name="islr"&gt;{{cite book |first1=Gareth |last1=James |first2=Daniela |last2=Witten |author-link2=Daniela Witten |first3=Trevor |last3=Hastie |author-link3=Trevor Hastie |first4=Robert |last4=Tibshirani |author-link4=Robert Tibshirani |title=An Introduction to Statistical Learning |publisher=Springer |year=2013 |url=http://www-bcf.usc.edu/~gareth/ISL/ }}&lt;/ref&gt;{{rp|34}}&lt;ref name="ESL"&gt;{{cite book |first1=Trevor |last1=Hastie |first2=Robert |last2=Tibshirani |first3=Jerome H. |last3=Friedman |author-link3=Jerome H. Friedman |year=2009 |title=The Elements of Statistical Learning |url=http://statweb.stanford.edu/~tibs/ElemStatLearn/ |access-date=2014-08-20 |archive-url=https://web.archive.org/web/20150126123924/http://statweb.stanford.edu/~tibs/ElemStatLearn/ |archive-date=2015-01-26 |url-status=dead }}&lt;/ref&gt;{{rp|223}}

:&lt;math&gt;
\operatorname{E}_D\Big[\big(y - \hat{f}(x;D)\big)^2\Big]
= \Big(\operatorname{Bias}_D\big[\hat{f}(x;D)\big] \Big) ^2 + \operatorname{Var}_D\big[\hat{f}(x;D)\big] + \sigma^2
&lt;/math&gt;

where
:&lt;math&gt;
\operatorname{Bias}_D\big[\hat{f}(x;D)\big] = \operatorname{E}_D\big[\hat{f}(x;D)\big] - f(x)
&lt;/math&gt;

and

:&lt;math&gt;
\operatorname{Var}_D\big[\hat{f}(x;D)\big] = \operatorname{E}_D[\big(\operatorname{E}_D[\hat{f}(x;D)] - \hat{f}(x;D)\big)^2].
&lt;/math&gt;

The expectation ranges over different choices of the training set &lt;math&gt;D=\{(x_1,y_1) \dots, (x_n, y_n)\}&lt;/math&gt;, all sampled from the same joint distribution &lt;math&gt;P(x,y)&lt;/math&gt;. The three terms represent:
* the square of the ''bias'' of the learning method, which can be thought of as the error caused by the simplifying assumptions built into the method. E.g., when approximating a non-linear function &lt;math&gt;f(x)&lt;/math&gt; using a learning method for [[linear model]]s, there will be error in the estimates &lt;math&gt;\hat{f}(x)&lt;/math&gt; due to this assumption;
* the ''variance'' of the learning method, or, intuitively, how much the learning method &lt;math&gt;\hat{f}(x)&lt;/math&gt; will move around its mean;
* the irreducible error &lt;math&gt;\sigma^2&lt;/math&gt;. 

Since all three terms are non-negative, this forms a lower bound on the expected error on unseen samples.&lt;ref name="islr" /&gt;{{rp|34}}

The more complex the model &lt;math&gt;\hat{f}(x)&lt;/math&gt; is, the more data points it will capture, and the lower the bias will be. However, complexity will make the model "move" more to capture the data points, and hence its variance will be larger.

===Derivation===
The derivation of the bias–variance decomposition for squared error proceeds as follows.&lt;ref&gt;{{cite web |first1=Sethu |last1=Vijayakumar |author-link=Sethu Vijayakumar |title=The Bias–Variance Tradeoff |publisher=[[University of Edinburgh]] |year=2007 |access-date=19 August 2014 |url=http://www.inf.ed.ac.uk/teaching/courses/mlsc/Notes/Lecture4/BiasVariance.pdf }}&lt;/ref&gt;&lt;ref&gt;{{cite web |title=Notes on derivation of bias-variance decomposition in linear regression |first=Greg |last=Shakhnarovich |year=2011 |access-date=20 August 2014 |url=http://ttic.uchicago.edu/~gregory/courses/wis-ml2012/lectures/biasVarDecom.pdf |archive-url=https://web.archive.org/web/20140821063842/http://ttic.uchicago.edu/~gregory/courses/wis-ml2012/lectures/biasVarDecom.pdf |archive-date=21 August 2014 }}&lt;/ref&gt; For notational convenience, we abbreviate &lt;math&gt;f = f(x)&lt;/math&gt;, &lt;math&gt;\hat{f} = \hat{f}(x;D)&lt;/math&gt; and we drop the &lt;math&gt;D&lt;/math&gt; subscript on our expectation operators. First, recall that, by definition, for any random variable &lt;math&gt;X&lt;/math&gt;, we have

:&lt;math&gt;
\operatorname{Var}[X] = \operatorname{E}[X^2] - \operatorname{E}[X]^2.
&lt;/math&gt;
Rearranging, we get:
:&lt;math&gt;
\operatorname{E}[X^2] = \operatorname{Var}[X] + \operatorname{E}[X]^2.
&lt;/math&gt;

Since &lt;math&gt;f&lt;/math&gt; is [[Deterministic algorithm|deterministic]], i.e. independent of &lt;math&gt;D&lt;/math&gt;,

:&lt;math&gt;
\operatorname{E}[f] = f.
&lt;/math&gt;

Thus, given &lt;math&gt;y = f + \varepsilon&lt;/math&gt; and &lt;math&gt;\operatorname{E}[\varepsilon] = 0&lt;/math&gt; (because &lt;math&gt;\varepsilon&lt;/math&gt; is noise), implies &lt;math&gt;\operatorname{E}[y] = \operatorname{E}[f + \varepsilon] = \operatorname{E}[f] = f.&lt;/math&gt;

Also, since &lt;math&gt;\operatorname{Var}[\varepsilon] = \sigma^2,&lt;/math&gt;

:&lt;math&gt;
\operatorname{Var}[y] = \operatorname{E}[(y - \operatorname{E}[y])^2] = \operatorname{E}[(y - f)^2] = \operatorname{E}[(f + \varepsilon - f)^2] = \operatorname{E}[\varepsilon^2] = \operatorname{Var}[\varepsilon] + \operatorname{E}[\varepsilon]^2  = \sigma^2 + 0^2 = \sigma^2.

&lt;/math&gt;

Thus, since &lt;math&gt;\varepsilon&lt;/math&gt; and &lt;math&gt;\hat{f}&lt;/math&gt; are independent, we can write

:&lt;math&gt;
\begin{align}
\operatorname{E}\big[(y - \hat{f})^2\big]
 &amp; = \operatorname{E}\big[(f+\varepsilon  - \hat{f} )^2\big] \\[5pt]
 &amp; = \operatorname{E}\big[(f+\varepsilon  - \hat{f} +\operatorname{E}[\hat{f}]-\operatorname{E}[\hat{f}])^2\big] \\[5pt]
 &amp; = \operatorname{E}\big[(f-\operatorname{E}[\hat{f}])^2\big]+\operatorname{E}[\varepsilon^2]+\operatorname{E}\big[(\operatorname{E}[\hat{f}]- \hat{f})^2\big] 
+2\operatorname{E}\big[(f-\operatorname{E}[\hat{f}])\varepsilon\big]
+2\operatorname{E}\big[\varepsilon(\operatorname{E}[\hat{f}]- \hat{f})\big]
+2\operatorname{E}\big[(\operatorname{E}[\hat{f}]- \hat{f})(f-\operatorname{E}[\hat{f}])\big] \\[5pt]
 &amp; = (f-\operatorname{E}[\hat{f}])^2+\operatorname{E}[\varepsilon^2]+\operatorname{E}\big[(\operatorname{E}[\hat{f}]- \hat{f})^2\big] 
+2(f-\operatorname{E}[\hat{f}])\operatorname{E}[\varepsilon]
+2\operatorname{E}[\varepsilon]\operatorname{E}\big[\operatorname{E}[\hat{f}]- \hat{f}\big]
+2\operatorname{E}\big[\operatorname{E}[\hat{f}]- \hat{f}\big](f-\operatorname{E}[\hat{f}]) \\[5pt]
 &amp; = (f-\operatorname{E}[\hat{f}])^2+\operatorname{E}[\varepsilon^2]+\operatorname{E}\big[(\operatorname{E}[\hat{f}]- \hat{f})^2\big]\\[5pt]
 &amp; = (f-\operatorname{E}[\hat{f}])^2+\operatorname{Var}[\varepsilon]+\operatorname{Var}\big[\hat{f}\big]\\[5pt]
 &amp; = \operatorname{Bias}[\hat{f}]^2+\operatorname{Var}[\varepsilon]+\operatorname{Var}\big[\hat{f}\big]\\[5pt]
 &amp; = \operatorname{Bias}[\hat{f}]^2+\sigma^2+\operatorname{Var}\big[\hat{f}\big].
\end{align}
&lt;/math&gt;

Finally, MSE loss function (or negative log-likelihood) is obtained by taking the expectation value over &lt;math&gt;x\sim P&lt;/math&gt;:
:&lt;math&gt;
\text{MSE} = \operatorname{E}_x\bigg\{\operatorname{Bias}_D[\hat{f}(x;D)]^2+\operatorname{Var}_D\big[\hat{f}(x;D)\big]\bigg\} + \sigma^2.
&lt;/math&gt;

==Approaches==
[[Dimensionality reduction]] and [[feature selection]] can decrease variance by simplifying models. Similarly, a larger training set tends to decrease variance. Adding features (predictors) tends to decrease bias, at the expense of introducing additional variance. Learning algorithms typically have some tunable parameters that control bias and variance; for example,
* [[linear model|linear]]  and [[Generalized linear model|Generalized linear]] models can be [[Regularization (mathematics)|regularized]] to decrease their variance at the cost of increasing their bias.&lt;ref&gt;{{cite book |last=Belsley |first=David |title=Conditioning diagnostics : collinearity and weak data in regression |publisher=Wiley |location=New York (NY) |year=1991 |isbn=978-0471528890 }}&lt;/ref&gt;
* In [[artificial neural network]]s, the variance increases and the bias decreases as the number of hidden units increase,&lt;ref name="geman"&gt;{{cite journal |last1=Geman |first1=Stuart |author-link1=Stuart Geman |first2=Élie |last2=Bienenstock |first3=René |last3=Doursat |year=1992 |title=Neural networks and the bias/variance dilemma |journal=Neural Computation |volume=4 |pages=1–58 |doi=10.1162/neco.1992.4.1.1 |url=http://web.mit.edu/6.435/www/Geman92.pdf }}&lt;/ref&gt; although this classical assumption has been the subject of recent debate.&lt;ref name="neal2018" /&gt; Like in GLMs, regularization is typically applied.
* In [[k-nearest neighbor|''k''-nearest neighbor]] models, a high value of {{mvar|k}} leads to high bias and low variance (see below).
* In [[instance-based learning]], regularization can be achieved varying the mixture of [[prototype]]s and exemplars.&lt;ref&gt;{{cite journal |last1=Gagliardi |first1=Francesco |date=May 2011 |title=Instance-based classifiers applied to medical databases: diagnosis and knowledge extraction |journal=Artificial Intelligence in Medicine |volume=52 |issue=3 |pages=123–139 |doi=10.1016/j.artmed.2011.04.002 |pmid=21621400 |url=https://www.researchgate.net/publication/51173579 }}&lt;/ref&gt;
* In [[decision tree]]s, the depth of the tree determines the variance. Decision trees are commonly pruned to control variance.&lt;ref name="islr" /&gt;{{rp|307}}

One way of resolving the trade-off is to use [[mixture models]] and [[ensemble learning]].&lt;ref&gt;{{cite book |first1=Jo-Anne |last1=Ting |first2=Sethu |last2=Vijaykumar |first3=Stefan |last3=Schaal |url=http://homepages.inf.ed.ac.uk/svijayak/publications/ting-EMLDM2016.pdf |chapter=Locally Weighted Regression for Control |title=Encyclopedia of Machine Learning |editor-first1=Claude |editor-last1=Sammut |editor-first2=Geoffrey I. |editor-last2=Webb |publisher=Springer |year=2011 |page=615 |bibcode=2010eoml.book.....S }}&lt;/ref&gt;&lt;ref&gt;{{cite web |first=Scott |last=Fortmann-Roe |title=Understanding the Bias–Variance Tradeoff |year=2012 |url=http://scott.fortmann-roe.com/docs/BiasVariance.html }}&lt;/ref&gt; For example, [[Boosting (machine learning)|boosting]] combines many "weak" (high bias) models in an ensemble that has lower bias than the individual models, while [[Bootstrap aggregating|bagging]] combines "strong" learners in a way that reduces their variance.  

[[Model validation]] methods such as [[cross-validation (statistics)]] can be used to tune models so as to optimize the trade-off. 

===''k''-nearest neighbors===
In the case of [[k-nearest neighbors algorithm|{{mvar|k}}-nearest neighbors regression]], when the expectation is taken over the possible labeling of a fixed training set, a [[closed-form expression]] exists that relates the bias–variance decomposition to the parameter {{mvar|k}}:&lt;ref name="ESL" /&gt;{{rp|37, 223}}

:&lt;math&gt;
\operatorname{E}[(y - \hat{f}(x))^2\mid X=x] = \left( f(x) - \frac{1}{k}\sum_{i=1}^k f(N_i(x)) \right)^2 + \frac{\sigma^2}{k} + \sigma^2
&lt;/math&gt;

where &lt;math&gt;N_1(x), \dots, N_k(x)&lt;/math&gt; are the {{mvar|k}} nearest neighbors of {{mvar|x}} in the training set. The bias (first term) is a monotone rising function of {{mvar|k}}, while the variance (second term) drops off as {{mvar|k}} is increased. In fact, under "reasonable assumptions" the bias of the first-nearest neighbor (1-NN) estimator vanishes entirely as the size of the training set approaches infinity.&lt;ref name="geman" /&gt;

==Applications==

===In regression===
The bias–variance decomposition forms the conceptual basis for regression [[Regularization (mathematics)|regularization]] methods such as [[Lasso (statistics)|Lasso]] and [[ridge regression]]. Regularization methods introduce bias into the regression solution that can reduce variance considerably relative to the [[ordinary least squares|ordinary least squares (OLS)]] solution.  Although the OLS solution provides non-biased regression estimates, the lower variance solutions produced by regularization techniques provide superior MSE performance.

===In classification===
The bias–variance decomposition was originally formulated for least-squares regression. For the case of [[statistical classification|classification]] under the [[0-1 loss]] (misclassification rate), it is possible to find a similar decomposition.&lt;ref&gt;{{cite conference |last=Domingos |first=Pedro |author-link=Pedro Domingos |title=A unified bias-variance decomposition |conference=ICML |year=2000 |url=http://homes.cs.washington.edu/~pedrod/bvd.pdf }}&lt;/ref&gt;&lt;ref&gt;{{cite journal |first1=Giorgio |last1=Valentini |first2=Thomas G. |last2=Dietterich |author-link2=Thomas G. Dietterich |title=Bias–variance analysis of support vector machines for the development of SVM-based ensemble methods |journal=[[Journal of Machine Learning Research]] |volume=5 |year=2004 |pages=725–775 |url=http://www.jmlr.org/papers/volume5/valentini04a/valentini04a.pdf }}&lt;/ref&gt; Alternatively, if the classification problem can be phrased as [[probabilistic classification]], then the expected squared error of the predicted probabilities with respect to the true probabilities can be decomposed as before.&lt;ref&gt;{{cite book |first1=Christopher D. |last1=Manning |first2=Prabhakar |last2=Raghavan |first3=Hinrich |last3=Schütze |title=Introduction to Information Retrieval |publisher=Cambridge University Press |year=2008 |url=http://nlp.stanford.edu/IR-book/ |pages=308–314 }}&lt;/ref&gt;

===In reinforcement learning===
Even though the bias–variance decomposition does not directly apply in [[reinforcement learning]], a similar tradeoff can also characterize generalization. When an agent has limited information on its environment, the suboptimality of an RL algorithm can be decomposed into the sum of two terms: a term related to an asymptotic bias and a term due to overfitting. The asymptotic bias is directly related to the learning algorithm (independently of the quantity of data) while the overfitting term comes from the fact that the amount of data is limited.&lt;ref&gt;{{cite journal |first1=Vincent |last1=Francois-Lavet |first2=Guillaume |last2=Rabusseau |first3=Joelle |last3=Pineau |first4=Damien |last4=Ernst |first5=Raphael |last5=Fonteneau |title=On Overﬁtting and Asymptotic Bias in Batch Reinforcement Learning with Partial Observability |journal=Journal of AI Research |volume=65 |year=2019 |pages=1–30 |url=https://jair.org/index.php/jair/article/view/11478 |doi=10.1613/jair.1.11478 |doi-access=free }}&lt;/ref&gt;

===In human learning===
While widely discussed in the context of machine learning, the bias-variance dilemma has been examined in the context of [[Cognitive science|human cognition]], most notably by [[Gerd Gigerenzer]] and co-workers in the context of learned heuristics. They have argued (see references below) that the human brain resolves the dilemma in the case of the typically sparse, poorly-characterised training-sets provided by experience by adopting high-bias/low variance heuristics. This reflects the fact that a zero-bias approach has poor generalisability to new situations, and also unreasonably presumes precise knowledge of the true state of the world. The resulting heuristics are relatively simple, but produce better inferences in a wider variety of situations.&lt;ref name="ReferenceA"&gt;{{Cite journal |last1=Gigerenzer |first1=Gerd |author-link1=Gerd Gigerenzer |last2=Brighton |first2=Henry |doi=10.1111/j.1756-8765.2008.01006.x |title=Homo Heuristicus: Why Biased Minds Make Better Inferences |journal=Topics in Cognitive Science |volume=1 |issue=1 |pages=107–143 |year=2009 |pmid=25164802 |hdl=11858/00-001M-0000-0024-F678-0 |hdl-access=free }}&lt;/ref&gt;

[[Stuart Geman|Geman]] et al.&lt;ref name="geman" /&gt; argue that the bias-variance dilemma implies that abilities such as generic [[object recognition]] cannot be learned from scratch, but require a certain degree of “hard wiring”   that is later tuned by experience.  This is because model-free approaches to inference require impractically large training sets if they are to avoid high variance.

==See also==
{{Div col|colwidth=25em}}
* [[Accuracy and precision]]
* [[Bias of an estimator]]
* [[Gauss–Markov theorem]]
* [[Hyperparameter optimization]]
* [[Minimum-variance unbiased estimator]]
* [[Model selection]]
* [[Regression model validation]]
* [[Supervised learning]]
{{Div col end}}

==References==
{{Reflist}}

{{DEFAULTSORT:Bias-variance dilemma}}
[[Category:Dilemmas]]
[[Category:Model selection]]
[[Category:Machine learning]]
[[Category:Statistical classification]]</text>
      <sha1>0irdxvh9wvud9c8qzt3hvgz8gmerp2f</sha1>
    </revision>
  </page>
  <page>
    <title>Solomonoff's theory of inductive inference</title>
    <ns>0</ns>
    <id>405562</id>
    <revision>
      <id>1002403869</id>
      <parentid>996802886</parentid>
      <timestamp>2021-01-24T07:44:08Z</timestamp>
      <contributor>
        <username>N4ut1lu5354r3c00l</username>
        <id>25942846</id>
      </contributor>
      <comment>Changed last sentence of intro</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="22400" xml:space="preserve">{{multiple issues|
{{clarity|reason=large swathes of this article are filled with [[WP:JARGON|jargon]] and (unsourced!) vague generalizations|date=June 2017}}
{{refimprove|date=June 2017}}
}}

'''Solomonoff's theory of inductive inference''' is a mathematical theory of [[Inductive reasoning|induction]] introduced by [[Ray Solomonoff]], based on [[probability theory]] and [[Computer science|theoretical computer science]].&lt;ref&gt;{{Cite book|last=Zenil|first=Hector|url=https://books.google.com/books?id=ep_FCgAAQBAJ&amp;q=Algorithmic+Probability+--+Its+Discovery+--+Its+Properties+and+Application+to+Strong+AI&amp;pg=PA149|title=Randomness Through Computation: Some Answers, More Questions|date=2011-02-11|publisher=World Scientific|isbn=978-981-4462-63-1|language=en}}&lt;/ref&gt;&lt;ref&gt;{{Citation|last=Solomonoff|first=Ray J.|title=Algorithmic Probability: Theory and Applications|date=2009|url=https://doi.org/10.1007/978-0-387-84816-7_1|work=Information Theory and Statistical Learning|pages=1–23|editor-last=Emmert-Streib|editor-first=Frank|place=Boston, MA|publisher=Springer US|language=en|doi=10.1007/978-0-387-84816-7_1|isbn=978-0-387-84816-7|access-date=2020-07-21|editor2-last=Dehmer|editor2-first=Matthias}}&lt;/ref&gt;&lt;ref name=":0"&gt;{{Cite book|last=Hoang|first=Lê Nguyên|url=https://www.worldcat.org/oclc/1162366056|title=The equation of knowledge : from Bayes' rule to a unified philosophy of science|isbn=978-0-367-85530-7|edition=First|location=Boca Raton, FL|oclc=1162366056}}&lt;/ref&gt; In essence, Solomonoff's induction derives the [[posterior probability]] of any [[Computability|computable]] theory, given a sequence of observed data. This posterior probability is derived from [[Bayes' theorem|Bayes rule]] and some ''universal'' prior, that is, a prior that assigns a positive probability to any computable theory.

Solomonoff's induction naturally formalizes [[Occam's razor]]&lt;ref name="ReferenceA"&gt;JJ McCall. Induction: From Kolmogorov and Solomonoff to De Finetti and Back to Kolmogorov – Metroeconomica, 2004 – Wiley Online Library.&lt;/ref&gt;&lt;ref name="ReferenceB"&gt;D Stork. Foundations of Occam's razor and parsimony in learning from ricoh.com – NIPS 2001 Workshop, 2001&lt;/ref&gt;&lt;ref name="ReferenceC"&gt;A.N. Soklakov. Occam's razor as a formal basis for a physical theory [https://arxiv.org/abs/math-ph/0009007 from arxiv.org] – Foundations of Physics Letters, 2002 – Springer&lt;/ref&gt;&lt;ref name="Hernandez.1999"&gt;{{cite journal| author=Jose Hernandez-Orallo| title=Beyond the Turing Test| journal=Journal of Logic, Language and Information| year=1999| volume=9| url=http://users.dsic.upv.es/proy/anynt/Beyond.pdf}}&lt;/ref&gt;&lt;ref name="Hutter.2003"&gt;M Hutter. On the existence and convergence of computable universal priors [https://arxiv.org/abs/cs/0305052 arxiv.org] – Algorithmic Learning Theory, 2003 – Springer&lt;/ref&gt; by assigning larger prior credences to theories that require a shorter algorithmic description.

==Origin==

===Philosophical===
The theory is based in philosophical foundations, and was founded by [[Ray Solomonoff]] around 1960.&lt;ref&gt;Samuel Rathmanner and [[Marcus Hutter]]. A philosophical treatise of universal induction. Entropy, 13(6):1076–1136, 2011&lt;/ref&gt; It is a mathematically formalized combination of [[Occam's razor]]&lt;ref name="ReferenceA"/&gt;&lt;ref name="ReferenceB"/&gt;&lt;ref name="ReferenceC"/&gt;&lt;ref name="Hernandez.1999"/&gt;&lt;ref name="Hutter.2003"/&gt; and the [[Principle of Multiple Explanations]].&lt;ref name="Paul Vitanyi p 339"&gt;Ming Li and Paul Vitanyi, ''An Introduction to Kolmogorov Complexity and Its Applications.''  Springer-Verlag, N.Y., 2008p 339 ff.&lt;/ref&gt; All [[computable]] theories which perfectly describe previous observations are used to calculate the probability of the next observation, with more weight put on the shorter computable theories. Marcus Hutter's [[universal artificial intelligence]] builds upon this to calculate the [[expected value]] of an action.

===Principle===
Solomonoff's induction has been argued to be the computational formalization of pure [[Bayesian probability|Bayesianism]].&lt;ref name=":0" /&gt; To understand, recall that Bayesianism derives the posterior probability &lt;math&gt;\mathbb P[T|D]&lt;/math&gt; of a theory &lt;math&gt;T&lt;/math&gt; given data &lt;math&gt;D&lt;/math&gt; by applying Bayes rule, which yields &lt;math&gt;\mathbb P[T|D] = \mathbb P[D|T] \mathbb P[T] / (\mathbb P[D|T] \mathbb P[T] + \sum_{A \neq T} \mathbb P[D|A] \mathbb P[A]) &lt;/math&gt;, where theories &lt;math&gt;A&lt;/math&gt; are alternatives to theory &lt;math&gt;T&lt;/math&gt;. For this equation to make sense, the quantities &lt;math&gt;\mathbb P[D|T]&lt;/math&gt; and &lt;math&gt;\mathbb P[D|A]&lt;/math&gt; must be well-defined for all theories &lt;math&gt;T&lt;/math&gt; and &lt;math&gt;A&lt;/math&gt;. In other words, any theory must define a probability distribution over observable data &lt;math&gt;D&lt;/math&gt;. Solomonoff's induction essentially boils down to demanding in addition that all such probability distributions be [[computable]].

Interestingly, the set of computable probability distributions is a subset of the set of all programs, which is [[Countable_set|countable]]. Similarly, the sets of observable data considered by Solomonoff were finite. Without loss of generality, we can thus consider that any observable data is a finite [[bit_array|bit string]]. As a result, Solomonoff's induction can be defined by only invoking discrete probability distributions.

Solomonoff's induction then allows to make probabilistic predictions of future data &lt;math&gt;F&lt;/math&gt;, by simply obeying the laws of probability. Namely, we have &lt;math&gt;\mathbb P[F|D] = \mathbb E_T [\mathbb P[F|T,D] ] = \sum_T \mathbb P[F|T,D] \mathbb P[T|D]&lt;/math&gt;. This quantity can be interpreted as the average predictions &lt;math&gt;\mathbb P[F|T,D]&lt;/math&gt; of all theories &lt;math&gt;T&lt;/math&gt; given past data &lt;math&gt;D&lt;/math&gt;, weighted by their posterior credences &lt;math&gt;\mathbb P[T|D]&lt;/math&gt;.

===Mathematical===
The proof of the "razor" is based on the known mathematical properties of a probability distribution over a [[countable set]]. These properties are relevant because the infinite set of all programs is a denumerable set. The sum S of the probabilities of all programs must be exactly equal to one (as per the definition of [[probability]]) thus the probabilities must roughly decrease as we enumerate the infinite set of all programs, otherwise S will be strictly greater than one.  To be more precise, for every &lt;math&gt;\epsilon&lt;/math&gt; &gt; 0, there is some length ''l'' such that the probability of all programs longer than ''l'' is at most &lt;math&gt;\epsilon&lt;/math&gt;.  This does not, however, preclude very long programs from having very high probability.

Fundamental ingredients of the theory are the concepts of [[algorithmic probability]]  and [[Kolmogorov complexity]]. The universal [[prior probability]] of any prefix ''p'' of a computable sequence ''x'' is the sum of the probabilities of all programs (for a [[universal computer]]) that compute something starting with ''p''. Given some ''p'' and any computable but unknown probability distribution from which ''x'' is sampled, the universal prior and [[Bayes' theorem]] can be used to predict the yet unseen parts of ''x'' in optimal fashion.

==Mathematical guarantees==

===Solomonoff's completeness===

The remarkable property of Solomonoff's induction is its completeness. In essence, the completeness theorem guarantees that the expected cumulative errors made by the predictions based on Solomonoff's induction are upper-bounded by the [[Kolmogorov complexity]] of the (stochastic) data generating process. The errors can be measured using the [[Kullback–Leibler divergence]] or the square of the difference between the induction's prediction and the probability assigned by the (stochastic) data generating process.

===Solomonoff's uncomputability===

Unfortunately, Solomonoff also proved that Solomonoff's induction is uncomputable. In fact, he showed that [[computability]] and completeness are mutually exclusive: any complete theory must be uncomputable. The proof of this is derived from a game between the induction and the environment. Essentially, any computable induction can be tricked by a computable environment, by choosing the computable environment that negates the computable induction's prediction. This fact can be regarded as an instance of the ''[[no free lunch theorem]]''.

==Modern applications==

===Artificial intelligence===
Though Solomonoff's inductive inference is not [[computable]], several [[AIXI]]-derived algorithms approximate it in order to make it run on a modern computer. The more computing power they are given, the closer their predictions are to the predictions of inductive inference (their mathematical [[limit (math)|limit]] is Solomonoff's inductive inference).&lt;ref&gt;J. Veness, K.S. Ng, M. Hutter, W. Uther, D. Silver. "A Monte Carlo AIXI Approximation" – [https://arxiv.org/abs/0909.0801 Arxiv preprint], 2009 arxiv.org&lt;/ref&gt;&lt;ref&gt;J. Veness, K.S. Ng, M. Hutter, D. Silver. "Reinforcement Learning via AIXI Approximation" [https://arxiv.org/abs/1007.2049 Arxiv preprint], 2010 – aaai.org&lt;/ref&gt;&lt;ref&gt;S. Pankov. A computational approximation to the AIXI model from agiri.org – Artificial general intelligence, 2008: proceedings of …, 2008 – books.google.com&lt;/ref&gt;

Another direction of inductive inference is based on [[E. Mark Gold]]'s model of [[Language identification in the limit|learning in the limit]] from 1967 and has developed since then more and more models of learning.&lt;ref&gt;{{Cite journal | last1 = Gold | first1 = E. Mark | year = 1967 | title = Language identification in the limit | journal = Information and Control | volume = 10 | issue = 5 | pages = 447–474 | doi = 10.1016/S0019-9958(67)91165-5 | url=http://web.mit.edu/~6.863/www/spring2009/readings/gold67limit.pdf }}&lt;/ref&gt; The general scenario is the following: Given a class ''S'' of computable functions, is there a learner (that is, recursive functional) which for any input of the form (''f''(0),''f''(1),...,''f''(''n'')) outputs a hypothesis (an index ''e'' with respect to a previously agreed on acceptable numbering of all computable functions; the indexed function may be required consistent with the given values of ''f''). A learner ''M'' learns a function ''f'' if almost all its hypotheses are the same index ''e'', which generates the function ''f''; ''M'' learns ''S'' if ''M'' learns every ''f'' in ''S''. Basic results are that all recursively enumerable classes of functions are learnable while the class REC of all computable functions is not learnable.{{citation needed|reason=The previously cited paper (Gold 1967) is only about learning of a language, i.e. (a description of) a set of strings, from a sequence of member strings. Another reference is needed for the more general scenario about learning functions from sample values, in particular about the basic results.|date=January 2014}}
Many related models have been considered and also the learning of classes of recursively enumerable sets from positive data is a topic studied from Gold's pioneering paper in 1967 onwards. A far reaching extension of the Gold’s approach is developed by Schmidhuber's theory of generalized Kolmogorov complexities,&lt;ref name="GenKolm"&gt;{{cite journal| author=J. Schmidhuber | title=Hierarchies of generalized Kolmogorov complexities and nonenumerable universal measures computable in the limit | journal=International Journal of Foundations of Computer Science | volume=13 | issue=4 | pages=587–612 | year=2002 | url=ftp://ftp.idsia.ch/pub/juergen/ijfcspreprint.pdf| doi=10.1142/S0129054102001291}}&lt;/ref&gt; which are kinds of [[super-recursive algorithm]]s.

===Turing machines===
{{Unreferenced section|date=June 2017}}

The third mathematically based direction of inductive inference makes use of the theory of automata and computation. In this context, the process of inductive inference is performed by an abstract automaton called an inductive [[Turing machine]] (Burgin, 2005).
''Inductive Turing machines'' represent the next step in the development of computer science providing better models for contemporary computers and computer networks (Burgin, 2001) and forming an important class of super-recursive algorithms as they satisfy all conditions in the definition of [[algorithm]]. Namely, each inductive Turing machine is a type of effective method in which a definite list of well-defined instructions for completing a task, when given an initial state, will proceed through a well-defined series of successive states, eventually terminating in an end-state. The difference between an inductive Turing machine and a [[Turing machine]] is that to produce the result a Turing machine has to stop, while in some cases an inductive Turing machine can do this without stopping. [[Stephen Kleene]] called procedures that could run forever without stopping by the name ''calculation procedure or algorithm'' (Kleene 1952:137). Kleene also demanded that such an algorithm must eventually exhibit "some object" (Kleene 1952:137). This condition is satisfied by inductive Turing machines, as their results are exhibited after a finite number of steps, but inductive Turing machines do not always tell at which step the result has been obtained.

Simple inductive Turing machines are equivalent to other models of computation. More advanced inductive Turing machines are much more powerful. It is proved (Burgin, 2005) that limiting partial recursive functions, trial and error predicates, general Turing machines, and simple inductive Turing machines are equivalent models of computation. However, simple inductive Turing machines and general Turing machines give direct constructions of computing automata, which are thoroughly grounded in physical machines. In contrast, trial and error predicates, limiting recursive functions and limiting partial recursive functions present syntactic systems of symbols with formal rules for their manipulation. Simple inductive Turing machines and general Turing machines are related to limiting partial recursive functions and trial and error predicates as Turing machines are related to partial recursive functions and lambda-calculus.

Note that only simple inductive Turing machines have the same structure (but different functioning semantics of the output mode) as Turing machines. Other types of inductive Turing machines have an essentially more advanced structure due to the structured memory and more powerful instructions. Their utilization for inference and learning allows achieving higher efficiency and better reflects learning of people (Burgin and Klinger, 2004).

Some researchers confuse computations of inductive Turing machines with non-stopping computations or with infinite time computations. First, some of computations of inductive Turing machines halt. As in the case of conventional Turing machines, some halting computations give the result, while others do not give. Second, some non-stopping computations of inductive Turing machines give results, while others do not give. Rules of inductive Turing machines determine when a computation (stopping or non-stopping) gives a result. Namely, an inductive Turing machine produces output from time to time and once this output stops changing, it is considered the result of the computation. It is necessary to know that descriptions of this rule in some papers are incorrect. For instance, Davis (2006: 128) formulates the rule when result is obtained without stopping as "once the correct output has been produced any subsequent output will simply repeat this correct result." Third, in contrast to the widespread misconception, inductive Turing machines give results (when it happens) always after a finite number of steps (in finite time) in contrast to infinite and infinite-time computations.
There are two main distinctions between conventional Turing machines and simple inductive Turing machines. The first distinction is that even simple inductive Turing machines can do much more than conventional Turing machines. The second distinction is that a conventional Turing machine always informs (by halting or by coming to a final state) when the result is obtained, while a simple inductive Turing machine in some cases does inform about reaching the result, while in other cases (where the conventional Turing machine is helpless), it does not inform. People have an illusion that a computer always itself informs (by halting or by other means) when the result is obtained. In contrast to this, users themselves have to decide in many cases whether the computed result is what they need or it is necessary to continue computations. Indeed, everyday desktop computer applications like word processors and spreadsheets spend most of their time waiting in [[event loop]]s, and do not terminate until directed to do so by users.

====Evolutionary inductive Turing machines====
Evolutionary approach to inductive inference is accomplished by another class of automata called evolutionary inductive Turing machines (Burgin and Eberbach, 2009; 2012). An '''evolutionary inductive Turing machine''' is a (possibly infinite) sequence ''E'' = {''A''[''t'']; ''t'' = 1, 2, 3, ... } of inductive Turing machines ''A''[''t''] each working on generations X[t] which are coded as words in the alphabet of the machines ''A''[''t'']. The goal is to build a “population” ''Z'' satisfying the inference condition. The automaton ''A''[''t''] called a component, or a level automaton, of E represents (encodes) a one-level evolutionary algorithm that works with input generations ''X''[''i''] of the population by applying the variation operators v and selection operator s. The first generation ''X''[0] is given as input to ''E'' and is processed by the automaton ''A''[1], which generates/produces the first generation ''X''[1] as its transfer output, which goes to the automaton ''A''[2]. For all ''t'' =&amp;nbsp;1,&amp;nbsp;2,&amp;nbsp;3,&amp;nbsp;..., the automaton ''A''[''t''] receives the generation ''X''[''t''&amp;nbsp;−&amp;nbsp;1] as its input from ''A''[''t''&amp;nbsp;−&amp;nbsp;1] and then applies the variation operator v and selection operator ''s'', producing the generation ''X''[''i''&amp;nbsp;+&amp;nbsp;1] and sending it to ''A''[''t''&amp;nbsp;+&amp;nbsp;1] to continue evolution.

==See also==
* [[Algorithmic information theory]]
* [[Bayesian inference]]
* [[Language identification in the limit]]
* [[Inductive inference]]
* [[Inductive probability]]
* [[Mill's methods]]
* [[Minimum description length]]
* [[Minimum message length]]
* For a philosophical viewpoint, see: [[Problem of induction]] and [[New riddle of induction]]

==References==
{{reflist}}

==Sources==
* {{cite journal| last1=Angluin | first1=Dana | last2= Smith| first2= Carl H.| title=Inductive Inference: Theory and Methods| journal=Computing Surveys|date=Sep 1983| volume=15| number=3| pages=237–269| url=https://dl.acm.org/doi/pdf/10.1145/356914.356918| doi=10.1145/356914.356918| s2cid=3209224 }}
* Burgin, M. (2005), ''Super-recursive Algorithms'', Monographs in computer science, Springer. {{ISBN|0-387-95569-0}}
* Burgin, M., "How We Know What Technology Can Do", ''Communications of the ACM'', v. 44, No. 11, 2001, pp.&amp;nbsp;82–88.
* Burgin, M.; Eberbach, E., "Universality for Turing Machines, Inductive Turing Machines and Evolutionary Algorithms", ''Fundamenta Informaticae'', v. 91, No. 1, 2009, 53–77.
* Burgin, M.; Eberbach, E., "On Foundations of Evolutionary Computation: An Evolutionary Automata Approach", in ''Handbook of Research on Artificial Immune Systems and Natural Computing: Applying Complex Adaptive Technologies'' (Hongwei Mo, Ed.), IGI Global, Hershey, Pennsylvania, 2009, 342–360.
* Burgin, M.; Eberbach, E., "Evolutionary Automata: Expressiveness and Convergence of Evolutionary Computation", ''Computer Journal'', v. 55, No. 9, 2012, pp.&amp;nbsp;1023–1029.
* Burgin, M.; Klinger, A. Experience, Generations, and Limits in Machine Learning, ''Theoretical Computer Science'', v. 317, No. 1/3, 2004, pp.&amp;nbsp;71–91
* [[Martin Davis (mathematician)|Davis, Martin]] (2006) "The Church–Turing Thesis: Consensus and opposition]". Proceedings, Computability in Europe 2006.  Lecture Notes in Computer Science, 3988 pp.&amp;nbsp;125–132.
* [[William Gasarch|Gasarch, W.]]; [[Carl Herbert Smith|Smith, C. H.]] (1997) "A survey of inductive inference with an emphasis on queries". ''Complexity, logic, and recursion theory'', Lecture Notes in Pure and Appl. Math., 187, Dekker, New York, pp.&amp;nbsp;225–260.
* Hay, Nick. "[http://www.cs.auckland.ac.nz/CDMTCS/researchreports/300nick.pdf Universal Semimeasures: An Introduction]," CDMTCS Research Report Series, University of Auckland, Feb. 2007.
* Jain, Sanjay ; Osherson, Daniel ; Royer, James ; Sharma, Arun, ''Systems that Learn: An Introduction to Learning Theory'' (second edition), [[MIT Press]], 1999.
* {{Citation | last1=Kleene | first1=Stephen C. | author1-link=Stephen C. Kleene| title=Introduction to Metamathematics | publisher=North-Holland | location=Amsterdam | year=1952|edition=First}}.
* Li Ming; Vitanyi, Paul, ''An Introduction to Kolmogorov Complexity and Its Applications'', 2nd Edition, Springer Verlag, 1997.
* Osherson, Daniel ; Stob, Michael ; Weinstein, Scott, ''Systems That Learn, An Introduction to Learning Theory for Cognitive and Computer Scientists'', [[MIT Press]], 1986.
* {{cite journal| last = Solomonoff | first = Ray J.| title=Two Kinds of Probabilistic Induction| journal=The Computer Journal| year=1999| volume=42| number=4|doi=10.1093/comjnl/42.4.256 | page=256| citeseerx = 10.1.1.68.8941| url=http://world.std.com/~rjs/compj99.pdf}}
* {{cite journal | doi=10.1016/S0019-9958(64)90223-2 | last=Solomonoff | first= Ray | title=A Formal Theory of Inductive Inference Part I | journal = Information and Control | url=http://world.std.com/~rjs/1964pt1.pdf | volume=7 | issue= 1 | pages= 1&amp;ndash;22 | date=March 1964}}
* {{cite journal | doi=10.1016/S0019-9958(64)90131-7 | last=Solomonoff |first= Ray | title=A Formal Theory of Inductive Inference Part II | journal = Information and Control | url=http://world.std.com/~rjs/1964pt2.pdf |volume=7 |issue= 2 |pages= 224&amp;ndash;254 |date=June 1964}}

==External links==
*[http://www.scholarpedia.org/article/Algorithmic_probability Algorithmic probability – Scholarpedia]

[[Category:Statistical inference]]
[[Category:Inductive reasoning]]
[[Category:Machine learning]]
[[Category:Bayesian statistics]]
[[Category:Algorithmic information theory]]</text>
      <sha1>443tmr1l5grzsm2myzmyzgvh59h1lfz</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Datasets in machine learning</title>
    <ns>14</ns>
    <id>42320378</id>
    <revision>
      <id>601428596</id>
      <timestamp>2014-03-26T23:33:22Z</timestamp>
      <contributor>
        <username>Kri</username>
        <id>253188</id>
      </contributor>
      <comment>Created category</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="68" xml:space="preserve">[[Category:Datasets|Machine learning]]
[[Category:Machine learning]]</text>
      <sha1>9e9amm06w9m0jhho39gaem1cv9kv81o</sha1>
    </revision>
  </page>
  <page>
    <title>Inductive probability</title>
    <ns>0</ns>
    <id>42579971</id>
    <revision>
      <id>993717913</id>
      <parentid>986325301</parentid>
      <timestamp>2020-12-12T02:57:12Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 12 templates: del empty params (2×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="44409" xml:space="preserve">{{short description|Determining the probability of future events based on past events}}
'''Inductive probability''' attempts to give the [[probability]] of future events based on past events. It is the basis for [[inductive reasoning]], and gives the mathematical basis for [[learning]] and the perception of patterns. It is a source of [[knowledge]] about the world.

There are three sources of knowledge: [[inference]], communication, and deduction. Communication relays information found using other methods.  Deduction establishes new facts based on existing facts.  Inference establishes new facts from data. Its basis is [[Bayes' theorem]].

Information describing the world is written in a language. For example, a simple mathematical language of propositions may be chosen. Sentences may be written down in this language as strings of characters.  But in the computer it is possible to encode these sentences as strings of bits (1s and 0s). Then the language may be encoded so that the most commonly used sentences are the shortest. This internal language implicitly represents probabilities of statements.

[[Occam's razor]] says the "simplest theory, consistent with the data is most likely to be  correct". The "simplest theory" is interpreted as the representation of the theory written in this internal language. The theory with the shortest encoding in this internal language is most likely to be correct.

== History ==

Probability and statistics was focused on [[probability distribution]]s and tests of significance.  Probability was formal, well defined, but limited in scope.  In particular its application was limited to situations that could be defined as an experiment or trial, with a well defined population.

[[Bayes's theorem]] is named after Rev. [[Thomas Bayes]] 1701–1761. [[Bayesian inference]] broadened the application of probability to many situations where a population was not well defined.  But Bayes' theorem always depended on prior probabilities, to generate new probabilities. It was unclear where these prior probabilities should come from.

[[Ray Solomonoff]] developed [[algorithmic probability]] which gave an explanation for what randomness is and how patterns in the data may be represented by computer programs, that give shorter representations of the data circa 1964.

[[Chris Wallace (computer scientist)|Chris Wallace]] and D. M. Boulton developed [[minimum message length]] circa 1968. Later [[Jorma Rissanen]] developed the [[minimum description length]] circa 1978. These methods allow [[information theory]] to be related to probability, in a way that can be compared to the application of Bayes' theorem, but which give a source and explanation for the role of prior probabilities.

[[Marcus Hutter]] combined [[decision theory]] with the work of Ray Solomonoff and [[Andrey Kolmogorov]] to give a theory for the [[Pareto efficiency|Pareto optimal]] behavior for an [[Intelligent agent]], circa 1998.
 
===Minimum description/message length===

The program with the shortest length that matches the data is the most likely to predict future data. This is the thesis behind the [[minimum message length]]&lt;ref&gt;{{cite journal|last=Wallace|first=Chris| author2=Boulton |title=An information measure for classification |journal=Computer Journal|year=1968|volume=11|issue=2|pages=185–194|doi=10.1093/comjnl/11.2.185|doi-access=free}}&lt;/ref&gt; and [[minimum description length]]&lt;ref&gt;{{Cite journal | last1 = Rissanen | first1 = J. | title = Modeling by shortest data description | doi = 10.1016/0005-1098(78)90005-5 | journal = Automatica | volume = 14 | issue = 5 | pages = 465–658 | year = 1978 }}&lt;/ref&gt; methods.

At first sight [[Bayes' theorem]] appears different from the minimimum message/description length principle. At closer inspection it turns out to be the same. Bayes' theorem is about conditional probabilities, and states the probability that event ''B'' happens if firstly event ''A'' happens:

:&lt;math&gt;P(A \land B) = P(B) \cdot P(A |  B) = P(A) \cdot P(B |  A)&lt;/math&gt;

becomes in terms of message length ''L'',
:&lt;math&gt;L(A \land B) = L(B) + L(A |  B) = L(A) + L(B |  A).&lt;/math&gt;

This means that if all the information is given describing an event then the length of the information may be used to give the raw probability of the event. So if the information describing the occurrence of ''A'' is given, along with the information describing ''B'' given ''A'', then all the information describing ''A'' and ''B'' has been given.&lt;ref&gt;
{{cite web
|last=Allison
|first=Lloyd
|title=Minimum Message Length (MML) – LA's MML introduction
|url=http://www.csse.monash.edu.au/~lloyd/tildeMML
}}&lt;/ref&gt;
&lt;ref&gt;
{{cite document
|last=Oliver
|first=J. J.
|last2=Baxter
|first2=Rohan A.
|title=MML and Bayesianism: Similarities and Differences (Introduction to Minimum Encoding Inference – Part II)
|year=1994
|url=http://citeseerx.ist.psu.edu/viewdoc/similar;jsessionid=65475C44F4C425AFE77BCAE59D49CE92?doi=10.1.1.1.7367&amp;type=ab}}&lt;/ref&gt;

====Overfitting====

[[Overfitting]] occurs when the model matches the random noise and not the pattern in the data. For example, take the situation where a curve is fitted to a set of points. If a polynomial with many terms is fitted then it can more closely represent the data. Then the fit will be better, and the information needed to describe the deviations from the fitted curve will be smaller. Smaller information length means higher probability.

However, the information needed to describe the curve must also be considered. The total information for a curve with many terms may be greater than for a curve with fewer terms, that has not as good a fit, but needs less information to describe the polynomial.

===Inference based on program complexity===

[[Solomonoff's theory of inductive inference]] is also inductive inference.  A bit string ''x'' is observed.  Then consider all programs that generate strings starting with ''x''.  Cast in the form of inductive inference, the programs are theories that imply the observation of the bit string ''x''.

The method used here to give probabilities for inductive inference is based on [[Solomonoff's theory of inductive inference]].

====Detecting patterns in the data====

If all the bits are 1, then people infer that there is a bias in the coin and that it is more likely also that the next bit is 1 also. This is described as learning from, or detecting a pattern in the data.

Such a pattern may be represented by a [[computer program]]. A short computer program may be written that produces a series of bits which are all 1. If the length of the program ''K'' is &lt;math&gt;L(K)&lt;/math&gt; bits then its prior probability is,
:&lt;math&gt;P(K) = 2^{-L(K)}&lt;/math&gt;

The length of the shortest program that represents the string of bits is called the [[Kolmogorov complexity]].

Kolmogorov complexity is not computable.  This is related to the [[halting problem]].  When searching for the shortest program some programs may go into an infinite loop.

====Considering all theories====

The Greek philosopher [[Epicurus]] is quoted as saying "If more than one theory is consistent with the observations, keep all theories".&lt;ref&gt;Li, M. and Vitanyi, P., ''An Introduction to Kolmogorov Complexity and Its Applications'', 3rd Edition, Springer Science and Business Media, N.Y., 2008, p 347&lt;/ref&gt;

As in a crime novel all theories must be considered in determining the likely murderer, so with inductive probability all programs must be considered in determining the likely future bits arising from the stream of bits.

Programs that are already longer than ''n'' have no predictive power. The raw (or prior) probability that the pattern of bits is random (has no pattern) is &lt;math&gt;2^{-n}&lt;/math&gt;.

Each program that produces the sequence of bits, but is shorter than the ''n'' is a theory/pattern about the bits with a probability of &lt;math&gt;2^{-k}&lt;/math&gt; where ''k'' is the length of the program.

The probability of receiving a sequence of bits ''y'' after receiving a series of bits ''x'' is then the [[conditional probability]] of receiving ''y'' given ''x'', which is the probability of ''x'' with ''y'' appended, divided by the probability of ''x''.&lt;ref&gt;Solomonoff, R., "[http://world.std.com/~rjs/rayfeb60.pdf A Preliminary Report on a General Theory of Inductive Inference]", Report V-131, Zator Co., Cambridge, Ma. Feb 4, 1960, [http://world.std.com/~rjs/z138.pdf revision], Nov., 1960.&lt;/ref&gt;&lt;ref&gt;Solomonoff, R., "[http://world.std.com/~rjs/1964pt1.pdf A Formal Theory of Inductive Inference, Part I]" ''Information and Control'', Vol 7, No. 1 pp 1–22, March 1964.&lt;/ref&gt;&lt;ref&gt;Solomonoff, R., "[http://world.std.com/~rjs/1964pt2.pdf A Formal Theory of Inductive Inference, Part II]" ''Information and Control'', Vol 7, No. 2 pp 224–254, June 1964.&lt;/ref&gt;

====Universal priors====

The programming language affects the predictions of the next bit in the string.  The language acts as a [[prior probability]].  This is particularly a problem where the programming language codes for numbers and other data types.  Intuitively we think that 0 and 1 are simple numbers, and that prime numbers are somehow more complex than numbers that may be composite.

Using the [[Kolmogorov complexity]] gives an unbiased estimate (a universal prior) of the prior probability of a number.  As a thought experiment an [[intelligent agent]] may be fitted with a data input device giving a series of numbers, after applying some transformation function to the raw numbers.  Another agent might have the same input device with a different transformation function.  The agents do not see or know about these transformation functions.  Then there appears no rational basis for preferring one function over another.  A universal prior insures that although two agents may have different initial probability distributions for the data input, the difference will be bounded by a constant.

So universal priors do not eliminate an initial bias, but they reduce and limit it.  Whenever we describe an event in a language, either using a natural language or other, the language has encoded in it our prior expectations. So some reliance on prior probabilities are inevitable.

A problem arises where an intelligent agent's prior expectations interact with the environment to form a self reinforcing feed back loop. This is the problem of bias or prejudice.  Universal priors reduce but do not eliminate this problem.

===Universal artificial intelligence===

The theory of [[universal artificial intelligence]] applies [[decision theory]]  to inductive probabilities.  The theory shows how the best actions to optimize a reward function may be chosen.  The result is a theoretical model of intelligence.&lt;ref&gt;{{cite book |last=Hutter|first=Marcus |title=Sequential Decisions Based on Algorithmic Probability |year=1998|publisher=Springer |isbn=3-540-22139-5}}&lt;/ref&gt;

It is a fundamental theory of intelligence, which optimizes the agents behavior in,
* Exploring the environment; performing actions to get responses that broaden the agents knowledge.
* Competing or co-operating with another agent; games.
* Balancing short and long term rewards.

In general no agent will always provide the best actions in all situations.  A particular choice made by an agent may be wrong, and the environment may provide no way for the agent to recover from an initial bad choice.  However the agent is [[Pareto optimal]] in the sense that no other agent will do better than this agent in this environment, without doing worse in another environment.  No other agent may, in this sense, be said to be better.

At present the theory is limited by incomputability (the [[halting problem]]).  Approximations may be used to avoid this.  Processing speed and [[combinatorial explosion]] remain the primary limiting factors for [[artificial intelligence]].

== Probability ==

Probability is the representation of uncertain or partial knowledge about the truth of statements. Probabilities are subjective and personal estimates of likely outcomes based on past experience and inferences made from the data.

This description of probability may seem strange at first.  In natural language we refer to "the probability" that the sun will rise tomorrow.  We do not refer to "your probability" that the sun will rise.  But in order for inference to be correctly modeled probability must be personal, and the act of inference generates new posterior probabilities from prior probabilities.

Probabilities are personal because they are conditional on the knowledge of the individual.  Probabilities are subjective because they always depend, to some extent, on prior probabilities assigned by the individual. Subjective should not be taken here to mean vague or undefined.

The term [[intelligent agent]] is used to refer to the holder of the probabilities.  The intelligent agent may be a human or a machine. If the intelligent agent does not interact with the environment then the probability will converge over time to the frequency of the event.

If however the agent uses the probability to interact with the environment there may be a feedback, so that two agents in the identical environment starting with only slightly different priors, end up with completely different probabilities. In this case optimal [[decision theory]] as in [[Marcus Hutter|Marcus Hutter's]] Universal Artificial Intelligence will give [[Pareto optimal]] performance for the agent. This means that no other intelligent agent could do better in one environment without doing worse in another environment.

=== Comparison to deductive probability ===

In deductive probability theories, probabilities are absolutes, independent of the individual making the assessment. But deductive probabilities are based on,
* Shared knowledge.
* Assumed facts, that should be inferred from the data.

For example, in a trial the participants are aware the outcome of all the previous history of trials. They also assume that each outcome is equally probable.  Together this allows a single unconditional value of probability to be defined.

But in reality each individual does not have the same information. And in general the probability of each outcome is not equal.  The dice may be loaded, and this loading needs to be inferred from the data.

=== Probability as estimation ===

The [[principle of indifference]] has played a key role in probability theory. It says that if N statements are symmetric so that one condition cannot be preferred over another then all statements are equally probable.&lt;ref&gt;{{cite web|last1=Carnap|first1=Rudolf|title=STATISTICAL AND INDUCTIVE PROBABILITY|url=http://fitelson.org/probability/carnap_saip.pdf|author1-link=Carnap}}&lt;/ref&gt;

Taken seriously, in evaluating probability this principle leads to contradictions.  Suppose there are 3 bags of gold in the distance and one is asked to select one. Then because of the distance one cannot see the bag sizes. You estimate using the principle of indifference that each bag has equal amounts of gold, and each bag has one third of the gold.

Now, while one of us is not looking, the other takes one of the bags and divide it into 3 bags.  Now there are 5 bags of gold. The principle of indifference now says each bag has one fifth of the gold. A bag that was estimated to have one third of the gold is now estimated to have one fifth of the gold.

Taken as a value associated with the bag the values are different therefore contradictory. But taken as an estimate given under a particular scenario, both values are separate estimates given under different circumstances and there is no reason to believe they are equal.

Estimates of prior probabilities are particularly suspect. Estimates will be constructed that do not follow any consistent frequency distribution. For this reason prior probabilities are considered as estimates of probabilities rather than probabilities.

A full theoretical treatment would associate with each probability,
* The statement
* Prior knowledge
* Prior probabilities
* The estimation procedure used to give the probability.

===Combining probability approaches===

Inductive probability combines two different approaches to probability.
* Probability and information
* Probability and frequency

Each approach gives a slightly different viewpoint.  Information theory is used in relating probabilities to quantities of information.  This approach is often used in giving estimates of prior probabilities.

[[Frequentist probability]] defines probabilities as objective statements about how often an event occurs.  This approach may be stretched by defining the [[Experiment (probability theory)|trials]] to be over [[possible world]]s.  Statements about possible worlds define [[Event (probability theory)|events]].

== Probability and information ==

Whereas logic represents only two values; true and false as the values of statement, probability associates a number in [0,1] to each statement. If the probability of a statement is 0, the statement is false.  If the probability of a statement is 1 the statement is true.

In considering some data as a string of bits the prior probabilities for a sequence of 1s and 0s, the probability of 1 and 0 is equal. Therefore, each extra bit halves the probability of a sequence of bits.
This leads to the conclusion that,
:&lt;math&gt;P(x) = 2^{-L(x)}&lt;/math&gt;
Where &lt;math&gt;P(x)&lt;/math&gt; is the probability of the string of bits &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;L(x)&lt;/math&gt; is its length.

The prior probability of any statement is calculated from the number of bits needed to state it.  See also [[information theory]].

=== Combining information ===

Two statements &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt; may be represented by two separate encodings. Then the length of the encoding is,

: &lt;math&gt;L(A \land B) = L(A) + L(B)&lt;/math&gt;

or in terms of probability,

: &lt;math&gt;P(A \land B) = P(A) P(B)&lt;/math&gt;

But this law is not always true because there may be a shorter method of encoding &lt;math&gt;B&lt;/math&gt; if we assume &lt;math&gt;A&lt;/math&gt;. So the above probability law applies only if &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt; are "independent".

===The internal language of information===

The primary use of the information approach to probability is to provide estimates of the complexity of statements. Recall that Occam's razor states that "All things being equal, the simplest theory is the most likely to be correct". In order to apply this rule, first there needs to be a definition of what "simplest" means. Information theory defines simplest to mean having the shortest encoding.

Knowledge is represented as [[Statement (logic)|statements]]. Each statement is a [[Boolean algebra|Boolean]] [[Expression (mathematics)|expression]]. Expressions are encoded by a function that takes a description (as against the value) of the expression and encodes it as a bit string.

The length of the encoding of a statement gives an estimate of the probability of a statement. This probability estimate will often be used as the prior probability of a statement.

Technically this estimate is not a probability because it is not constructed from a frequency distribution. The probability estimates given by it do not always obey [[#The law of total of probability|the law of total of probability]]. Applying the law of total probability to various scenarios will usually give a more accurate probability estimate of the prior probability than the estimate from the length of the statement.

====Encoding expressions====

An expression is constructed from sub expressions,
* Constants (including function identifier).
* Application of functions.
* [[Quantifier (logic)|quantifiers]].

A [[Huffman coding|Huffman code]] must distinguish the 3 cases. The length of each code is based on the frequency of each type of sub expressions.

Initially constants are all assigned the same length/probability. Later constants may be assigned a probability using the Huffman code based on the number of uses of the function id in all expressions recorded so far. In using a Huffman code the goal is to estimate probabilities, not to compress the data.

The length of a function application is the length of the function identifier constant plus the sum of the sizes of the expressions for each parameter.

The length of a quantifier is the length of the expression being quantified over.

====Distribution of numbers====

No explicit representation of natural numbers is given.  However natural numbers may be constructed by applying the successor function to 0, and then applying other arithmetic functions.  A distribution of natural numbers is implied by this, based on the complexity of constructing each number.

Rational numbers are constructed by the division of natural numbers. The simplest representation has no common factors between the numerator and the denominator. This allows the probability distribution of natural numbers may be extended to rational numbers.

== Probability and frequency ==

The probability of an [[Event (probability theory)|event]] may be interpreted as the frequencies of [[Outcome (probability)|outcomes]] where the statement is true divided by the total number of outcomes.  If the outcomes form a continuum the frequency may need to be replaced with a [[Probability measure|measure]].

Events are sets of outcomes. Statements may be related to events. A Boolean statement B about outcomes defines a set of outcomes b,
: &lt;math&gt; b = \{x : B(x)\} &lt;/math&gt;
 
=== Conditional probability ===

Each probability is always associated with the state of knowledge at a particular point in the argument. Probabilities before an inference are known as prior probabilities, and probabilities after are known as posterior probabilities.

Probability depends on the facts known. The truth of a fact limits the domain of outcomes to the outcomes consistent with the fact. Prior probabilities are the probabilities before a fact is known. Posterior probabilities are after a fact is known. The posterior probabilities are said to be conditional on the fact. the probability that &lt;math&gt;B&lt;/math&gt; is true given that &lt;math&gt;A&lt;/math&gt; is true is written as: &lt;math&gt;P(B  |  A).&lt;/math&gt;

All probabilities are in some sense conditional.  The prior probability of &lt;math&gt;B&lt;/math&gt; is,
: &lt;math&gt;P(B) = P(B  | \top)&lt;/math&gt;

=== The frequentist approach applied to possible worlds ===

In the [[Frequentist inference|frequentist approach]], probabilities are defined as the ratio of the number of [[Outcome (probability)|outcomes]] within an event to the total number of outcomes. In the [[possible world]] model each possible world is an outcome, and statements about possible worlds define events. The probability of a statement being true is the number of possible worlds where the statement is true divided by the total number of possible worlds. The probability of a statement &lt;math&gt;A&lt;/math&gt; being true about possible worlds is then,
: &lt;math&gt; P(A) = \frac{|\{x : A(x)\}|}{|x : \top|} &lt;/math&gt;

For a conditional probability.
: &lt;math&gt; P(B  |  A) = \frac{|\{x : A(x) \land B(x)\}|}{|x : A(x)|} &lt;/math&gt;

then

: &lt;math&gt; \begin{align} P(A \land B) &amp;= \frac{|\{x : A(x) \land B(x)\}|}{|x : \top|} \\[8pt]
&amp;= \frac{|\{x : A(x) \land B(x)\}|}{|\{x : A(x)\}|} \frac{|\{x : A(x)\}|}{|x : \top|} \\[8pt]
&amp;= P(A) P(B  |  A) 
\end{align}&lt;/math&gt;

Using symmetry this equation may be written out as Bayes' law.
: &lt;math&gt; P(A \land B) = P(A) P(B  |  A) = P(B) P(A  |  B)&lt;/math&gt;

This law describes the relationship between prior and posterior probabilities when new facts are learnt.

Written as quantities of information [[Bayes' Theorem]] becomes,
: &lt;math&gt;L(A \land B) = L(A) + L(B  |  A) = L(B) + L(A  |  B)&lt;/math&gt;

Two statements A and B are said to be independent if knowing the truth of A does not change the probability of B. Mathematically this is,
: &lt;math&gt;P(B) = P(B  |  A)&lt;/math&gt;

then [[Bayes' Theorem]] reduces to,
: &lt;math&gt;P(A \land B) = P(A) P(B)&lt;/math&gt;

=== The law of total of probability ===

For a set of mutually exclusive possibilities &lt;math&gt;A_i&lt;/math&gt;, the sum of the posterior probabilities must be 1.
: &lt;math&gt;\sum_i{P(A_i  |  B)} = 1&lt;/math&gt;

Substituting using Bayes' theorem gives the [[law of total probability]]
: &lt;math&gt;\sum_i{P(B  |  A_i)P(A_i)} = \sum_i{P(A_i  |  B)P(B)}&lt;/math&gt;

: &lt;math&gt;P(B) = \sum_i{P(B  |  A_i) P(A_i)}&lt;/math&gt;

This result is used to give the [[Bayes' theorem#extended form|extended form of Bayes' theorem]],
: &lt;math&gt;P(A_i  |  B) = \frac{P(B  |  A_i) P(A_i)}{\sum_j{P(B  |  A_j) P(A_j)}}&lt;/math&gt;

This is the usual form of Bayes' theorem used in practice, because it guarantees the sum of all the posterior probabilities for &lt;math&gt;A_i&lt;/math&gt; is 1.

=== Alternate possibilities ===

For mutually exclusive possibilities, the probabilities add.
:&lt;math&gt; P(A \lor B) = P(A) + P(B), \qquad \text{if }  P(A \land B) = 0 &lt;/math&gt;

Using
: &lt;math&gt; A \lor B = (A \land \neg (A \land B)) \lor (B \land \neg (A \land B)) \lor (A \land B)&lt;/math&gt;
Then the alternatives
: &lt;math&gt; A \land \neg (A \land B), \quad  B \land \neg (A \land B), \quad A \land B &lt;/math&gt;
are all mutually exclusive. Also,
: &lt;math&gt; (A \land \neg (A \land B)) \lor (A \land B) = A &lt;/math&gt;
: &lt;math&gt; P(A \land \neg (A \land B)) + P(A \land B) = P(A) &lt;/math&gt;
: &lt;math&gt; P(A \land \neg (A \land B)) = P(A) - P(A \land B)  &lt;/math&gt;

so, putting it all together,

: &lt;math&gt; \begin{align}
P(A \lor B) &amp;= P((A \land \neg (A \land B)) \lor (B \land \neg (A \land B)) \lor (A \land B))  \\
&amp; = P(A \land \neg (A \land B) + P(B \land \neg (A \land B)) + P(A \land B) \\
&amp;= P(A) - P(A \land B) + P(B) - P(A \land B) + P(A \land B) \\
&amp;= P(A) + P(B) - P(A \land B) 
\end{align}&lt;/math&gt;

=== Negation ===

As,
: &lt;math&gt; A \lor \neg A = \top &lt;/math&gt;
then
: &lt;math&gt; P(A) + P(\neg A) = 1&lt;/math&gt;

=== Implication and condition probability ===

Implication is related to conditional probability by the following equation,
:&lt;math&gt;A \to B \iff P(B  |  A) = 1&lt;/math&gt;

Derivation,

:&lt;math&gt;\begin{align}
A \to B &amp; \iff P(A \to B) = 1 \\
&amp;\iff P(A \land B \lor \neg A) = 1 \\
&amp;\iff P(A \land B) + P(\neg A) = 1 \\
&amp;\iff P(A \land B) = P(A) \\
&amp;\iff P(A) \cdot P(B  |  A) = P(A) \\
&amp;\iff P(B  |  A) = 1
\end{align}&lt;/math&gt;

== Bayesian hypothesis testing ==

Bayes' theorem may be used to estimate the probability of a hypothesis or theory H, given some facts F. The posterior probability of H is then

: &lt;math&gt;P(H  |  F) = \frac{P(H)P(F  |  H)}{P(F)}&lt;/math&gt;

or in terms of information,
: &lt;math&gt;P(H  |  F) = 2^{-(L(H) + L(F  |  H) - L(F))} &lt;/math&gt;

By assuming the hypothesis is true, a simpler representation of the statement F may be given. The length of the encoding of this simpler representation is &lt;math&gt;L(F  |  H).&lt;/math&gt;

&lt;math&gt;L(H) + L(F  |  H) &lt;/math&gt; represents the amount of information needed to represent the facts F, if H is true. &lt;math&gt;L(F)&lt;/math&gt; is the amount of information needed to represent F without the hypothesis H. The difference is how much the representation of the facts has been compressed by assuming that H is true.  This is the evidence that the hypothesis H is true.

If &lt;math&gt;L(F)&lt;/math&gt; is estimated from [[#Probability priors from encoding length|encoding length]] then the probability obtained will not be between 0 and 1. The value obtained is proportional to the probability, without being a good probability estimate. The number obtained is sometimes referred to as a relative probability, being how much more probable the theory is than not holding the theory.

If a full set of mutually exclusive hypothesis that provide evidence is known, a proper estimate may be given for the prior probability &lt;math&gt;P(F)&lt;/math&gt;.

===Set of hypothesis===

Probabilities may be calculated from the extended form of Bayes' theorem. Given all mutually exclusive hypothesis &lt;math&gt;H_i&lt;/math&gt; which give evidence, such that,
: &lt;math&gt;L(H_i) + L(F  |  H_i) &lt; L(F)&lt;/math&gt;

and also the hypothesis R, that none of the hypothesis is true, then,
: &lt;math&gt; \begin{align}
P(H_i  |  F) &amp;= \frac{P(H_i) P(F  |  H_i)}{P(F|R) + \sum_j{P(H_j) P(F  |  H_j)}} \\[8pt]
P(R  |  F) &amp;= \frac{P(F  |  R)}{P(F  |  R) + \sum_j{P(H_j) P(F  |  H_j)}}
\end{align}&lt;/math&gt;

In terms of information,

: &lt;math&gt;\begin{align}
P(H_i | F) &amp;= \frac{2^{-(L(H_i) + L(F  |  H_i))}}{2^{-L(F  |  R)} + \sum_j 2^{-(L(H_j) + L(F |  H_j)) }} \\[8pt]
P(R| F) &amp;= \frac{2^{-L(F  |  R)}}{2^{-L(F  |  R)} + \sum_j{2^{-(L(H_j) + L(F  |  H_j))}}}
\end{align}&lt;/math&gt;

In most situations it is a good approximation to assume that &lt;math&gt;F&lt;/math&gt; is independent of &lt;math&gt;R&lt;/math&gt;, which means &lt;math&gt;P(F  |  R) = P(F)&lt;/math&gt; giving,

: &lt;math&gt;\begin{align}
P(H_i  |  F) &amp;\approx \frac{2^{-(L(H_i) + L(F  |  H_i))}}{2^{-L(F)} + \sum_j{2^{-(L(H_j) + L(F|H_j))}}} \\[8pt]
P(R  |  F) &amp;\approx \frac{2^{-L(F)}}{2^{-L(F)} + \sum_j{2^{-(L(H_j) + L(F  |  H_j))}}}
\end{align}&lt;/math&gt;

==Boolean inductive inference==

[[Abductive reasoning#Probabilistic abduction|Abductive inference]] &lt;ref&gt;{{cite book |title=Abduction |year=2017 |publisher=Metaphysics Research Lab, Stanford University |url=http://plato.stanford.edu/entries/abduction/ }}&lt;/ref&gt;&lt;ref&gt;{{cite journal| first1=Niki| last1=Pfeifer|first2=Gernot D.|last2=Kleiter|title=INFERENCE IN CONDITIONAL PROBABILITY LOGIC|journal=Kybernetika |date=2006 |volume=42|issue=4 |pages=391–404}}&lt;/ref&gt;&lt;ref&gt;{{cite web |title=Conditional Probability |url=http://artint.info/html/ArtInt_142.html |work=Artificial Intelligence - Foundations of computational agents}}&lt;/ref&gt;&lt;ref&gt;{{cite web |title=Introduction to the theory of Inductive Logic Programming (ILP) |url=http://www.cs.ox.ac.uk/activities/machlearn/ilp_theory.html}}&lt;/ref&gt; starts with a set of facts ''F'' which is a statement (Boolean expression).  [[Abductive reasoning]] is of the form,

:''A theory T implies the statement F.  As the theory T is simpler than F, abduction says that there is a probability that the theory T is implied by F''.

The theory ''T'', also called an explanation of the condition ''F'', is an answer to the ubiquitous factual "why" question.  For example, for the condition ''F'' is "Why do apples fall?". The answer is a theory ''T'' that implies that apples fall;
:&lt;math&gt;F = G \frac{m_1 m_2}{r^2}&lt;/math&gt;

Inductive inference is of the form,
:''All observed objects in a class C have a property P.  Therefore there is a probability that all objects in a class C have a property P''.

In terms of abductive inference, ''all objects in a class C or set have a property P'' is a theory that implies the observed condition, ''All observed objects in a class C have a property P''.

So [[inductive inference]] is a special case of abductive inference.  In common usage the term inductive inference is often used to refer to both abductive and inductive inference.

===Generalization and specialization===

Inductive inference is related to [[generalization]].  Generalizations may be formed from statements by replacing a specific value with membership of a category, or by replacing membership of a category with membership of a broader category.  In deductive logic, generalization is a powerful method of generating new theories that may be true. In inductive inference generalization generates theories that have a probability of being true.

The opposite of generalization is specialization.  Specialization is used in applying a general rule to a specific case.  Specializations are created from generalizations by replacing membership of a category by a specific value, or by replacing a category with a sub category.

The [[Carl Linnaeus|Linnaen]] classification of living things and objects forms the basis for generalization and specification. The ability to identify, recognize and classify is the basis for generalization. Perceiving the world as a collection of objects appears to be a key aspect of human intelligence.  It is the object oriented model, in the non [[computer science]] sense.

The object oriented model is constructed from our [[perception]]. In particularly [[Visual perception|vision]] is based on the ability to compare two images and calculate how much information is needed to morph or map one image into another.  [[Computer vision]] uses this mapping to construct 3D images from [[Stereoscopy|stereo image pairs]].

[[Inductive logic programming]] is a means of constructing theory that implies a condition.  Plotkin's &lt;ref&gt;{{cite journal|first1=Gordon D.|last1=Plotkin|title=A Note on Inductive Generalization|editor1-first=B.|editor1-last=Meltzer|editor2-first=D.|editor2-last=Michie|publisher=Edinburgh University Press|journal=Machine Intelligence|volume=5|pages=153–163|year=1970}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|first1=Gordon D.|last1=Plotkin|title=A Further Note on Inductive Generalization|editor1-first=B.|editor1-last=Meltzer|editor2-first=D.|editor2-last=Michie|publisher=Edinburgh University Press|journal=Machine Intelligence|volume=6|pages=101–124|year=1971}}&lt;/ref&gt; "''relative least general generalization (rlgg)''" approach constructs the simplest generalization consistent with the condition.

===Newton's use of induction===

[[Isaac Newton]] used inductive arguments in constructing his [[Newton's law of universal gravitation|law of universal gravitation]].&lt;ref&gt;Isaac Newton: "In [experimental] philosophy particular propositions are inferred from the phenomena and afterwards rendered general by induction": "[[Philosophiae Naturalis Principia Mathematica|Principia]]", Book 3, General Scholium, at p.392 in Volume 2 of Andrew Motte's English translation published 1729.&lt;/ref&gt; Starting with the statement,
* The center of an apple falls towards the center of the earth.

Generalizing by replacing apple for object, and earth for object gives, in a two body system,
* The center of an object falls towards the center of another object.

The theory explains all objects falling, so there is strong evidence for it. The second observation,
* The planets appear to follow an elliptical path.

After some complicated mathematical [[calculus]], it can be seen that if the acceleration follows the inverse square law then objects will follow an ellipse. So induction gives evidence for the inverse square law.

Using [[Galileo Galilei|Galileo's]] observation that all objects drop with the same speed,
:&lt;math&gt;F_1 = m_1 a_1 = \frac{m_1 k_1}{r^2} i_1&lt;/math&gt;
:&lt;math&gt;F_2 = m_2 a_2 = \frac{m_2 k_2}{r^2} i_2&lt;/math&gt;

where &lt;math&gt;i_1&lt;/math&gt; and &lt;math&gt;i_2&lt;/math&gt; vectors towards the center of the other object. Then using [[Newton's laws of motion#Newton's third law|Newton's third law]] &lt;math&gt;F_1 = -F_2&lt;/math&gt;
:&lt;math&gt;F = G\frac{m_1 m_2}{r^2}&lt;/math&gt;

===Probabilities for inductive inference===

[[#Implication and condition probability|Implication determines condition probability]] as,
:&lt;math&gt;T \to F \iff P(F  |  T) = 1&lt;/math&gt;

So,
: &lt;math&gt;P(F  |  T) = 1&lt;/math&gt;
: &lt;math&gt;L(F  |  T) = 0&lt;/math&gt;

This result may be used in the probabilities given for Bayesian hypothesis testing. For a single theory, H = T and,
: &lt;math&gt;P(T  |  F) = \frac{P(T)}{P(F)}&lt;/math&gt;

or in terms of information, the relative probability is,
: &lt;math&gt;P(T  |  F) = 2^{-(L(T) - L(F))} &lt;/math&gt;

Note that this estimate for P(T|F) is not a true probability. If &lt;math&gt;L(T_i) &lt; L(F)&lt;/math&gt; then the theory has evidence to support it. Then for a set of theories &lt;math&gt;T_i = H_i&lt;/math&gt;, such that &lt;math&gt;L(T_i) &lt; L(F)&lt;/math&gt;,

: &lt;math&gt;P(T_i  |  F) = \frac{P(T_i)}{P(F  |  R) + \sum_j{P(T_j)}}&lt;/math&gt;
: &lt;math&gt;P(R  |  F) = \frac{P(F  |  R)}{P(F  |  R) + \sum_j{P(T_j)}}&lt;/math&gt;

giving,
: &lt;math&gt;P(T_i  |  F) \approx \frac{2^{-L(T_i)}}{2^{-L(F)} + \sum_j{2^{-L(T_j)}}}&lt;/math&gt;
: &lt;math&gt;P(R  |  F) \approx \frac{2^{-L(F)}}{2^{-L(F)} + \sum_j{2^{-L(T_j)}}}&lt;/math&gt;

==Derivations==

===Derivation of inductive probability===

Make a list of all the shortest programs &lt;math&gt;K_i&lt;/math&gt; that each produce a distinct infinite string of bits, and satisfy the relation,

:&lt;math&gt;T_n(R(K_i)) = x&lt;/math&gt;

where &lt;math&gt;R(K_i)&lt;/math&gt; is the result of running the program &lt;math&gt;K_i&lt;/math&gt; and &lt;math&gt;T_n&lt;/math&gt; truncates the string after ''n'' bits.

The problem is to calculate the probability that the source is produced by program &lt;math&gt;K_i,&lt;/math&gt; given that the truncated source after n bits is ''x''. This is represented by the conditional probability,

:&lt;math&gt;P(s = R(K_i) |  T_n(s) = x)&lt;/math&gt;

Using the [[Bayes' theorem#Extended form|extended form of Bayes' theorem]]

:&lt;math&gt;P(s = R(K_i) |T_n(s) = x) = \frac{P(T_n(s) = x|s = R(K_i))P(s = R(K_i))}{\sum_j P(T_n(s) = x|s = R(K_j)) P(s = R(K_j))}.&lt;/math&gt;

The extended form relies on the [[law of total probability]]. This means that the &lt;math&gt;s = R(K_i) &lt;/math&gt; must be distinct possibilities, which is given by the condition that each &lt;math&gt;K_i&lt;/math&gt; produce a different infinite string. Also one of the conditions &lt;math&gt;s = R(K_i) &lt;/math&gt; must be true. This must be true, as in the limit as &lt;math&gt;n \to \infty,&lt;/math&gt; there is always at least one program that produces &lt;math&gt;T_n(s)&lt;/math&gt;.

As &lt;math&gt;K_i&lt;/math&gt; are chosen so that &lt;math&gt;T_n(R(K_i)) = x,&lt;/math&gt; then,
:&lt;math&gt;P(T_n(s) = x |  s = R(K_i)) = 1 &lt;/math&gt;

The apriori probability of the string being produced from the program, given no information about the string, is based on the size of the program,
:&lt;math&gt;P(s = R(K_i)) = 2^{-I(K_i)}&lt;/math&gt;

giving,
:&lt;math&gt;P(s = R(K_i) |  T_n(s) = x) = \frac{2^{-I(K_i)}}{\sum_j 2^{-I(K_j)}}.&lt;/math&gt;

Programs that are the same or longer than the length of ''x'' provide no predictive power. Separate them out giving,
:&lt;math&gt;P(s = R(K_i) |  T_n(s) = x) = \frac{2^{-I(K_i)}}{\sum_{j:I(K_j)&lt;n} 2^{-I(K_j)}+\sum_{j:I(K_j)\geqslant n} 2^{-I(K_j)}}.&lt;/math&gt;

Then identify the two probabilities as,
:&lt;math&gt;P(x \text{ has pattern}) = \sum_{j:I(K_j)&lt;n} 2^{-I(K_j)}&lt;/math&gt;
:&lt;math&gt;P(x \text{ is random}) = \sum_{j:I(K_j)\geqslant n} 2^{-I(K_j)}&lt;/math&gt;

But the prior probability that ''x'' is a random set of bits is &lt;math&gt;2^{-n}&lt;/math&gt;. So,
:&lt;math&gt;P(s = R(K_i) |  T_n(s) = x) = \frac{2^{-I(K_i)}}{2^{-n} + \sum_{j:I(K_j)&lt;n} 2^{-I(K_j)}}.&lt;/math&gt;

The probability that the source is random, or unpredictable is,
:&lt;math&gt;P(\operatorname{random}(s) |  T_n(s) = x) = \frac{2^{-n}}{2^{-n} + \sum_{j:I(K_j)&lt;n} 2^{-I(K_j)}}.&lt;/math&gt;

===A model for inductive inference===

A model of how worlds are constructed is used in determining the probabilities of theories,
* A random bit string is selected.
* A condition is constructed from the bit string.
* A world is constructed that is consistent with the condition.

If ''w'' is the bit string then the world is created such that &lt;math&gt;R(w)&lt;/math&gt; is true.  An [[intelligent agent]] has some facts about the word, represented by the bit string ''c'', which gives the condition,
:&lt;math&gt;C = R(c)&lt;/math&gt;

The set of bit strings identical with any condition ''x'' is &lt;math&gt;E(x)&lt;/math&gt;.
:&lt;math&gt;\forall x, E(x) = \{w : R(w) \equiv x \}&lt;/math&gt;

A theory is a simpler condition that explains (or implies) ''C''.  The set of all such theories is called ''T'',
:&lt;math&gt; T(C) = \{t : t \to C \}&lt;/math&gt;

====Applying Bayes' theorem====

[[Bayes' theorem#Extended form|extended form of Bayes' theorem]] may be applied
:&lt;math&gt;P(A_i |  B) = \frac{P(B |  A_i)\,P(A_i)}{\sum_j P(B |  A_j)\,P(A_j)},&lt;/math&gt;
where,
:&lt;math&gt;B = E(C)&lt;/math&gt;
:&lt;math&gt;A_i = E(t)&lt;/math&gt;

To apply Bayes' theorem the following must hold: &lt;math&gt;A_i&lt;/math&gt; is a [[partition of a set|partition]] of the event space.

For &lt;math&gt;T(C)&lt;/math&gt; to be a partition, no bit string ''n'' may belong to two theories.  To prove this assume they can and derive a contradiction,
:&lt;math&gt;(N \in T) \land (N \in M) \land (N \ne M) \land (n \in E(N) \land n \in E(M))&lt;/math&gt;
:&lt;math&gt;\implies (N \ne M) \land R(n) \equiv N \land R(n) \equiv M&lt;/math&gt;
:&lt;math&gt;\implies \bot&lt;/math&gt;

Secondly prove that ''T'' includes all outcomes consistent with the condition. As all theories consistent with ''C'' are included then &lt;math&gt;R(w)&lt;/math&gt; must be in this set.

So Bayes theorem may be applied as specified giving,
:&lt;math&gt;\forall t \in T(C), P(E(t) | E(C)) = \frac{P(E(t)) \cdot P(E(C) | E(t))}{\sum_{j \in T(C)} P(E(j)) \cdot P(E(C) | E(j))}  &lt;/math&gt;

Using the [[#Implication and condition probability|implication and condition probability law]], the definition of &lt;math&gt;T(C)&lt;/math&gt; implies,
:&lt;math&gt;\forall t \in T(C), P(E(C) | E(t)) = 1&lt;/math&gt;

The probability of each theory in ''T'' is given by,
:&lt;math&gt; \forall t \in T(C), P(E(t)) = \sum_{n: R(n) \equiv t} 2^{-L(n)}&lt;/math&gt;

so,
:&lt;math&gt;\forall t \in T(C), P(E(t) | E(C)) = \frac{\sum_{n: R(n) \equiv t} 2^{-L(n)}}{\sum_{j \in T(C)} \sum_{m: R(m) \equiv j} 2^{-L(m)}}  &lt;/math&gt;

Finally the probabilities of the events may be identified with the probabilities of the condition which the outcomes in the event satisfy,
:&lt;math&gt;\forall t \in T(C), P(E(t) | E(C)) = P(t | C)&lt;/math&gt;

giving
:&lt;math&gt;\forall t \in T(C), P(t | C) = \frac{\sum_{n: R(n) \equiv t} 2^{-L(n)}}{\sum_{j \in T(C)} \sum_{m: R(m) \equiv j} 2^{-L(m)}}  &lt;/math&gt;

This is the probability of the theory ''t'' after observing that the condition ''C'' holds.

====Removing theories without predictive power====

Theories that are less probable than the condition ''C'' have no predictive power.  Separate them out giving,
:&lt;math&gt;\forall t \in T(C), P(t | C) = \frac{P(E(t))}{(\sum_{j : j \in T(C) \land P(E(j)) &gt; P(E(C))} P(E(j))) + (\sum_{j : j \in T(C) \land P(E(j)) \le P(E(C))} P(j))}  &lt;/math&gt;

The probability of the theories without predictive power on ''C'' is the same as the probability of ''C''.  So,
:&lt;math&gt;P(E(C)) = \sum_{j : j \in T(C) \land P(E(j)) \le P(E(C))} P(j)&lt;/math&gt;

So the probability 
:&lt;math&gt;\forall t \in T(C), P(t | C) = \frac{P(E(t))}{P(E(C)) + \sum_{j : j \in T(C) \land P(E(j)) &gt; P(E(C))} P(E(j))}  &lt;/math&gt;

and the probability of no prediction for C, written as &lt;math&gt;\operatorname{random}(C)&lt;/math&gt;,
:&lt;math&gt;P(\text{random}(C) | C) = \frac{P(E(C))}{P(E(C)) + \sum_{j : j \in T(C) \land P(E(j)) &gt; P(E(C))} P(E(j))}  &lt;/math&gt;

The probability of a condition was given as,
:&lt;math&gt; \forall t, P(E(t)) = \sum_{n: R(n) \equiv t} 2^{-L(n)}&lt;/math&gt;

Bit strings for theories that are more complex than the bit string given to the agent as input have no predictive power.  There probabilities are better included in the ''random'' case.  To implement this a new definition is given as ''F'' in,

:&lt;math&gt; \forall t, P(F(t, c)) = \sum_{n: R(n) \equiv t \land L(n) &lt; L(c)} 2^{-L(n)}&lt;/math&gt;

Using ''F'', an improved version of the abductive probabilities is,
:&lt;math&gt;\forall t \in T(C), P(t | C) = \frac{P(F(t, c))}{P(F(C, c)) + \sum_{j : j \in T(C) \land P(F(j, c)) &gt; P(F(C, c))} P(E(j, c))}  &lt;/math&gt;
:&lt;math&gt;P(\operatorname{random}(C) | C) = \frac{P(F(C, c))}{P(F(C, c)) + \sum_{j : j \in T(C) \land P(F(j, c)) &gt; P(F(C, c))} P(F(j, c))}  &lt;/math&gt;

==Key people==

* [[William of Ockham]]
* [[Thomas Bayes]]
* [[Ray Solomonoff]]
* [[Andrey Kolmogorov]]
* [[Chris Wallace (computer scientist)|Chris Wallace]]
* D. M. Boulton
* [[Jorma Rissanen]]
* [[Marcus Hutter]]

==See also==

* [[Abductive reasoning]]
* [[Algorithmic probability]]
* [[Algorithmic information theory]]
* [[Bayesian inference]]
* [[Information theory]]
* [[Inductive inference]]
* [[Inductive logic programming]]
* [[Inductive reasoning]]
* [[Learning]]
* [[Minimum message length]]
* [[Minimum description length]]
* [[Occam's razor]]
* [[Solomonoff's theory of inductive inference]]
* [[Universal artificial intelligence]]

==References==
{{Reflist}}

==External links==
* Rathmanner, S and Hutter, M., "A Philosophical Treatise of Universal Induction" in Entropy 2011, 13, 1076–1136: A very clear philosophical and mathematical analysis of Solomonoff's Theory of Inductive Inference.
* [[Chris Wallace (computer scientist)|C.S. Wallace]], [http://www.springeronline.com/sgw/cda/frontpage/0,11855,4-10129-22-35893962-0,00.html Statistical and Inductive Inference by Minimum Message Length], Springer-Verlag (Information Science and Statistics), {{ISBN|0-387-23795-X}}, May 2005 – [https://www.springer.com/west/home/statistics/theory?SGWID=4-10129-22-35893962-detailsPage=ppmmedia|toc chapter headings], [https://web.archive.org/web/20150923211609/http://www.csse.monash.edu.au/mml/toc.pdf table of contents] and [https://books.google.com/books?ie=ISO-8859-1&amp;id=3NmFwNHaNbUC&amp;q=wallace+%22statistical+and+inductive+inference+by+minimum+message+length%22&amp;dq=wallace+%22statistical+and+inductive+inference+by+minimum+message+length%22 sample pages].

[[Category:Philosophy of statistics]]
[[Category:Inductive reasoning]]
[[Category:Inference]]
[[Category:Machine learning]]
[[Category:Probability theory]]</text>
      <sha1>97m9bh0qj58dyaux0l81zcuvdb1i8cg</sha1>
    </revision>
  </page>
  <page>
    <title>Universal portfolio algorithm</title>
    <ns>0</ns>
    <id>37787103</id>
    <revision>
      <id>948374034</id>
      <parentid>916001742</parentid>
      <timestamp>2020-03-31T18:06:09Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <comment>Add: isbn. | You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | Activated by [[User:Zppix]] | [[Category:Machine learning‎]] | via #UCB_Category</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1228" xml:space="preserve">The '''universal portfolio algorithm''' is a portfolio selection algorithm from the field of [[machine learning]] and [[information theory]]. The algorithm learns adaptively from historical data and maximizes the log-optimal growth rate in the long run. It was introduced by the late [[Stanford University]] information theorist [[Thomas M. Cover]].&lt;ref&gt;
{{cite journal
  |title=Universal Portfolios
  |first=Thomas M.|last=Cover
  |journal=Mathematical Finance
  |volume=1
  |issue=1
  |pages=1–29
  |year=1991
  |doi=10.1111/j.1467-9965.1991.tb00002.x
}}&lt;/ref&gt;


The algorithm rebalances the portfolio at the beginning of each trading period. At the beginning of the first trading period it starts with a naive diversification. In the following trading periods the portfolio composition depends on the historical total return of all possible constant-rebalanced portfolios.&lt;ref&gt;
{{cite book
|last1=Dochow|first1=Robert
|title=Online Algorithms for the Portfolio Selection Problem
|date=2016
|publisher=Springer Gabler
|isbn=9783658135270
|url=https://www.springer.com/de/book/9783658135270|
}}
&lt;/ref&gt;

==References==
{{reflist}}

[[Category:Machine learning]]
[[Category:Algorithmic trading]]
[[Category:Portfolio theories]]</text>
      <sha1>3afot7el9c1vnhuqzn3rm2ax49wuo6a</sha1>
    </revision>
  </page>
  <page>
    <title>Kernel embedding of distributions</title>
    <ns>0</ns>
    <id>41370976</id>
    <revision>
      <id>947670160</id>
      <parentid>947667637</parentid>
      <timestamp>2020-03-27T19:28:02Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <minor/>
      <comment>Dating maintenance tags: {{Cleanup}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="53835" xml:space="preserve">{{cleanup|reason=This nonsense of calling a distribution ''P''(''X''), with a capital ''X'', when capital ''X'' is also the name of the random variable, and other like things, need to get cleaned up.|date=March 2020}}

In [[machine learning]], the '''kernel embedding of distributions''' (also called the '''kernel mean''' or '''mean map''') comprises a class of [[nonparametric]] methods in which a [[probability distribution]] is represented as an element of a [[reproducing kernel Hilbert space]]  (RKHS).&lt;ref name = "Smola2007"&gt;A. Smola, A. Gretton, L. Song, B. Schölkopf. (2007). [http://eprints.pascal-network.org/archive/00003987/01/SmoGreSonSch07.pdf A Hilbert Space Embedding for Distributions] {{Webarchive|url=https://web.archive.org/web/20131215111545/http://eprints.pascal-network.org/archive/00003987/01/SmoGreSonSch07.pdf |date=2013-12-15 }}. ''Algorithmic Learning Theory: 18th International Conference''. Springer: 13–31.&lt;/ref&gt;   A generalization of the individual data-point feature mapping done in classical [[kernel methods]], the embedding of distributions into infinite-dimensional feature spaces can preserve all of the statistical features of arbitrary distributions, while allowing one to compare and manipulate distributions using Hilbert space operations such as [[inner product]]s, distances, [[projection (linear algebra)|projections]], [[linear transformation]]s, and [[spectral theory|spectral analysis]].&lt;ref name = "Song2013"&gt;L. Song, K. Fukumizu, F. Dinuzzo, A. Gretton (2013). [http://www.gatsby.ucl.ac.uk/~gretton/papers/SonFukGre13.pdf Kernel Embeddings of Conditional Distributions: A unified kernel framework for nonparametric inference in graphical models]. ''IEEE Signal Processing Magazine'' '''30''': 98–111.&lt;/ref&gt;    This [[machine learning|learning]] framework is very general and can be applied to distributions over any space &lt;math&gt;\Omega &lt;/math&gt; on which a sensible [[kernel function]] (measuring similarity between elements of &lt;math&gt;\Omega &lt;/math&gt;) may be defined.  For example, various kernels have been proposed for learning from data which are: [[Vector (mathematics and physics)|vectors]] in &lt;math&gt;\mathbb{R}^d&lt;/math&gt;, discrete classes/categories, [[string (computer science)|string]]s, [[Graph (discrete mathematics)|graph]]s/[[network theory|networks]], images, [[time series]], [[manifold]]s, [[dynamical systems]], and other structured objects.&lt;ref&gt;J. Shawe-Taylor, N. Christianini. (2004). ''Kernel Methods for Pattern Analysis''. Cambridge University Press, Cambridge, UK.&lt;/ref&gt;&lt;ref&gt;T. Hofmann, B. Schölkopf, A. Smola. (2008). [http://projecteuclid.org/DPubS?service=UI&amp;version=1.0&amp;verb=Display&amp;handle=euclid.aos/1211819561 Kernel Methods in Machine Learning]. ''The Annals of Statistics'' '''36'''(3):1171–1220.&lt;/ref&gt;  The theory behind kernel embeddings of distributions has been primarily developed by  [http://alex.smola.org/ Alex Smola], [http://www.cc.gatech.edu/~lsong/ Le Song ], [http://www.gatsby.ucl.ac.uk/~gretton/ Arthur Gretton], and [[Bernhard Schölkopf]]. A review of recent works on kernel embedding of distributions can be found in.&lt;ref&gt;{{Cite journal|last=Muandet|first=Krikamol|last2=Fukumizu|first2=Kenji|last3=Sriperumbudur|first3=Bharath|last4=Schölkopf|first4=Bernhard|date=2017-06-28|title=Kernel Mean Embedding of Distributions: A Review and Beyond|journal=Foundations and Trends in Machine Learning|language=English|volume=10|issue=1–2|pages=1–141|doi=10.1561/2200000060|issn=1935-8237|arxiv=1605.09522}}&lt;/ref&gt;

The analysis of distributions is fundamental in [[machine learning]] and [[statistics]],  and many algorithms in these fields rely on information theoretic approaches such as [[entropy]], [[mutual information]], or [[Kullback–Leibler divergence]].  However, to estimate these quantities, one must first either perform density estimation, or employ sophisticated space-partitioning/bias-correction strategies which are typically infeasible for high-dimensional data.&lt;ref name = "SongThesis"&gt;L. Song. (2008) [http://www.cc.gatech.edu/~lsong/papers/lesong_thesis.pdf Learning via Hilbert Space Embedding of Distributions]. PhD Thesis, University of Sydney.&lt;/ref&gt;  Commonly, methods for modeling complex distributions rely on parametric assumptions that may be unfounded or computationally challenging (e.g. [[Mixture model#Gaussian mixture model|Gaussian mixture models]]), while nonparametric methods like [[kernel density estimation]] (Note: the smoothing kernels in this context have a different interpretation than the kernels discussed here) or [[characteristic function (probability theory)|characteristic function]] representation (via the [[Fourier transform]] of the distribution) break down in high-dimensional settings.&lt;ref name = "Song2013" /&gt;

Methods based on the kernel embedding of distributions sidestep these problems and also possess the following advantages:&lt;ref name = "SongThesis" /&gt; 
# Data may be modeled without restrictive assumptions about the form of the distributions and relationships between variables
#  Intermediate density estimation is not needed
#  Practitioners may specify the properties of a distribution most relevant for their problem (incorporating prior knowledge via choice of the kernel)
# If a ''characteristic'' kernel is used, then the embedding can uniquely preserve all information about a distribution, while thanks to the [[kernel trick]], computations on the potentially infinite-dimensional RKHS can be implemented in practice as simple [[Gramian matrix|Gram]] matrix operations 
# Dimensionality-independent rates of convergence for the empirical kernel mean (estimated using samples from the distribution)  to the kernel embedding of the true underlying distribution can be proven.
# Learning algorithms based on this framework exhibit good generalization ability and finite sample convergence, while often being simpler and more effective than information theoretic methods
Thus, learning via the kernel embedding of distributions offers a principled drop-in replacement for information theoretic approaches and is a framework which not only subsumes many popular methods in machine learning and statistics as special cases, but also can lead to entirely new learning algorithms.

==Definitions==

Let &lt;math&gt;X&lt;/math&gt; denote a random variable with domain &lt;math&gt;\Omega&lt;/math&gt; and distribution &lt;math&gt;P.&lt;/math&gt; Given a kernel &lt;math&gt;k&lt;/math&gt; on &lt;math&gt;\Omega \times \Omega,&lt;/math&gt; the [[Reproducing kernel Hilbert space#Moore–Aronszajn theorem|Moore–Aronszajn theorem]] asserts the existence of a RKHS &lt;math&gt;\mathcal{H}&lt;/math&gt; (a [[Hilbert space]] of functions &lt;math&gt;f: \Omega \to \R&lt;/math&gt; equipped with inner products &lt;math&gt;\langle \cdot, \cdot \rangle_\mathcal{H}&lt;/math&gt; and norms &lt;math&gt;\| \cdot \|_\mathcal{H}&lt;/math&gt;) in which the element &lt;math&gt;k(x,\cdot)&lt;/math&gt; satisfies the reproducing property 

:&lt;math&gt;\forall f \in \mathcal{H}, \forall x \in \Omega \qquad \langle f, k(x,\cdot) \rangle_\mathcal{H} = f(x).&lt;/math&gt;

One may alternatively consider &lt;math&gt;k(x,\cdot)&lt;/math&gt; an implicit feature mapping &lt;math&gt;\varphi(x)&lt;/math&gt; from &lt;math&gt;\Omega&lt;/math&gt; to &lt;math&gt; \mathcal{H} &lt;/math&gt; (which is therefore also called the feature space), so that &lt;math&gt;k(x, x') = \langle \varphi(x), \varphi(x')\rangle_\mathcal{H}&lt;/math&gt; can be viewed as a measure of similarity between points &lt;math&gt;x, x' \in \Omega.&lt;/math&gt; While the [[similarity measure]] is linear in the feature space, it may be highly nonlinear in the original space depending on the choice of kernel.

===Kernel embedding===
The kernel embedding of the distribution &lt;math&gt;P&lt;/math&gt; in &lt;math&gt; \mathcal{H} &lt;/math&gt; (also called the '''kernel mean''' or '''mean map''') is given by:&lt;ref name = "Smola2007" /&gt;

:&lt;math&gt;\mu_X := \mathbb{E} [k(X, \cdot) ] = \mathbb{E} [\varphi(X) ] = \int_\Omega \varphi(x) \ \mathrm{d}P(x) &lt;/math&gt;

If &lt;math&gt;P&lt;/math&gt; allows a square integrable density &lt;math&gt;p&lt;/math&gt;, then &lt;math&gt;\mu_X = \mathcal{E}_k p&lt;/math&gt;, where &lt;math&gt;\mathcal{E}_k&lt;/math&gt; is the [[Hilbert–Schmidt integral operator]]. A kernel is ''characteristic'' if the mean embedding &lt;math&gt;\mu: \{\text{family of distributions over }\Omega \} \to \mathcal{H} &lt;/math&gt; is injective.&lt;ref name = "Fukumizu2008"&gt;K. Fukumizu, A. Gretton, X. Sun, and B. Schölkopf (2008). [http://papers.nips.cc/paper/3340-kernel-measures-of-conditional-dependence.pdf Kernel measures of conditional independence]. ''Advances in Neural Information Processing Systems'' '''20''', MIT Press, Cambridge, MA.&lt;/ref&gt; Each distribution can thus be uniquely represented in the RKHS and all statistical features of distributions are preserved by the kernel embedding if a characteristic kernel is used.

===Empirical kernel embedding===
Given &lt;math&gt;n&lt;/math&gt; training examples &lt;math&gt;\{x_1, \ldots, x_n\} &lt;/math&gt; drawn [[Independent and identically distributed random variables|independently and identically distributed]] (i.i.d.) from &lt;math&gt;P,&lt;/math&gt; the kernel embedding of &lt;math&gt;P&lt;/math&gt; can be empirically estimated as

:&lt;math&gt;\widehat{\mu}_X = \frac{1}{n} \sum_{i=1}^n \varphi(x_i) &lt;/math&gt;

===Joint distribution embedding===
If &lt;math&gt;Y&lt;/math&gt; denotes another random variable (for simplicity, assume the co-domain of &lt;math&gt;Y&lt;/math&gt; is also &lt;math&gt;\Omega&lt;/math&gt; with the same kernel &lt;math&gt;k&lt;/math&gt; which satisfies &lt;math&gt; \langle \varphi(x) \otimes \varphi(y), \varphi(x') \otimes \varphi(y') \rangle = k(x,x') \otimes k(y,y')&lt;/math&gt;), then the [[Joint probability distribution|joint distribution]] &lt;math&gt; P(x,y)) &lt;/math&gt; can be mapped into a [[tensor product]] feature space &lt;math&gt;\mathcal{H} \otimes \mathcal{H} &lt;/math&gt; via &lt;ref name = "Song2013"/&gt;

:&lt;math&gt; \mathcal{C}_{XY} = \mathbb{E} [\varphi(X) \otimes \varphi(Y)] = \int_{\Omega \times \Omega} \varphi(x) \otimes \varphi(y) \ \mathrm{d} P(x,y) &lt;/math&gt;

By the equivalence between a [[tensor]] and a [[linear map]], this joint embedding may be interpreted as an uncentered [[cross-covariance]] operator &lt;math&gt;\mathcal{C}_{XY}: \mathcal{H} \to \mathcal{H}&lt;/math&gt; from which the cross-covariance of mean-zero functions &lt;math&gt;f,g \in \mathcal{H}&lt;/math&gt; can be computed as &lt;ref name = "SongCDE"&gt;L. Song, J. Huang, A. J. Smola, K. Fukumizu. (2009).[http://www.stanford.edu/~jhuang11/research/pubs/icml09/icml09.pdf Hilbert space embeddings of conditional distributions]. ''Proc. Int. Conf. Machine Learning''. Montreal, Canada: 961–968.&lt;/ref&gt;

:&lt;math&gt;\operatorname{Cov} (f(X), g(Y)) := \mathbb{E} [f(X) g(Y)] = \langle f , \mathcal{C}_{XY} g \rangle_{\mathcal{H}} = \langle f \otimes g , \mathcal{C}_{XY} \rangle_{\mathcal{H} \otimes \mathcal{H}}&lt;/math&gt;

Given &lt;math&gt;n&lt;/math&gt; pairs of training examples &lt;math&gt;\{(x_1, y_1), \dots, (x_n, y_n)\} &lt;/math&gt; drawn i.i.d. from &lt;math&gt;P&lt;/math&gt;, we can also empirically estimate the joint distribution kernel embedding via

:&lt;math&gt;\widehat{\mathcal{C}}_{XY} = \frac{1}{n} \sum_{i=1}^n \varphi(x_i) \otimes \varphi(y_i) &lt;/math&gt;

===Conditional distribution embedding===
Given a [[conditional distribution]] &lt;math&gt;P(y\mid x),&lt;/math&gt; one can define the corresponding RKHS embedding as &lt;ref name = "Song2013"/&gt;

:&lt;math&gt;\mu_{Y \mid x} = \mathbb{E} [ \varphi(Y)\mid X ] = \int_\Omega \varphi(y) \ \mathrm{d}P(y \mid x) &lt;/math&gt;

Note that the embedding of &lt;math&gt;P(y\mid x) &lt;/math&gt; thus defines a family of points in the RKHS indexed by the values &lt;math&gt;x&lt;/math&gt; taken by conditioning variable &lt;math&gt;X&lt;/math&gt;. By fixing &lt;math&gt;X&lt;/math&gt; to a particular value, we obtain a single element in &lt;math&gt;\mathcal{H}&lt;/math&gt;, and thus it is natural to define the operator

:&lt;math&gt;\begin{cases} \mathcal{C}_{Y\mid X}: \mathcal{H} \to \mathcal{H} \\ \mathcal{C}_{Y\mid X} = \mathcal{C}_{YX} \mathcal{C}_{XX}^{-1} \end{cases}&lt;/math&gt; 

which given the feature mapping of &lt;math&gt;x&lt;/math&gt; outputs the conditional embedding of &lt;math&gt;Y&lt;/math&gt; given &lt;math&gt;X = x.&lt;/math&gt; Assuming that for all &lt;math&gt;g \in \mathcal{H}: \mathbb{E} [g(Y)\mid X] \in \mathcal{H},&lt;/math&gt; it can be shown that &lt;ref name = "SongCDE" /&gt;

:&lt;math&gt; \mu_{Y \mid x} = \mathcal{C}_{Y \mid X} \varphi(x)&lt;/math&gt;

This assumption is always true for finite domains with characteristic kernels, but may not necessarily hold for continuous domains.&lt;ref name = "Song2013"/&gt; Nevertheless, even in cases where the assumption fails, &lt;math&gt; \mathcal{C}_{Y \mid X} \varphi(x) &lt;/math&gt; may still be used to approximate the conditional kernel embedding &lt;math&gt;\mu_{Y \mid x},&lt;/math&gt; and in practice, the inversion operator is replaced with a regularized version of itself &lt;math&gt;(\mathcal{C}_{XX} + \lambda \mathbf{I})^{-1} &lt;/math&gt; (where &lt;math&gt;\mathbf{I}&lt;/math&gt; denotes the [[identity matrix]]).

Given training examples &lt;math&gt;\{(x_1, y_1),\dots, (x_n, y_n)\},&lt;/math&gt; the empirical kernel conditional embedding operator may be estimated as &lt;ref name = "Song2013" /&gt;

:&lt;math&gt;\widehat{C}_{Y\mid X} = \boldsymbol{\Phi} (\mathbf{K} + \lambda \mathbf{I})^{-1} \boldsymbol{\Upsilon}^T&lt;/math&gt;

where &lt;math&gt;\boldsymbol{\Phi} = \left(\varphi(y_i),\dots, (y_n)\right), \boldsymbol{\Upsilon} = \left(\varphi(x_i),\dots, (x_n)\right) &lt;/math&gt; are implicitly formed feature matrices, &lt;math&gt;\mathbf{K} =\boldsymbol{\Upsilon}^T \boldsymbol{\Upsilon} &lt;/math&gt; is the Gram matrix for samples of &lt;math&gt;X&lt;/math&gt;, and &lt;math&gt;\lambda&lt;/math&gt; is a [[Regularization (mathematics)|regularization]] parameter needed to avoid [[overfitting]].

Thus, the empirical estimate of the kernel conditional embedding is given by a weighted sum of samples of &lt;math&gt;Y&lt;/math&gt; in the feature space:

:&lt;math&gt; \widehat{\mu}_{Y\mid x} = \sum_{i=1}^n \beta_i (x) \varphi(y_i) = \boldsymbol{\Phi} \boldsymbol{\beta}(x) &lt;/math&gt; 

where &lt;math&gt; \boldsymbol{\beta}(x) = (\mathbf{K} + \lambda \mathbf{I})^{-1} \mathbf{K}_x&lt;/math&gt; and &lt;math&gt; \mathbf{K}_x = \left( k(x_1, x), \dots, k(x_n, x) \right)^T &lt;/math&gt;

==Properties==

* The expectation of any function &lt;math&gt; f &lt;/math&gt; in the RKHS can be computed as an inner product with the kernel embedding:
::&lt;math&gt; \mathbb{E} [f(X)] = \langle f, \mu_X \rangle_\mathcal{H} &lt;/math&gt;

* In the presence of large sample sizes, manipulations of the &lt;math&gt;n \times n&lt;/math&gt; Gram matrix may be computationally demanding. Through use of a low-rank approximation of the Gram matrix (such as the [[incomplete Cholesky factorization]]), running time and memory requirements of kernel-embedding-based learning algorithms can be drastically reduced without suffering much loss in approximation accuracy.&lt;ref name = "Song2013"/&gt;

=== Convergence of empirical kernel mean to the true distribution embedding ===

* If &lt;math&gt;k&lt;/math&gt; is defined such that &lt;math&gt;f&lt;/math&gt; takes values in &lt;math&gt;[0,1]&lt;/math&gt; for all &lt;math&gt;f \in \mathcal{H}&lt;/math&gt; with &lt;math&gt;\| f\|_\mathcal{H} \le 1 &lt;/math&gt; (as is the case for the widely used [[radial basis function]] kernels), then with probability at least &lt;math&gt;1-\delta &lt;/math&gt;:&lt;ref name="SongThesis" /&gt;
::&lt;math&gt;\|\mu_X - \widehat{\mu}_X \|_\mathcal{H} = \sup_{f \in \mathcal{B}(0,1)} \left| \mathbb{E} [f(X)] - \frac{1}{n} \sum_{i=1}^n f(x_i) \right| \le \frac{2}{n} \mathbb{E} \left[ \sqrt{\operatorname{tr} K} \right] + \sqrt{\frac{\log (2/\delta)}{2n}}&lt;/math&gt; 
:where &lt;math&gt;\mathcal{B}(0,1)&lt;/math&gt; denotes the unit ball in &lt;math&gt;\mathcal{H}&lt;/math&gt; and &lt;math&gt;\mathbf{K} =(k_{ij})&lt;/math&gt; is the Gram matrix with &lt;math&gt;k_{ij} = k(x_i, x_j).&lt;/math&gt; 

* The rate of convergence (in RKHS norm) of the empirical kernel embedding to its distribution counterpart is &lt;math&gt;O(n^{-1/2})&lt;/math&gt; and does ''not'' depend on the dimension of &lt;math&gt;X&lt;/math&gt;. 

* Statistics based on kernel embeddings thus avoid the [[curse of dimensionality]], and though the true underlying distribution is unknown in practice, one can (with high probability) obtain an approximation within &lt;math&gt;O(n^{-1/2})&lt;/math&gt; of the true kernel embedding based on a finite sample of size &lt;math&gt;n&lt;/math&gt;.

* For the embedding of conditional distributions, the empirical estimate can be seen as a ''weighted'' average of feature mappings (where the weights &lt;math&gt;\beta_i(x) &lt;/math&gt; depend on the value of the conditioning variable and capture the effect of the conditioning on the kernel embedding). In this case, the empirical estimate converges to the conditional distribution RKHS embedding with rate &lt;math&gt;O\left(n^{-1/4} \right)&lt;/math&gt; if the regularization parameter &lt;math&gt;\lambda&lt;/math&gt; is decreased as &lt;math&gt;O\left( n^{-1/2} \right),&lt;/math&gt; though faster rates of convergence may be achieved by placing additional assumptions on the joint distribution.&lt;ref name="Song2013"/&gt;

=== Universal kernels ===

* Letting &lt;math&gt;C(\mathcal{X})&lt;/math&gt; denote the space of [[Continuous function|continuous]] [[Bounded function|bounded]] functions on [[Compact space|compact]] domain &lt;math&gt;\mathcal{X}&lt;/math&gt;, we call a kernel &lt;math&gt;k&lt;/math&gt; ''universal'' if &lt;math&gt;k(x,\cdot)&lt;/math&gt; is continuous for all &lt;math&gt;x&lt;/math&gt; and the RKHS induced by &lt;math&gt;k&lt;/math&gt; is [[Dense set|dense]] in &lt;math&gt;C(\mathcal{X})&lt;/math&gt;.

* If &lt;math&gt;k&lt;/math&gt; induces a strictly positive definite kernel matrix for any set of distinct points, then it is a universal kernel.&lt;ref name = "SongThesis" /&gt; For example, the widely used Gaussian RBF kernel 
::&lt;math&gt; k(x,x') = \exp\left(-\frac{1}{2\sigma^2} \|x-x'\|^2 \right)&lt;/math&gt;
:on compact subsets of &lt;math&gt;\mathbb{R}^d &lt;/math&gt; is universal.

* If &lt;math&gt;k&lt;/math&gt; is shift-invariant &lt;math&gt;h(x-y)=k(x, y)&lt;/math&gt; and its representation in Fourier domain is 
::&lt;math&gt;h(t) = \int e^{-i\langle t, \omega \rangle} \mu(d\omega)&lt;/math&gt;
:and [[Support (mathematics)|support]] of &lt;math&gt;\mu&lt;/math&gt; is an entire space, then &lt;math&gt;k&lt;/math&gt; is universal.&lt;ref&gt;[https://web.stanford.edu/class/cs229t/notes.pdf] page 139&lt;/ref&gt; For example, Gaussian RBF is universal, [[sinc]] kernel is not universal.

* If &lt;math&gt; k &lt;/math&gt; is universal, then it is ''characteristic'', i.e. the kernel embedding is one-to-one.&lt;ref&gt;A. Gretton, K. Borgwardt, M. Rasch, B. Schölkopf, A. Smola. (2007). [http://www.gatsby.ucl.ac.uk/~gretton/papers/GreBorRasSchSmo07.pdf A kernel method for the two-sample-problem]. ''Advances in Neural Information Processing Systems'' '''19''', MIT Press, Cambridge, MA.&lt;/ref&gt;

=== Parameter selection for conditional distribution kernel embeddings ===

* The empirical kernel conditional distribution embedding operator &lt;math&gt;\widehat{\mathcal{C}}_{Y|X}&lt;/math&gt; can alternatively be viewed as the solution of the following regularized least squares (function-valued) regression problem &lt;ref&gt;S. Grunewalder, G. Lever, L. Baldassarre, S. Patterson, A. Gretton, M. Pontil. (2012). [http://icml.cc/2012/papers/898.pdf Conditional mean embeddings as regressors]. ''Proc. Int. Conf. Machine Learning'': 1823–1830.&lt;/ref&gt;
::&lt;math&gt;\min_{\mathcal{C}: \mathcal{H} \to \mathcal{H}} \sum_{i=1}^n \left \|\varphi(y_i)-\mathcal{C} \varphi(x_i) \right \|_\mathcal{H}^2 + \lambda \|\mathcal{C} \|_{HS}^2&lt;/math&gt; 
:where &lt;math&gt;\|\cdot\|_{HS}&lt;/math&gt; is the [[Hilbert–Schmidt operator|Hilbert–Schmidt norm]]. 

* One can thus select the regularization parameter &lt;math&gt;\lambda&lt;/math&gt; by performing [[cross-validation (statistics)|cross-validation]] based on the squared loss function of the regression problem.

== Rules of probability as operations in the RKHS ==

This section illustrates how basic probabilistic rules may be reformulated as (multi)linear algebraic operations in the kernel embedding framework and is primarily based on the work of Song et al.&lt;ref name = "Song2013" /&gt;&lt;ref name = "SongCDE" /&gt; The following notation is adopted: 

* &lt;math&gt;P(X,Y)= &lt;/math&gt; joint distribution over random variables &lt;math&gt; X, Y &lt;/math&gt;

* &lt;math&gt;P(X)= \int_\Omega P(X, \mathrm{d}y) = &lt;/math&gt; marginal distribution of &lt;math&gt;X&lt;/math&gt;; &lt;math&gt;P(Y)= &lt;/math&gt; marginal distribution of &lt;math&gt;Y &lt;/math&gt;

* &lt;math&gt; P(Y \mid X) = \frac{P(X,Y)}{P(X)} = &lt;/math&gt; conditional distribution of &lt;math&gt; Y &lt;/math&gt; given &lt;math&gt; X &lt;/math&gt; with corresponding conditional embedding operator &lt;math&gt; \mathcal{C}_{Y \mid X}&lt;/math&gt; 

* &lt;math&gt; \pi(Y) = &lt;/math&gt; prior distribution over &lt;math&gt; Y &lt;/math&gt;

* &lt;math&gt; Q &lt;/math&gt; is used to distinguish distributions which incorporate the prior from distributions &lt;math&gt; P &lt;/math&gt; which do not rely on the prior

In practice, all embeddings are empirically estimated from data &lt;math&gt;\{(x_1,y_1),\dots, (x_n, y_n)\}&lt;/math&gt; and it assumed that a set of samples &lt;math&gt;\{\widetilde{y}_1, \ldots, \widetilde{y}_{\widetilde{n}} \}&lt;/math&gt; may be used to estimate the kernel embedding of the prior distribution &lt;math&gt; \pi(Y) &lt;/math&gt;.

=== Kernel sum rule ===
In probability theory, the marginal distribution of &lt;math&gt;X&lt;/math&gt; can be computed by integrating out &lt;math&gt; Y &lt;/math&gt; from the joint density (including the prior distribution on &lt;math&gt;Y&lt;/math&gt;)

:&lt;math&gt; Q(X) = \int_\Omega P(X \mid Y) \, \mathrm{d} \pi(Y) &lt;/math&gt;

The analog of this rule in the kernel embedding framework states that &lt;math&gt;\mu_X^\pi,&lt;/math&gt; the RKHS embedding of &lt;math&gt;Q(X)&lt;/math&gt;, can be computed via

:&lt;math&gt;\mu_X^\pi = \mathbb{E} [\mathcal{C}_{X \mid Y} \varphi(Y) ] = \mathcal{C}_{X\mid Y} \mathbb{E} [\varphi(Y)] = \mathcal{C}_{X\mid Y} \mu_Y^\pi &lt;/math&gt; 

where &lt;math&gt;\mu_Y^\pi&lt;/math&gt; is the kernel embedding of &lt;math&gt;\pi(Y).&lt;/math&gt; In practical implementations, the kernel sum rule takes the following form

:&lt;math&gt; \widehat{\mu}_X^\pi = \widehat{\mathcal{C}}_{X \mid Y} \widehat{\mu}_Y^\pi = \boldsymbol{\Upsilon} (\mathbf{G} + \lambda \mathbf{I})^{-1} \widetilde{\mathbf{G}} \boldsymbol{\alpha} &lt;/math&gt; 

where 

:&lt;math&gt;\mu_Y^\pi = \sum_{i=1}^{\widetilde{n}} \alpha_i \varphi(\widetilde{y}_i)&lt;/math&gt; 

is the empirical kernel embedding of the prior distribution, &lt;math&gt;\boldsymbol{\alpha} = (\alpha_1, \ldots, \alpha_{\widetilde{n}} )^T,&lt;/math&gt; &lt;math&gt;\boldsymbol{\Upsilon} = \left(\varphi(x_1), \ldots, \varphi(x_n) \right) &lt;/math&gt;, and &lt;math&gt;\mathbf{G}, \widetilde{\mathbf{G}} &lt;/math&gt; are Gram matrices with entries &lt;math&gt;\mathbf{G}_{ij} = k(y_i, y_j), \widetilde{\mathbf{G}}_{ij} = k(y_i, \widetilde{y}_j) &lt;/math&gt; respectively.

=== Kernel chain rule ===
In probability theory, a joint distribution can be factorized into a product between conditional and marginal distributions 

:&lt;math&gt;Q(X,Y) = P(X \mid Y) \pi(Y) &lt;/math&gt;

The analog of this rule in the kernel embedding framework states that &lt;math&gt; \mathcal{C}_{XY}^\pi,&lt;/math&gt; the joint embedding of &lt;math&gt;Q(X,Y),&lt;/math&gt; can be factorized as a composition of conditional embedding operator with the auto-covariance operator associated with &lt;math&gt;\pi(Y)&lt;/math&gt;

:&lt;math&gt;\mathcal{C}_{XY}^\pi = \mathcal{C}_{X \mid Y} \mathcal{C}_{YY}^\pi &lt;/math&gt; 

where 

:&lt;math&gt;\mathcal{C}_{XY}^\pi = \mathbb{E} [\varphi(X) \otimes \varphi(Y) ],&lt;/math&gt; 
:&lt;math&gt;\mathcal{C}_{YY}^\pi = \mathbb{E} [\varphi(Y) \otimes \varphi(Y)].&lt;/math&gt; 

In practical implementations, the kernel chain rule takes the following form

:&lt;math&gt; \widehat{\mathcal{C}}_{XY}^\pi = \widehat{\mathcal{C}}_{X \mid Y} \widehat{\mathcal{C}}_{YY}^\pi = \boldsymbol{\Upsilon} (\mathbf{G} + \lambda \mathbf{I})^{-1} \widetilde{\mathbf{G}} \operatorname{diag}(\boldsymbol{\alpha}) \boldsymbol{\widetilde{\Phi}}^T &lt;/math&gt;

=== Kernel Bayes' rule ===
In probability theory, a posterior distribution can be expressed in terms of a prior distribution and a likelihood function as 

:&lt;math&gt;Q(Y\mid x) = \frac{P(x\mid Y) \pi(Y)}{Q(x)} &lt;/math&gt; where &lt;math&gt; Q(x) = \int_\Omega P(x \mid y) \, \mathrm{d} \pi(y) &lt;/math&gt;

The analog of this rule in the kernel embedding framework expresses the kernel embedding of the conditional distribution in terms of conditional embedding operators which are modified by the prior distribution

:&lt;math&gt; \mu_{Y\mid x}^\pi = \mathcal{C}_{Y \mid X}^\pi \varphi(x) = \mathcal{C}_{YX}^\pi \left ( \mathcal{C}_{XX}^\pi \right )^{-1} \varphi(x)&lt;/math&gt; 

where from the chain rule: 

:&lt;math&gt; \mathcal{C}_{YX}^\pi = \left( \mathcal{C}_{X\mid Y} \mathcal{C}_{YY}^\pi \right)^T.&lt;/math&gt;

In practical implementations, the kernel Bayes' rule takes the following form

:&lt;math&gt;\widehat{\mu}_{Y\mid x}^\pi = \widehat{\mathcal{C}}_{YX}^\pi \left( \left (\widehat{\mathcal{C}}_{XX} \right )^2 + \widetilde{\lambda} \mathbf{I} \right)^{-1} \widehat{\mathcal{C}}_{XX}^\pi \varphi(x) = \widetilde{\boldsymbol{\Phi}} \boldsymbol{\Lambda}^T \left( (\mathbf{D} \mathbf{K})^2 + \widetilde{\lambda} \mathbf{I} \right)^{-1} \mathbf{K} \mathbf{D} \mathbf{K}_x &lt;/math&gt; 

where 

:&lt;math&gt;\boldsymbol{\Lambda} = \left(\mathbf{G} + \widetilde{\lambda} \mathbf{I} \right)^{-1} \widetilde{\mathbf{G}} \operatorname{diag}(\boldsymbol{\alpha}), \qquad \mathbf{D} = \operatorname{diag}\left(\left(\mathbf{G} + \widetilde{\lambda} \mathbf{I} \right)^{-1} \widetilde{\mathbf{G}} \boldsymbol{\alpha} \right).&lt;/math&gt;

Two regularization parameters are used in this framework: &lt;math&gt;\lambda &lt;/math&gt; for the estimation of &lt;math&gt; \widehat{\mathcal{C}}_{YX}^\pi, \widehat{\mathcal{C}}_{XX}^\pi = \boldsymbol{\Upsilon} \mathbf{D} \boldsymbol{\Upsilon}^T&lt;/math&gt; and &lt;math&gt;\widetilde{\lambda}&lt;/math&gt; for the estimation of the final conditional embedding operator 

:&lt;math&gt;\widehat{\mathcal{C}}_{Y\mid X}^\pi = \widehat{\mathcal{C}}_{YX}^\pi \left( \left (\widehat{\mathcal{C}}_{XX}^\pi \right )^2 + \widetilde{\lambda} \mathbf{I} \right)^{-1} \widehat{\mathcal{C}}_{XX}^\pi.&lt;/math&gt;

The latter regularization is done on square of &lt;math&gt;\widehat{\mathcal{C}}_{XX}^\pi&lt;/math&gt; because &lt;math&gt;D&lt;/math&gt; may not be [[Positive-definite matrix|positive definite]].

==Applications==

=== Measuring distance between distributions ===
The '''maximum mean discrepancy (MMD)''' is a distance-measure between distributions &lt;math&gt;P(X)&lt;/math&gt; and &lt;math&gt;Q(Y)&lt;/math&gt; which is defined as the squared distance between their embeddings in the RKHS &lt;ref name = "SongThesis" /&gt;

:&lt;math&gt;\text{MMD}(P,Q) = \left \| \mu_X - \mu_Y \right \|_{\mathcal{H}}^2 &lt;/math&gt;

While most distance-measures between distributions such as the widely used [[Kullback–Leibler divergence]] either require density estimation (either parametrically or nonparametrically) or space partitioning/bias correction strategies,&lt;ref name = "SongThesis" /&gt; the MMD is easily estimated as an empirical mean which is concentrated around the true value of the MMD. The characterization of this distance as the ''maximum mean discrepancy'' refers to the fact that computing the MMD is equivalent to finding the RKHS function that maximizes the difference in expectations between the two probability distributions 

:&lt;math&gt;\text{MMD}(P,Q) = \sup_{\|f \|_\mathcal{H} \le 1} \left( \mathbb{E} [f(X)] - \mathbb{E} [f(Y)] \right)&lt;/math&gt;

=== Kernel two-sample test ===
Given ''n'' training examples from &lt;math&gt;P(X)&lt;/math&gt; and ''m'' samples from &lt;math&gt;Q(Y)&lt;/math&gt;, one can formulate a test statistic based on the empirical estimate of the MMD

:&lt;math&gt;
\begin{align}
\widehat{\text{MMD}}(P,Q) &amp; = \left\| \frac{1}{n}\sum_{i=1}^n \varphi(x_i) - \frac{1}{m}\sum_{i=1}^m \varphi(y_i) \right \|_{\mathcal{H}}^2 \\[5pt]
&amp; = \frac{1}{n^2} \sum_{i=1}^n\sum_{j=1}^n k(x_i, x_j) + \frac{1}{m^2} \sum_{i=1}^m\sum_{j=1}^m k(y_i, y_j) - \frac{2}{nm} \sum_{i=1}^n\sum_{j=1}^m k(x_i, y_j)
\end{align}
&lt;/math&gt;

to obtain a '''two-sample test''' &lt;ref&gt;A. Gretton, K. Borgwardt, M. Rasch, B. Schölkopf, A. Smola. (2012). [http://jmlr.org/papers/volume13/gretton12a/gretton12a.pdf A kernel two-sample test]. ''Journal of Machine Learning Research'', '''13''': 723–773.&lt;/ref&gt; of the null hypothesis that both samples stem from the same distribution (i.e. &lt;math&gt;P = Q&lt;/math&gt;) against the broad alternative &lt;math&gt;P \neq Q&lt;/math&gt;.

=== Density estimation via kernel embeddings ===
Although learning algorithms in the kernel embedding framework circumvent the need for intermediate density estimation, one may nonetheless use the empirical embedding to perform density estimation based on ''n'' samples drawn from an underlying distribution &lt;math&gt;P_X^*&lt;/math&gt;. This can be done by solving the following optimization problem &lt;ref name ="SongThesis"/&gt;&lt;ref&gt;M. Dudík, S. J. Phillips, R. E. Schapire. (2007). [http://classes.soe.ucsc.edu/cmps242/Winter08/lect/15/maxent_genreg_jmlr.pdf Maximum Entropy Distribution Estimation with Generalized Regularization and an Application to Species Distribution Modeling]. ''Journal of Machine Learning Research'', '''8''': 1217–1260.&lt;/ref&gt;

:&lt;math&gt; \max_{P_X} H(P_X) &lt;/math&gt; subject to &lt;math&gt;\|\widehat{\mu}_X - \mu_X[P_X] \|_\mathcal{H} \le \varepsilon&lt;/math&gt;

where the maximization is done over the entire space of distributions on &lt;math&gt;\Omega.&lt;/math&gt; Here, &lt;math&gt;\mu_X[P_X]&lt;/math&gt; is the kernel embedding of the proposed density &lt;math&gt;P_X&lt;/math&gt; and &lt;math&gt;H&lt;/math&gt; is an entropy-like quantity (e.g. [[Entropy (information theory)|Entropy]], [[Kullback–Leibler divergence|KL divergence]], [[Bregman divergence]]). The distribution which solves this optimization may be interpreted as a compromise between fitting the empirical kernel means of the samples well, while still allocating a substantial portion of the probability mass to all regions of the probability space (much of which may not be represented in the training examples). In practice, a good approximate solution of the difficult optimization may be found by restricting the space of candidate densities to a mixture of ''M'' candidate distributions with regularized mixing proportions. Connections between the ideas underlying [[Gaussian process]]es and [[conditional random fields]] may be drawn with the estimation of conditional probability distributions in this fashion, if one views the feature mappings associated with the kernel as sufficient statistics in generalized (possibly infinite-dimensional) [[exponential family|exponential families]].&lt;ref name = "SongThesis"/&gt;

=== Measuring dependence of random variables ===
A measure of the statistical dependence between random variables &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt; (from any domains on which sensible kernels can be defined) can be formulated based on the Hilbert–Schmidt Independence Criterion &lt;ref&gt;A. Gretton, O. Bousquet, A. Smola, B. Schölkopf. (2005). [http://www.gatsby.ucl.ac.uk/~gretton/papers/GreBouSmoSch05.pdf Measuring statistical dependence with Hilbert–Schmidt norms]. ''Proc. Intl. Conf. on Algorithmic Learning Theory'': 63–78.&lt;/ref&gt; 

:&lt;math&gt; \text{HSIC}(X, Y) = \left \| \mathcal{C}_{XY} - \mu_X \otimes \mu_Y \right \|_{\mathcal{H} \otimes \mathcal{H}}^2 &lt;/math&gt;

and can be used as a principled replacement for [[mutual information]], [[Pearson correlation]] or any other dependence measure used in learning algorithms. Most notably, HSIC can detect arbitrary dependencies (when a characteristic kernel is used in the embeddings, HSIC is zero if and only if the variables are [[independence (probability theory)|independent]]), and can be used to measure dependence between different types of data (e.g. images and text captions). Given ''n'' i.i.d. samples of each random variable, a simple parameter-free [[Bias of an estimator|unbiased]] estimator of HSIC which exhibits [[Concentration of measure|concentration]] about the true value can be computed in &lt;math&gt;O(n(d_f^2 +d_g^2))&lt;/math&gt; time,&lt;ref name = "SongThesis"/&gt; where the Gram matrices of the two datasets are approximated using &lt;math&gt;\mathbf{A} \mathbf{A}^T, \mathbf{B} \mathbf{B}^T &lt;/math&gt; with &lt;math&gt;\mathbf{A} \in \R^{n \times d_f}, \mathbf{B} \in \R^{n \times d_g}&lt;/math&gt;. The desirable properties of HSIC have led to the formulation of numerous algorithms which utilize this dependence measure for a variety of common machine learning tasks such as: [[feature selection]] (BAHSIC &lt;ref&gt;L. Song, A. Smola , A. Gretton, K. Borgwardt, J. Bedo. (2007). [http://www.machinelearning.org/proceedings/icml2007/papers/244.pdf Supervised feature selection via dependence estimation]. ''Proc. Intl. Conf. Machine Learning'', Omnipress: 823–830.&lt;/ref&gt;), [[Cluster analysis|clustering]] (CLUHSIC &lt;ref&gt;L. Song, A. Smola, A. Gretton, K. Borgwardt. (2007). [http://machinelearning.wustl.edu/mlpapers/paper_files/icml2007_SongSGB07.pdf A dependence maximization view of clustering]. ''Proc. Intl. Conf. Machine Learning''. Omnipress: 815–822.&lt;/ref&gt;), and [[dimensionality reduction]] (MUHSIC &lt;ref&gt;L. Song, A. Smola, K. Borgwardt, A. Gretton. (2007). [http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2007_492.pdf Colored maximum variance unfolding]. ''Neural Information Processing Systems''.&lt;/ref&gt;).

HSIC can be extended to measure the dependence of multiple random variables. The question of when HSIC captures independence in this case has recently been studied:&lt;ref name = "CharAndUniv"&gt;Zoltán Szabó, Bharath K. Sriperumbudur. [http://jmlr.org/papers/v18/17-492.html Characteristic and Universal Tensor Product Kernels]. ''Journal of Machine Learning Research'', 19:1–29, 2018.&lt;/ref&gt; for 
more than two variables
* on &lt;math&gt;\R^d&lt;/math&gt;: the characteristic property of the individual kernels remains an equivalent condition.
* on general domains: the characteristic property of the kernel components is necessary but ''not sufficient''.

=== Kernel belief propagation ===
[[Belief propagation]] is a fundamental algorithm for inference in [[graphical model]]s in which nodes repeatedly pass and receive messages corresponding to the evaluation of conditional expectations. In the kernel embedding framework, the messages may be represented as RKHS functions and the conditional distribution embeddings can be applied to efficiently compute message updates. Given ''n'' samples of random variables represented by nodes in a [[Markov random field]], the incoming message to node ''t'' from node ''u'' can be expressed as 

:&lt;math&gt;m_{ut}(\cdot) = \sum_{i=1}^n \beta_{ut}^i \varphi(x_t^i)&lt;/math&gt; 

if it assumed to lie in the RKHS. The '''kernel belief propagation update''' message from ''t'' to node ''s'' is then given by &lt;ref name = "Song2013"/&gt;

:&lt;math&gt; \widehat{m}_{ts} = \left( \odot_{u \in N(t) \backslash s} \mathbf{K}_t \boldsymbol{\beta}_{ut} \right)^T (\mathbf{K}_s + \lambda \mathbf{I} )^{-1} \boldsymbol{\Upsilon}_s^T \varphi(x_s)&lt;/math&gt;

where &lt;math&gt;\odot&lt;/math&gt; denotes the element-wise vector product, &lt;math&gt;N(t) \backslash s &lt;/math&gt; is the set of nodes connected to ''t'' excluding node ''s'', &lt;math&gt; \boldsymbol{\beta}_{ut} = \left(\beta_{ut}^1, \dots, \beta_{ut}^n \right) &lt;/math&gt;, &lt;math&gt;\mathbf{K}_t, \mathbf{K}_s &lt;/math&gt; are the Gram matrices of the samples from variables &lt;math&gt;X_t, X_s &lt;/math&gt;, respectively, and &lt;math&gt;\boldsymbol{\Upsilon}_s = \left(\varphi(x_s^1),\dots, \varphi(x_s^n)\right)&lt;/math&gt; is the feature matrix for the samples from &lt;math&gt;X_s&lt;/math&gt;.

Thus, if the incoming messages to node ''t'' are linear combinations of feature mapped samples from &lt;math&gt; X_t &lt;/math&gt;, then the outgoing message from this node is also a linear combination of feature mapped samples from &lt;math&gt; X_s &lt;/math&gt;. This RKHS function representation of message-passing updates therefore produces an efficient belief propagation algorithm in which the [[Markov Random Field#Clique factorization|potentials]] are nonparametric functions inferred from the data so that arbitrary statistical relationships may be modeled.&lt;ref name = "Song2013"/&gt;

=== Nonparametric filtering in hidden Markov models ===
In the [[hidden Markov model]] (HMM), two key quantities of interest are the transition probabilities between hidden states &lt;math&gt; P(S^t \mid S^{t-1})&lt;/math&gt; and the emission probabilities &lt;math&gt;P(O^t \mid S^t)&lt;/math&gt; for observations. Using the kernel conditional distribution embedding framework, these quantities may be expressed in terms of samples from the HMM. A serious limitation of the embedding methods in this domain is the need for training samples containing hidden states, as otherwise inference with arbitrary distributions in the HMM is not possible.

One common use of HMMs is [[Hidden Markov Model#Filtering|filtering]] in which the goal is to estimate posterior distribution over the hidden state &lt;math&gt;s^t&lt;/math&gt; at time step ''t'' given a history of previous observations &lt;math&gt;h^t = (o^1, \dots, o^t)&lt;/math&gt; from the system. In filtering, a '''belief state''' &lt;math&gt;P(S^{t+1} \mid h^{t+1})&lt;/math&gt; is recursively maintained via a prediction step (where updates &lt;math&gt;P(S^{t+1} \mid h^t) = \mathbb{E}[P(S^{t+1} \mid S^t) \mid h^t]&lt;/math&gt; are computed by marginalizing out the previous hidden state) followed by a conditioning step (where updates &lt;math&gt; P(S^{t+1} \mid h^t, o^{t+1}) \propto P(o^{t+1} \mid S^{t+1}) P(S^{t+1} \mid h^t) &lt;/math&gt; are computed by applying Bayes' rule to condition on a new observation).&lt;ref name = "Song2013"/&gt; The RKHS embedding of the belief state at time ''t+1'' can be recursively expressed as 

:&lt;math&gt;\mu_{S^{t+1} \mid h^{t+1}} = \mathcal{C}_{S^{t+1} O^{t+1}}^\pi \left(\mathcal{C}_{O^{t+1} O^{t+1}}^\pi \right)^{-1} \varphi(o^{t+1}) &lt;/math&gt;

by computing the embeddings of the prediction step via the [[#Kernel Sum Rule|kernel sum rule]] and the embedding of the conditioning step via [[#Kernel Bayes' Rule|kernel Bayes' rule]]. Assuming a training sample &lt;math&gt;(\widetilde{s}^1, \dots, \widetilde{s}^T, \widetilde{o}^1, \dots, \widetilde{o}^T) &lt;/math&gt; is given, one can in practice estimate 

:&lt;math&gt;\widehat{\mu}_{S^{t+1} \mid h^{t+1}} = \sum_{i=1}^T \alpha_i^t \varphi(\widetilde{s}^t)&lt;/math&gt; 

and filtering with kernel embeddings is thus implemented recursively using the following updates for the weights &lt;math&gt;\boldsymbol{\alpha} = (\alpha_1, \dots, \alpha_T)&lt;/math&gt; &lt;ref name = "Song2013"/&gt;

:&lt;math&gt;\mathbf{D}^{t+1} = \operatorname{diag}\left((G+\lambda \mathbf{I})^{-1} \widetilde{G} \boldsymbol{\alpha}^t \right)&lt;/math&gt;
:&lt;math&gt;\boldsymbol{\alpha}^{t+1} = \mathbf{D}^{t+1} \mathbf{K} \left( (\mathbf{D}^{t+1} K)^2 + \widetilde{\lambda} \mathbf{I} \right)^{-1} \mathbf{D}^{t+1} \mathbf{K}_{o^{t+1}} &lt;/math&gt;

where &lt;math&gt;\mathbf{G}, \mathbf{K}&lt;/math&gt; denote the Gram matrices of &lt;math&gt;\widetilde{s}^1, \dots, \widetilde{s}^T &lt;/math&gt; and &lt;math&gt;\widetilde{o}^1, \dots, \widetilde{o}^T&lt;/math&gt; respectively, &lt;math&gt; \widetilde{\mathbf{G}}&lt;/math&gt; is a transfer Gram matrix defined as &lt;math&gt;\widetilde{\mathbf{G}}_{ij} = k(\widetilde{s}_i, \widetilde{s}_{j+1}),&lt;/math&gt; and &lt;math&gt;\mathbf{K}_{o^{t+1}} = (k(\widetilde{o}^1, o^{t+1}), \dots, k(\widetilde{o}^T, o^{t+1}))^T.&lt;/math&gt;

=== Support measure machines ===
The '''support measure machine''' (SMM) is a generalization of the [[support vector machine]] (SVM) in which the training examples are probability distributions paired with labels &lt;math&gt; \{P_i, y_i\}_{i=1}^n, \ y_i \in \{+1, -1\} &lt;/math&gt;.&lt;ref name = "SMM"&gt;K. Muandet, K. Fukumizu, F. Dinuzzo, B. Schölkopf. (2012). [http://books.nips.cc/papers/files/nips25/NIPS2012_0015.pdf Learning from Distributions via Support Measure Machines]. ''Advances in Neural Information Processing Systems'': 10–18.&lt;/ref&gt; SMMs solve the standard SVM [[Support vector machine#Dual form|dual optimization problem]] using the following '''expected kernel'''

:&lt;math&gt; K\left(P(X), Q(Z)\right) = \langle \mu_X , \mu_Z \rangle_\mathcal{H} = \mathbb{E} [k(x,z)] &lt;/math&gt; 

which is computable in closed form for many common specific distributions &lt;math&gt; P_i &lt;/math&gt; (such as the Gaussian distribution) combined with popular embedding kernels &lt;math&gt;k&lt;/math&gt; (e.g. the Gaussian kernel or polynomial kernel), or can be accurately empirically estimated from i.i.d. samples &lt;math&gt;\{x_i\}_{i=1}^n \sim P(X), \{z_j\}_{j=1}^m \sim Q(Z) &lt;/math&gt; via

:&lt;math&gt; \widehat{K} (X, Z) = \frac{1}{n m} \sum_{i=1}^n \sum_{j=1}^m k(x_i, z_j) &lt;/math&gt;

Under certain choices of the embedding kernel &lt;math&gt;k&lt;/math&gt;, the SMM applied to training examples &lt;math&gt;\{P_i, y_i\}_{i=1}^n &lt;/math&gt; is equivalent to a SVM trained on samples &lt;math&gt;\{x_i, y_i\}_{i=1}^n&lt;/math&gt;, and thus the SMM can be viewed as a ''flexible'' SVM in which a different data-dependent kernel (specified by the assumed form of the distribution &lt;math&gt; P_i &lt;/math&gt;) may be placed on each training point.&lt;ref name = "SMM" /&gt;

=== Domain adaptation under covariate, target, and conditional shift ===
The goal of [[domain adaptation]] is the formulation of learning algorithms which generalize well when the training and test data have different distributions. Given training examples &lt;math&gt;\{(x_i^\text{tr}, y_i^\text{tr})\}_{i=1}^n&lt;/math&gt; and a test set &lt;math&gt;\{(x_j^\text{te}, y_j^\text{te}) \}_{j=1}^m &lt;/math&gt; where the &lt;math&gt;y_j^\text{te}&lt;/math&gt; are unknown, three types of differences are commonly assumed between the distribution of the training examples &lt;math&gt;P^\text{tr}(X,Y)&lt;/math&gt; and the test distribution &lt;math&gt; P^\text{te}(X,Y)&lt;/math&gt;:&lt;ref name = "DA"&gt;K. Zhang, B. Schölkopf, K. Muandet, Z. Wang. (2013). [http://jmlr.org/proceedings/papers/v28/zhang13d.pdf Domain adaptation under target and conditional shift]. ''Journal of Machine Learning Research, '''28'''(3): 819–827.&lt;/ref&gt;&lt;ref name = "CovS"&gt;A. Gretton, A. Smola, J. Huang, M. Schmittfull, K. Borgwardt, B. Schölkopf. (2008). Covariate shift and local learning by distribution matching. ''In J. Quinonero-Candela, M. Sugiyama, A. Schwaighofer, N. Lawrence (eds.). Dataset shift in machine learning'', MIT Press, Cambridge, MA: 131–160.&lt;/ref&gt;
# '''Covariate shift''' in which the marginal distribution of the covariates changes across domains: &lt;math&gt; P^\text{tr}(X) \neq P^\text{te}(X)&lt;/math&gt;
# '''Target shift''' in which the marginal distribution of the outputs changes across domains: &lt;math&gt; P^\text{tr}(Y) \neq P^\text{te}(Y)&lt;/math&gt;
# '''Conditional shift''' in which &lt;math&gt;P(Y)&lt;/math&gt; remains the same across domains, but the conditional distributions differ: &lt;math&gt;P^\text{tr}(X \mid Y) \neq P^\text{te}(X \mid Y)&lt;/math&gt;. In general, the presence of conditional shift leads to an [[Well-posed problem|ill-posed]] problem, and the additional assumption that &lt;math&gt;P(X \mid Y)&lt;/math&gt; changes only under [[Location parameter|location]]-[[Scale parameter|scale]] (LS) transformations on &lt;math&gt; X &lt;/math&gt; is commonly imposed to make the problem tractable.

By utilizing the kernel embedding of marginal and conditional distributions, practical approaches to deal with the presence of these types of differences between training and test domains can be formulated. Covariate shift may be accounted for by reweighting examples via estimates of the ratio &lt;math&gt;P^\text{te}(X)/P^\text{tr}(X)&lt;/math&gt; obtained directly from the kernel embeddings of the marginal distributions of &lt;math&gt;X&lt;/math&gt; in each domain without any need for explicit estimation of the distributions.&lt;ref name = "CovS"/&gt; Target shift, which cannot be similarly dealt with since no samples from &lt;math&gt;Y&lt;/math&gt; are available in the test domain, is accounted for by weighting training examples using the vector &lt;math&gt;\boldsymbol{\beta}^*(\mathbf{y}^\text{tr}) &lt;/math&gt; which solves the following optimization problem (where in practice, empirical approximations must be used) &lt;ref name = "DA"/&gt;

:&lt;math&gt;\min_{\boldsymbol{\beta}(y)} \left \|\mathcal{C}_{{(X \mid Y)}^\text{tr}} \mathbb{E} [\boldsymbol{\beta}(y) \varphi(y^\text{tr})] - \mu_{X^\text{te}} \right \|_\mathcal{H}^2&lt;/math&gt; subject to &lt;math&gt;\boldsymbol{\beta}(y) \ge 0, \mathbb{E} [\boldsymbol{\beta}(y^\text{tr})] = 1&lt;/math&gt;

To deal with location scale conditional shift, one can perform a LS transformation of the training points to obtain new transformed training data &lt;math&gt; \mathbf{X}^\text{new} = \mathbf{X}^\text{tr} \odot \mathbf{W} + \mathbf{B}&lt;/math&gt; (where &lt;math&gt;\odot&lt;/math&gt; denotes the element-wise vector product). To ensure similar distributions between the new transformed training samples and the test data, &lt;math&gt;\mathbf{W},\mathbf{B}&lt;/math&gt; are estimated by minimizing the following empirical kernel embedding distance &lt;ref name = "DA"/&gt;

:&lt;math&gt;\left \| \widehat{\mu}_{X^\text{new}} - \widehat{\mu}_{X^\text{te}} \right \|_{\mathcal{H}}^2 = \left \| \widehat{\mathcal{C}}_{(X \mid Y)^\text{new}} \widehat{\mu}_{Y^\text{tr}} - \widehat{\mu}_{X^\text{te}} \right \|_{\mathcal{H}}^2 &lt;/math&gt;

In general, the kernel embedding methods for dealing with LS conditional shift and target shift may be combined to find a reweighted transformation of the training data which mimics the test distribution, and these methods may perform well even in the presence of conditional shifts other than location-scale changes.&lt;ref name = "DA"/&gt;

=== Domain generalization via invariant feature representation ===
Given ''N'' sets of training examples sampled i.i.d. from distributions &lt;math&gt;P^{(1)}(X,Y), P^{(2)}(X,Y), \ldots, P^{(N)}(X,Y)&lt;/math&gt;, the goal of '''domain generalization''' is to formulate learning algorithms which perform well on test examples sampled from a previously unseen domain &lt;math&gt;P^*(X,Y)&lt;/math&gt; where no data from the test domain is available at training time. If conditional distributions &lt;math&gt;P(Y \mid X)&lt;/math&gt; are assumed to be relatively similar across all domains, then a learner capable of domain generalization must estimate a functional relationship between the variables which is robust to changes in the marginals &lt;math&gt;P(X)&lt;/math&gt;. Based on kernel embeddings of these distributions, Domain Invariant Component Analysis (DICA) is a method which determines the transformation of the training data that minimizes the difference between marginal distributions while preserving a common conditional distribution shared between all training domains.&lt;ref name = "DICA"&gt;K. Muandet, D. Balduzzi, B. Schölkopf. (2013).[http://jmlr.org/proceedings/papers/v28/muandet13.pdf Domain Generalization Via Invariant Feature Representation]. ''30th International Conference on Machine Learning''.&lt;/ref&gt; DICA thus extracts ''invariants'', features that transfer across domains, and may be viewed as a generalization of many popular dimension-reduction methods such as [[kernel principal component analysis]], transfer component analysis, and covariance operator inverse regression.&lt;ref name = "DICA"/&gt; 

Defining a probability distribution &lt;math&gt;\mathcal{P}&lt;/math&gt; on the RKHS &lt;math&gt;\mathcal{H}&lt;/math&gt; with 

:&lt;math&gt;\mathcal{P} \left (\mu_{X^{(i)}Y^{(i)}} \right ) = \frac{1}{N} \qquad \text{ for } i=1,\dots, N,&lt;/math&gt; 

DICA measures dissimilarity between domains via '''distributional variance''' which is computed as 

:&lt;math&gt;V_\mathcal{H} (\mathcal{P}) = \frac{1}{N} \operatorname{tr}(\mathbf{G}) - \frac{1}{N^2} \sum_{i,j=1}^N \mathbf{G}_{ij} &lt;/math&gt; 

where 

:&lt;math&gt;\mathbf{G}_{ij} = \left \langle \mu_{X^{(i)}}, \mu_{X^{(j)}} \right \rangle_\mathcal{H} &lt;/math&gt; 

so &lt;math&gt;\mathbf{G}&lt;/math&gt; is a &lt;math&gt;N \times N&lt;/math&gt; Gram matrix over the distributions from which the training data are sampled. Finding an [[Orthogonal matrix|orthogonal transform]] onto a low-dimensional [[Linear subspace|subspace]] ''B'' (in the feature space) which minimizes the distributional variance, DICA simultaneously ensures that ''B'' aligns with the [[Basis function|bases]] of a '''central subspace''' ''C'' for which &lt;math&gt;Y&lt;/math&gt; becomes independent of &lt;math&gt;X&lt;/math&gt; given &lt;math&gt;C^T X&lt;/math&gt; across all domains. In the absence of target values &lt;math&gt;Y&lt;/math&gt;, an unsupervised version of DICA may be formulated which finds a low-dimensional subspace that minimizes distributional variance while simultaneously maximizing the variance of &lt;math&gt;X&lt;/math&gt; (in the feature space) across all domains (rather than preserving a central subspace).&lt;ref name = "DICA"/&gt;

=== Distribution regression ===
In distribution regression, the goal is to regress from probability distributions to reals (or vectors). Many important [[machine learning]] and statistical tasks fit into this framework, including [[Multiple-instance learning|multi-instance learning]], and [[point estimation]] problems without analytical solution (such as [[hyperparameter]] or [[entropy estimation]]). In practice only samples from sampled distributions are observable, and the estimates have to rely on similarities computed between ''sets of points''. Distribution regression has been successfully applied for example in supervised entropy learning, and aerosol prediction using multispectral satellite images.&lt;ref name = "MERR"&gt;Z. Szabó, B. Sriperumbudur, B. Póczos, A. Gretton. [http://jmlr.org/papers/v17/14-510.html Learning Theory for Distribution Regression]. ''Journal of Machine Learning Research'', 17(152):1–40, 2016.&lt;/ref&gt;

Given &lt;math&gt;{\left(\{X_{i,n}\}_{n=1}^{N_i}, y_i\right)}_{i=1}^\ell&lt;/math&gt; training data, where the &lt;math&gt;\hat{X_i} := \{X_{i,n}\}_{n=1}^{N_i}&lt;/math&gt; bag contains samples from a probability distribution &lt;math&gt;X_i&lt;/math&gt; and the &lt;math&gt;i^\text{th}&lt;/math&gt; output label is &lt;math&gt;y_i\in \R&lt;/math&gt;, one can tackle the distribution regression task by taking the embeddings of the distributions, and learning the regressor from the embeddings to the outputs. In other words, one can consider the following kernel [[Tikhonov regularization|ridge regression]] problem &lt;math&gt;(\lambda&gt;0)&lt;/math&gt;

:&lt;math&gt;J(f) = \frac{1}{\ell} \sum_{i=1}^\ell \left[f\left(\mu_{\hat{X_i}}\right)-y_i\right]^2 + \lambda \|f\|_{\mathcal{H}(K)}^2 \to \min_{f\in \mathcal{H}(K)}, &lt;/math&gt;

where 

:&lt;math&gt;\mu_{\hat{X}_i} = \int_\Omega k(\cdot,u) \, \mathrm{d} \hat{X}_i(u)= \frac{1}{N_i} \sum_{n=1}^{N_i} k(\cdot, X_{i,n})&lt;/math&gt; 

with a &lt;math&gt;k&lt;/math&gt; kernel on the domain of &lt;math&gt;X_i&lt;/math&gt;-s &lt;math&gt;(k:\Omega\times \Omega \to \R)&lt;/math&gt;, &lt;math&gt;K&lt;/math&gt; is a kernel on the embedded distributions, and &lt;math&gt;\mathcal{H}(K)&lt;/math&gt; is the RKHS determined by &lt;math&gt;K&lt;/math&gt;. Examples for &lt;math&gt;K&lt;/math&gt; include the linear kernel &lt;math&gt;\left[ K(\mu_P,\mu_Q) = \langle\mu_P,\mu_Q\rangle_{\mathcal{H}(k)} \right] &lt;/math&gt;, the Gaussian kernel &lt;math&gt; \left[ K(\mu_P,\mu_Q) = e^{-\left\|\mu_P-\mu_Q\right\|_{H(k)}^2/(2\sigma^2)} \right] &lt;/math&gt;, the exponential kernel &lt;math&gt; \left[ K(\mu_P,\mu_Q) = e^{-\left\|\mu_P-\mu_Q\right\|_{H(k)}/(2\sigma^2)} \right] &lt;/math&gt;, the Cauchy kernel &lt;math&gt; \left[ K(\mu_P,\mu_Q) = \left(1+ \left\|\mu_P-\mu_Q\right\|_{H(k)}^2/\sigma^2 \right)^{-1} \right] &lt;/math&gt;, the generalized t-student kernel &lt;math&gt; \left[ K(\mu_P,\mu_Q) = \left(1+ \left\|\mu_P-\mu_Q\right\|_{H(k)}^{\sigma} \right)^{-1}, (\sigma \le 2) \right] &lt;/math&gt;, or the inverse multiquadrics kernel &lt;math&gt; \left[ K(\mu_P,\mu_Q) = \left(\left\|\mu_P-\mu_Q\right\|_{H(k)}^2 + \sigma^2 \right)^{-\frac{1}{2}} \right] &lt;/math&gt;.

The prediction on a new distribution &lt;math&gt;(\hat{X})&lt;/math&gt; takes the simple, analytical form
:: &lt;math&gt; \hat{y}\big(\hat{X}\big) = \mathbf{k} [\mathbf{G} + \lambda \ell]^{-1}\mathbf{y}, &lt;/math&gt; 
where &lt;math&gt;\mathbf{k}=\big[K \big(\mu_{\hat{X}_i},\mu_{\hat{X}}\big)\big]\in \R^{1\times \ell}&lt;/math&gt;, &lt;math&gt;\mathbf{G}=[G_{ij}]\in \R^{\ell\times \ell}&lt;/math&gt;, &lt;math&gt;G_{ij} = K\big(\mu_{\hat{X}_i},\mu_{\hat{X}_j}\big)\in \R&lt;/math&gt;, &lt;math&gt;\mathbf{y}=[y_1;\ldots;y_\ell]\in \R^\ell&lt;/math&gt;. Under mild regularity conditions this estimator can be shown to be consistent and it can achieve the one-stage sampled (as if one had access to the true &lt;math&gt;X_i&lt;/math&gt;-s) [[Minimax estimator|minimax optimal]] rate.&lt;ref name = "MERR" /&gt; In the &lt;math&gt;J&lt;/math&gt; objective function &lt;math&gt;y_i&lt;/math&gt;-s are real numbers; the results can also be extended to the case when &lt;math&gt;y_i&lt;/math&gt;-s are &lt;math&gt;d&lt;/math&gt;-dimensional vectors, or more generally elements of a [[Separable space|separable]] [[Hilbert space]] using operator-valued &lt;math&gt;K&lt;/math&gt; kernels.

== Example ==
In this simple example, which is taken from Song et al.,&lt;ref name = "Song2013"/&gt; &lt;math&gt;X, Y&lt;/math&gt; are assumed to be [[Probability distribution#Discrete probability distribution|discrete random variables]] which take values in the set &lt;math&gt;\{1,\ldots,K\} &lt;/math&gt; and the kernel is chosen to be the [[Kronecker delta]] function, so &lt;math&gt;k(x,x') = \delta(x,x')&lt;/math&gt;. The feature map corresponding to this kernel is the [[standard basis]] vector &lt;math&gt;\varphi(x) = \mathbf{e}_x&lt;/math&gt;. The kernel embeddings of such a distributions are thus vectors of marginal probabilities while the embeddings of joint distributions in this setting are &lt;math&gt;K\times K &lt;/math&gt; matrices specifying joint probability tables, and the explicit form of these embeddings is

:&lt;math&gt;\mu_X = \mathbb{E} [\mathbf{e}_X] = \begin{pmatrix} P(X=1) \\ \vdots \\ P(X=K) \\ \end{pmatrix}&lt;/math&gt;
:&lt;math&gt;\mathcal{C}_{XY} = \mathbb{E} [\mathbf{e}_X \otimes \mathbf{e}_Y] = ( P(X=s, Y=t))_{s,t \in \{1,\ldots,K\}} &lt;/math&gt;

The conditional distribution embedding operator, 

:&lt;math&gt;\mathcal{C}_{Y\mid X} = \mathcal{C}_{YX} \mathcal{C}_{XX}^{-1},&lt;/math&gt; 

is in this setting a conditional probability table

:&lt;math&gt;\mathcal{C}_{Y \mid X} = ( P(Y=s \mid X=t))_{s,t \in \{1,\dots,K\}}&lt;/math&gt;

and 

:&lt;math&gt;\mathcal{C}_{XX} =\begin{pmatrix} P(X=1) &amp; \dots &amp; 0 \\ \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; \dots &amp; P(X=K) \\ \end{pmatrix}&lt;/math&gt;

Thus, the embeddings of the conditional distribution under a fixed value of &lt;math&gt;X&lt;/math&gt; may be computed as

:&lt;math&gt;\mu_{Y \mid x} = \mathcal{C}_{Y \mid X} \varphi(x) = \begin{pmatrix} P(Y=1 \mid X = x) \\ \vdots \\ P(Y=K \mid X = x) \\ \end{pmatrix} &lt;/math&gt;

In this discrete-valued setting with the Kronecker delta kernel, the [[#Rules of probability as operations in the RKHS|kernel sum rule]] becomes

:&lt;math&gt;\underbrace{\begin{pmatrix} Q(X=1) \\ \vdots \\ P(X = N) \\ \end{pmatrix}}_{\mu_X^\pi} = \underbrace{\begin{pmatrix} \\ P(X=s \mid Y=t) \\ \\ \end{pmatrix}}_{\mathcal{C}_{X\mid Y}} \underbrace{\begin{pmatrix} \pi(Y=1) \\ \vdots \\ \pi(Y = N) \\ \end{pmatrix}}_{ \mu_Y^\pi}&lt;/math&gt;

The [[#Rules of probability as operations in the RKHS|kernel chain rule]] in this case is given by

:&lt;math&gt;\underbrace{\begin{pmatrix} \\ Q(X=s,Y=t) \\ \\ \end{pmatrix} }_{\mathcal{C}_{XY}^\pi} = \underbrace{\begin{pmatrix} \\ P(X=s \mid Y=t) \\ \\ \end{pmatrix} }_{\mathcal{C}_{X \mid Y}} \underbrace{ \begin{pmatrix} \pi(Y=1) &amp; \dots &amp; 0 \\ \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; \dots &amp; \pi(Y=K) \\
\end{pmatrix} }_{\mathcal{C}_{YY}^\pi} &lt;/math&gt;

==References==
{{reflist}}

==External links==
* [https://bitbucket.org/szzoli/ite/ Information Theoretical Estimators toolbox] (distribution regression demonstration).

[[Category:Machine learning]]
[[Category:Theory of probability distributions]]</text>
      <sha1>5bi3gvjngwu8zm9we5loyf9dbdplekb</sha1>
    </revision>
  </page>
  <page>
    <title>Stability (learning theory)</title>
    <ns>0</ns>
    <id>33886025</id>
    <revision>
      <id>991937657</id>
      <parentid>991936354</parentid>
      <timestamp>2020-12-02T16:44:18Z</timestamp>
      <contributor>
        <ip>2A01:E0A:389:80:0:0:10B4:855A</ip>
      </contributor>
      <comment>/* Leave-one-out cross-validation (CVloo) Stability */ can't fix this minus sign</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="16245" xml:space="preserve">'''Stability''', also known as '''algorithmic stability''', is a notion in [[computational learning theory]] of how a [[machine learning| machine learning algorithm]] is perturbed by small changes to its inputs. A stable learning algorithm is one for which the prediction does not change much when the training data is modified slightly. For instance, consider a machine learning algorithm that is being trained to [[Handwriting recognition|recognize handwritten letters]] of the alphabet, using 1000 examples of handwritten letters and their labels ("A" to "Z") as a training set. One way to modify this training set is to leave out an example, so that only 999 examples of handwritten letters and their labels are available. A stable learning algorithm would produce a similar [[statistical classification|classifier]] with both the 1000-element and 999-element training sets.

Stability can be studied for many types of learning problems, from [[Natural language processing|language learning]] to [[inverse problem]]s in physics and engineering, as it is a property of the learning process rather than the type of information being learned. The study of stability gained importance in [[computational learning theory]] in the 2000s when it was shown to have a connection with [[Machine learning#Generalization|generalization]]{{citation needed|date=September 2019}}. It was shown that for large classes of learning algorithms, notably [[empirical risk minimization]] algorithms, certain types of stability ensure good generalization.

== History ==

A central goal in designing a [[machine learning| machine learning system]] is to guarantee that the learning algorithm will [[Machine learning#Generalization|generalize]], or perform accurately on new examples after being trained on a finite number of them. In the 1990s, milestones were reached in obtaining generalization bounds for [[supervised learning| supervised learning algorithms]]. The technique historically used to prove generalization was to show that an algorithm was [[consistent estimator|consistent]], using the [[uniform convergence]] properties of empirical quantities to their means. This technique was used to obtain generalization bounds for the large class of [[empirical risk minimization]] (ERM) algorithms. An ERM algorithm is one that selects a solution from a hypothesis space &lt;math&gt;H&lt;/math&gt; in such a way to minimize the empirical error on a training set &lt;math&gt;S&lt;/math&gt;.

A general result, proved by [[Vladimir Vapnik]] for an ERM binary classification algorithms, is that for any target function and input distribution, any hypothesis space &lt;math&gt;H&lt;/math&gt; with [[VC dimension|VC-dimension]] &lt;math&gt;d&lt;/math&gt;, and &lt;math&gt;n&lt;/math&gt; training examples, the algorithm is consistent and will produce a training error that is at most &lt;math&gt;O\left(\sqrt{\frac{d}{n}}\right)&lt;/math&gt; (plus logarithmic factors) from the true error. The result was later extended to almost-ERM algorithms with function classes that do not have unique minimizers.

Vapnik's work, using what became known as [[VC theory]], established a relationship between generalization of a learning algorithm and properties of the hypothesis space &lt;math&gt;H&lt;/math&gt; of functions being learned. However, these results could not be applied to algorithms with hypothesis spaces of unbounded VC-dimension. Put another way, these results could not be applied when the information being learned had a complexity that was too large to measure. Some of the simplest machine learning algorithms—for instance, for regression—have hypothesis spaces with unbounded VC-dimension. Another example is language learning algorithms that can produce sentences of arbitrary length.

Stability analysis was developed in the 2000s for [[computational learning theory]] and is an alternative method for obtaining generalization bounds. The stability of an algorithm is a property of the learning process, rather than a direct property of the hypothesis space &lt;math&gt;H&lt;/math&gt;, and it can be assessed in algorithms that have hypothesis spaces with unbounded or undefined VC-dimension such as nearest neighbor. A stable learning algorithm is one for which the learned function does not change much when the training set is slightly modified, for instance by leaving out an example. A measure of [[Leave one out error]] is used in a Cross Validation Leave One Out (CVloo) algorithm to evaluate a learning algorithm's stability with respect to the loss function. As such, stability analysis is the application of [[sensitivity analysis]] to machine learning.

== Summary of classic results ==

* '''Early 1900s''' - Stability in learning theory was earliest described in terms of continuity of the learning map &lt;math&gt;L&lt;/math&gt;, traced to [[Andrey Nikolayevich Tikhonov]].
* '''1979''' - Devroye and Wagner observed that the leave-one-out behavior of an algorithm is related to its sensitivity to small changes in the sample.&lt;ref&gt;L. Devroye and Wagner, Distribution-free performance bounds for potential function rules, IEEE Trans. Inf. Theory 25(5) (1979) 601–604.&lt;/ref&gt;
* '''1999''' - Kearns and Ron discovered a connection between finite VC-dimension and stability.&lt;ref&gt;M. Kearns and [[Dana Ron|D. Ron]], Algorithmic stability and sanity-check bounds for leave-one-out cross-validation, Neural Comput. 11(6) (1999) 1427–1453.&lt;/ref&gt;
* '''2002''' - In a landmark paper, Bousquet and Elisseeff proposed the notion of ''uniform hypothesis stability'' of a learning algorithm and showed that it implies low generalization error. Uniform hypothesis stability, however, is a strong condition that does not apply to large classes of algorithms, including ERM algorithms with a hypothesis space of only two functions.&lt;ref&gt;O. Bousquet and A. Elisseeff. Stability and generalization. J. Mach. Learn. Res., 2:499–526, 2002.&lt;/ref&gt;
* '''2002''' - Kutin and Niyogi extended Bousquet and Elisseeff's results by providing generalization bounds for several weaker forms of stability which they called ''almost-everywhere stability''. Furthermore, they took an initial step in establishing the relationship between stability and consistency in ERM algorithms in the Probably Approximately Correct (PAC) setting.&lt;ref&gt;S. Kutin and P. Niyogi, Almost-everywhere algorithmic stability and generalization error, Technical Report TR-2002-03, University of Chicago (2002).&lt;/ref&gt;
* '''2004''' - Poggio et al. proved a general relationship between stability and ERM consistency. They proposed a statistical form of leave-one-out-stability which they called ''CVEEEloo stability'', and showed that it is a) sufficient for generalization in bounded loss classes, and b) necessary and sufficient for consistency (and thus generalization) of ERM algorithms for certain loss functions such as the square loss, the absolute value and the binary classification loss.&lt;ref&gt;S. Mukherjee, P. Niyogi, T. Poggio, and R. M. Rifkin. Learning theory: stability is sufficient for generalization and necessary and sufficient for consistency of empirical risk minimization. Adv. Comput. Math., 25(1-3):161–193, 2006.&lt;/ref&gt;
* '''2010''' - Shalev Shwartz noticed problems with the original results of Vapnik due to the complex relations between hypothesis space and loss class. They discuss stability notions that capture different loss classes and different types of learning, supervised and unsupervised.&lt;ref&gt;Shalev Shwartz, S., Shamir, O., Srebro, N., Sridharan, K.,  Learnability, Stability and Uniform Convergence, Journal of Machine Learning Research, 11(Oct):2635-2670, 2010.&lt;/ref&gt;

== Preliminary definitions ==

We define several terms related to learning algorithms training sets, so that we can then define stability in multiple ways and present theorems from the field.

A machine learning algorithm, also known as a learning map &lt;math&gt;L&lt;/math&gt;, maps a training data set, which is a set of labeled examples &lt;math&gt;(x,y)&lt;/math&gt;, onto a function &lt;math&gt;f&lt;/math&gt; from &lt;math&gt;X&lt;/math&gt; to &lt;math&gt;Y&lt;/math&gt;, where &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt; are in the same space of the training examples. The functions &lt;math&gt;f&lt;/math&gt; are selected from a hypothesis space of functions called &lt;math&gt;H&lt;/math&gt;.

The training set from which an algorithm learns is defined as

&lt;math&gt;S = \{z_1 = (x_1,\ y_1)\ ,..,\ z_m = (x_m,\ y_m)\}&lt;/math&gt;

and is of size &lt;math&gt;m&lt;/math&gt; in &lt;math&gt;Z = X \times Y&lt;/math&gt;

drawn i.i.d. from an unknown distribution D.

Thus, the learning map &lt;math&gt;L&lt;/math&gt; is defined as a mapping from &lt;math&gt;Z_m&lt;/math&gt; into &lt;math&gt;H&lt;/math&gt;, mapping a training set &lt;math&gt;S&lt;/math&gt; onto a function &lt;math&gt;f_S&lt;/math&gt; from &lt;math&gt;X&lt;/math&gt; to &lt;math&gt;Y&lt;/math&gt;. Here, we consider only deterministic algorithms where &lt;math&gt;L&lt;/math&gt; is symmetric with respect to &lt;math&gt;S&lt;/math&gt;, i.e. it does not depend on the order of the elements in the training set. Furthermore, we assume that all functions are measurable and all sets are countable.

The loss &lt;math&gt;V&lt;/math&gt; of a hypothesis &lt;math&gt;f&lt;/math&gt; with respect to an example &lt;math&gt;z = (x,y)&lt;/math&gt; is then defined as &lt;math&gt;V(f,z) = V(f(x),y)&lt;/math&gt;.

The empirical error of &lt;math&gt;f&lt;/math&gt; is &lt;math&gt;I_S[f] = \frac{1}{n}\sum V(f,z_i)&lt;/math&gt;.

The true error of &lt;math&gt;f&lt;/math&gt; is &lt;math&gt;I[f] = \mathbb{E}_z V(f,z)&lt;/math&gt;

Given a training set S of size m, we will build, for all i = 1....,m, modified training sets as follows:
* By removing the i-th element
&lt;math&gt;S^{|i} = \{z_1 ,...,\ z_{i-1},\ z_{i+1},...,\ z_m\}&lt;/math&gt;
* By replacing the i-th element
&lt;math&gt;S^i = \{z_1 ,...,\ z_{i-1},\ z_i^',\ z_{i+1},...,\ z_m\}&lt;/math&gt;

== Definitions of stability ==

===Hypothesis Stability===
An algorithm &lt;math&gt;L&lt;/math&gt; has hypothesis stability β with respect to the loss function V if the following holds:

&lt;math&gt;\forall i\in \{1,...,m\}, \mathbb{E}_{S,z} [|V(f_S,z)-V(f_{S^{|i}},z)|]\leq\beta.&lt;/math&gt;

===Point-wise Hypothesis Stability===
An algorithm &lt;math&gt;L&lt;/math&gt; has point-wise hypothesis stability β with respect to the loss function V if the following holds:

&lt;math&gt;\forall i\in\ \{1,...,m\}, \mathbb{E}_{S} [|V(f_S,z_i)-V(f_{S^{|i}},z_i)|]\leq\beta.&lt;/math&gt;

===Error Stability===
An algorithm &lt;math&gt;L&lt;/math&gt; has error stability β with respect to the loss function V if the following holds:

&lt;math&gt;\forall S\in Z^m, \forall i\in\{1,...,m\}, |\mathbb{E}_z[V(f_S,z)]-\mathbb{E}_z[V(f_{S^{|i}},z)]|\leq\beta&lt;/math&gt;

===Uniform Stability===
An algorithm &lt;math&gt;L&lt;/math&gt; has uniform stability β with respect to the loss function V if the following holds:

&lt;math&gt;\forall S\in Z^m, \forall i\in\{1,...,m\}, \sup_{z\in Z}|V(f_S,z)-V(f_{S^{|i}},z)|\leq\beta&lt;/math&gt;

A probabilistic version of uniform stability β is:

&lt;math&gt;\forall S\in Z^m, \forall i\in\{1,...,m\}, \mathbb{P}_S\{\sup_{z\in Z}|V(f_S,z)-V(f_{S^{|i}},z)|\leq\beta\}\geq1-\delta&lt;/math&gt;

An algorithm is said to be '''stable''', when the value of &lt;math&gt;\beta&lt;/math&gt; decreases as &lt;math&gt;O(\frac{1}{m})&lt;/math&gt;.

===Leave-one-out cross-validation (CVloo) Stability===
An algorithm &lt;math&gt;L&lt;/math&gt; has CVloo stability β with respect to the loss function V if the following holds:

&lt;math&gt;\forall i\in\{1,...,m\}, \mathbb{P}_S\{ |V(f_S,z_i) - V(f_{S^{|i}},z_i)|\leq\beta_{CV}\}\geq1 - \delta_{CV}&lt;/math&gt;

The definition of (CVloo) Stability is '''equivalent''' to Pointwise-hypothesis  stability seen earlier.

===Expected-leave-one-out error (&lt;math&gt;Eloo_{err}&lt;/math&gt;) Stability===
An algorithm &lt;math&gt;L&lt;/math&gt; has &lt;math&gt;Eloo_{err}&lt;/math&gt; stability if for each n there exists a &lt;math&gt;\beta_{EL}^m&lt;/math&gt; and a &lt;math&gt;\delta_{EL}^m&lt;/math&gt; such that:

&lt;math&gt;\forall i\in\{1,...,m\}, \mathbb{P}_S\{|I[f_S]-\frac{1}{m}\sum_{i=1}^m V(f_{S^{|i}},z_i)|\leq\beta_{EL}^m\}\geq1-\delta_{EL}^m&lt;/math&gt;, with &lt;math&gt;\beta_{EL}^m&lt;/math&gt; and &lt;math&gt;\delta_{EL}^m&lt;/math&gt; going to zero for &lt;math&gt;m,\rightarrow\infty&lt;/math&gt;

== Classic theorems ==

'''From Bousquet and Elisseeff (02)''':

For symmetric learning algorithms with bounded loss, if the algorithm has Uniform Stability with the probabilistic definition above, then the algorithm generalizes.

Uniform Stability is a strong condition which is not met by all algorithms but is, surprisingly, met by the large and important class of Regularization algorithms.
The generalization bound is given in the article.

'''From Mukherjee et al. (06)''':

*For symmetric learning algorithms with bounded loss, if the algorithm has ''both'' Leave-one-out cross-validation (CVloo) Stability and Expected-leave-one-out error (&lt;math&gt;Eloo_{err}&lt;/math&gt;) Stability as defined above, then the algorithm generalizes.
*Neither condition alone is sufficient for generalization. However, both together ensure generalization (while the converse is not true).
*For ERM algorithms specifically (say for the square loss), Leave-one-out cross-validation (CVloo) Stability is both necessary and sufficient for consistency and generalization.

This is an important result for the foundations of learning theory, because it shows that two previously unrelated properties of an algorithm, stability and consistency, are equivalent for ERM (and certain loss functions).
The generalization bound is given in the article.

==Algorithms that are stable==
This is a list of algorithms that have been shown to be stable, and the article where the associated generalization bounds are provided.

* [[Linear regression]]&lt;ref&gt;Elisseeff, A. A study about algorithmic stability and
 their relation to generalization performances. Technical
 report. (2000)
&lt;/ref&gt;
*k-NN classifier with a {0-1} loss function.&lt;ref&gt;L. Devroye and Wagner, Distribution-free performance bounds for potential function rules, IEEE Trans. Inf. Theory 25(5) (1979) 601–604.&lt;/ref&gt;
*[[Support Vector Machine]] (SVM) classification with a bounded kernel and where the regularizer is a norm in a Reproducing Kernel Hilbert Space. A large regularization constant &lt;math&gt;C&lt;/math&gt; leads to good stability.&lt;ref&gt;O. Bousquet and A. Elisseeff. Stability and generalization. J. Mach. Learn. Res., 2:499–526, 2002.&lt;/ref&gt;
*Soft margin SVM classification.&lt;ref&gt;O. Bousquet and A. Elisseeff. Stability and generalization. J. Mach. Learn. Res., 2:499–526, 2002.&lt;/ref&gt;
*[[regularization (machine learning)|Regularized]] Least Squares regression.&lt;ref&gt;O. Bousquet and A. Elisseeff. Stability and generalization. J. Mach. Learn. Res., 2:499–526, 2002.&lt;/ref&gt;
*The minimum relative entropy algorithm for classification.&lt;ref&gt;O. Bousquet and A. Elisseeff. Stability and generalization. J. Mach. Learn. Res., 2:499–526, 2002.&lt;/ref&gt;
*A version of [[bootstrap aggregating|bagging]] regularizers with the number &lt;math&gt;k&lt;/math&gt; of regressors increasing with &lt;math&gt;n&lt;/math&gt;.&lt;ref&gt;Rifkin, R. Everything Old is New Again: A fresh
 look at historical approaches in machine learning. Ph.D. Thesis, MIT, 2002&lt;/ref&gt;
*Multi-class SVM classification.&lt;ref&gt;Rifkin, R. Everything Old is New Again: A fresh
 look at historical approaches in machine learning. Ph.D. Thesis, MIT, 2002&lt;/ref&gt;
*All learning algorithms with Tikhonov regularization satisfies Uniform Stability criteria and are, thus, generalizable.&lt;ref&gt;http://www.mit.edu/~9.520/spring09/Classes/class10_stability.pdf&lt;/ref&gt;

== References ==
{{Reflist}}

==Further reading==
{{Refbegin}}
*S.Kutin and P.Niyogi.Almost-everywhere algorithmic stability and generalization error. In Proc. of UAI 18, 2002
*S. Rakhlin, S. Mukherjee, and T. Poggio. Stability results in learning theory. Analysis and Applications, 3(4):397–419, 2005
*V.N. Vapnik. The Nature of Statistical Learning Theory. Springer, 1995
*Vapnik, V., Statistical Learning Theory. Wiley, New York, 1998
*Poggio, T., Rifkin, R., Mukherjee, S. and Niyogi, P., "Learning Theory: general conditions for predictivity", Nature, Vol. 428, 419-422, 2004
*Andre Elisseeff, Theodoros Evgeniou, Massimiliano Pontil, Stability of Randomized Learning Algorithms, Journal of Machine Learning Research 6, 55–79, 2010
*Elisseeff, A. Pontil, M., Leave-one-out Error and Stability of Learning Algorithms with Applications, NATO SCIENCE SERIES SUB SERIES III COMPUTER AND SYSTEMS SCIENCES, 2003, VOL 190, pages 111-130
*Shalev Shwartz, S., Shamir, O., Srebro, N., Sridharan, K.,  Learnability, Stability and Uniform Convergence, Journal of Machine Learning Research, 11(Oct):2635-2670, 2010
{{Refend}}

[[Category:Machine learning]]
[[Category:Learning]]</text>
      <sha1>dwgg9qy8dq79bva1er7ctp1x073tmxi</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Artificial neural networks</title>
    <ns>14</ns>
    <id>42936114</id>
    <revision>
      <id>960124081</id>
      <parentid>952535605</parentid>
      <timestamp>2020-06-01T07:06:52Z</timestamp>
      <contributor>
        <username>Pi bot</username>
        <id>30394555</id>
      </contributor>
      <minor/>
      <comment>Updating the Commons category from "Category:Artificial neural network" to "Category:Artificial neural networks" to avoid a category redirect</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="460" xml:space="preserve">{{JEL code|C45}}
{{Commons cat|Artificial neural networks}}
{{Cat main|Artificial neural networks}}

This category are for articles about artificial neural networks (ANN).

[[Category:Classification algorithms]]
[[Category:Computational neuroscience]]
[[Category:Computational statistics]]
[[Category:Cybernetics]]
[[Category:Machine learning]]
[[Category:Mathematical modeling]]
[[Category:Mathematical psychology]]
[[Category:Neural networks]]
{{CatAutoTOC}}</text>
      <sha1>itbfdp555ag4tyvd9ibzbnfwhrrq2gu</sha1>
    </revision>
  </page>
  <page>
    <title>Bayesian interpretation of kernel regularization</title>
    <ns>0</ns>
    <id>35867897</id>
    <revision>
      <id>951079928</id>
      <parentid>948786594</parentid>
      <timestamp>2020-04-15T11:07:01Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: doi added to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="17459" xml:space="preserve">{{context|date=May 2012}}
In [[machine learning]], [[kernel methods]] arise from the assumption of an inner product space or similarity structure on inputs. For some such methods, such as [[support vector machine]]s (SVMs), the original formulation and its [[regularization (mathematics)|regularization]] were not Bayesian in nature. It is helpful to understand them from a [[Bayesian probability|Bayesian]] perspective.  Because the kernels are not necessarily positive semidefinite, the underlying structure may not be inner product spaces, but instead more general [[reproducing kernel Hilbert space]]s.  In Bayesian probability kernel methods are a key component of [[Gaussian processes]], where the kernel function is known as the covariance function.  Kernel methods have traditionally been used in [[supervised learning]] problems where the ''input space'' is usually a ''space of vectors'' while the ''output space'' is a ''space of scalars''. More recently these methods have been extended to problems that deal with [[Kernel methods for vector output|multiple outputs]] such as in [[multi-task learning]].&lt;ref name=AlvRosLaw11&gt;{{cite arxiv|last=Álvarez|first=Mauricio A.|author2=Rosasco, Lorenzo |author3=Lawrence, Neil D. |title=Kernels for Vector-Valued Functions: A Review|eprint=1106.6251 |date=June 2011|class=stat.ML}}&lt;/ref&gt;

A mathematical equivalence between the regularization and the Bayesian point of view is easily proved in cases where the reproducing kernel Hilbert space is ''finite-dimensional''. The infinite-dimensional case raises subtle mathematical issues; we will consider here the finite-dimensional case. We start with a brief review of the main ideas underlying kernel methods for scalar learning, and briefly introduce the concepts of regularization and Gaussian processes. We then show how both points of view arrive at essentially equivalent [[estimator|estimators]], and show the connection that ties them together.

==The supervised learning problem==

The classical [[supervised learning]] problem requires estimating the output for some new input point &lt;math&gt;\mathbf{x}'&lt;/math&gt; by learning a scalar-valued estimator &lt;math&gt;\hat{f}(\mathbf{x}')&lt;/math&gt; on the basis of a training set &lt;math&gt;S&lt;/math&gt; consisting of &lt;math&gt;n&lt;/math&gt; input-output pairs, &lt;math&gt;S = (\mathbf{X},\mathbf{Y}) = (\mathbf{x}_1,y_1),\ldots,(\mathbf{x}_n,y_n)&lt;/math&gt;.&lt;ref name=Vap98&gt;{{cite book|last=Vapnik|first=Vladimir|title=Statistical learning theory|year=1998|publisher=Wiley|isbn=9780471030034|url=https://books.google.com/?id=GowoAQAAMAAJ&amp;q=statistical+learning+theory&amp;dq=statistical+learning+theory}}&lt;/ref&gt;  Given a symmetric and positive bivariate function &lt;math&gt;k(\cdot,\cdot)&lt;/math&gt; called a ''kernel'', one of the most popular estimators in machine learning is given by

{{NumBlk|::|&lt;math&gt;
\hat{f}(\mathbf{x}') = \mathbf{k}^\top(\mathbf{K} + \lambda n \mathbf{I})^{-1} \mathbf{Y},
&lt;/math&gt;|{{EquationRef|1}}}}

where &lt;math&gt;\mathbf{K} \equiv k(\mathbf{X},\mathbf{X})&lt;/math&gt; is the [[Gramian matrix|kernel matrix]] with entries &lt;math&gt;\mathbf{K}_{ij} = k(\mathbf{x}_i,\mathbf{x}_j)&lt;/math&gt;, &lt;math&gt; \mathbf{k} = [k(\mathbf{x}_1,\mathbf{x}'),\ldots,k(\mathbf{x}_n,\mathbf{x}')]^\top&lt;/math&gt;, and &lt;math&gt;\mathbf{Y} = [y_1,\ldots,y_n]^\top&lt;/math&gt;.  We will see how this estimator can be derived both from a regularization and a Bayesian perspective.

==A regularization perspective==

The main assumption in the regularization perspective is that the set of functions &lt;math&gt;\mathcal{F}&lt;/math&gt; is assumed to belong to a reproducing kernel Hilbert space &lt;math&gt;\mathcal{H}_k&lt;/math&gt;.&lt;ref name=Vap98 /&gt;&lt;ref name=Wah90 /&gt;&lt;ref name=SchSmo02&gt;{{cite book|last=Schölkopf|first=Bernhard|title=Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond|year=2002|publisher=MIT Press|isbn=9780262194754|author2=Smola, Alexander J.}}&lt;/ref&gt;&lt;ref name=GirPog90&gt;{{cite journal|last=Girosi|first=F.|author2=Poggio, T.|title=Networks and the best approximation property|journal=Biological Cybernetics|year=1990|volume=63|issue=3|pages=169–176|publisher=Springer|doi=10.1007/bf00195855|url=https://dspace.mit.edu/bitstream/1721.1/6017/2/AIM-1164.pdf|hdl=1721.1/6017}}&lt;/ref&gt;

===Reproducing kernel Hilbert space===

A [[reproducing kernel Hilbert space]] (RKHS) &lt;math&gt;\mathcal{H}_k&lt;/math&gt; is a [[Hilbert space]] of functions defined by a [[Symmetry in mathematics|symmetric]], [[positive-definite function]] &lt;math&gt;k : \mathcal{X} \times \mathcal{X} \rightarrow \mathbb{R}&lt;/math&gt; called the ''reproducing kernel'' such that the function &lt;math&gt;k(\mathbf{x},\cdot)&lt;/math&gt; belongs to &lt;math&gt;\mathcal{H}_k&lt;/math&gt; for all &lt;math&gt;\mathbf{x} \in \mathcal{X}&lt;/math&gt;.&lt;ref name=Aro50&gt;{{cite journal|last=Aronszajn|first=N|title=Theory of Reproducing Kernels|journal=Transactions of the American Mathematical Society|date=May 1950|volume=68|issue=3|pages=337–404|doi=10.2307/1990404|jstor=1990404|doi-access=free}}&lt;/ref&gt;&lt;ref name=Sch64&gt;{{cite journal|last=Schwartz|first=Laurent|title=Sous-espaces hilbertiens d'espaces vectoriels topologiques et noyaux associés (noyaux reproduisants)|journal=Journal d'Analyse Mathématique|year=1964|volume=13|issue=1|pages=115–256|publisher=Springer|doi=10.1007/bf02786620}}&lt;/ref&gt;&lt;ref name=CucSma01&gt;{{cite journal|last=Cucker|first=Felipe|author2=Smale, Steve|title=On the mathematical foundations of learning|journal=Bulletin of the American Mathematical Society|date=October 5, 2001|volume=39|issue=1|pages=1–49|doi=10.1090/s0273-0979-01-00923-5|doi-access=free}}&lt;/ref&gt; There are three main properties make an RKHS appealing:

1. The ''reproducing property'', which gives name to the space,

:&lt;math&gt;
f(\mathbf{x}) = \langle f,k(\mathbf{x},\cdot) \rangle_k, \quad \forall \ f \in \mathcal{H}_k,
&lt;/math&gt;

where &lt;math&gt;\langle \cdot,\cdot \rangle_k&lt;/math&gt; is the inner product in &lt;math&gt;\mathcal{H}_k&lt;/math&gt;.

2. Functions in an RKHS are in the closure of the linear combination of the kernel at given points,

:&lt;math&gt;
f(\mathbf{x}) = \sum_i k(\mathbf{x}_i,\mathbf{x})c_i
&lt;/math&gt;.

This allows the construction in a unified framework of both linear and generalized linear models.

3. The squared norm in an RKHS can be written as

:&lt;math&gt;\|f\|_k^2 = \sum_{i,j} k(\mathbf{x}_i,\mathbf{x}_j) c_i c_j
&lt;/math&gt;

and could be viewed as measuring the ''complexity'' of the function.

===The regularized functional===

The estimator is derived as the minimizer of the regularized functional

{{NumBlk|::|&lt;math&gt;
\frac{1}{n} \sum_{i=1}^{n}(f(\mathbf{x}_i)-y_i)^2 + \lambda \|f\|_k^2,
&lt;/math&gt;|{{EquationRef|2}}}}

where &lt;math&gt;f \in \mathcal{H}_k&lt;/math&gt; and &lt;math&gt;\|\cdot\|_k&lt;/math&gt; is the norm in &lt;math&gt;\mathcal{H}_k&lt;/math&gt;.  The first term in this functional, which measures the average of the squares of the errors between the &lt;math&gt;f(\mathbf{x}_i)&lt;/math&gt; and the &lt;math&gt;y_i&lt;/math&gt;, is called the ''empirical risk'' and represents the cost we pay by predicting &lt;math&gt;f(\mathbf{x}_i)&lt;/math&gt; for the true value &lt;math&gt;y_i&lt;/math&gt;.  The second term in the functional is the squared norm in a RKHS multiplied by a weight &lt;math&gt;\lambda&lt;/math&gt; and serves the purpose of stabilizing the problem&lt;ref name=Wah90 /&gt;&lt;ref name=GirPog90 /&gt; as well as of adding a trade-off between fitting and complexity of the estimator.&lt;ref name=Vap98 /&gt;  The weight &lt;math&gt;\lambda&lt;/math&gt;, called the ''regularizer'', determines the degree to which instability and complexity of the estimator should be penalized (higher penalty for increasing value of &lt;math&gt;\lambda&lt;/math&gt;).

===Derivation of the estimator===

The explicit form of the estimator in equation ({{EquationNote|1}}) is derived in two steps.  First, the representer theorem&lt;ref name=KimWha70&gt;{{cite journal|last=Kimeldorf|first=George S.|author2=Wahba, Grace|title=A correspondence between Bayesian estimation on stochastic processes and smoothing by splines|journal=The Annals of Mathematical Statistics|year=1970|volume=41|issue=2|pages=495–502|doi=10.1214/aoms/1177697089|doi-access=free}}&lt;/ref&gt;&lt;ref name=SchHerSmo01&gt;{{cite journal|last=Schölkopf|first=Bernhard|author2=Herbrich, Ralf |author3=Smola, Alex J. |title=A Generalized Representer Theorem|journal=COLT/EuroCOLT 2001, LNCS|year=2001|volume=2111/2001|pages=416–426|doi=10.1007/3-540-44581-1_27|series=Lecture Notes in Computer Science|isbn=978-3-540-42343-0}}&lt;/ref&gt;&lt;ref name=DevEtal04&gt;{{cite journal|last=De Vito|first=Ernesto|author2=Rosasco, Lorenzo |author3=Caponnetto, Andrea |author4=Piana, Michele |author5= Verri, Alessandro |title=Some Properties of Regularized Kernel Methods|journal=Journal of Machine Learning Research|date=October 2004|volume=5|pages=1363–1390}}&lt;/ref&gt; states that the minimizer of the functional ({{EquationNote|2}}) can always be written as a linear combination of the kernels centered at the training-set points,

{{NumBlk|::|&lt;math&gt;
\hat{f}(\mathbf{x}') = \sum_{i=1}^n c_i k(\mathbf{x}_i,\mathbf{x}') = \mathbf{k}^\top \mathbf{c},
&lt;/math&gt;|{{EquationRef|3}}}}

for some &lt;math&gt;\mathbf{c} \in \mathbb{R}^n&lt;/math&gt;.  The explicit form of the coefficients &lt;math&gt;\mathbf{c} = [c_1,\ldots,c_n]^\top&lt;/math&gt; can be found by substituting for &lt;math&gt;f(\cdot)&lt;/math&gt; in the functional ({{EquationNote|2}}).  For a function of the form in equation ({{EquationNote|3}}), we have that

:&lt;math&gt;\begin{align}
\|f\|_k^2 &amp; = \langle f,f \rangle_k, \\
&amp; = \left\langle \sum_{i=1}^N c_i k(\mathbf{x}_i,\cdot), \sum_{j=1}^N c_j k(\mathbf{x}_j,\cdot) \right\rangle_k, \\
&amp; = \sum_{i=1}^N \sum_{j=1}^N c_i c_j \langle k(\mathbf{x}_i,\cdot), k(\mathbf{x}_j,\cdot) \rangle_k, \\
&amp; = \sum_{i=1}^N \sum_{j=1}^N c_i c_j k(\mathbf{x}_i,\mathbf{x}_j), \\
&amp; = \mathbf{c}^\top \mathbf{K} \mathbf{c}.
\end{align}&lt;/math&gt;

We can rewrite the functional ({{EquationNote|2}}) as

:&lt;math&gt;
\frac{1}{n} \| \mathbf{y} - \mathbf{K} \mathbf{c} \|^2 + \lambda \mathbf{c}^\top \mathbf{K} \mathbf{c}.
&lt;/math&gt;

This functional is convex in &lt;math&gt;\mathbf{c}&lt;/math&gt; and therefore we can find its minimum by setting the gradient with respect to &lt;math&gt;\mathbf{c}&lt;/math&gt; to zero,

:&lt;math&gt;\begin{align}
-\frac{1}{n} \mathbf{K} (\mathbf{Y} - \mathbf{K} \mathbf{c}) + \lambda \mathbf{K} \mathbf{c} &amp; = 0, \\
(\mathbf{K} + \lambda n \mathbf{I}) \mathbf{c} &amp; = \mathbf{Y}, \\
\mathbf{c} &amp; = (\mathbf{K} + \lambda n \mathbf{I})^{-1} \mathbf{Y}.
\end{align}&lt;/math&gt;

Substituting this expression for the coefficients in equation ({{EquationNote|3}}), we obtain the estimator stated previously in equation ({{EquationNote|1}}),

:&lt;math&gt;
\hat{f}(\mathbf{x}') = \mathbf{k}^\top(\mathbf{K} + \lambda n \mathbf{I})^{-1} \mathbf{Y}.
&lt;/math&gt;

==A Bayesian perspective==

The notion of a kernel plays a crucial role in Bayesian probability as the covariance function of a stochastic process called the ''[[Gaussian process]]''.

===A review of Bayesian probability===

As part of the Bayesian framework, the Gaussian process specifies the [[Prior probability|''prior distribution'']] that describes the prior beliefs about the properties of the function being modeled.  These beliefs are updated after taking into account observational data by means of a ''[[likelihood function]]'' that relates the prior beliefs to the observations.  Taken together, the prior and likelihood lead to an updated distribution called the [[Posterior probability|''posterior distribution'']] that is customarily used for predicting test cases.

===The Gaussian process===

A [[Gaussian process]] (GP) is a stochastic process in which any finite number of random variables that are sampled follow a joint [[Multivariate normal distribution|Normal distribution]].&lt;ref name=RasWil06 /&gt;  The mean vector and covariance matrix of the Gaussian distribution completely specify the GP.  GPs are usually used as a priori distribution for functions, and as such the mean vector and covariance matrix can be viewed as functions, where the covariance function is also called the ''kernel'' of the GP.  Let a function &lt;math&gt;f&lt;/math&gt; follow a Gaussian process with mean function &lt;math&gt;m&lt;/math&gt; and kernel function &lt;math&gt;k&lt;/math&gt;,

:&lt;math&gt;
f \sim \mathcal{GP}(m,k).
&lt;/math&gt;

In terms of the underlying Gaussian distribution, we have that for any finite set &lt;math&gt;\mathbf{X} = \{\mathbf{x}_i\}_{i=1}^{n}&lt;/math&gt; if we let &lt;math&gt;f(\mathbf{X}) = [f(\mathbf{x}_1),\ldots,f(\mathbf{x}_n)]^\top&lt;/math&gt; then

:&lt;math&gt;
f(\mathbf{X}) \sim \mathcal{N}(\mathbf{m},\mathbf{K}),
&lt;/math&gt;

where &lt;math&gt;\mathbf{m} = m(\mathbf{X}) = [m(\mathbf{x}_1),\ldots,m(\mathbf{x}_N)]^\top&lt;/math&gt; is the mean vector and &lt;math&gt;\mathbf{K} = k(\mathbf{X},\mathbf{X})&lt;/math&gt; is the covariance matrix of the multivariate Gaussian distribution.

===Derivation of the estimator===
{{further|Minimum mean square error#Linear MMSE estimator for linear observation process}}
In a regression context, the likelihood function is usually assumed to be a Gaussian distribution and the observations to be independent and identically distributed (iid),

:&lt;math&gt;
p(y|f,\mathbf{x},\sigma^2) = \mathcal{N}(f(\mathbf{x}),\sigma^2).
&lt;/math&gt;

This assumption corresponds to the observations being corrupted with zero-mean Gaussian noise with variance &lt;math&gt;\sigma^2&lt;/math&gt;. The iid assumption makes it possible to factorize the likelihood function over the data points given the set of inputs &lt;math&gt;\mathbf{X}&lt;/math&gt; and the variance of the noise &lt;math&gt;\sigma^2&lt;/math&gt;, and thus the posterior distribution can be computed analytically. For a test input vector &lt;math&gt;\mathbf{x}'&lt;/math&gt;, given the training data &lt;math&gt;S = \{\mathbf{X},\mathbf{Y}\}&lt;/math&gt;, the posterior distribution is given by

:&lt;math&gt;
p(f(\mathbf{x}')|S,\mathbf{x}',\boldsymbol{\phi}) = \mathcal{N}(m(\mathbf{x}'),\sigma^2(\mathbf{x}')),
&lt;/math&gt;

where &lt;math&gt;\boldsymbol{\phi}&lt;/math&gt; denotes the set of parameters which include the variance of the noise &lt;math&gt;\sigma^2&lt;/math&gt; and any parameters from the covariance function &lt;math&gt;k&lt;/math&gt; and where

:&lt;math&gt;\begin{align}
m(\mathbf{x}') &amp; = \mathbf{k}^\top (\mathbf{K} + \sigma^2 \mathbf{I})^{-1} \mathbf{Y}, \\
\sigma^2(\mathbf{x}') &amp; = k(\mathbf{x}',\mathbf{x}') - \mathbf{k}^\top (\mathbf{K} + \sigma^2 \mathbf{I})^{-1} \mathbf{k}.
\end{align}&lt;/math&gt;

==The connection between regularization and Bayes==

A connection between regularization theory and Bayesian theory can only be achieved in the case of ''finite dimensional RKHS''. Under this assumption, regularization theory and Bayesian theory are connected through Gaussian process prediction.&lt;ref name=Wah90&gt;{{cite book|last=Wahba|first=Grace|title=Spline models for observational data|year=1990|publisher=SIAM}}&lt;/ref&gt;&lt;ref name=RasWil06&gt;{{cite book|last=Rasmussen|first=Carl Edward|title=Gaussian Processes for Machine Learning|year=2006|publisher=The MIT Press|isbn=0-262-18253-X|url=http://www.gaussianprocess.org/gpml/|author2=Williams, Christopher K. I.}}&lt;/ref&gt;

In the finite dimensional case, every RKHS can be described in terms of a feature map &lt;math&gt;\Phi : \mathcal{X} \rightarrow \mathbb{R}^p&lt;/math&gt; such that&lt;ref name=Vap98 /&gt;

:&lt;math&gt;
k(\mathbf{x},\mathbf{x}') = \sum_{i=1}^p \Phi^i(\mathbf{x})\Phi^i(\mathbf{x}').
&lt;/math&gt;

Functions in the RKHS with kernel &lt;math&gt;\mathbf{K}&lt;/math&gt; can be then be written as

:&lt;math&gt;
f_{\mathbf{w}}(\mathbf{x}) = \sum_{i=1}^p \mathbf{w}^i \Phi^i(\mathbf{x}) = \langle \mathbf{w},\Phi(\mathbf{x}) \rangle,
&lt;/math&gt;

and we also have that

:&lt;math&gt;
\|f_{\mathbf{w}} \|_k = \|\mathbf{w}\|.
&lt;/math&gt;

We can now build a Gaussian process by assuming &lt;math&gt; \mathbf{w} = [w^1,\ldots,w^p]^\top &lt;/math&gt; to be distributed according to a multivariate Gaussian distribution with zero mean and identity covariance matrix,

:&lt;math&gt;
\mathbf{w} \sim \mathcal{N}(0,\mathbf{I}) \propto \exp(-\|\mathbf{w}\|^2).
&lt;/math&gt;

If we assume a Gaussian likelihood we have

:&lt;math&gt;
P(\mathbf{Y}|\mathbf{X},f) = \mathcal{N}(f(\mathbf{X}),\sigma^2 \mathbf{I}) \propto \exp\left(-\frac{1}{\sigma^2} \| f_{\mathbf{w}}(\mathbf{X}) - \mathbf{Y} \|^2\right),
&lt;/math&gt;

where &lt;math&gt; f_{\mathbf{w}}(\mathbf{X}) = (\langle\mathbf{w},\Phi(\mathbf{x}_1)\rangle,\ldots,\langle\mathbf{w},\Phi(\mathbf{x}_n \rangle) &lt;/math&gt;. The resulting posterior distribution is the given by

:&lt;math&gt;
P(f|\mathbf{X},\mathbf{Y}) \propto \exp\left(-\frac{1}{\sigma^2} \|f_{\mathbf{w}}(\mathbf{X}) - \mathbf{Y}\|_n^2 + \|\mathbf{w}\|^2\right)
&lt;/math&gt;

We can see that a ''maximum posterior (MAP)'' estimate is equivalent to the minimization problem defining [[Tikhonov regularization]], where in the Bayesian case the regularization parameter is related to the noise variance.

From a philosophical perspective, the loss function in a regularization setting plays a different role than the likelihood function in the Bayesian setting. Whereas the loss function measures the error that is incurred when predicting &lt;math&gt;f(\mathbf{x})&lt;/math&gt; in place of &lt;math&gt;y&lt;/math&gt;, the likelihood function measures how likely the observations are from the model that was assumed to be true in the generative process. From a mathematical perspective, however, the formulations of the regularization and Bayesian frameworks make the loss function and the likelihood function to have the same mathematical role of promoting the inference of functions &lt;math&gt;f&lt;/math&gt; that approximate the labels &lt;math&gt;y&lt;/math&gt; as much as possible.

==See also==
* [[Regularized least squares]]
* [[Bayesian linear regression]]
* [[Tikhonov_regularization#Bayesian_interpretation|Bayesian interpretation of Tikhonov regularization]]

==References==
{{Reflist}}

[[Category:Bayesian statistics]]
[[Category:Machine learning]]</text>
      <sha1>iqt2cnuexmqkkw16xmlbgsxqc35ngp5</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Artificial intelligence conferences</title>
    <ns>14</ns>
    <id>12932492</id>
    <revision>
      <id>613183752</id>
      <parentid>609781290</parentid>
      <timestamp>2014-06-16T19:46:36Z</timestamp>
      <contributor>
        <username>Fayenatic london</username>
        <id>1639942</id>
      </contributor>
      <comment>CFD closed as no consensus, but remove journals</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="273" xml:space="preserve">[[Academic conference]]s related to [[artificial intelligence]], [[machine learning]] and [[pattern recognition]].

[[Category:Artificial intelligence|Conferences]]
[[Category:Machine learning|Conferences]]
[[Category:Data mining]]
[[Category:Computer science conferences]]</text>
      <sha1>hyprmos40ih781v7hwrk2zbzejuzrj2</sha1>
    </revision>
  </page>
  <page>
    <title>Machine Learning (journal)</title>
    <ns>0</ns>
    <id>5721403</id>
    <revision>
      <id>992590069</id>
      <parentid>950635434</parentid>
      <timestamp>2020-12-06T02:17:27Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 21 templates: del empty params (6×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="7085" xml:space="preserve">{{Infobox Journal
| title        = Machine Learning
| cover        = Machine Learning (journal).jpg
| discipline   = [[Machine learning]]
| abbreviation = Mach. Learn.
| website      = https://www.springer.com/west/home/computer/artificial?SGWID=4-147-70-35726603-0
| publisher    = [[Kluwer]]/[[Springer Science+Business Media|Springer]]
| country      = [[United States|USA]]
| history      = 1986 to present
| impact       = 2.809
| impact-year  = 2018
| ISSN         = 1573-0565
}}
'''''Machine Learning'''''  is a [[peer-review]]ed [[scientific journal]], published since 1986.
It should be distinguished from the journal ''Machine intelligence'' which was established in the mid-1960s.&lt;ref&gt;E.g.: {{cite journal | author=John Alan Robinson | title=Computational Logic: The Unification Computation | journal=Machine Intelligence | volume=6 | pages=63–72 | year=1971 }}&lt;BR&gt;vs.: {{cite journal | url=https://link.springer.com/content/pdf/10.1007/BF00058753.pdf | author=Robert C. Berwick and Samuel F. Pilato | title=Learning Syntax by Automata Induction | journal=Machine Learning | volume=2 | number=1 | pages=9–38 | year=1987 | doi=10.1007/BF00058753 }}&lt;/ref&gt; 

In 2001, forty editors and members of the [[editorial board]] of ''Machine Learning'' resigned in order to support the ''[[Journal of Machine Learning Research]]'' (JMLR), saying that in the era of the [[internet]], it was detrimental for researchers to continue publishing their papers in expensive journals with pay-access archives. Instead, they wrote, they supported the model of ''JMLR'', in which authors retained copyright over their papers and archives were freely available on the internet.&lt;ref&gt;{{cite journal | title = Editorial Board of the Kluwer Journal, Machine Learning: Resignation Letter | journal = SIGIR Forum | volume = 35 | issue = 2 | year = 2001 | url = http://sigir.org/files/forum/F2001/sigirFall01Letters.html}}&lt;/ref&gt;

Following the mass resignation, [[Kluwer]] changed their publishing policy to allow authors to self-archive their papers online after [[peer-review]].&lt;ref&gt;{{cite journal|last1=Robin|first1=Peek|title=Machine Learning's Editorial Board Divided|journal=Information Today|date=1 December 2001|volume=18|issue=11|url=https://www.questia.com/magazine/1P3-95801675/machine-learning-s-editorial-board-divided|language=en}}&lt;/ref&gt;

== Selected articles ==
* {{cite journal | author=J.R. Quinlan | title=Induction of Decision Trees | journal=Machine Learning | volume= 1| pages=81–106 | year=1986 | doi=10.1007/BF00116251 | doi-access=free }} 
* {{cite journal | author=Nick Littlestone | title=Learning Quickly When Irrelevant Attributes Abound: A New Linear-threshold Algorithm | journal=Machine Learning | volume=2 | issue=4 | pages=285–318 | year=1988 | doi=10.1007/BF00116827 | url=http://www.cs.utsa.edu/~bylander/cs6243/littlestone1988.pdf }} 
* {{cite journal | author=Robert E. Schapire | title=The Strength of Weak Learnability | journal=Machine Learning | volume=5 | issue=2 | pages=197–227 | year=1990 | doi=10.1007/BF00116037 | url=http://www.cs.princeton.edu/~schapire/papers/strengthofweak.pdf | access-date=2020-02-22 | archive-url=https://web.archive.org/web/20121010030839/http://www.cs.princeton.edu/~schapire/papers/strengthofweak.pdf | archive-date=2012-10-10 | url-status=dead }} 
* {{cite journal | author=J. Quinlan | title=Learning Logical Descriptions from Relations | journal=Machine Learning | volume=5 | number=3 | pages=239–266 | year=1990 | doi=10.1007/BF00117105 | url=http://www.cs.utsa.edu/~bylander/cs6243/quinlan1990foil.pdf }} 
* {{cite journal | author=John R. Anderson and Michael Matessa | title=Explorations of an Incremental, Bayesian Algorithm for Categorization | journal=Machine Learning | volume=9 | issue=4 | pages=275–308 | year=1992 | doi=10.1007/BF00994109 | doi-access=free }}
* {{cite journal | author=David Klahr | title=Children, Adults, and Machines as Discovery Systems | journal=Machine Learning | volume=14 | issue=3 | pages=313–320 | year=1994 | doi=10.1007/BF00993981 | doi-access=free }} 
* {{cite journal | author=Thomas Dean and Dana Angluin and Kenneth Basye and Sean Engelson and Leslie Kaelbling and Evangelos Kokkevis and Oded Maron | title=Inferring Finite Automata with Stochastic Output Functions and an Application to Map Learning | journal=Machine Learning | volume=18 | pages=81–108 | year=1995 | doi=10.1007/BF00993822 | doi-access=free }}
* {{cite journal | author=Luc De Raedt and Luc Dehaspe | title=Clausal Discovery | journal=Machine Learning | volume=26 | issue=2/3 | pages=99–146 | year=1997 | doi=10.1023/A:1007361123060 | doi-access=free }} 
* {{cite journal | author=C. de la Higuera | title=Characteristic Sets for Grammatical Inference | journal=Machine Learning | volume=27 | pages=1–14 | year=1997 }} 
* {{cite journal | author=Robert E. Schapire and Yoram Singer | title=Improved Boosting Algorithms Using Confidence-rated Predictions | journal=Machine Learning | volume=37 | issue=3 | pages=297–336 | year=1999 | doi=10.1023/A:1007614523901 | doi-access=free }} 
* {{cite journal | author=Robert E. Schapire and Yoram Singer | title=BoosTexter: A Boosting-based System for Text Categorization | journal=Machine Learning | volume=39 | issue=2/3 | pages=135–168 | year=2000 | doi=10.1023/A:1007649029923 | doi-access=free }} 
* {{cite journal | author=P. Rossmanith and T. Zeugmann | title=Stochastic Finite Learning of the Pattern Languages | journal=Machine Learning | volume=44 | number=1–2 | pages=67–91 | year=2001 | doi=10.1023/A:1010875913047 | doi-access=free }} 
* {{Cite journal|last=Parekh|first=Rajesh|last2=Honavar|first2=Vasant|date=2001|title=Learning DFA from Simple Examples|journal=Machine Learning|volume=44|issue=1/2|pages=9–35|doi=10.1023/A:1010822518073|doi-access=free}}
* {{cite journal | author=Ayhan Demiriz and Kristin P. Bennett and John Shawe-Taylor | title=Linear Programming Boosting via Column Generation | journal=Machine Learning | volume=46 | pages=225–254 | year=2002 | doi=10.1023/A:1012470815092 | doi-access=free }}
* {{cite journal | author=Simon Colton and Stephen Muggleton | title=Mathematical Applications of Inductive Logic Programming | journal=Machine Learning | volume=64 | issue=1–3 | pages=25–64 | year=2006 | doi=10.1007/s10994-006-8259-x | url=http://www.doc.ic.ac.uk/crg/papers/colton_mlj06.pdf }} 
* {{cite journal | author=Will Bridewell and Pat Langley and Ljupco Todorovski and Saso Dzeroski | title=Inductive Process Modeling | journal=Machine Learning | year=2008 }} 
* {{cite journal | author=Stephen Muggleton and Alireza Tamaddoni-Nezhad | title=QG/GA: a stochastic search for Progol | journal=Machine Learning | volume=70 | issue=2–3 | pages=121–133 | year=2008 | doi=10.1007/s10994-007-5029-3 | doi-access=free }}

== References ==
{{reflist}}

[[Category:Computer science journals]]
[[Category:Machine learning]]
[[Category:Delayed open access journals]]
[[Category:Springer Science+Business Media academic journals]]
[[Category:Publications established in 1986]]


{{compu-journal-stub}}</text>
      <sha1>37svbc0vgsm9nx7tumc11jkbh65e0cz</sha1>
    </revision>
  </page>
  <page>
    <title>Journal of Machine Learning Research</title>
    <ns>0</ns>
    <id>5721283</id>
    <revision>
      <id>1001228878</id>
      <parentid>999185149</parentid>
      <timestamp>2021-01-18T20:14:51Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 4 templates: hyphenate params (3×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3571" xml:space="preserve">{{Infobox journal
| cover =
| discipline = [[Machine learning]]
| editor = Francis Bach, David Blei, [[Bernhard Schölkopf]]
| abbreviation = J. Mach. Learn. Res.
| publisher = JMLR, Inc. and Microtome Publishing
| country = United States
| history = 2000–present
| license =
| openaccess = Yes
| impact = 4.091
| impact-year = 2018
| website = https://dl.acm.org/journal/jmlr
| link2 = https://dl.acm.org/journal/jmlr
| link2-name = Online archive
| ISSN = 1532-4435
| eISSN = 1533-7928
| OCLC = 712803341
| CODEN = JMLRAJ
| LCCN = 00212568
}}
The '''''Journal of Machine Learning Research''''' is a [[peer-reviewed]] [[open access]] [[scientific journal]] covering [[machine learning]]. It was established in 2000 and the first editor-in-chief was [[Leslie Kaelbling]].&lt;ref name="effjour"&gt;{{cite web |last1=Shieber |first1=Stuart |title=An efficient journal |url=https://blogs.harvard.edu/pamphlet/2012/03/06/an-efficient-journal/ |website=The Occasional Pamphlet |access-date=12 February 2017 |date=6 March 2012}}&lt;/ref&gt; The current [[editors-in-chief]] are Francis Bach ([[Inria]]), David Blei ([[Columbia University]]) and [[Bernhard Schölkopf]] ([[Max Planck Institute for Intelligent Systems]]).

== History ==
The journal was established as an open-access alternative to the journal [[Machine Learning (journal)|''Machine Learning'']]. In 2001, forty [[editorial board]] members of ''Machine Learning'' resigned, saying that in the era of the [[Internet]], it was detrimental for researchers to continue publishing their papers in expensive journals with pay-access archives. The open access model employed by the ''Journal of Machine Learning Research'' allows authors to publish articles for free and retain copyright, while archives are freely available online.&lt;ref&gt;{{cite journal |title=Editorial Board of the Kluwer Journal, Machine Learning: Resignation Letter |journal=SIGIR Forum |volume=35 |issue=2 |year=2001 |url=http://sigir.org/files/forum/F2001/sigirFall01Letters.html}}&lt;/ref&gt;

Print editions of the journal were published by [[MIT Press]] until 2004 and by Microtome Publishing thereafter. From its inception, the journal received no revenue from the print edition and paid no subvention to MIT Press or Microtome Publishing.&lt;ref name="effjour"/&gt;

In response to the prohibitive costs of arranging workshop and conference [[proceedings]] publication with traditional [[academic publishing]] companies, the journal launched a proceedings publication arm in 2007&lt;ref&gt;{{cite web |last1=Lawrence |first1=Neil |title=Proceedings of Machine Learning Research |url=http://inverseprobability.com/2015/03/30/proceedings-of-machine-learning-research |website=Inverseprobability |access-date=12 February 2017 |date=30 March 2015}}&lt;/ref&gt; and now publishes proceedings for several leading machine learning [[academic conference|conferences]], including the [[International Conference on Machine Learning]], [[Conference On Learning Theory|COLT]], [[AISTATS]], and  workshops held at the [[Conference on Neural Information Processing Systems]].

==Further reading==
*{{cite web |title=Top journals in computer science |date=14 May 2009 |work=[[Times Higher Education]] |access-date=22 August 2009 |url=http://www.timeshighereducation.co.uk/story.asp?sectioncode=26&amp;storycode=406557}}

==References==
{{reflist}}

==External links==
*{{Official website|https://dl.acm.org/journal/jmlr}}

[[Category:Computer science journals]]
[[Category:Open access journals]]
[[Category:Machine learning]]
[[Category:Publications established in 2000]]


{{compu-journal-stub}}</text>
      <sha1>b5mj5b14my0hs2cklndlp0uvr99hcab</sha1>
    </revision>
  </page>
  <page>
    <title>AIXI</title>
    <ns>0</ns>
    <id>30511763</id>
    <revision>
      <id>985777861</id>
      <parentid>977671851</parentid>
      <timestamp>2020-10-27T22:05:46Z</timestamp>
      <contributor>
        <username>Trappist the monk</username>
        <id>10289486</id>
      </contributor>
      <minor/>
      <comment>/* top */fix / remove deprecated parameters;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="13120" xml:space="preserve">'''AIXI''' {{IPA-all|'ai̯k͡siː|}} is a theoretical [[Mathematical logic#Formal logical systems|mathematical formalism]] for [[artificial general intelligence]].
It combines [[Solomonoff induction]] with [[Decision theory|sequential decision theory]].
AIXI was first proposed by [[Marcus Hutter]] in 2000&lt;ref&gt;{{cite book |author=Marcus Hutter |title=A Theory of Universal Artificial Intelligence based on Algorithmic Complexity |url=https://archive.org/details/arxiv-cs0004001 |arxiv=cs.AI/0004001 |year=2000 |bibcode=2000cs........4001H }}&lt;/ref&gt; and several results regarding AIXI are proved in Hutter's 2005 book ''Universal Artificial Intelligence''.&lt;ref name="uaibook"&gt;{{cite book |author=Marcus Hutter |title=Universal Artificial Intelligence: Sequential Decisions Based on Algorithmic Probability |series=Texts in Theoretical Computer Science an EATCS Series |url=https://books.google.com/books?id=NP53iZGt4KUC |year=2004 |publisher=Springer |isbn=978-3-540-22139-5 |doi=10.1007/b138233 |ref=harv |author-mask=1}}&lt;/ref&gt;

AIXI is a [[Reinforcement learning|reinforcement learning agent]]. It maximizes the expected total rewards received from the environment. Intuitively, it simultaneously considers every computable hypothesis (or environment). In each time step, it looks at every possible program and evaluates how many rewards that program generates depending on the next action taken. The promised rewards are then weighted by the [[Subjective logic|subjective belief]] that this program constitutes the true environment. This belief is computed from the length of the program: longer programs are considered less likely, in line with [[Occam's razor]]. AIXI then selects the action that has the highest expected total reward in the weighted sum of all these programs.

== Definition ==

AIXI is a reinforcement learning agent that interacts with some stochastic and unknown but computable environment &lt;math&gt;\mu&lt;/math&gt;. The interaction proceeds in time steps, from &lt;math&gt;t=1&lt;/math&gt; to &lt;math&gt;t=m&lt;/math&gt;, where &lt;math&gt;m \in \mathbb{N}&lt;/math&gt; is the lifespan of the AIXI agent. At time step ''t'', the agent chooses an action &lt;math&gt;a_t \in \mathcal{A}&lt;/math&gt; (e.g. a limb movement) and executes it in the environment, and the environment responds with a "percept" &lt;math&gt;e_t \in \mathcal{E} = \mathcal{O} \times \mathbb{R}&lt;/math&gt;, which consists of an "observation" &lt;math&gt;o_t \in \mathcal{O}&lt;/math&gt; (e.g., a camera image) and a reward &lt;math&gt;r_t \in \mathbb{R}&lt;/math&gt;, distributed according to the [[conditional probability]] &lt;math&gt;\mu(o_t r_t | a_1 o_1 r_1 ... a_{t-1} o_{t-1} r_{t-1} a_t)&lt;/math&gt;, where &lt;math&gt;a_1 o_1 r_1 ... a_{t-1} o_{t-1} r_{t-1} a_t&lt;/math&gt; is the "history" of actions, observations and rewards. The environment &lt;math&gt;\mu&lt;/math&gt; is thus mathematically represented as a [[probability distribution]] over "percepts" (observations and rewards) which depend on the ''full'' history, so there is no [[Markov property|Markov assumption]] (as opposed to other RL algorithms). Note again that this probability distribution is ''unknown'' to the AIXI agent. Furthermore, note again that &lt;math&gt;\mu&lt;/math&gt; is computable, that is, the observations and rewards received by the agent from the environment &lt;math&gt;\mu&lt;/math&gt; can be computed by some program (which runs on a [[Turing machine]]), given the past actions of the AIXI agent.&lt;ref name=veness2009&gt;{{cite arXiv |last1=Veness |first1=Joel |author2=Kee Siong Ng |last3=Hutter |first3=Marcus |last4=Uther |first4=William  |last5=Silver |first5=David   |eprint=0909.0801 |title=A Monte Carlo AIXI Approximation |year=2009 |class=cs.AI}}&lt;/ref&gt;

The ''only'' goal of the AIXI agent is to maximise &lt;math&gt;\sum_{t=1}^m r_t&lt;/math&gt;, that is, the sum of rewards from time step 1 to m.

The AIXI agent is associated with a stochastic policy &lt;math&gt;\pi : (\mathcal{A} \times \mathcal{E})^* \rightarrow \mathcal{A}&lt;/math&gt;, which is the function it uses to choose actions at every time step, where &lt;math&gt;\mathcal{A}&lt;/math&gt; is the space of all possible actions that AIXI can take and &lt;math&gt;\mathcal{E}&lt;/math&gt; is the space of all possible "percepts" that can be produced by the environment. The environment (or probability distribution) &lt;math&gt;\mu&lt;/math&gt; can also be thought of as a stochastic policy (which is a function): &lt;math&gt;\mu  : (\mathcal{A} \times \mathcal{E})^* \times \mathcal{A} \rightarrow \mathcal{E} &lt;/math&gt;, where the &lt;math&gt;*&lt;/math&gt; is the [[Kleene star]] operation.

In general, at time step &lt;math&gt;t&lt;/math&gt; (which ranges from 1 to m), AIXI, having previously executed actions &lt;math&gt;a_1\dots a_{t-1}&lt;/math&gt; (which is often abbreviated in the literature as &lt;math&gt;a_{&lt;t}&lt;/math&gt;) and having observed the history of percepts &lt;math&gt;o_1 r_1 ... o_{t-1} r_{t-1}&lt;/math&gt; (which can be abbreviated as &lt;math&gt;e_{&lt;t}&lt;/math&gt;), chooses and executes in the environment the action, &lt;math&gt;a_t&lt;/math&gt;, defined as follows &lt;ref&gt;[http://hutter1.net/ai/uaibook.htm Universal Artificial Intelligence&lt;!-- Bot generated title --&gt;]&lt;/ref&gt;

:&lt;math&gt;
a_t := \arg \max_{a_t} \sum_{o_t r_t} \ldots \max_{a_m} \sum_{o_m r_m} [r_t + \ldots + r_m] \sum_{q:\; U(q, a_1 \ldots a_m) = o_1 r_1 \ldots o_m r_m} 2^{-\textrm{length}(q)} 
&lt;/math&gt;

or, using parentheses, to disambiguate the precedences

:&lt;math&gt;
a_t :=  \arg \max_{a_t} \left( \sum_{o_t r_t} \ldots \left( \max_{a_m} \sum_{o_m r_m} [r_t + \ldots + r_m] \left( \sum_{q:\; U(q, a_1 \ldots a_m) = o_1 r_1 \ldots o_m r_m} 2^{-\textrm{length}(q)} \right) \right) \right)
&lt;/math&gt;

Intuitively, in the definition above, AIXI considers the sum of the total reward over all possible "futures" up to &lt;math&gt;m - t&lt;/math&gt; time steps ahead (that is, from &lt;math&gt;t&lt;/math&gt; to &lt;math&gt;m&lt;/math&gt;), weighs each of them by the complexity of programs &lt;math&gt;q&lt;/math&gt; (that is, by &lt;math&gt;2^{-\textrm{length}(q)}&lt;/math&gt;) consistent with the agent's past (that is, the previously executed actions, &lt;math&gt;a_{&lt;t}&lt;/math&gt;, and received percepts, &lt;math&gt;e_{&lt;t}&lt;/math&gt;) that can generate that future, and then picks the action that maximises expected future rewards.&lt;ref name=veness2009 /&gt;

Let us break this definition down in order to attempt to fully understand it.

&lt;math&gt;o_t r_t&lt;/math&gt; is the "percept" (which consists of the observation &lt;math&gt;o_t&lt;/math&gt; and reward &lt;math&gt;r_t&lt;/math&gt;) received by the AIXI agent at time step &lt;math&gt;t&lt;/math&gt; from the environment (which is unknown and stochastic). Similarly, &lt;math&gt;o_m r_m&lt;/math&gt; is the percept received by AIXI at time step &lt;math&gt;m&lt;/math&gt; (the last time step where AIXI is active).

&lt;math&gt;r_t + \ldots + r_m&lt;/math&gt; is the sum of rewards from time step &lt;math&gt;t&lt;/math&gt; to time step &lt;math&gt;m&lt;/math&gt;, so AIXI needs to look into the future to choose its action at time step &lt;math&gt;t&lt;/math&gt;.

&lt;math&gt;U&lt;/math&gt; denotes a [[monotone class theorem|monotone]] [[universal Turing machine]], and &lt;math&gt;q&lt;/math&gt; ranges over all (deterministic) programs on the universal machine &lt;math&gt;U&lt;/math&gt;, which receives as input the program &lt;math&gt;q&lt;/math&gt; and the sequence of actions &lt;math&gt;a_1\dots a_m&lt;/math&gt; (that is, all actions), and produces the sequence of percepts &lt;math&gt;o_1 r_1 \ldots o_m r_m&lt;/math&gt;. The universal Turing machine &lt;math&gt;U&lt;/math&gt; is thus used to "simulate" or compute the environment responses or percepts, given the program &lt;math&gt;q&lt;/math&gt; (which "models" the environment) and all actions of the AIXI agent: in this sense, the environment is "computable" (as stated above). Note that, in general, the program which "models" the ''current'' and actual environment (where AIXI needs to act) is unknown because the current environment is also unknown. 

&lt;math&gt;\textrm{length}(q)&lt;/math&gt; is the length of the program &lt;math&gt;q&lt;/math&gt; (which is encoded as a string of bits). Note that &lt;math&gt;2^{-\textrm{length}(q)} = \frac{1}{2^{\textrm{length}(q)}}&lt;/math&gt;. Hence, in the definition above, &lt;math&gt;\sum_{q:\; U(q, a_1 \ldots a_m) = o_1 r_1 \ldots o_m r_m} 2^{-\textrm{length}(q)}&lt;/math&gt; should be interpreted as a [[Mixture (probability)|mixture]] (in this case, a sum) over all computable environments (which are consistent with the agent's past), each weighted by its complexity &lt;math&gt;2^{-\textrm{length}(q)}&lt;/math&gt;. Note that &lt;math&gt;a_1 \ldots a_m&lt;/math&gt; can also be written as &lt;math&gt;a_1 \ldots a_{t-1}a_t \ldots a_m&lt;/math&gt;, and &lt;math&gt;a_1 \ldots a_{t-1} = a_{&lt;t}&lt;/math&gt; is the sequence of actions already executed in the environment by the AIXI agent. Similarly, &lt;math&gt;o_1 r_1 \ldots o_m r_m = o_1 r_1 \ldots o_{t-1} r_{t-1}o_{t} r_{t} \ldots o_m r_m&lt;/math&gt;, and &lt;math&gt;o_1 r_1 \ldots o_{t-1} r_{t-1}&lt;/math&gt; is the sequence of percepts produced by the environment so far.

Let us now put all these components together in order to understand this equation or definition.

At time step t, AIXI chooses the action &lt;math&gt;a_t&lt;/math&gt; where the function &lt;math&gt;\sum_{o_t r_t} \ldots \max_{a_m} \sum_{o_m r_m} [r_t + \ldots + r_m] \sum_{q:\; U(q, a_1 \ldots a_m) = o_1 r_1 \ldots o_m r_m} 2^{-\textrm{length}(q)}&lt;/math&gt; attains its maximum. 

{{Missing information|description of the selection of actions|date=February 2019}}

=== Parameters ===

The parameters to AIXI are the universal Turing machine ''U'' and the agent's lifetime ''m'', which need to be chosen. The latter parameter can be removed by the use of [[discounting]].

== The meaning of the word AIXI ==

According to Hutter, the word "AIXI" can have several interpretations. AIXI can stand for AI based on Solomonoff's distribution, denoted by &lt;math&gt;\xi&lt;/math&gt; (which is the Greek letter xi), or e.g. it can stand for AI "crossed" (X) with induction (I). There are other interpretations.

== Optimality ==

AIXI's performance is measured by the expected total number of rewards it receives.
AIXI has been proven to be optimal in the following ways.&lt;ref name="uaibook" /&gt;

* [[Pareto optimality]]: there is no other agent that performs at least as well as AIXI in all environments while performing strictly better in at least one environment.{{citation needed|date=June 2014}}
* Balanced Pareto optimality: Like Pareto optimality, but considering a weighted sum of environments.
* Self-optimizing: a policy ''p'' is called self-optimizing for an environment &lt;math&gt;\mu&lt;/math&gt; if the performance of ''p'' approaches the theoretical maximum for &lt;math&gt;\mu&lt;/math&gt; when the length of the agent's lifetime (not time) goes to infinity. For environment classes where self-optimizing policies exist, AIXI is self-optimizing.

It was later shown by Hutter and Jan Leike that balanced Pareto optimality is subjective and that any policy can be considered Pareto optimal, which they describe as undermining all previous optimality claims for AIXI.&lt;ref&gt;{{cite conference|conference=Proceedings of the 28th Conference on Learning Theory|last1=Leike|first1=Jan|last2=Hutter|first2=Marcus|title=Bad Universal Priors and Notions of Optimality|date=2015|url=http://proceedings.mlr.press/v40/Leike15.pdf}}&lt;/ref&gt;

However, AIXI does have limitations. It is restricted to maximizing rewards based on percepts as opposed to external states. It also assumes it interacts with the environment solely through action and percept channels, preventing it from considering the possibility of being damaged or modified. Colloquially, this means that it doesn't consider itself to be contained by the environment it interacts with. It also assumes the environment is computable.&lt;ref&gt;{{cite web|last1=Soares|first1=Nate|title=Formalizing Two Problems of Realistic World-Models|url=https://intelligence.org/files/RealisticWorldModels.pdf|website=Intelligence.org|accessdate=2015-07-19|ref=MIRI}}&lt;/ref&gt; Since AIXI is incomputable (see below), it assigns zero probability to its own existence{{citation needed|date=October 2017}}.

== Computational aspects ==

Like [[Solomonoff induction]], AIXI is [[Undecidable problem|incomputable]]. However, there are computable approximations of it. One such approximation is AIXI''tl'', which performs at least as well as the provably best time ''t'' and space ''l'' limited agent.&lt;ref name="uaibook" /&gt; Another approximation to AIXI with a restricted environment class is MC-AIXI (FAC-CTW) (which stands for [[Monte Carlo method|Monte Carlo]] AIXI FAC-[[Context tree weighting|Context-Tree Weighting]]), which has had some success playing simple games such as [[Partially observable system|partially observable]] [[Pac-Man]].&lt;ref name=veness2009&gt;{{cite arXiv |last1=Veness |first1=Joel |author2=Kee Siong Ng |last3=Hutter |first3=Marcus |last4=Uther |first4=William  |last5=Silver |first5=David   |eprint=0909.0801 |title=A Monte Carlo AIXI Approximation |year=2009 |class=cs.AI}}&lt;/ref&gt;&lt;ref&gt;[https://www.youtube.com/watch?v=yfsMHtmGDKE Playing Pacman using AIXI Approximation - YouTube&lt;!-- Bot generated title --&gt;]&lt;/ref&gt;

== See also ==
* [[Gödel machine]]

== References ==

{{reflist}}
* "Universal Algorithmic Intelligence: A mathematical top-&gt;down approach", Marcus Hutter, {{arXiv|cs/0701125}}; also in ''Artificial General Intelligence'', eds. B. Goertzel and C. Pennachin, Springer, 2007, {{ISBN|9783540237334}}, pp.&amp;nbsp;227–290, {{doi|10.1007/978-3-540-68677-4_8}}.

[[Category:Optimal decisions]]
[[Category:Decision theory]]
[[Category:Machine learning]]</text>
      <sha1>e7zchbkrq3qaq0ztx50mys8o1bzphvu</sha1>
    </revision>
  </page>
  <page>
    <title>Sample complexity</title>
    <ns>0</ns>
    <id>43269516</id>
    <revision>
      <id>986452727</id>
      <parentid>959360173</parentid>
      <timestamp>2020-10-31T23:31:49Z</timestamp>
      <contributor>
        <username>JustSomeName</username>
        <id>40478839</id>
      </contributor>
      <minor/>
      <comment>fixed references</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="14151" xml:space="preserve">{{Machine learning bar}}
The '''sample complexity''' of a [[machine learning]] algorithm represents the number of training-samples that it needs in order to successfully learn a target function.

More precisely, the sample complexity is the number of training-samples that we need to supply to the algorithm, so that the function returned by the algorithm is within an arbitrarily small error of the best possible function, with probability arbitrarily close to 1.

There are two variants of sample complexity:
* The weak variant fixes a particular input-output distribution;
* The strong variant takes the worst-case sample complexity over all input-output distributions.

The No Free Lunch theorem, discussed below, proves that, in general, the strong sample complexity is infinite, i.e. that there is no algorithm that can learn the globally-optimal target function using a finite number of training samples.

However, if we are only interested in a particular class of target functions (e.g, only linear functions) then the sample complexity is finite, and it depends linearly on the [[VC dimension]] on the class of target functions.&lt;ref name=":0" /&gt;

==Definition==
Let &lt;math&gt;X&lt;/math&gt; be a space which we call the input space, and &lt;math&gt;Y&lt;/math&gt; be a space which we call the output space, and let &lt;math&gt;Z&lt;/math&gt; denote the product &lt;math&gt;X\times Y&lt;/math&gt;. For example, in the setting of binary classification, &lt;math&gt;X&lt;/math&gt; is typically a finite-dimensional vector space and &lt;math&gt;Y&lt;/math&gt; is the set &lt;math&gt;\{-1,1\}&lt;/math&gt;.

Fix a hypothesis space &lt;math&gt;\mathcal H&lt;/math&gt; of functions &lt;math&gt;h\colon X\to Y&lt;/math&gt;. A learning algorithm over &lt;math&gt;\mathcal H&lt;/math&gt; is a computable map from &lt;math&gt;Z^*&lt;/math&gt; to &lt;math&gt;\mathcal H&lt;/math&gt;. In other words, it is an algorithm that takes as input a finite sequence of training samples and outputs a function from &lt;math&gt;X&lt;/math&gt; to &lt;math&gt;Y&lt;/math&gt;. Typical learning algorithms include [[empirical risk minimization]], without or with [[Tikhonov regularization]].

Fix a loss function &lt;math&gt;\mathcal{L}\colon Y\times Y\to\R_{\geq 0}&lt;/math&gt;, for example, the square loss &lt;math&gt;\mathcal{L}(y, y') = (y - y')^2&lt;/math&gt;, where &lt;math&gt;h(x) = y'&lt;/math&gt;. For a given distribution &lt;math&gt;\rho&lt;/math&gt; on &lt;math&gt;X\times Y&lt;/math&gt;, the '''expected risk''' of a hypothesis (a function) &lt;math&gt;h\in\mathcal H&lt;/math&gt; is

:&lt;math&gt;\mathcal E(h) :=\mathbb E_\rho[\mathcal{L}(h(x),y)]=\int_{X\times Y} \mathcal{L}(h(x),y)\,d\rho(x,y)&lt;/math&gt;

In our setting, we have &lt;math&gt;h=\mathcal{A}(S_n)&lt;/math&gt;, where &lt;math&gt;\mathcal{A}&lt;/math&gt; is a learning algorithm and &lt;math&gt;S_n = ((x_1,y_1),\ldots,(x_n,y_n))\sim \rho^n&lt;/math&gt; is a sequence of vectors which are all drawn independently from &lt;math&gt;\rho&lt;/math&gt;. Define the optimal risk&lt;math display="block"&gt; 
\mathcal E^*_\mathcal{H} = \underset{h \in \mathcal H}{\inf}\mathcal E(h).
&lt;/math&gt;Set &lt;math&gt;h_n=\mathcal{A}(S_n)&lt;/math&gt;, for each &lt;math&gt;n&lt;/math&gt;. Note that &lt;math&gt;h_n&lt;/math&gt; is a [[random variable]] and depends on the random variable &lt;math&gt;S_n&lt;/math&gt;, which is drawn from the distribution &lt;math&gt;\rho^n&lt;/math&gt;. The algorithm &lt;math&gt;\mathcal{A}&lt;/math&gt; is called '''consistent''' if &lt;math&gt; \mathcal E(h_n) &lt;/math&gt; probabilistically converges to &lt;math&gt; \mathcal E_\mathcal H^*&lt;/math&gt;. In other words, for all &lt;math&gt;\epsilon, \delta &gt; 0&lt;/math&gt;, there exists a positive integer &lt;math&gt;N&lt;/math&gt;, such that, for all &lt;math&gt;n \geq N&lt;/math&gt;, we have

&lt;math display="block"&gt; 
\Pr_{\rho^n}[\mathcal E(h_n) - \mathcal E^*_\mathcal{H}\geq\varepsilon]&lt;\delta.
&lt;/math&gt;
The '''sample complexity''' of &lt;math&gt;\mathcal{A}&lt;/math&gt; is then the minimum &lt;math&gt;N&lt;/math&gt; for which this holds, as a function of &lt;math&gt;\rho, \epsilon&lt;/math&gt;, and &lt;math&gt;\delta&lt;/math&gt;. We write the sample complexity as &lt;math&gt;N(\rho, \epsilon, \delta)&lt;/math&gt; to emphasize that this value of &lt;math&gt;N&lt;/math&gt; depends on &lt;math&gt;\rho, \epsilon&lt;/math&gt;, and &lt;math&gt;\delta&lt;/math&gt;. If &lt;math&gt;\mathcal{A}&lt;/math&gt; is '''not consistent''', then we set &lt;math&gt;N(\rho,\epsilon,\delta)=\infty&lt;/math&gt;. If there exists an algorithm for which &lt;math&gt;N(\rho,\epsilon,\delta)&lt;/math&gt; is finite, then we say that the hypothesis space &lt;math&gt; \mathcal H&lt;/math&gt; is '''learnable'''.

In others words, the sample complexity &lt;math&gt;N(\rho,\epsilon,\delta)&lt;/math&gt; defines the rate of consistency of the algorithm: given a desired accuracy &lt;math&gt;\epsilon&lt;/math&gt; and confidence &lt;math&gt;\delta&lt;/math&gt;, one needs to sample &lt;math&gt;N(\rho,\epsilon,\delta)&lt;/math&gt; data points to guarantee that the risk of the output function is within &lt;math&gt;\epsilon&lt;/math&gt; of the best possible, with probability at least &lt;math&gt;1 - \delta&lt;/math&gt; .&lt;ref name="Rosasco"&gt;{{citation |last = Rosasco | first = Lorenzo | title = Consistency, Learnability, and Regularization | series = Lecture Notes for MIT Course 9.520. | year = 2014 }}&lt;/ref&gt;

In [[Probably approximately correct learning|probably approximately correct (PAC) learning]], one is concerned with whether the sample complexity is ''polynomial'', that is, whether &lt;math&gt;N(\rho,\epsilon,\delta)&lt;/math&gt; is bounded by a polynomial in &lt;math&gt;1/\epsilon&lt;/math&gt; and &lt;math&gt;1/\delta&lt;/math&gt;. If &lt;math&gt;N(\rho,\epsilon,\delta)&lt;/math&gt; is polynomial for some learning algorithm, then one says that the hypothesis space  &lt;math&gt; \mathcal H &lt;/math&gt; is '''PAC-learnable'''. Note that this is a stronger notion than being learnable.

==Unrestricted hypothesis space: infinite sample complexity==
&lt;span id='No Free Lunch Theorem'&gt;&lt;/span&gt;
One can ask whether there exists a learning algorithm so that the sample complexity is finite in the strong sense, that is, there is a bound on the number of samples needed so that the algorithm can learn any distribution over the input-output space with a specified target error. More formally, one asks whether there exists a learning algorithm &lt;math&gt;\mathcal{A}&lt;/math&gt;, such that, for all &lt;math&gt;\epsilon, \delta &gt; 0&lt;/math&gt;, there exists a positive integer &lt;math&gt;N&lt;/math&gt; such that for all &lt;math&gt;n \geq N&lt;/math&gt;, we have

&lt;math display="block"&gt; 
\sup_\rho\left(\Pr_{\rho^n}[\mathcal E(h_n) - \mathcal E^*_\mathcal{H}\geq\varepsilon]\right)&lt;\delta,
&lt;/math&gt;
where &lt;math&gt;h_n=\mathcal{A}(S_n)&lt;/math&gt;, with &lt;math&gt;S_n = ((x_1,y_1),\ldots,(x_n,y_n))\sim \rho^n&lt;/math&gt; as above. The [[No free lunch in search and optimization|No Free Lunch Theorem]] says that without restrictions on the hypothesis space &lt;math&gt;\mathcal H&lt;/math&gt;, this is not the case, i.e., there always exist "bad" distributions for which the sample complexity is arbitrarily large.&lt;ref name=":0"&gt;{{citation |last = Vapnik | first = Vladimir | title = Statistical Learning Theory | place = New York | publisher = Wiley. | year = 1998}}&lt;/ref&gt;

Thus, in order to make statements about the rate of convergence of the quantity
&lt;math display="block"&gt; 
\sup_\rho\left(\Pr_{\rho^n}[\mathcal E(h_n) - \mathcal E^*_\mathcal{H}\geq\varepsilon]\right),
&lt;/math&gt;
one must either
*constrain the space of probability distributions &lt;math&gt;\rho&lt;/math&gt;, e.g. via a parametric approach, or
*constrain the space of hypotheses &lt;math&gt;\mathcal H&lt;/math&gt;, as in distribution-free approaches.

==Restricted hypothesis space: finite sample-complexity==
The latter approach leads to concepts such as [[VC dimension]] and [[Rademacher complexity]] which control the complexity of the space &lt;math&gt;\mathcal H&lt;/math&gt;. A smaller hypothesis space introduces more bias into the inference process, meaning that &lt;math&gt;\mathcal E^*_\mathcal{H}&lt;/math&gt; may be greater than the best possible risk in a larger space. However, by restricting the complexity of the hypothesis space it becomes possible for an algorithm to produce more uniformly consistent functions. This trade-off leads to the concept of [[regularization (mathematics)|regularization]].&lt;ref name = "Rosasco" /&gt;

It is a theorem from [[Vapnik–Chervonenkis theory|VC theory]] that the following three statements are equivalent for a hypothesis space &lt;math&gt;\mathcal H&lt;/math&gt;:
# &lt;math&gt;\mathcal H&lt;/math&gt; is PAC-learnable.
# The VC dimension of &lt;math&gt;\mathcal H&lt;/math&gt; is finite.
# &lt;math&gt;\mathcal H&lt;/math&gt; is a uniform [[Glivenko-Cantelli class]].
This gives a way to prove that certain hypothesis spaces are PAC learnable, and by extension, learnable.

=== An example of a PAC-learnable hypothesis space ===
&lt;math&gt;X = \R^d, Y = \{-1, 1\}&lt;/math&gt;, and let &lt;math&gt;\mathcal H&lt;/math&gt; be the space of affine functions on &lt;math&gt;X&lt;/math&gt;, that is, functions of the form &lt;math&gt;x\mapsto \langle w,x\rangle+b&lt;/math&gt; for some &lt;math&gt;w\in\R^d,b\in\R&lt;/math&gt;. This is the linear classification with offset learning problem. Now, note that four coplanar points in a square cannot be shattered by any affine function, since no affine function can be positive on two diagonally opposite vertices and negative on the remaining two. Thus, the VC dimension of &lt;math&gt;\mathcal H&lt;/math&gt; is &lt;math&gt;d + 1&lt;/math&gt;, so it is finite. It follows by the above characterization of PAC-learnable classes that &lt;math&gt;\mathcal H&lt;/math&gt; is PAC-learnable, and by extension, learnable.

=== Sample-complexity bounds ===
&lt;span id='bounds'&gt;&lt;/span&gt;
Suppose &lt;math&gt;\mathcal H&lt;/math&gt; is a class of binary functions (functions to &lt;math&gt;\{0,1\}&lt;/math&gt;). Then, &lt;math&gt;\mathcal H&lt;/math&gt; is &lt;math&gt;(\epsilon,\delta)&lt;/math&gt;-PAC-learnable with a sample of size:
&lt;ref&gt;{{Cite journal|title=The optimal sample complexity of PAC learning
|journal=J. Mach. Learn. Res.|volume=17|issue=1|pages=1319–1333|author=Steve Hanneke|year=2016|url=https://www.jmlr.org/papers/v17/15-389.html}}&lt;/ref&gt;
&lt;math display="block"&gt; 
N = O\bigg(\frac{VC(\mathcal H) + \ln{1\over \delta}}{\epsilon}\bigg)
&lt;/math&gt;
where &lt;math&gt;VC(\mathcal H)&lt;/math&gt; is the [[VC dimension]] of &lt;math&gt;\mathcal H&lt;/math&gt;.
Moreover, any &lt;math&gt;(\epsilon,\delta)&lt;/math&gt;-PAC-learning algorithm for &lt;math&gt;\mathcal H&lt;/math&gt; must have sample-complexity:&lt;ref&gt;{{Cite journal|doi=10.1016/0890-5401(89)90002-3|title=A general lower bound on the number of examples needed for learning|journal=Information and Computation|volume=82|issue=3|pages=247|year=1989|last1=Ehrenfeucht|first1=Andrzej|last2=Haussler|first2=David|last3=Kearns|first3=Michael|last4=Valiant|first4=Leslie}}&lt;/ref&gt;
&lt;math display="block"&gt; 
N = \Omega\bigg(\frac{VC(\mathcal H) + \ln{1\over \delta}}{\epsilon}\bigg)
&lt;/math&gt;
Thus, the sample-complexity is a linear function of the [[VC dimension]] of the hypothesis space.

Suppose &lt;math&gt;\mathcal H&lt;/math&gt; is a class of real-valued functions with range in &lt;math&gt;[0,T]&lt;/math&gt;. Then, &lt;math&gt;\mathcal H&lt;/math&gt; is &lt;math&gt;(\epsilon,\delta)&lt;/math&gt;-PAC-learnable with a sample of size:
&lt;ref name=mr15&gt;{{cite book|first1=Martin|last1=Anthony|first2=Peter L.|last2=Bartlett|title=Neural Network Learning: Theoretical Foundations|year=2009|isbn=9780521118620}}&lt;/ref&gt;&lt;ref&gt;{{cite conference|title=On the Pseudo-Dimension of Nearly Optimal Auctions|year=2015|conference=NIPS|url=http://papers.nips.cc/paper/5766-on-the-pseudo-dimension-of-nearly-optimal-auctions|arxiv=1506.03684|last1=Morgenstern|first1=Jamie|last2=Roughgarden|first2=Tim|pages=136–144|publisher=Curran Associates}}&lt;/ref&gt;
&lt;math display="block"&gt; 
N = O\bigg(T^2\frac{PD(\mathcal H)\ln{T\over \epsilon} + \ln{1\over \delta}}{\epsilon^2}\bigg)
&lt;/math&gt;
where &lt;math&gt;PD(\mathcal H)&lt;/math&gt; is [[VC dimension#Generalizations|Pollard's pseudo-dimension]] of &lt;math&gt;\mathcal H&lt;/math&gt;.

==Other Settings==
In addition to the supervised learning setting, sample complexity is relevant to [[semi-supervised learning]] problems including [[active learning]],&lt;ref name="Balcan"&gt;{{cite journal |doi = 10.1007/s10994-010-5174-y|title = The true sample complexity of active learning|journal = Machine Learning|date = 2010|volume = 80|issue = 2–3|pages = 111–139|last1=Balcan|first1=Maria-Florina|authorlink1= Maria-Florina Balcan|last2=Hanneke|first2=Steve|last3=Wortman Vaughan|first3=Jennifer|doi-access = free}}&lt;/ref&gt; where the algorithm can ask for labels to specifically chosen inputs in order to reduce the cost of obtaining many labels. The concept of sample complexity also shows up in [[reinforcement learning]],&lt;ref&gt;{{citation |last = Kakade | first = Sham | title = On the Sample Complexity of Reinforcement Learning | place = University College London | publisher = Gatsby Computational Neuroscience Unit. | series = PhD Thesis | year = 2003 | url = http://www.ias.tu-darmstadt.de/uploads/Research/NIPS2006/SK.pdf}}&lt;/ref&gt; [[online machine learning|online learning]], and unsupervised algorithms, e.g. for [[dictionary learning]].&lt;ref&gt;{{cite journal |last1 = Vainsencher | first1 = Daniel | last2 = Mannor | first2 = Shie | last3 = Bruckstein | first3 = Alfred | title = The Sample Complexity of Dictionary Learning | journal = Journal of Machine Learning Research | volume = 12 | pages = 3259–3281 | date = 2011 | url = http://www.jmlr.org/papers/volume12/vainsencher11a/vainsencher11a.pdf}}&lt;/ref&gt;

==Efficiency in robotics==
A high sample complexity means, that many calculations are needed for running a [[Monte Carlo tree search]].&lt;ref&gt;{{cite conference |title=Monte-carlo tree search by best arm identification |author=Kaufmann, Emilie and Koolen, Wouter M |conference=Advances in Neural Information Processing Systems |pages=4897–4906 |year=2017 }}&lt;/ref&gt; Its equal to a [[Model-free (reinforcement learning)|model free]] brute force search in the state space. In contrast, a high efficiency algorithm has a low sample complexity.&lt;ref&gt;{{cite conference |title=The chin pinch: A case study in skill learning on a legged robot |author=Fidelman, Peggy and Stone, Peter |conference=Robot Soccer World Cup |pages=59–71 |year=2006 |publisher=Springer }}&lt;/ref&gt; Possible techniques for reducing the sample complexity are [[metric learning]]&lt;ref&gt;{{cite conference |title=Sample complexity of learning mahalanobis distance metrics |author=Verma, Nakul and Branson, Kristin |conference=Advances in neural information processing systems |pages=2584–2592 |year=2015 }}&lt;/ref&gt; and model based reinforcement learning.&lt;ref&gt;{{cite arxiv |title=Model-ensemble trust-region policy optimization |author=Kurutach, Thanard and Clavera, Ignasi and Duan, Yan and Tamar, Aviv and Abbeel, Pieter |eprint=1802.10592 |year=2018 |class=cs.LG }}&lt;/ref&gt;

==References==
{{Reflist}}

[[Category:Machine learning]]</text>
      <sha1>foglwsagi2uyq4773839pp5mrn75wke</sha1>
    </revision>
  </page>
  <page>
    <title>Evaluation of binary classifiers</title>
    <ns>0</ns>
    <id>43218024</id>
    <revision>
      <id>1000124861</id>
      <parentid>965503331</parentid>
      <timestamp>2021-01-13T18:18:24Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 3 templates: hyphenate params (1×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="14168" xml:space="preserve">{{Confusion matrix terms}}
[[Image:binary-classification-labeled.svg|thumb|220px|right|From the [[confusion matrix]] you can derive four basic measures]]

The '''evaluation of binary classifiers''' compares two methods of assigning a binary attribute, one of which is usually a standard method and the other is being investigated. There are many metrics that can be used to measure the performance of a classifier or predictor; different fields have different preferences for specific metrics due to different goals. For example, in medicine [[sensitivity and specificity]] are often used, while in computer science [[precision and recall]] are preferred. An important distinction is between metrics that are independent on the [[prevalence]] (how often each category occurs in the population), and metrics that depend on the prevalence – both types are useful, but they have very different properties.

==Contingency table==
{{main article|Confusion matrix}}

Given a data set, a classification (the output of a classifier on that set) gives two numbers: the number of positives and the number of negatives, which add up to the total size of the set. To evaluate a classifier, one compares its output to another reference classification – ideally a perfect classification, but in practice the output of another [[gold standard (test)|gold standard]] test – and [[cross tabulation|cross tabulates]] the data into a 2×2 [[contingency table]], comparing the two classifications. One then evaluates the classifier ''relative'' to the gold standard by computing [[summary statistic]]s of these 4 numbers. Generally these statistics will be [[scale invariant]] (scaling all the numbers by the same factor does not change the output), to make them independent of population size, which is achieved by using ratios of [[homogeneous function]]s, most simply [[homogeneous linear]] or [[homogeneous quadratic]] functions.

Say we test some people for the presence of a disease. Some of these people have the disease, and our test correctly says they are positive. They are called ''[[true positive]]s'' (TP). Some have the disease, but the test incorrectly claims they don't. They are called ''[[false negative]]s'' (FN). Some don't have the disease, and the test says they don't – ''[[true negative]]s'' (TN). Finally, there might be healthy people who have a positive test result – ''[[false positive]]s'' (FP). These can be arranged into a 2×2 contingency table ([[confusion matrix]]), conventionally with the test result on the vertical axis and the actual condition on the horizontal axis.

These numbers can then be totaled, yielding both a [[grand total]] and [[marginal total]]s. Totaling the entire table, the number of true positives, false negatives, true negatives, and false positives add up to 100% of the set. Totaling the rows (adding horizontally) the number of true positives and false positives add up to 100% of the test positives, and likewise for negatives. Totaling the columns (adding vertically), the number of true positives and false negatives add up to 100% of the condition positives (conversely for negatives). The basic marginal ratio statistics are obtained by dividing the 2×2=4 values in the table by the marginal totals (either rows or columns), yielding 2 auxiliary 2×2 tables, for a total of 8 ratios. These ratios come in 4 complementary pairs, each pair summing to 1, and so each of these derived 2×2 tables can be summarized as a pair of 2 numbers, together with their complements. Further statistics can be obtained by taking ratios of these ratios, ratios of ratios, or more complicated functions.

The contingency table and the most common derived ratios are summarized below; see sequel for details.

{{DiagnosticTesting Diagram}}

Note that the columns correspond to the ''condition actually'' being positive or negative (or classified as such by the gold standard), as indicated by the color-coding, and the associated statistics are prevalence-independent, while the rows correspond to the ''test'' being positive or negative, and the associated statistics are prevalence-dependent. There are analogous likelihood ratios for prediction values, but these are less commonly used, and not depicted above.

== Sensitivity and specificity ==
{{main article|Sensitivity and specificity}}
The fundamental prevalence-independent statistics are [[sensitivity and specificity]].

'''[[Sensitivity (tests)|Sensitivity]]''' or [[True Positive Rate]] (TPR), also known as [[Precision and recall|recall]], is the proportion of people that tested positive and are positive (True Positive, TP) of all the people that actually are positive (Condition Positive, CP = TP + FN). It can be seen as ''the probability that the test is positive given that the patient is sick''. With higher sensitivity, fewer actual cases of disease go undetected (or, in the case of the factory quality control, fewer faulty products go to the market).

'''[[Specificity (tests)|Specificity]]''' (SPC) or [[True Negative Rate]] (TNR) is the proportion of people that tested negative and are negative (True Negative, TN) of all the people that actually are negative (Condition Negative, CN = TN + FP). As with sensitivity, it can be looked at as ''the probability that the test result is negative given that the patient is not sick''. With higher specificity, fewer healthy people are labeled as sick (or, in the factory case, fewer good products are discarded).

The relationship between sensitivity and specificity, as well as the performance of the classifier, can be visualized and studied using the [[Receiver Operating Characteristic]] (ROC) curve.

In theory, sensitivity and specificity are independent in the sense that it is possible to achieve 100% in both (such as in the red/blue ball example given above). In more practical, less contrived instances, however, there is usually a trade-off, such that they are inversely proportional to one another to some extent. This is because we rarely measure the actual thing we would like to classify; rather, we generally measure an indicator of the thing we would like to classify, referred to as a [[surrogate endpoint|surrogate marker]]. The reason why 100% is achievable in the ball example is because redness and blueness is determined by directly detecting redness and blueness. However, indicators are sometimes compromised, such as when non-indicators mimic indicators or when indicators are time-dependent, only becoming evident after a certain lag time. The following example of a pregnancy test will make use of such an indicator.

Modern pregnancy tests ''do not'' use the pregnancy itself to determine pregnancy status; rather, [[human chorionic gonadotropin]] is used, or hCG, present in the urine of [[gravid]] females, as a ''surrogate marker to indicate'' that a woman is pregnant. Because hCG can also be produced by a [[neoplasm|tumor]], the specificity of modern pregnancy tests cannot be 100% (because false positives are possible). Also, because hCG is present in the urine in such small concentrations after fertilization and early [[embryogenesis]], the sensitivity of modern pregnancy tests cannot be 100% (because false negatives are possible).

===Likelihood ratios===
{{main article|Likelihood ratios in diagnostic testing}}
{{empty section|date=July 2014}}

==Positive and negative predictive values==
{{main article|Positive and negative predictive values}}
In addition to sensitivity and specificity, the performance of a binary classification test can be measured with [[positive predictive value]] (PPV), also known as [[Precision and recall#Precision|precision]], and [[negative predictive value]] (NPV). The positive prediction value answers the question "If the test result is ''positive'', how well does that ''predict'' an actual presence of disease?". It is calculated as TP/(TP + FP); that is, it is the proportion of true positives out of all positive results. The negative prediction value is the same, but for negatives, naturally.

=== Impact of prevalence on prediction values ===
Prevalence has a significant impact on prediction values. As an example, suppose there is a test for a disease with 99% sensitivity and 99% specificity. If 2000 people are tested and the prevalence (in the sample) is 50%, 1000 of them are sick and 1000 of them are healthy. Thus about 990 true positives and 990 true negatives are likely, with 10 false positives and 10 false negatives. The positive and negative prediction values would be 99%, so there can be high confidence in the result.

However, if the prevalence is only 5%, so of the 2000 people only 100 are really sick, then the prediction values change significantly. The likely result is 99 true positives, 1 false negative, 1881 true negatives and 19 false positives. Of the 19+99 people tested positive, only 99 really have the disease – that means, intuitively, that given that a patient's test result is positive, there is only 84% chance that they really have the disease. On the other hand, given that the patient's test result is negative, there is only 1 chance in 1882, or 0.05% probability, that the patient has the disease despite the test result.

===Likelihood ratios===
{{empty section|date=July 2014}}

==Precision and recall==
{{main article|Precision and recall}}
{{empty section|date=July 2014}}

===Relationships===
There are various relationships between these ratios.

If the prevalence, sensitivity, and specificity are known, the positive predictive value can be obtained from the following identity:

::&lt;math&gt; \text{PPV} = \frac{(\text{sensitivity}) (\text{prevalence})}{(\text{sensitivity}) (\text{prevalence}) + (1 - \text{specificity}) (1-\text{prevalence})} &lt;/math&gt;

If the prevalence, sensitivity, and specificity are known, the negative predictive value can be obtained from the following identity:

::&lt;math&gt; 
\text{NPV} = \frac{(\text{specificity}) (1 - \text{prevalence})}{(\text{specificity}) (1 - \text{prevalence}) + (1 - \text{sensitivity}) (\text{prevalence})}. &lt;/math&gt;

==Single metrics==
In addition to the paired metrics, there are also single metrics that give a single number to evaluate the test.

Perhaps the simplest statistic is [[Accuracy and precision#In binary classification|accuracy]] or ''fraction correct'' (FC), which measures the fraction of all instances that are correctly categorized; it is the ratio of the number of correct classifications to the total number of correct or incorrect classifications: (TP + TN)/total population = (TP + TN)/(TP + TN + FP + FN). This is often not very useful, compared to the marginal ratios, as it does not yield useful marginal interpretations, due to mixing true positives (test positive, condition positive) and true negatives (test negative, condition negative) – in terms of the condition table, it sums the diagonal; further, it is prevalence-dependent. The complement is the ''fraction incorrect'' (FiC): FC + FiC = 1, or (FP + FN)/(TP + TN + FP + FN) – this is the sum of the [[antidiagonal]], divided by the total population.

The [[diagnostic odds ratio]] (DOR) is a more useful overall metric, which can be defined directly as (TP×TN)/(FP×FN) = (TP/FN)/(FP/TN), or indirectly as a ratio of ratio of ratios (ratio of likelihood ratios, which are themselves ratios of true rates or prediction values). This has a useful interpretation – as an [[odds ratio]] – and is prevalence-independent.

An [[F-score]] is a combination of the [[Precision and recall#Precision|precision]] and the [[Precision and recall#Recall|recall]], providing a single score. There is a one-parameter family of statistics, with parameter ''β,'' which determines the relative weights of precision and recall. The traditional or balanced F-score ([[F1 score]]) is the [[Harmonic mean#Harmonic mean of two numbers|harmonic mean]] of precision and recall:

:&lt;math&gt;F_1 = 2 \cdot \frac{\mathrm{precision} \cdot \mathrm{recall}}{\mathrm{precision} + \mathrm{recall}} &lt;/math&gt;.

===Alternative metrics===
Note, however, that the F-scores do not take the true negative rate into account, and are more suited to [[information retrieval]] and [[information extraction]] evaluation where the true negatives are innumerable. Instead, measures such as the [[phi coefficient]], [[Matthews correlation coefficient]], [[informedness]] or [[Cohen's kappa]] may be preferable to assess the performance of a binary classifier.&lt;ref name="Powers2007"&gt;{{cite journal |first=David M W |last=Powers |date=2011 |title=Evaluation: From Precision, Recall and F-Score to ROC, Informedness, Markedness &amp; Correlation |journal=Journal of Machine Learning Technologies |volume=2 |issue=1 |pages=37–63 |hdl=2328/27165 }}&lt;/ref&gt;&lt;ref name=Powers2012&gt;{{cite conference |first=David M. W. |last=Powers |date=2012 |title=The Problem with Kappa |book-title=Conference of the European Chapter of the Association for Computational Linguistics (EACL2012) Joint ROBUS-UNSUP Workshop |url=http://dl.dropbox.com/u/27743223/201209-eacl2012-Kappa.pdf |archive-url=http://arquivo.pt/wayback/20160518183306/http://dl.dropbox.com/u/27743223/201209-eacl2012-Kappa.pdf |url-status=dead |archive-date=2016-05-18 |access-date=2012-07-20 }}&lt;/ref&gt; As a [[Correlation and dependence|correlation coefficient]], the Matthews correlation coefficient is the [[geometric mean]] of the [[regression coefficient]]s of the problem and its [[Dual (mathematics)|dual]]. The component regression coefficients of the Matthews correlation coefficient are [[markedness]] (deltap) and informedness ([[Youden's J statistic]] or deltap').&lt;ref name="Perruchet2004"&gt;{{cite journal |first1=P. |last1=Perruchet |first2=R. |last2=Peereman |s2cid=17104364 |year=2004 |title=The exploitation of distributional information in syllable processing |journal=J. Neurolinguistics |volume=17 |issue=2–3 |pages=97–119|doi=10.1016/S0911-6044(03)00059-9 }}&lt;/ref&gt;

==See also==
*[[Population impact measures]]
* [[Attributable risk]]
* [[Attributable risk percent]]
* [[Scoring rule]] (for probability predictions)

==References==
{{Reflist}}

[[Category:Statistical classification]]
[[Category:Machine learning]]</text>
      <sha1>7hoihq5m4zkwytq1hdk8sazania7kc7</sha1>
    </revision>
  </page>
  <page>
    <title>Vanishing gradient problem</title>
    <ns>0</ns>
    <id>43502368</id>
    <revision>
      <id>1001031740</id>
      <parentid>1001031690</parentid>
      <timestamp>2021-01-17T22:55:24Z</timestamp>
      <contributor>
        <username>The Anome</username>
        <id>76</id>
      </contributor>
      <comment>Changing [[Wikipedia:Short description|short description]] from "Diffmachine learning model training problem" to "Machine learning model training problem" ([[Wikipedia:Shortdesc helper|Shortdesc helper]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="12805" xml:space="preserve">{{short description|Machine learning model training problem}}
{{machine learning bar}}
In [[machine learning]], the '''vanishing gradient problem''' is encountered when training [[artificial neural network]]s with [[Stochastic gradient descent|gradient-based learning methods]] and [[backpropagation]]. In such methods, each of the neural network's weights receives an update proportional to the [[partial derivative]] of the error function with respect to the current weight in each iteration of training. The problem is that in some cases, the gradient will be vanishingly small, effectively preventing the weight from changing its value. In the worst case, this may completely stop the neural network from further training. As one example of the problem cause, traditional [[activation function]]s such as the [[hyperbolic tangent]] function have gradients in the range (−1, 1), and backpropagation computes gradients by the [[chain rule]]. This has the effect of multiplying {{mvar|n}} of these small numbers to compute gradients of the early layers in an {{mvar|n}}-layer network, meaning that the gradient (error signal) decreases exponentially with {{mvar|n}} while the early layers train very slowly.

Back-propagation allowed researchers to train [[Supervised learning|supervised]] deep artificial neural networks from scratch, initially with little success. [[Sepp Hochreiter|Hochreiter]]'s [[diplom]] thesis of 1991 formally identified the reason for this failure in the "vanishing gradient problem",&lt;ref&gt;{{cite thesis |first=S. |last=Hochreiter |title=Untersuchungen zu dynamischen neuronalen Netzen |type=Diplom thesis |publisher=Institut f. Informatik, Technische Univ. Munich |year=1991 |url=http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf }}&lt;/ref&gt;&lt;ref&gt;{{cite book |first=S. |last=Hochreiter |first2=Y. |last2=Bengio |first3=P. |last3=Frasconi |first4=J. |last4=Schmidhuber |chapter=Gradient flow in recurrent nets: the difficulty of learning long-term dependencies |editor-first=S. C. |editor-last=Kremer |editor2-first=J. F. |editor2-last=Kolen |title=A Field Guide to Dynamical Recurrent Neural Networks |publisher=IEEE Press |year=2001 |isbn=0-7803-5369-2 }}&lt;/ref&gt; which not only affects [[Deep learning|many-layered]] [[Feedforward neural network|feedforward networks]],&lt;ref&gt;{{Cite journal|last1=Goh|first1=Garrett B.|last2=Hodas|first2=Nathan O.|last3=Vishnu|first3=Abhinav|date=2017-06-15|title=Deep learning for computational chemistry|journal=Journal of Computational Chemistry|language=en|volume=38|issue=16|pages=1291–1307|doi=10.1002/jcc.24764|pmid=28272810|arxiv=1701.04503|bibcode=2017arXiv170104503G|s2cid=6831636}}&lt;/ref&gt; but also [[recurrent neural network|recurrent network]]s.&lt;ref&gt;{{cite arxiv|last1=Pascanu|first1=Razvan|last2=Mikolov|first2=Tomas|last3=Bengio|first3=Yoshua|date=2012-11-21|title=On the difficulty of training Recurrent Neural Networks|eprint=1211.5063|class=cs.LG}}&lt;/ref&gt; The latter are trained by unfolding them into very deep feedforward networks, where a new layer is created for each time step of an input sequence processed by the network. (The combination of unfolding and backpropagation is termed [[backpropagation through time]].)

When activation functions are used whose derivatives can take on larger values, one risks encountering the related '''exploding gradient problem'''.
{{toclimit|3}}

== Solutions ==
{{Multiple issues|section=y|
{{refimprove science | section | date= December 2017}}
{{unreliable sources | section | date= December 2017}}
}}

=== Multi-level hierarchy ===
To overcome this problem, several methods were proposed. One is [[Jürgen Schmidhuber]]'s  multi-level hierarchy of networks (1992) pre-trained one level at a time through [[unsupervised learning]], fine-tuned through [[backpropagation]].&lt;ref name="SCHMID1992"&gt;J. Schmidhuber., "Learning complex, extended sequences using the principle of history compression," ''Neural Computation'', 4, pp. 234–242, 1992.&lt;/ref&gt; Here each level learns a compressed representation of the observations that is fed to the next level.

==== Related approach ====
Similar ideas have been used in feed-forward neural networks for unsupervised pre-training to structure a neural network, making it first learn generally useful [[feature detection (nervous system)|feature detectors]]. Then the network is trained further by supervised [[backpropagation]] to classify labeled data. The [[deep belief network]] model by Hinton et al. (2006) involves learning the distribution of a high level representation using successive layers of binary or real-valued [[latent variable]]s. It uses a [[restricted Boltzmann machine]] to model each new layer of higher level features. Each new layer guarantees an increase on the [[Lower bound|lower-bound]] of the [[log likelihood]] of the data, thus improving the model, if trained properly. Once sufficiently many layers have been learned the deep architecture may be used as a [[generative model]] by reproducing the data when sampling down the model (an "ancestral pass") from the top level feature activations.&lt;ref name="hinton2006"&gt;{{cite journal|last2=Osindero|first2=S.|last3=Teh|first3=Y.|year=2006|title=A fast learning algorithm for deep belief nets|url=http://www.cs.toronto.edu/~hinton/absps/fastnc.pdf|journal=[[Neural Computation (journal)|Neural Computation]]|volume=18|issue=7|pages=1527–1554|doi=10.1162/neco.2006.18.7.1527|pmid=16764513|last1=Hinton|first1=G. E.|author-link1=Geoffrey Hinton|citeseerx=10.1.1.76.1541|s2cid=2309950}}&lt;/ref&gt; Hinton reports that his models are effective feature extractors over high-dimensional, structured data.&lt;ref&gt;{{Cite journal|year=2009|title=Deep belief networks|journal=Scholarpedia|volume=4|issue=5|pages=5947|doi=10.4249/scholarpedia.5947|last1=Hinton|first1=G.|bibcode=2009SchpJ...4.5947H|doi-access=free}}&lt;/ref&gt;

=== Long short-term memory ===
{{Main|Long short-term memory}}

Another technique particularly used for [[recurrent neural network]]s is the [[long short-term memory]] (LSTM) network of 1997 by [[Sepp Hochreiter|Hochreiter]] &amp; [[Jürgen Schmidhuber|Schmidhuber]].&lt;ref name=lstm&gt;{{cite journal | last1 = Hochreiter | first1 = Sepp | author-link = Sepp Hochreiter | author-link2 = Jürgen Schmidhuber | last2 = Schmidhuber | first2 = Jürgen | year = 1997 | title = Long Short-Term Memory | journal = Neural Computation | volume = 9 | issue = 8| pages = 1735–1780 | doi=10.1162/neco.1997.9.8.1735 | pmid=9377276| s2cid = 1915014 }}&lt;/ref&gt; In 2009, deep multidimensional LSTM networks demonstrated the power of deep learning with many nonlinear layers, by winning three [[ICDAR]] 2009 competitions in connected [[handwriting recognition]], without any prior knowledge about the three different languages to be learned.&lt;ref&gt;Graves, Alex; and Schmidhuber, Jürgen; ''Offline Handwriting Recognition with Multidimensional Recurrent Neural Networks'', in Bengio, Yoshua; Schuurmans, Dale; Lafferty, John; Williams, Chris K. I.; and Culotta, Aron (eds.), ''Advances in Neural Information Processing Systems 22 (NIPS'22), December 7th–10th, 2009, Vancouver, BC'', Neural Information Processing Systems (NIPS) Foundation, 2009, pp. 545–552&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Graves | first1 = A. | last2 = Liwicki | first2 = M. | last3 = Fernandez | first3 = S. | last4 = Bertolami | first4 = R. | last5 = Bunke | first5 = H. | last6 = Schmidhuber | first6 = J. | title = A Novel Connectionist System for Improved Unconstrained Handwriting Recognition | journal = IEEE Transactions on Pattern Analysis and Machine Intelligence | volume = 31 | issue = 5| year = 2009 | pages = 855–868 | doi = 10.1109/tpami.2008.137 | pmid = 19299860 | citeseerx = 10.1.1.139.4502 | s2cid = 14635907 }}&lt;/ref&gt;

===Faster hardware===
Hardware advances have meant that from 1991 to 2015, computer power (especially as delivered by [[General-purpose computing on graphics processing units|GPUs]]) has increased around a million-fold, making standard backpropagation feasible for networks several layers deeper than when the vanishing gradient problem was recognized. Schmidhuber notes that this "is basically what is winning many of the image recognition competitions now", but that it "does not really overcome the problem in a fundamental way"&lt;ref&gt;{{cite journal |last=Schmidhuber |first=Jürgen |title=Deep learning in neural networks: An overview |journal=Neural Networks |volume=61 |year=2015 |pages=85–117 |arxiv=1404.7828 |doi=10.1016/j.neunet.2014.09.003|pmid=25462637 |s2cid=11715509 }}&lt;/ref&gt; since the original models tackling the vanishing gradient problem by Hinton and others were trained in a [[Xeon|Xeon processor]], not GPUs.&lt;ref name="hinton2006" /&gt;

=== Residual networks ===
One of the newest and most effective ways to resolve the vanishing gradient problem is with [[Residual neural network|residual neural networks]], or ResNets&lt;ref&gt;{{cite web|url=https://blog.init.ai/residual-neural-networks-are-an-exciting-area-of-deep-learning-research-acf14f4912e9|title=Residual neural networks are an exciting area of deep learning research|date=28 April 2016}}&lt;/ref&gt; (not to be confused with recurrent neural networks).&lt;ref&gt;http://www.fit.vutbr.cz/research/groups/speech/servite/2010/rnnlm_mikolov.pdf&lt;/ref&gt; ResNets refer to neural networks where skip connections or residual connections are part of the network architecture. These skip connections allow gradient information to pass through the layers, by creating "highways" of information, where the output of a previous layer/activation is added to the output of a deeper layer. This allows information from the earlier parts of the network to be passed to the deeper parts of the network, helping maintain signal propagation even in deeper networks. Skip connections are a critical component of what allowed successful training of deeper neural networks. &lt;ref&gt;{{Cite arxiv |title=Deep Residual Learning for Image Recognition|eprint=1512.03385|last1=He|first1=Kaiming|last2=Zhang|first2=Xiangyu|last3=Ren|first3=Shaoqing|last4=Sun|first4=Jian|year=2015|class=cs.CV}}&lt;/ref&gt; 

ResNets&lt;ref&gt;{{cite web|url=https://chatbotslife.com/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32|title=ResNets, HighwayNets, and DenseNets, Oh My! – Chatbot's Life|date=14 October 2016}}&lt;/ref&gt; yielded lower training error (and test error) than their shallower counterparts simply by reintroducing outputs from shallower layers in the network to compensate for the vanishing data.&lt;ref&gt;{{Cite arxiv |title=Deep Residual Learning for Image Recognition|eprint=1512.03385|last1=He|first1=Kaiming|last2=Zhang|first2=Xiangyu|last3=Ren|first3=Shaoqing|last4=Sun|first4=Jian|year=2015|class=cs.CV}}&lt;/ref&gt;Note that ResNets are an ensemble of relatively shallow nets and do not resolve the vanishing gradient problem by preserving gradient flow throughout the entire depth of the network – rather, they avoid the problem simply by constructing ensembles of many short networks together. (Ensemble by Construction&lt;ref&gt;{{cite arxiv|last1=Veit|first1=Andreas|last2=Wilber|first2=Michael|last3=Belongie|first3=Serge|date=2016-05-20|title=Residual Networks Behave Like Ensembles of Relatively Shallow Networks|eprint=1605.06431|class=cs.CV}}&lt;/ref&gt;)

=== Other activation functions ===
[[Rectifier (neural networks)|Rectifier]]s such as [[ReLU]] suffer less from the vanishing gradient problem, because they only saturate in one direction.&lt;ref&gt;{{Cite journal|last1=Glorot|first1=Xavier|last2=Bordes|first2=Antoine|last3=Bengio|first3=Yoshua|date=2011-06-14|title=Deep Sparse Rectifier Neural Networks|url=http://proceedings.mlr.press/v15/glorot11a.html|journal=PMLR|pages=315–323|language=en}}&lt;/ref&gt;

=== Other ===
Behnke relied only on the sign of the gradient ([[Rprop]]) when training his [[Neural Abstraction Pyramid]]&lt;ref&gt;{{cite book|url=http://www.ais.uni-bonn.de/books/LNCS2766.pdf|title=Hierarchical Neural Networks for Image Interpretation.|publisher=Springer|year=2003|series=Lecture Notes in Computer Science|volume=2766|author=Sven Behnke}}&lt;/ref&gt; to solve problems like image reconstruction and face localization.{{Citation needed|date=June 2017}}

Neural networks can also be optimized by using a universal search algorithm on the space of neural network's weights, e.g.,  [[random guess]] or more systematically [[genetic algorithm]]. This approach is not based on gradient and avoids the vanishing gradient problem.&lt;ref&gt;{{Cite web|url=http://people.idsia.ch/~juergen/fundamentaldeeplearningproblem.html|title=Sepp Hochreiter's Fundamental Deep Learning Problem (1991)|website=people.idsia.ch|access-date=2017-01-07}}&lt;/ref&gt;

== See also ==
* [[Spectral radius]]

== References ==
{{reflist|30em}}
{{Use dmy dates|date=August 2019}}


[[Category:Machine learning]]
[[Category:Artificial neural networks]]</text>
      <sha1>2m7sa3p8dt4rd7gurct3dbapxx3nmw2</sha1>
    </revision>
  </page>
  <page>
    <title>Query-level feature</title>
    <ns>0</ns>
    <id>41929726</id>
    <revision>
      <id>835841706</id>
      <parentid>814119833</parentid>
      <timestamp>2018-04-11T02:57:56Z</timestamp>
      <contributor>
        <username>GoodDay</username>
        <id>589223</id>
      </contributor>
      <comment>Reduce whitespace</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="432" xml:space="preserve">A '''query-level feature''' or '''QLF''' is a ranking feature utilized in a [[machine-learned ranking]] algorithm.

Example QLFs:
* How many times has this query been run in the last month?
* How many words are in the query?
* What is the sum/average/min/max/median of the [[Probabilistic relevance model (BM25)|BM25F]] values for the query?

{{compu-ai-stub}}

[[Category:Machine learning algorithms]]
[[Category:Machine learning]]</text>
      <sha1>il7s84spuuj846669xpfnok8yfes9t4</sha1>
    </revision>
  </page>
  <page>
    <title>Random projection</title>
    <ns>0</ns>
    <id>43932548</id>
    <revision>
      <id>1005264824</id>
      <parentid>1005264723</parentid>
      <timestamp>2021-02-06T20:47:23Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <comment>Add: bibcode, s2cid, author pars. 1-1. Removed accessdate with no specified URL. Removed parameters. Some additions/deletions were actually parameter name changes. | You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | Suggested by Chris Capoccia | via #UCB_toolbar</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="11146" xml:space="preserve">{{multiple issues|
{{refimprove|date=November 2014}}
{{expert needed|date=November 2014}}
}}

In mathematics and statistics, '''random projection''' is a technique used to [[dimensionality reduction|reduce the dimensionality]] of a set of points which lie in [[Euclidean space]]. Random projection methods are known for their power, simplicity, and low error rates when compared to other methods{{Citation needed|reason=What other methods? Says who?|date=June 2017}}. According to experimental results, random projection preserves distances well, but empirical results are sparse.&lt;ref&gt;{{cite conference
 | first1 = Bingham | last1 = Ella
 | first2 = Mannila | last2 = Heikki
 | title = Random projection in dimensionality reduction: Applications to image and text data
 | book-title = KDD-2001: Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining
 | pages = 245–250
 | publisher = Association for Computing Machinery | date = 2001 | location = New York
 | doi = 10.1145/502512.502546 | citeseerx = 10.1.1.24.5135
 }}&lt;/ref&gt; They have been applied to many natural language tasks under the name [[random indexing]].

==Dimensionality reduction==
{{main|Dimensionality reduction}}
Dimensionality reduction, as the name suggests, is reducing the number of random variables using various mathematical methods from statistics and machine learning. Dimensionality reduction is often used to reduce the problem of managing and manipulating large data sets. Dimensionality reduction techniques generally use linear transformations in determining the intrinsic dimensionality of the manifold as well as extracting its principal directions. For this purpose there are various related techniques, including: [[principal component analysis]], [[linear discriminant analysis]], [[canonical correlation analysis]], [[discrete cosine transform]], random projection, etc.

Random projection is a simple and computationally efficient way to reduce the dimensionality of data by trading a controlled amount of error for faster processing times and smaller model sizes. The dimensions and distribution of random projection matrices are controlled so as to approximately preserve the pairwise distances between any two samples of the dataset.

==Method==

The core idea behind random projection is given in the [[Johnson-Lindenstrauss lemma]],&lt;ref&gt;{{cite book
 | last1 = Johnson
 | first1 = William B.
 | author1-link = William B. Johnson (mathematician)
 | last2 = Lindenstrauss
 | first2 = Joram
 | author2-link = Joram Lindenstrauss
 | contribution = Extensions of Lipschitz mappings into a Hilbert space
 | doi = 10.1090/conm/026/737400
 | location = Providence, RI
 | mr = 737400
 | pages = [https://archive.org/details/conferenceinmode0000conf/page/189 189–206]
 | publisher = American Mathematical Society
 | series = Contemporary Mathematics
 | title = Conference in Modern Analysis and Probability (New Haven, Conn., 1982)
 | volume = 26
 | year = 1984
 | isbn = 9780821850305
 | url-access = registration
 | url = https://archive.org/details/conferenceinmode0000conf/page/189
 }}.
&lt;/ref&gt; which states that if points in a vector space are of sufficiently high dimension, then they may be projected into a suitable lower-dimensional space in a way which approximately preserves the distances between the points.

In random projection, the original d-dimensional data is projected to a k-dimensional (k &lt;&lt; d) subspace, using a random &lt;math&gt;k \times d &lt;/math&gt; - dimensional matrix R whose columns have unit lengths.{{citation needed|date=January 2019}} Using matrix notation: If &lt;math&gt;X_{d \times N}&lt;/math&gt; is the original set of N d-dimensional observations, then &lt;math&gt;X_{k \times N}^{RP}=R_{k \times d}X_{d \times N}&lt;/math&gt; is the projection of the data onto a lower k-dimensional subspace. Random projection is computationally simple: form the random matrix "R" and project the &lt;math&gt;d \times N&lt;/math&gt; data matrix X onto K dimensions of order &lt;math&gt;O(dkN)&lt;/math&gt;. If the data matrix X is sparse with about c nonzero entries per column, then the complexity of this operation is of order &lt;math&gt;O(ckN)&lt;/math&gt;.&lt;ref&gt;{{Cite web|url =http://www.ime.unicamp.br/~wanderson/Artigos/randon_projection_kdd.pdf |title =Random projection in dimensionality reduction: Applications to image and text data |date = May 6, 2014|website = | last1 = Bingham | first1 = Ella | last2 = Mannila | first2 = Heikki  }}&lt;/ref&gt;

===Gaussian random projection===

The random matrix R can be generated using a Gaussian distribution. The first row is a random unit vector uniformly chosen from &lt;math&gt;S^{d-1}&lt;/math&gt;. The second row is a random unit vector from the space orthogonal to the first row, the third row is a random unit vector from the space orthogonal to the first two rows, and so on. In this way of choosing R, R is an orthogonal matrix (the inverse of its transpose), and the following properties are satisfied:
* Spherical symmetry: For any orthogonal matrix &lt;math&gt;A \in O(d)&lt;/math&gt;, RA and R have the same distribution.
* Orthogonality: The rows of R are orthogonal to each other.
* Normality: The rows of R are unit-length vectors.

===More computationally efficient random projections===

Achlioptas&lt;ref&gt;{{cite book|doi=10.1145/375551.375608|chapter=Database-friendly random projections|title=Proceedings of the twentieth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems - PODS '01|pages=274–281|year=2001|last1=Achlioptas|first1=Dimitris|isbn=978-1581133615|citeseerx=10.1.1.28.6652|s2cid=2640788}}&lt;/ref&gt; has shown that the Gaussian distribution can be replaced by a much simpler distribution such as
:&lt;math&gt;R_{i,j} = \sqrt{3} \times \begin{cases}
+1 &amp; \text{with probability }\frac{1}{6}\\
0 &amp; \text{with probability }\frac{2}{3}\\
-1 &amp; \text{with probability }\frac{1}{6} \end{cases} &lt;/math&gt;
This is efficient for database applications because the computations can be performed using integer arithmetic.

It was later shown how to use integer arithmetic while making the distribution even sparser, having very few nonzeroes per column, in work on the Sparse JL Transform.&lt;ref&gt;{{cite journal
 | first1 = Daniel M. | last1 = Kane | last2 = Nelson | first2 = Jelani
 | doi = 10.1145/2559902
 | issue = 1
 | pages = 1–23 | journal = [[Journal of the ACM]]
 | title = Sparser Johnson-Lindenstrauss Transforms
 | volume = 61
 | year = 2014
 | mr = 3167920| arxiv = 1012.1577| s2cid = 7821848 }}
&lt;/ref&gt; This is advantageous since a sparse embedding matrix means being able to project the data to lower dimension even faster.

==Large quasiorthogonal [[Basis (linear algebra)|bases]]==
The [[Johnson–Lindenstrauss lemma|Johnson-Lindenstrauss lemma]] states that large sets of vectors in a high-dimensional space can be linearly mapped in a space of much lower (but still high) dimension ''n''  with approximate preservation of distances.  One of the explanations of this effect is the exponentially high quasiorthogonal dimension of ''n''-dimensional [[Euclidean space]].&lt;ref&gt;{{citation
 | last1 = Kainen | first1 = Paul C. | author1-link = Paul Chester Kainen
 | last2 = Kůrková | first2 = Věra | author2-link = Věra Kůrková
 | doi = 10.1016/0893-9659(93)90023-G
 | issue = 3
 | journal = Applied Mathematics Letters
 | mr = 1347278
 | pages = 7–10
 | title = Quasiorthogonal dimension of Euclidean spaces
 | volume = 6
 | year = 1993}}&lt;/ref&gt; There are exponentially large (in dimension ''n'')    sets of almost [[Orthogonality|orthogonal]] vectors (with small value of [[Inner product space|inner products]]) in ''n''–dimensional Euclidean space. This observation is useful in [[Database index|indexing]] of high-dimensional data.&lt;ref&gt;{{cite book |last1=Hecht-Nielsen |first1=R. |chapter=Context vectors: General-purpose approximate meaning representations self-organized from raw data |pages=43–56 |editor1-last=Zurada |editor1-first=Jacek M. |editor2-last=Marks |editor2-first=Robert Jackson |editor3-last=Robinson |editor3-first=Charles J. |title=Computational Intelligence: Imitating Life |date=1994 |publisher=IEEE |isbn=978-0-7803-1104-6 }}&lt;/ref&gt;

Quasiorthogonality of large random sets is important for methods of random approximation in [[machine learning]]. In high dimensions, exponentially large numbers of randomly and independently chosen vectors from equidistribution on a sphere (and from many other distributions) are almost orthogonal with probability close to one.&lt;ref name = "GorbanTyukin2016"&gt;{{cite journal
 | first1 = Alexander N. | last1 = Gorban | author1-link = Aleksandr Gorban
 | first2 = Ivan Y. | last2 = Tyukin | first3 = Danil V. | last3 = Prokhorov | first4 = Konstantin I. | last4 = Sofeikov
 | doi = 10.1016/j.ins.2015.09.021
 | pages = 129–145
 | journal = [[Information Sciences (journal)|Information Sciences]]
 | title = Approximation with Random Bases: Pro et Contra
 | volume = 364-365
 | year = 2016
 | arxiv = 1506.04631| s2cid = 2239376 }}&lt;/ref&gt;  This implies that in order to represent an element of such a high-dimensional space by linear combinations of randomly and independently chosen vectors, it may often be necessary to generate samples of exponentially large length if we use bounded coefficients in linear combinations. On the other hand, if coefficients with arbitrarily large values are allowed, the number of randomly generated elements that are sufficient for approximation is even less than dimension of the data space.

== Implementations ==

* [https://cran.r-project.org/web/packages/RandPro/index.html RandPro] - An R package for random projection &lt;ref&gt;{{cite journal |last1=Ravindran |first1=Siddharth |title=A Data-Independent Reusable Projection (DIRP) Technique for Dimension Reduction in Big Data Classification Using k-Nearest Neighbor (k-NN) |journal=National Academy Science Letters |volume=43 |pages=13–21 |doi=10.1007/s40009-018-0771-6 |year=2020 |s2cid=91946077 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last1=Siddharth |first1=R. |last2=Aghila |first2=G. |title=RandPro- A practical implementation of random projection-based feature extraction for high dimensional multivariate data analysis in R |journal=SoftwareX |date=July 2020 |volume=12 |pages=100629 |doi=10.1016/j.softx.2020.100629 |bibcode=2020SoftX..1200629S }}&lt;/ref&gt;
* [http://scikit-learn.org/stable/modules/random_projection.html sklearn.random_projection] - Python module for random projection
* Weka implementation [http://weka.sourceforge.net/doc.stable/weka/filters/unsupervised/attribute/RandomProjection.html]

==See also==
* [[Locality-sensitive hashing]]
* [[Random mapping]]
* [[Johnson-Lindenstrauss lemma]]

==References==
{{Reflist}}

==Further reading==
* {{cite report |last1=Fodor |first1=Imola K |year=2002 |citeseerx=10.1.1.8.5098 |title=A survey of dimension reduction techniques }}
* {{cite thesis |first1=Aditya Krishna |last1=Menon |year=2007 |citeseerx=10.1.1.164.640 |title=Random projections and applications to dimensionality reduction }}
* {{cite report |last1=Ramdas |first1=Aditya |citeseerx=10.1.1.377.2593 |title=A Random Introduction To Random Projections }}

[[Category:Machine learning]]
[[Category:Dimension reduction]]</text>
      <sha1>tvqec1y97ycyu1cdau9tutqt0gxzan1</sha1>
    </revision>
  </page>
  <page>
    <title>Action model learning</title>
    <ns>0</ns>
    <id>43808044</id>
    <revision>
      <id>1000133991</id>
      <parentid>938082354</parentid>
      <timestamp>2021-01-13T19:13:57Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: doi added to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="7229" xml:space="preserve">{{Machine learning bar}}

'''Action model learning''' (sometimes abbreviated '''action learning''') is an area of [[machine learning]] concerned with creation and modification of [[software agent]]'s knowledge about ''effects'' and ''preconditions'' of the ''actions'' that can be executed within its ''environment''. This knowledge is usually represented in logic-based [[action language|action description language]] and used as the input for [[automated planning|automated planners]].

Learning action models is important when goals change. When an agent acted for a while, it can use its accumulated knowledge about actions in the domain to make better decisions. Thus, learning action models differs from [[reinforcement learning]]. It enables reasoning about actions instead of expensive trials in the world.&lt;ref name="amir2008"&gt;
{{cite journal
  | last = Amir | first = Eyal
  | last2 = Chang | first2 = Allen
  | title = Learning Partially Observable Deterministic Action Models
  | journal =  Journal of Artificial Intelligence Research
  | volume = 33
  | pages = 349&amp;ndash;402
  | year = 2008
  | url = http://dl.acm.org/citation.cfm?id=1622708
| doi = 10.1613/jair.2575
 | arxiv = 1401.3437
  }}
&lt;/ref&gt; Action model learning is a form of [[inductive reasoning]], where new knowledge is generated based on agent's ''observations''. It differs from standard [[supervised learning]] in that correct input/output pairs are never presented, nor imprecise action models explicitly corrected.

Usual motivation for action model learning is the fact that manual specification of action models for planners is often a difficult, time consuming, and error-prone task (especially in complex environments).

== Action models ==

Given a [[training set]] &lt;math&gt;E&lt;/math&gt; consisting of examples &lt;math&gt;e = (s,a,s')&lt;/math&gt;, where &lt;math&gt;s,s'&lt;/math&gt; are observations of a world state from two consecutive time steps &lt;math&gt;t, t'&lt;/math&gt; and &lt;math&gt;a&lt;/math&gt; is an ''action instance'' observed in time step &lt;math&gt;t&lt;/math&gt;, the goal of action model learning in general is to construct an ''action model'' &lt;math&gt;\langle D,P \rangle&lt;/math&gt;, where &lt;math&gt;D&lt;/math&gt; is a description of domain dynamics in action description formalism like [[Stanford Research Institute Problem Solver|STRIPS]], [[Architecture description language|ADL]] or [[PDDL]] and &lt;math&gt;P&lt;/math&gt; is a probability function defined over the elements of &lt;math&gt;D&lt;/math&gt;.
&lt;ref name="certicky2013"&gt;
{{cite journal
  | doi = 10.1080/08839514.2014.927692
  | last = Čertický | first = Michal
  | title = Real-Time Action Model Learning with Online Algorithm 3SG
  | journal = Applied Artificial Intelligence
  | volume = 28
  | issue = 7 | pages = 690&amp;ndash;711
  | year = 2014
  }}
&lt;/ref&gt;
However, many state of the art ''action learning methods'' assume determinism and do not induce &lt;math&gt;P&lt;/math&gt;. In addition to determinism, individual methods differ in how they deal with other attributes of domain (e.g. partial observability or sensoric noise).

== Action learning methods ==

=== State of the art ===
Recent action learning methods take various approaches and employ a wide variety of tools from different areas of [[artificial intelligence]] and [[computational logic]]. As an example of a method based on propositional logic, we can mention SLAF (Simultaneous Learning and Filtering) algorithm,&lt;ref name="amir2008"/&gt; which uses agent's observations to construct a long propositional formula over time and subsequently interprets it using a [[SAT solver|satisfiability (SAT) solver]]. Another technique, in which learning is converted into a satisfiability problem (weighted [[MAX-SAT]] in this case) and SAT solvers are used, is implemented in ARMS (Action-Relation Modeling System).&lt;ref name="yang2007"&gt;
{{cite journal
|last1=Yang
|first1=Qiang
|last2=Kangheng
|first2=Wu
|last3=Yunfei
|first3=Jiang
|title=Learning action models from plan examples using weighted MAX-SAT
|journal=Artificial Intelligence
|date=2007
|volume=171
|issue=2–3
|pages=107–143
|doi=10.1016/j.artint.2006.11.005|doi-access=free
}}&lt;/ref&gt;
Two mutually similar, fully declarative approaches to action learning were based on logic programming paradigm [[Answer Set Programming]] (ASP)&lt;ref&gt;{{cite journal|last1=Balduccini|first1=Marcelo|title=Learning Action Descriptions with A-Prolog: Action Language C|journal=AAAI Spring Symposium: Logical Formalizations of Commonsense Reasoning|date=2007|pages=13–18|url=http://www.aaai.org/Library/Symposia/Spring/2007/ss07-05-004.php}}&lt;/ref&gt; and its extension, Reactive ASP.&lt;ref&gt;{{cite book|last1=Čertický|first1=Michal|title=Action Learning with Reactive Answer Set Programming: Preliminary Report|journal=ICAS 2012, the Eighth International Conference on Autonomic and Autonomous Systems|date=2012|pages=107–111|url=http://www.thinkmind.org/index.php?view=article&amp;articleid=icas_2012_5_20_20056|isbn=9781612081878}}&lt;/ref&gt; In another example, bottom-up [[inductive logic programming]] approach was employed.&lt;ref&gt;{{cite journal|last1=Benson|first1=Scott|title=Inductive learning of reactive action models|journal=Machine Learning: Proceedings of the Twelfth International Conference (ICML)|date=1995}}&lt;/ref&gt; Several different solutions are not directly logic-based. For example, the action model learning using a [[perceptron algorithm]] &lt;ref&gt;{{cite journal|last1=Mourao|first1=Kira|last2=Petrick|first2=Ronald|last3=Steedman|first3=Mark|title=Learning action effects in partially observable domains|journal= Frontiers in Artificial Intelligence and Applications|date=2010|volume=215|issue=ECAI 2010|pages=973–974|doi=10.3233/978-1-60750-606-5-973|url=http://www.ebooks.iospress.nl/volumearticle/5920}}&lt;/ref&gt; or the multi level [[greedy search]] over the space of
possible action models.&lt;ref&gt;{{cite journal|last1=Zettlemoyer|first1=Luke|last2=Pasula|first2=Hanna|last3=Kaelblin|first3=Leslie Pack|title=Learning planning rules in noisy stochastic worlds|journal=AAAI|date=2005|pages=911–918|url=http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.65.3417}}&lt;/ref&gt; In the older paper from 1992,&lt;ref&gt;{{cite journal|last1=Lin|first1=Long-Ji|title=Self-improving reactive agents based on reinforcement learning, planning and teaching|journal=Machine Learning|date=1992|volume=8|issue=3–4|pages=293–321|doi=10.1023/A:1022628806385|doi-access=free}}&lt;/ref&gt; the action model learning was studied as an extension of [[reinforcement learning]].

=== Literature ===
Most action learning research papers are published in journals and conferences focused on [[artificial intelligence]] in general (e.g. Journal of Artificial Intelligence Research (JAIR), Artificial Intelligence, Applied Artificial Intelligence (AAI) or AAAI conferences). Despite mutual relevance of the topics, action model learning is usually not addressed on [[Automated planning and scheduling|planning]] conferences like ICAPS.

==See also==
* [[Machine learning]]
* [[Automated planning and scheduling]]
* [[Action language]]
* [[PDDL]]
* [[Architecture description language]]
* [[Inductive reasoning]]
* [[Computational logic]]
* [[Knowledge representation]]

== References ==
{{reflist}}

[[Category:Inductive reasoning]]
[[Category:Machine learning]]
[[Category:Data mining]]</text>
      <sha1>cfg074q28bz7cymxmw9850epl8ri216</sha1>
    </revision>
  </page>
  <page>
    <title>Bradley–Terry model</title>
    <ns>0</ns>
    <id>44439173</id>
    <revision>
      <id>948554716</id>
      <parentid>921037194</parentid>
      <timestamp>2020-04-01T17:53:24Z</timestamp>
      <contributor>
        <username>Arimakat</username>
        <id>9937613</id>
      </contributor>
      <minor/>
      <comment>pages in one reference</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="7306" xml:space="preserve">The '''Bradley–Terry model''' is a [[probability theory|probability model]] that can predict the outcome of a paired comparison. Given a pair of individuals {{mvar|i}} and {{mvar|j}} drawn from some [[Population (statistics)|population]], it estimates the probability that the [[pairwise comparison]] {{math|''i'' &gt; ''j''}} turns out true, as

:&lt;math&gt;P(i &gt; j) = \frac{p_i}{p_i + p_j}&lt;/math&gt;

where {{mvar|p&lt;sub&gt;i&lt;/sub&gt;}} is a positive [[real number|real-valued]] score assigned to individual {{mvar|i}}. The comparison {{math|''i'' &gt; ''j''}} can be read as "{{mvar|i}} is preferred to {{mvar|j}}", "{{mvar|i}} ranks higher than {{mvar|j}}", or "{{mvar|i}} beats {{mvar|j}}", depending on the application.

For example, {{mvar|p&lt;sub&gt;i&lt;/sub&gt;}} may represent the skill of a team in a sports tournament, estimated from the number of times {{mvar|i}} has won a match. &lt;math&gt;P(i&gt;j)&lt;/math&gt; then represents the probability that {{mvar|i}} will win a match against {{mvar|j}}.&lt;ref name="hunter" /&gt;&lt;ref name="agresti" /&gt; Another example used to explain the model's purpose is that of scoring products in a certain category by quality. While it's hard for a person to draft a direct ranking of (many) brands of wine, it may be feasible to compare a sample of pairs of wines and say, for each pair, which one is better. The Bradley–Terry model can then be used to derive a full ranking.&lt;ref name="agresti" /&gt;

== History and applications ==
The model is named after R. A. Bradley and M. E. Terry,&lt;ref&gt;{{cite encyclopedia |author=E.E.M. van Berkum |title=Bradley-Terry model |encyclopedia=Encyclopedia of Mathematics |url=http://www.encyclopediaofmath.org/index.php?title=Bradley-Terry_model&amp;oldid=22181 |accessdate=18 November 2014}}&lt;/ref&gt; who presented it in 1952,&lt;ref&gt;{{Cite journal | doi = 10.2307/2334029| jstor = 2334029| title = Rank Analysis of Incomplete Block Designs: I. The Method of Paired Comparisons| journal = Biometrika| volume = 39| issue = 3/4| pages = 324-345| year = 1952| last1 = Bradley | first1 = Ralph Allan | last2 = Terry | first2 = Milton E. }}&lt;/ref&gt; although it had already been studied by [[Ernst Zermelo|Zermelo]] in the 1920s.&lt;ref name="hunter"&gt;{{Cite journal| first = David R. | last = Hunter| title = MM algorithms for generalized Bradley–Terry models| journal = The Annals of Statistics| volume = 32 | issue = 1| year = 2004| pages = 384–406| jstor = 3448514| url = http://projecteuclid.org/euclid.aos/1079120141| citeseerx = 10.1.1.110.7878| doi=10.1214/aos/1079120141}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last=Zermelo |first=Ernst |title=Die Berechnung der Turnier-Ergebnisse als ein Maximumproblem der Wahrscheinlichkeitsrechnung |journal=[[Mathematische Zeitschrift]] |volume=29 |number=1 |year=1929 |pages=436–460|doi=10.1007/BF01180541}}&lt;/ref&gt;&lt;ref&gt;{{citation |title=Ernst Zermelo: An Approach to His Life and Work |author=Heinz-Dieter Ebbinghaus |year=2007 |isbn=9783540495536 |pages=268–269}}&lt;/ref&gt;

Real-world applications of the model include estimation of the influence of [[Statistics|statistical]] [[scientific journal|journals]], or ranking documents by relevance in [[Learning to rank|machine-learned]] [[search engine]]s.&lt;ref&gt;{{cite conference |last1=Szummer |first1=Martin |first2=Emine |last2=Yilmaz |title=Semi-supervised learning to rank with preference regularization |conference=CIKM |year=2011 |url=http://research.microsoft.com/pubs/154323/SzummerYilmaz-semisupervised-ranking-cikm11.pdf}}&lt;/ref&gt;
In the latter application, &lt;math&gt;P(i &gt; j)&lt;/math&gt; may reflect that document {{mvar|i}} is more relevant to the user's [[Web search query|query]] than document {{mvar|j}}, so it should be displayed earlier in the results list. The individual {{mvar|p&lt;sub&gt;i&lt;/sub&gt;}} then express the relevance of the document, and can be estimated from the frequency with which users click particular "hits" when presented with a result list.&lt;ref&gt;{{cite conference |first1=Filip |last1=Radlinski |first2=Thorsten |last2=Joachims |title=Active Exploration for Learning Rankings from Clickthrough Data |conference=KDD '07 Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining |year=2007 |url=http://www.cs.cornell.edu/People/tJ/publications/radlinski_joachims_07a.pdf|doi=10.1145/1281192.1281254|pages=570–579 }}&lt;/ref&gt;

== Definition ==
The Bradley–Terry model can be parametrized in various ways. One way to do so is to pick a single parameter per observation, leading to a model of {{mvar|n}} parameters {{math|''p''&lt;sub&gt;1&lt;/sub&gt;, ..., ''p&lt;sub&gt;n&lt;/sub&gt;''}}.&lt;ref name="wu"&gt;{{cite conference |title=Ranking Optimization with Constraints |conference=CIKM '14 Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management |author1=Fangzhao Wu |author2=Jun Xu |author3=Hang Li |author4=Xin Jiang |year=2014|doi=10.1145/2661829.2661895|pages=1049–1058 }}&lt;/ref&gt;
Another variant, in fact the version considered by Bradley and Terry,&lt;ref name="agresti"&gt;{{cite book |last=Agresti |first=Alan |title=Categorical Data Analysis |publisher=John Wiley &amp; Sons |year=2014 |pages=436–439}}&lt;/ref&gt; uses exponential score functions &lt;math&gt;p_i = e^{\beta_i}&lt;/math&gt; so that

:&lt;math&gt;P(i &gt; j) = \frac{e^{\beta_i}}{e^{\beta_i} + e^{\beta_j}}&lt;/math&gt;

or, using the [[logit]] (and disallowing ties),&lt;ref name="hunter" /&gt;

:&lt;math&gt;\operatorname{logit}(P(i &gt; j)) = \log\left(\frac{P(i &gt; j)}{1 - P(i &gt; j)}\right) = \log\left(\frac{P(i &gt; j)}{P(j &gt; i)}\right) = \beta_i - \beta_j&lt;/math&gt;

reducing the model to [[logistic regression]] on pairs of individuals.

=== Estimating the parameters ===
The following [[algorithm]] computes the parameters {{mvar|p&lt;sub&gt;i&lt;/sub&gt;}} of the basic version of the model from a sample of observations. Formally, it computes a [[maximum likelihood estimation|maximum likelihood estimate]], i.e., it maximizes the [[likelihood]] of the observed data. The algorithm dates back to the work of Zermelo.&lt;ref name="hunter" /&gt;

The observations required are the outcomes of previous comparisons, for example, pairs {{math|(''i'', ''j'')}} where {{mvar|i}} beats {{mvar|j}}. Summarizing these outcomes as {{mvar|w&lt;sub&gt;ij&lt;/sub&gt;}}, the number of times {{mvar|i}} has beaten {{mvar|j}}, we obtain the [[log-likelihood]] of the parameter vector {{math|'''p''' {{=}} ''p''&lt;sub&gt;1&lt;/sub&gt;, ..., ''p&lt;sub&gt;n&lt;/sub&gt;''}} as&lt;ref name="hunter" /&gt;

:&lt;math&gt;L(\mathbf{p}) = \sum_i^n \sum_j^n w_{ij} \ln p_i - w_{ij} \ln(p_i + p_j).&lt;/math&gt;

Denote the number of comparisons "won" by {{mvar|i}} as {{mvar|W&lt;sub&gt;i&lt;/sub&gt;}}. Starting from an arbitrary vector {{math|'''p'''}}, the algorithm iteratively performs the update

:&lt;math&gt;p'_i = W_i \left( \sum_{j \ne i} \frac{w_{ij} + w_{ji}}{p_i + p_j} \right)^{-1}&lt;/math&gt;

for all {{mvar|i}}. After computing all of the new parameters, they should be renormalized,

:&lt;math&gt;p_i \leftarrow \frac{p'_i}{\sum_{j=1}^n p'_j}.&lt;/math&gt;

This estimation procedure improves the log-likelihood in every iteration, and eventually converges to a unique maximum.

== See also ==
*[[Ordinal regression]]
*[[Rasch model]]
*[[Scale (social sciences)]]
*[[Elo rating system]]
*[[Thurstonian model]]

== References ==
{{reflist|30em}}

{{DEFAULTSORT:Bradley-Terry model}}
[[Category:Machine learning]]
[[Category:Statistical models]]
[[Category:Logistic regression]]
[[Category:Regression models]]</text>
      <sha1>eekx52lxt4hvsb7e02tfu45da6l16q1</sha1>
    </revision>
  </page>
  <page>
    <title>Quantum machine learning</title>
    <ns>0</ns>
    <id>44108758</id>
    <revision>
      <id>1003233392</id>
      <parentid>1002209818</parentid>
      <timestamp>2021-01-28T01:13:43Z</timestamp>
      <contributor>
        <username>HotVector</username>
        <id>38283378</id>
      </contributor>
      <minor/>
      <comment>Remove duplicate image + description</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="62610" xml:space="preserve">{{short description|Interdisciplinary research area at the intersection of quantum physics and machine learning}}
{{Close connection|date=September 2018}}
{{Quantum mechanics}}
'''Quantum machine learning''' is the integration of [[quantum algorithm]]s within [[machine learning]] programs.&lt;ref&gt;{{Cite book|title=Supervised Learning with Quantum Computers|doi=10.1007/978-3-319-96424-9|series=Quantum Science and Technology|year=2018|last1=Schuld|first1=Maria|last2=Petruccione|first2=Francesco|isbn=978-3-319-96423-2}}&lt;/ref&gt;&lt;ref name=":5"&gt;{{cite journal |doi=10.1080/00107514.2014.964942 |arxiv=1409.3097 |title=An introduction to quantum machine learning |journal=Contemporary Physics |volume=56 |issue=2 |pages=172–185 |year=2014 |last1=Schuld |first1=Maria |last2=Sinayskiy |first2=Ilya |last3=Petruccione |first3=Francesco |bibcode=2015ConPh..56..172S|citeseerx=10.1.1.740.5622 |s2cid=119263556 }}&lt;/ref&gt;&lt;ref&gt;{{cite book |last=Wittek |first=Peter |title=Quantum Machine Learning: What Quantum Computing Means to Data Mining |publisher=Academic Press |year=2014 |isbn=978-0-12-800953-6|url=http://www.sciencedirect.com/science/book/9780128009536}}&lt;/ref&gt;&lt;ref&gt;{{cite arxiv |eprint=1512.02900 |first1=Jeremy|last1=Adcock|first2=Euan|last2=Allen|first3=Matthew|last3=Day|first4=Stefan|last4=Frick|first5=Janna|last5=Hinchliff|first6=Mack|last6=Johnson|first7=Sam|last7=Morley-Short|first8=Sam|last8=Pallister|first9=Alasdair|last9=Price|first10=Stasja|last10=Stanisic|title=Advances in quantum machine learning |class=quant-ph |year=2015}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|arxiv=1611.09347 |first1=Jacob|last1=Biamonte|first2=Peter|last2=Wittek|first3=Nicola|last3=Pancotti|first4=Patrick|last4=Rebentrost|first5=Nathan|last5=Wiebe|first6=Seth|last6=Lloyd|title=Quantum machine learning |journal=Nature|volume=549|issue=7671|pages=195–202|year=2017|doi=10.1038/nature23474|pmid=28905917|bibcode=2017Natur.549..195B|s2cid=64536201}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |first1=Alejandro|last1=Perdomo-Ortiz|first2=Marcello|last2=Benedetti|first3=John|last3=Realpe-Gómez|first4=Rupak|last4=Biswas|title=Opportunities and challenges for quantum-assisted machine learning in near-term quantum computers |journal=Quantum Science and Technology|volume=3|issue=3|pages=030502|year=2018|doi=10.1088/2058-9565/aab859|arxiv=1708.09757|bibcode=2018QS&amp;T....3c0502P|s2cid=3963470}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last1=Das Sarma|first1=Sankar|last2=Deng|first2=Dong-Ling|last3=Duan|first3=Lu-Ming|date=2019-03-01|title=Machine learning meets quantum physics|url=https://physicstoday.scitation.org/doi/10.1063/PT.3.4164|journal=Physics Today|volume=72|issue=3|pages=48–54|doi=10.1063/PT.3.4164|arxiv=1903.03516|bibcode=2019PhT....72c..48D|s2cid=86648124|issn=0031-9228}}&lt;/ref&gt; The most common use of the term refers to machine learning algorithms for the analysis of classical data executed on a [[quantum computer]], i.e. ''quantum-enhanced machine learning''.&lt;ref name="Nathan Wiebe 2014"&gt;{{Cite journal |arxiv=1401.2142 |last1=Wiebe |first1=Nathan |title=Quantum Algorithms for Nearest-Neighbor Methods for Supervised and Unsupervised Learning |journal=Quantum Information &amp; Computation |volume=15 |issue=3 |pages=0318–0358 |last2=Kapoor |first2=Ashish |last3=Svore |first3=Krysta |year=2014|bibcode=2014arXiv1401.2142W }}&lt;/ref&gt;&lt;ref&gt;{{cite arxiv |eprint=1307.0411 |last1=Lloyd |first1=Seth |title=Quantum algorithms for supervised and unsupervised machine learning |last2=Mohseni |first2=Masoud |last3=Rebentrost |first3=Patrick |class=quant-ph |year=2013}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |arxiv=1303.6055 |last1=Yoo |first1=Seokwon |title=A quantum speedup in machine learning: Finding a N-bit Boolean function for a classification |journal=New Journal of Physics |volume=16 |issue=10 |pages=103014 |last2=Bang |first2=Jeongho |last3=Lee |first3=Changhyoup |last4=Lee |first4=Jinhyoung |year=2014 |doi=10.1088/1367-2630/16/10/103014|bibcode=2014NJPh...16j3014Y |s2cid=4956424 }}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |arxiv=1706.01561 |last1=Lee|first1=Joong-Sung|last2=Bang|first2=Jeongho|last3=Hong|first3=Sunghyuk|last4=Lee|first4=Changhyoup|last5=Seol|first5=Kang Hee|last6=Lee|first6=Jinhyoung|last7=Lee|first7=Kwang-Geol|title=Experimental demonstration of quantum learning speedup with classical input data|journal=Physical Review A|volume=99|issue=1|pages=012313|year=2019|doi=10.1103/PhysRevA.99.012313|bibcode=2019PhRvA..99a2313L|s2cid=53977163}}&lt;/ref&gt; While machine learning algorithms are used to compute immense quantities of data, quantum machine learning utilizes qubits and quantum operations or specialized quantum systems to improve computational speed and data storage done by algorithms in a program.&lt;ref name=":12"&gt;{{Cite journal|last1=Schuld|first1=Maria|last2=Sinayskiy|first2=Ilya|last3=Petruccione|first3=Francesco|date=2014-10-15|title=An introduction to quantum machine learning|journal=Contemporary Physics|language=en|volume=56|issue=2|pages=172–185|doi=10.1080/00107514.2014.964942|issn=0010-7514|citeseerx=10.1.1.740.5622|bibcode=2015ConPh..56..172S|s2cid=119263556}}&lt;/ref&gt; This includes hybrid methods that involve both classical and quantum processing, where computationally difficult subroutines are outsourced to a quantum device.&lt;ref&gt;{{Cite journal|last1=Benedetti|first1=Marcello|last2=Realpe-Gómez|first2=John|last3=Biswas|first3=Rupak|last4=Perdomo-Ortiz|first4=Alejandro|date=2017-11-30|title=Quantum-Assisted Learning of Hardware-Embedded Probabilistic Graphical Models|arxiv=1609.02542|journal=Physical Review X|volume=7|issue=4|pages=041052|doi=10.1103/PhysRevX.7.041052|issn=2160-3308|bibcode=2017PhRvX...7d1052B|s2cid=55331519}}&lt;/ref&gt;&lt;ref name="Farhi"&gt;{{cite arxiv|last1=Farhi|first1=Edward|last2=Neven|first2=Hartmut|date=2018-02-16|title=Classification with Quantum Neural Networks on Near Term Processors|eprint=1802.06002|class=quant-ph}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Schuld|first1=Maria|last2=Bocharov|first2=Alex|last3=Svore|first3=Krysta|last4=Wiebe|first4=Nathan|title=Circuit-centric quantum classifiers|journal=Physical Review A|year=2020|volume=101|issue=3|pages=032308|doi=10.1103/PhysRevA.101.032308|arxiv=1804.00633|bibcode=2020PhRvA.101c2308S|s2cid=49577148}}&lt;/ref&gt; These routines can be more complex in nature and executed faster on a quantum computer.&lt;ref name=":5" /&gt; Furthermore, quantum algorithms can be used to analyze quantum states instead of classical data.&lt;ref&gt;{{cite journal|last1=Yu|first1=Shang|last2=Albarran-Arriagada|first2=F.|last3=Retamal|first3=J. C.|last4=Wang|first4=Yi-Tao|last5=Liu|first5=Wei|last6=Ke|first6=Zhi-Jin|last7=Meng|first7=Yu|last8=Li|first8=Zhi-Peng|last9=Tang|first9=Jian-Shun|date=2018-08-28|title=Reconstruction of a Photonic Qubit State with Quantum Reinforcement Learning|arxiv=1808.09241|doi=10.1002/qute.201800074|journal=Advanced Quantum Technologies|volume=2|issue=7–8|page=1800074|s2cid=85529734}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Ghosh|first1=Sanjib|last2=Opala|first2=A.|last3=Matuszewski|first3=M.|last4=Paterek|first4= T.|last5= Liew|first5= Timothy C. H.|date=2019|title=Quantum reservoir processing|arxiv=1811.10335|doi=10.1038/s41534-019-0149-8|journal= NPJ Quantum Information|volume=5|pages=35|number=35|bibcode=2019npjQI...5...35G|s2cid=119197635}}&lt;/ref&gt; Beyond quantum computing, the term "quantum machine learning" is also associated with classical machine learning methods applied to data generated from quantum experiments (i.e. ''[[Machine learning in physics|machine learning of quantum systems]]''), such as learning the phase transitions of a quantum system&lt;ref&gt;{{cite arxiv|last1=Broecker|first1=Peter|last2=Assaad|first2=Fakher F.|last3=Trebst|first3=Simon|date=2017-07-03|title=Quantum phase recognition via unsupervised machine learning|eprint=1707.00663|class=cond-mat.str-el}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last1=Huembeli|first1=Patrick|last2=Dauphin|first2=Alexandre|last3=Wittek|first3=Peter|year=2018|title=Identifying Quantum Phase Transitions with Adversarial Neural Networks|arxiv=1710.08382|journal=Physical Review B|volume=97|issue=13|pages=134109|doi=10.1103/PhysRevB.97.134109|issn=2469-9950|bibcode=2018PhRvB..97m4109H}}&lt;/ref&gt; or creating new quantum experiments.&lt;ref name="Krenn 090405"&gt;{{Cite journal|last=Krenn|first=Mario|date=2016-01-01|title=Automated Search for new Quantum Experiments|journal=Physical Review Letters|volume=116|issue=9|pages=090405|arxiv=1509.02749|bibcode=2016PhRvL.116i0405K|doi=10.1103/PhysRevLett.116.090405|pmid=26991161|s2cid=20182586}}&lt;/ref&gt;&lt;ref name="Knott 073033"&gt;{{Cite journal|last=Knott|first=Paul|date=2016-03-22|title=A search algorithm for quantum state engineering and metrology|journal=New Journal of Physics|volume=18|issue=7|pages=073033|arxiv=1511.05327|bibcode=2016NJPh...18g3033K|doi=10.1088/1367-2630/18/7/073033|s2cid=2721958}}&lt;/ref&gt;&lt;ref name=":6"&gt;{{Cite journal|last1=Dunjko|first1=Vedran|last2=Briegel|first2=Hans J|date=2018-06-19|title=Machine learning &amp; artificial intelligence in the quantum domain: a review of recent progress|journal=Reports on Progress in Physics|volume=81|issue=7|pages=074001|doi=10.1088/1361-6633/aab406|pmid=29504942|issn=0034-4885|bibcode=2018RPPh...81g4001D|hdl=1887/71084|s2cid=3681629|hdl-access=free}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last1=Melnikov|first1=Alexey A.|last2=Nautrup|first2=Hendrik Poulsen|last3=Krenn|first3=Mario|last4=Dunjko|first4=Vedran|last5=Tiersch|first5=Markus|last6=Zeilinger|first6=Anton|last7=Briegel|first7=Hans J.|year=1221|title=Active learning machine learns to create new quantum experiments|journal=Proceedings of the National Academy of Sciences|language=en|volume=115|issue=6|pages=1221–1226|doi=10.1073/pnas.1714936115|issn=0027-8424|pmc=5819408|pmid=29348200|arxiv=1706.00868}}&lt;/ref&gt; Quantum machine learning also extends to a branch of research that explores methodological and structural similarities between certain physical systems and learning systems, in particular neural networks. For example, some mathematical and numerical techniques from quantum physics are applicable to classical deep learning and vice versa.&lt;ref&gt;{{cite journal|last1=Huggins|first1=William|last2=Patel|first2=Piyush|last3=Whaley|first3=K. Birgitta|last4=Stoudenmire|first4=E. Miles|date=2018-03-30|title=Towards Quantum Machine Learning with Tensor Networks|journal=Quantum Science and Technology|volume=4|issue=2|pages=024001|arxiv=1803.11537|doi=10.1088/2058-9565/aaea94|s2cid=4531946}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Carleo|first1=Giuseppe|last2=Nomura|first2=Yusuke|last3=Imada|first3=Masatoshi|date=2018-02-26|title=Constructing exact representations of quantum many-body systems with deep neural networks|journal=Nature Communications|volume=9|issue=1|pages=5322|arxiv=1802.09558|doi=10.1038/s41467-018-07520-3|pmid=30552316|pmc=6294148|bibcode=2018NatCo...9.5322C}}&lt;/ref&gt;&lt;ref&gt;{{cite arxiv|last=Bény|first=Cédric|date=2013-01-14|title=Deep learning and the renormalization group|eprint=1301.3124 |class=quant-ph}}&lt;/ref&gt; Furthermore, researchers investigate more abstract notions of learning theory with respect to quantum information, sometimes referred to as "quantum learning theory".&lt;ref&gt;{{cite arxiv|last1=Arunachalam|first1=Srinivasan|last2=de Wolf|first2=Ronald|date=2017-01-24|title=A Survey of Quantum Learning Theory|eprint=1701.06806|class=quant-ph}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last1=Sergioli|first1=Giuseppe|last2=Giuntini|first2=Roberto|last3=Freytes|first3=Hector|date=2019-05-09|title=A new Quantum approach to binary classification|journal=PLOS ONE|volume=14|issue=5|doi=10.1371/journal.pone.0216224|page=e0216224|pmid=31071129|pmc=6508868|bibcode=2019PLoSO..1416224S|doi-access=free}}&lt;/ref&gt;

[[File:Qml approaches.tif|thumb|Four different approaches to combine the disciplines of quantum computing and machine learning.&lt;ref name="AimeurEtAl_2006"&gt;{{Cite book|title=Machine Learning in a Quantum World|last1=Aïmeur|first1=Esma|last2=Brassard|first2=Gilles|last3=Gambs|first3=Sébastien|date=2006-06-07|journal=Advances in Artificial Intelligence|isbn=978-3-540-34628-9|series=Lecture Notes in Computer Science|volume=4013|pages=[https://archive.org/details/advancesinartifi0000cana/page/431 431–442]|language=en|doi=10.1007/11766247_37|url=https://archive.org/details/advancesinartifi0000cana/page/431}}&lt;/ref&gt;&lt;ref name="DunjkoTaylorBriegel"&gt;{{Cite journal|last1=Dunjko|first1=Vedran|last2=Taylor|first2=Jacob M.|last3=Briegel|first3=Hans J.|date=2016-09-20|title=Quantum-Enhanced Machine Learning|journal=Physical Review Letters|volume=117|issue=13|pages=130501|arxiv=1610.08251|bibcode=2016PhRvL.117m0501D|doi=10.1103/PhysRevLett.117.130501|pmid=27715099|s2cid=12698722}}&lt;/ref&gt; The first letter refers to whether the system under study is classical or quantum, while the second letter defines whether a classical or quantum information processing device is used.]]

== Machine learning with quantum computers ==
Quantum-enhanced machine learning refers to [[quantum algorithm]]s that solve tasks in machine learning, thereby improving and often expediting classical machine learning techniques. Such algorithms typically require one to encode the given classical data set into a quantum computer to make it accessible for quantum information processing. Subsequently, quantum information processing routines are applied and the result of the quantum computation is read out by measuring the quantum system. For example, the outcome of the measurement of a qubit reveals the result of a binary classification task. While many proposals of quantum machine learning algorithms are still purely theoretical and require a full-scale universal [[quantum computer]] to be tested, others have been implemented on small-scale or special purpose quantum devices.

=== Linear algebra simulation with quantum amplitudes ===

A number of quantum algorithms for machine learning are based on the idea of ''amplitude encoding'', that is, to associate the [[Probability amplitude|amplitudes]] of a quantum state with the inputs and outputs of computations.&lt;ref name="Patrick Rebentrost 2014"&gt;{{cite journal |doi=10.1103/PhysRevLett.113.130503|pmid=25302877|title=Quantum Support Vector Machine for Big Data Classification|journal=Physical Review Letters|volume=113|issue=13|pages=130503|year=2014|last1=Rebentrost|first1=Patrick|last2=Mohseni|first2=Masoud|last3=Lloyd|first3=Seth|bibcode=2014PhRvL.113m0503R|arxiv=1307.0471|hdl=1721.1/90391|s2cid=5503025}}&lt;/ref&gt;&lt;ref name="Nathan Wiebe 2012"&gt;{{cite journal |doi=10.1103/PhysRevLett.109.050505|pmid=23006156|title=Quantum Algorithm for Data Fitting|journal=Physical Review Letters|volume=109|issue=5|pages=050505|year=2012|last1=Wiebe|first1=Nathan|last2=Braun|first2=Daniel|last3=Lloyd|first3=Seth|bibcode=2012PhRvL.109e0505W|arxiv=1204.5242}}&lt;/ref&gt;&lt;ref name="Maria Schuld 2016"&gt;{{cite journal |doi=10.1103/PhysRevA.94.022342|title=Prediction by linear regression on a quantum computer|journal=Physical Review A|volume=94|issue=2|pages=022342|year=2016|last1=Schuld|first1=Maria|last2=Sinayskiy|first2=Ilya|last3=Petruccione|first3=Francesco|bibcode=2016PhRvA..94b2342S|arxiv=1601.07823|s2cid=118459345}}&lt;/ref&gt;&lt;ref name="ReferenceA"&gt;{{cite journal |arxiv=1512.03929 |last1=Zhao |first1=Zhikuan |title=Quantum assisted Gaussian process regression |journal=Physical Review A |volume=99 |issue=5 |pages=052331 |last2=Fitzsimons |first2=Jack K. |last3=Fitzsimons |first3=Joseph F. |year=2019|doi=10.1103/PhysRevA.99.052331 |bibcode=2019PhRvA..99e2331Z |s2cid=18303333 }}&lt;/ref&gt; Since a state of &lt;math&gt;n&lt;/math&gt; qubits is described by &lt;math&gt;2^n&lt;/math&gt; complex amplitudes, this information encoding can allow for an exponentially compact representation. Intuitively, this corresponds to associating a discrete probability distribution over binary random variables with a classical vector. The goal of algorithms based on amplitude encoding is to formulate quantum algorithms whose resources grow polynomially in the number of qubits &lt;math&gt;n&lt;/math&gt;, which amounts to a logarithmic growth in the number of amplitudes and thereby the dimension of the input.

Many quantum machine learning algorithms in this category are based on variations of the [[quantum algorithm for linear systems of equations]]&lt;ref&gt;{{Cite journal |arxiv=0811.3171 |last1=Harrow |first1=Aram W. |title=Quantum algorithm for solving linear systems of equations |journal=Physical Review Letters |volume=103 |issue=15 |pages=150502 |last2=Hassidim |first2=Avinatan |last3=Lloyd |first3=Seth |year=2008 |doi=10.1103/PhysRevLett.103.150502|pmid=19905613 |bibcode=2009PhRvL.103o0502H |s2cid=5187993 }}&lt;/ref&gt; (colloquially called HHL, after the paper's authors) which, under specific conditions, performs a matrix inversion using an amount of physical resources growing only logarithmically in the dimensions of the matrix. One of these conditions is that a Hamiltonian which entrywise corresponds to the matrix can be simulated efficiently, which is known to be possible if the matrix is sparse&lt;ref&gt;{{cite conference |title=Hamiltonian simulation with nearly optimal dependence on all parameters |last1=Berry |first1= Dominic W.|last2=Childs |first2=Andrew M.|last3=Kothari|first3=Robin|date=2015 |publisher=IEEE |pages=792–809 |conference= 56th Annual Symposium on Foundations of Computer Science|doi=10.1109/FOCS.2015.54|arxiv=1501.01715}}&lt;/ref&gt; or low rank.&lt;ref&gt;{{cite journal |doi=10.1038/nphys3029|title=Quantum principal component analysis|journal=Nature Physics|volume=10|issue=9|pages=631|year=2014|last1=Lloyd|first1=Seth|last2=Mohseni|first2=Masoud|last3=Rebentrost|first3=Patrick|bibcode=2014NatPh..10..631L|arxiv=1307.0401|citeseerx=10.1.1.746.480|s2cid=11553314}}&lt;/ref&gt; For reference, any known classical algorithm for [[matrix inversion]] requires a number of operations that grows [[Computational complexity of mathematical operations#Matrix algebra|at least quadratically in the dimension of the matrix]], but they are not restricted to sparse matrices.

Quantum matrix inversion can be applied to machine learning methods in which the training reduces to solving a [[System of linear equations|linear system of equations]], for example in least-squares linear regression,&lt;ref name="Nathan Wiebe 2012" /&gt;&lt;ref name="Maria Schuld 2016" /&gt; the least-squares version of [[support vector machine]]s,&lt;ref name="Patrick Rebentrost 2014" /&gt; and Gaussian processes.&lt;ref name="ReferenceA" /&gt;

A crucial bottleneck of methods that simulate linear algebra computations with the amplitudes of quantum states is state preparation, which often requires one to initialise a quantum system in a state whose amplitudes reflect the features of the entire dataset. Although efficient methods for state preparation are known for specific cases,&lt;ref&gt;{{cite journal |doi=10.1103/PhysRevA.73.012307|title=Efficient state preparation for a register of quantum bits|journal=Physical Review A|volume=73|issue=1|pages=012307|year=2006|last1=Soklakov|first1=Andrei N.|last2=Schack|first2=Rüdiger|bibcode=2006PhRvA..73a2307S|arxiv=quant-ph/0408045}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |doi=10.1103/PhysRevLett.100.160501|pmid=18518173|title=Quantum Random Access Memory|journal=Physical Review Letters|volume=100|issue=16|pages=160501|year=2008|last1=Giovannetti|first1=Vittorio|last2=Lloyd|first2=Seth|last3=MacCone|first3=Lorenzo|bibcode=2008PhRvL.100p0501G|arxiv=0708.1879|s2cid=570390}}&lt;/ref&gt; this step easily hides the complexity of the task.&lt;ref&gt;{{Cite journal |doi=10.1038/nphys3272|title=Read the fine print|journal=Nature Physics|volume=11|issue=4|pages=291–293|year=2015|last1=Aaronson|first1=Scott|bibcode=2015NatPh..11..291A}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |doi=10.1103/PhysRevA.99.012326|title=Optimal usage of quantum random access memory in quantum machine learning
|journal=Physical Review A|volume=99|issue=1|pages=012326|year=2019|last1=Bang|first1=Jeongho|last2=Dutta|first2=Arijit|last3=Lee|first3=Seung-Woo|last4=Kim|first4=Jaewan|arxiv=1809.04814
|bibcode=2019PhRvA..99a2326B
|s2cid=62841090
}}&lt;/ref&gt;

=== Quantum machine learning algorithms based on Grover search ===
Another approach to improving classical machine learning with quantum information processing uses [[amplitude amplification]] methods based on [[Grover's algorithm|Grover's search]] algorithm, which has been shown to solve unstructured search problems with a quadratic speedup compared to classical algorithms. These quantum routines can be employed for learning algorithms that translate into an unstructured search task, as can be done, for instance, in the case of the [[K-medians clustering|k-medians]]&lt;ref name=":0"&gt;{{Cite journal|last1=Aïmeur|first1=Esma|last2=Brassard|first2=Gilles|last3=Gambs|first3=Sébastien|date=2013-02-01|title=Quantum speed-up for unsupervised learning|journal=Machine Learning|language=en|volume=90|issue=2|pages=261–287|doi=10.1007/s10994-012-5316-5|issn=0885-6125|doi-access=free}}&lt;/ref&gt; and the [[k-nearest neighbour|k-nearest neighbors algorithms]].&lt;ref name="Nathan Wiebe 2014" /&gt; Another application is a quadratic speedup in the training of [[perceptrons|perceptron]].&lt;ref name=wiebe2016nips&gt;{{cite conference |arxiv=1602.04799|last1=Wiebe|first1=Nathan|title=Quantum Perceptron Models|last2=Kapoor|first2=Ashish|last3=Svore|first3=Krysta M.|conference=Advances in Neural Information Processing Systems|volume=29|pages=3999–4007|url=https://papers.nips.cc/paper/6401-quantum-perceptron-models|bibcode=2016arXiv160204799W|year=2016}}&lt;/ref&gt;

An example of amplitude amplification being used in a machine learning algorithm is Grover's search algorithm minimization. In which a subroutine uses Grover's search algorithm to find an element less than some previously defined element. This can be done with an oracle that determines whether or not a state with a corresponding element is less than the predefined one. Grover's algorithm can then find an element such that our condition is met. The minimization is initialized by some random element in our data set, and iteratively does this subroutine to find the minimum element in the data set. This minimization is notably used in quantum k-medians, and it has a speed up of at least &lt;math&gt;O(\sqrt{n/k})&lt;/math&gt; compared to classical versions of k-medians, where &lt;math&gt;n&lt;/math&gt; is the number of data points and &lt;math&gt;k&lt;/math&gt; is the number of clusters.&lt;ref name=":0" /&gt;

Amplitude amplification is often combined with [[quantum walk]]s to achieve the same quadratic speedup. Quantum walks have been proposed to enhance Google's PageRank algorithm&lt;ref&gt;{{cite journal |doi= 10.1038/srep00444|pmid= 22685626|pmc= 3370332|title= Google in a Quantum Network|journal= Scientific Reports|volume= 2|issue= 444|pages= 444|year= 2012|last1= Paparo|first1= Giuseppe Davide|last2= Martin-Delgado|first2= Miguel Angel|bibcode= 2012NatSR...2E.444P|arxiv= 1112.2079}}&lt;/ref&gt; as well as the performance of reinforcement learning agents in the projective simulation framework.&lt;ref name=paparo2014quantum&gt;{{cite journal |doi=10.1103/PhysRevX.4.031002|title=Quantum Speedup for Active Learning Agents|journal=Physical Review X|volume=4|issue=3|pages=031002|year=2014|last1=Paparo|first1=Giuseppe Davide|last2=Dunjko|first2=Vedran|last3=Makmal|first3=Adi|last4=Martin-Delgado|first4=Miguel Angel|last5=Briegel|first5=Hans J.|bibcode=2014PhRvX...4c1002P|arxiv=1401.4997|s2cid=54652978}}&lt;/ref&gt;

=== Quantum-enhanced reinforcement learning ===
[[Reinforcement learning]] is a branch of machine learning distinct from supervised and unsupervised learning, which also admits quantum enhancements.&lt;ref&gt;{{Cite journal|last2=Chen|first2=Chunlin|last3=Li|first3=Hanxiong|last4=Tarn|first4=Tzyh-Jong|year=2008|title=Quantum Reinforcement Learning|journal=IEEE Transactions on Systems, Man, and Cybernetics – Part B: Cybernetics|volume=38|issue=5|pages=1207–1220|doi=10.1109/TSMCB.2008.925743|pmid=18784007|first1=Daoyi|last1=Dong|arxiv=0810.3828|citeseerx=10.1.1.243.5369}}&lt;/ref&gt;&lt;ref name="paparo2014quantum" /&gt;&lt;ref&gt;{{cite  arxiv|eprint=1612.05695|last1=Crawford|first1=Daniel|title=Reinforcement Learning Using Quantum Boltzmann Machines|last2=Levit|first2=Anna|last3=Ghadermarzy|first3=Navid|last4=Oberoi|first4=Jaspreet S.|last5=Ronagh|first5=Pooya|class=quant-ph|year=2018}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last1=Briegel|first1=Hans J.|last2=Cuevas|first2=Gemma De las|date=2012-05-15|title=Projective simulation for artificial intelligence|journal=Scientific Reports|language=en|volume=2|issue=400|pages=400|doi=10.1038/srep00400|issn=2045-2322|pmc=3351754|pmid=22590690|arxiv=1104.3787|bibcode=2012NatSR...2E.400B}}&lt;/ref&gt; In quantum-enhanced reinforcement learning, a quantum agent interacts with a classical environment and occasionally receives rewards for its actions, which allows the agent to adapt its behavior—in other words, to learn what to do in order to gain more rewards. In some situations, either because of the quantum processing capability of the agent,&lt;ref name="paparo2014quantum" /&gt; or due to the possibility to probe the environment in [[Quantum superposition|superpositions]],&lt;ref name="DunjkoTaylorBriegel" /&gt; a quantum speedup may be achieved. Implementations of these kinds of protocols in superconducting circuits&lt;ref&gt;{{cite journal|last1=Lamata|first1=Lucas|title=Basic protocols in quantum reinforcement learning with superconducting circuits|journal=Scientific Reports|volume=7|issue=1|pages=1609|doi=10.1038/s41598-017-01711-6|pmid=28487535|pmc=5431677|year=2017|arxiv=1701.05131|bibcode=2017NatSR...7.1609L}}&lt;/ref&gt; and in systems of trapped ions&lt;ref&gt;{{Cite journal|last1=Dunjko|first1=V.|last2=Friis|first2=N.|last3=Briegel|first3=H. J.|date=2015-01-01|title=Quantum-enhanced deliberation of learning agents using trapped ions|journal=New Journal of Physics|language=en|volume=17|issue=2|pages=023006|doi=10.1088/1367-2630/17/2/023006|issn=1367-2630|arxiv=1407.2830|bibcode=2015NJPh...17b3006D|s2cid=119292539}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last1=Sriarunothai|first1=Th.|last2=Wölk|first2=S.|last3=Giri|first3=G. S.|last4=Friis|first4=N.|last5=Dunjko|first5=V.|last6=Briegel|first6=H. J.|last7=Wunderlich|first7=Ch.|date=2019|title=Speeding-up the decision making of a learning agent using an ion trap quantum processor|journal=Quantum Science and Technology|language=en|volume=4|issue=1|pages=015014|doi=10.1088/2058-9565/aaef5e|issn=2058-9565|arxiv=1709.01366|bibcode=2019QS&amp;T....4a5014S|s2cid=2429346}}&lt;/ref&gt; have been proposed.

=== Quantum annealing ===
{{Main|Quantum annealing}}
[[Quantum annealing]] is an optimization technique used to determine the local minima and maxima of a function over a given set of candidate functions. This is a method of discretizing a function with many local minima or maxima in order to determine the observables of the function. The process can be distinguished from [[Simulated annealing]] by the [[Quantum tunnelling|Quantum tunneling]] process, by which particles tunnel through kinetic or potential barriers from a high state to a low state. Quantum annealing starts from a superposition of all possible states of a system, weighted equally. Then the time-dependent [[Schrödinger equation]] guides the time evolution of the system, serving to affect the amplitude of each state as time increases. Eventually, the ground state can be reached to yield the instantaneous Hamiltonian of the system.

=== Quantum sampling techniques ===
Sampling from high-dimensional probability distributions is at the core of a wide spectrum of computational techniques with important applications across science, engineering, and society. Examples include [[deep learning]], [[probabilistic programming]], and other machine learning and artificial intelligence applications.

A computationally hard problem, which is key for some relevant machine learning tasks, is the estimation of averages over probabilistic models defined in terms of a [[Boltzmann distribution]]. Sampling from generic probabilistic models is hard: algorithms relying heavily on sampling are expected to remain intractable no matter how large and powerful classical computing resources become. Even though [[quantum annealing|quantum annealers]], like those produced by D-Wave Systems, were designed for challenging combinatorial optimization problems, it has been recently recognized as a potential candidate to speed up computations that rely on sampling by exploiting quantum effects.&lt;ref&gt;{{cite journal |last1=Biswas |first1=Rupak |last2=Jiang |first2=Zhang |last3=Kechezi |first3=Kostya |last4=Knysh |first4=Sergey |last5=Mandrà |first5=Salvatore |last6=O’Gorman |first6=Bryan |last7=Perdomo-Ortiz |first7=Alejando |last8=Pethukov |first8=Andre |last9=Realpe-Gómez |first9=John |last10=Rieffel |first10=Eleanor|author1-link= Eleanor Rieffel |last11=Venturelli|first11=Davide|last12=Vasko|first12=Fedir|last13=Wang|first13=Zhihui |title=A NASA perspective on quantum computing: Opportunities and challenges |year=2016|doi=10.1016/j.parco.2016.11.002|journal=Parallel Computing|volume=64 |pages=81–98 |url=https://zenodo.org/record/1259293 |arxiv=1704.04836 |s2cid=27547901 }}&lt;/ref&gt;

Some research groups have recently explored the use of quantum annealing hardware for training [[Boltzmann machine]]s and [[deep neural networks]].&lt;ref name=Adachi2015&gt;{{cite arXiv |last1=Adachi |first1=Steven H. |last2=Henderson |first2=Maxwell P. |date=2015 |title=Application of quantum annealing to training of deep neural networks |eprint=1510.06356 |class=quant-ph}}&lt;/ref&gt;&lt;ref name=Benedetti2016a&gt;{{Cite journal|last1=Benedetti |first1=Marcello |last2=Realpe-Gómez |first2=John |last3=Biswas |first3=Rupak |last4=Perdomo-Ortiz |first4=Alejandro |year=2017 |title=Quantum-assisted learning of graphical models with arbitrary pairwise connectivity |journal=Physical Review X |volume=7 |issue=4 |pages=041052 |arxiv=1609.02542 |doi=10.1103/PhysRevX.7.041052 |bibcode=2017PhRvX...7d1052B |s2cid=55331519 }}&lt;/ref&gt;&lt;ref name=Benedetti2016b&gt;{{cite journal |last1=Benedetti |first1=Marcello |last2=Realpe-Gómez |first2=John |last3=Biswas |first3=Rupak |last4=Perdomo-Ortiz |first4=Alejandro |date=2016 |title=Estimation of effective temperatures in quantum annealers for sampling applications: A case study with possible applications in deep learning |journal=Physical Review A |doi=10.1103/PhysRevA.94.022308 |volume=94 |issue=2 |pages=022308 |bibcode=2016PhRvA..94b2308B|arxiv=1510.07611 |s2cid=118602077 }}&lt;/ref&gt;&lt;ref name="William G 1611"&gt;{{cite arXiv |last1=Korenkevych |first1=Dmytro |last2=Xue |first2=Yanbo |last3=Bian |first3=Zhengbing |last4=Chudak |first4=Fabian |last5=Macready |first5=William G. |last6=Rolfe |first6=Jason |last7=Andriyash |first7=Evgeny |date=2016 |title=Benchmarking quantum hardware for training of fully visible Boltzmann machines |eprint=1611.04528 |class=quant-ph}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last1=Khoshaman|first1=Amir|last2=Vinci|first2=Walter|last3=Denis|first3=Brandon|last4=Andriyash|first4=Evgeny|last5=Amin|first5=Mohammad H|year=2019|title=Quantum variational autoencoder|journal=Quantum Science and Technology|volume=4|issue=1|pages=014001|doi=10.1088/2058-9565/aada1f|issn=2058-9565|arxiv=1802.05779|bibcode=2019QS&amp;T....4a4001K|s2cid=3376805}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last1=Ajagekar|first1=Akshay|last2=You|first2=Fengqi|date=2020-12-05|title=Quantum computing assisted deep learning for fault detection and diagnosis in industrial process systems|url=http://www.sciencedirect.com/science/article/pii/S0098135420308322|journal=Computers &amp; Chemical Engineering|language=en|volume=143|pages=107119|doi=10.1016/j.compchemeng.2020.107119|issn=0098-1354|arxiv=2003.00264|s2cid=211678230}}&lt;/ref&gt; The standard approach to training Boltzmann machines relies on the computation of certain averages that can be estimated by standard [[Gibbs sampling|sampling]] techniques, such as [[Markov chain Monte Carlo]] algorithms. Another possibility is to rely on a physical process, like quantum annealing, that naturally generates samples from a Boltzmann distribution. The objective is to find the optimal control parameters that best represent the empirical distribution of a given dataset.

The D-Wave 2X system hosted at NASA Ames Research Center has been recently used for the learning of a special class of restricted Boltzmann machines that can serve as a building block for deep learning architectures.&lt;ref name=Benedetti2016b /&gt; Complementary work that appeared roughly simultaneously showed that quantum annealing can be used for supervised learning in classification tasks.&lt;ref name=Adachi2015 /&gt; The same device was later used to train a fully connected Boltzmann machine to generate, reconstruct, and classify down-scaled, low-resolution handwritten digits, among other synthetic datasets.&lt;ref name=Benedetti2016a /&gt; In both cases, the models trained by quantum annealing had a similar or better performance in terms of quality. The ultimate question that drives this endeavour is whether there is quantum speedup in sampling applications. Experience with the use of quantum annealers for combinatorial optimization suggests the answer is not straightforward.

Inspired by the success of Boltzmann machines based on classical Boltzmann distribution, a new machine learning approach based on quantum Boltzmann distribution of a transverse-field Ising Hamiltonian was recently proposed.&lt;ref&gt;{{Cite journal |last1=Amin |first1=Mohammad H. |last2=Andriyash |first2=Evgeny |last3=Rolfe |first3=Jason |last4=Kulchytskyy |first4=Bohdan |last5=Melko |first5=Roger |year=2018 |title=Quantum Boltzmann machines |journal=Phys. Rev. X |volume=8 |issue=21050 |pages=021050 |arxiv=1601.02036 |doi=10.1103/PhysRevX.8.021050 |bibcode=2018PhRvX...8b1050A |s2cid=119198869 }}&lt;/ref&gt; Due to the non-commutative nature of quantum mechanics, the training process of the quantum Boltzmann machine can become nontrivial. This problem was, to some extent, circumvented by introducing bounds on the quantum probabilities, allowing the authors to train the model efficiently by sampling. It is possible that a specific type of quantum Boltzmann machine has been trained in the D-Wave 2X by using a learning rule analogous to that of classical Boltzmann machines.&lt;ref name=Benedetti2016a /&gt;&lt;ref name="William G 1611" /&gt;&lt;ref&gt;{{Cite web|url=https://archive.is/jzQ7n|title=Phys. Rev. E 72, 026701 (2005): Quantum annealing in a kinetically co…|date=2014-01-13|website=archive.is|access-date=2018-12-07}}&lt;/ref&gt;

[[Quantum annealing]] is not the only technology for sampling. In a prepare-and-measure scenario, a universal quantum computer prepares a thermal state, which is then sampled by measurements. This can reduce the time required to train a deep restricted Boltzmann machine, and provide a richer and more comprehensive framework for deep learning than classical computing.&lt;ref&gt;{{cite arXiv |last1=Wiebe |first1=Nathan |last2=Kapoor |first2=Ashish |last3=Svore |first3=Krysta M. |date=2014 |title=Quantum deep learning |eprint=1412.3489 |class=quant-ph}}&lt;/ref&gt; The same quantum methods also permit efficient training of full Boltzmann machines and multi-layer, fully connected models and do not have well-known classical counterparts. Relying on an efficient thermal state preparation protocol starting from an arbitrary state, quantum-enhanced [[Markov logic network]]s exploit the symmetries and the locality structure of the [[Graphical model|probabilistic graphical model]] generated by a [[first-order logic]] template.&lt;ref&gt;{{cite journal |last1=Wittek |first1=Peter |last2=Gogolin |first2=Christian |date=2017 |title=Quantum Enhanced Inference in Markov Logic Networks |journal=Scientific Reports|doi=10.1038/srep45672|pmid=28422093 |pmc=5395824 |volume=7|issue=45672 |page=45672 |arxiv=1611.08104|bibcode=2017NatSR...745672W}}&lt;/ref&gt; This provides an exponential reduction in computational complexity in probabilistic inference, and, while the protocol relies on a universal quantum computer, under mild assumptions it can be embedded on contemporary quantum annealing hardware.

=== Quantum neural networks ===
{{Main|Quantum neural network|}}

Quantum analogues or generalizations of classical neural nets are often referred to as [[quantum neural network]]s. The term is claimed by a wide range of approaches, including the implementation and extension of neural networks using photons, layered variational circuits or quantum Ising-type models. Quantum neural networks are often defined as an expansion on Deutsch's model of a quantum computational network.&lt;ref name=":13"&gt;{{Cite journal|date=2001-11-01|title=Quantum Neural Networks|journal=Journal of Computer and System Sciences|language=en|volume=63|issue=3|pages=355–383|doi=10.1006/jcss.2001.1769|issn=0022-0000|last1=Gupta|first1=Sanjay|last2=Zia|first2=R.K.P.|arxiv=quant-ph/0201144|s2cid=206569020}}&lt;/ref&gt; Within this model, nonlinear and irreversible gates, dissimilar to the Hamiltonian operator, are deployed to speculate the given data set.&lt;ref name=":13" /&gt; Such gates make certain phases unable to be observed and generate specific oscillations.&lt;ref name=":13" /&gt; Quantum neural networks apply the principals quantum information and quantum computation to classical neurocomputing.&lt;ref name=":03"&gt;{{Citation|last1=Ezhov|first1=Alexandr A.|title=Quantum Neural Networks|date=2000|work=Future Directions for Intelligent Systems and Information Sciences|pages=213–235|publisher=Physica-Verlag HD|language=en|doi=10.1007/978-3-7908-1856-7_11|isbn=978-3-7908-2470-4|last2=Ventura|first2=Dan|citeseerx=10.1.1.683.5972}}&lt;/ref&gt; Current research shows that QNN can exponentially increase the amount of computing power and the degrees of freedom for a computer, which is limited for a classical computer to its size.&lt;ref name=":03" /&gt; A quantum neural network has computational capabilities to decrease the number of steps, qubits used, and computation time.&lt;ref name=":13" /&gt; The wave function to quantum mechanics is the neuron for Neural networks. To test quantum applications in a neural network, quantum dot molecules are deposited on a substrate of GaAs or similar to record how they communicate with one another. Each quantum dot can be referred as an island of electric activity, and when such dots are close enough (approximately 10±20&amp;nbsp;nm)&lt;ref name=":23"&gt;{{Cite journal|date=2000-10-01|title=Simulations of quantum neural networks|journal=Information Sciences|language=en|volume=128|issue=3–4|pages=257–269|doi=10.1016/S0020-0255(00)00056-6|issn=0020-0255|last1=Behrman|first1=E.C.|last2=Nash|first2=L.R.|last3=Steck|first3=J.E.|last4=Chandrashekar|first4=V.G.|last5=Skinner|first5=S.R.}}&lt;/ref&gt; electrons can tunnel underneath the islands. An even distribution across the substrate in sets of two create dipoles and ultimately two spin states, up or down. These states are commonly known as qubits with corresponding states of &lt;math&gt;|0\rangle&lt;/math&gt;  and &lt;math&gt;|1\rangle&lt;/math&gt; in Dirac notation.&lt;ref name=":23" /&gt;

=== Hidden Quantum Markov Models ===
Hidden Quantum Markov Models&lt;ref&gt;{{cite book|last1=Clark|first1=Lewis A.|last2=Huang W.|first2=Wei|last3=Barlow|first3=Thomas H.|last4=Beige|first4=Almut|editor1-last=Sanayei|editor1-first=Ali|editor2-last=Rössler|editor2-first=Otto E.|editor3-last=Zelinka|editor3-first=Ivan|title=ISCS 2014: Interdisciplinary Symposium on Complex Systems. Emergence, Complexity and Computation|journal=Iscs, P. 143, Springer (2015)|volume=14|issue=14|isbn=978-3-319-10759-2|pages=131–151|chapter=Hidden Quantum Markov Models and Open Quantum Systems with Instantaneous Feedback|arxiv=1406.5847|doi=10.1007/978-3-319-10759-2_16|series=Emergence, Complexity and Computation|year=2015|citeseerx=10.1.1.749.3332|s2cid=119226526}}&lt;/ref&gt; (HQMMs) are a quantum-enhanced version of classical [[Hidden Markov model|Hidden Markov Models]] (HMMs), which are typically used to model sequential data in various fields like [[robotics]] and [[Natural-language processing|natural language processing]]. Unlike the approach taken by other quantum-enhanced machine learning algorithms, HQMMs can be viewed as models inspired by quantum mechanics that can be run on classical computers as well.&lt;ref name=":4"&gt;{{Cite journal|last1=Srinivasan|first1=Siddarth|last2=Gordon|first2=Geoff|last3=Boots|first3=Byron|date=2018|title=Learning Hidden Quantum Markov Models|url=https://www.cc.gatech.edu/~bboots3/files/learning_hqmms.pdf|journal=Aistats}}&lt;/ref&gt; Where classical HMMs use probability vectors to represent hidden 'belief' states, HQMMs use the quantum analogue: [[Density matrix|density matrices]]. Recent work has shown that these models can be successfully learned by maximizing the log-likelihood of the given data via classical optimization, and there is some empirical evidence that these models can better model sequential data compared to classical HMMs in practice, although further work is needed to determine exactly when and how these benefits are derived.&lt;ref name=":4" /&gt; Additionally, since classical HMMs are a particular kind of [[Bayesian network|Bayes net]], an exciting aspect of HQMMs is that the techniques used show how we can perform quantum-analogous [[Bayesian inference]], which should allow for the general construction of the quantum versions of [[Graphical model|probabilistic graphical models]].&lt;ref name=":4" /&gt;

=== Fully quantum machine learning ===
In the most general case of quantum machine learning, both the learning device and the system under study, as well as their interaction, are fully quantum. This section gives a few examples of results on this topic.

One class of problem that can benefit from the fully quantum approach is that of 'learning' unknown quantum states, processes or measurements, in the sense that one can subsequently reproduce them on another quantum system. For example, one may wish to learn a measurement that discriminates between two coherent states, given not a classical description of the states to be discriminated, but instead a set of example quantum systems prepared in these states. The naive approach would be to first extract a classical description of the states and then implement an ideal discriminating measurement based on this information. This would only require classical learning. However, one can show that a fully quantum approach is strictly superior in this case.&lt;ref&gt;{{cite journal|last1=Sentís|first1=Gael|last2=Guţă|first2=Mădălin|last3=Adesso|first3=Gerardo|date=9 July 2015|title=Quantum learning of coherent states|journal=EPJ Quantum Technology|volume=2|issue=1|doi=10.1140/epjqt/s40507-015-0030-4|doi-access=free}}&lt;/ref&gt; (This also relates to work on quantum pattern matching.&lt;ref&gt;{{cite journal|last1=Sasaki|first1=Masahide|last2=Carlini|first2=Alberto|date=6 August 2002|title=Quantum learning and universal quantum matching machine|journal=Physical Review A|volume=66|issue=2|pages=022303|arxiv=quant-ph/0202173|bibcode=2002PhRvA..66b2303S|doi=10.1103/PhysRevA.66.022303|s2cid=119383508}}&lt;/ref&gt;) The problem of learning unitary transformations can be approached in a similar way.&lt;ref&gt;{{cite journal|last1=Bisio|first1=Alessandro|last2=Chiribella|first2=Giulio|last3=D’Ariano|first3=Giacomo Mauro|last4=Facchini|first4=Stefano|last5=Perinotti|first5=Paolo|date=25 March 2010|title=Optimal quantum learning of a unitary transformation|journal=Physical Review A|volume=81|issue=3|pages=032324|arxiv=0903.0543|bibcode=2010PhRvA..81c2324B|doi=10.1103/PhysRevA.81.032324|s2cid=119289138}}&lt;/ref&gt;

Going beyond the specific problem of learning states and transformations, the task of [[quantum clustering|clustering]] also admits a fully quantum version, wherein both the oracle which returns the distance between data-points and the information processing device which runs the algorithm are quantum.&lt;ref&gt;{{Cite book|title=Quantum Clustering Algorithms|last1=Aïmeur|first1=Esma|last2=Brassard|first2=Gilles|last3=Gambs|first3=Sébastien|date=1 January 2007|journal=Proceedings of the 24th International Conference on Machine Learning|isbn=978-1-59593-793-3|pages=1–8|citeseerx=10.1.1.80.9513|doi=10.1145/1273496.1273497|s2cid=4357684}}&lt;/ref&gt; Finally, a general framework spanning supervised, unsupervised and reinforcement learning in the fully quantum setting was introduced in,&lt;ref name="DunjkoTaylorBriegel" /&gt; where it was also shown that the possibility of probing the environment in superpositions permits a quantum speedup in reinforcement learning.

== Classical learning applied to quantum problems ==
{{Further|Machine learning in physics}}

The term "quantum machine learning" sometimes refers to ''classical'' machine learning performed on data from quantum systems. A basic example of this is [[quantum tomography|quantum state tomography]], where a quantum state is learned from measurement. Other applications include learning Hamiltonians&lt;ref&gt;{{Cite journal|last1=Cory|first1=D. G.|last2=Wiebe|first2=Nathan|last3=Ferrie|first3=Christopher|last4=Granade|first4=Christopher E.|date=2012-07-06|title=Robust Online Hamiltonian Learning|journal=New Journal of Physics|volume=14|issue=10|pages=103013|language=en|doi=10.1088/1367-2630/14/10/103013|arxiv=1207.1655|bibcode=2012NJPh...14j3013G|s2cid=9928389}}&lt;/ref&gt; and automatically generating quantum experiments.&lt;ref name="Krenn 090405" /&gt;

== Quantum learning theory ==
Quantum learning theory pursues a mathematical analysis of the quantum generalizations of classical learning models and of the possible speed-ups or other improvements that they may provide. The framework is very similar to that of classical [[computational learning theory]], but the learner in this case is a quantum information processing device, while the data may be either classical or quantum. Quantum learning theory should be contrasted with the quantum-enhanced machine learning discussed above, where the goal was to consider ''specific problems'' and to use quantum protocols to improve the time complexity of classical algorithms for these problems. Although quantum learning theory is still under development, partial results in this direction have been obtained.&lt;ref&gt;{{cite arXiv|class=quant-ph|first2=Ronald|last2=de Wolf|title=A Survey of Quantum Learning Theory|date=2017|last1=Arunachalam|first1=Srinivasan|eprint=1701.06806}}&lt;/ref&gt;

The starting point in learning theory is typically a ''concept class'', a set of possible concepts. Usually a concept is a function on some domain, such as &lt;math&gt;\{0,1\}^n&lt;/math&gt;. For example, the concept class could be the set of [[disjunctive normal form]] (DNF) formulas on ''n'' bits or the set of Boolean circuits of some constant depth. The goal for the learner is to learn (exactly or approximately) an unknown ''target concept'' from this concept class. The learner may be actively interacting with the target concept, or passively receiving samples from it.

In active learning, a learner can make ''membership queries'' to the target concept ''c'', asking for its value ''c(x)'' on inputs ''x'' chosen by the learner. The learner then has to reconstruct the exact target concept, with high probability. In the model of ''quantum exact learning'', the learner can make membership queries in quantum superposition. If the complexity of the learner is measured by the number of membership queries it makes, then quantum exact learners can be polynomially more efficient than classical learners for some concept classes, but not more.&lt;ref name="gortlerservedioquantum"&gt;{{cite journal|last2=Gortler|first2=Steven J.|year=2004|title=Equivalences and Separations Between Quantum and Classical Learnability|journal=SIAM Journal on Computing|volume=33|issue=5|pages=1067–1092|doi=10.1137/S0097539704412910|last1=Servedio|first1=Rocco A.|citeseerx=10.1.1.69.6555}}&lt;/ref&gt; If complexity is measured by the amount of ''time'' the learner uses, then there are concept classes that can be learned efficiently by quantum learners but not by classical learners (under plausible complexity-theoretic assumptions).&lt;ref name="gortlerservedioquantum" /&gt;

A natural model of passive learning is Valiant's [[probably approximately correct learning|probably approximately correct (PAC) learning]]. Here the learner receives random examples ''(x,c(x))'', where ''x'' is distributed according to some unknown distribution ''D''. The learner's goal is to output a hypothesis function ''h'' such that ''h(x)=c(x)'' with high probability when ''x'' is drawn according to ''D''. The learner has to be able to produce such an 'approximately correct' ''h'' for every ''D'' and every target concept ''c'' in its concept class. We can consider replacing the random examples by potentially more powerful quantum examples &lt;math&gt;\sum_x \sqrt{D(x)}|x,c(x)\rangle&lt;/math&gt;. In the PAC model (and the related agnostic model), this doesn't significantly reduce the number of examples needed: for every concept class, classical and quantum sample complexity are the same up to constant factors.&lt;ref&gt;{{cite arXiv|class=quant-ph|first2=Ronald|last2=de Wolf|title=Optimal Quantum Sample Complexity of Learning Algorithms|date=2016|last1=Arunachalam|first1=Srinivasan|eprint=1607.00932}}&lt;/ref&gt; However, for learning under some fixed distribution ''D'', quantum examples can be very helpful, for example for learning DNF under the uniform distribution.&lt;ref&gt;{{cite journal|last2=Jeffrey|first2=Jackson C.|year=1999|title=Learning DNF over the Uniform Distribution Using a Quantum Example Oracle|journal=SIAM Journal on Computing|volume=28|issue=3|pages=1136–1153|doi=10.1137/S0097539795293123|last1=Nader|first1=Bshouty H.|citeseerx=10.1.1.23.5709}}&lt;/ref&gt; When considering ''time'' complexity, there exist concept classes that can be PAC-learned efficiently by quantum learners, even from classical examples, but not by classical learners (again, under plausible complexity-theoretic assumptions).&lt;ref name="gortlerservedioquantum" /&gt;

This passive learning type is also the most common scheme in supervised learning: a learning algorithm typically takes the training examples fixed, without the ability to query the label of unlabelled examples. Outputting a hypothesis ''h'' is a step of induction. Classically, an inductive model splits into a training and an application phase: the model parameters are estimated in the training phase, and the learned model is applied an arbitrary many times in the application phase. In the asymptotic limit of the number of applications, this splitting of phases is also present with quantum resources.&lt;ref&gt;{{cite journal|first2=Gael|last2=Sentís|title=Inductive supervised quantum learning|year=2017|last1=Monràs|first1=Alex|last3=Wittek|first3=Peter|journal=Physical Review Letters|volume=118|issue=19|pages=190503|doi=10.1103/PhysRevLett.118.190503 |pmid=28548536|bibcode=2017PhRvL.118s0503M|arxiv=1605.07541}}&lt;/ref&gt;

== Implementations and experiments ==

The earliest experiments were conducted using the adiabatic [[D-Wave Systems|D-Wave]] quantum computer, for instance, to detect cars in digital images using regularized boosting with a nonconvex objective function in a demonstration in 2009.&lt;ref&gt;{{cite web|url=http://static.googleusercontent.com/media/www.google.com/de//googleblogs/pdfs/nips_demoreport_120709_research.pdf|title=NIPS 2009 Demonstration: Binary Classification using Hardware Implementation of Quantum Annealing|publisher=Static.googleusercontent.com|access-date=26 November 2014}}&lt;/ref&gt; Many experiments followed on the same architecture, and leading tech companies have shown interest in the potential of quantum machine learning for future technological implementations. In 2013, Google Research, [[NASA]], and the [[Universities Space Research Association]] launched the [[Quantum Artificial Intelligence Lab]] which explores the use of the adiabatic D-Wave quantum computer.&lt;ref&gt;{{cite web|url=https://plus.google.com/+QuantumAILab|title=Google Quantum A.I. Lab Team|date=31 January 2017|website=Google Plus|access-date=31 January 2017|author=&lt;!--Staff writer(s); no by-line.--&gt;}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=https://ti.arc.nasa.gov/tech/dash/physics/quail/|title=NASA Quantum Artificial Intelligence Laboratory|date=31 January 2017|website=NASA|publisher=NASA|access-date=31 January 2017|author=&lt;!--Staff writer(s); no by-line.--&gt;|archive-url=https://web.archive.org/web/20170201210200/https://ti.arc.nasa.gov/tech/dash/physics/quail/|archive-date=1 February 2017|url-status=dead}}&lt;/ref&gt; A more recent example trained a probabilistic generative models with arbitrary pairwise connectivity, showing that their model is capable of generating handwritten digits as well as reconstructing noisy images of bars and stripes and handwritten digits.&lt;ref name="Benedetti2016a" /&gt;

Using a different annealing technology based on [[nuclear magnetic resonance]] (NMR), a quantum [[Hopfield network]] was implemented in 2009 that mapped the input data and memorized data to Hamiltonians, allowing the use of adiabatic quantum computation.&lt;ref&gt;{{cite journal|last2=Neves|first2=Jorge L.|last3=Sollacher|first3=Rudolf|last4=Glaser|first4=Steffen J.|year=2009|title=Quantum pattern recognition with liquid-state nuclear magnetic resonance|journal=Physical Review A|volume=79|issue=4|pages=042321|arxiv=0802.1592|bibcode=2009PhRvA..79d2321N|doi=10.1103/PhysRevA.79.042321|last1=Neigovzen|first1=Rodion|s2cid=119115625}}&lt;/ref&gt; NMR technology also enables universal quantum computing,{{Citation needed|date=February 2017}} and it was used for the first experimental implementation of a quantum support vector machine to distinguish hand written number ‘6’ and ‘9’ on a liquid-state  quantum computer in 2015.&lt;ref&gt;{{cite journal|last2=Liu|first2=Xiaomei|last3=Xu|first3=Nanyang|last4=Du|first4=Jiangfeng|year=2015|title=Experimental Realization of a Quantum Support Vector Machine|journal=Physical Review Letters|volume=114|issue=14|pages=140504|arxiv=1410.1054|bibcode=2015PhRvL.114n0504L|doi=10.1103/PhysRevLett.114.140504|pmid=25910101|last1=Li|first1=Zhaokai}}&lt;/ref&gt; The training data involved the pre-processing of the image which maps them to normalized 2-dimensional vectors to represent the images as the states of a qubit. The two entries of the vector are the vertical and horizontal ratio of the pixel intensity of the image. Once the vectors are defined on the [[feature space]], the quantum support vector machine was implemented to classify the unknown input vector. The readout avoids costly [[quantum tomography]] by reading out the final state in terms of direction (up/down) of the NMR signal.

Photonic implementations are attracting more attention,&lt;ref name="WanDKGK16"&gt;{{cite journal|last1=Wan|first1=Kwok-Ho|last2=Dahlsten|first2=Oscar|last3=Kristjansson|first3=Hler|last4=Gardner|first4=Robert|last5=Kim|first5=Myungshik|year=2017|title=Quantum generalisation of feedforward neural networks|journal=NPJ Quantum Information|volume=3|issue=36|pages=36|arxiv=1612.01045|bibcode=2017npjQI...3...36W|doi=10.1038/s41534-017-0032-4|s2cid=51685660}}&lt;/ref&gt; not the least because they do not require extensive cooling. Simultaneous spoken digit and speaker recognition and chaotic time-series prediction were demonstrated at data rates beyond 1 gigabyte per second in 2013.&lt;ref&gt;{{cite journal|last2=Soriano|first2=Miguel C.|last3=Mirasso|first3=Claudio R.|last4=Fischer|first4=Ingo|year=2013|title=Parallel photonic information processing at gigabyte per second data rates using transient states|journal=Nature Communications|volume=4|pages=1364|bibcode=2013NatCo...4.1364B|doi=10.1038/ncomms2368|pmc=3562454|pmid=23322052|last1=Brunner|first1=Daniel}}&lt;/ref&gt; Using non-linear photonics to implement an all-optical linear classifier, a perceptron model was capable of learning the classification boundary iteratively from training data through a feedback rule.&lt;ref&gt;{{cite journal|last2=Mabuchi|first2=Hideo|year=2015|title=A coherent perceptron for all-optical learning|journal=EPJ Quantum Technology|volume=2|arxiv=1501.01608|doi=10.1140/epjqt/s40507-015-0023-3|last1=Tezak|first1=Nikolas|bibcode=2015arXiv150101608T|s2cid=28568346}}&lt;/ref&gt; A core building block in many learning algorithms is to calculate the distance between two vectors: this was first experimentally demonstrated for up to eight dimensions using entangled qubits in a photonic quantum computer in 2015.&lt;ref&gt;{{cite journal|last2=Wu|first2=D.|last3=Su|first3=Z.-E.|last4=Chen|first4=M.-C.|last5=Wang|first5=X.-L.|last6=Li|first6=Li|last7=Liu|first7=N.-L.|last8=Lu|first8=C.-Y.|last9=Pan|first9=J.-W.|year=2015|title=Entanglement-Based Machine Learning on a Quantum Computer|journal=Physical Review Letters|volume=114|issue=11|pages=110504|arxiv=1409.7770|bibcode=2015PhRvL.114k0504C|doi=10.1103/PhysRevLett.114.110504|pmid=25839250|last1=Cai|first1=X.-D.|s2cid=44769024}}&lt;/ref&gt;

Recently, based on a neuromimetic approach, a novel ingredient has been added to the field of quantum machine learning, in the form of a so-called quantum memristor, a quantized model of the standard classical [[memristor]].&lt;ref&gt;{{cite journal |doi=10.1038/srep29507 |pmid=27381511 |pmc=4933948 |title=Quantum memristors |journal=Scientific Reports |volume=6 |issue=2016 |pages=29507 |year=2016|last1=Pfeiffer |first1=P. |last2=Egusquiza |first2=I. L. |last3=Di Ventra |first3=M. |last4=Sanz |first4=M. |last5=Solano |first5=E. |bibcode=2016NatSR...629507P|arxiv=1511.02192 }}&lt;/ref&gt; This device can be constructed by means of a tunable resistor, weak measurements on the system, and a classical feed-forward mechanism. An implementation of a quantum memristor in superconducting circuits has been proposed,&lt;ref&gt;{{cite journal |doi=10.1038/srep42044|pmid= 28195193|pmc= 5307327|last1= Salmilehto|first1= J.|title= Quantum Memristors with Superconducting Circuits|last2=  Deppe|first2= F.|last3=  Di Ventra|first3= M.|last4=  Sanz|first4= M.|last5=  Solano|first5= E.|journal=Scientific Reports |volume=7 |issue= 42044|pages=42044|year= 2017|arxiv=1603.04487|bibcode=2017NatSR...742044S}}&lt;/ref&gt; and an experiment with quantum dots performed.&lt;ref&gt;{{Cite journal|arxiv=1612.08409|last1=Li|first1=Ying|title=A simple and robust quantum memristor|journal=Physical Review B|volume=96|issue=7|pages=075446|last2= Holloway|first2=Gregory W.|last3= Benjamin|first3=Simon C.|last4= Briggs|first4=G. Andrew D.|last5=Baugh|first5=Jonathan|last6= Mol|first6=Jan A.|year=2017|doi=10.1103/PhysRevB.96.075446|bibcode=2017PhRvB..96g5446L|s2cid=119454549}}&lt;/ref&gt; A quantum memristor would implement nonlinear interactions in the quantum dynamics which would aid the search for a fully functional [[quantum neural network]].

Since 2016, IBM has launched an online cloud-based platform for quantum software developers, called the [[IBM Q Experience]]. This platform consists of several fully operational quantum processors accessible via the IBM Web API. In doing so, the company is encouraging software developers to pursue new algorithms through a development environment with quantum capabilities. New architectures are being explored on an experimental basis, up to 32 qbits, utilizing both trapped-ion and superconductive quantum computing methods.

In October 2019, it was noted that the introduction of Quantum Random Number Generators (QRNGs) to machine learning models including Neural Networks and Convolutional Neural Networks for random initial weight distribution and Random Forests for splitting processes had a profound effect on their ability when compared to the classical method of Pseudorandom Number Generators (PRNGs).&lt;ref&gt;{{cite journal | last1=Bird | first1=Jordan J. | last2=Ekárt | first2=Anikó | last3=Faria | first3=Diego R. | title=On the effects of pseudorandom and quantum-random number generators in soft computing | journal=Soft Computing | publisher=Springer Science and Business Media LLC | date=2019-10-28 | issn=1432-7643 | doi=10.1007/s00500-019-04450-0 | volume=24 | issue=12 | pages=9243–9256 | doi-access=free }}&lt;/ref&gt;

==Skepticism==

While [[machine learning]] itself is now not only a research field but an economically significant and fast growing industry and [[quantum computing]] is a well established field of both theoretical and experimental research, quantum machine learning remains a purely theoretical field of studies. Attempts to experimentally demonstrate concepts of quantum machine learning remain insufficient.{{citation needed|date=December 2020}}

Many of the leading scientists that extensively publish in the field of quantum machine learning warn about the extensive hype around the topic and are very restrained if asked about its practical uses in the foreseeable future. Sophia Chen&lt;ref&gt;{{Cite web|date=2020-05-04|title=Can quantum machine learning move beyond its own hype?|url=https://www.protocol.com/manuals/quantum-computing/machine-learning-ai-quantum-computing-move-beyond-hype|access-date=2020-10-27|website=Protocol|language=en}}&lt;/ref&gt; collected some of the statements made by well known scientists in the field:

* "I think we haven't done our homework yet. This is an extremely new scientific field," - physicist Maria Schuld of Canada-based quantum computing startup Xanadu.
* "There is a lot more work that needs to be done before claiming quantum machine learning will actually work," - computer scientist Iordanis Kerenidis, the head of quantum algorithms at the Silicon Valley-based quantum computing startup QC Ware.
* "I have not seen a single piece of evidence that there exists a meaningful [machine learning] task for which it would make sense to use a quantum computer and not a classical computer," - physicist Ryan Sweke of the Free University of Berlin in Germany.

“Don't fall for the hype!” -  Frank Zickert,&lt;ref&gt;{{Cite web|last=Zickert|first=Frank|date=2020-09-23|title=Quantum Machine Learning|url=https://towardsdatascience.com/quantum-machine-learning-e1955476a6ad|access-date=2020-10-27|website=Medium|language=en}}&lt;/ref&gt; who is the author of probably the most practical book related to the subject beware that ”quantum computers are far away from advancing machine learning for their representation ability”, and even speaking about evaluation and optimization for any kind of useful task quantum supremacy is not yet achieved. Furthermore, nobody among the active researchers in the field make any forecasts about when it could possibly become practical.{{citation needed|date=December 2020}}

== See also ==
*[[Quantum computing]]
*[[Quantum algorithm for linear systems of equations]]
*[[Quantum annealing]]
*[[Quantum neural network]]
*[[Quantum image]]

== References ==
{{Reflist |30em}}

{{Quantum computing}}
{{emerging technologies|quantum=yes|other=yes}}

[[Category:Machine learning]]
[[Category:Quantum information science]]
[[Category:Theoretical computer science]]
[[Category:Emerging technologies]]
[[Category:Quantum programming]]</text>
      <sha1>ejjguhno5f9kkr6ucrgb5i1ima7qar7</sha1>
    </revision>
  </page>
  <page>
    <title>M-Theory (learning framework)</title>
    <ns>0</ns>
    <id>44632031</id>
    <revision>
      <id>941262904</id>
      <parentid>931980010</parentid>
      <timestamp>2020-02-17T15:10:52Z</timestamp>
      <contributor>
        <username>Kku</username>
        <id>5846</id>
      </contributor>
      <minor/>
      <comment>link [[facial recognition system|face recognition]] using [[:en:User:Edward/Find link|Find link]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="26046" xml:space="preserve">{{about|machine learning|the physics term|M-theory}}
{{Orphan|date=December 2014}}

In [[Machine Learning]] and [[Computer Vision]], '''M-Theory''' is a learning framework inspired by feed-forward processing in the [[Two-streams hypothesis|ventral stream]] of [[visual cortex]] and originally developed for recognition and classification of objects in visual scenes. M-Theory was later applied to other areas, such as [[speech recognition]]. On certain image recognition tasks, algorithms based on a specific instantiation of M-Theory, HMAX, achieved human-level performance.&lt;ref&gt;Serre T., Oliva A., Poggio T. (2007) A feedforward architecture accounts for rapid categorization. ''PNAS'', vol. 104, no. 15, pp. 6424-6429&lt;/ref&gt;

The core principle of M-Theory is extracting representations invariant to various transformations of images (translation, scale, 2D and 3D rotation and others). In contrast with other approaches using invariant representations, in M-Theory they are not hardcoded into the algorithms, but learned. M-Theory also shares some principles with [[Compressed Sensing]]. The theory proposes multilayered hierarchical learning architecture, similar to that of visual cortex.

==Intuition==

===Invariant representations===

A great challenge in visual recognition tasks is that the same object can be seen in a variety of conditions. It can be seen from different distances, different viewpoints, under different lighting, partially occluded, etc. In addition, for particular classes objects, such as faces, highly complex specific transformations may be relevant, such as changing facial expressions. For learning to recognize images, it is greatly beneficial to factor out these variations. It results in much simpler classification problem and, consequently, in great reduction of [[sample complexity]] of the model.

A simple computational experiment illustrates this idea. Two instances of a classifier were trained to distinguish images of planes from those of cars. For training and testing of the first instance, images with arbitrary viewpoints were used. Another instance received only images seen from a particular viewpoint, which was equivalent to training and testing the system on invariant representation of the images. One can see that the second classifier performed quite well even after receiving a single example from each category, while performance of the first classifier was close to random guess even after seeing 20 examples.

Invariant representations has been incorporated into several learning architectures, such as [[neocognitron]]s. Most of these architectures, however, provided invariance through custom-designed features or properties of architecture itself. While it helps to take into account some sorts of transformations, such as translations, it is very nontrivial to accommodate for other sorts of transformations, such as 3D rotations and changing facial expressions. M-Theory provides a framework of how such transformations can be learned. In addition to higher flexibility, this theory also suggests how human brain may have similar capabilities.

===Templates===

Another core idea of M-Theory is close in spirit to ideas from the field of [[compressed sensing]]. An implication from [[Johnson–Lindenstrauss lemma]] says that a particular number of images can be embedded into a low-dimensional [[feature space]] with the same distances between images by using random projections. This result suggests that [[dot product]] between the observed image and some other image stored in memory, called template, can be used as a feature helping to distinguish the image from other images. The template need not to be anyhow related to the image, it could be chosen randomly.

===Combining templates and invariant representations===

The two ideas outlined in previous sections can be brought together to construct a framework for learning invariant representations. The key observation is how dot product between image &lt;math&gt;I&lt;/math&gt; and a template &lt;math&gt;t&lt;/math&gt; behaves when image is transformed (by such transformations as translations, rotations, scales, etc.). If transformation &lt;math&gt;g&lt;/math&gt; is a member of a [[unitary group]] of transformations, then the following holds:

&lt;math&gt;\langle gI,t \rangle = \langle I,g^{-1}t \rangle    (1) &lt;/math&gt;

In other words, the dot product of transformed image and a template is equal to the dot product of original image and inversely transformed template. For instance, for image rotated by 90 degrees, the inversely transformed template would be rotated by -90 degrees.

Consider the set of dot products of an image &lt;math&gt;I&lt;/math&gt; to all possible transformations of template: &lt;math&gt;\lbrace \langle I,g^\prime t\rangle | g^\prime \in G \rbrace&lt;/math&gt;. If one applies a transformation &lt;math&gt;g&lt;/math&gt; to &lt;math&gt;I&lt;/math&gt;, the set would become &lt;math&gt;\lbrace \langle gI,g^\prime t\rangle | g^\prime \in G\rbrace&lt;/math&gt;. But because of the property (1), this is equal to &lt;math&gt;\lbrace \langle I,g^{-1}g^\prime t\rangle | g^\prime \in G\rbrace&lt;/math&gt;. The set &lt;math&gt;\lbrace g^{-1}g^\prime | g^\prime \in G \rbrace&lt;/math&gt; is equal to just the set of all elements in &lt;math&gt;G&lt;/math&gt;. To see this, note that every &lt;math&gt;g^{-1}g^\prime&lt;/math&gt; is in &lt;math&gt;G&lt;/math&gt; due to the closure property of [[group (mathematics)|groups]], and for every &lt;math&gt;g^{\prime\prime}&lt;/math&gt; in G there exist its prototype &lt;math&gt;g^\prime&lt;/math&gt; such as &lt;math&gt;g^{\prime\prime} = g^{-1}g^\prime&lt;/math&gt; (namely, &lt;math&gt;g^\prime = gg^{\prime\prime}&lt;/math&gt;). Thus, &lt;math&gt;\lbrace \langle I,g^{-1}g^\prime t\rangle | g^\prime \in G\rbrace = \lbrace\langle I,g^{\prime\prime}t\rangle | g^{\prime\prime} \in G \rbrace&lt;/math&gt;. One can see that the set of dot products remains the same despite that a transformation was applied to the image! This set by itself may serve as a (very cumbersome) invariant representation of an image. More practical representations can be derived from it.

In the introductory section, it was claimed that M-Theory allows to learn invariant representations. This is because templates and their transformed versions can be learned from visual experience - by exposing the system to sequences of transformations of objects. It is plausible that similar visual experiences occur in early period of human life, for instance when infants twiddle toys in their hands. Because templates may be totally unrelated to images that the system later will try to classify, memories of these visual experiences may serve as a basis for recognizing many different kinds of objects in later life. However, as it is shown later, for some kinds of transformations, specific templates are needed.

==Theoretical aspects==

===From orbits to distribution measures ===

To implement the ideas described in previous sections, one need to know how to derive a computationally efficient invariant representation of an image. Such unique representation for each image can be characterized as it appears by a set of one-dimensional probability distributions (empirical distributions of the dot-products between image and a set of templates stored during unsupervised learning). These probability distributions in their turn can be described by either histograms or a set of statistical moments of it, as it will be shown below.

Orbit &lt;math&gt;O_I&lt;/math&gt; is a set of images &lt;math&gt;gI&lt;/math&gt; generated from a single image &lt;math&gt;I&lt;/math&gt; under the action of the group &lt;math&gt;G, \forall g \in G&lt;/math&gt;.

In other words, images of an object and of its transformations correspond to an orbit &lt;math&gt;O_I&lt;/math&gt;. If two orbits have a point in common they are identical everywhere,&lt;ref name="magic_paper"&gt;F Anselmi, JZ Leibo, L Rosasco, J Mutch, A Tacchetti, T Poggio (2014) ''Unsupervised learning of invariant representations in hierarchical architectures''  arXiv preprint arXiv:1311.4158&lt;/ref&gt; i.e. an orbit is an invariant and unique representation of an image. So, two images are called equivalent when they belong to the same orbit: &lt;math&gt;I \sim I^\prime&lt;/math&gt; if &lt;math&gt;\exists g \in G&lt;/math&gt; such that &lt;math&gt;I^\prime = gI&lt;/math&gt;. Conversely, two orbits are different if none of the images in one orbit coincide with any image in the other.&lt;ref&gt;H. Schulz-Mirbach. Constructing invariant features by averaging techniques. In Pattern Recognition, 1994. Vol. 2 - Conference B: Computer Vision amp; Image Processing., Proceedings of the 12th IAPR International. Conference on, volume 2, pages 387 –390 vol.2, 1994.&lt;/ref&gt;

A natural question arises: how can one compare two orbits? There are several possible approaches. One of them employs the fact that intuitively two empirical orbits are the same irrespective of the ordering of their points. Thus, one can consider a probability distribution &lt;math&gt;P_I&lt;/math&gt; induced by the group's action on images &lt;math&gt;I&lt;/math&gt; (&lt;math&gt;gI&lt;/math&gt; can be seen as a realization of a random variable).
 
This probability distribution &lt;math&gt;P_I&lt;/math&gt; can be almost uniquely characterized by &lt;math&gt;K&lt;/math&gt; one-dimensional probability distributions &lt;math&gt;P_{\langle I ,t^k \rangle}&lt;/math&gt; induced by the (one-dimensional) results of projections &lt;math&gt;\langle I,t^k\rangle&lt;/math&gt;, where &lt;math&gt;t^k, k = 1,...,K&lt;/math&gt; are a set of templates (randomly chosen images) (based on the Cramer-Wold theorem  &lt;ref&gt;H. Cramer and H. Wold. Some theorems on distribution functions. J. London Math. Soc., 4:290–294, 1936.&lt;/ref&gt; and concentration of measures).
  
Consider &lt;math&gt;n&lt;/math&gt; images &lt;math&gt;X_n \in X&lt;/math&gt;. Let &lt;math&gt;K \geq \frac{2}{c\epsilon^2} \log \frac{n}{\delta}&lt;/math&gt; , where &lt;math&gt;c&lt;/math&gt; is a universal constant. Then

&lt;math&gt;|d(P_I,P_I^\prime)-dK(P_I,P_I^\prime)| \leq \epsilon,&lt;/math&gt;

with probability &lt;math&gt;1 - \delta^2&lt;/math&gt;, for all &lt;math&gt;I, I^\prime&lt;/math&gt; &lt;math&gt;\in &lt;/math&gt; &lt;math&gt;X_n&lt;/math&gt;.
 
This result (informally) says that an approximately invariant and unique representation of an image &lt;math&gt;I&lt;/math&gt; can be obtained from the estimates of &lt;math&gt;K&lt;/math&gt; 1-D probability distributions &lt;math&gt;P_{\langle I,t^k \rangle}&lt;/math&gt; for &lt;math&gt;k = 1,...,K&lt;/math&gt;. The number &lt;math&gt;K&lt;/math&gt; of projections needed to discriminate &lt;math&gt;n&lt;/math&gt; orbits, induced by &lt;math&gt;n&lt;/math&gt; images, up to precision &lt;math&gt;\epsilon&lt;/math&gt; (and with confidence &lt;math&gt;1 - \delta^2&lt;/math&gt;) is &lt;math&gt;K \geq \frac{2}{c\epsilon^2} \log \frac{n}{\delta}&lt;/math&gt;, where &lt;math&gt;c&lt;/math&gt; is a universal constant.
  
To classify an image, the following "recipe" can be used:
 
#     Memorize a set of images/objects called templates;
#     Memorize observed transformations for each template;
#     Compute dot products of its transformations with image;
#     Compute histogram of the resulting values, called ''signature'' of the image;
#     Compare the obtained histogram with signatures stored in memory.

Estimates of such one-dimensional probability density functions (PDFs) &lt;math&gt;P_{\langle I ,t^k \rangle}&lt;/math&gt; can be written in terms of histograms as &lt;math&gt;\mu^k_n(I) = 1/\left|G\right| \sum_{i=1}^{\left|G\right|} \eta_n(\langle I, g_i t^k \rangle) &lt;/math&gt;, where &lt;math&gt;\eta_n, n = 1, ... , N &lt;/math&gt; is a set of nonlinear functions. These 1-D probability distributions can be characterized with N-bin histograms or set of statistical moments. For example, HMAX represents an architecture in which pooling is done with a max operation.

===Non-compact groups of transformations===

In the "recipe" for image classification, groups of transformations are approximated with finite number of transformations. Such approximation is possible only when the group is [[compact group|compact]].

Such groups as all translations and all scalings of the image are not compact, as they allow arbitrarily big transformations. However, they are [[locally compact group|locally compact]]. For locally compact groups, invariance is achievable within certain range of transformations.&lt;ref name="magic_paper" /&gt;

Assume that &lt;math&gt;G_0&lt;/math&gt; is a subset of transformations from &lt;math&gt;G&lt;/math&gt; for which the transformed patterns exist in memory. For an image &lt;math&gt;I&lt;/math&gt; and template &lt;math&gt;t_k&lt;/math&gt;, assume that &lt;math&gt;\langle I,g^{-1}t_k\rangle&lt;/math&gt; is equal to zero everywhere except some subset of &lt;math&gt;G_0&lt;/math&gt;. This subset is called [[support (mathematics)|support]] of &lt;math&gt;\langle I,g^{-1}t_k\rangle&lt;/math&gt; and denoted as &lt;math&gt;supp(\langle I, g^{-1}t_k\rangle)&lt;/math&gt;. It can be proven that if for a transformation &lt;math&gt;g^\prime&lt;/math&gt;, support set will also lie within &lt;math&gt;g^\prime G_0&lt;/math&gt;, then signature of &lt;math&gt;I&lt;/math&gt; is invariant with respect to &lt;math&gt;g^\prime&lt;/math&gt;.&lt;ref name="magic_paper" /&gt; This theorem determines the range of transformations for which invariance is guaranteed to hold.

One can see that the smaller is &lt;math&gt;supp(\langle I, g^{-1}t_k\rangle)&lt;/math&gt;, the larger is the range of transformations for which invariance is guaranteed to hold. It means that for a group that is only locally compact, not all templates would work equally well anymore. Preferable templates are those with a reasonably small &lt;math&gt;supp(\langle gI, t_k\rangle)&lt;/math&gt; for a generic image. This property is called localization: templates are sensitive only to images within a small range of transformations. Note that although minimizing &lt;math&gt;supp(\langle gI, t_k\rangle)&lt;/math&gt; is not absolutely necessary for the system to work, it improves approximation of invariance. Requiring localization simultaneously for translation and scale yields a very specific kind of templates: [[Gabor function]]s.&lt;ref name="magic_paper" /&gt;

The desirability of custom templates for non-compact group is in conflict with the principle of learning invariant representations. However, for certain kinds of regularly encountered image transformations, templates might be the result of evolutionary adaptations. Neurobiological data suggests that there is Gabor-like tuning in the first layer of visual cortex.&lt;ref&gt;F. Anselmi, J.Z. Leibo, L. Rosasco, J. Mutch, A. Tacchetti, T. Poggio (2013) ''Magic Materials: a theory of deep hierarchical architectures for learning sensory representations.'' CBCL paper, Massachusetts Institute of Technology, Cambridge, MA&lt;/ref&gt; The optimality of Gabor templates for translations and scales is a possible explanation of this phenomenon.

===Non-group transformations===

Many interesting transformations of images do not form groups. For instance, transformations of images associated with 3D rotation of corresponding 3D object do not form a group, because it is impossible to define an inverse transformation (two objects may looks the same from one angle but different from another angle). However, approximate invariance is still achievable even for non-group transformations, if localization condition for templates holds and transformation can be locally linearized.

As it was said in the previous section, for specific case of translations and scaling, localization condition can be satisfied by use of generic Gabor templates. However, for general case (non-group) transformation, localization condition can be satisfied only for specific class of objects.&lt;ref name="magic_paper" /&gt; More specifically, in order to satisfy the condition, templates must be similar to the objects one would like to recognize. For instance, if one would like to build a system to recognize 3D rotated faces, one need to use other 3D rotated faces as templates. This may explain the existence of such specialized modules in the brain as one responsible for [[facial recognition system|face recognition]].&lt;ref name="magic_paper" /&gt; Even with custom templates, a noise-like encoding of images and templates is necessary for localization. It can be naturally achieved if the non-group transformation is processed on any layer other than the first in hierarchical recognition architecture.

===Hierarchical architectures===

The previous section suggests one motivation for hierarchical image recognition architectures. However, they have other benefits as well.

Firstly, hierarchical architectures best accomplish the goal of ‘parsing’ a complex visual scene with many objects consisting of many parts, whose relative position may greatly vary. In this case, different elements of the system must react to different objects and parts. In hierarchical architectures, representations of parts at different levels of embedding hierarchy can be stored at different layers of hierarchy.

Secondly, hierarchical architectures which have invariant representations for parts of objects may facilitate learning of complex compositional concepts. This facilitation may happen through reusing of learned representations of parts that were constructed before in process of learning of other concepts. As a result, sample complexity of learning compositional concepts may be greatly reduced.

Finally, hierarchical architectures have better tolerance to clutter. Clutter problem arises when the target object is in front of a non-uniform background, which functions as a distractor for the visual task. Hierarchical architecture provides signatures for parts of target objects, which do not include parts of background and are not affected by background variations.&lt;ref&gt;Liao Q., Leibo J., Mroueh Y., Poggio T. (2014) ''Can a biologically-plausible hierarchy effectively replace face detection, alignment, and recognition pipelines?'' CBMM Memo No. 003, Massachusetts Institute of Technology, Cambridge, MA&lt;/ref&gt;

In hierarchical architectures, one layer is not necessarily invariant to all transformations that are handled by the hierarchy as a whole. Some transformations may pass through that layer to upper layers, as in the case of non-group transformations described in the previous section. For other transformations, an element of the layer may produce invariant representations only within small range of transformations. For instance, elements of the lower layers in hierarchy have small visual field and thus can handle only a small range of translation. For such transformations, the layer should provide ''covariant'' rather than invariant, signatures. The property of covariance can be written as &lt;math&gt;distr(\langle \mu_l(gI),\mu_l(t)\rangle) = distr(\langle \mu_l(I),\mu_l(g^{-1}t)\rangle)&lt;/math&gt;, where &lt;math&gt;l&lt;/math&gt; is a layer, &lt;math&gt;\mu_l(I)&lt;/math&gt; is the signature of image on that layer, and &lt;math&gt;distr&lt;/math&gt; stands for "distribution of values of the expression for all &lt;math&gt;g \in G&lt;/math&gt;".

==Relation to biology==

M-theory is based on a quantitative theory of the ventral stream of visual cortex.&lt;ref&gt;M. Riesenhuber and T. Poggio ''Hierarchical Models of Object Recognition in Cortex'' (1999) Nature Neuroscience, vol. 2, no. 11, pp. 1019-1025, 1999.&lt;/ref&gt;&lt;ref&gt;T. Serre, M. Kouh, C. Cadieu, U. Knoblich, G. Kreiman, and T. Poggio (2005) ''A Theory of Object Recognition: Computations and Circuits in the Feedforward Path of the Ventral Stream in Primate Visual Cortex'' AI Memo 2005-036/CBCL Memo 259, Massachusetts Inst. of Technology, Cambridge.&lt;/ref&gt; Understanding how visual cortex works in object recognition is still a challenging task for neuroscience. Humans and primates are able to memorize and recognize objects after seeing just couple of examples unlike any state-of-the art machine vision systems that usually require a lot of data in order to recognize objects. Prior to the use of visual neuroscience in computer vision has been limited to early vision for deriving stereo algorithms (e.g.,&lt;ref name="HW"&gt;D.H. Hubel and T.N. Wiesel (1962) ''Receptive fields, binocular interaction and functional architecture in the cat’s visual cortex'' The Journal of Physiology 160.&lt;/ref&gt;) and to justify the use of DoG (derivative-of-Gaussian) filters and more recently of Gabor filters.&lt;ref&gt;D. Gabor (1946) ''Theory of Communication'' J. IEE, vol. 93, pp. 429-459.&lt;/ref&gt;&lt;ref&gt;J.P. Jones and L.A. Palmer (1987) ''An Evaluation of the Two-Dimensional Gabor Filter Model of Simple Receptive Fields in Cat Striate Cortex'' J. Neurophysiol., vol. 58, pp. 1233-1258.&lt;/ref&gt; No real attention has been given to biologically plausible features of higher complexity. While mainstream computer vision has always been inspired and challenged by human vision, it seems to have never advanced past the very first stages of processing in the simple cells in V1 and V2. Although some of the systems inspired - to various degrees - by neuroscience, have been tested on at least some natural images, neurobiological models of object recognition in cortex have not yet been extended to deal with real-world image databases.&lt;ref name="Robust_Obj_Recog" &gt;Thomas Serre, Lior Wolf, Stanley Bileschi, Maximilian Riesenhuber, and Tomaso Poggio (2007) ''Robust Object Recognition with Cortex-Like Mechanisms'' IEEE Transactions on Pattern Analysis and Machine Intelligence, VOL. 29, NO. 3&lt;/ref&gt;

M-theory learning framework employs a novel hypothesis about the main computational function of the ventral stream: the representation of new objects/images in terms of a signature, which is invariant to transformations learned during visual experience. This allows recognition from very few labeled examples - in the limit, just one.

Neuroscience	suggests that natural functionals for a neuron to compute is a high-dimensional dot product between an "image patch" and	another image	patch (called template) 
which is stored in terms of synaptic weights (synapses per neuron). The standard computational model of a neuron is based on a dot product and a threshold. Another important feature of the visual cortex is that it consists of simple and complex cells. This idea was originally proposed by Hubel and Wiesel.&lt;ref name="HW"/&gt; M-theory employs this idea. Simple cells compute dot products of an image and transformations of templates &lt;math&gt;\langle I,g_it^k\rangle&lt;/math&gt; for &lt;math&gt;i = 1,...,|G|&lt;/math&gt; (&lt;math&gt;|G|&lt;/math&gt; is a number of simple cells). Complex cells are responsible for pooling and computing empirical histograms or statistical moments of it. The following formula for constructing histogram can be computed by neurons:

&lt;math&gt;\frac{1}{|G|}\sum_{i=1}^{|G|}\sigma(\langle I,g_it^k\rangle+n\Delta),&lt;/math&gt;

where &lt;math&gt;\sigma&lt;/math&gt; is a smooth version of step function, &lt;math&gt;\Delta&lt;/math&gt; is the width of a histogram bin, and &lt;math&gt;n&lt;/math&gt; is the number of the bin.

==Applications==

===Applications to computer vision===
In {{clarify|date=December 2014}}&lt;ref&gt;Qianli Liao, Joel Z Leibo, Youssef Mroueh, Tomaso Poggio (2014) ''Can a biologically-plausible hierarchy effectively replace face detection, alignment, and recognition pipelines?'' CBMM Memo No. 003&lt;/ref&gt;&lt;ref&gt;Qianli Liao, Joel Z Leibo, and Tomaso Poggio (2014) ''Learning invariant representations and applications to face verification'' NIPS 2014&lt;/ref&gt; authors applied M-theory to unconstrained face recognition in natural photographs. Unlike the DAR (detection, alignment, and recognition) method, which handles clutter by detecting objects and cropping closely around them so that very little background remains, this approach accomplishes detection and alignment implicitly by storing transformations of training images (templates) rather than explicitly detecting and aligning or cropping faces at test time. This system is built according to the principles of a recent theory of invariance in hierarchical networks and can evade the clutter problem generally problematic for feedforward systems. 
The resulting end-to-end system achieves a drastic improvement in the state of the art on this end-to-end task, reaching the same level of performance as the best systems operating on aligned, closely cropped images (no outside training data). It also performs well on two newer datasets, similar to LFW, but more difficult: significantly jittered (misaligned) version of LFW and SUFR-W (for example, the model's accuracy in the LFW "unaligned &amp; no outside data used" category is 87.55±1.41% compared to state-of-the-art APEM (adaptive probabilistic elastic matching): 81.70±1.78%).

The theory was also applied to a range of recognition tasks: from invariant single object recognition in clutter to multiclass categorization problems on publicly available data sets (CalTech5, CalTech101, MIT-CBCL) and complex (street) scene understanding tasks that requires the recognition of both shape-based as well as texture-based objects (on StreetScenes data set).&lt;ref name="Robust_Obj_Recog"/&gt; The approach performs really well: It has the capability of learning from only a few training examples and was shown to outperform several more complex state-of-the-art systems constellation models, the hierarchical SVM-based face-detection system. A key element in the approach is a new set of scale and position-tolerant feature detectors, which are biologically plausible and agree quantitatively with the tuning properties of cells along the ventral stream of visual cortex. These features are adaptive to the training set, though we also show that a universal feature set, learned from a set of natural images unrelated to any categorization task, likewise achieves good performance.

===Applications to speech recognition===

This theory can also be extended for the speech recognition domain.
As an example, in&lt;ref&gt;Georgios Evangelopoulos, Stephen Voinea, Chiyuan Zhang, Lorenzo Rosasco, Tomaso Poggio (2014) ''Learning An Invariant Speech Representation'' CBMM Memo No. 022&lt;/ref&gt; an extension of a theory for unsupervised learning of invariant visual representations to the auditory domain and empirically evaluated its validity for voiced speech sound classification was proposed. Authors empirically demonstrated that a single-layer, phone-level representation, extracted from base speech features, improves segment classification accuracy and decreases the number of training examples in comparison with standard spectral and cepstral features for an acoustic classification task on TIMIT dataset.&lt;ref&gt;https://catalog.ldc.upenn.edu/LDC93S1&lt;/ref&gt;

==References==
{{Reflist}}

[[Category:Machine learning]]
[[Category:Computer vision]]
[[Category:Speech recognition]]</text>
      <sha1>0nu9nh95uzdyvn5lipbvq6bxshkukhj</sha1>
    </revision>
  </page>
  <page>
    <title>Instantaneously trained neural networks</title>
    <ns>0</ns>
    <id>470314</id>
    <revision>
      <id>914833024</id>
      <parentid>867038963</parentid>
      <timestamp>2019-09-09T16:40:34Z</timestamp>
      <contributor>
        <ip>130.64.25.59</ip>
      </contributor>
      <comment>/* CC4 network */  Corrected the formula for w_ij when i=n+1: the correct expression if r-s+1 and not the previously stated r+s-1. See the original paper http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.86.3290&amp;rep=rep1&amp;type=pdf for details.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="4369" xml:space="preserve">'''Instantaneously trained neural networks''' are feedforward [[artificial neural networks]] that create a new hidden neuron node for each novel training sample. The weights to this hidden neuron separate out not only this training sample but others that are near it, thus providing generalization. &lt;ref name="kak93"&gt;Kak, S. On training feedforward neural networks. Pramana, vol. 40, pp. 35-42, 1993 [https://link.springer.com/article/10.1007/BF02898040] &lt;/ref&gt;&lt;ref&gt;Kak, S. New algorithms for training feedforward neural networks. Pattern Recognition Letters 15: 295-298, 1994.&lt;/ref&gt; This separation is done using the nearest hyperplane that can be written down instantaneously. In the two most important implementations the neighborhood of generalization either varies with the training sample (CC1 network) or remains constant (CC4 network). These networks use [[unary coding]] for an effective representation of the data sets.&lt;ref&gt;Kak, S. On generalization by neural networks, Information Sciences 111: 293-302, 1998.&lt;/ref&gt;

This type of network was first proposed in a 1993 paper of [[Subhash Kak]].&lt;ref name="kak93"/&gt; Since then, instantaneously trained neural networks have been proposed as models of short term [[learning]] and used in [[web search]], and financial [[time series prediction]] applications.&lt;ref&gt;Kak, S. Faster web search and prediction using instantaneously trained neural networks. IEEE Intelligent Systems 14: 79-82, November/December 1999.&lt;/ref&gt; They have also been used in instant [[document classification|classification of documents]]&lt;ref&gt;Zhang, Z. et al., TextCC: New feedforward neural network for classifying documents instantly. Advances in Neural Networks ISNN 2005. [[Lecture Notes in Computer Science]] 3497: 232-237, 2005.&lt;/ref&gt; and for [[deep learning]] and [[data mining]].&lt;ref&gt;Zhang, Z. et al., Document Classification Via TextCC Based on Stereographic Projection and for deep learning, International Conference on Machine Learning and Cybernetics, Dalin, 2006&lt;/ref&gt;&lt;ref&gt;Schmidhuber, J. Deep Learning in Neural Networks: An Overview, arXiv:1404.7828, 2014 https://arxiv.org/abs/1404.7828&lt;/ref&gt;

As in other neural networks, their normal use is as software, but they have also been implemented in hardware using FPGAs&lt;ref&gt;Zhu, J. and G. Milne, Implementing Kak Neural Networks on a Reconfigurable Computing Platform, Lecture Notes in Computer Science Volume 1896: 260-269, 2000.&lt;/ref&gt; and by optical implementation.&lt;ref&gt;Shortt, A., J.G. Keating, L. Moulinier, C.N. Pannell, Optical implementation of the Kak neural network, Information Sciences 171: 273-287, 2005.&lt;/ref&gt;

==CC4 network==

In the CC4 network, which is a three-stage network, the number of input nodes is one more than the size of the training vector, with the extra node serving as the biasing node whose input is always 1. For binary input vectors, the weights from the input nodes to the hidden neuron (say of index j) corresponding to the trained vector is given by the following formula:
:&lt;math id="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.86.3290&amp;rep=rep1&amp;type=pdf"&gt;w_{ij} = \begin{cases}
   -1, &amp; \mbox{for } x_i = 0\\
                         +1, &amp; \mbox{for } x_i = 1\\
  r-s+1, &amp; \mbox{for } i = n+1
\end{cases}&lt;/math&gt;

where &lt;math&gt;r &lt;/math&gt; is the radius of generalization and &lt;math&gt;s &lt;/math&gt; is the [[Hamming weight]] (the number of 1s) of the binary sequence. From the hidden layer to the output layer the weights are 1 or -1 depending on whether the vector belongs to a given output class or not. The neurons in the hidden and output layers output 1 if the weighted sum to the input is 0 or positive and 0, if the weighted sum to the input is negative:

:&lt;math&gt;y = \left\{ \begin{matrix} 1 &amp; \mbox{if } \sum x_i \ge 0\\ 0 &amp; \mbox{if } \sum x_i&lt; 0\end{matrix} \right.&lt;/math&gt;
==Other networks==

The CC4 network has also been modified to include non-binary input with varying radii of generalization so that it effectively provides a CC1 implementation.&lt;ref&gt;Tang, K.W. and Kak, S. Fast classification networks for signal processing. ''Circuits, Systems, Signal Processing'' 21, 2002, pp. 207-224.&lt;/ref&gt;

In feedback networks the Willshaw network as well as the [[Hopfield network]] are able to learn instantaneously.

==References==
{{Reflist}}

[[Category:Learning]]
[[Category:Artificial neural networks]]
[[Category:Machine learning]]</text>
      <sha1>hk1szbgj8fbbjwp9homlmepk4hkrfxs</sha1>
    </revision>
  </page>
  <page>
    <title>Adversarial machine learning</title>
    <ns>0</ns>
    <id>45049676</id>
    <revision>
      <id>1005147707</id>
      <parentid>1002974511</parentid>
      <timestamp>2021-02-06T05:46:59Z</timestamp>
      <contributor>
        <ip>73.135.59.211</ip>
      </contributor>
      <comment>added two citations to research on human perception of audio adversarial examples</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="30667" xml:space="preserve">{{short description|Research field that lies at the intersection of machine learning and computer security}}
{{Distinguish|Generative adversarial network}}
{{excessive citations|date=September 2018}}
'''Adversarial machine learning''' is a [[machine learning]] technique that attempts to fool models by supplying deceptive input.&lt;ref&gt;{{Cite book|chapter=Timing Attacks on Machine Learning: State of the Art
|last1=Kianpour|first1=Mazaher|last2=Wen|first2=Shao-Fang|title=Intelligent Systems and Applications
|series=Advances in Intelligent Systems and Computing
|date=2020|volume=1037
|pages=111–125
|language=en|doi=10.1007/978-3-030-29516-5_10|isbn=978-3-030-29515-8
}}&lt;/ref&gt;&lt;ref&gt;{{Cite arxiv|title=Adversarial Machine Learning at Scale|last1=Bengio|first1=Samy|last2=Goodfellow|first2=Ian J.|date=2017|last3=Kurakin|first3=Alexey|class=cs.CV|eprint=1611.01236}}&lt;/ref&gt;&lt;ref name="LimTaeihagh2019"&gt;{{Cite journal|last1=Lim|first1=Hazel Si Min|last2=Taeihagh|first2=Araz|date=2019|title=Algorithmic Decision-Making in AVs: Understanding Ethical and Technical Concerns for Smart Cities|journal=Sustainability|language=en|volume=11|issue=20|pages=5791|doi=10.3390/su11205791|arxiv=1910.13122|bibcode=2019arXiv191013122L|s2cid=204951009}}&lt;/ref&gt; The most common reason is to cause a malfunction in a machine learning model.

Most machine learning techniques were designed to work on specific problem sets in which the training and test data are generated from the same statistical distribution ([[Independent and identically distributed random variables|IID]]). When those models are applied to the real world, adversaries may supply data that violates that statistical assumption. This data may be arranged to exploit specific vulnerabilities and compromise the results.&lt;ref name="LimTaeihagh2019" /&gt;&lt;ref name="GoodfellowMcDaniel2018"&gt;{{cite journal |last1=Goodfellow |first1=Ian |last2=McDaniel |first2=Patrick |last3=Papernot |first3=Nicolas |title=Making machine learning robust against adversarial inputs |journal=Communications of the ACM |date=25 June 2018 |volume=61 |issue=7 |pages=56–66 |doi=10.1145/3134599|url= https://cacm.acm.org/magazines/2018/7/229030-making-machine-learning-robust-against-adversarial-inputs/fulltex |access-date=2018-12-13 |issn=0001-0782|language=en|doi-access=free }}&lt;/ref&gt;

== History ==
In ''[[Snow Crash]]'' (1992), the author offered scenarios of technology that was vulnerable to an adversarial attack. In ''[[Zero History]]'' (2010), a character dons a t-shirt decorated in a way that renders him invisible to electronic surveillance.&lt;ref&gt;{{cite news |last1=Vincent |first1=James |title=Magic AI: these are the optical illusions that trick, fool, and flummox computers |url=https://www.theverge.com/2017/4/12/15271874/ai-adversarial-images-fooling-attacks-artificial-intelligence |access-date=27 March 2020 |work=The Verge |date=12 April 2017 |language=en}}&lt;/ref&gt;

In 2004, Nilesh Dalvi and others noted that [[linear classifier]]s used in [[Email filtering|spam filters]] could be defeated by simple "[[evasion (network security)|evasion]] attacks" as spammers inserted "good words" into their spam emails. (Around 2007, some spammers added random noise to fuzz words within "image spam" in order to defeat [[Optical character recognition|OCR]]-based filters.) In 2006, Marco Barreno and others published "Can Machine Learning Be Secure?", outlining a broad taxonomy of attacks. As late as 2013 many researchers continued to hope that non-linear classifiers (such as [[support vector machine]]s and [[neural networks]]) might be robust to adversaries. In 2012, [[Deep learning|deep neural networks]] began to dominate computer vision problems; starting in 2014, Christian Szegedy and others demonstrated that deep neural networks could be fooled by adversaries.&lt;ref name=":0"&gt;{{cite journal |last1=Biggio |first1=Battista |last2=Roli |first2=Fabio |title=Wild patterns: Ten years after the rise of adversarial machine learning |journal=Pattern Recognition |date=December 2018 |volume=84 |pages=317–331 |doi=10.1016/j.patcog.2018.07.023|arxiv=1712.03141 |s2cid=207324435 }}&lt;/ref&gt;

Recently, it was observed that adversarial attacks are harder to produce in the practical world due to the different environmental constraints that cancel out the effect of noises.&lt;ref&gt;{{cite arxiv |eprint=1607.02533|last1=Kurakin|first1=Alexey|last2=Goodfellow|first2=Ian|last3=Bengio|first3=Samy|title=Adversarial examples in the physical world|year=2016|class=cs.CV}}&lt;/ref&gt;&lt;ref&gt;Gupta, Kishor Datta, Dipankar Dasgupta, and Zahid Akhtar. "Applicability issues of Evasion-Based Adversarial Attacks and Mitigation Techniques." 2020 IEEE Symposium Series on Computational Intelligence (SSCI). 2020.&lt;/ref&gt; For example, any small rotation or slight illumination on an adversarial image can destroy the adversariality.

=== Examples ===
Examples include attacks in [[spam filtering]], where spam messages are obfuscated through the misspelling of “bad” words or the insertion of “good” words;&lt;ref name="BiggioFumera2010"&gt;{{cite journal|last1=Biggio|first1=Battista|last2=Fumera|first2=Giorgio|last3=Roli|first3=Fabio|title=Multiple classifier systems for robust classifier design in adversarial environments|journal=International Journal of Machine Learning and Cybernetics|volume=1|issue=1–4|year=2010|pages=27–41|issn=1868-8071|doi=10.1007/s13042-010-0007-7|s2cid=8729381|url=http://pralab.diee.unica.it/en/node/671}}&lt;/ref&gt;&lt;ref name="Adversarial Machine Learning_18A"&gt;{{cite journal |last1=Brückner |first1=Michael |last2=Kanzow |first2=Christian |last3=Scheffer |first3=Tobias |title=Static Prediction Games for Adversarial Learning Problems |journal=Journal of Machine Learning Research |date=2012 |volume=13 |issue=Sep |pages=2617–2654 |url=http://www.jmlr.org/papers/volume13/brueckner12a/brueckner12a.pdf |issn=1533-7928}}&lt;/ref&gt; attacks in [[computer security]], such as obfuscating malware code within [[network packet]]s or to mislead signature detection; attacks in biometric recognition where fake biometric traits may be exploited to impersonate a legitimate user;&lt;ref name="RodriguesLing2009"&gt;{{cite journal |last1=Rodrigues |first1=Ricardo N. |last2=Ling |first2=Lee Luan |last3=Govindaraju |first3=Venu |title=Robustness of multimodal biometric fusion methods against spoof attacks |journal=Journal of Visual Languages &amp; Computing |date=1 June 2009 |volume=20 |issue=3 |pages=169–179 |doi=10.1016/j.jvlc.2009.01.010 |url=http://cubs.cedar.buffalo.edu/images/pdf/pub/robustness-of-multimodal-biometric-fusion-methods-against-spoof-attacks.pdf |language=en |issn=1045-926X}}&lt;/ref&gt; or to compromise users' template galleries that adapt to updated traits over time.

Researchers showed that by changing only one-pixel it was possible to fool deep learning algorithms.&lt;ref&gt;{{Cite journal | arxiv=1710.08864| doi=10.1109/TEVC.2019.2890858| title=One Pixel Attack for Fooling Deep Neural Networks| year=2019| last1=Su| first1=Jiawei| last2=Vargas| first2=Danilo Vasconcellos| last3=Sakurai| first3=Kouichi| journal=IEEE Transactions on Evolutionary Computation| volume=23| issue=5| pages=828–841| s2cid=2698863}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last1=Su |first1=Jiawei |last2=Vargas |first2=Danilo Vasconcellos |last3=Sakurai |first3=Kouichi |title=One Pixel Attack for Fooling Deep Neural Networks |journal=IEEE Transactions on Evolutionary Computation |date=October 2019 |volume=23 |issue=5 |pages=828–841 |doi=10.1109/TEVC.2019.2890858 |arxiv=1710.08864 |s2cid=2698863 |issn=1941-0026}}&lt;/ref&gt; Others [[3-D print]]ed a toy turtle with a texture engineered to make Google's object detection [[Artificial intelligence|AI]] classify it as a rifle regardless of the angle from which the turtle was viewed.&lt;ref&gt;{{cite news|title=Single pixel change fools AI programs|url=https://www.bbc.com/news/technology-41845878|access-date=12 February 2018|work=BBC News|date=3 November 2017}}&lt;/ref&gt; Creating the turtle required only low-cost commercially available 3-D printing technology.&lt;ref&gt;{{cite arxiv |eprint=1707.07397|last1=Athalye|first1=Anish|last2=Engstrom|first2=Logan|last3=Ilyas|first3=Andrew|last4=Kwok|first4=Kevin|title=Synthesizing Robust Adversarial Examples|year=2017|class=cs.CV}}&lt;/ref&gt;

A machine-tweaked image of a dog was shown to look like a cat to both computers and humans.&lt;ref&gt;{{cite news|title=AI Has a Hallucination Problem That's Proving Tough to Fix|url=https://www.wired.com/story/ai-has-a-hallucination-problem-thats-proving-tough-to-fix/|access-date=10 March 2018|work=WIRED|date=2018}}&lt;/ref&gt; A 2019 study reported that humans can guess how machines will classify adversarial images.&lt;ref&gt;{{cite journal |doi=10.1038/s41467-019-08931-6 |doi-access=free|title=Humans can decipher adversarial images|year=2019|last1=Zhou|first1=Zhenglong|last2=Firestone|first2=Chaz|journal=Nature Communications|volume=10|issue=1|page=1334|pmid=30902973|pmc=6430776|arxiv=1809.04120|bibcode=2019NatCo..10.1334Z}}&lt;/ref&gt; Researchers discovered methods for perturbing the appearance of a stop sign such that an autonomous vehicle classified it as a merge or speed limit sign.&lt;ref name="LimTaeihagh2019" /&gt;&lt;ref&gt;{{Cite web|url=https://towardsdatascience.com/breaking-neural-networks-with-adversarial-attacks-f4290a9a45aa|title=Breaking neural networks with adversarial attacks - Towards Data Science|last=Jain|first=Anant|date=2019-02-09|website=Medium|language=en|access-date=2019-07-15}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://spectrum.ieee.org/cars-that-think/transportation/sensors/slight-street-sign-modifications-can-fool-machine-learning-algorithms|title=Slight Street Sign Modifications Can Completely Fool Machine Learning Algorithms|last=Ackerman|first=Evan|date=2017-08-04|website=IEEE Spectrum: Technology, Engineering, and Science News|language=en|access-date=2019-07-15}}&lt;/ref&gt;

[[McAfee]] attacked [[Tesla, Inc.|Tesla]]'s former [[Mobileye]] system, fooling it into driving 50&amp;nbsp;mph over the speed limit, simply by adding a two-inch strip of black tape to a speed limit sign.&lt;ref&gt;{{cite news |title=A Tiny Piece of Tape Tricked Teslas Into Speeding Up 50 MPH |url=https://www.wired.com/story/tesla-speed-up-adversarial-example-mgm-breach-ransomware/ |access-date=11 March 2020 |work=Wired |date=2020 |language=en}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://securingtomorrow.mcafee.com/blogs/other-blogs/mcafee-labs/model-hacking-adas-to-pave-safer-roads-for-autonomous-vehicles|title=Model Hacking ADAS to Pave Safer Roads for Autonomous Vehicles|date=2020-02-19|website=McAfee Blogs|language=en-US|access-date=2020-03-11}}&lt;/ref&gt;

Adversarial patterns on glasses or clothing designed to deceive facial-recognition systems or license-plate readers, have led to a niche industry of "stealth streetwear".&lt;ref&gt;{{cite news |last1=Seabrook |first1=John |title=Dressing for the Surveillance Age |url=https://www.newyorker.com/magazine/2020/03/16/dressing-for-the-surveillance-age |access-date=5 April 2020 |work=The New Yorker |date=2020 |language=en}}&lt;/ref&gt;

An adversarial attack on a neural network can allow an attacker to inject algorithms into the target system.&lt;ref name="nature why"&gt;{{cite journal|last1=Heaven|first1=Douglas|title=Why deep-learning AIs are so easy to fool|date=October 2019|journal=Nature|volume=574|issue=7777|pages=163–166|language=en|doi=10.1038/d41586-019-03013-5|pmid=31597977|bibcode=2019Natur.574..163H|doi-access=free}}&lt;/ref&gt; Researchers can also create adversarial audio inputs to disguise commands to intelligent assistants in benign-seeming audio;&lt;ref&gt;{{cite journal|last1=Hutson|first1=Matthew|date=10 May 2019|title=AI can now defend itself against malicious messages hidden in speech|journal=Nature|doi=10.1038/d41586-019-01510-1|pmid=32385365}}&lt;/ref&gt; a parallel literature explores human perception of such stimuli.&lt;ref&gt;{{cite arxiv|last1=Lepori|first1= Michael A|last2=Firestone|first2=Chaz|date=2020-03-27|title=Can you hear me now? Sensitive comparisons of human and machine perception|class=eess.AS|eprint=2003.12362}}&lt;/ref&gt;&lt;ref&gt;{{cite arxiv|last1=Vadillo|first1=Jon|last2=Santana|first2=Roberto|date=2020-01-23|title=On the human evaluation of audio adversarial examples|class=eess.AS|eprint=2001.08444}}&lt;/ref&gt;

Clustering algorithms are used in security applications. Malware and [[computer viruses|computer virus]] analysis aims to identify malware families, and to generate specific detection signatures.&lt;ref name="Adversarial Machine Learning_42A"&gt;D. B. Skillicorn. "Adversarial knowledge discovery". IEEE Intelligent Systems, 24:54–61, 2009.&lt;/ref&gt;&lt;ref name="Adversarial Machine Learning_46A"&gt;B. Biggio, G. Fumera, and F. Roli. "[http://pralab.diee.unica.it/en/node/1103 Pattern recognition systems under attack: Design issues and research challenges]". Int'l J. Patt. Recogn. Artif. Intell., 28(7):1460002, 2014.&lt;/ref&gt;

==Attack Modalities==
===Taxonomy===
Attacks against (supervised) machine learning algorithms have been categorized along three primary axes:&lt;ref name="Adversarial Machine Learning_2"&gt;{{Cite journal|url=https://link.springer.com/content/pdf/10.1007/s10994-010-5188-5.pdf|doi = 10.1007/s10994-010-5188-5|title = The security of machine learning|year = 2010|last1 = Barreno|first1 = Marco|last2 = Nelson|first2 = Blaine|last3 = Joseph|first3 = Anthony D.|last4 = Tygar|first4 = J. D.|journal = Machine Learning|volume = 81|issue = 2|pages = 121–148|s2cid = 2304759}}&lt;/ref&gt; influence on the classifier, the security violation and their specificity.

* Classifier influence: An attack can influence the classifier by disrupting the classification phase. This may be preceded by an exploration phase to identify vulnerabilities. The attacker's capabilities might restricted by the presence of data manipulation constraints.&lt;ref&gt;{{cite book |last=Sikos |first=Leslie F. |title=AI in Cybersecurity |volume=151 |location=Cham |publisher=Springer |isbn=978-3-319-98841-2 |doi=10.1007/978-3-319-98842-9 | page = 50 |series=Intelligent Systems Reference Library |year=2019 }}&lt;/ref&gt;
*Security violation: An attack can supply malicious data that gets classified as legitimate. Malicious data supplied during training can cause legitimate data to be rejected after training.
*Specificity: A targeted attack attempts to allow a specific intrusion/disruption. Alternatively, an indiscriminate attack creates general mayhem.
This taxonomy has been extended into a more comprehensive threat model that allows explicit assumptions about the adversary's goal, knowledge of the attacked system, capability of manipulating the input data/system components, and on attack strategy.&lt;ref name="Adversarial Machine Learning_4A"&gt;B. Biggio, G. Fumera, and F. Roli. "[http://pralab.diee.unica.it/en/node/657 Security evaluation of pattern classifiers under attack] {{Webarchive|url=https://web.archive.org/web/20180518055115/http://pralab.diee.unica.it/en/node/657|date=2018-05-18}}". IEEE Transactions on Knowledge and Data Engineering, 26(4):984–996, 2014.&lt;/ref&gt;&lt;ref name="Adversarial Machine Learning_5A"&gt;{{cite book|last1=Biggio|first1=Battista|title=Support Vector Machines Applications|last2=Corona|first2=Igino|last3=Nelson|first3=Blaine|last4=Rubinstein|first4=Benjamin I. P.|last5=Maiorca|first5=Davide|last6=Fumera|first6=Giorgio|last7=Giacinto|first7=Giorgio|last8=Roli|first8=Fabio|date=2014|publisher=Springer International Publishing|isbn=978-3-319-02300-7|pages=105–153|language=en|chapter=Security Evaluation of Support Vector Machines in Adversarial Environments|arxiv=1401.7727|doi=10.1007/978-3-319-02300-7_4|s2cid=18666561}}&lt;/ref&gt; This taxonomy has further been extended to include dimensions for defense strategies against adverserial attacks.&lt;ref&gt;{{Cite journal|last=Heinrich|first=Kai|last2=Graf|first2=Johannes|last3=Chen|first3=Ji|last4=Laurisch|first4=Jakob|last5=Zschech|first5=Patrick|date=2020-06-15|title=FOOL ME ONCE, SHAME ON YOU, FOOL ME TWICE, SHAME ON ME: A TAXONOMY OF ATTACK AND DE-FENSE PATTERNS FOR AI SECURITY|url=https://aisel.aisnet.org/ecis2020_rp/166|journal=ECIS 2020 Research Papers}}&lt;/ref&gt; Two of the main attack scenarios are:

=== Strategies ===

====Evasion ====
Evasion attacks&lt;ref name="Adversarial Machine Learning_4A" /&gt;&lt;ref name="Adversarial Machine Learning_5A" /&gt;&lt;ref name="Adversarial Machine Learning_36A"&gt;B. Nelson, B. I. Rubinstein, L. Huang, A. D. Joseph, S. J. Lee, S. Rao, and J. D. Tygar. "[http://www.jmlr.org/papers/volume13/nelson12a/nelson12a.pdf Query strategies for evading convex-inducing classifiers]". J. Mach. Learn. Res., 13:1293–1332, 2012&lt;/ref&gt; are the most prevalent type of attack. For instance, spammers and hackers often attempt to evade detection by obfuscating the content of spam emails and [[malware]]. Samples are modified to evade detection; that is, to be classified as legitimate. This does not involve influence over the training data. A clear example of evasion is [[Image spam|image-based spam]] in which the spam content is embedded within an attached image to evade textual analysis by anti-spam filters. Another example of evasion is given by spoofing attacks against biometric verification systems.&lt;ref name="RodriguesLing2009" /&gt;

====Poisoning====
Poisoning is adversarial contamination of training data. Machine learning systems can be re-trained using data collected during operations. For instance, [[Intrusion detection system|intrusion detection systems (IDSs)]] are often re-trained using such data. An attacker may poison this data by injecting malicious samples during operation that subsequently disrupt retraining.&lt;ref name="Adversarial Machine Learning_4A" /&gt;&lt;ref name="Adversarial Machine Learning_5A" /&gt;&lt;ref name="Adversarial Machine Learning_2" /&gt;&lt;ref name="Adversarial Machine Learning_15A"&gt;B. Biggio, B. Nelson, and P. Laskov. "[http://pralab.diee.unica.it/en/node/751 Support vector machines under adversarial label noise]". In Journal of Machine Learning Research - Proc. 3rd Asian Conf. Machine Learning, volume 20, pp. 97–112, 2011.&lt;/ref&gt;&lt;ref name="Adversarial Machine Learning_29A"&gt;M. Kloft and P. Laskov. "[http://www.jmlr.org/papers/volume13/kloft12b/kloft12b.pdf Security analysis of online centroid anomaly detection]". Journal of Machine Learning Research, 13:3647–3690, 2012.&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://towardsdatascience.com/poisoning-attacks-on-machine-learning-1ff247c254db|title=Poisoning attacks on Machine Learning - Towards Data Science|last=Moisejevs|first=Ilja|date=2019-07-15|website=Medium|language=en|access-date=2019-07-15}}&lt;/ref&gt;

==== Model Stealing ====
Model stealing (also called model extraction) involves an adversary probing a black box machine learning system in order to either reconstruct the model or extract the data it was trained on.&lt;ref&gt;{{Cite web|date=2020-04-06|title=How to steal modern NLP systems with gibberish?|url=http://cleverhans.io/2020/04/06/stealing-bert.html|access-date=2020-10-15|website=cleverhans-blog|language=en}}&lt;/ref&gt;&lt;ref name=":1"&gt;{{cite arxiv|last1=Wang|first1=Xinran|last2=Xiang|first2=Yu|last3=Gao|first3=Jun|last4=Ding|first4=Jie|date=2020-09-13|title=Information Laundering for Model Privacy|class=cs.CR|eprint=2009.06112}}&lt;/ref&gt;  This can cause issues when either the training data or the model itself is sensitive and confidential. For example, model stealing could be used to extract a proprietary stock trading model which the adversary could then use for their own financial benefit.

== Specific Attacks Types ==
There are a large variety of different adversarial attacks that can be used against machine learning systems. Many of these work on both [[deep learning]] systems as well as traditional machine learning models such as [[Support vector machine|SVMs]]&lt;ref&gt;{{cite arxiv|last1=Biggio|first1=Battista|last2=Nelson|first2=Blaine|last3=Laskov|first3=Pavel|date=2013-03-25|title=Poisoning Attacks against Support Vector Machines|class=cs.LG|eprint=1206.6389}}&lt;/ref&gt; and  [[linear regression]].&lt;ref&gt;{{Cite journal|last1=Jagielski|first1=Matthew|last2=Oprea|first2=Alina|last3=Biggio|first3=Battista|last4=Liu|first4=Chang|last5=Nita-Rotaru|first5=Cristina|last6=Li|first6=Bo|date=May 2018|title=Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning|url=http://dx.doi.org/10.1109/sp.2018.00057|journal=2018 IEEE Symposium on Security and Privacy (SP)|pages=19–35|publisher=IEEE|doi=10.1109/sp.2018.00057|arxiv=1804.00308|isbn=978-1-5386-4353-2|s2cid=4551073}}&lt;/ref&gt; A high level sample of these attack types include:

* Adversarial Examples&lt;ref&gt;{{Cite web|date=2017-02-24|title=Attacking Machine Learning with Adversarial Examples|url=https://openai.com/blog/adversarial-example-research/|access-date=2020-10-15|website=OpenAI|language=en}}&lt;/ref&gt;
* Trojan Attacks / Backdoor Attacks&lt;ref&gt;{{cite arxiv|last1=Gu|first1=Tianyu|last2=Dolan-Gavitt|first2=Brendan|last3=Garg|first3=Siddharth|date=2019-03-11|title=BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain|class=cs.CR|eprint=1708.06733}}&lt;/ref&gt;
* Model Inversion&lt;ref&gt;{{Cite journal|last1=Veale|first1=Michael|last2=Binns|first2=Reuben|last3=Edwards|first3=Lilian|date=2018-11-28|title=Algorithms that remember: model inversion attacks and data protection law|journal=Philosophical Transactions. Series A, Mathematical, Physical, and Engineering Sciences|volume=376|issue=2133|doi=10.1098/rsta.2018.0083|issn=1364-503X|pmc=6191664|pmid=30322998|arxiv=1807.04644|bibcode=2018RSPTA.37680083V}}&lt;/ref&gt;
* Membership Inference &lt;ref&gt;{{cite arxiv|last1=Shokri|first1=Reza|last2=Stronati|first2=Marco|last3=Song|first3=Congzheng|last4=Shmatikov|first4=Vitaly|date=2017-03-31|title=Membership Inference Attacks against Machine Learning Models|class=cs.CR|eprint=1610.05820}}&lt;/ref&gt;

=== Adversarial Examples ===
An adversarial examples refers to specially crafted input which is design to look "normal" to humans but causes misclassification to a machine learning model.  Often, a form of specially designed "noise"  is used to elicit the misclassifications. Below are some current techniques for generating  adversarial examples in the literature (by no means an exhaustive list).

* Fast Gradient Sign Method (FGSM)&lt;ref name="Explaining and Harnessing Adversari"&gt;{{cite arxiv|last1=Goodfellow|first1=Ian J.|last2=Shlens|first2=Jonathon|last3=Szegedy|first3=Christian|date=2015-03-20|title=Explaining and Harnessing Adversarial Examples|class=stat.ML|eprint=1412.6572}}&lt;/ref&gt;
* Projected Gradient Descent (PGD)&lt;ref&gt;{{cite arxiv|last1=Madry|first1=Aleksander|last2=Makelov|first2=Aleksandar|last3=Schmidt|first3=Ludwig|last4=Tsipras|first4=Dimitris|last5=Vladu|first5=Adrian|date=2019-09-04|title=Towards Deep Learning Models Resistant to Adversarial Attacks|class=stat.ML|eprint=1706.06083}}&lt;/ref&gt;
* Carlini and Wagner (C&amp;W) attack&lt;ref&gt;{{cite arxiv|last1=Carlini|first1=Nicholas|last2=Wagner|first2=David|date=2017-03-22|title=Towards Evaluating the Robustness of Neural Networks|class=cs.CR|eprint=1608.04644}}&lt;/ref&gt;
* Adversarial patch attack&lt;ref&gt;{{cite arxiv|last1=Brown|first1=Tom B.|last2=Mané|first2=Dandelion|last3=Roy|first3=Aurko|last4=Abadi|first4=Martín|last5=Gilmer|first5=Justin|date=2018-05-16|title=Adversarial Patch|class=cs.CV|eprint=1712.09665}}&lt;/ref&gt;

== Defenses ==
[[File:Proactive arms race.jpg|thumb|Conceptual representation of the proactive arms race&lt;ref name="Adversarial Machine Learning_5A" /&gt;&lt;ref name="Adversarial Machine Learning_46A" /&gt;]]Researchers have proposed a multi-step approach to protecting machine learning.&lt;ref name=":0" /&gt;

* Threat modeling - Formalize the attackers goals and capabilities with respect to the target system.
* Attack simulation - Formalize the optimization problem the attacker tries to solve according to possible attack strategies.
* Attack impact evaluation
* Countermeasure design
* Noise detection (For evasion based attack)&lt;ref&gt;{{Cite arXiv|eprint = 2007.00337|author1 = Kishor Datta Gupta|last2 = Akhtar|first2 = Zahid|last3 = Dasgupta|first3 = Dipankar|title = Determining Sequence of Image Processing Technique (IPT) to Detect Adversarial Attacks|year = 2020|class = cs.CV}}&lt;/ref&gt;
*Information laundering - Alter the information received by adversaries (for model stealing attacks)&lt;ref name=":1" /&gt;

=== Mechanisms ===
A number of defense mechanisms against evasion, poisoning, and privacy attacks have been proposed, including:

* Secure learning algorithms&lt;ref name="Adversarial Machine Learning_18A" /&gt;&lt;ref name="Adversarial Machine Learning_22A"&gt;O. Dekel, O. Shamir, and L. Xiao. "[https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/DekelShXi09.pdf Learning to classify with missing and corrupted features]". Machine Learning, 81:149–178, 2010.&lt;/ref&gt;&lt;ref name="Adversarial Machine Learning_45A"&gt;{{Cite journal|url=https://link.springer.com/content/pdf/10.1007/s10994-010-5199-2.pdf|doi=10.1007/s10994-010-5199-2|title=Mining adversarial patterns via regularized loss minimization|year=2010|last1=Liu|first1=Wei|last2=Chawla|first2=Sanjay|journal=Machine Learning|volume=81|pages=69–83|s2cid=17497168}}&lt;/ref&gt;
* Multiple classifier systems&lt;ref name="BiggioFumera2010" /&gt;&lt;ref name="Adversarial Machine Learning_10A"&gt;B. Biggio, G. Fumera, and F. Roli. "[http://pralab.diee.unica.it/en/node/642 Evade hard multiple classifier systems]". In O. Okun and G. Valentini, editors, Supervised and Unsupervised Ensemble Methods and Their Applications, volume 245 of Studies in Computational Intelligence, pages 15–38. Springer Berlin / Heidelberg, 2009.&lt;/ref&gt;
* AI-written algorithms.&lt;ref name="nature why"/&gt;
* AIs that explore the training environment; for example, in image recognition, actively navigating a 3D environment rather than passively scanning a fixed set of 2D images.&lt;ref name="nature why"/&gt;
* Privacy-preserving learning&lt;ref name="Adversarial Machine Learning_5A" /&gt;&lt;ref name="Adversarial Machine Learning_41A"&gt;B. I. P. Rubinstein, P. L. Bartlett, L. Huang, and N. Taft. "[https://arxiv.org/abs/0911.5708 Learning in a large function space: Privacy- preserving mechanisms for svm learning]". Journal of Privacy and Confidentiality, 4(1):65–100, 2012.&lt;/ref&gt;
* Ladder algorithm for [[Kaggle]]-style competitions
* Game theoretic models&lt;ref name="feature_select"&gt;M. Kantarcioglu, B. Xi, C. Clifton. [http://www.stat.purdue.edu/~xbw/research/BoweiXi.AdversarialClassification2010.pdf "Classifier Evaluation and Attribute Selection against Active Adversaries"]. Data Min. Knowl. Discov., 22:291–335, January 2011.&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last1=Chivukula|first1=Aneesh|last2=Yang|first2=Xinghao|last3=Liu|first3=Wei|last4=Zhu|first4=Tianqing|last5=Zhou|first5=Wanlei|date=2020|title=Game Theoretical Adversarial Deep Learning with Variational Adversaries|url=https://ieeexplore.ieee.org/document/8986751|journal=IEEE Transactions on Knowledge and Data Engineering|pages=1|doi=10.1109/TKDE.2020.2972320|issn=1558-2191}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last1=Chivukula|first1=Aneesh Sreevallabh|last2=Liu|first2=Wei|date=2019|title=Adversarial Deep Learning Models with Multiple Adversaries|url=https://ieeexplore.ieee.org/document/8399545|journal=IEEE Transactions on Knowledge and Data Engineering|volume=31|issue=6|pages=1066–1079|doi=10.1109/TKDE.2018.2851247|s2cid=67024195|issn=1558-2191}}&lt;/ref&gt;
* Sanitizing training data
* Adversarial training&lt;ref name="Explaining and Harnessing Adversari"/&gt;
* Backdoor detection algorithms&lt;ref&gt;{{Cite web|title=TrojAI|url=https://www.iarpa.gov/index.php/research-programs/trojai|access-date=2020-10-14|website=www.iarpa.gov}}&lt;/ref&gt;

==Software==
Available software libraries, mainly for testing and research.
* [http://pralab.diee.unica.it/en/AdversariaLib AdversariaLib] - includes implementation of evasion attacks
* [https://github.com/vu-aml/adlib AdLib] - Python library with a scikit-style interface which includes implementations of a number of published evasion attacks and defenses
* [http://pralab.diee.unica.it/en/ALFASVMLib AlfaSVMLib] - Adversarial Label Flip Attacks against Support Vector Machines&lt;ref name="Adversarial Machine Learning_49A"&gt;H. Xiao, B. Biggio, B. Nelson, H. Xiao, C. Eckert, and F. Roli. "[http://pralab.diee.unica.it/en/node/1104 Support vector machines under adversarial label contamination]". Neurocomputing, Special Issue on Advances in Learning with Label Noise, In Press.&lt;/ref&gt;
* [http://pralab.diee.unica.it/en/BattistaBiggio/Code Poisoning Attacks against Support Vector Machines], and [http://pralab.diee.unica.it/en/BattistaBiggio/Code Attacks against Clustering Algorithms]
* [https://github.com/cchio/deep-pwning deep-pwning] - Metasploit for deep learning which currently has attacks on deep neural networks using [[TensorFlow|Tensorflow]].&lt;ref&gt;{{Cite web|url=https://github.com/cchio/deep-pwning|title=cchio/deep-pwning|website=GitHub|access-date=2016-08-08}}&lt;/ref&gt; This framework currently updates to maintain compatibility with the latest versions of Python.
* [https://github.com/tensorflow/cleverhans Cleverhans] - A Tensorflow Library to test existing deep learning models versus known attacks
*[https://github.com/bethgelab/foolbox foolbox] - Python Library to create adversarial examples, implements multiple attacks
*[https://gitlab.com/secml/secml SecML] - Python Library for secure and explainable machine learning - includes implementation of a wide range of ML and attack algorithms, support for dense and sparse data, multiprocessing, visualization tools.
*[https://github.com/trojai/trojai TrojAI]- Python Library for generating backdoored and trojaned models at scale for research into trojan detection
*[https://github.com/Trusted-AI/adversarial-robustness-toolbox Adversarial Robustness Toolkit (IBM ART)] - Python Library for Machine Learning Security 
*[https://github.com/BorealisAI/advertorch Advertorch] - Python toolbox for adversarial robustness research whose main functions are implemented in [[PyTorch]]

==See also==
* [[Pattern recognition]]

==References==
{{reflist}}

== External links ==
* NIPS 2007 Workshop on [https://web.archive.org/web/20120108072159/http://nips.cc/Conferences/2007/Program/event.php?ID=615 Machine Learning in Adversarial Environments for Computer Security]
* {{cite journal |doi=10.1007/s10994-010-5207-6|title=Machine learning in adversarial environments|year=2010|last1=Laskov|first1=Pavel|last2=Lippmann|first2=Richard|journal=Machine Learning|volume=81|issue=2|pages=115–119|s2cid=12567278}}
* Dagstuhl Perspectives Workshop on "[http://www.dagstuhl.de/en/program/calendar/semhp/?semnr=12371 Machine Learning Methods for Computer Security]"
* Workshop on [http://aisec.cc Artificial Intelligence and Security], (AISec) Series

{{Differentiable computing}}

[[Category:Machine learning]]
[[Category:Computer security]]</text>
      <sha1>4ih6vnt20jr45st602gfdbom7r03mp2</sha1>
    </revision>
  </page>
  <page>
    <title>Domain adaptation</title>
    <ns>0</ns>
    <id>45390860</id>
    <revision>
      <id>994145684</id>
      <parentid>986607771</parentid>
      <timestamp>2020-12-14T08:29:48Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 15 templates: del empty params (1×); hyphenate params (2×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="12874" xml:space="preserve">{{short description|Field associated with machine learning and transfer learning}}
{{technical|date=February 2015}}

[[File:Transfer learning and domain adaptation.png|thumb|Distinction between usual machine learning setting and transfer learning, and positioning of domain adaptation.]]

'''Domain adaptation'''&lt;ref&gt;{{cite book |last1=Redko |first1=Ievgen |last2=Morvant |first2=Emilie |last3=Habrard |first3=Amaury |last4=Sebban |first4=Marc |last5=Bennani |first5=Younès |title=Advances in Domain Adaptation Theory |date=2019 |publisher=ISTE Press - Elsevier |isbn=9781785482366 |pages=187 |url=https://www.elsevier.com/books/advances-in-domain-adaptation-theory/redko/978-1-78548-236-6}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last1=Bridle|first1=John S.|last2=Cox|first2=Stephen J|chapter=RecNorm: Simultaneous normalisation and classification applied to speech recognition|title=Conference on Neural Information Processing Systems (NIPS)|date=1990|pages=234–240|chapter-url=http://papers.nips.cc/paper/328-recnorm-simultaneous-normalisation-and-classification-applied-to-speech-recognition.pdf}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Ben-David|first1=Shai|last2=Blitzer|first2=John|last3=Crammer|first3=Koby|last4=Kulesza|first4=Alex|last5=Pereira|first5=Fernando|last6=Wortman Vaughan|first6=Jennifer|title=A theory of learning from different domains|journal=Machine Learning|date=2010|volume=79|issue=1–2|pages=151–175|url=https://link.springer.com/content/pdf/10.1007/s10994-009-5152-4.pdf|doi=10.1007/s10994-009-5152-4}}&lt;/ref&gt; is a field associated with [[machine learning]] and [[inductive transfer|transfer learning]]. This scenario arises when we aim at learning from a source data distribution a well performing model on a different (but related) target data distribution. For instance, one of the tasks of the common [[Anti-spam techniques|spam filtering problem]] consists in adapting a model from one user (the source distribution) to a new user who receives significantly different emails (the target distribution). Domain adaptation has also been shown to be beneficial for learning unrelated sources.&lt;ref name=":bmdl"&gt;{{Cite arXiv |eprint = 1810.09433|last1 = Hajiramezanali|first1 = Ehsan|title = Bayesian multi-domain learning for cancer subtype discovery from next-generation sequencing count data|author2 = Siamak Zamani Dadaneh|last3 = Karbalayghareh|first3 = Alireza|last4 = Zhou|first4 = Mingyuan|last5 = Qian|first5 = Xiaoning|class = stat.ML|year = 2018}}&lt;/ref&gt;
Note that, when more than one source distribution is available the problem is referred to as multi-source domain adaptation.&lt;ref&gt;{{cite journal|last1=Crammer|first1=Koby|last2=Kearns|first2=Michael|last3=Wortman|first3=Jeniifer|title=Learning from Multiple Sources|journal=Journal of Machine Learning Research|date=2008|volume=9|pages=1757–1774|url=http://www.jmlr.org/papers/volume9/crammer08a/crammer08a.pdf}}&lt;/ref&gt;

== Overview ==
Domain adaptation is the ability to apply an algorithm trained in one or more "source domains" to a different (but related) "target domain". Domain adaptation is a subcategory of transfer learning. In domain adaptation, the source and target domains all have the same [[feature space]] (but different distributions); in contrast, transfer learning includes cases where the target domain's feature space is different from the source feature space or spaces.&lt;ref name="survey multi-source"&gt;{{cite journal |last1=Sun |first1=Shiliang |last2=Shi |first2=Honglei |last3=Wu |first3=Yuanbin |title=A survey of multi-source domain adaptation |journal=Information Fusion |date=July 2015 |volume=24 |pages=84–92 |doi=10.1016/j.inffus.2014.12.003}}&lt;/ref&gt;

=== Domain shift ===
A '''domain shift''',&lt;ref name=frustratingly&gt;Sun, Baochen, Jiashi Feng, and Kate Saenko. "Return of frustratingly easy domain adaptation." In Thirtieth AAAI Conference on Artificial Intelligence. 2016.&lt;/ref&gt; or '''distributional shift''',&lt;ref&gt;Amodei, Dario, Chris Olah, Jacob Steinhardt, Paul Christiano, John Schulman, and Dan Mané. "Concrete problems in AI safety." arXiv preprint arXiv:1606.06565 (2016).&lt;/ref&gt; is a change in the data distribution between an algorithm's training dataset, and a dataset it encounters when deployed. These domain shifts are common in practical applications of artificial intelligence. Conventional machine-learning algorithms often adapt poorly to domain shifts. The modern machine-learning community has many different strategies to attempt to gain better domain adaptation.&lt;ref name=frustratingly/&gt;

=== Examples ===
* An algorithm trained on newswires might have to adapt to a new dataset of biomedical documents.&lt;ref&gt;Daumé III, Hal. "Frustratingly easy domain adaptation." arXiv preprint arXiv:0907.1815 (2009).&lt;/ref&gt;
* A spam filter, trained on a certain group of email users during training, must adapt to a new target user when deployed.&lt;ref&gt;Ben-David, Shai, John Blitzer, Koby Crammer, and Fernando Pereira. "Analysis of representations for domain adaptation." In Advances in neural information processing systems, pp. 137-144. 2007.&lt;/ref&gt;
* Applying AI diagnostic algorithms, trained on labeled data associated with previous diseases, to new unlabeled data associated with the [[COVID-19 pandemic]].&lt;ref&gt;{{cite journal |last1=Hu |first1=Yipeng |last2=Jacob |first2=Joseph |last3=Parker |first3=Geoffrey J. M. |last4=Hawkes |first4=David J. |last5=Hurst |first5=John R. |last6=Stoyanov |first6=Danail |title=The challenges of deploying artificial intelligence models in a rapidly evolving pandemic |journal=Nature Machine Intelligence |date=June 2020 |volume=2 |issue=6 |pages=298–300 |doi=10.1038/s42256-020-0185-2 |url=https://www.nature.com/articles/s42256-020-0185-2 |language=en |issn=2522-5839|doi-access=free }}&lt;/ref&gt;
* A sudden societal change, such as a pandemic outbreak, can constitute domain shift and cause machine learning algorithms trained on now-obsolete consumer data to fail and require intervention.&lt;ref&gt;{{cite news |last1=Matthews |first1=Dylan |title=AI disaster won’t look like the Terminator. It’ll be creepier. |url=https://www.vox.com/future-perfect/2019/3/26/18281297/ai-artificial-intelligence-safety-disaster-scenarios |access-date=21 June 2020 |work=Vox |date=26 March 2019 |language=en}}&lt;/ref&gt;&lt;ref&gt;{{cite news |title=Our weird behavior during the pandemic is messing with AI models |url=https://www.technologyreview.com/2020/05/11/1001563/covid-pandemic-broken-ai-machine-learning-amazon-retail-fraud-humans-in-the-loop/ |access-date=21 June 2020 |work=MIT Technology Review |date=11 May 2020 |language=en}}&lt;/ref&gt;

Other applications include wifi localization detection and many aspects of [[computer vision]].&lt;ref name="survey multi-source"/&gt;

== Formalization ==
Let &lt;math&gt;X&lt;/math&gt; be the input space (or description space) and let &lt;math&gt;Y&lt;/math&gt; be the output space (or label space). The objective of a machine learning algorithm is to learn a mathematical model (a hypothesis) &lt;math&gt;h:X\to Y&lt;/math&gt; able to attach a label from &lt;math&gt;Y&lt;/math&gt; to an example from &lt;math&gt;X&lt;/math&gt;. This model is learned from a learning sample &lt;math&gt;S=\{(x_i,y_i) \in (X \times Y)\}_{i=1}^m&lt;/math&gt;.

Usually in [[supervised learning]] (without domain adaptation), we suppose that the examples &lt;math&gt;(x_i,y_i)\in S&lt;/math&gt; are drawn i.i.d. from a distribution &lt;math&gt;D_S&lt;/math&gt; of support &lt;math&gt;X\times Y&lt;/math&gt; (unknown and fixed). The objective is then to learn &lt;math&gt;h&lt;/math&gt; (from &lt;math&gt;S&lt;/math&gt;) such that it commits the least error possible for labelling new examples coming from the distribution &lt;math&gt;D_S&lt;/math&gt;.

The main difference between supervised learning and domain adaptation is that in the latter situation we study two different (but related) distributions &lt;math&gt;D_S&lt;/math&gt; and &lt;math&gt;D_T&lt;/math&gt; on &lt;math&gt;X\times Y&lt;/math&gt;{{cn|date=February 2020}}. The domain adaptation task then consists of the transfer of knowledge from the source domain &lt;math&gt;D_S&lt;/math&gt; to the target one &lt;math&gt;D_T&lt;/math&gt;. The goal is then to learn &lt;math&gt;h&lt;/math&gt; (from labeled or unlabelled samples coming from the two domains) such that it commits as little error as possible on the target domain &lt;math&gt;D_T&lt;/math&gt;{{cn|date=February 2020}}.

The major issue is the following: if a model is learned from a source domain, what is its capacity to correctly label data coming from the target domain?

== The different types of domain adaptation == 
There are several contexts of domain adaptation. They differ in the information considered for the target task.
# The '''unsupervised domain adaptation''': the learning sample contains a set of labeled source examples, a set of unlabeled source examples and a set of unlabeled target examples.
# The '''semi-supervised domain adaptation''':  in this situation, we also consider a "small" set of labeled target examples. 
# The '''supervised domain adaptation''': all the examples considered are supposed to be labeled.

== Four algorithmic principles ==

=== Reweighting algorithms ===
The objective is to reweight the source labeled sample such that it "looks like" the target sample (in terms of the error measure considered).&lt;ref&gt;{{cite book|last1=Huang|first1=Jiayuan|last2=Smola|first2=Alexander J.|last3=Gretton|first3=Arthur|last4=Borgwardt|first4=Karster M.|last5=Schölkopf|first5=Bernhard|chapter=Correcting Sample Selection Bias by Unlabeled Data|title=Conference on Neural Information Processing Systems (NIPS)|date=2006|pages=601–608|chapter-url=http://papers.nips.cc/paper/3075-correcting-sample-selection-bias-by-unlabeled-data.pdf}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Shimodaira|first1=Hidetoshi|title=Improving predictive inference under covariate shift by weighting the log-likelihood function|journal=Journal of Statistical Planning and Inference|date=2000|volume=90|issue=2|pages=227–244|doi=10.1016/S0378-3758(00)00115-4|url=https://www.researchgate.net/publication/230710850}}&lt;/ref&gt;

=== Iterative algorithms ===
A method for adapting consists in iteratively "auto-labeling" the target examples. The principle is simple:
# a model &lt;math&gt;h&lt;/math&gt; is learned from the labeled examples;
# &lt;math&gt;h&lt;/math&gt; automatically labels some target examples;
# a new model is learned from the new labeled examples. 
Note that there exist other iterative approaches, but they usually need target labeled examples.&lt;ref&gt;{{Cite conference|last=Arief-Ang|first=I.B.|last2=Salim|first2=F.D.|last3=Hamilton|first3=M. |date=2017-11-08|title=DA-HOC: semi-supervised domain adaptation for room occupancy prediction using CO2 sensor data|url=https://dl.acm.org/citation.cfm?id=3137146|conference=4th ACM International Conference on Systems for Energy-Efficient Built Environments (BuildSys)|pages=1–10|doi=10.1145/3137133.3137146|location=Delft, Netherlands|isbn=978-1-4503-5544-5}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last1=Arief-Ang |first1=I.B. |last2=Hamilton |first2=M. |last3=Salim |first3=F.D. |date=2018-12-01 |title=A Scalable Room Occupancy Prediction with Transferable Time Series Decomposition of CO2 Sensor Data |journal=ACM Transactions on Sensor Networks |volume=14 |issue=3–4 |pages=21:1–21:28 |doi=10.1145/3217214 }}&lt;/ref&gt;

=== Search of a common representation space ===
The goal is to find or construct a common representation space for the two domains. The objective is to obtain a space in which the domains are close to each other while keeping good performances on the source labeling task.
This can be achieved through the use of [[Adversarial machine learning]] techniques where feature representations from samples in different domains are encouraged to be indistinguishable.&lt;ref name="Domain-Adversarial Training"&gt;{{cite journal | last1 = Ganin | first1 = Yaroslav | last2 = Ustinova | first2 = Evgeniya | last3 = Ajakan | first3 = Hana | last4 = Germain | first4 = Pascal | last5 = Larochelle | first5 = Hugo | last6 = Laviolette | first6 = François | last7 = Marchand | first7 = Mario | last8 = Lempitsky | first8 = Victor | year = 2016 | title = Domain-Adversarial Training of Neural Networks | url = http://jmlr.org/papers/volume17/15-239/15-239.pdf | format = PDF | journal = Journal of Machine Learning Research | volume = 17 | pages = 1–35 }}&lt;/ref&gt;&lt;ref name="ADA"&gt;{{Cite arXiv |eprint = 1703.01461|last1 = Hajiramezanali|first1 = Ehsan|title = Addressing Appearance Change in Outdoor Robotics with Adversarial Domain Adaptation|author2 = Siamak Zamani Dadaneh|last3 = Karbalayghareh|first3 = Alireza|last4 = Zhou|first4 = Mingyuan|last5 = Qian|first5 = Xiaoning|class = cs.RO|year = 2017}}&lt;/ref&gt;

=== Hierarchical Bayesian Model ===
The goal is to construct a Bayesian hierarchical model &lt;math&gt;p(n)&lt;/math&gt;, which is essentially a factorization model for counts &lt;math&gt;n&lt;/math&gt;, to derive domain-dependent latent representations allowing both domain-specific and globally shared latent factors.&lt;ref name=":bmdl"/&gt;

== References ==
{{Reflist}}

[[Category:Machine learning]]</text>
      <sha1>9ou2rpxslo84pf45xzgqj07h5cobz40</sha1>
    </revision>
  </page>
  <page>
    <title>Logic learning machine</title>
    <ns>0</ns>
    <id>45378845</id>
    <revision>
      <id>993378941</id>
      <parentid>979505736</parentid>
      <timestamp>2020-12-10T08:25:32Z</timestamp>
      <contributor>
        <ip>94.36.120.171</ip>
      </contributor>
      <comment>advertisement</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="5171" xml:space="preserve">{{Multiple issues|
{{third-party|date=June 2015}}
{{COI|date=June 2015}}
{{Orphan|date=July 2016}}
}}

{{Machine learning bar}}

'''Logic learning machine''' ('''LLM''') is a [[machine learning]] method based on the generation of intelligible rules. LLM is an efficient implementation of the Switching Neural Network (SNN) paradigm,&lt;ref&gt;{{cite journal
|last=Muselli
|first=Marco
|title=Switching Neural Networks: A new connectionist model for classification|journal=WIRN 2005 and NAIS 2005, Lecture Notes on Computer Science
| year=2006
| volume=3931
| pages=23–30
| url=http://www.rulex.ai/wp-content/uploads/2017/04/Switching-Neural-Networks-A-New-Connectionist-Model-for-Classification.pdf}}&lt;/ref&gt; developed by Marco Muselli, Senior Researcher at the Italian National Research Council CNR-IEIIT in [[Genoa]].

LLM has been employed in may different sectors, including the field of medicine (orthopedic patient classification,&lt;ref&gt;{{cite journal
| last1=Mordenti |first1=M.
| last2=Ferrari| first2=E.
| last3=Pedrini| first3 = E.
| last4=Fabbri| first4=N.
| last5=Campanacci| first5=L.
| last6=Muselli|first6=M.
| last7=Sangiorgi| first7=L.
| title=Validation of a New Multiple Osteochondromas Classification Through Switching Neural Networks|journal=American Journal of Medical Genetics Part A
| year=2013
| volume=161
|issue=3
| pages=556–560| doi=10.1002/ajmg.a.35819| pmid=23401177|s2cid=23983960
}}&lt;/ref&gt; DNA micro-array analysis &lt;ref&gt;{{cite journal
| last1=Cangelosi|first1=D.
| last2=Muselli| first2=M.
| last3=Blengio| first3 = F.
| last4=Becherini| first4=P.
| last5=Versteeg| first5=R.
| last6=Conte | first6=M.
| last7=Varesio| first7 = L.
| title=Use of Attribute Driven Incremental Discretization and Logic Learning Machine to build a prognostic classifier for neuroblastoma patients
| journal=Bits2013
| year=2013
|volume=15
|pages=S4
|doi=10.1186/1471-2105-15-S5-S4
|pmid=25078098
|pmc=4095004
| doi-access=free
}}&lt;/ref&gt; and Clinical Decision Support Systems &lt;ref&gt;{{cite journal
| last1=Parodi|first1=S.
| last2=Filiberti| first2=R.
| last3=Marroni| first3 = P.
| last4=Montani| first4=E.
| last5=Muselli| first5=M.
| title=Differential diagnosis of pleural mesothelioma using Logic Learning Machine
|journal=Bits2014
| year=2014
|volume=16
|pages=S3
|doi=10.1186/1471-2105-16-S9-S3
|pmid=26051106
|pmc=4464205
| doi-access=free
}}&lt;/ref&gt;), financial services and supply chain management.

== History ==

The Switching Neural Network approach was developed in the 1990s to overcome the drawbacks of the most commonly used machine learning methods. In particular, black box methods, such as [[multilayer perceptron]] and [[support vector machine]], had good accuracy but could not provide deep insight into the studied phenomenon. On the other hand, [[decision tree learning|decision trees]] were able to describe the phenomenon but often lacked accuracy. Switching Neural Networks made use of [[Boolean algebra]] to build sets of intelligible rules able to obtain very good performance. In 2014, an efficient version of Switching Neural Network was developed and implemented in the [[Rulex]] suite with the name Logic Learning Machine.&lt;ref&gt;{{cite web|title=Rulex: a software for knowledge extraction from data|publisher=Italian National Research Council|accessdate=7 March 2015 |url=http://www.cnr.it/istituti/FocusByN_eng.html?cds=029&amp;nfocus=7}}&lt;/ref&gt; Also a LLM version devoted to regression problems was developed.

== General ==

Like other machine learning methods, LLM uses data to build a model able to perform a good forecast about future behaviors. LLM starts from a table including a target variable (output) and some inputs and generates a set of rules that return the output value &lt;math&gt;y&lt;/math&gt; corresponding to a given configuration of inputs. A rule is written in the form:

:&lt;math&gt; \textbf{if }  \text{  } premise \text{  } \textbf{ then } \text{  } consequence&lt;/math&gt;

where ''consequence'' contains the output value whereas ''premise'' includes one or more conditions on the inputs. According to the input type, conditions can have different forms:
* for [[categorical variable]]s the input value must be in a given subset :&lt;math&gt;x_1 \in \{A,B,C,...\}&lt;/math&gt;.
* for [[real number|ordered variables]] the condition is written as an inequality or an interval: &lt;math&gt;x_2 \leq \alpha&lt;/math&gt; or &lt;math&gt;\beta\leq x_3\leq \gamma&lt;/math&gt;

A possible rule is therefore in the form

:&lt;math&gt; \textbf{if }  \text{  } x_1 \in \{A,B,C,...\} \text{  AND  } x_2 \leq \alpha \text{  AND  } \beta\leq x_3\leq \gamma \text{  } \textbf{ then } \text{  } y = \bar{y}&lt;/math&gt;

== Types ==

According to the output type, different versions of Logic Learning Machine have been developed:
* Logic Learning Machine for classification, when the output is a [[categorical variable]], which can assume values in a finite set
* Logic Learning Machine for regression, when the output is an [[integer]] or [[real number]].

== References ==
{{Reflist}}

== External links ==
*[https://www.rulex.ai Rulex] official site

&lt;!--- Categories ---&gt;
[[Category:Machine learning|Machine learning]]
[[Category:Classification algorithms]]
[[Category:Machine learning algorithms]]</text>
      <sha1>69hljfvmzd4260c74kx3ope04025gy0</sha1>
    </revision>
  </page>
  <page>
    <title>Native-language identification</title>
    <ns>0</ns>
    <id>45627703</id>
    <revision>
      <id>983441108</id>
      <parentid>983206721</parentid>
      <timestamp>2020-10-14T07:27:41Z</timestamp>
      <contributor>
        <ip>73.70.182.232</ip>
      </contributor>
      <comment>Undid revision 983206721 by [[Special:Contributions/73.254.48.170|73.254.48.170]] ([[User talk:73.254.48.170|talk]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="5648" xml:space="preserve">{{Short description|determining someone's first language based on how they write or speak a different language}}

'''Native-language identification''' ('''NLI''') is the task of determining an author's [[first language|native language]] (L1) based only on their writings in a [[second language]] (L2).&lt;ref&gt;Wong, Sze-Meng Jojo, and Mark Dras. [http://anthology.aclweb.org/D/D11/D11-1148.pdf "Exploiting parse structures for native language identification"]. Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 2011.&lt;/ref&gt; NLI works through identifying language-usage patterns that are common to specific L1 groups and then applying this knowledge to predict the native language of previously unseen texts. This is motivated in part by applications in [[second-language acquisition]], language teaching and [[forensic linguistics]], amongst others.

== Overview ==
NLI works under the assumption that an author's L1 will dispose them towards particular language production patterns in their L2, as influenced by their native language. This relates to cross-linguistic influence (CLI), a key topic in the field of second-language acquisition (SLA) that analyzes transfer effects from the L1 on later learned languages.

Using large-scale English data, NLI methods achieve over 80% accuracy in predicting the native language of texts written by authors from 11 different L1 backgrounds. This can be compared to a baseline of 9% for choosing randomly.

==Applications==

===Pedagogy and language transfer===
This identification of L1-specific features has been used to study [[language transfer]] effects in second-language acquisition.&lt;ref&gt;Malmasi, Shervin, and Mark Dras. [http://www.aclweb.org/anthology/D/D14/D14-1144.pdf "Language Transfer Hypotheses with Linear SVM Weights."] Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2014.&lt;/ref&gt; This is useful for developing pedagogical material, teaching methods, L1-specific instructions and generating learner feedback that is tailored to their native language.

===Forensic linguistics===
NLI methods can also be applied in [[forensic linguistics]] as a method of performing authorship profiling in order to infer the attributes of an author, including their linguistic background.
This is particularly useful in situations where a text, e.g. an anonymous letter, is the key piece of evidence in an investigation and clues about the native language of a writer can help investigators in identifying the source.
This has already attracted interest and funding from intelligence agencies.&lt;ref&gt;Ria Perkins. 2014. "Linguistic identifiers of L1 Persian speakers writing in English: NLID for authorship analysis". Ph.D. thesis, Aston University.&lt;/ref&gt;

== Methodology ==

[[Natural language processing]] methods are used to extract and identify language usage patterns common to speakers of an L1-group. This is done using language learner data, usually from a [[learner corpus]]. Next, [[machine learning]] is applied to train classifiers, like [[support vector machine]]s, for predicting the L1 of unseen texts.&lt;ref&gt;Tetreault et al, [http://anthology.aclweb.org/C/C12/C12-1158.pdf "Native Tongues, Lost and Found: Resources and Empirical Evaluations in Native Language Identification"], In Proc. International Conf. on Computational Linguistics (COLING), 2012&lt;/ref&gt;
A range of ensemble based systems have also been applied to the task and shown to improve performance over single classifier systems.&lt;ref&gt;Malmasi, Shervin, Sze-Meng Jojo Wong, and Mark Dras. [http://anthology.aclweb.org/W/W13/W13-1716.pdf "NLI Shared Task 2013: MQ submission"]. Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications. 2013.&lt;/ref&gt;

Various linguistic feature types have been applied for this task. These include syntactic features such as constituent parses, grammatical dependencies and part-of-speech tags.
Surface level lexical features such as character, word and lemma [[n-gram|n-grams]] have also been found to be quite useful for this task. However, it seems that character n-grams&lt;ref&gt;Radu Tudor Ionescu, Marius Popescu and Aoife Cahill. [http://www.mitpressjournals.org/doi/abs/10.1162/COLI_a_00256 "String Kernels for Native Language Identification: Insights from Behind the Curtains"], Computational Linguistics, 2016&lt;/ref&gt;&lt;ref&gt;Radu Tudor Ionescu and Marius Popescu. [https://arxiv.org/abs/1707.08349 "Can string kernels pass the test of time in Native Language Identification?"], In Proceedings of BEA12, 2017.&lt;/ref&gt; are the single best feature for the task.

== 2013 shared task ==
The Building Educational Applications (BEA) workshop at [[NAACL]] 2013 hosted the inaugural NLI shared task.&lt;ref&gt;Tetreault et al, [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.365.5931&amp;rep=rep1&amp;type=pdf "A report on the first native language identification shared task"], 2013&lt;/ref&gt; The competition resulted in 29 entries from teams across the globe, 24 of which also published a paper describing their systems and approaches.

==See also==
{{div col|colwidth=22em}}
*[[Crosslinguistic influence]]
*[[Foreign language writing aid]]
*[[Computer-assisted language learning]]
*[[Language education]]
*[[Natural language processing]]
*[[Language transfer]]
{{div col end}}

==References==
{{reflist}}

{{DEFAULTSORT:Natural Language Processing}}
[[Category:Computational linguistics]]
[[Category:Second-language acquisition]]
[[Category:Natural language processing]]
[[Category:Machine learning]]
[[Category:Applied linguistics]]
[[Category:Bilingualism]]</text>
      <sha1>po9lnvctztxmstys4az4ubmc3vn8o3l</sha1>
    </revision>
  </page>
  <page>
    <title>Constrained conditional model</title>
    <ns>0</ns>
    <id>28255458</id>
    <revision>
      <id>981751329</id>
      <parentid>926193805</parentid>
      <timestamp>2020-10-04T07:04:24Z</timestamp>
      <contributor>
        <username>Oronsay</username>
        <id>22986354</id>
      </contributor>
      <comment>added link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="11692" xml:space="preserve">A '''constrained conditional model''' (CCM) is a [[machine learning]] and inference framework that augments the learning of conditional (probabilistic or discriminative) models with declarative constraints. The constraint can be used as a way to incorporate expressive{{clarify|date=April 2013}} prior knowledge into the model and bias the assignments made by the learned model to satisfy these constraints. The framework can be used to support decisions in an expressive output space while maintaining modularity and tractability of training and inference.

Models of this kind have recently{{when|date=March 2013}} attracted much attention{{citation needed|date=March 2013}} within the natural language processing ([[Natural Language Processing|NLP]]) community.
Formulating problems as [[constrained optimization]] problems over the output of learned models has several advantages. It allows one to focus on the modeling of problems by providing the opportunity to incorporate domain-specific knowledge as global constraints using a first order language. Using this declarative framework frees the developer from low level [[feature engineering]] while capturing the problem's domain-specific properties and guarantying exact inference. From a machine learning perspective it allows decoupling the stage of model generation (learning) from that of the constrained inference stage, thus helping to simplify the learning stage while improving the quality of the solutions. For example, in the case of generating compressed sentences, rather than simply relying on a language model to retain the most commonly used n-grams in the sentence, constraints can be used to ensure that if a modifier is kept in the compressed sentence, its subject will also be kept.

==Motivation==
Making decisions in many domains (such as natural language processing and computer vision problems) often involves assigning values to sets of interdependent variables where the expressive dependency structure can influence, or even dictate, what assignments are possible. These settings are applicable not only to Structured Learning problems such as semantic role labeling, but also for cases that require making use of multiple pre-learned components, such as summarization, textual entailment and question answering. In all these cases, it is natural to formulate the decision problem as a constrained optimization problem, with an objective function that is composed of learned models, subject to domain- or problem-specific constraints.

Constrained conditional models form a learning and inference framework that augments the learning of conditional (probabilistic or discriminative) models with declarative constraints (written, for example, using a first-order representation) as a way to support decisions in an expressive output space while maintaining modularity and tractability of training and inference. These constraints can express either hard restrictions, completely prohibiting some assignments, or soft restrictions, penalizing unlikely assignments. In most applications of this framework in NLP, following,&lt;ref&gt;Dan Roth and Wen-tau Yih, [http://l2r.cs.uiuc.edu/~danr/Papers/RothYi04.pdf "A Linear Programming Formulation for Global Inference in Natural Language Tasks."] ''CoNLL'', (2004).&lt;/ref&gt; Integer Linear Programming (ILP) was used as the inference framework, although other algorithms can be used for that purpose.

==Formal Definition==
Given a set of feature functions &lt;math&gt;\{ \phi_i(x,y) \}&lt;/math&gt; and a set of constraints &lt;math&gt;\{ C_i (x,y)\}&lt;/math&gt;, defined over an input structure &lt;math&gt;x \in X&lt;/math&gt; and an output structure  &lt;math&gt; y \in Y&lt;/math&gt;, a constraint conditional model is characterized by two weight vectors, w and &lt;math&gt;\rho&lt;/math&gt;, and is defined as the solution to the following optimization problem:
:&lt;math&gt;argmax_{y} \sum_i w_i \phi_i (x,y) - \sum \rho_i C_i (x,y)&lt;/math&gt;.
 
Each constraint  &lt;math&gt;C_i \in C&lt;/math&gt;  is a boolean mapping indicating if the joint assignment &lt;math&gt;(x,y)&lt;/math&gt; violates a constraint, and &lt;math&gt;\rho&lt;/math&gt; is the penalty incurred for violating the constraints.  Constraints assigned an infinite penalty are known as hard constraints, and represent unfeasible assignments to the optimization problem.

==Training paradigms==

=== Learning local vs. global models ===
The objective function used by CCMs can be decomposed and learned in several ways, ranging from a complete joint training of the model along with the constraints to completely decoupling the learning and the inference stage. In the latter case, several local models are learned independently and the dependency between these models is considered only at decision time via a global decision process. The advantages of each approach are discussed in &lt;ref&gt;Vasin Punyakanok and Dan Roth and Wen-Tau Yih and Dav Zimak, [http://l2r.cs.uiuc.edu/~danr/Papers/PRYZ05.pdf  "Learning and Inference over Constrained Output."]  ''IJCAI'', (2005).&lt;/ref&gt; which studies the two training paradigms: (1) local models: L+I (learning + inference) and (2) global model: IBT (Inference based training), and shows both theoretically and experimentally that while IBT (joint training) is best in the limit, under some conditions (basically, ”good” components) L+I can generalize better.

The ability of CCM to combine local models is especially beneficial in cases where joint learning is computationally intractable or when training data are not available for joint learning. This flexibility distinguishes CCM from the other learning frameworks that also combine statistical information with declarative constraints, such as [[Markov logic network]], that emphasize joint training.

=== Minimally supervised CCM ===
CCM can help reduce supervision by using [[domain knowledge]] (expressed as constraints) to drive learning. These settings were studied in 
&lt;ref&gt;Ming-Wei Chang and Lev Ratinov and Dan Roth, [http://l2r.cs.uiuc.edu/~danr/Papers/ChangRaRo07.pdf "Guiding Semi-Supervision with Constraint-Driven Learning."] ''ACL'', (2007).&lt;/ref&gt; and.&lt;ref&gt;Ming-Wei Chang and Lev Ratinov and Dan Roth, [http://l2r.cs.uiuc.edu/~danr/Papers/ChangRaRo08.pdf "Constraints as Prior Knowledge."] ''ICML Workshop on Prior Knowledge for Text and Language Processing, (2008).&lt;/ref&gt; These works introduce semi-supervised Constraints Driven Learning
(CODL) and show that by incorporating domain knowledge the performance of the learned model improves significantly.

=== Learning over latent representations ===
CCMs have also been applied to latent learning frameworks, where the learning problem is defined over a latent representation layer. Since the notion of a ''correct representation'' is inherently ill-defined, no gold-standard labeled data regarding the representation decision is available to the learner. Identifying the correct (or optimal) learning representation is viewed as a [[structured prediction]] process and therefore modeled as a CCM. 
This problem was covered in several papers, in both supervised&lt;ref&gt;Ming-Wei Chang and Dan Goldwasser and Dan Roth and Vivek Srikumar, [http://l2r.cs.uiuc.edu/~danr/Papers/CGRS10.pdf "Discriminative Learning over Constrained Latent Representations."] NAACL, (2010).&lt;/ref&gt;  and unsupervised &lt;ref&gt;Ming-Wei Chang Dan Goldwasser Dan Roth and Yuancheng Tu, [http://l2r.cs.uiuc.edu/~danr/Papers/CGRT10.pdf "Unsupervised Constraint Driven Learning For Transliteration Discovery."]{{dead link|date=August 2017 |bot=InternetArchiveBot |fix-attempted=yes }} NAACL, (2009).&lt;/ref&gt; settings. In all cases research showed that explicitly modeling the interdependencies between representation decisions via constraints results in an improved performance.

== Integer linear programming for natural language processing applications ==
The advantages of the CCM declarative formulation and the availability of off-the-shelf solvers have led to a large variety of [[natural language processing]] tasks being formulated within the framework, including [[semantic role labeling]],&lt;ref&gt;Vasin Punyakanok, Dan Roth, Wen-tau Yih and Dav Zimak, [http://l2r.cs.uiuc.edu/~danr/Papers/PRYZ04.pdf "Semantic Role Labeling via Integer Linear Programming Inference."] COLING, (2004).&lt;/ref&gt; syntactic parsing,&lt;ref&gt;Kenji Sagae and Yusuke Miyao and Jun’ichi Tsujii, [http://www.aclweb.org/anthology/P07-1079 "HPSG Parsing with Shallow Dependency Constraints."] ACL, (2007).&lt;/ref&gt; [[coreference]] resolution,&lt;ref&gt;Pascal Denis and Jason Baldridge, [http://www.aclweb.org/anthology-new/N/N07/N07-1030.pdf "Joint Determination of Anaphoricity and Coreference Resolution using Integer Programming."] {{Webarchive|url=https://web.archive.org/web/20100621045710/http://aclweb.org/anthology-new/N/N07/N07-1030.pdf |date=2010-06-21 }} NAACL-HLT, (2007).&lt;/ref&gt; summarization,&lt;ref&gt;James Clarke and Mirella Lapata, [http://www.jair.org/media/2433/live-2433-3730-jair.ps "Global Inference for Sentence Compression: An Integer Linear Programming Approach."]  Journal of Artificial Intelligence Research (JAIR), (2008).&lt;/ref&gt;&lt;ref&gt;Katja Filippova and Michael Strube, [http://www.aclweb.org/anthology-new/W/W08/W08-1105 "Dependency Tree Based Sentence Compression."]{{Dead link|date=November 2019 |bot=InternetArchiveBot |fix-attempted=yes }} ''INLG'', (2008).&lt;/ref&gt;&lt;ref&gt;Katja Filippova and Michael Strube, [http://www.aclweb.org/anthology/D08-1019 "Sentence Fusion via Dependency Graph Compression."] ''EMNLP'', (2008).&lt;/ref&gt; [[transliteration]],&lt;ref&gt;Dan Goldwasser and Dan Roth, [http://l2r.cs.uiuc.edu/~danr/Papers/GoldwasserRo08a.pdf "Transliteration as Constrained Optimization."] EMNLP, (2008).&lt;/ref&gt; natural language generation &lt;ref&gt;Regina Barzilay and Mirrela Lapata, [http://www.aclweb.org/anthology/N/N06/N06-1046 "Aggregation via Set Partitioning for Natural Language Generation."] ''NAACL'', (2006).&lt;/ref&gt; and [[joint information]] extraction.&lt;ref&gt;Dan Roth and Wen-tau Yih, [http://l2r.cs.uiuc.edu/~danr/Papers/RothYi04.pdf  "A Linear Programming Formulation for Global Inference in Natural Language Tasks."] ''CoNLL'', (2004).&lt;/ref&gt;&lt;ref&gt;[[Yejin Choi]] and Eric Breck and Claire Cardie, [http://portal.acm.org/citation.cfm?id=1610075.1610136 "Joint Extraction of Entities and Relations for Opinion Recognition."] ''EMNLP'', (2006).&lt;/ref&gt;

Most of these works use an integer linear programming (ILP) solver to solve the decision problem. Although theoretically solving an Integer Linear Program is exponential in the size of the decision problem, in practice using state-of-the-art solvers and [[approximate inference]] techniques &lt;ref&gt;André F. T. Martins, Noah A. Smith, and Eric P. Xing, [https://www.cs.cmu.edu/~nasmith/papers/martins+smith+xing.acl09.pdf "Concise Integer Linear Programming Formulations for Dependency Parsing ."] ACL, (2009).&lt;/ref&gt; large scale problems can be solved efficiently.

The key advantage of using an ILP solver for solving the optimization problem defined by a constrained conditional model is the declarative formulation used as input for the ILP solver, consisting of a linear objective function and a set of linear constraints.

== Resources ==
* '''CCM Tutorial''' [http://l2r.cs.uiuc.edu/~danr/Talks/CCM-NAACL-12-Tutorial.pdf Predicting Structures in NLP: Constrained Conditional Models and Integer Linear Programming in NLP]

== External links==
* [http://l2r.cs.uiuc.edu/~cogcomp/wpt.php?pr_key=CCM University of Illinois Cognitive Computation Group]
* [https://web.archive.org/web/20100530234120/http://www-tsujii.is.s.u-tokyo.ac.jp/ilpnlp/ Workshop on Integer Linear Programming for Natural Language Processing, NAACL-2009]

==References==
&lt;references/&gt;

&lt;!--Categories--&gt;
[[Category:Structured prediction]]
[[Category:Machine learning]]</text>
      <sha1>gjts9wcqg3t31bz54q9mrby1lwd6sxj</sha1>
    </revision>
  </page>
  <page>
    <title>Feature engineering</title>
    <ns>0</ns>
    <id>46207323</id>
    <revision>
      <id>1004684842</id>
      <parentid>996982436</parentid>
      <timestamp>2021-02-03T21:24:34Z</timestamp>
      <contributor>
        <ip>173.66.202.76</ip>
      </contributor>
      <comment>/* Automation */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="11613" xml:space="preserve">{{Machine learning bar}}
'''Feature engineering''' is the process of using [[domain knowledge]] to extract [[Feature (machine learning)|features]] from raw [[data]] via [[data mining]] techniques. These features can be used to improve the performance of [[machine learning]] algorithms. Feature engineering can be considered as applied machine learning itself.&lt;ref&gt;{{cite web | title =Machine Learning and AI via Brain simulations | url =https://ai.stanford.edu/~ang/slides/DeepLearning-Mar2013.pptx  | website =Stanford University | access-date =2019-08-01 }}&lt;/ref&gt;

== Features ==
A [[Feature (machine learning)|feature]] is an attribute or property shared by all of the independent units on which analysis or prediction is to be done. Any attribute could be a feature, as long as it is useful to the model.

The purpose of a feature, other than being an attribute, would be much easier to understand in the context of a problem. A feature is a characteristic that might help when solving the problem.&lt;ref name=":0"&gt;{{Cite web|title = Discover Feature Engineering, How to Engineer Features and How to Get Good at It - Machine Learning Mastery|url = http://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/|website = Machine Learning Mastery|access-date = 2015-11-11}}&lt;/ref&gt;

== Importance ==

Features are important to [[Predictive modelling|predictive models]] and influence results.&lt;ref&gt;{{Cite web|title = Feature Engineering: How to transform variables and create new ones?|url = http://www.analyticsvidhya.com/blog/2015/03/feature-engineering-variable-transformation-creation/|website = Analytics Vidhya|date = 2015-03-12|access-date = 2015-11-12}} &lt;/ref&gt;  

It is asserted that feature engineering plays an important part of [[Kaggle]] competitions &lt;ref&gt;{{cite web |work=kaggle.com |date=2013-04-10 |title=Q&amp;A with Xavier Conort |url=http://blog.kaggle.com/2013/04/10/qa-with-xavier-conort/ |access-date=12 November 2015 }}&lt;/ref&gt; and machine learning projects' success or failure.&lt;ref&gt;{{Cite journal|last=Domingos|first=Pedro|date=2012-10-01|title=A few useful things to know about machine learning|url=http://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf|journal=Communications of the ACM|language=en|volume=55|issue=10|pages=78–87|doi=10.1145/2347736.2347755|s2cid=2559675}}&lt;/ref&gt;

== Process  ==
The feature engineering process is:&lt;ref&gt;{{cite web|title=Big Data: Week 3 Video 3 - Feature Engineering|url=https://www.youtube.com/watch?v=drUToKxEAUA|website=youtube.com}}&lt;/ref&gt;

*[[Brainstorming]] or [[Software testing|testing]] features;&lt;ref&gt;{{Cite journal|url=https://content.iospress.com/articles/international-journal-of-knowledge-based-and-intelligent-engineering-systems/kes180383|title=Big data and intelligent software systems|first=Ahmed Adeeb|last=Jalal|date=January 1, 2018|journal=International Journal of Knowledge-based and Intelligent Engineering Systems|volume=22|issue=3|pages=177–193|via=content.iospress.com|doi=10.3233/KES-180383}}&lt;/ref&gt;
* Deciding what features to create;
* Creating features;
* Checking how the features work with your model;
* Improving your features if needed;
* Go back to brainstorming/creating more features until the work is done.

== Relevance ==
A feature could be strongly relevant (i.e., the feature has information that doesn't exist in any other feature), relevant, weakly relevant (some information that other features include) or irrelevant.&lt;ref&gt;{{Cite web|url = http://www.cs.princeton.edu/courses/archive/spring10/cos424/slides/18-feat.pdf|title = Feature Engineering|date = 2010-04-22|access-date = 12 November 2015}}&lt;/ref&gt; Even if some features are irrelevant, having too many is better than missing those that are important. [[Feature selection]] can be used to prevent overfitting.&lt;ref&gt;{{Cite web|url=http://www.cs.berkeley.edu/~jordan/courses/294-fall09/lectures/feature/slides.pdf|title=Feature engineering and selection|date=October 1, 2009|publisher=Alexandre Bouchard-Côté|access-date=12 November 2015}}&lt;/ref&gt;

== Feature explosion ==
Feature explosion can be caused by feature combination or feature templates, both leading to a quick growth in the total number of features.

* Feature templates - implementing feature templates instead of coding new features
* Feature combinations - combinations that cannot be represented by the linear system

Feature explosion can be limited via techniques such as: [[Regularization (mathematics)|regularization]], [[kernel method]], [[feature selection]].&lt;ref&gt;{{Cite web|url = https://ufal.mff.cuni.cz/~zabokrtsky/courses/npfl104/html/feature_engineering.pdf|title = Feature engineering in Machine Learning|access-date = 12 November 2015|publisher = Zdenek Zabokrtsky|archive-url = https://web.archive.org/web/20160304112056/https://ufal.mff.cuni.cz/~zabokrtsky/courses/npfl104/html/feature_engineering.pdf|archive-date = 4 March 2016|url-status = dead}}&lt;/ref&gt;

== Automation ==
Automation of feature engineering is a research topic that dates back to at least the late 1990s&lt;ref&gt;{{Cite book| chapter-url = https://link.springer.com/content/pdf/10.1007/978-3-540-48247-5_46.pdf | chapter = Multi-relational Decision Tree Induction| doi = 10.1007/978-3-540-48247-5_46| title = Principles of Data Mining and Knowledge Discovery| volume = 1704| pages = 378–383| series = Lecture Notes in Computer Science| year = 1999| last1 = Knobbe| first1 = Arno J.| last2 = Siebes| first2 = Arno| last3 = Van Der Wallen| first3 = Daniël| isbn = 978-3-540-66490-1}}&lt;/ref&gt; and machine learning software that incorporates automated feature engineering has been commercially available since 2016.&lt;ref&gt;{{Cite web|website=Reality AI Blog|title=Its all about the features|date=September 2017|url=https://reality.ai/it-is-all-about-the-features/}}&lt;/ref&gt;  The academic literature on the topic can be roughly separated into two strings: First, Multi-relational decision tree learning (MRDTL), which uses a supervised algorithm that is similar to a [[decision tree]]. Second, more recent approaches, like Deep Feature Synthesis, which use simpler methods.{{cn|date=January 2020}}

Multi-relational decision tree learning (MRDTL) generates features in the form of SQL queries by successively adding new clauses to the queries.&lt;ref&gt;{{Cite journal| title = A Comparative Study Of Multi-Relational Decision Tree Learning Algorithm |citeseerx = 10.1.1.636.2932}}&lt;/ref&gt; For instance, the algorithm might start out with 

&lt;syntaxhighlight lang="sql"&gt;
SELECT COUNT(*) FROM ATOM t1 LEFT JOIN MOLECULE t2 ON t1.mol_id = t2.mol_id GROUP BY t1.mol_id
&lt;/syntaxhighlight&gt;

The query can then successively be refined by adding conditions, such as "WHERE t1.charge &lt;= -0.392".&lt;ref&gt;{{Cite document |first1=Hector |last1=Leiva |first2=Anna |last2=Atramentov |first3=Vasant |last3=Honavar | url = http://web.cs.iastate.edu/~honavar/Papers/kddmrdmpaperfinal.pdf | title = Experiments with MRDTL – A Multi-relational Decision Tree Learning Algorithm |date=2002 }}&lt;/ref&gt;

However, most of the academic studies on MRDTL use implementations based on existing relational databases, which results in many redundant operations. These redundancies can be reduced by using tricks such as tuple id propagation.&lt;ref&gt;{{Cite book |first1=Xiaoxin |last1=Yin |first2=Jiawei |last2=Han |first3=Jiong |last3=Yang |first4=Philip S. |last4=Yu |title=Proceedings. 20th International Conference on Data Engineering |chapter = CrossMine: Efficient Classification Across Multiple Database Relations |work=Proceedings of the 20th International Conference on Data Engineering |year=2004 |pages=399–410 |doi=10.1109/ICDE.2004.1320014 |isbn=0-7695-2065-0 |s2cid=1183403 }}&lt;/ref&gt;&lt;ref&gt;{{Cite book| chapter = A Method for Multi-relational Classification Using Single and Multi-feature Aggregation Functions | doi = 10.1007/978-3-540-74976-9_43 | title = Knowledge Discovery in Databases: PKDD 2007 | volume = 4702 | pages = 430–437 | series = Lecture Notes in Computer Science | year = 2007 | last1 = Frank | first1 = Richard | last2 = Moser | first2 = Flavia | last3 = Ester | first3 = Martin | isbn = 978-3-540-74975-2 }}&lt;/ref&gt; More recently, it has been demonstrated that the efficiency can be increased further by using incremental updates, which completely eliminates redundancies.&lt;ref&gt;{{Cite web| url = https://get.ml/resources/how-getml-works | title = How automated feature engineering works - The most efficient feature engineering solution for relational data and time series | access-date=2019-11-21 }}{{Promotional source|date=January 2020}}&lt;/ref&gt;

In 2015, researchers at MIT presented the Deep Feature Synthesis algorithm and demonstrated its effectiveness in online data science competitions where it beat 615 of 906 human teams.&lt;ref&gt;{{Cite web| url = https://news.mit.edu/2015/automating-big-data-analysis-1016| title = Automating big-data analysis}}&lt;/ref&gt;&lt;ref&gt;{{Cite book |first1=James Max |last1=Kanter |first2=Kalyan |last2=Veeramachaneni |title=2015 IEEE International Conference on Data Science and Advanced Analytics (DSAA) |chapter=Deep Feature Synthesis: Towards Automating Data Science Endeavors |date=2015 |work=IEEE International Conference on Data Science and Advanced Analytics |pages=1–10 |doi=10.1109/DSAA.2015.7344858 |isbn=978-1-4673-8272-4 |s2cid=206610380 }}&lt;/ref&gt; Deep Feature Synthesis is available as an open source library called Featuretools.&lt;ref&gt;{{Cite web|url=https://www.featuretools.com/|title=Featuretools {{!}} An open source framework for automated feature engineering Quick Start|website=www.featuretools.com|access-date=2019-08-22}}&lt;/ref&gt; That work was followed by other researchers including IBM's OneBM&lt;ref&gt;{{Cite document| title = One button machine for automating feature engineering in relational databases|arxiv = 1706.00327|author1 = Hoang Thanh Lam|last2 = Thiebaut|first2 = Johann-Michael|last3 = Sinn|first3 = Mathieu|last4 = Chen|first4 = Bei|last5 = Mai|first5 = Tiep|last6 = Alkan|first6 = Oznur|year = 2017|bibcode = 2017arXiv170600327T}}&lt;/ref&gt; and Berkeley's ExploreKit.&lt;ref&gt;{{Cite web|url = https://people.eecs.berkeley.edu/~dawnsong/papers/icdm-2016.pdf| title = ExploreKit: Automatic Feature Generation and Selection}}&lt;/ref&gt; The researchers at IBM stated that feature engineering automation "helps data scientists reduce data exploration time allowing them to try and error many ideas in short time. On the other hand, it enables non-experts, who are not familiar with data science, to quickly extract value from their data with a little effort, time, and cost."{{cn|date=January 2020}}

==See also==
* [[Covariate]]
* [[Data transformation (statistics)|Data transformation]]
* [[Feature extraction]]
* [[Feature learning]]
* [[Hashing trick]]
* [[Kernel method]]
* [[List of datasets for machine learning research]]
* [[Space mapping]]

==References==
{{Reflist}}

==Further reading==
*{{cite book |first1=Bradley |last1=Boehmke |first2=Brandon |last2=Greenwell |chapter=Feature &amp; Target Engineering |pages=41–75 |title=Hands-On Machine Learning with R |publisher=Chapman &amp; Hall |year=2019 |isbn=978-1-138-49568-5 }}
*{{cite book |first1=Alice |last1=Zheng |first2=Amanda |last2=Casari |title=Feature Engineering for Machine Learning: Principles and Techniques for Data Scientists |publisher=O'Reilly |year=2018 |isbn=978-1-4919-5324-2 }}
*{{cite book |first1=Nina |last1=Zumel |first2=John |last2=Mount |chapter=Data Engineering and Data Shaping |title=Practical Data Science with R |publisher=Manning |edition=2nd |year=2020 |isbn=978-1-61729-587-4 |pages=113–160 }}

[[Category:Machine learning]]
[[Category:Data analysis]]</text>
      <sha1>bzzsgplgxxvqbpmo87vjgs6s6kw9e4w</sha1>
    </revision>
  </page>
  <page>
    <title>Formal concept analysis</title>
    <ns>0</ns>
    <id>313845</id>
    <revision>
      <id>1004479172</id>
      <parentid>1000470779</parentid>
      <timestamp>2021-02-02T20:08:25Z</timestamp>
      <contributor>
        <ip>81.220.44.232</ip>
      </contributor>
      <comment>/* Algorithms and tools */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="44819" xml:space="preserve">{{short description|Method of deriving an ontology}}
{{Expand German|Formale Begriffsanalyse|date=February 2012}}
'''Formal concept analysis''' ('''FCA''') is a [[Principle|principled way]] of deriving a ''concept hierarchy'' or formal [[Ontology (computer science)|ontology]] from a collection of [[Mathematical object|objects]] and their [[Property (philosophy)|properties]]. Each concept in the hierarchy represents the objects sharing some set of properties; and each sub-concept in the hierarchy represents a [[subset]] of the objects (as well as a superset of the properties) in the concepts above it. The term was introduced by [[Rudolf Wille]] in 1981, and builds on the mathematical theory of [[lattice theory|lattices]] and [[order theory|ordered sets]] that was developed by [[Garrett Birkhoff]] and others in the 1930s.

Formal concept analysis finds practical application in fields including [[data mining]], [[text mining]], [[machine learning]], [[knowledge management]], [[semantic web]], [[software development]], [[chemistry]] and [[biology]].

== Overview and history ==
The original motivation of formal concept analysis was the search for real-world meaning of mathematical [[order theory]]. One such possibility of very general nature is that data tables can be transformed into algebraic structures called ''complete lattices'', and that these can be utilized for data visualization and interpretation. A data table that represents a [[heterogeneous relation]] between objects and attributes, tabulating pairs of the form "object ''g'' has attribute ''m''", is considered as a basic data type. It is referred to as a ''formal context''. In this theory, a ''formal concept'' is defined to be a pair (''A'', ''B''), where ''A'' is a set of objects (called the ''extent'') and ''B'' is a set of attributes (the ''intent'') such that

* the extent ''A'' consists of all objects that share the attributes in ''B'', and [[dual (math)|dually]]
* the intent ''B'' consists of all attributes shared by the objects in ''A''.

In this way, formal concept analysis formalizes the [[semantics|semantic]] notions of [[Extension (semantics)|extension]] and [[intension]].

The formal concepts of any formal context can—as explained below—be [[partially ordered set|ordered]] in a hierarchy called more formally the context's "concept lattice." The concept lattice can be graphically visualized as a "line diagram", which then may be helpful for understanding the data. Often however these lattices get too large for visualization. Then the mathematical theory of formal concept analysis may be helpful, e.g., for decomposing the lattice into smaller pieces without information loss, or for embedding it into another structure which is easier to interpret.

The theory in its present form goes back to the early 1980s and a research group led by [[Rudolf Wille]], [[:de:Bernhard Ganter|Bernhard Ganter]] and Peter Burmeister at the [[Technische Universität Darmstadt]]. Its basic mathematical definitions, however, were already introduced in the 1930s by [[Garrett Birkhoff]] as part of general lattice theory. Other previous approaches to the same idea arose from various French research groups, but the Darmstadt group normalised the field and systematically worked out both its mathematical theory and its philosophical foundations. The latter refer in particular to [[Charles S. Peirce]], but also to the ''[[Port-Royal Logic]]''.

== Motivation and philosophical background ==
In his article "Restructuring Lattice Theory" (1982),&lt;ref name="restructuring"&gt;Rudolf Wille, "Restructuring lattice theory: An approach based on hierarchies of concepts". Published in {{cite book |editor1-last=Rival |editor1-first=Ivan |title=Ordered Sets. Proceedings of the NATO Advanced Study Institute held at Banff, Canada, August 28 to September 12, 1981 |series=Nato Science Series C |volume=83 |publisher=Springer Netherlands |date=1982 |pages=445–470 |doi=10.1007/978-94-009-7798-3|isbn=978-94-009-7800-3 }}, reprinted in {{cite book |editor1-last=Ferré |editor1-first=Sébastien |editor2-last=Rudolph |editor2-first=Sebastian | title=Formal Concept Analysis: 7th International Conference, ICFCA 2009 Darmstadt, Germany, May 21–24, 2009 Proceedings | page=314 | publisher=Springer Science &amp; Business Media | isbn=978-364201814-5 }}&lt;/ref&gt; initiating formal concept analysis as a mathematical discipline, Wille starts from a discontent with the current lattice theory and pure mathematics in general: The production of theoretical results—often achieved by "elaborate mental gymnastics"—were impressive, but the connections between neighboring domains, even parts of a theory were getting weaker.

{{Quote |text=Restructuring lattice theory is an attempt to reinvigorate connections with our general culture by interpreting the theory as concretely as possible, and in this way to promote better communication between lattice theorists and potential users of lattice theory |author=Rudolf Wille |source=&lt;ref name="restructuring" /&gt;}}

This aim traces back to the educationalist Hartmut von Hentig, who in 1972 pleaded for restructuring sciences in view of better teaching and in order to make sciences mutually available and more generally (i.e. also without specialized knowledge) critiqueable.&lt;ref&gt;{{cite book |last=Hentig, von |first=Hartmut |date=1972 |title=Magier oder Magister? Über die Einheit der Wissenschaft im Verständigungsprozeß |publisher=Klett (1972), Suhrkamp (1974) |isbn=978-3518067079}}&lt;/ref&gt; Hence, by its origins formal concept analysis aims at interdisciplinarity and democratic control of research.&lt;ref name="AttrExGeneRegProc"&gt;Johannes Wollbold: ''[http://www.db-thueringen.de/servlets/DerivateServlet/Derivate-24615/Wollbold/Dissertation.pdf Attribute Exploration of Gene Regulatory Processes]''. PhD thesis, University of Jena 2011, p. 9&lt;/ref&gt;

It corrects the starting point of lattice theory during the development of [[formal logic]] in the 19th century. Then—and later in [[model theory]]—a concept as unary [[predicate (logic)|predicate]] had been reduced to its extent. Now again, the philosophy of concepts should become less abstract by considering the intent. Hence, formal concept analysis is oriented towards the categories [[extension (semantics)|extension]] and [[intension]] of [[linguistics]] and classical conceptual logic.&lt;ref name="GW"&gt;Ganter, Bernhard and Wille, Rudolf: ''Formal Concept Analysis: Mathematical Foundations''. Springer, Berlin, {{ISBN|3-540-62771-5}}&lt;/ref&gt;

Formal concept analysis aims at the clarity of concepts according to Charles S. Peirce's [[pragmatic maxim]] by unfolding observable, elementary properties of the [[Minor premise|subsumed]] objects.&lt;ref name="AttrExGeneRegProc" /&gt; In his late philosophy, Peirce assumed that logical thinking aims at perceiving [[reality]], by the triade concept, [[judgement]] and [[Consequent|conclusion]]. Mathematics is an abstraction of logic, develops patterns of [[Logical possibility|possible]] realities and therefore may support rational [[communication]]. On this background, Wille defines:

{{Quote |text=The aim and meaning of Formal Concept Analysis as mathematical theory of concepts and concept hierarchies is to support the rational communication of humans by mathematically developing appropriate conceptual structures which can be logically activated. |author=Rudolf Wille |source = &lt;ref&gt;Rudolf Wille, "Formal Concept Analysis as Mathematical Theory of Concepts and Concept Hierarchies". In {{cite book |editor1-last=Ganter |editor1-first=Bernhard |editor2-last=Stumme |editor2-first=Gerd |editor3-last=Wille |editor3-first=Rudolf | title=Formal Concept Analysis. Foundations and Applications |publisher=Springer Science &amp; Business Media |date=2005 |isbn=978-354027891-7|url=https://books.google.com/books?id=oyb6BwAAQBAJ}}&lt;/ref&gt;}}

== Example ==
The data in the example is taken from a semantic field study, where different kinds of [[Body of water|bodies of water]] were systematically categorized by their attributes.&lt;ref&gt;{{citation |author1=Peter Rolf Lutzeier |title=Wort und Feld: wortsemantische Fragestellungen mit besonderer Berücksichtigung des Wortfeldbegriffes: Dissertation |series=Linguistische Arbeiten 103 |publisher=Niemeyer |location=Tübingen |oclc=8205166 |date=1981 |language=de |doi=10.1515/9783111678726.fm}}&lt;/ref&gt; For the purpose here it has been simplified.

The data table represents a ''formal context'', the ''line diagram'' next to it shows its ''concept lattice''. Formal definitions follow below.

{| class="wikitable" style="text-align: center; margin-right: 2em; float: left; font-size: 80%"
|+ Example for a formal context: "bodies of water"
|-
! rowspan="2" colspan="2"| bodies of water !! colspan="8" | attributes
|-
! ''temporary'' !! ''running'' !! ''natural'' !! ''stagnant'' !! ''constant'' !! ''maritime''
|-
! rowspan="18" {{verth|va=middle|objects}}
! {{rh}} | [[canal]]
| || X || || || X ||
|-
! {{rh}} | [[Channel (geography)|channel]]
| || X || || || X ||
|-
! {{rh}} | [[lagoon]]
| || || X || X || X || X
|-
! {{rh}} | [[lake]]
| || || X || X || X ||
|-
! {{rh}} | [[maar]]
| || || X || X || X ||
|-
! {{rh}} | [[puddle]]
| X || || X || X || ||
|-
! {{rh}} | [[pond]]
| || || X || X || X ||
|-
! {{rh}} | pool
| || || X || X || X ||
|-
! {{rh}} | [[reservoir]]
| || || || X || X ||
|-
! {{rh}} | [[river]]
| || X || X || || X ||
|-
! {{rh}} | [[rivulet]]
| || X || X || || X ||
|-
! {{rh}} | [[Stream|runnel]]
| || X || X || || X ||
|-
! {{rh}} | [[sea]]
| || || X || X || X || X
|-
! {{rh}} | [[stream]]
| || X || X || || X ||
|-
! {{rh}} | [[Tarn (lake)|tarn]]
| || || X || X || X ||
|-
! {{rh}} | torrent
| || X || X || || X ||
|-
! {{rh}} | [[trickle]]
| || X || X || || X ||
|}
&amp;nbsp; &lt;!-- for the diagramm, to be displayed on the same level as the table --&gt;
[[file:FCA body of water.svg|thumb|Line diagram corresponding to the formal context ''bodies of water'' on the left]]
{{Clear}}

The above line diagram consists of circles, connecting line segments, and labels. Circles represent ''formal concepts''. The lines allow to read off the subconcept-superconcept hierarchy. Each object and attribute name is used as a label exactly once in the diagram, with objects below and attributes above concept circles. This is done in a way that an attribute can be reached from an object via an ascending path if and only if the object has the attribute.

In the diagram shown, e.g. the object ''reservoir'' has the attributes ''stagnant'' and ''constant'', but not the attributes ''temporary, running, natural, maritime''. Accordingly, ''puddle'' has exactly the characteristics ''temporary, stagnant'' and ''natural''.

The original formal context can be reconstructed from the labelled diagram, as well as the formal concepts. The extent of a concept consists of those objects from which an ascending path leads to the circle representing the concept. The intent consists of those attributes to which there is an ascending path from that concept circle (in the diagram). In this diagram the concept immediately to the left of the label ''reservoir'' has the intent ''stagnant'' and ''natural'' and the extent ''puddle, maar, lake, pond, tarn, pool, lagoon,'' and ''sea''.

== Formal contexts and concepts ==
A formal context is a triple ''K'' = (''G'', ''M'', ''I''), where ''G'' is a set of ''objects'', ''M'' is a set of ''attributes'', and ''I'' &amp;sube; ''G'' &amp;times; ''M'' is a binary relation called ''incidence'' that expresses which objects ''have'' which attributes.&lt;ref name="GW" /&gt; For subsets ''A'' &amp;sube; ''G'' of objects and subsets ''B'' &amp;sube; ''M'' of attributes, one defines two ''derivation operators'' as follows:

''A''' = {''m'' &amp;isin; ''M'' | ''(g,m)'' &amp;isin; ''I'' for all ''g'' &amp;isin; ''A''}, i.e., a set of '''all''' attributes shared by all objects from A, and dually

''B''' = {''g'' &amp;isin; ''G'' | ''(g,m)'' &amp;isin; ''I'' for all ''m'' &amp;isin; ''B''}, i.e., a set of '''all''' objects sharing all attributes from B.

Applying either derivation operator and then the other constitutes two [[closure operator]]s:

''A'' &amp;nbsp; ↦ &amp;nbsp;''A''" = (''A''')' &amp;nbsp; for ''A'' &amp;sube; G &amp;nbsp; (extent closure), and

''B'' &amp;nbsp; ↦ &amp;nbsp;''B''" = (''B''')' &amp;nbsp; for ''B'' &amp;sube; M &amp;nbsp; (intent closure).

The derivation operators define a [[Galois connection]] between sets of objects and of attributes. This is why in French a concept lattice is sometimes called a ''treillis de Galois'' (Galois lattice).

With these derivation operators, Wille gave an elegant definition of a formal concept:
&lt;!--With these derivation operators, it is possible to restate the definition of the term "formal concept" more rigorously:--&gt;
a pair (''A'',''B'') is a ''formal concept'' of a context (''G'', ''M'', ''I'') provided that:

''A'' &amp;sube; ''G'', &amp;nbsp; ''B'' &amp;sube; ''M'', &amp;nbsp; ''A''&amp;prime; = ''B'', &amp;nbsp; and &amp;nbsp;''B''&amp;prime; = ''A''.

Equivalently and more intuitively, (''A'',''B'') is a formal concept precisely when:
* every object in ''A'' has every attribute in ''B'',
* for every object in ''G'' that is not in ''A'', there is some attribute in ''B'' that the object does not have,
* for every attribute in ''M'' that is not in ''B'', there is some object in ''A'' that does not have that attribute.

For computing purposes, a formal context may be naturally represented as a [[(0,1)-matrix]] ''K'' in which the rows correspond to the objects, the columns correspond to the attributes, and each entry ''k''&lt;sub&gt;''i'',''j''&lt;/sub&gt; equals to 1 if "object ''i'' has attribute ''j''." In this matrix representation, each formal concept corresponds to a [[maximal element|maximal]] submatrix (not necessarily contiguous) all of whose elements equal 1. It is however misleading to consider a formal context as ''boolean'', because the negated incidence ("object ''g'' does '''not''' have attribute ''m''") is not concept forming in the same way as defined above. For this reason, the values 1 and 0 or TRUE and FALSE are usually avoided when representing formal contexts, and a symbol like &lt;math&gt;\times&lt;/math&gt; is used to express incidence.

== Concept lattice of a formal context ==
The concepts (''A''&lt;sub&gt;''i''&lt;/sub&gt;, ''B''&lt;sub&gt;''i''&lt;/sub&gt;) of a context ''K'' can be [[Partial order|(partially) ordered]] by the inclusion of extents, or, equivalently, by the dual inclusion of intents. An order ≤ on the concepts is defined as follows: for any two concepts (''A''&lt;sub&gt;''1''&lt;/sub&gt;, ''B''&lt;sub&gt;''1''&lt;/sub&gt;) and (''A''&lt;sub&gt;''2''&lt;/sub&gt;, ''B''&lt;sub&gt;''2''&lt;/sub&gt;) of ''K'', we say that (''A''&lt;sub&gt;''1''&lt;/sub&gt;, ''B''&lt;sub&gt;''1''&lt;/sub&gt;) ≤ (''A''&lt;sub&gt;''2''&lt;/sub&gt;, ''B''&lt;sub&gt;''2''&lt;/sub&gt;) precisely when ''A''&lt;sub&gt;''1''&lt;/sub&gt; ⊆ ''A''&lt;sub&gt;''2''&lt;/sub&gt;. Equivalently, (''A''&lt;sub&gt;''1''&lt;/sub&gt;, ''B''&lt;sub&gt;''1''&lt;/sub&gt;) ≤ (''A''&lt;sub&gt;''2''&lt;/sub&gt;, ''B''&lt;sub&gt;''2''&lt;/sub&gt;) whenever ''B''&lt;sub&gt;''1''&lt;/sub&gt; ⊇ ''B''&lt;sub&gt;''2''&lt;/sub&gt;.

In this order, every set of formal concepts has a [[join and meet|greatest common subconcept]], or meet. Its extent consists of those objects that are common to all extents of the set. [[dual (math)|Dually]], every set of formal concepts has a ''least common superconcept'', the intent of which comprises all attributes which all objects of that set of concepts have.

These meet and join operations satisfy the axioms defining a [[Lattice (order)|lattice]], in fact a [[complete lattice]]. Conversely, it can be shown that every complete lattice is the concept lattice of some formal context (up to isomorphism).

== Attribute values and negation ==
Real-world data is often given in the form of an object-attribute table, where the attributes have "values". Formal concept analysis handles such data by transforming them into the basic type of a ("one-valued") formal context. The method is called ''conceptual scaling''.

The negation of an attribute ''m'' is an attribute &amp;not;''m'', the extent of which is just the complement of the extent of ''m'', i.e., with (&amp;not;''m'')' = G&amp;nbsp;\&amp;nbsp;m'. It is in general ''not'' assumed that negated attributes are available for concept formation. But pairs of attributes which are negations of each other often naturally occur, for example in contexts derived from conceptual scaling.

For possible negations of formal concepts see the section [[#concept algebra|concept algebras]] below.

== Implications ==
An ''[[Implication (information science)|implication]]'' ''A &amp;rarr; B'' relates two sets ''A'' and ''B'' of attributes and expresses that every object possessing each attribute from ''A'' also has each attribute from ''B''. When (''G'',''M'',''I'') is a formal context and ''A'', ''B'' are subsets of the set ''M'' of attributes (i.e., ''A,B &amp;sube; M''), then the implication ''A &amp;rarr; B'' ''is valid'' if ''A&amp;prime; &amp;sube; B&amp;prime;''. For each finite formal context, the set of all valid implications has a ''canonical basis'',&lt;ref&gt;Guigues, J.L. and Duquenne, V. ''Familles minimales d'implications informatives résultant d'un tableau de données binaires.'' Mathématiques et Sciences Humaines 95 (1986): 5–18.&lt;/ref&gt; an irredundant set of implications from which all valid implications can be derived by the natural inference ([[Armstrong axioms|Armstrong rules]]). This is used in ''attribute exploration'', a knowledge acquisition method based on implications.&lt;ref name="GanterObiedkov"&gt; Ganter, Bernhard and Obiedkov, Sergei (2016) ''Conceptual Exploration''. Springer, {{ISBN|978-3-662-49290-1}}&lt;/ref&gt;

== Arrow relations ==
Formal concept analysis has elaborate mathematical foundations,&lt;ref name="GW" /&gt; making the field versatile. As a basic example we mention the ''arrow relations'', which are simple and easy to compute, but very useful. They are defined as follows: For ''g'' &amp;isin; ''G'' and ''m'' &amp;isin; ''M'' let

''g'' ↗ ''m'' &amp;nbsp;⇔&amp;nbsp; ''(g, m)'' &amp;notin; ''I'' and if ''m'&amp;sube;n' '' and ''m' ≠ n' '', then ''(g, n)'' &amp;isin; ''I'',

and dually

''g'' ↙ ''m'' &amp;nbsp;⇔&amp;nbsp; ''(g, m)'' &amp;notin; ''I'' and if ''g'&amp;sube;h' '' and ''g' ≠ h' '', then ''(h, m)'' &amp;isin; ''I''.

Since only non-incident object-attribute pairs can be related, these relations can conveniently be recorded in the table representing a formal context. Many lattice properties can be read off from the arrow relations, including distributivity and several of its generalizations. They also reveal structural information and can be used for determining, e.g., the congruence relations of the lattice.

== Extensions of the theory ==
* '''Triadic concept analysis''' replaces the binary incidence relation between objects and attributes by a ternary relation between objects, attributes, and conditions. An incidence ''(g,m,c)'' then expresses that ''the object g has the attribute m under the condition c''. Although ''triadic concepts'' can be defined in analogy to the formal concepts above, the theory of the ''trilattices'' formed by them is much less developed than that of concept lattices, and seems to be difficult.&lt;ref&gt;Wille R. "The basic theorem of triadic concept analysis". ''Order'' 12, 149–158, 1995&lt;/ref&gt; Voutsadakis has studied the ''n''-ary case.&lt;ref name="Voutsadakis"&gt;Voutsadakis G. "Polyadic Concept Analysis". ''Order'' 19(3), 295–304, 2002&lt;/ref&gt;
* '''Fuzzy concept analysis''': Extensive work has been done on a fuzzy version of formal concept analysis.&lt;ref&gt;{{Cite web |url=http://www.glc.us.es/cla2010/slides/tutorialI_Belohlavek.pdf |title=Formal Concept Analysis and Fuzzy Logic |access-date=2017-12-08 |archive-url=https://web.archive.org/web/20171209043947/http://www.glc.us.es/cla2010/slides/tutorialI_Belohlavek.pdf |archive-date=2017-12-09 |url-status=dead }}&lt;/ref&gt;
* &lt;span id="concept algebra"&gt;'''Concept algebras'''&lt;/span&gt;: Modelling negation of formal concepts is somewhat problematic because the complement (''G''&amp;nbsp;\&amp;nbsp;''A'', ''M''&amp;nbsp;\&amp;nbsp;''B'') of a formal concept (''A'', ''B'') is in general not a concept. However, since the concept lattice is complete one can consider the join (''A'', ''B'')&lt;sup&gt;Δ&lt;/sup&gt; of all concepts (''C'', ''D'') that satisfy ''C''&amp;nbsp;⊆&amp;nbsp;''G''&amp;nbsp;\&amp;nbsp;''A''; or dually the meet (''A'', ''B'')&lt;sup&gt;𝛁&lt;/sup&gt; of all concepts satisfying ''D''&amp;nbsp;⊆&amp;nbsp;''M''&amp;nbsp;\&amp;nbsp;''B''. These two operations are known as ''weak negation'' and ''weak opposition'', respectively. This can be expressed in terms of the ''derivation operators''. Weak negation can be written as (''A'', ''B'')&lt;sup&gt;Δ&lt;/sup&gt; = ((''G''&amp;nbsp;\&amp;nbsp;''A'')&lt;nowiki&gt;''&lt;/nowiki&gt;, (''G''&amp;nbsp;\&amp;nbsp;''A'')'), and weak opposition can be written as (''A'', ''B'')&lt;sup&gt;𝛁&lt;/sup&gt; = ((''M''&amp;nbsp;\&amp;nbsp;''B'')', (''M''&amp;nbsp;\&amp;nbsp;''B'')&lt;nowiki&gt;''&lt;/nowiki&gt;). The concept lattice equipped with the two additional operations Δ and 𝛁 is known as the ''concept algebra'' of a context. Concept algebras generalize [[power set]]s. Weak negation on a concept lattice ''L'' is a ''weak complementation'', i.e. an [[order-reversing]] map Δ:&amp;nbsp;''L''&amp;nbsp;→&amp;nbsp;''L'' which satisfies the axioms ''x''&lt;sup&gt;ΔΔ&lt;/sup&gt;&amp;nbsp;≤&amp;nbsp;''x'' and (''x''⋀''y'')&amp;nbsp;⋁&amp;nbsp;(''x''⋀''y''&lt;sup&gt;Δ&lt;/sup&gt;)&amp;nbsp;=&amp;nbsp;''x''. Weak composition is a dual weak complementation. A (bounded) lattice such as a concept algebra, which is equipped with a weak complementation and a dual weak complementation, is called a ''weakly dicomplemented lattice''. Weakly dicomplemented lattices generalize distributive [[orthocomplemented lattice]]s, i.e. [[Boolean algebra (structure)|Boolean algebras]].&lt;ref&gt;{{Citation |last=Wille |first=Rudolf |year=2000 |contribution=Boolean Concept Logic |editor1-last=Ganter |editor1-first=B. |editor2-last=Mineau |editor2-first=G. W. |title=ICCS 2000 Conceptual Structures: Logical, Linguistic and Computational Issues |publisher=Springer |pages=317–331 |isbn=978-3-540-67859-5 |series=LNAI 1867}}.&lt;/ref&gt;&lt;ref name=kwuida2004&gt;{{Citation |last=Kwuida |first=Léonard |title=Dicomplemented Lattices. A contextual generalization of Boolean algebras |year=2004 |publisher=[[Shaker Verlag]] |isbn=978-3-8322-3350-1 |url=http://hsss.slub-dresden.de/documents/1101148726640-2926/1101148726640-2926.pdf }}&lt;/ref&gt;

=== Temporal concept analysis ===
Temporal concept analysis (TCA) is an extension of Formal Concept Analysis (FCA) aiming at a conceptual description of temporal phenomena. It provides animations in concept lattices obtained from data about changing objects. It offers a general way of understanding change of concrete or abstract objects in continuous, discrete or hybrid space and time. TCA applies conceptual scaling to temporal data bases.&lt;ref&gt;
{{Citation |last=Wolff |first=Karl Erich |year=2010 |contribution=Temporal Relational Semantic Systems |editor1-last=Croitoru |editor1-first= Madalina |editor2-last=Ferré |editor2-first=Sébastien |editor3-last=Lukose |editor3-first=Dickson |title=Conceptual Structures: From Information to Intelligence. ICCS 2010. LNAI 6208 |publisher=Springer-Verlag|pages=165–180 |isbn=978-3-642-14196-6 |doi=10.1007/978-3-642-14197-3 |series=Lecture Notes in Artificial Intelligence|volume=6208 |url=https://basepub.dauphine.fr/handle/123456789/12138 }}.&lt;/ref&gt;

In the simplest case TCA considers objects that change in time like a particle in physics, which, at each time, is at exactly one place. That happens in those temporal data where the attributes 'temporal object' and 'time' together form a key of the data base. Then the state (of a temporal object at a time in a view) is formalized as a certain object concept of the formal context describing the chosen view. In this simple case, a typical visualization of a temporal system is a line diagram of the concept lattice of the view into which trajectories of temporal objects are embedded.
&lt;ref&gt;{{Citation |last=Wolff |first=Karl Erich |year=2019 |contribution=Temporal Concept Analysis with SIENA |url=http://ceur-ws.org/Vol-2378/shortAT12.pdf |editor1-last=Cristea |editor1-first=Diana |editor2-last=Le Ber |editor2-first=Florence |editor3-last=Missaoui |editor3-first=Rokia |editor4-last=Kwuida |editor4-first=Léonard |editor5-last=Sertkaya |editor5-first=Bariş |title=Supplementary Proceedings of ICFCA 2019, Conference and Workshops |publisher=Springer |location=Frankfurt, Germany |pages=94–99 }}.&lt;/ref&gt;

TCA generalizes the above mentioned case by considering temporal data bases with an arbitrary key. That leads to the notion of distributed objects which are at any given time at possibly many places, as for example, a high pressure zone on a weather map. The notions of 'temporal objects', 'time' and 'place' are represented as formal concepts in scales. A state is formalized as a set of object concepts.
That leads to a conceptual interpretation of the ideas of particles and waves in physics.&lt;ref&gt;{{Citation |last=Wolff |first=Karl Erich |year=2004 |contribution=‘Particles’ and ‘Waves’ as Understood by Temporal Concept Analysis. |editor1-last=Wolff |editor1-first=Karl Erich |editor2-last=Pfeiffer |editor2-first=Heather D. |editor3-last=Delugach |editor3-first=Harry S. |title=Conceptual Structures at Work. 12th International Conference on Conceptual Structures, ICCS 2004. Huntsville, AL, USA, July 2004, LNAI 3127. Proceedings |publisher=Springer-Verlag |location=Berlin Heidelberg |pages=126–141 |isbn=978-3-540-22392-4 |series=Lecture Notes in Artificial Intelligence|doi=10.1007/978-3-540-27769-9_8 }}.&lt;/ref&gt;

== Algorithms and tools==
There are a number of simple and fast algorithms for generating formal concepts and for constructing and navigating concept lattices. For a survey, see Kuznetsov and Obiedkov&lt;ref name="AlgSurvey"&gt;Kuznetsov S., Obiedkov S. ''Comparing Performance of Algorithms for Generating Concept Lattices'', 14, [[Journal of Experimental and Theoretical Artificial Intelligence]], Taylor &amp; Francis, {{ISSN|0952-813X}} (print) {{ISSN|1362-3079}} (online), pp.189–216, 2002&lt;/ref&gt; or the book by Ganter and Obiedkov,&lt;ref name="GanterObiedkov"/&gt; where also some pseudo-code can be found. Since the number of formal concepts may be exponential in the size of the formal context, the complexity of the algorithms usually is given with respect to the output size. Concept lattices with a few million elements can be handled without problems.

Many FCA software applications are available today.&lt;ref name="fcahome.org.uk"&gt;One can find a non exhaustive list of FCA tools in the FCA software website: {{cite web |url=http://www.fcahome.org.uk/fcasoftware.html |title=Formal Concept Analysis Software and Applications |access-date=2010-06-10 |url-status=dead |archive-url=https://web.archive.org/web/20100416002832/http://www.fcahome.org.uk/fcasoftware.html |archive-date=2010-04-16}}&lt;/ref&gt; The main purpose of these tools varies from formal context creation to formal [[concept mining]] and generating the concepts lattice of a given formal context and the corresponding implications and [[association rules]]. Most of these tools are academic open-source applications, such as:
* ConExp&lt;ref name="conexp.sourceforge.net"&gt;{{cite web|url=http://conexp.sourceforge.net/|title=The Concept Explorer|website=Conexp.sourceforge.net|access-date=27 December 2018}}&lt;/ref&gt;
* ToscanaJ&lt;ref name="toscanaj.sourceforge.net"&gt;{{cite web|url=http://toscanaj.sourceforge.net/|title=ToscanaJ: Welcome|website=Toscanaj.sourceforge.net|access-date=27 December 2018}}&lt;/ref&gt;
* [[Lattice Miner]]&lt;ref name="ReferenceB"&gt;Boumedjout Lahcen and Leonard Kwuida. "Lattice Miner: A Tool for Concept Lattice Construction and Exploration". In: Supplementary Proceeding of International Conference on Formal concept analysis (ICFCA'10), 2010&lt;/ref&gt;
* Coron&lt;ref name="coron.loria.fr"&gt;{{cite web|url=http://coron.loria.fr/site/index.php|title=The Coron System|website=Coron.loria.fr|access-date=27 December 2018}}&lt;/ref&gt;
* FcaBedrock&lt;ref name="sourceforge.net"&gt;{{cite web|url=https://sourceforge.net/projects/fcabedrock/|title=FcaBedrock Formal Context Creator|website=SourceForge.net|access-date=27 December 2018}}&lt;/ref&gt;
* GALACTIC&lt;ref name="galactic.univ-lr.fr"&gt;{{cite web|url=https://galactic.univ-lr.fr/|title=GALACTIC GAlois LAttices, Concept Theory, Implicational system and Closures|website=galactic.univ-lr.fr|access-date=2 February 2021}}&lt;/ref&gt;

== Related analytical techniques ==
=== Bicliques ===
A formal context can naturally be interpreted as a [[bipartite graph]]. The formal concepts then correspond to the maximal [[biclique]]s in that graph. The mathematical and algorithmic results of formal concept analysis may thus be used for the theory of maximal bicliques. The notion of [[bipartite dimension]] (of the complemented bipartite graph) translates&lt;ref name="GW" /&gt; to that of ''Ferrers dimension'' (of the formal context) and of [[order dimension]] (of the concept lattice) and has applications e.g. for Boolean matrix factorization.&lt;ref&gt;Belohlavek, Radim, and Vychodil, Vilem. [http://www.sciencedirect.com/science/article/pii/S0022000009000415 "Discovery of optimal factors in binary data via a novel method of matrix decomposition"]. ''Journal of Computer and System Sciences'' 76.1 (2010): 3–20.&lt;/ref&gt;

=== Biclustering and multidimensional clustering ===
Given an object-attribute numerical data-table, the goal of [[biclustering]] is to group together some objects having similar values of some attributes. For example, in gene expression data, it is known that genes (objects) may share a common behavior for a subset of biological situations (attributes) only: one should accordingly produce local patterns to characterize biological processes, the latter should possibly overlap, since a gene may be involved in several processes. The same remark applies for recommender systems where one is interested in local patterns characterizing groups of users that strongly share almost the same tastes for a subset of items.&lt;ref name="AdomTuzh"&gt;Adomavicius C., Tuzhilin A. [http://homepages.dcc.ufmg.br/~nivio/cursos/ri13/sources/recommender-systems-survey-2005.pdf "Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions"]. ''IEEE Transactions on Knowledge and Data Engineering'', 17(6): 734–749, 2005.&lt;/ref&gt;

A bicluster in a binary object-attribute data-table is a pair ''(A,B)'' consisting of an inclusion-maximal set of objects ''A'' and an inclusion-maximal set of attributes ''B'' such that almost all objects from ''A'' have almost all attributes from ''B'' and vice versa.

Of course, formal concepts can be considered as "rigid" biclusters where all objects have all attributes and vice versa. Hence, it is not surprising that some bicluster definitions coming from practice&lt;ref&gt;Prelic, S. Bleuler, P. Zimmermann, A. Wille, P. Buhlmann, W. Gruissem, L. Hennig, L. Thiele, and E. Zitzler. [https://academic.oup.com/bioinformatics/article/22/9/1122/200492 "A Systematic Comparison and Evaluation of Biclustering Methods for Gene Expression Data"]. ''Bioinformatics'', 22(9):1122–1129, 2006&lt;/ref&gt; are just definitions of a formal concept.&lt;ref name="KayMinBicl"&gt;Kaytoue M., Kuznetsov S., Macko J., Wagner Meira Jr., Napoli A. "Mining Biclusters of Similar Values with Triadic Concept Analysis". CLA : 175–190, 2011&lt;/ref&gt;

A bicluster of similar values in a numerical object-attribute data-table is usually defined&lt;ref&gt;R. G. Pensa, C. Leschi, J. Besson, J.-F. Boulicaut. [https://www.academia.edu/download/35719269/biokdd04.pdf "Assessment of discretization techniques for relevant pattern discovery from gene expression data"]. In M. J. Zaki, S. Morishita, and I. Rigoutsos, editors, Proceedings of the 4th ACM SIGKDD Workshop on Data Mining in Bioinformatics (BIOKDD 2004), 24–30, 2004.&lt;/ref&gt;&lt;ref&gt;Besson J., Robardet C. Raedt L.D., Boulicaut, J.-F. [https://lirias.kuleuven.be/bitstream/123456789/134532/1/07-kdid-bessonetal.pdf "Mining bi-sets in numerical data"]. In S. Dzeroski and J. Struyf, editors, KDID, LNCS 4747, p.11–23. Springer, 2007.&lt;/ref&gt;&lt;ref name="CerfCloPat"&gt;Cerf L., Besson J., Robardet C., Boulicaut J.-F. [http://homepages.dcc.ufmg.br/~lcerf/publications/articles/Closed%20Patterns%20Meet%20n-ary%20Relations.pdf "Closed patterns meet n-ary relations"]. TKDD, 3(1), 2009&lt;/ref&gt; as a pair consisting of an inclusion-maximal set of objects and an inclusion-maximal set of attributes having similar values for the objects. Such a pair can be represented as an inclusion-maximal rectangle in the numerical table, modulo rows and columns permutations. In&lt;ref name="KayMinBicl" /&gt; it was shown that biclusters of similar values correspond to triconcepts of a triadic context where the third dimension is given by a scale that represents numerical attribute values by binary attributes.

This fact can be generalized to ''n''-dimensional case, where ''n''-dimensional clusters of similar values in ''n''-dimensional data are represented by ''n+1''-dimensional concepts. This reduction allows one to use standard definitions and algorithms from multidimensional concept analysis&lt;ref name="CerfCloPat"/&gt;&lt;ref name="Voutsadakis" /&gt; for computing multidimensional clusters.

=== Knowledge spaces ===
In the theory of [[knowledge space]]s it is assumed that in any knowledge space the family of ''knowledge states'' is union-closed. The complements of knowledge states therefore form a [[closure operator|closure system]] and may be represented as the extents of some formal context.

== Hands-on experience with formal concept analysis ==
The formal concept analysis can be used as a qualitative method for data analysis. Since the early beginnings of FBA in the early 1980s, the FBA research group at TU Darmstadt has gained experience from more than 200 projects using the FBA (as of 2005).&lt;ref name="FCAFaA"&gt;{{citation |editor1=Bernhard Ganter |editor2=Gerd Stumme |editor3=Rudolf Wille|title=Formal Concept Analysis. Foundations and Applications|series=Lecture Notes in Computer Science |publisher=Springer Science &amp; Business Media|location=Berlin Heidelberg|isbn=3-540-27891-5|date=2005|volume=3626 | doi=10.1007/978-3-540-31881-1|url=https://books.google.com/books?id=nEh4D4e88NwC|access-date=2015-11-14}}&lt;/ref&gt; Including the fields of: [[medicine]] and [[cell biology]],&lt;ref&gt;{{citation |author1=Susanne Motameny |author2=Beatrix Versmold |author3=Rita Schmutzler |editor1=Raoul Medina |editor2=Sergei Obiedkov|periodical=Icfca 2008|title=Formal Concept Analysis for the Identification of Combinatorial Biomarkers in Breast Cancer |series=LNAI |volume=4933 |publisher=Springer |location=Berlin Heidelberg |pages=229–240 |isbn=978-3-540-78136-3 |date=2008 |url=https://www.springer.com/us/book/9783540781363 |access-date=2016-01-29}}&lt;/ref&gt;&lt;ref&gt;{{citation |author1=Dominik Endres |author2=Ruth Adam |author3=Martin A. Giese |author4=Uta Noppeney |editor1=Florent Domenach |editor2=Dmitry I. Ignatov |editor3=Jonas Poelmans |periodical=Icfca 2012 |title=Understanding the Semantic Structure of Human fMRI Brain Recordings with Formal Concept Analysis |series=LNCS |volume=7278 |publisher=Springer |location=Berlin Heidelberg |pages=96–111 |isbn=978-3-642-29891-2 |issn=0302-9743 |date=2012 |doi=10.1007/978-3-642-29892-9|s2cid=6256292 }}&lt;/ref&gt; [[genetics]],&lt;ref&gt;{{citation |author1=Denis Ponomaryov |author2=Nadezhda Omelianchuk |author3=Victoria Mironova |author4=Eugene Zalevsky |author5=Nikolay Podkolodny |author6=Eric Mjolsness |author7=Nikolay Kolchanov |editor1=Karl Erich Wolff |editor2=Dmitry E. Palchunov |editor3=Nikolay G. Zagoruiko |editor4=Urs Andelfinger |periodical=Kont 2007, KPP 2007|title=From Published Expression and Phenotype Data to Structured Knowledge: The Arabidopsis Gene Net Supplementary Database and Its Applications |series=LNCS |volume=6581 |publisher=Springer |location=Heidelberg New York |pages=101–120 |isbn=978-3-642-22139-2 |issn=0302-9743 |date=2011 |doi=10.1007/978-3-642-22140-8}}&lt;/ref&gt;&lt;ref&gt;{{citation |author1=Mehdi Kaytoue |author2=Sergei Kuznetsov |author3=Amedeo Napoli |author4=Sébastien Duplessis |periodical=Information Sciences |title=Mining gene expression data with pattern structures in formal concept analysis |volume=181 |issue=10 |publisher=Elsevier |pages=1989–2001 |date=2011 |doi=10.1016/j.ins.2010.07.007 |citeseerx=10.1.1.457.8879 |url=https://www.hse.ru/data/2010/11/01/1223500185/InformationSciences.pdf |access-date=2016-02-13 }}&lt;/ref&gt; [[ecology]],&lt;ref&gt;{{citation |author1=Aurélie Bertaux |author2=Florence Le Ber |author3=Agnès Braud |author4=Michèle Trémolières |editor1=Sébastien Ferré |editor2=Sebastian Rudolph |periodical=Icfca 2009 |title=Identifying Ecological Traits: A Concrete FCA-Based Approach |series=LNAI |volume=5548 |publisher=Springer-Verlag |location=Berlin Heidelberg |pages=224–236 |isbn=978-3-642-01814-5 |date=2009 |doi=10.1007/978-3-642-01815-2|s2cid=26304023 }}&lt;/ref&gt; [[software engineering]],&lt;ref&gt;{{citation |author1=Gregor Snelting |author2=Frank Tip |periodical=Proceeding. SIGSOFT '98/FSE-6 |title=Reengineering class hierarchies using concept analysis |volume=23 |issue=6 |publisher=ACM |location=New York |pages=99–110 |isbn=1-58113-108-9 |date=1998 |doi=10.1145/291252.288273 |url=http://dl.acm.org/citation.cfm?doid=288195.288273 |access-date=2016-02-04}}&lt;/ref&gt; [[ontology (information science)|ontology]],&lt;ref&gt;{{citation |author1=Gerd Stumme |author2=Alexander Maedche |editor1=Universität Leipzig |periodical=IJCAI |title=FCA-Merge: Bottom-up merging of ontologies |location=Leipzig |pages=225–230 |date=2001 |url=http://se-pubs.dbs.uni-leipzig.de/files/Stumme2001FCAMergeBottomupmergingofontologies.pdf |archive-url=https://web.archive.org/web/20160213113131/http://se-pubs.dbs.uni-leipzig.de/files/Stumme2001FCAMergeBottomupmergingofontologies.pdf |url-status=dead |archive-date=2016-02-13 |access-date=2016-02-13 }}&lt;/ref&gt; [[information management|information]] and [[library science]]s,&lt;ref&gt;{{citation |author1=Uta Priss |editor1=American Documentation Institute |periodical=Annual Review of Information Science and Technology |title=Formal Concept Analysis in Information Science |volume=40 |issue=1 |publisher=Information Today |location=Medford, NJ 09855 |pages=521–543 |issn=0066-4200 |date=2006 |doi=10.1002/aris.1440400120 |citeseerx=10.1.1.60.4220 |url=http://www.upriss.org.uk/papers/arist.pdf |access-date=2016-02-04 }}&lt;/ref&gt;&lt;ref&gt;{{citation |author1=Jens Illig |author2=Andreas Hotho |author3=Robert Jäschke |author4=Gerd Stumme |editor1=Karl Erich Wolff |editor2=Dmitry E. Palchunov |editor3=Nikolay G. Zagoruiko |editor4=Urs Andelfinger |periodical=Kont 2007, KPP 2007 |title=A Comparison of Content-Based Tag Recommendations in Folksonomy Systems |series=LNCS |volume=6581 |publisher=Springer |location=Heidelberg New York |pages=136–149 |isbn=978-3-642-22139-2 |issn=0302-9743 |date=2011 |doi=10.1007/978-3-642-22140-8}}&lt;/ref&gt;&lt;ref&gt;{{citation |editor1=Claudio Carpineto |editor2=Giovanni Romano |title=Concept Data Analysis: Theory and Applications |publisher=John Wiley &amp; Sons |isbn=0-470-85055-8 |date=2004 |url=http://eu.wiley.com/WileyCDA/WileyTitle/productCd-0470850558.html |access-date=2016-02-04}}&lt;/ref&gt; [[office administration]],&lt;ref&gt;{{citation |author1=Richard Cole |author2=Gerd Stumme |editor1=Bernhard Ganter |editor2=Guy W. Mineau |periodical=Conceptual Structures: Logical, Linguistic, and Computational Issues |title=CEM – A Conceptual Email Manager |series=LNAI |volume=1867 |publisher=Springer-Verlag |location=Berlin Heidelberg |pages=438–452 |isbn=3-540-67859-X |date=2000 |doi=10.1007/10722280|s2cid=5942241 }}&lt;/ref&gt; [[law]],&lt;ref&gt;{{citation |author1=Dieter Eschenfelder |author2=Wolfgang Kollewe |author3=Martin Skorsky |author4=Rudolf Wille |editor1=Gerd Stumme |editor2=Rudolf Wille |periodical=Begriffliche Wissensverarbeitung – Methoden und Anwendungen |title=Ein Erkundungssystem zum Baurecht: Methoden der Entwicklung eines TOSCANA-Systems |publisher=Springer |location=Berlin Heidelberg |pages=254–272 |isbn=3-540-66391-6 |date=2000 |language=de |doi=10.1007/978-3-642-57217-3_12}}&lt;/ref&gt;&lt;ref&gt;{{citation |author1=Nada Mimouni |author2=Adeline Nazarenko |author3=Sylvie Salotti |editor1=Jaume Baixeries |editor2=Christian Sacarea |editor3=Manuel Ojeda-Aciego |periodical=Icfca 2015 |title=A Conceptual Approach for Relational IR: Application to Legal Collections |series=LNAI |volume=9113 |publisher=Springer |location=Heidelberg New York |pages=303–318 |isbn=978-3-319-19544-5 |issn=0302-9743 |date=2015 |doi=10.1007/978-3-319-19545-2_19}}&lt;/ref&gt; [[linguistics]],&lt;ref&gt;{{citation |author1=Uta Priss |editor1=Bernhard Ganter |editor2=Gerd Stumme |editor3=Rudolf Wille |periodical=Formal Concept Analysis – Foundations and Applications|title=Linguistic Applications of Formal Concept Analysis |series=LNCS |volume=3626 |publisher=Springer |location=Berlin Heidelberg |pages=149–160 |isbn=3-540-27891-5 |issn=0302-9743 |date=2005 |doi=10.1007/978-3-540-31881-1}}&lt;/ref&gt; [[political science]].&lt;ref&gt;{{citation |author1=Beate Kohler-Koch |author2=Frank Vogt |author3=Gerhard Stumme |author4=Rudolf Wille |periodical=Begriffliche Wissenverarbeitung – Methoden und Anwendungen|title=Normen- und Regelgeleitete internationale Kooperationen: Quoted in: Peter Becker et al. The ToscanaJ Suite for Implementing Conceptual Information Systems |publisher=Springer |location=Berlin, Heidelberg, New York |pages=325–340 |isbn=978-3-540-66391-1 |date=2000 |language=de}}&lt;/ref&gt;

Many more examples are e.g. described in: ''Formal Concept Analysis. Foundations and Applications'',&lt;ref name="FCAFaA" /&gt; conference papers at regular conferences such as: ''International Conference on Formal Concept Analysis'' (ICFCA),&lt;ref&gt;{{cite web| title=International Conference on Formal Concept Analysis| publisher=[[Digital Bibliography &amp; Library Project|dblp]]| url=http://dblp.uni-trier.de/db/conf/icfca/index| access-date=2016-02-14}}&lt;/ref&gt; ''Concept Lattices and their Applications'' (CLA),&lt;ref&gt;{{cite web| title=CLA: Concept Lattices and Their Applications| publisher=CLA| url=http://cla.inf.upol.cz/papers.html| access-date=2015-11-14}}&lt;/ref&gt; or ''International Conference on Conceptual Structures'' (ICCS).&lt;ref&gt;{{cite web |title=International Conferences On Conceptual Structures – Conferences and Workshops| publisher=New Mexico State University |url=http://conceptualstructures.org/confs.htm |access-date=2016-02-14}}&lt;/ref&gt;

== See also ==
{{Div col|colwidth=22em}}
* [[Association rule learning]]
* [[Cluster analysis]]
* [[Commonsense reasoning]]
* [[Conceptual analysis]]
* [[Conceptual clustering]]
* [[Conceptual space]]
* [[Concept learning]]
* [[Correspondence analysis]]
* [[Description logic]]
* [[Factor analysis]]
* [[Graphical model]]
* [[Grounded theory]]
* [[Inductive logic programming]]
* [[Pattern theory]]
* [[Statistical relational learning]]
* [[Schema (genetic algorithms)]]
{{Div col end}}

== Notes ==
{{Reflist}}

== References ==
{{refbegin}}
* {{citation | editor1-last = Ganter | editor1-first = Bernhard | editor2-last = Stumme | editor2-first = Gerd | editor3-last = Wille | editor3-first = Rudolf | title = Formal Concept Analysis: Foundations and Applications | publisher = Lecture Notes in Artificial Intelligence, no. 3626, Springer-Verlag | year = 2005 | isbn = 3-540-27891-5}}
* {{citation | last1 = Ganter | first1 = Bernhard | last2 = Wille | first2 = Rudolf | title = Formal Concept Analysis: Mathematical Foundations | publisher = Springer-Verlag, Berlin | year = 1998 | isbn = 3-540-62771-5 |translator=C. Franzke}}
* {{citation | last1 = Carpineto | first1 = Claudio | last2 = Romano | first2 = Giovanni | title = Concept Data Analysis: Theory and Applications | publisher = Wiley | year = 2004 | isbn = 978-0-470-85055-8}}
* {{citation |first = Karl Erich |last = Wolff |title = A first course in Formal Concept Analysis |editor = F. Faulbaum in StatSoft 1993 |publisher = Gustav Fischer Verlag |url = http://fbmn.fh-darmstadt.de/home/wolff/Publikationen/A_First_Course_in_Formal_Concept_Analysis.pdf |pages = 429–438 |year = 1994 |archive-url=https://web.archive.org/web/20060323075347/http://fbmn.fh-darmstadt.de/home/wolff/Publikationen/A_First_Course_in_Formal_Concept_Analysis.pdf |archive-date = 2006-03-23 }}
* {{citation | last1=Davey | first1=B.A. | last2=Priestley | first2=H. A. | title=Introduction to Lattices and Order, chapter 3. Formal Concept Analysis | publisher=[[Cambridge University Press]] | isbn=978-0-521-78451-1 | year=2002}}
{{refend}}

== External links ==
* [http://www.upriss.org.uk/fca/fca.html A Formal Concept Analysis Homepage]
* [http://www.ketlab.org.uk/scripts/context Demo]
* [http://www.math.tu-dresden.de/icfca13/ 11th International Conference on Formal Concept Analysis. ICFCA 2013 – Dresden, Germany – May 21–24, 2013]

{{DEFAULTSORT:Formal Concept Analysis}}
[[Category:Machine learning]]
[[Category:Lattice theory]]
[[Category:Data mining]]
[[Category:Ontology (information science)]]</text>
      <sha1>mbtnfrid3aqpqtf6uze53y2exlkvahp</sha1>
    </revision>
  </page>
  <page>
    <title>Deeplearning4j</title>
    <ns>0</ns>
    <id>43169442</id>
    <revision>
      <id>1003050071</id>
      <parentid>1002442638</parentid>
      <timestamp>2021-01-27T05:25:18Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 20 templates: hyphenate params (10×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="14638" xml:space="preserve">{{cleanup-PR|1=article|date=November 2017}}
{{notability|Products|date=July 2020}}
{{Infobox software
| name                   = Eclipse Deeplearning4j
| logo                   = 
| screenshot             = 
| caption                =
| collapsible            =
| author                 = Alex D. Black, Adam Gibson, Vyacheslav Kokorin, Josh Patterson
| developer              = [https://github.com/eclipse/deeplearning4j/graphs/contributors Various]
| released               = &lt;!-- {{Start date and age|YYYY|MM|DD|df=yes}} --&gt;
| latest release version = 1.0.0-beta6
| latest release date    = {{Start date and age|2019|9|10|df=yes}}
| latest preview version = 
| latest preview date    = &lt;!-- {{Start date and age|YYYY|MM|DD|df=yes}} --&gt;
| programming language   = [[Java (programming language)|Java]], [[CUDA]], [[C (programming language)|C]], [[C++]], 
| operating system       = [[Linux]], [[macOS]], [[Microsoft Windows|Windows]], [[Android (operating system)|Android]], [[iOS]]
| platform               = [[Cross-platform]]
| size                   =
| language               = English
| status                 = Active
| genre                  = [[Natural language processing]], [[deep learning]], [[machine vision]], [[artificial intelligence]]
| license                = [[Apache License 2.0]]
}}

{{machine learning bar}}
Eclipse '''Deeplearning4j''' is a programming [[Library (computing)|library]] written in [[Java (programming language)|Java]] for the [[Java virtual machine]] (JVM).&lt;ref name="wired"&gt;{{cite magazine|first=Cade|last=Metz|title=The Mission to Bring Google's AI to the Rest of the World|magazine=[[Wired.com]]|date=2014-06-02|url=https://www.wired.com/2014/06/skymind-deep-learning/|access-date=2014-06-28}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.businessweek.com/articles/2014-06-03/teaching-smaller-companies-how-to-probe-deep-learning-on-their-own|title=Deep Learning for (Some of) the People|last=Vance|first=Ashlee|work=[[Bloomberg Businessweek]]|date=2014-06-03|access-date=2014-06-28}}&lt;/ref&gt; It is a [[Software framework|framework]] with wide support for deep learning algorithms.&lt;ref&gt;{{cite web|url=https://venturebeat.com/2015/11/14/deep-learning-frameworks/|title=Want an open-source deep learning framework? Take your pick|last=Novet|first=Jordan|work=[[VentureBeat]]|date=2015-11-14|access-date=2015-11-24}}&lt;/ref&gt; Deeplearning4j includes implementations of the [[restricted Boltzmann machine]], [[deep belief net]], deep autoencoder, stacked denoising autoencoder and [[Recursive neural network#Tensor|recursive neural tensor network]], [[word2vec]], doc2vec, and [[GloVe (machine learning)|GloVe]]. These algorithms all include [[Distributed computing|distributed]] [[Parallel computing|parallel]] versions that integrate with [[Apache Hadoop]] and [[Apache Spark|Spark]].&lt;ref&gt;{{cite web|url=https://www.youtube.com/watch?v=LCsc1hFuNac|title=Adam Gibson, DeepLearning4j on Spark and Data Science on JVM with nd4j, SF Spark @Galvanize 20150212 |last=TV|first=Functional|work=SF Spark Meetup|date=2015-02-12|access-date=2015-03-01}}&lt;/ref&gt;

Deeplearning4j is [[open-source software]] released under [[Apache License]] 2.0,&lt;ref&gt;{{cite web|title=Github Repository|date=April 2020|url=https://github.com/agibsonccc/java-deeplearning}}&lt;/ref&gt; developed mainly by a [[machine learning]] group headquartered in [[San Francisco]].&lt;ref name="deeplearning4j.org"&gt;{{cite web|url=http://deeplearning4j.org/|title=deeplearning4j.org}}&lt;/ref&gt; It is supported commercially by the startup Skymind, which bundles DL4J, [[TensorFlow]], [[Keras]] and other deep learning libraries in an enterprise distribution called the Skymind Intelligence Layer.&lt;ref&gt;{{cite web|title=Skymind Intelligence Layer Community Edition|url=https://skymind.ai/quickstart|access-date=2017-11-02|archive-url=https://web.archive.org/web/20171107015537/https://skymind.ai/quickstart|archive-date=2017-11-07|url-status=dead}}&lt;/ref&gt; Deeplearning4j was contributed to the [[Eclipse Foundation]] in October 2017.&lt;ref&gt;{{cite web|title=Eclipse Deeplearning4j Project Page|date=22 June 2017|url=https://projects.eclipse.org/proposals/deeplearning4j}}&lt;/ref&gt;&lt;ref&gt;{{cite web|title=Skymind's Deeplearning4j, the Eclipse Foundation, and scientific computing in the JVM|url=https://jaxenter.com/skymind-deeplearning4j-eclipse-138872.html|work=Jaxenter|date=13 November 2017|access-date=2017-11-15}}&lt;/ref&gt;

==Introduction==
Deeplearning4j relies on the widely used programming language [[Java (programming language)|Java]], though it is compatible with [[Clojure]] and includes a [[Scala (programming language)|Scala]] [[application programming interface]] (API). It is powered by its own open-source numerical computing library, [[ND4J (software)|ND4J]], and works with both [[central processing unit]]s (CPUs) and [[graphics processing unit]]s (GPUs).&lt;ref name="om"&gt;{{cite web|first=Derrick|last=Harris|title=A startup called Skymind launches, pushing open source deep learning|work=[[GigaOM.com]]|date=2014-06-02|url=http://gigaom.com/2014/06/02/a-startup-called-skymind-launches-pushing-open-source-deep-learning/|access-date=2014-06-29}}&lt;/ref&gt;&lt;ref name="vb"&gt;{{cite web|first=Jordan|last=Novet|title=Skymind launches with open-source, plug-and-play deep learning features for your app|date=2014-06-02|url=https://venturebeat.com/2014/06/02/skymind-launches-with-open-source-plug-and-play-deep-learning-features-for-your-app//|access-date=2014-06-29}}&lt;/ref&gt;

Deeplearning4j has been used in several commercial and academic applications. The code is hosted on [[GitHub]].&lt;ref&gt;[https://github.com/deeplearning4j/deeplearning4j Deeplearning4j source code]&lt;/ref&gt; A support forum is maintained on [[Gitter]].&lt;ref&gt;[https://gitter.im/deeplearning4j/deeplearning4j Deeplearning4j Gitter Support Channel]&lt;/ref&gt;

The framework is composable, meaning shallow neural nets such as restricted Boltzmann machines, convolutional nets, autoencoders, and recurrent nets can be added to one another to create deep nets of varying types. It also has extensive visualization tools,&lt;ref&gt;[http://deeplearning4j.org/visualization Deeplearning4j Visualization Tools]&lt;/ref&gt; and a computation graph.&lt;ref&gt;[http://deeplearning4j.org/compgraph Deeplearning4j Computation Graph]&lt;/ref&gt;

==Distributed==
Training with Deeplearning4j occurs in a cluster. Neural nets are trained in parallel via iterative reduce, which works on [[Hadoop]]-YARN and on [[Apache Spark|Spark]].&lt;ref name="deeplearning4j.org"/&gt;&lt;ref&gt;{{cite web|url=https://github.com/emsixteeen/IterativeReduce|title=Iterative reduce|date=15 March 2020}}&lt;/ref&gt; Deeplearning4j also integrates with CUDA kernels to conduct pure GPU operations, and works with distributed GPUs.

==Scientific computing for the JVM==
Deeplearning4j includes an n-dimensional array class using [[ND4J (software)|ND4J]] that allows scientific computing in Java and Scala, similar to the functions that [[NumPy]] provides to [[Python (programming language)|Python]]. It's effectively based on a library for [[linear algebra]] and [[Matrix (mathematics)|matrix]] manipulation in a production environment.

==DataVec vectorization library for machine-learning==
DataVec vectorizes various file formats and data types using an [[input/output]] format system similar to Hadoop's use of MapReduce; that is, it turns various data types into columns of scalars termed [[Vector (mathematics and physics)|vectors]]. DataVec is designed to vectorize CSVs, images, sound, text, video, and time series.&lt;ref&gt;[http://deeplearning4j.org/datavec DataVec ETL for Machine Learning]&lt;/ref&gt;&lt;ref&gt;[https://www.infoq.com/articles/deep-learning-time-series-anomaly-detection Anomaly Detection for Time Series Data with Deep Learning]&lt;/ref&gt;

==Text and NLP==
Deeplearning4j includes a [[vector space model]]ing and [[topic model]]ing toolkit, implemented in Java and integrating with parallel GPUs for performance. It is designed to handle large text sets.

Deeplearning4j includes implementations of term frequency–inverse document frequency ([[tf–idf]]), [[deep learning]], and Mikolov's word2vec algorithm,&lt;ref&gt;[https://code.google.com/p/word2vec/ word2vec]&lt;/ref&gt; doc2vec, and GloVe, reimplemented and optimized in Java. It relies on [[t-distributed stochastic neighbor embedding]] (t-SNE) for word-cloud visualizations.

==Real-world use cases and integrations==
Real-world use cases for Deeplearning4j include network intrusion detection and cybersecurity, fraud detection for the financial sector,&lt;ref&gt;{{Cite web |url=http://www.skymind.io/finance/ |title=Archived copy |access-date=2016-02-22 |archive-url=https://web.archive.org/web/20160310082208/http://www.skymind.io/finance/ |archive-date=2016-03-10 |url-status=dead }}&lt;/ref&gt;&lt;ref&gt;https://skymind.ai/bsa-aml{{Dead link|date=September 2018 |bot=InternetArchiveBot |fix-attempted=yes }}&lt;/ref&gt; anomaly detection in industries such as manufacturing, recommender systems in e-commerce and advertising,&lt;ref&gt;{{cite web |url=http://www.skymind.io/commerce/ |title=Archived copy |access-date=2016-02-22 |url-status=dead |archive-url=https://web.archive.org/web/20160310082156/http://www.skymind.io/commerce/ |archive-date=2016-03-10 }}&lt;/ref&gt; and image recognition.&lt;ref&gt;https://skymind.ai/image{{Dead link|date=September 2018 |bot=InternetArchiveBot |fix-attempted=yes }}&lt;/ref&gt; Deeplearning4j has integrated with other machine-learning platforms such as RapidMiner, Prediction.io,&lt;ref&gt;https://www.rapidminerchina.com/en/products/shop/product/deeplearning4j/{{Dead link|date=September 2018 |bot=InternetArchiveBot |fix-attempted=yes }}&lt;/ref&gt; and [[Weka (machine learning)|Weka]].&lt;ref&gt;https://deeplearning.cms.waikato.ac.nz/&lt;/ref&gt;

==Machine Learning Model Server==

Deeplearning4j serves machine-learning models for inference in production using the free developer edition of SKIL, the Skymind Intelligence Layer.&lt;ref&gt;{{Cite web |url=https://skymind.ai/products |title=Archived copy |access-date=2017-09-20 |archive-url=https://web.archive.org/web/20170921001159/https://skymind.ai/products |archive-date=2017-09-21 |url-status=dead }}&lt;/ref&gt;&lt;ref&gt;{{Cite web |url=https://deeplearning4j.org/modelserver |title=Archived copy |access-date=2017-09-20 |archive-url=https://web.archive.org/web/20170921001516/https://deeplearning4j.org/modelserver |archive-date=2017-09-21 |url-status=dead }}&lt;/ref&gt; A model server serves the parametric machine-learning models that makes decisions about data. It is used for the inference stage of a machine-learning workflow, after data pipelines and model training. A model server is the tool that allows data science research to be deployed in a real-world production environment.

What a Web server is to the Internet, a model server is to AI. Where a Web server receives an HTTP request and returns data about a Web site, a model server receives data, and returns a decision or prediction about that data: e.g. sent an image, a model server might return a label for that image, identifying faces or animals in photographs.

The SKIL model server is able to import models from Python frameworks such as Tensorflow, Keras, Theano and CNTK, overcoming a major barrier in deploying deep learning models.

==Benchmarks==
Deeplearning4j is as fast as Caffe for non-trivial image recognition tasks using multiple GPUs.&lt;ref&gt;{{Cite web | url=https://github.com/deeplearning4j/dl4j-benchmark | title=GitHub - deeplearning4j/Dl4j-benchmark: Repo to track dl4j benchmark code | date=19 December 2019}}&lt;/ref&gt; For programmers unfamiliar with HPC on the JVM, there are several parameters that must be adjusted to optimize neural network training time. These include setting the heap space, the garbage collection algorithm, employing off-heap memory and pre-saving data (pickling) for faster ETL.&lt;ref&gt;https://deeplearning4j.org/benchmark&lt;/ref&gt; Together, these optimizations can lead to a 10x acceleration in performance with Deeplearning4j.

==API Languages: Java, Scala, Python , Clojure &amp; Kotlin==
Deeplearning4j can be used via multiple API languages including Java, Scala, Python, Clojure and Kotlin. Its Scala API is called ScalNet.&lt;ref&gt;https://deeplearning4j.org/scala&lt;/ref&gt;  Keras serves as its Python API.&lt;ref&gt;{{Cite web |url=https://deeplearning4j.org/keras# |title=Archived copy |access-date=2017-02-25 |archive-url=https://web.archive.org/web/20170225133010/https://deeplearning4j.org/keras# |archive-date=2017-02-25 |url-status=dead }}&lt;/ref&gt;  And its Clojure wrapper is known as DL4CLJ.&lt;ref&gt;{{Cite web |url=https://deeplearning4j.org/clojure |title=Archived copy |access-date=2017-02-25 |archive-url=https://web.archive.org/web/20170225133007/https://deeplearning4j.org/clojure |archive-date=2017-02-25 |url-status=dead }}&lt;/ref&gt; The core languages performing the large-scale mathematical operations necessary for deep learning are C, C++ and CUDA C.

==Tensorflow, Keras &amp; Deeplearning4j==

Tensorflow, Keras and Deeplearning4j work together. Deeplearning4j can import models from Tensorflow and other Python frameworks if they have been created with Keras.&lt;ref&gt;{{Cite web |url=https://deeplearning4j.org/tensorflow |title=Archived copy |access-date=2017-09-07 |archive-url=https://web.archive.org/web/20170908021856/https://deeplearning4j.org/tensorflow |archive-date=2017-09-08 |url-status=dead }}&lt;/ref&gt;

==See also==
{{Portal|Free and open-source software|Computer programming}}
* [[Comparison of deep learning software]]
* [[Artificial intelligence]]
* [[Machine learning]]
* [[Deep learning]]

==References==
{{Reflist|30em}}

{{Computer vision footer}}
{{Deep Learning Software}}

[[Category:Applied machine learning]]
[[Category:Artificial neural networks]]
[[Category:Cluster computing]]
[[Category:Data mining and machine learning software]]
[[Category:Deep learning]]
[[Category:Neural network software]]
[[Category:Free data analysis software]]
[[Category:Free science software]]
[[Category:Free software programmed in Java (programming language)]]
[[Category:Java (programming language) software]]
[[Category:Free software programmed in Scala]]
[[Category:Free statistical software]]
[[Category:Hadoop]]
[[Category:Image processing]]
[[Category:Information technology companies of the United States]]
[[Category:Java (programming language) libraries]]
[[Category:Java platform]]
[[Category:Java programming language family]]
[[Category:JVM programming languages]]
[[Category:Machine learning]]
[[Category:Natural language processing]]
[[Category:Numerical programming languages]]
[[Category:Open-source artificial intelligence]]
[[Category:Scala (programming language)]]
[[Category:Software using the Apache license]]
[[Category:Technology companies based in the San Francisco Bay Area]]</text>
      <sha1>7pizn8joxsmbtsl5fxhp2tnpuadbkvs</sha1>
    </revision>
  </page>
  <page>
    <title>Local case-control sampling</title>
    <ns>0</ns>
    <id>46963137</id>
    <revision>
      <id>948377111</id>
      <parentid>886291396</parentid>
      <timestamp>2020-03-31T18:26:04Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <comment>Add: pmc, pmid. | You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | Activated by [[User:Zppix]] | [[Category:Machine learning‎]] | via #UCB_Category</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="5792" xml:space="preserve">In [[machine learning]], '''local case-control sampling''' &lt;ref name="LCC"&gt;{{cite journal|last1=Fithian|first1=William|last2=Hastie|first2=Trevor|title=Local case-control sampling: Efficient subsampling in imbalanced data sets|journal=The Annals of Statistics|date=2014|volume=42|issue=5|pages=1693–1724|ref=http://arxiv.org/abs/1306.3706|doi=10.1214/14-aos1220|pmid=25492979|pmc=4258397|arxiv=1306.3706}}&lt;/ref&gt; is an [[algorithm]] used to reduce the complexity of training a [[logistic regression]] classifier. The algorithm reduces the training complexity by selecting a small subsample of the original dataset for training. It assumes the availability of a (unreliable) pilot estimation of the parameters. It then performs a single pass over the entire dataset using the pilot estimation to identify the most "surprising" samples. In practice, the pilot may come from prior knowledge or training using a subsample of the dataset. The algorithm is most effective when the underlying dataset is imbalanced. It exploits the structures of conditional imbalanced datasets more efficiently than alternative methods, such as [[Logistic regression#Case-control sampling|case control sampling]] and weighted case control sampling.

== Imbalanced datasets == 
In [[Statistical classification|classification]], a dataset is a set of ''N'' data points &lt;math&gt; (x_i, y_i)_{i=1}^N &lt;/math&gt;, where &lt;math&gt; x_i \in\mathbb R^d &lt;/math&gt; is a feature vector, &lt;math&gt; y_i \in \{0,1\} &lt;/math&gt; is a label. Intuitively, a dataset is imbalanced when certain important statistical patterns are rare. The lack of observations of certain patterns does not always imply their irrelevance. For example, in medical studies of rare diseases, the small number of infected patients (cases) conveys the most valuable information for diagnosis and treatments.

Formally, an imbalanced dataset exhibits one or more of the following properties:
* ''Marginal Imbalance''. A dataset is marginally imbalanced if one class is rare compared to the other class. In other words, &lt;math&gt; \mathbb{P}(Y=1) \approx 0 &lt;/math&gt;. 
* ''Conditional Imbalance''. A dataset is conditionally imbalanced when it is easy to predict the correct labels in most cases. For example, if &lt;math&gt; X \in \{0,1\} &lt;/math&gt;, the dataset is conditionally imbalanced if &lt;math&gt; \mathbb{P}(Y=1\mid X=0) \approx 0 &lt;/math&gt; and &lt;math&gt; \mathbb{P}(Y=1\mid X=1) \approx 1 &lt;/math&gt;.

== Algorithm outline ==
In logistic regression, given the model &lt;math&gt; \theta = (\alpha, \beta) &lt;/math&gt;, the prediction is made according to &lt;math&gt; \mathbb{P}(Y=1\mid X; \theta) =  \tilde{p}_{\theta}(x) = \frac{\exp(\alpha+\beta^T x)}{1+\exp(\alpha+\beta^T x)} &lt;/math&gt;. The local-case control sampling algorithm assumes the availability of a pilot model &lt;math&gt;\tilde{\theta} =  (\tilde{\alpha}, \tilde{\beta}) &lt;/math&gt;. Given the pilot model, the algorithm performs a single pass over the entire dataset to select the subset of samples to include in training the logistic regression model. For a sample &lt;math&gt; (x,y) &lt;/math&gt;, define the acceptance probability as &lt;math&gt; a(x,y) = |y-\tilde{p}_{\tilde{\theta}}(x)| &lt;/math&gt;. The algorithm proceeds as follows:

# Generate independent &lt;math&gt; z_i \sim \text{Bernoulli}(a(x_i,y_i)) &lt;/math&gt; for &lt;math&gt; i \in \{1, \ldots, N\} &lt;/math&gt;.
# Fit a logistic regression model to the subsample &lt;math&gt; S = \{(x_i, y_i) : z_i =1 \} &lt;/math&gt;, obtaining the unadjusted estimates &lt;math&gt; \hat{\theta}_S = (\hat{\alpha}_S, \hat{\beta}_S) &lt;/math&gt;. 
# The output model is &lt;math&gt; \hat{\theta} = (\hat{\alpha}, \hat{\beta}) &lt;/math&gt;, where &lt;math&gt;\hat{\alpha} \leftarrow \hat{\alpha}_S + \tilde{\alpha} &lt;/math&gt; and &lt;math&gt;\hat{\beta} \leftarrow \hat{\beta}_S + \tilde{\beta} &lt;/math&gt;.

The algorithm can be understood as selecting samples that surprises the pilot model. Intuitively these samples are closer to the [[decision boundary]] of the classifier and is thus more informative.

=== Obtaining the pilot model ===
In practice, for cases where a pilot model is naturally available, the algorithm can be applied directly to reduce the complexity of training. In cases where a natural pilot is nonexistent, an estimate using a subsample selected through another sampling technique can be used instead. In the original paper describing the algorithm, the authors propose to use weighted case-control sampling with half the assigned sampling budget. For example, if the objective is to use a subsample with size &lt;math&gt; N=1000 &lt;/math&gt;, first estimate a model &lt;math&gt;\tilde{\theta} &lt;/math&gt; using &lt;math&gt; N_h = 500 &lt;/math&gt; samples from weighted case control sampling, then collect another &lt;math&gt; N_h = 500 &lt;/math&gt; samples using local case-control sampling.

=== Larger or smaller sample size ===
It is possible to control the sample size by multiplying the acceptance probability with a constant &lt;math&gt; c &lt;/math&gt;. For a larger sample size, pick &lt;math&gt; c&gt;1 &lt;/math&gt; and adjust the acceptance probability to &lt;math&gt; \min(ca(x_i, y_i), 1) &lt;/math&gt;. For a smaller sample size, the same strategy applies. In cases where the number of samples desired is precise, a convenient alternative method is to uniformly downsample from a larger subsample selected by local case-control sampling.

== Properties ==
The algorithm has the following properties. When the pilot is [[Consistency (statistics)|consistent]], the estimates using the samples from local case-control sampling is consistent even under [[Statistical model specification|model misspecification]]. If the model is correct then the algorithm has exactly twice the asymptotic variance of logistic regression on the full data set. For a larger sample size with &lt;math&gt; c&gt;1 &lt;/math&gt;, the factor 2 is improved to &lt;math&gt; 1+\frac{1}{c} &lt;/math&gt;.

== References == 
{{Reflist}}

[[Category:Machine learning]]
[[Category:Logistic regression]]</text>
      <sha1>6ye0fgv905wak0uyiift10csfwdj1oq</sha1>
    </revision>
  </page>
  <page>
    <title>Machine learning</title>
    <ns>0</ns>
    <id>233488</id>
    <revision>
      <id>1004065505</id>
      <parentid>1004065404</parentid>
      <timestamp>2021-01-31T22:49:36Z</timestamp>
      <contributor>
        <username>Гармонический Мир</username>
        <id>26270034</id>
      </contributor>
      <comment>/* Proprietary software with free and open-source editions */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="87690" xml:space="preserve">{{short description|Scientific study of algorithms and statistical models that computer systems use to perform tasks without explicit instructions}}
{{for|the journal|Machine Learning (journal)}}
{{redirect|Statistical learning|statistical learning in linguistics|statistical learning in language acquisition}}
{{Machine learning bar}}
{{Evolutionary algorithms}}

'''Machine learning''' ('''ML''') is the study of computer [[algorithm]]s that improve automatically through experience.&lt;ref&gt;{{Cite book|last=Mitchell|first=Tom|url=http://www.cs.cmu.edu/~tom/mlbook.html|title=Machine Learning|publisher=McGraw Hill|year=1997|isbn=0-07-042807-7|location=New York|oclc=36417892|author-link=Tom M. Mitchell}}&lt;/ref&gt; It is seen as a part of [[artificial intelligence]]. Machine learning algorithms build a model based on sample data, known as "[[training data]]", in order to make predictions or decisions without being explicitly programmed to do so.{{refn|The definition "without being explicitly programmed" is often attributed to [[Arthur Samuel]], who coined the term "machine learning" in 1959, but the phrase is not found verbatim in this publication, and may be a [[paraphrase]] that appeared later. Confer "Paraphrasing Arthur Samuel (1959), the question is: How can computers learn to solve problems without being explicitly programmed?" in {{Cite conference|title=Automated Design of Both the Topology and Sizing of Analog Electrical Circuits Using Genetic Programming|conference=Artificial Intelligence in Design '96|last1=Koza|first1=John R.|last2=Bennett|first2=Forrest H.|last3=Andre|first3=David|last4=Keane|first4=Martin A.|date=1996|publisher=Springer, Dordrecht|pages=151–170|language=en|doi=10.1007/978-94-009-0279-4_9}}}} Machine learning algorithms are used in a wide variety of applications, such as [[email filtering]] and [[computer vision]], where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.

A subset of machine learning is closely related to [[computational statistics]], which focuses on making predictions using computers; but not all machine learning is statistical learning. The study of [[mathematical optimization]] delivers methods, theory and application domains to the field of machine learning. [[Data mining]] is a related field of study, focusing on [[exploratory data analysis]] through [[unsupervised learning]].{{refn|Machine learning and pattern recognition "can be viewed as two facets of the same field."&lt;ref name="bishop2006" /&gt;{{rp|vii}}}}&lt;ref&gt;{{cite journal |last=Friedman |first=Jerome H. |author-link = Jerome H. Friedman|title=Data Mining and Statistics: What's the connection? |journal=Computing Science and Statistics |volume=29 |issue=1 |year=1998 |pages=3–9}}&lt;/ref&gt; In its application across business problems, machine learning is also referred to as [[predictive analytics]].

{{Toclimit|3}}

== Overview ==
Machine learning involves computers discovering how they can perform tasks without being explicitly programmed to do so. It involves computers learning from data provided so that they carry out certain tasks. For simple tasks assigned to computers, it is possible to program algorithms telling the machine how to execute all steps required to solve the problem at hand; on the computer's part, no learning is needed. For more advanced tasks, it can be challenging for a human to manually create the needed algorithms. In practice, it can turn out to be more effective to help the machine develop its own algorithm, rather than having human programmers specify every needed step.&lt;ref name = "Alpaydin2020"&gt;{{cite book
 | author = Ethem Alpaydin 
 | title =Introduction to Machine Learning
 | year = 2020
 | edition = Fourth
 | pages = xix, 1–3, 13–18
 | publisher = [[MIT]]
 |isbn = 978-0262043793
 }}&lt;/ref&gt;

The discipline of machine learning employs various approaches to teach computers to accomplish tasks where no fully satisfactory algorithm is available. In cases where vast numbers of potential answers exist, one approach is to label some of the correct answers as valid. This can then be used as training data for the computer to improve the algorithm(s) it uses to determine correct answers. For example, to train a system for the task of digital character recognition, the [[MNIST database|MNIST]] dataset of handwritten digits has often been used.&lt;ref name = "Alpaydin2020"/&gt;

=== Machine learning approaches ===
{{Anchor|Algorithm types}}
Machine learning approaches are traditionally divided into three broad categories, depending on the nature of the "signal" or "feedback" available to the learning system:
* [[Supervised learning]]: The computer is presented with example inputs and their desired outputs, given by a "teacher", and the goal is to learn a general rule that [[Map (mathematics)|maps]] inputs to outputs.
* [[Unsupervised learning]]: No labels are given to the learning algorithm, leaving it on its own to find structure in its input. Unsupervised learning can be a goal in itself (discovering hidden patterns in data) or a means towards an end ([[feature learning]]).
* [[Reinforcement learning]]: A computer program interacts with a dynamic environment in which it must perform a certain goal (such as [[Autonomous car|driving a vehicle]] or playing a game against an opponent). As it navigates its problem space, the program is provided feedback that's analogous to rewards, which it tries to maximize.&lt;ref name="bishop2006"/&gt;

Other approaches have been developed which don't fit neatly into this three-fold categorisation, and sometimes more than one is used by the same machine learning system. For example [[topic modeling]], [[dimensionality reduction]] or [[Meta learning (computer science)|meta learning]].&lt;ref&gt;{{cite book
 | authors = Pavel Brazdil, Christophe Giraud Carrier, Carlos Soares, Ricardo Vilalta
 | title =Metalearning: Applications to Data Mining
 | year = 2009
 | edition = Fourth
 | pages = 10–14, ''passim''
 | publisher = [[Springer Science+Business Media]]
 |isbn = 978-3540732624
 }}&lt;/ref&gt;

As of 2020, [[deep learning]] has become the dominant approach for much ongoing work in the field of machine learning.&lt;ref name = "Alpaydin2020"/&gt;

== History and relationships to other fields ==
{{see also|Timeline of machine learning}}
The term ''machine learning'' was coined in 1959 by [[Arthur Samuel]], an American [[IBMer]] and pioneer in the field of [[computer gaming]] and [[artificial intelligence]].&lt;ref name="Samuel"&gt;{{Cite journal|last=Samuel|first=Arthur|date=1959|title=Some Studies in Machine Learning Using the Game of Checkers|journal=IBM Journal of Research and Development|volume=3|issue=3|pages=210–229|doi=10.1147/rd.33.0210|citeseerx=10.1.1.368.2254}}&lt;/ref&gt;&lt;ref&gt;R. Kohavi and F. Provost, "Glossary of terms," Machine Learning, vol. 30, no. 2–3, pp. 271–274, 1998.&lt;/ref&gt; A representative book of the machine learning research during the 1960s was the Nilsson's book on Learning Machines, dealing mostly with machine learning for pattern classification.&lt;ref&gt;Nilsson N. Learning Machines, McGraw Hill, 1965.&lt;/ref&gt; Interest related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973.&lt;ref&gt;Duda, R., Hart P. Pattern Recognition and Scene Analysis, Wiley Interscience, 1973&lt;/ref&gt; In 1981 a report was given on using teaching strategies so that a neural network learns to recognize 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal.&lt;ref&gt;S. Bozinovski "Teaching space: A representation concept for adaptive pattern classification" COINS Technical Report No. 81-28, Computer and Information Science Department, University of Massachusetts at Amherst, MA, 1981. https://web.cs.umass.edu/publication/docs/1981/UM-CS-1981-028.pdf&lt;/ref&gt;

[[Tom M. Mitchell]] provided a widely quoted, more formal definition of the algorithms studied in the machine learning field: "A computer program is said to learn from experience ''E'' with respect to some class of tasks ''T'' and performance measure ''P'' if its performance at tasks in ''T'', as measured by ''P'',  improves with experience ''E''."&lt;ref name="Mitchell-1997"&gt;{{cite book
|author=Mitchell, T. 
|title=Machine Learning
|publisher=McGraw Hill
|isbn= 978-0-07-042807-2
|pages=2
|year=1997}}&lt;/ref&gt; This definition of the tasks in which machine learning is concerned offers a fundamentally [[operational definition]] rather than defining the field in cognitive terms. This follows [[Alan Turing]]'s proposal in his paper "[[Computing Machinery and Intelligence]]", in which the question "Can machines think?" is replaced with the question "Can machines do what we (as thinking entities) can do?".&lt;ref&gt;{{Citation |chapter-url=http://eprints.ecs.soton.ac.uk/12954/ |first=Stevan |last=Harnad |author-link=Stevan Harnad |year=2008 |chapter=The Annotation Game: On Turing (1950) on Computing, Machinery, and Intelligence |editor1-last=Epstein |editor1-first=Robert |editor2-last=Peters |editor2-first=Grace |title=The Turing Test Sourcebook: Philosophical and Methodological Issues in the Quest for the Thinking Computer |pages=23–66 |publisher=Kluwer |isbn= 9781402067082}}&lt;/ref&gt;

Modern day machine learning has two objectives, one is to classify data based on models which have been developed, the other purpose is to make predictions for future outcomes based on these models. A hypothetical algorithm specific to classifying data may use computer vision of moles coupled with supervised learning in order to train it to classify the cancerous moles. Where as, a machine learning algorithm for stock trading may inform the trader of future potential predictions.&lt;ref&gt;{{Cite web|date=2020-12-08|title=Introduction to AI Part 1|url=https://edzion.com/2020/12/09/introduction-to-ai-part-1/|access-date=2020-12-09|website=Edzion|language=en}}&lt;/ref&gt;

=== Artificial intelligence ===
[[File:Fig-X_All_ML_as_a_subfield_of_AI.jpg|thumb|Machine Learning as subfield of AI&lt;ref name="journalimcms.org"&gt;{{cite journal |title=AN EMPIRICAL SCIENCE RESEARCH ON BIOINFORMATICS IN MACHINE LEARNING – Journal |url=http://www.journalimcms.org/special_issue/an-empirical-science-research-on-bioinformatics-in-machine-learning/ |access-date=28 October 2020}}&lt;/ref&gt;]]
[[File:Fig-y_Part_of_ML_as_subfield_of_AI_or_AI_as_subfield_of_ML.jpg|thumb|Part of Machine Learning as subfield of AI or part of AI as subfield of Machine Learning&lt;ref&gt;{{cite web |title=rasbt/stat453-deep-learning-ss20 |url=https://github.com/rasbt/stat453-deep-learning-ss20/blob/master/L01-intro/L01-intro_slides.pdf |website=GitHub |language=en}}&lt;/ref&gt;
]]
As a scientific endeavor, machine learning grew out of the quest for artificial intelligence. In the early days of AI as an [[Discipline (academia)|academic discipline]], some researchers were interested in having machines learn from data. They attempted to approach the problem with various symbolic methods, as well as what was then termed "[[neural network]]s"; these were mostly [[perceptron]]s and [[ADALINE|other models]] that were later found to be reinventions of the [[generalized linear model]]s of statistics.&lt;ref&gt;{{cite citeseerx |last1=Sarle |first1=Warren |title=Neural Networks and statistical models |citeseerx=10.1.1.27.699 |year=1994}}&lt;/ref&gt; [[Probability theory|Probabilistic]] reasoning was also employed, especially in automated [[medical diagnosis]].&lt;ref name="aima"&gt;{{cite AIMA|edition=2}}&lt;/ref&gt;{{rp|488}}

However, an increasing emphasis on the [[GOFAI|logical, knowledge-based approach]] caused a rift between AI and machine learning. Probabilistic systems were plagued by theoretical and practical problems of data acquisition and representation.&lt;ref name="aima" /&gt;{{rp|488}} By 1980, [[expert system]]s had come to dominate AI, and statistics was out of favor.&lt;ref name="changing"&gt;{{Cite journal | last1 = Langley | first1 = Pat| title = The changing science of machine learning | doi = 10.1007/s10994-011-5242-y | journal = [[Machine Learning (journal)|Machine Learning]]| volume = 82 | issue = 3 | pages = 275–279 | year = 2011 | doi-access = free }}&lt;/ref&gt; Work on symbolic/knowledge-based learning did continue within AI, leading to [[inductive logic programming]], but the more statistical line of research was now outside the field of AI proper, in [[pattern recognition]] and [[information retrieval]].&lt;ref name="aima" /&gt;{{rp|708–710; 755}} Neural networks research had been abandoned by AI and [[computer science]] around the same time. This line, too, was continued outside the AI/CS field, as "[[connectionism]]", by researchers from other disciplines including [[John Hopfield|Hopfield]], [[David Rumelhart|Rumelhart]] and [[Geoff Hinton|Hinton]]. Their main success came in the mid-1980s with the reinvention of [[backpropagation]].&lt;ref name="aima" /&gt;{{rp|25}}

Machine learning (ML), reorganized as a separate field, started to flourish in the 1990s. The field changed its goal from achieving artificial intelligence to tackling solvable problems of a practical nature. It shifted focus away from the [[symbolic artificial intelligence|symbolic approaches]] it had inherited from AI, and toward methods and models borrowed from statistics and [[probability theory]].&lt;ref name="changing" /&gt;

As of 2020, many sources continue to assert that machine learning remains a subfield of AI.&lt;ref&gt;{{cite web |last1=Garbade |first1=Dr Michael J. |title=Clearing the Confusion: AI vs Machine Learning vs Deep Learning Differences |url=https://towardsdatascience.com/clearing-the-confusion-ai-vs-machine-learning-vs-deep-learning-differences-fce69b21d5eb |website=Medium |access-date=28 October 2020 |language=en |date=14 September 2018}}&lt;/ref&gt;&lt;ref&gt;{{cite news |title=AI vs. Machine Learning vs. Deep Learning vs. Neural Networks: What's the Difference? |url=https://www.ibm.com/cloud/blog/ai-vs-machine-learning-vs-deep-learning-vs-neural-networks |access-date=28 October 2020 |work=www.ibm.com |language=en-us}}&lt;/ref&gt;&lt;ref name="journalimcms.org"/&gt; The main disagreement is whether all of ML is part of AI, as this would mean that anyone using ML could claim they are using AI. Others have the view that not all of ML is part of AI&lt;ref&gt;{{cite web |title=Chapter 1: Introduction to Machine Learning and Deep Learning |url=https://sebastianraschka.com/blog/2020/intro-to-dl-ch01.html |website=Dr. Sebastian Raschka |access-date=28 October 2020 |date=5 August 2020}}&lt;/ref&gt;&lt;ref&gt;{{cite web |last1=August 2011 |first1=Dovel Technologies in |title=Not all Machine Learning is Artificial Intelligence |url=https://ctovision.com/not-all-machine-learning-is-artificial-intelligence/ |website=CTOvision.com |access-date=28 October 2020 |date=15 May 2018}}&lt;/ref&gt;&lt;ref&gt;{{cite web |title=AI Today Podcast #30: Interview with MIT Professor Luis Perez-Breva -- Contrary Perspectives on AI and ML |url=https://www.cognilytica.com/2018/03/28/ai-today-podcast-30-interview-with-mit-professor-luis-perez-breva-contrary-perspectives-on-ai-and-ml/ |website=Cognilytica |access-date=28 October 2020 |date=28 March 2018}}&lt;/ref&gt; where only an 'intelligent' subset of ML is part of AI.&lt;ref&gt;{{cite web |title=rasbt/stat453-deep-learning-ss20 |url=https://github.com/rasbt/stat453-deep-learning-ss20/blob/master/L01-intro/L01-intro_slides.pdf |website=GitHub |access-date=28 October 2020 |language=en}}&lt;/ref&gt;

The question to what is the difference between ML and AI is answered by [[Judea Pearl]] in ''The Book of Why''.&lt;ref&gt;{{cite book |last1=Pearl |first1=Judea |last2=Mackenzie |first2=Dana |title=The Book of Why: The New Science of Cause and Effect |publisher=Basic Books |isbn=9780465097609 |edition=2018 |url=https://www.basicbooks.com/titles/judea-pearl/the-book-of-why/9780465097609/ |access-date=28 October 2020}}&lt;/ref&gt; Accordingly ML learns and predicts based on passive observations, whereas AI implies an agent  interacting with the environment to learn and take actions that maximize its chance of successfully achieving its goals.{{refn|name="Definition of AI"|Definition of AI as the study of [[intelligent agents]]: * {{Harvtxt|Poole|Mackworth|Goebel|1998}}, which provides the version that is used in this article. These authors use the term "computational intelligence" as a synonym for artificial intelligence.{{sfn|Poole|Mackworth|Goebel|1998|loc=[http://people.cs.ubc.ca/~poole/ci/ch1.pdf p. 1]}} * {{Harvtxt|Russell|Norvig|2003}} (who prefer the term "rational agent") and write "The whole-agent view is now widely accepted in the field".{{sfn|Russell|Norvig|2003|p=55}} * {{Harvnb|Nilsson|1998}} &lt;!--These textbooks are the most widely used in academic AI.--&gt; * {{Harvnb|Legg|Hutter|2007}}}}

=== Data mining ===
Machine learning and [[data mining]] often employ the same methods and overlap significantly, but while machine learning focuses on prediction, based on ''known'' properties learned from the training data, [[data mining]] focuses on the [[discovery (observation)|discovery]] of (previously) ''unknown'' properties in the data (this is the analysis step of [[knowledge discovery]] in databases). Data mining uses many machine learning methods, but with different goals; on the other hand, machine learning also employs data mining methods as "unsupervised learning" or as a preprocessing step to improve learner accuracy. Much of the confusion between these two research communities (which do often have separate conferences and separate journals, [[ECML PKDD]] being a major exception) comes from the basic assumptions they work with: in machine learning, performance is usually evaluated with respect to the ability to ''reproduce known'' knowledge, while in knowledge discovery and data mining (KDD) the key task is the discovery of previously ''unknown'' knowledge. Evaluated with respect to known knowledge, an uninformed (unsupervised) method will easily be outperformed by other supervised methods, while in a typical KDD task, supervised methods cannot be used due to the unavailability of training data.

=== Optimization ===
Machine learning also has intimate ties to [[Mathematical optimization|optimization]]: many learning problems are formulated as minimization of some [[loss function]] on a training set of examples. Loss functions express the discrepancy between the predictions of the model being trained and the actual problem instances (for example, in classification, one wants to assign a label to instances, and models are trained to correctly predict the pre-assigned labels of a set of examples).&lt;ref&gt;{{cite encyclopedia |last1=Le Roux |first1=Nicolas |first2=Yoshua |last2=Bengio |first3=Andrew |last3=Fitzgibbon |title=Improving First and Second-Order Methods by Modeling Uncertainty |encyclopedia=Optimization for Machine Learning |year=2012 |page=404 |editor1-last=Sra |editor1-first=Suvrit |editor2-first=Sebastian |editor2-last=Nowozin |editor3-first=Stephen J. |editor3-last=Wright |publisher=MIT Press|url=https://books.google.com/books?id=JPQx7s2L1A8C&amp;q="Improving+First+and+Second-Order+Methods+by+Modeling+Uncertainty&amp;pg=PA403|isbn=9780262016469 }}&lt;/ref&gt;

=== Generalization ===
The difference between optimization and machine learning arises from the goal of generalization: while optimization algorithms can minimize the loss on a training set, machine learning is concerned with minimizing the loss on unseen samples. Characterizing the generalization of various learning algorithms is an active topic of current research, especially for [[deep learning]] algorithms.

=== Statistics ===
Machine learning and [[statistics]] are closely related fields in terms of methods, but distinct in their principal goal: statistics draws population [[Statistical inference|inferences]] from a [[Sample (statistics)|sample]], while machine learning finds generalizable predictive patterns.&lt;ref&gt;{{cite journal |first1=Danilo |last1=Bzdok |first2=Naomi |last2=Altman |author-link2=Naomi Altman |first3=Martin |last3=Krzywinski |title=Statistics versus Machine Learning |journal=[[Nature Methods]] |volume=15 |issue=4 |pages=233–234 |year=2018 |doi=10.1038/nmeth.4642 |pmid=30100822 |pmc=6082636 }}&lt;/ref&gt; According to [[Michael I. Jordan]], the ideas of machine learning, from methodological principles to theoretical tools, have had a long pre-history in statistics.&lt;ref name="mi jordan ama"&gt;{{cite web|url=https://www.reddit.com/r/MachineLearning/comments/2fxi6v/ama_michael_i_jordan/ckelmtt?context=3 |title=statistics and machine learning|publisher=reddit|date=2014-09-10|access-date=2014-10-01|author = Michael I. Jordan|author-link=Michael I. Jordan}}&lt;/ref&gt; He also suggested the term [[data science]] as a placeholder to call the overall field.&lt;ref name="mi jordan ama" /&gt;

[[Leo Breiman]] distinguished two statistical modeling paradigms: data model and algorithmic model,&lt;ref&gt;{{cite web|url=http://projecteuclid.org/download/pdf_1/euclid.ss/1009213726|title=Breiman: Statistical Modeling: The Two Cultures (with comments and a rejoinder by the author)|author=Cornell University Library|access-date=8 August 2015}}&lt;/ref&gt; wherein "algorithmic model" means more or less the machine learning algorithms like [[Random forest]].

Some statisticians have adopted methods from machine learning, leading to a combined field that they call ''statistical learning''.&lt;ref name="islr"&gt;{{cite book |author1=Gareth James |author2=Daniela Witten |author3=Trevor Hastie |author4=Robert Tibshirani |title=An Introduction to Statistical Learning |publisher=Springer |year=2013 |url=http://www-bcf.usc.edu/~gareth/ISL/ |page=vii}}&lt;/ref&gt;

== {{anchor|Generalization}} Theory ==
{{Main|Computational learning theory|Statistical learning theory}}
A core objective of a learner is to generalize from its experience.&lt;ref name="bishop2006"&gt;{{citation|first= C. M. |last= Bishop |author-link=Christopher M. Bishop |year=2006 |title=Pattern Recognition and Machine Learning |publisher=Springer |isbn=978-0-387-31073-2}}&lt;/ref&gt;&lt;ref&gt;{{Cite Mehryar Afshin Ameet 2012}}&lt;/ref&gt; Generalization in this context is the ability of a learning machine to perform accurately on new, unseen examples/tasks after having experienced a learning data set. The training examples come from some generally unknown probability distribution (considered representative of the space of occurrences) and the learner has to build a general model about this space that enables it to produce sufficiently accurate predictions in new cases.

The computational analysis of machine learning algorithms and their performance is a branch of [[theoretical computer science]] known as [[computational learning theory]]. Because training sets are finite and the future is uncertain, learning theory usually does not yield guarantees of the performance of algorithms. Instead, probabilistic bounds on the performance are quite common. The [[bias–variance decomposition]] is one way to quantify generalization [[Errors and residuals|error]].

For the best performance in the context of generalization, the complexity of the hypothesis should match the complexity of the function underlying the data. If the hypothesis is less complex than the function, then the model has under fitted the data. If the complexity of the model is increased in response, then the training error decreases. But if the hypothesis is too complex, then the model is subject to [[overfitting]] and generalization will be poorer.&lt;ref name="alpaydin"&gt;{{Cite book |author=Alpaydin, Ethem |title=Introduction to Machine Learning |url=https://archive.org/details/introductiontoma00alpa_0 |year=2010 |publisher=The MIT Press |place=London |isbn=978-0-262-01243-0 |access-date=4 February 2017 |url-access=registration }}&lt;/ref&gt;

In addition to performance bounds, learning theorists study the time complexity and feasibility of learning. In computational learning theory, a computation is considered feasible if it can be done in [[Time complexity#Polynomial time|polynomial time]]. There are two kinds of [[time complexity]] results. Positive results show that a certain class of functions can be learned in polynomial time. Negative results show that certain classes cannot be learned in polynomial time.

== Approaches ==

=== Types of learning algorithms ===

The types of machine learning algorithms differ in their approach, the type of data they input and output, and the type of task or problem that they are intended to solve.

==== Supervised learning ====
{{Main|Supervised learning}}
[[File:Svm max sep hyperplane with margin.png|thumb|A [[support vector machine]] is a supervised learning model that divides the data into regions separated by a [[linear classifier|linear boundary]]. Here, the linear boundary divides the black circles from the white.]]
Supervised learning algorithms build a mathematical model of a set of data that contains both the inputs and the desired outputs.&lt;ref&gt;{{cite book |last1=Russell |first1=Stuart J. |last2=Norvig |first2=Peter |title=Artificial Intelligence: A Modern Approach |date=2010 |publisher=Prentice Hall |isbn=9780136042594 |edition=Third|title-link=Artificial Intelligence: A Modern Approach }}&lt;/ref&gt; The data is known as [[training data]], and consists of a set of training examples. Each training example has one or more inputs and the desired output, also known as a supervisory signal.  In the mathematical model, each training example is represented by an [[array data structure|array]] or vector, sometimes called a feature vector, and the training data is represented by a [[Matrix (mathematics)|matrix]]. Through [[Mathematical optimization#Computational optimization techniques|iterative optimization]] of an [[Loss function|objective function]], supervised learning algorithms learn a function that can be used to predict the output associated with new inputs.&lt;ref&gt;{{cite book |last1=Mohri |first1=Mehryar |last2=Rostamizadeh |first2=Afshin |last3=Talwalkar |first3=Ameet |title=Foundations of Machine Learning |date=2012 |publisher=The MIT Press |isbn=9780262018258}}&lt;/ref&gt; An optimal function will allow the algorithm to correctly determine the output for inputs that were not a part of the training data. An algorithm that improves the accuracy of its outputs or predictions over time is said to have learned to perform that task.&lt;ref name="Mitchell-1997" /&gt;

Types of supervised learning algorithms include [[Active learning (machine learning)|active learning]], [[Statistical classification|classification]] and [[Regression analysis|regression]].&lt;ref&gt;{{cite book|last=Alpaydin|first=Ethem|title=Introduction to Machine Learning|date=2010|publisher=MIT Press|isbn=978-0-262-01243-0|page=9|url=https://books.google.com/books?id=7f5bBAAAQBAJ}}&lt;/ref&gt; Classification algorithms are used when the outputs are restricted to a limited set of values, and regression algorithms are used when the outputs may have any numerical value within a range. As an example, for a classification algorithm that filters emails, the input would be an incoming email, and the output would be the name of the folder in which to file the email.

[[Similarity learning]] is an area of supervised machine learning closely related to regression and classification, but the goal is to learn from examples using a similarity function that measures how similar or related two objects are. It has applications in [[ranking]], [[recommendation systems]], visual identity tracking, face verification, and speaker verification.

==== Unsupervised learning ====
{{Main|Unsupervised learning}}{{See also|Cluster analysis}}
Unsupervised learning algorithms take a set of data that contains only inputs, and find structure in the data, like grouping or clustering of data points. The algorithms, therefore, learn from test data that has not been labeled, classified or categorized. Instead of responding to feedback, unsupervised learning algorithms identify commonalities in the data and react based on the presence or absence of such commonalities in each new piece of data. A central application of unsupervised learning is in the field of [[density estimation]] in [[statistics]], such as finding the [[probability density function]].&lt;ref name="JordanBishop2004"&gt;{{cite book |first1=Michael I. |last1=Jordan |first2=Christopher M. |last2=Bishop |chapter=Neural Networks |editor=Allen B. Tucker |title=Computer Science Handbook, Second Edition (Section VII: Intelligent Systems) |location=Boca Raton, Florida |publisher=Chapman &amp; Hall/CRC Press LLC |year=2004 |isbn=978-1-58488-360-9 }}&lt;/ref&gt; Though unsupervised learning encompasses other domains involving summarizing and explaining data features.

Cluster analysis is the assignment of a set of observations into subsets (called ''clusters'') so that observations within the same cluster are similar according to one or more predesignated criteria, while observations drawn from different clusters are dissimilar. Different clustering techniques make different assumptions on the structure of the data, often defined by some ''similarity metric'' and evaluated, for example, by ''internal compactness'', or the similarity between members of the same cluster, and ''separation'', the difference between clusters. Other methods are based on ''estimated density'' and ''graph connectivity''.

==== Semi-supervised learning ====
{{Main|Semi-supervised learning}}

Semi-supervised learning falls between [[unsupervised learning]] (without any labeled training data) and [[supervised learning]] (with completely labeled training data). Some of the training examples are missing training labels,  yet many machine-learning researchers have found that unlabeled data, when used in conjunction with a small amount of labeled data, can produce a considerable improvement in learning accuracy.

In [[Weak supervision|weakly supervised learning]], the training labels are noisy, limited, or imprecise; however, these labels are often cheaper to obtain, resulting in larger effective training sets.&lt;ref&gt;{{Cite web|url=https://hazyresearch.github.io/snorkel/blog/ws_blog_post.html|title=Weak Supervision: The New Programming Paradigm for Machine Learning|author1=Alex Ratner |author2=Stephen Bach |author3=Paroma Varma |author4=Chris |others= referencing work by many other members of Hazy Research|website=hazyresearch.github.io|access-date=2019-06-06}}&lt;/ref&gt;

==== Reinforcement learning ====
{{Main|Reinforcement learning}}
Reinforcement learning is an area of machine learning concerned with how [[software agent]]s ought to take [[Action selection|actions]] in an environment so as to maximize some notion of cumulative reward. Due to its generality, the field is studied in many other disciplines, such as [[game theory]], [[control theory]], [[operations research]], [[information theory]], [[simulation-based optimization]], [[multi-agent system]]s, [[swarm intelligence]], [[statistics]] and [[genetic algorithm]]s. In machine learning, the environment is typically represented as a [[Markov decision process]] (MDP). Many reinforcement learning algorithms use [[dynamic programming]] techniques.&lt;ref&gt;{{Cite book|title=Reinforcement learning and markov decision processes|author1=van Otterlo, M.|author2=Wiering, M.|journal=Reinforcement Learning |volume=12|pages=3–42 |year=2012 |doi=10.1007/978-3-642-27645-3_1|series=Adaptation, Learning, and Optimization|isbn=978-3-642-27644-6}}&lt;/ref&gt; Reinforcement learning algorithms do not assume knowledge of an exact mathematical model of the MDP, and are used when exact models are infeasible. Reinforcement learning algorithms are used in autonomous vehicles or in learning to play a game against a human opponent.

==== Self learning ====

Self-learning as a machine learning paradigm was introduced in 1982 along with a neural network capable of self-learning named ''crossbar adaptive array'' (CAA).&lt;ref&gt;Bozinovski, S. (1982). "A self-learning system using secondary reinforcement". In Trappl, Robert (ed.). Cybernetics and Systems Research: Proceedings of the Sixth European Meeting on Cybernetics and Systems Research. North Holland. pp. 397–402. {{ISBN|978-0-444-86488-8}}.&lt;/ref&gt; It is a learning with no external rewards and no external teacher advice. The CAA self-learning algorithm computes, in a crossbar fashion, both decisions about actions and emotions (feelings) about consequence situations. The system is driven by the interaction between cognition and emotion.&lt;ref&gt;Bozinovski, Stevo (2014) "Modeling mechanisms of cognition-emotion interaction in artificial neural networks, since 1981." Procedia Computer Science p. 255-263&lt;/ref&gt;
The self-learning algorithm updates a memory matrix W =||w(a,s)|| such that in each iteration executes the following machine learning routine: 
  In situation s perform an action a;
  Receive consequence situation s’;
  Compute emotion of being in consequence situation v(s’);
  Update crossbar memory  w’(a,s) = w(a,s) + v(s’).

It is a system with only one input, situation s, and only one output, action (or behavior) a. There is neither a separate reinforcement input nor an advice input from the environment. The backpropagated value (secondary reinforcement) is the emotion toward the consequence situation. The CAA exists in two environments, one is the behavioral environment where it behaves, and the other is the genetic environment, wherefrom it initially and only once receives initial emotions about situations to be encountered in the behavioral environment. After receiving the genome (species) vector from the genetic environment, the CAA learns a goal-seeking behavior, in an environment that contains both desirable and undesirable situations.&lt;ref&gt;Bozinovski, S. (2001) "Self-learning agents: A connectionist theory of emotion based on crossbar value judgment." Cybernetics and Systems 32(6) 637-667.&lt;/ref&gt;

==== Feature learning ====
{{Main|Feature learning}}

Several learning algorithms aim at discovering better representations of the inputs provided during training.&lt;ref name="pami"&gt;{{cite journal |author1=Y. Bengio |author2=A. Courville |author3=P. Vincent |title=Representation Learning: A Review and New Perspectives |journal= IEEE Transactions on Pattern Analysis and Machine Intelligence|year=2013|doi=10.1109/tpami.2013.50 |pmid=23787338 |volume=35 |issue=8 |pages=1798–1828|arxiv=1206.5538 |s2cid=393948 }}&lt;/ref&gt; Classic examples include [[principal components analysis]] and cluster analysis. Feature learning algorithms, also called representation learning algorithms, often attempt to preserve the information in their input but also transform it in a way that makes it useful, often as a pre-processing step before performing classification or predictions. This technique allows reconstruction of the inputs coming from the unknown data-generating distribution, while not being necessarily faithful to configurations that are implausible under that distribution. This replaces manual [[feature engineering]], and allows a machine to both learn the features and use them to perform a specific task.

Feature learning can be either supervised or unsupervised. In supervised feature learning, features are learned using labeled input data. Examples include [[artificial neural network]]s, [[multilayer perceptron]]s, and supervised [[dictionary learning]]. In unsupervised feature learning, features are learned with unlabeled input data.  Examples include dictionary learning, [[independent component analysis]], [[autoencoder]]s, [[matrix decomposition|matrix factorization]]&lt;ref&gt;{{cite conference |author1=Nathan Srebro |author2=Jason D. M. Rennie |author3=Tommi S. Jaakkola |title=Maximum-Margin Matrix Factorization |conference=[[Conference on Neural Information Processing Systems|NIPS]] |year=2004}}&lt;/ref&gt; and various forms of [[Cluster analysis|clustering]].&lt;ref name="coates2011"&gt;{{cite conference
|last1 = Coates
|first1 = Adam
|last2 = Lee
|first2 = Honglak
|last3 = Ng
|first3 = Andrew Y.
|title = An analysis of single-layer networks in unsupervised feature learning
|conference = Int'l Conf. on AI and Statistics (AISTATS)
|year = 2011
|url = http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2011_CoatesNL11.pdf
|access-date = 2018-11-25
|archive-url = https://web.archive.org/web/20170813153615/http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2011_CoatesNL11.pdf
|archive-date = 2017-08-13
|url-status = dead
}}&lt;/ref&gt;&lt;ref&gt;{{cite conference |last1 = Csurka |first1 = Gabriella|last2 = Dance |first2 = Christopher C.|last3 = Fan |first3 = Lixin|last4 = Willamowski |first4 = Jutta|last5 = Bray |first5 = Cédric|title = Visual categorization with bags of keypoints|conference = ECCV Workshop on Statistical Learning in Computer Vision|year = 2004|url = https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/csurka-eccv-04.pdf}}&lt;/ref&gt;&lt;ref name="jurafsky"&gt;{{cite book |title=Speech and Language Processing |author1=Daniel Jurafsky |author2=James H. Martin |publisher=Pearson Education International |year=2009 |pages=145–146}}&lt;/ref&gt;

[[Manifold learning]] algorithms attempt to do so under the constraint that the learned representation is low-dimensional. [[Sparse coding]] algorithms attempt to do so under the constraint that the learned representation is sparse, meaning that the mathematical model has many zeros. [[Multilinear subspace learning]] algorithms aim to learn low-dimensional representations directly from [[tensor]] representations for multidimensional data, without reshaping them into higher-dimensional vectors.&lt;ref&gt;{{cite journal |first1=Haiping |last1=Lu |first2=K.N. |last2=Plataniotis |first3=A.N. |last3=Venetsanopoulos |url=http://www.dsp.utoronto.ca/~haiping/Publication/SurveyMSL_PR2011.pdf |title=A Survey of Multilinear Subspace Learning for Tensor Data |journal=Pattern Recognition |volume=44 |number=7 |pages=1540–1551 |year=2011 |doi=10.1016/j.patcog.2011.01.004}}&lt;/ref&gt; [[Deep learning]] algorithms discover multiple levels of representation, or a hierarchy of features, with higher-level, more abstract features defined in terms of (or generating) lower-level features. It has been argued that an intelligent machine is one that learns a representation that disentangles the underlying factors of variation that explain the observed data.&lt;ref&gt;{{cite book | title = Learning Deep Architectures for AI | author = Yoshua Bengio | publisher = Now Publishers Inc. | year = 2009 | isbn = 978-1-60198-294-0 | pages = 1–3 | url = https://books.google.com/books?id=cq5ewg7FniMC&amp;pg=PA3| author-link = Yoshua Bengio }}&lt;/ref&gt;

Feature learning is motivated by the fact that machine learning tasks such as classification often require input that is mathematically and computationally convenient to process. However, real-world data such as images, video, and sensory data has not yielded to attempts to algorithmically define specific features. An alternative is to discover such features or representations thorough examination, without relying on explicit algorithms.

==== Sparse dictionary learning ====
{{Main|Sparse dictionary learning}}
Sparse dictionary learning is a feature learning method where a training example is represented as a linear combination of [[basis function]]s, and is assumed to be a [[sparse matrix]]. The method is [[strongly NP-hard]] and difficult to solve approximately.&lt;ref&gt;{{cite journal |first=A. M. |last=Tillmann |title=On the Computational Intractability of Exact and Approximate Dictionary Learning |journal=IEEE Signal Processing Letters |volume=22 |issue=1 |year=2015 |pages=45–49 |doi=10.1109/LSP.2014.2345761|bibcode=2015ISPL...22...45T |arxiv=1405.6664 |s2cid=13342762 }}&lt;/ref&gt; A popular [[heuristic]] method for sparse dictionary learning is the [[K-SVD]] algorithm. Sparse dictionary learning has been applied in several contexts. In classification, the problem is to determine the class to which a previously unseen training example belongs. For a dictionary where each class has already been built, a new training example is associated with the class that is best sparsely represented by the corresponding dictionary. Sparse dictionary learning has also been applied in [[image de-noising]]. The key idea is that a clean image patch can be sparsely represented by an image dictionary, but the noise cannot.&lt;ref&gt;Aharon, M, M Elad, and A Bruckstein. 2006. "[http://sites.fas.harvard.edu/~cs278/papers/ksvd.pdf K-SVD: An Algorithm for Designing Overcomplete Dictionaries for Sparse Representation]." Signal Processing, IEEE Transactions on 54 (11): 4311–4322&lt;/ref&gt;

==== Anomaly detection ====
{{Main|Anomaly detection}}
In [[data mining]], anomaly detection, also known as outlier detection, is the identification of rare items, events or observations which raise suspicions by differing significantly from the majority of the data.&lt;ref name=":0"&gt;{{Citation|last1=Zimek|first1=Arthur|title=Outlier Detection|date=2017|encyclopedia=Encyclopedia of Database Systems|pages=1–5|publisher=Springer New York|language=en|doi=10.1007/978-1-4899-7993-3_80719-1|isbn=9781489979933|last2=Schubert|first2=Erich}}&lt;/ref&gt; Typically, the anomalous items represent an issue such as [[bank fraud]], a structural defect, medical problems or errors in a text. Anomalies are referred to as [[outlier]]s, novelties, noise, deviations and exceptions.&lt;ref&gt;{{cite journal | last1 = Hodge | first1 = V. J. | last2 = Austin | first2 = J. | doi = 10.1007/s10462-004-4304-y | title = A Survey of Outlier Detection Methodologies | journal = Artificial Intelligence Review| volume = 22 | issue = 2 | pages = 85–126 | year = 2004 | url = http://eprints.whiterose.ac.uk/767/1/hodgevj4.pdf| citeseerx = 10.1.1.318.4023 | s2cid = 59941878 }}&lt;/ref&gt;

In particular, in the context of abuse and network intrusion detection, the interesting objects are often not rare objects, but unexpected bursts of inactivity. This pattern does not adhere to the common statistical definition of an outlier as a rare object, and many outlier detection methods (in particular, unsupervised algorithms) will fail on such data unless it has been aggregated appropriately. Instead, a cluster analysis algorithm may be able to detect the micro-clusters formed by these patterns.&lt;ref&gt;{{cite journal| first1=Paul | last1=Dokas | first2=Levent |last2=Ertoz |first3=Vipin |last3=Kumar |first4=Aleksandar |last4=Lazarevic |first5=Jaideep |last5=Srivastava |first6=Pang-Ning |last6=Tan | title=Data mining for network intrusion detection | year=2002 | journal=Proceedings NSF Workshop on Next Generation Data Mining | url=http://www.csee.umbc.edu/~kolari1/Mining/ngdm/dokas.pdf}}&lt;/ref&gt;

Three broad categories of anomaly detection techniques exist.&lt;ref name="ChandolaSurvey"&gt;{{cite journal |last1=Chandola |first1=V. |last2=Banerjee |first2=A. |last3=Kumar |first3=V. |s2cid=207172599 |year=2009 |title=Anomaly detection: A survey|journal=[[ACM Computing Surveys]]|volume=41|issue=3|pages=1–58|doi=10.1145/1541880.1541882}}&lt;/ref&gt; Unsupervised anomaly detection techniques detect anomalies in an unlabeled test data set under the assumption that the majority of the instances in the data set are normal, by looking for instances that seem to fit least to the remainder of the data set. Supervised anomaly detection techniques require a data set that has been labeled as "normal" and "abnormal" and involves training a classifier (the key difference to many other statistical classification problems is the inherently unbalanced nature of outlier detection). Semi-supervised anomaly detection techniques construct a model representing normal behavior from a given normal training data set and then test the likelihood of a test instance to be generated by the model.

====Robot learning====
In [[developmental robotics]], [[robot learning]] algorithms generate their own sequences of learning experiences, also known as a curriculum, to cumulatively acquire new skills through self-guided exploration and social interaction with humans. These robots use guidance mechanisms such as active learning, maturation, [[Motor coordination#Muscle synergies|motor synergies]] and imitation.

==== Association rules ====
{{Main|Association rule learning}}{{See also|Inductive logic programming}}
Association rule learning is a [[rule-based machine learning]] method for discovering relationships between variables in large databases. It is intended to identify strong rules discovered in databases using some measure of "interestingness".&lt;ref name="piatetsky"&gt;Piatetsky-Shapiro, Gregory (1991), ''Discovery, analysis, and presentation of strong rules'', in Piatetsky-Shapiro, Gregory; and Frawley, William J.; eds., ''Knowledge Discovery in Databases'', AAAI/MIT Press, Cambridge, MA.&lt;/ref&gt;

Rule-based machine learning is a general term for any machine learning method that identifies, learns, or evolves "rules" to store, manipulate or apply knowledge. The defining characteristic of a rule-based machine learning algorithm is the identification and utilization of a set of relational rules that collectively represent the knowledge captured by the system. This is in contrast to other machine learning algorithms that commonly identify a singular model that can be universally applied to any instance in order to make a prediction.&lt;ref&gt;{{Cite journal|last1=Bassel|first1=George W.|last2=Glaab|first2=Enrico|last3=Marquez|first3=Julietta|last4=Holdsworth|first4=Michael J.|last5=Bacardit|first5=Jaume|date=2011-09-01|title=Functional Network Construction in Arabidopsis Using Rule-Based Machine Learning on Large-Scale Data Sets|journal=The Plant Cell|language=en|volume=23|issue=9|pages=3101–3116|doi=10.1105/tpc.111.088153|issn=1532-298X|pmc=3203449|pmid=21896882}}&lt;/ref&gt; Rule-based machine learning approaches include [[learning classifier system]]s, association rule learning, and [[artificial immune system]]s.

Based on the concept of strong rules, [[Rakesh Agrawal (computer scientist)|Rakesh Agrawal]], [[Tomasz Imieliński]] and Arun Swami introduced association rules for discovering regularities between products in large-scale transaction data recorded by [[point-of-sale]] (POS) systems in supermarkets.&lt;ref name="mining"&gt;{{Cite book | last1 = Agrawal | first1 = R. | last2 = Imieliński | first2 = T. | last3 = Swami | first3 = A. | doi = 10.1145/170035.170072 | chapter = Mining association rules between sets of items in large databases | title = Proceedings of the 1993 ACM SIGMOD international conference on Management of data - SIGMOD '93 | pages = 207 | year = 1993 | isbn = 978-0897915922 | citeseerx = 10.1.1.40.6984 | s2cid = 490415 }}&lt;/ref&gt; For example, the rule &lt;math&gt;\{\mathrm{onions, potatoes}\} \Rightarrow \{\mathrm{burger}\}&lt;/math&gt; found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat. Such information can be used as the basis for decisions about marketing activities such as promotional [[pricing]] or [[product placement]]s. In addition to [[market basket analysis]], association rules are employed today in application areas including [[Web usage mining]], [[intrusion detection]], [[continuous production]], and [[bioinformatics]]. In contrast with [[sequence mining]], association rule learning typically does not consider the order of items either within a transaction or across transactions.

Learning classifier systems (LCS) are a family of rule-based machine learning algorithms that combine a discovery component, typically a [[genetic algorithm]], with a learning component, performing either [[supervised learning]], [[reinforcement learning]], or [[unsupervised learning]]. They seek to identify a set of context-dependent rules that collectively store and apply knowledge in a [[piecewise]] manner in order to make predictions.&lt;ref&gt;{{Cite journal|last1=Urbanowicz|first1=Ryan J.|last2=Moore|first2=Jason H.|date=2009-09-22|title=Learning Classifier Systems: A Complete Introduction, Review, and Roadmap|journal=Journal of Artificial Evolution and Applications|language=en|volume=2009|pages=1–25|doi=10.1155/2009/736398|issn=1687-6229|doi-access=free}}&lt;/ref&gt;

Inductive logic programming (ILP) is an approach to rule-learning using [[logic programming]] as a uniform representation for input examples, background knowledge, and hypotheses. Given an encoding of the known background knowledge and a set of examples represented as a logical database of facts, an ILP system will derive a hypothesized logic program that [[Entailment|entails]] all positive and no negative examples. [[Inductive programming]] is a related field that considers any kind of programming language for representing hypotheses (and not only logic programming), such as [[Functional programming|functional programs]].

Inductive logic programming is particularly useful in [[bioinformatics]] and [[natural language processing]]. [[Gordon Plotkin]] and [[Ehud Shapiro]] laid the initial theoretical foundation for inductive machine learning in a logical setting.&lt;ref&gt;Plotkin G.D. [https://www.era.lib.ed.ac.uk/bitstream/handle/1842/6656/Plotkin1972.pdf;sequence=1 Automatic Methods of Inductive Inference], PhD thesis, University of Edinburgh, 1970.&lt;/ref&gt;&lt;ref&gt;Shapiro, Ehud Y. [http://ftp.cs.yale.edu/publications/techreports/tr192.pdf Inductive inference of theories from facts], Research Report 192, Yale University, Department of Computer Science, 1981. Reprinted in J.-L. Lassez, G. Plotkin (Eds.), Computational Logic, The MIT Press, Cambridge, MA, 1991, pp. 199–254.&lt;/ref&gt;&lt;ref&gt;Shapiro, Ehud Y. (1983). ''Algorithmic program debugging''. Cambridge, Mass: MIT Press. {{ISBN|0-262-19218-7}}&lt;/ref&gt; Shapiro built their first implementation (Model Inference System) in 1981: a Prolog program that inductively inferred logic programs from positive and negative examples.&lt;ref&gt;Shapiro, Ehud Y. "[http://dl.acm.org/citation.cfm?id=1623364 The model inference system]." Proceedings of the 7th international joint conference on Artificial intelligence-Volume 2. Morgan Kaufmann Publishers Inc., 1981.&lt;/ref&gt; The term ''inductive'' here refers to [[Inductive reasoning|philosophical]] induction, suggesting a theory to explain observed facts, rather than [[mathematical induction]], proving a property for all members of a well-ordered set.

=== Models ===
Performing machine learning involves creating a [[Statistical model|model]], which is trained on some training data and then can process additional data to make predictions. Various types of models have been used and researched for machine learning systems.

==== Artificial neural networks ====
{{Main|Artificial neural network}}{{See also|Deep learning}}
[[File:Colored neural network.svg|thumb|300px|An artificial neural network is an interconnected group of nodes, akin to the vast network of [[neuron]]s in a [[brain]]. Here, each circular node represents an [[artificial neuron]] and an arrow represents a connection from the output of one artificial neuron to the input of another.]]
Artificial neural networks (ANNs), or [[Connectionism|connectionist]] systems, are computing systems vaguely inspired by the [[biological neural network]]s that constitute animal [[brain]]s. Such systems "learn" to perform tasks by considering examples, generally without being programmed with any task-specific rules.

An ANN is a model based on a collection of connected units or nodes called "[[artificial neuron]]s", which loosely model the [[neuron]]s in a biological [[brain]]. Each connection, like the [[synapse]]s in a biological [[brain]], can transmit information, a "signal", from one artificial neuron to another. An artificial neuron that receives a signal can process it and then signal additional artificial neurons connected to it. In common ANN implementations, the signal at a connection between artificial neurons is a [[real number]], and the output of each artificial neuron is computed by some non-linear function of the sum of its inputs. The connections between artificial neurons are called "edges". Artificial neurons and edges typically have a [[weight (mathematics)|weight]] that adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Artificial neurons may have a threshold such that the signal is only sent if the aggregate signal crosses that threshold. Typically, artificial neurons are aggregated into layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first layer (the input layer) to the last layer (the output layer), possibly after traversing the layers multiple times.

The original goal of the ANN approach was to solve problems in the same way that a [[human brain]] would. However, over time, attention moved to performing specific tasks, leading to deviations from [[biology]]. Artificial neural networks have been used on a variety of tasks, including [[computer vision]], [[speech recognition]], [[machine translation]], [[social network]] filtering, [[general game playing|playing board and video games]] and [[medical diagnosis]].

[[Deep learning]] consists of multiple hidden layers in an artificial neural network. This approach tries to model the way the human brain processes light and sound into vision and hearing. Some successful applications of deep learning are [[computer vision]] and [[speech recognition]].&lt;ref&gt;Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng. "[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.149.802&amp;rep=rep1&amp;type=pdf Convolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations]" Proceedings of the 26th Annual International Conference on Machine Learning, 2009.&lt;/ref&gt;

==== Decision trees ====
{{Main|Decision tree learning}}
Decision tree learning uses a [[decision tree]] as a [[Predictive modelling|predictive model]] to go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves). It is one of the predictive modeling approaches used in statistics, data mining, and machine learning. Tree models where the target variable can take a discrete set of values are called classification trees; in these tree structures, [[leaf node|leaves]] represent class labels and branches represent [[Logical conjunction|conjunction]]s of features that lead to those class labels. Decision trees where the target variable can take continuous values (typically [[real numbers]]) are called regression trees. In decision analysis, a decision tree can be used to visually and explicitly represent decisions and [[decision making]]. In data mining, a decision tree describes data, but the resulting classification tree can be an input for decision making.

==== Support vector machines ====
{{Main|Support vector machines}}
Support vector machines (SVMs), also known as support vector networks, are a set of related [[supervised learning]] methods used for classification and regression. Given a set of training examples, each marked as belonging to one of two categories, an SVM training algorithm builds a model that predicts whether a new example falls into one category or the other.&lt;ref name="CorinnaCortes"&gt;{{Cite journal |last1=Cortes |first1=Corinna |author-link1=Corinna Cortes |last2=Vapnik |first2=Vladimir N. |year=1995 |title=Support-vector networks |journal=[[Machine Learning (journal)|Machine Learning]] |volume=20 |issue=3 |pages=273–297 |doi=10.1007/BF00994018 |doi-access=free }}&lt;/ref&gt;  An SVM training algorithm is a non-[[probabilistic classification|probabilistic]], [[binary classifier|binary]], [[linear classifier]], although methods such as [[Platt scaling]] exist to use SVM in a probabilistic classification setting. In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the [[kernel trick]], implicitly mapping their inputs into high-dimensional feature spaces.

[[Image:Linear regression.svg|thumb|upright=1.3|Illustration of linear regression on a data set.]]

==== Regression analysis ====
{{Main|Regression analysis}}
Regression analysis encompasses a large variety of statistical methods to estimate the relationship between input variables and their associated features. Its most common form is [[linear regression]], where a single line is drawn to best fit the given data according to a mathematical criterion such as [[ordinary least squares]]. The latter is often extended by [[regularization (mathematics)]] methods to mitigate overfitting and bias, as in [[ridge regression]]. When dealing with non-linear problems, go-to models include [[polynomial regression]] (for example, used for trendline fitting in Microsoft Excel&lt;ref&gt;{{cite web|last1=Stevenson|first1=Christopher|title=Tutorial: Polynomial Regression in Excel|url=https://facultystaff.richmond.edu/~cstevens/301/Excel4.html|website=facultystaff.richmond.edu|access-date=22 January 2017}}&lt;/ref&gt;), [[logistic regression]] (often used in [[statistical classification]]) or even [[kernel regression]], which introduces non-linearity by taking advantage of the [[kernel trick]] to implicitly map input variables to higher-dimensional space.

==== Bayesian networks ====
{{Main|Bayesian network}}
[[Image:SimpleBayesNetNodes.svg|thumb|right|A simple Bayesian network. Rain influences whether the sprinkler is activated, and both rain and the sprinkler influence whether the grass is wet.]]

A Bayesian network, belief network, or directed acyclic graphical model is a probabilistic [[graphical model]] that represents a set of [[random variables]] and their [[conditional independence]] with a [[directed acyclic graph]] (DAG). For example, a Bayesian network could represent the probabilistic relationships between diseases and symptoms. Given symptoms, the network can be used to compute the probabilities of the presence of various diseases. Efficient algorithms exist that perform [[inference]] and learning. Bayesian networks that model sequences of variables, like [[speech recognition|speech signals]] or [[peptide sequence|protein sequences]], are called [[dynamic Bayesian network]]s. Generalizations of Bayesian networks that can represent and solve decision problems under uncertainty are called [[influence diagram]]s.

==== Genetic algorithms ====
{{Main|Genetic algorithm}}
A genetic algorithm (GA) is a [[search algorithm]] and [[heuristic (computer science)|heuristic]] technique that mimics the process of [[natural selection]], using methods such as [[Mutation (genetic algorithm)|mutation]] and [[Crossover (genetic algorithm)|crossover]] to generate new [[Chromosome (genetic algorithm)|genotype]]s in the hope of finding good solutions to a given problem. In machine learning, genetic algorithms were used in the 1980s and 1990s.&lt;ref&gt;{{cite journal |last1=Goldberg |first1=David E. |first2=John H. |last2=Holland |title=Genetic algorithms and machine learning |journal=[[Machine Learning (journal)|Machine Learning]] |volume=3 |issue=2 |year=1988 |pages=95–99 |doi=10.1007/bf00113892|s2cid=35506513 |url=https://deepblue.lib.umich.edu/bitstream/2027.42/46947/1/10994_2005_Article_422926.pdf }}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |title=Machine Learning, Neural and Statistical Classification |journal=Ellis Horwood Series in Artificial Intelligence |first1=D. |last1=Michie |first2=D. J. |last2=Spiegelhalter |first3=C. C. |last3=Taylor |year=1994 |bibcode=1994mlns.book.....M }}&lt;/ref&gt; Conversely, machine learning techniques have been used to improve the performance of genetic and [[evolutionary algorithm]]s.&lt;ref&gt;{{cite journal |last1=Zhang |first1=Jun |last2=Zhan |first2=Zhi-hui |last3=Lin |first3=Ying |last4=Chen |first4=Ni |last5=Gong |first5=Yue-jiao |last6=Zhong |first6=Jing-hui |last7=Chung |first7=Henry S.H. |last8=Li |first8=Yun |last9=Shi |first9=Yu-hui |title=Evolutionary Computation Meets Machine Learning: A Survey |journal=Computational Intelligence Magazine |year=2011 |volume=6 |issue=4 |pages=68–75 |doi=10.1109/mci.2011.942584|s2cid=6760276 }}&lt;/ref&gt;

=== Training models ===
Usually, machine learning models require a lot of data in order for them to perform well. Usually, when training a machine learning model, one needs to collect a large, representative sample of data from a training set. Data from the training set can be as varied as a corpus of text, a collection of images, and data collected from individual users of a service. [[Overfitting]] is something to watch out for when training a machine learning model. Trained models derived from biased data can result in skewed or undesired predictions. [[Algorithmic bias]] is a potential result from data not fully prepared for training.

==== Federated learning ====
{{Main|Federated learning}}
Federated learning is an adapted form of [[distributed artificial intelligence]] to training machine learning models that decentralizes the training process, allowing for users' privacy to be maintained by not needing to send their data to a centralized server. This also increases efficiency by decentralizing the training process to many devices. For example, [[Gboard]] uses federated machine learning to train search query prediction models on users' mobile phones without having to send individual searches back to [[Google]].&lt;ref&gt;{{Cite web|url=http://ai.googleblog.com/2017/04/federated-learning-collaborative.html|title=Federated Learning: Collaborative Machine Learning without Centralized Training Data|website=Google AI Blog|language=en|access-date=2019-06-08}}&lt;/ref&gt;

== Applications ==
There are many applications for machine learning, including:
{{cols|colwidth=21em}}
* [[Precision agriculture|Agriculture]]
* [[Computational anatomy|Anatomy]]
* [[Adaptive website]]s
* [[Affective computing]]
* [[Banking]]
* [[Bioinformatics]]
* [[Brain–machine interface]]s
* [[Cheminformatics]]
* [[Citizen science]]
* [[Network simulation|Computer networks]]
* [[Computer vision]]
* [[Credit-card fraud]] detection
* [[Data quality]]
* [[DNA sequence]] classification
* [[Computational economics|Economics]]
* [[Financial market]] analysis&lt;ref&gt;Machine learning is included in the [[Chartered Financial Analyst (CFA)#Curriculum|CFA Curriculum]] (discussion is top down); see: [https://www.cfainstitute.org/-/media/documents/study-session/2020-l2-ss3.ashx Kathleen DeRose and Christophe Le Lanno (2020). "Machine Learning"].&lt;/ref&gt;
* [[General game playing]]
* [[Handwriting recognition]]
* [[Information retrieval]]
* [[Insurance]]
* [[Internet fraud]] detection
* [[Computational linguistics|Linguistics]]
* [[Machine learning control]]
* [[Machine perception]]
* [[Machine translation]]
* [[Marketing]]
* [[Automated medical diagnosis|Medical diagnosis]]
* [[Natural language processing]]
* [[Natural language understanding]]
* [[Online advertising]]
* [[Mathematical optimization|Optimization]]
* [[Recommender system]]s
* [[Robot locomotion]]
* [[Search engines]]
* [[Sentiment analysis]]
* [[Sequence mining]]
* [[Software engineering]]
* [[Speech recognition]]
* [[Structural health monitoring]]
* [[Syntactic pattern recognition]]
* [[Telecommunication]]
* [[Automated theorem proving|Theorem proving]]
* [[Time series|Time series forecasting]]
* [[User behavior analytics]]
{{colend}}

In 2006, the media-services provider [[Netflix]] held the first "[[Netflix Prize]]" competition to find a program to better predict user preferences and improve the accuracy of its existing Cinematch movie recommendation algorithm by at least 10%.  A joint team made up of researchers from [[AT&amp;T Labs]]-Research in collaboration with the teams Big Chaos and Pragmatic Theory built an [[Ensemble Averaging|ensemble model]] to win the Grand Prize in 2009 for $1&amp;nbsp;million.&lt;ref&gt;[https://web.archive.org/web/20151110062742/http://www2.research.att.com/~volinsky/netflix/ "BelKor Home Page"] research.att.com&lt;/ref&gt; Shortly after the prize was awarded, Netflix realized that viewers' ratings were not the best indicators of their viewing patterns ("everything is a recommendation") and they changed their recommendation engine accordingly.&lt;ref&gt;{{cite web|url=http://techblog.netflix.com/2012/04/netflix-recommendations-beyond-5-stars.html|title=The Netflix Tech Blog: Netflix Recommendations: Beyond the 5 stars (Part 1)|access-date=8 August 2015|date=2012-04-06|archive-url=https://web.archive.org/web/20160531002916/http://techblog.netflix.com/2012/04/netflix-recommendations-beyond-5-stars.html|archive-date=31 May 2016|url-status=dead}}&lt;/ref&gt; In 2010 The Wall Street Journal wrote about the firm Rebellion Research and their use of machine learning to predict the financial crisis.&lt;ref&gt;{{cite web|url=https://www.wsj.com/articles/SB10001424052748703834604575365310813948080|title=Letting the Machines Decide|author=Scott Patterson|date=13 July 2010|publisher=[[The Wall Street Journal]]|access-date=24 June 2018}}&lt;/ref&gt; In 2012, co-founder of [[Sun Microsystems]], [[Vinod Khosla]], predicted that 80% of medical doctors' jobs would be lost in the next two decades to automated machine learning medical diagnostic software.&lt;ref&gt;{{cite web|url=https://techcrunch.com/2012/01/10/doctors-or-algorithms/|author=Vinod Khosla|publisher=Tech Crunch|title=Do We Need Doctors or Algorithms?|date=January 10, 2012}}&lt;/ref&gt; In 2014, it was reported that a machine learning algorithm had been applied in the field of art history to study fine art paintings and that it may have revealed previously unrecognized influences among artists.&lt;ref&gt;[https://medium.com/the-physics-arxiv-blog/when-a-machine-learning-algorithm-studied-fine-art-paintings-it-saw-things-art-historians-had-never-b8e4e7bf7d3e When A Machine Learning Algorithm Studied Fine Art Paintings, It Saw Things Art Historians Had Never Noticed], ''The Physics at [[ArXiv]] blog''&lt;/ref&gt; In 2019 [[Springer Nature]] published the first research book created using machine learning.&lt;ref&gt;{{Cite web|url=https://www.theverge.com/2019/4/10/18304558/ai-writing-academic-research-book-springer-nature-artificial-intelligence|title=The first AI-generated textbook shows what robot writers are actually good at|last=Vincent|first=James|date=2019-04-10|website=The Verge|access-date=2019-05-05}}&lt;/ref&gt;

== Limitations ==
Although machine learning has been transformative in some fields, machine-learning programs often fail to deliver expected results.&lt;ref&gt;{{Cite news|url=https://www.bloomberg.com/news/articles/2016-11-10/why-machine-learning-models-often-fail-to-learn-quicktake-q-a|title=Why Machine Learning Models Often Fail to Learn: QuickTake Q&amp;A|date=2016-11-10|work=Bloomberg.com|access-date=2017-04-10|archive-url=https://web.archive.org/web/20170320225010/https://www.bloomberg.com/news/articles/2016-11-10/why-machine-learning-models-often-fail-to-learn-quicktake-q-a|archive-date=2017-03-20}}&lt;/ref&gt;&lt;ref&gt;{{Cite news|url=https://hbr.org/2017/04/the-first-wave-of-corporate-ai-is-doomed-to-fail|title=The First Wave of Corporate AI Is Doomed to Fail|date=2017-04-18|work=Harvard Business Review|access-date=2018-08-20}}&lt;/ref&gt;&lt;ref&gt;{{Cite news|url=https://venturebeat.com/2016/09/17/why-the-a-i-euphoria-is-doomed-to-fail/|title=Why the A.I. euphoria is doomed to fail|date=2016-09-18|work=VentureBeat|access-date=2018-08-20|language=en-US}}&lt;/ref&gt; Reasons for this are numerous: lack of (suitable) data, lack of access to the data, data bias, privacy problems, badly chosen tasks and algorithms, wrong tools and people, lack of resources, and evaluation problems.&lt;ref&gt;{{Cite web|url=https://www.kdnuggets.com/2018/07/why-machine-learning-project-fail.html|title=9 Reasons why your machine learning project will fail|website=www.kdnuggets.com|language=en-US|access-date=2018-08-20}}&lt;/ref&gt;

In 2018, a self-driving car from [[Uber]] failed to detect a pedestrian, who was killed after a collision.&lt;ref&gt;{{Cite news|url=https://www.economist.com/the-economist-explains/2018/05/29/why-ubers-self-driving-car-killed-a-pedestrian|title=Why Uber's self-driving car killed a pedestrian|work=The Economist|access-date=2018-08-20|language=en}}&lt;/ref&gt; Attempts to use machine learning in healthcare with the [[Watson (computer)|IBM Watson]] system failed to deliver even after years of time and billions of dollars invested.&lt;ref&gt;{{Cite news|url=https://www.statnews.com/2018/07/25/ibm-watson-recommended-unsafe-incorrect-treatments/|title=IBM's Watson recommended 'unsafe and incorrect' cancer treatments - STAT|date=2018-07-25|work=STAT|access-date=2018-08-21|language=en-US}}&lt;/ref&gt;&lt;ref&gt;{{Cite news|url=https://www.wsj.com/articles/ibm-bet-billions-that-watson-could-improve-cancer-treatment-it-hasnt-worked-1533961147|title=IBM Has a Watson Dilemma|last1=Hernandez|first1=Daniela|date=2018-08-11|work=Wall Street Journal|access-date=2018-08-21|last2=Greenwald|first2=Ted|language=en-US|issn=0099-9660}}&lt;/ref&gt;

Machine learning has been used as a strategy to update the evidence related to systematic review and increased reviewer burden related to the growth of biomedical literature. While it has improved with training sets, it has not yet developed sufficiently to reduce the workload burden without limiting the necessary sensitivity for the findings research themselves.&lt;ref&gt;{{Cite journal|last1=Reddy|first1=Shivani M.|last2=Patel|first2=Sheila|last3=Weyrich|first3=Meghan|last4=Fenton|first4=Joshua|last5=Viswanathan|first5=Meera|date=2020|title=Comparison of a traditional systematic review approach with review-of-reviews and semi-automation as strategies to update the evidence|url=https://systematicreviewsjournal.biomedcentral.com/articles/10.1186/s13643-020-01450-2|journal=Systematic Reviews|language=en|volume=9|issue=1|pages=243|doi=10.1186/s13643-020-01450-2|issn=2046-4053|pmc=7574591|pmid=33076975}}&lt;/ref&gt;

===Bias===
{{main|Algorithmic bias}}
Machine learning approaches in particular can suffer from different data biases. A machine learning system trained on current customers only may not be able to predict the needs of new customer groups that are not represented in the training data. When trained on man-made data, machine learning is likely to pick up the same constitutional and unconscious biases already present in society.&lt;ref&gt;{{Cite journal|last=Garcia|first=Megan|s2cid=151595343|date=2016|title=Racist in the Machine|journal=World Policy Journal|language=en|volume=33|issue=4|pages=111–117|doi=10.1215/07402775-3813015|issn=0740-2775}}&lt;/ref&gt; Language models learned from data have been shown to contain human-like biases.&lt;ref&gt;{{Cite journal|last1=Caliskan|first1=Aylin|last2=Bryson|first2=Joanna J.|last3=Narayanan|first3=Arvind|date=2017-04-14|title=Semantics derived automatically from language corpora contain human-like biases|journal=Science|language=en|volume=356|issue=6334|pages=183–186|doi=10.1126/science.aal4230|issn=0036-8075|pmid=28408601|bibcode=2017Sci...356..183C|arxiv=1608.07187|s2cid=23163324}}&lt;/ref&gt;&lt;ref&gt;{{Citation|last1=Wang|first1=Xinan|title=An algorithm for L1 nearest neighbor search via monotonic embedding|date=2016|url=http://papers.nips.cc/paper/6227-an-algorithm-for-l1-nearest-neighbor-search-via-monotonic-embedding.pdf|work=Advances in Neural Information Processing Systems 29|pages=983–991|editor-last=Lee|editor-first=D. D.|publisher=Curran Associates, Inc.|access-date=2018-08-20|last2=Dasgupta|first2=Sanjoy|editor2-last=Sugiyama|editor2-first=M.|editor3-last=Luxburg|editor3-first=U. V.|editor4-last=Guyon|editor4-first=I.}}&lt;/ref&gt; Machine learning systems used for criminal risk assessment have been found to be biased against black people.&lt;ref&gt;{{Cite web|url=https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing|title=Machine Bias|date=2016-05-23|website=[[ProPublica]]|author1=Julia Angwin |author2=Jeff Larson |author3=Lauren Kirchner |author4=Surya Mattu|access-date=2018-08-20}}&lt;/ref&gt;&lt;ref&gt;{{Cite news|url=https://www.nytimes.com/2017/10/26/opinion/algorithm-compas-sentencing-bias.html|title=Opinion {{!}} When an Algorithm Helps Send You to Prison|work=[[New York Times]]|access-date=2018-08-20|language=en}}&lt;/ref&gt; In 2015, Google photos would often tag black people as gorillas,&lt;ref&gt;{{Cite news|url=https://www.bbc.co.uk/news/technology-33347866|title=Google apologises for racist blunder|date=2015-07-01|work=BBC News|access-date=2018-08-20|language=en-GB}}&lt;/ref&gt; and in 2018 this still was not well resolved, but Google reportedly was still using the workaround to remove all gorillas from the training data, and thus was not able to recognize real gorillas at all.&lt;ref&gt;{{Cite news|url=https://www.theverge.com/2018/1/12/16882408/google-racist-gorillas-photo-recognition-algorithm-ai|title=Google 'fixed' its racist algorithm by removing gorillas from its image-labeling tech|work=The Verge|access-date=2018-08-20}}&lt;/ref&gt; Similar issues with recognizing non-white people have been found in many other systems.&lt;ref&gt;{{Cite news|url=https://www.nytimes.com/2016/06/26/opinion/sunday/artificial-intelligences-white-guy-problem.html|title=Opinion {{!}} Artificial Intelligence's White Guy Problem|work=[[New York Times]]|access-date=2018-08-20|language=en}}&lt;/ref&gt; In 2016, Microsoft tested a [[chatbot]] that learned from Twitter, and it quickly picked up racist and sexist language.&lt;ref&gt;{{Cite news|url=https://www.technologyreview.com/s/601111/why-microsoft-accidentally-unleashed-a-neo-nazi-sexbot/|title=Why Microsoft's teen chatbot, Tay, said lots of awful things online|last=Metz|first=Rachel|work=MIT Technology Review|access-date=2018-08-20|language=en}}&lt;/ref&gt; Because of such challenges, the effective use of machine learning may take longer to be adopted in other domains.&lt;ref&gt;{{Cite news|url=https://www.technologyreview.com/s/603944/microsoft-ai-isnt-yet-adaptable-enough-to-help-businesses/|title=Microsoft says its racist chatbot illustrates how AI isn't adaptable enough to help most businesses|last=Simonite|first=Tom|work=MIT Technology Review|access-date=2018-08-20|language=en}}&lt;/ref&gt; Concern for [[Fairness (machine learning)|fairness]] in machine learning, that is, reducing bias in machine learning and propelling its use for human good is increasingly expressed by artificial intelligence scientists, including [[Fei-Fei Li]], who reminds engineers that "There’s nothing artificial about AI...It’s inspired by people, it’s created by people, and—most importantly—it impacts people. It is a powerful tool we are only just beginning to understand, and that is a profound responsibility.”&lt;ref&gt;{{Cite news|url=https://www.wired.com/story/fei-fei-li-artificial-intelligence-humanity/|title=Fei-Fei Li's Quest to Make Machines Better for Humanity|last=Hempel|first=Jessi|date=2018-11-13|work=Wired|access-date=2019-02-17|issn=1059-1028}}&lt;/ref&gt;

== Model assessments ==
Classification of machine learning models can be validated by accuracy estimation techniques like the [[Test set|holdout]] method, which splits the data in a training and test set (conventionally 2/3 training set and 1/3 test set designation) and evaluates the performance of the training model on the test set. In comparison, the K-fold-[[Cross-validation (statistics)|cross-validation]] method randomly partitions the data into K subsets and then K experiments are performed each respectively considering 1 subset for evaluation and the remaining K-1 subsets for training the model. In addition to the holdout and cross-validation methods, [[Bootstrapping|bootstrap]], which samples n instances with replacement from the dataset, can be used to assess model accuracy.&lt;ref&gt;{{cite journal|last1=Kohavi|first1=Ron|title=A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection|journal=International Joint Conference on Artificial Intelligence|date=1995|url=http://web.cs.iastate.edu/~jtian/cs573/Papers/Kohavi-IJCAI-95.pdf}}&lt;/ref&gt;

In addition to overall accuracy, investigators frequently report [[sensitivity and specificity]] meaning True Positive Rate (TPR) and True Negative Rate (TNR) respectively. Similarly, investigators sometimes report the [[false positive rate]] (FPR) as well as the [[false negative rate]] (FNR). However, these rates are ratios that fail to reveal their numerators and denominators. The [[total operating characteristic]] (TOC) is an effective method to express a model's diagnostic ability. TOC shows the numerators and denominators of the previously mentioned rates, thus TOC provides more information than the commonly used [[receiver operating characteristic]] (ROC) and ROC's associated area under the curve (AUC).&lt;ref&gt;{{cite journal|last1=Pontius|first1=Robert Gilmore|last2=Si|first2=Kangping|title=The total operating characteristic to measure diagnostic ability for multiple thresholds| journal=International Journal of Geographical Information Science|volume=28|issue=3|year=2014|pages=570–583|doi=10.1080/13658816.2013.862623|s2cid=29204880}}&lt;/ref&gt;

== Ethics ==
Machine learning poses a host of [[Machine ethics|ethical questions]]. Systems which are trained on datasets collected with biases may exhibit these biases upon use ([[algorithmic bias]]), thus digitizing cultural prejudices.&lt;ref&gt;{{Cite web|url=http://www.nickbostrom.com/ethics/artificial-intelligence.pdf|title=The Ethics of Artificial Intelligence|last=Bostrom|first=Nick|date=2011|access-date=11 April 2016|archive-url=https://web.archive.org/web/20160304015020/http://www.nickbostrom.com/ethics/artificial-intelligence.pdf|archive-date=4 March 2016|url-status=dead}}&lt;/ref&gt; For example, using job hiring data from a firm with racist hiring policies may lead to a machine learning system duplicating the bias by scoring job applicants against similarity to previous successful applicants.&lt;ref name="Edionwe Outline"&gt;{{cite web|last1=Edionwe|first1=Tolulope|title=The fight against racist algorithms|url=https://theoutline.com/post/1571/the-fight-against-racist-algorithms|website=The Outline|access-date=17 November 2017}}&lt;/ref&gt;&lt;ref name="Jeffries Outline"&gt;{{cite web|last1=Jeffries|first1=Adrianne|title=Machine learning is racist because the internet is racist|url=https://theoutline.com/post/1439/machine-learning-is-racist-because-the-internet-is-racist|website=The Outline|access-date=17 November 2017}}&lt;/ref&gt; Responsible [[Data collection|collection of data]] and documentation of algorithmic rules used by a system thus is a critical part of machine learning.

The evolvement of AI systems raises a lot questions in the realm of ethics and morality. AI can be well equipped in making decisions in certain fields such technical and scientific which rely
heavily on data and historical information. These decisions rely on objectivity and logical reasoning.&lt;ref&gt;{{cite web |url=https://www.nickbostrom.com/ethics/artificial-intelligence.pdf |title=THE ETHICS OF ARTIFICIAL INTELLIGENCE |date= 2011 |first1=Nick |last1=Bostrom |first2=Eliezer| last2=Yudkowsky| website=Nick Bostrom}}&lt;/ref&gt; Because human languages contain biases, machines trained on language ''[[Text corpus|corpora]]'' will necessarily also learn these biases.&lt;ref&gt;{{cite arXiv|eprint=1809.02208|class=cs.CY|authors=M.O.R. Prates, P.H.C. Avelar, L.C. Lamb|title=Assessing Gender Bias in Machine Translation -- A Case Study with Google Translate|date=11 Mar 2019}}&lt;/ref&gt;&lt;ref&gt;{{cite web |url=https://freedom-to-tinker.com/2016/08/24/language-necessarily-contains-human-biases-and-so-will-machines-trained-on-language-corpora/ |title=Language necessarily contains human biases, and so will machines trained on language corpora |date=August 24, 2016 |first=Arvind |last=Narayanan |website=Freedom to Tinker}}&lt;/ref&gt;

Other forms of ethical challenges, not related to personal biases, are more seen in health care. There are concerns among health care professionals that these systems might not be designed in the public's interest but as income-generating machines. This is especially true in the United States where there is a long-standing ethical dilemma of improving health care, but also increasing profits. For example, the algorithms could be designed to provide patients with unnecessary tests or medication in which the algorithm's proprietary owners hold stakes. There is huge potential for machine learning in health care to provide professionals a great tool to diagnose, medicate, and even plan recovery paths for patients, but this will not happen until the personal biases mentioned previously, and these "greed" biases are addressed.&lt;ref&gt;{{cite journal |last1=Char |first1=D. S. |last2=Shah |first2=N. H. |last3=Magnus |first3=D. |year=2018 |title=Implementing Machine Learning in Health Care—Addressing Ethical Challenges |journal=[[New England Journal of Medicine]] |volume=378 |issue=11 |pages=981–983 |doi=10.1056/nejmp1714229 |pmid=29539284 |pmc=5962261 }}&lt;/ref&gt;

==Hardware==
Since the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks (a particular narrow subdomain of machine learning) that contain many layers of non-linear hidden units.&lt;ref&gt;{{cite web|last1=Research|first1=AI|title=Deep Neural Networks for Acoustic Modeling in Speech Recognition|url=http://airesearch.com/ai-research-papers/deep-neural-networks-for-acoustic-modeling-in-speech-recognition/|website=airesearch.com|access-date=23 October 2015|date=23 October 2015}}&lt;/ref&gt; By 2019, graphic processing units ([[GPU]]s), often with AI-specific enhancements, had displaced CPUs as the dominant method of training large-scale commercial cloud AI.&lt;ref&gt;{{cite news |title=GPUs Continue to Dominate the AI Accelerator Market for Now |url=https://www.informationweek.com/big-data/ai-machine-learning/gpus-continue-to-dominate-the-ai-accelerator-market-for-now/a/d-id/1336475 |access-date=11 June 2020 |work=InformationWeek |date=December 2019 |language=en}}&lt;/ref&gt; [[OpenAI]] estimated the hardware compute used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017), and found a 300,000-fold increase in the amount of compute required, with a doubling-time trendline of 3.4 months.&lt;ref&gt;{{cite news |last1=Ray |first1=Tiernan |title=AI is changing the entire nature of compute |url=https://www.zdnet.com/article/ai-is-changing-the-entire-nature-of-compute/ |access-date=11 June 2020 |work=ZDNet |date=2019 |language=en}}&lt;/ref&gt;&lt;ref&gt;{{cite web |title=AI and Compute |url=https://openai.com/blog/ai-and-compute/ |website=OpenAI |access-date=11 June 2020 |language=en |date=16 May 2018}}&lt;/ref&gt;

== Software ==
[[Software suite]]s containing a variety of machine learning algorithms include the following:

=== Free and open-source software{{anchor|Open-source_software}} ===
{{Div col|colwidth=18em}}
* [[Caffe (software)|Caffe]]
* [[Microsoft Cognitive Toolkit|CNTK]]
* [[Deeplearning4j]]
* [[DeepSpeed]]
* [[ELKI]]
* [[Infer.NET]]
* [[Keras]]
* [[LightGBM]]
* [[Apache Mahout|Mahout]]
* [[Mallet (software project)|Mallet]] 
* [[ML.NET]]
* [[mlpack]]
* [[MXNet]]
* [[Neural Lab]]
* [[GNU Octave|Octave]]
* [[OpenNN]]
* [[Orange (software)|Orange]]
* [[ROOT]] (TMVA with ROOT)
* [[scikit-learn]]
* [[Shogun (toolbox)|Shogun]]
* [[Apache Spark#MLlib Machine Learning Library|Spark MLlib]]
* [[Apache SystemML|SystemML]]
* [[TensorFlow]]
* [[Torch (machine learning)|Torch]] / [[PyTorch]]
* [[Weka (machine learning)|Weka]] / [[MOA (Massive Online Analysis)|MOA]]
* [[XGBoost]]
* [[Yooreeka]]
* [[pandas (software)]]
{{Div col end}}

=== Proprietary software with free and open-source editions ===
* [[KNIME]]
* [[RapidMiner]]

=== Proprietary software ===
{{Div col|colwidth=18em}}
* [[Amazon Machine Learning]]
* [[Angoss]] KnowledgeSTUDIO
* [[Azure Machine Learning]]
* [[Ayasdi]]
* [[IBM Watson Studio]]
* [[Google APIs|Google Prediction API]]
* [[SPSS Modeler|IBM SPSS Modeler]]
* [[KXEN Inc.|KXEN Modeler]]
* [[LIONsolver]]
* [[Mathematica]]
* [[MATLAB]]
* [[Neural Designer]]
* [[NeuroSolutions]]
* [[Oracle Data Mining]]
* [[Oracle Cloud#Platform as a Service (PaaS)|Oracle AI Platform Cloud Service]]
* [[RCASE]]
* [[SAS (software)#Components|SAS Enterprise Miner]]
* [[SequenceL]]
* [[Splunk]]
* [[STATISTICA]] Data Miner
{{Div col end}}

== Journals ==
* [[Journal of Machine Learning Research]]
* [[Machine Learning (journal)|Machine Learning]]
* [[Nature Machine Intelligence]]
* [[Neural Computation (journal)|Neural Computation]]

== Conferences ==
* [[Association for Computational Linguistics|Association for Computational Linguistics ('''ACL''')]]
* [[European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases|European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases ('''ECML PKDD''')]]
* [[International Conference on Machine Learning|International Conference on Machine Learning ('''ICML''')]]
* [[International Conference on Learning Representations|International Conference on Learning Representations ('''ICLR''')]]
* [[International Conference on Intelligent Robots and Systems|International Conference on Intelligent Robots and Systems ('''IROS''')]]
* [[Conference on Knowledge Discovery and Data Mining|Conference on Knowledge Discovery and Data Mining ('''KDD''')]]
* [[Conference on Neural Information Processing Systems|Conference on Neural Information Processing Systems ('''NeurIPS''')]]

== See also ==

* {{annotated link|Automated machine learning}}
* {{annotated link|Big data}}
* [[List of important publications in computer science#Machine learning|List of important publications in machine learning]]
* {{annotated link|List of datasets for machine learning research}}

== References ==
{{Reflist|30em}}

== Further reading ==
{{Refbegin|2}} 
*  Nils J. Nilsson, ''[https://ai.stanford.edu/people/nilsson/mlbook.html Introduction to Machine Learning]''.
* [[Trevor Hastie]], [[Robert Tibshirani]] and [[Jerome H. Friedman]] (2001). ''[https://web.stanford.edu/~hastie/ElemStatLearn/ The Elements of Statistical Learning]'', Springer. {{ISBN|0-387-95284-5}}.
* [[Pedro Domingos]] (September 2015), ''[[The Master Algorithm]]'', Basic Books, {{ISBN|978-0-465-06570-7}} 
* Ian H. Witten and Eibe Frank (2011). ''Data Mining: Practical machine learning tools and techniques'' Morgan Kaufmann, 664pp., {{ISBN|978-0-12-374856-0}}.
* Ethem Alpaydin (2004). ''Introduction to Machine Learning'', MIT Press, {{ISBN|978-0-262-01243-0}}.
* [[David J. C. MacKay]]. ''[http://www.inference.phy.cam.ac.uk/mackay/itila/book.html Information Theory, Inference, and Learning Algorithms]'' Cambridge: Cambridge University Press, 2003. {{ISBN|0-521-64298-1}}
* [[Richard O. Duda]], [[Peter E. Hart]], David G. Stork (2001) ''Pattern classification'' (2nd edition), Wiley, New York, {{ISBN|0-471-05669-3}}.
* [[Christopher Bishop]] (1995). ''Neural Networks for Pattern Recognition'', Oxford University Press. {{ISBN|0-19-853864-2}}.
* Stuart Russell &amp; Peter Norvig, (2009). ''[http://aima.cs.berkeley.edu/ Artificial Intelligence – A Modern Approach]''. Pearson, {{ISBN|9789332543515}}. 
* [[Ray Solomonoff]], ''An Inductive Inference Machine'', IRE Convention Record, Section on Information Theory, Part 2, pp., 56–62, 1957.
* [[Ray Solomonoff]], ''[http://world.std.com/~rjs/indinf56.pdf An Inductive Inference Machine]'' A privately circulated report from the 1956 [[Dartmouth workshop|Dartmouth Summer Research Conference on AI]].
{{Refend}}

==External links==
{{Commons category}}
*[https://web.archive.org/web/20171230081341/http://machinelearning.org/ International Machine Learning Society]
*[https://mloss.org/ mloss] is an academic database of open-source machine learning software.
*[https://developers.google.com/machine-learning/crash-course/ Machine Learning Crash Course] by [[Google]]. This is a free course on machine learning through the use of [[TensorFlow]].

{{Computer science}}
{{Differentiable computing}}

[[Category:Machine learning| ]]
[[Category:Cybernetics]]
[[Category:Learning]]</text>
      <sha1>skabdy6cyxbchjc5uwekn1n5dpe5sba</sha1>
    </revision>
  </page>
  <page>
    <title>OpenNN</title>
    <ns>0</ns>
    <id>42129549</id>
    <revision>
      <id>1002126502</id>
      <parentid>996728781</parentid>
      <timestamp>2021-01-23T00:15:54Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 8 templates: hyphenate params (1×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="5131" xml:space="preserve">{{Infobox software
| name             = Open Neural Networks Library
| title            = OpenNN
| logo             = White logo opennn.svg
| screenshot       = 
| caption          = 
| developer        = [http://www.artelnics.com Artelnics]
| operating system = [[Cross-platform]]
| platform         = 
| genre            = [[Neural networks]]
| license          = [[GNU Lesser General Public License|LGPL]]
| website          = {{URL|http://www.opennn.net}}
}}

'''OpenNN''' (Open Neural Networks Library) is a [[software library]] written in the [[C++]] [[programming language]] which implements [[neural networks]], a main area of [[deep learning]] research.&lt;ref&gt;{{cite web|url=http://www.kdnuggets.com/2014/06/opennn-open-source-library-neural-networks.html|title=OpenNN, An Open Source Library For Neural Networks | publisher=KDNuggets | date= June 2014}}&lt;/ref&gt; The library is [[open-source software|open-source]], licensed under the [[GNU Lesser General Public License]].

==Characteristics==
The software implements any number of layers of non-linear processing units for [[supervised learning]]. This deep architecture allows the design of neural networks with [[Universal approximation theorem|universal approximation]] properties. Additionally, it allows [[multiprocessing]] programming by means of [[OpenMP]], in order to increase [[computer performance]].

OpenNN contains [[machine learning]] algorithms as a bundle of functions. These can be embedded in other software tools, using an [[application programming interface]], for the integration of the [[predictive analytics]] tasks. In this regard, a graphical user interface is missing but some functions can be supported by specific visualization tools.&lt;ref&gt;{{cite journal | url=https://www.academia.edu/6491835 | title=Categorization of Data Mining Tools Based on Their Types | author=J. Mary Dallfin Bruxella| journal = International Journal of Computer Science and Mobile Computing | volume = 3 | issue = 3 | pages = 445–452 | year = 2014 |display-authors=etal}}&lt;/ref&gt;

==History==
The development started in 2003 at the [[Polytechnic University of Catalonia#UPC Research Centers|International Center for Numerical Methods in Engineering]], within the research project funded by the [[European Union]] called RAMFLOOD (Risk Assessment and Management of FLOODs).&lt;ref&gt;{{cite web|url=http://cordis.europa.eu/projects/rcn/67049_en.html |title=CORDIS - EU Research Project RAMFLOOD |publisher=European Commission | date=December 2004}}&lt;/ref&gt; Then it continued as part of similar projects.
At present, OpenNN is being developed by the [[startup company]] Artelnics.&lt;ref&gt;{{cite web | url=http://www.artelnics.com |title=Artelnics home page}}&lt;/ref&gt;

==Applications==
OpenNN is a general purpose [[artificial intelligence]] software package.&lt;ref&gt;{{cite web|url=http://www.efytimes.com/e1/fullnews.asp?edid=142005|title=Here Are 7 Thought-Provoking AI Software Packages For Your Info|publisher=Saurabh Singh|access-date=25 June 2014|archive-url=https://web.archive.org/web/20140627090333/http://efytimes.com/e1/fullnews.asp?edid=142005|archive-date=2014-06-27|url-status=dead}}&lt;/ref&gt; It uses [[machine learning]] techniques for solving [[predictive analytics]] tasks in different fields. For instance, the library has been applied in the engineering, energy, or chemistry sectors.&lt;ref&gt;{{cite journal|title= Neural Networks for Variational Problems in Engineering | author = R. Lopez| journal = International Journal for Numerical Methods in Engineering | volume = 75 | issue = 11 | pages =  1341–1360 | year = 2008 | doi=10.1002/nme.2304|display-authors=etal| bibcode = 2008IJNME..75.1341L}}&lt;/ref&gt;&lt;ref&gt;{{cite book | chapter=Optimisation of Concentrating Solar Thermal Power Plants with Neural Networks | journal = Lecture Notes in Computer Science | author = P. Richter| title = Adaptive and Natural Computing Algorithms | volume = 6593 | pages = 190–199 | year = 2011 | doi=10.1007/978-3-642-20282-7_20|display-authors=etal|isbn = 978-3-642-20281-0}}&lt;/ref&gt;&lt;ref&gt;{{cite journal | title = Artificial Neural Network Prediction of Multilinear Gradient Retention in Reversed-Phase HPLC | journal = Analytical and Bioanalytical Chemistry |  author= A.A. D’Archivio| pages = 1–10 | year= 2014 | doi=10.1007/s00216-014-8317-3 | pmid = 25395205 | volume=407|issue = 4| s2cid = 40461902 |display-authors=etal}}&lt;/ref&gt;

==See also==

{{Portal|Free and open-source software}}
* [[Comparison of deep learning software]]
* [[Neural Designer]], also developed by Artelnics
* [[Artificial intelligence]]
* [[Machine learning]]
* [[Deep learning]]
* [[Artificial neural network]]

==References==
{{Reflist}}

{{Deep Learning Software}}

[[Category:Applied machine learning]]
[[Category:Artificial intelligence applications]]
[[Category:Artificial neural networks]]
[[Category:C++ libraries]]
[[Category:Data mining and machine learning software]]
[[Category:Deep learning]]
[[Category:Free software programmed in C++]]
[[Category:Machine learning]]
[[Category:Neural network software]]
[[Category:Open-source artificial intelligence]]
[[Category:Software using the LGPL license]]</text>
      <sha1>obi5816p02l0zjytu3to7ewewda0oth</sha1>
    </revision>
  </page>
  <page>
    <title>Ball tree</title>
    <ns>0</ns>
    <id>31877832</id>
    <revision>
      <id>992909605</id>
      <parentid>984680360</parentid>
      <timestamp>2020-12-07T19:24:37Z</timestamp>
      <contributor>
        <ip>213.137.83.155</ip>
      </contributor>
      <comment>/* Pseudocode */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="9978" xml:space="preserve">{{About|the binary tree variant|a metric-tree involving multi-way splits|M-tree}}

In [[computer science]], a '''ball tree''', '''balltree'''&lt;ref name=r1 /&gt; or '''metric tree''', is a [[space partitioning]] [[data structure]] for organizing points in a multi-dimensional space. The ball tree gets its name from the fact that it partitions data points into a nested set of hyperspheres known as "balls". The resulting data structure has characteristics that make it useful for a number of applications, most notably [[nearest neighbor search]].

== Informal description ==
A ball tree is a [[binary tree]] in which every node defines a D-dimensional [[hypersphere]], or ball, containing a subset of the points to be searched. Each internal node of the tree partitions the data points into two disjoint sets which are associated with different balls. While the balls themselves may intersect, each point is assigned to one or the other ball in the partition according to its distance from the ball's center. Each leaf node in the tree defines a ball and enumerates all data points inside that ball.

Each node in the tree defines the smallest ball that contains all data points in its subtree. This gives rise to the useful property that, for a given test point {{mvar|t}}, the distance to any point in a ball {{mvar|B}} in the tree is greater than or equal to the distance from {{mvar|t}} to the ball. &lt;!-- an explanation with a graphic might be nice here --&gt;  Formally:
&lt;ref name="liu"&gt;{{cite journal|author1=Liu, T. |author2=Moore, A. |author3=Gray, A.  |name-list-style=amp |url=http://people.ee.duke.edu/~lcarin/liu06a.pdf |title=New Algorithms for Efficient High-Dimensional Nonparametric Classification|journal=Journal of Machine Learning Research|volume=7|pages=1135–1158|year= 2006}}&lt;/ref&gt;
: &lt;math&gt;
    D^{B}(t) = 
        \begin{cases}
            \max(|t - B.pivot| - B.radius, D^{B.parent}),
                &amp; \text{if }B \neq Root \\
            \max(|t - B.pivot| - B.radius, 0),
                &amp; \text{if }B = Root \\
        \end{cases}
&lt;/math&gt;
Where &lt;math&gt;D^{B}(t)&lt;/math&gt; is the minimum possible distance from any point in the ball {{mvar|B}} to some point {{mvar|t}}.

Ball-trees are related to the [[M-tree]], but only support binary splits, whereas in the M-tree each level splits &lt;math&gt;m&lt;/math&gt; to &lt;math&gt;2m&lt;/math&gt; fold, thus leading to a shallower tree structure, therefore need fewer distance computations, which usually yields faster queries. Furthermore, M-trees can better be stored [[Computer_data_storage#Secondary_storage|on disk]], which is organized in [[Page (computer memory)|pages]]. The M-tree also keeps the distances from the parent node precomputed to speed up queries.

[[Vantage-point tree]]s are also similar, but they binary split into one ball, and the remaining data, instead of using two balls.

== Construction ==
A number of ball tree construction algorithms are available.&lt;ref name=r1&gt;Omohundro, Stephen M. (1989) [ftp://ftp.icsi.berkeley.edu/pub/techreports/1989/tr-89-063.pdf "Five Balltree Construction Algorithms"]&lt;/ref&gt; The goal of such an algorithm is to produce a tree that will efficiently support queries of the desired type (e.g. nearest-neighbor) efficiently in the average case. The specific criteria of an ideal tree will depend on the type of question being answered and the distribution of the underlying data. However, a generally applicable measure of an efficient tree is one that minimizes the total volume of its internal nodes. Given the varied distributions of real-world data sets, this is a difficult task, but there are several heuristics that partition the data well in practice. In general, there is a tradeoff between the cost of constructing a tree and the efficiency achieved by this metric. 
&lt;ref name="liu" /&gt;

This section briefly describes the simplest of these algorithms. A more in-depth discussion of five algorithms was given by Stephen Omohundro.&lt;ref name=r1/&gt;

=== k-d Construction Algorithm ===
The simplest such procedure is termed the "k-d Construction Algorithm", by analogy with the process used to construct [[k-d tree]]s. This is an [[off-line algorithm]], that is, an algorithm that operates on the entire data set at once. The tree is built top-down by recursively splitting the data points into two sets. Splits are chosen along the single dimension with the greatest spread of points, with the sets partitioned by the median value of all points along that dimension. Finding the split for each internal node requires linear time in the number of samples contained in that node, yielding an algorithm with [[time complexity]] &lt;math&gt;O(n\, \log\, n)&lt;/math&gt;, where ''n'' is the number of data points.

==== Pseudocode ====
 '''function''' construct_balltree '''is'''
     '''input:''' ''D'', an array of data points.
     '''output:''' ''B'', the root of a constructed ball tree.
 
     '''if''' a single point remains '''then'''
         create a leaf ''B'' containing the single point in ''D''
         '''return''' ''B''
     '''else'''
         let ''c'' be the dimension of greatest spread
         let ''p'' be the central point selected considering c
         let ''L'', ''R'' be the sets of points lying to the left and right of the median along dimension ''c''
         create ''B'' with two children: 
             ''B''.pivot := ''p''
             ''B''.child1 := construct_balltree(L),
             ''B''.child2 := construct_balltree(R),
             let ''B''.radius be maximum distance from ''p'' among children
         '''return''' ''B''
     '''end if'''
 '''end function'''

== Nearest-neighbor search ==

An important application of ball trees is expediting [[nearest neighbor search]] queries, in which the objective is to find the k points in the tree that are closest to a given test point by some distance metric (e.g. [[Euclidean distance]]). A simple search algorithm, sometimes called KNS1, exploits the distance property of the ball tree. In particular, if the algorithm is searching the data structure with a test point ''t'', and has already seen some point ''p'' that is closest to ''t'' among the points encountered so far, then any subtree whose ball is further from ''t'' than ''p'' can be ignored for the rest of the search.

=== Description ===

The ball tree nearest-neighbor algorithm examines nodes in depth-first order, starting at the root. During the search, the algorithm
maintains a max-first [[priority queue]] (often implemented with a [[Heap (data structure)|heap]]), denoted ''Q'' here, of the k nearest points encountered so far. At each node ''B'', it may perform one of three operations, before finally returning an updated version of the priority queue:

# If the distance from the test point ''t'' to the current node ''B'' is greater than the furthest point in ''Q'', ignore ''B'' and return ''Q''.
# If ''B'' is a leaf node, scan through every point enumerated in ''B'' and update the nearest-neighbor queue appropriately. Return the updated queue.
# If ''B'' is an internal node, call the algorithm recursively on ''B'''s two children, searching the child whose center is closer to ''t'' first. Return the queue after each of these calls has updated it in turn.

Performing the recursive search in the order described in point 3 above increases likelihood that the further child will be pruned 
entirely during the search.

=== Pseudocode ===
 '''function''' knn_search '''is'''
     '''input:''' 
         t, the target point for the query
         k, the number of nearest neighbors of t to search for
         Q, max-first priority queue containing at most k points
         B, a node, or ball, in the tree
     '''output:''' 
         Q, containing the k nearest neighbors from within B
 
     '''if''' distance(t, B.pivot) - B.radius ≥ distance(t, Q.first) '''then'''
         '''return''' Q unchanged
     '''else if''' B is a leaf node '''then'''
         '''for each''' point p in B '''do'''
             '''if''' distance(t, p) &lt; distance(t, Q.first) '''then'''
                 add p to Q
                 '''if''' size(Q) &gt; k '''then'''
                     remove the furthest neighbor from Q
                 '''end if'''
             '''end if'''
         '''repeat'''
     '''else'''
         let child1 be the child node closest to t
         let child2 be the child node furthest from t
         knn_search(t, k, Q, child1)
         knn_search(t, k, Q, child2)
     '''end if'''
 '''end function'''&lt;ref name="liu" /&gt;

=== Performance ===
In comparison with several other data structures, ball trees have been shown to perform fairly well on 
the nearest-neighbor search problem, particularly as their number of dimensions grows.&lt;ref name="kumar"&gt;{{Cite book | doi = 10.1007/978-3-540-88688-4_27| chapter = What is a Good Nearest Neighbors Algorithm for Finding Similar Patches in Images?| title = Computer Vision – ECCV 2008| volume = 5303| pages = 364| series = Lecture Notes in Computer Science| year = 2008| last1 = Kumar | first1 = N. | last2 = Zhang | first2 = L. | last3 = Nayar | first3 = S. | citeseerx = 10.1.1.360.7582| isbn = 978-3-540-88685-3|url=http://www1.cs.columbia.edu/CAVE/publications/pdfs/Kumar_ECCV08_2.pdf}}&lt;/ref&gt;&lt;ref name="kibriya"&gt;{{Cite book | doi = 10.1007/978-3-540-74976-9_16| chapter = An Empirical Comparison of Exact Nearest Neighbour Algorithms| title = Knowledge Discovery in Databases: PKDD 2007| volume = 4702| pages = 140| series = Lecture Notes in Computer Science| year = 2007| last1 = Kibriya | first1 = A. M. | last2 = Frank | first2 = E. | isbn = 978-3-540-74975-2|url=http://www.cs.waikato.ac.nz/~ml/publications/2007/KibriyaAndFrankPKDD07.pdf}}&lt;/ref&gt;
However, the best nearest-neighbor data structure for a given application will depend on the dimensionality, number of data points, and underlying structure of the data.

==References==

{{reflist}}

[[Category:Trees (data structures)]]
[[Category:Machine learning]]
[[Category:Articles with example pseudocode]]</text>
      <sha1>er0vu0jl8fytvpmq9ndmorpdloi1jvx</sha1>
    </revision>
  </page>
  <page>
    <title>User behavior analytics</title>
    <ns>0</ns>
    <id>47228422</id>
    <revision>
      <id>993564399</id>
      <parentid>977514184</parentid>
      <timestamp>2020-12-11T07:16:08Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 6 templates: del empty params (13×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="6060" xml:space="preserve">'''User behavior analytics''' ('''UBA''') as defined by [[Gartner]] is a [[cybersecurity]] process about [[threat detection|detection of insider threats]], targeted attacks, and financial fraud. UBA solutions look at patterns of [[human behavior]], and then apply algorithms and statistical analysis to detect meaningful anomalies from those patterns—anomalies that indicate potential threats.&lt;ref&gt;[https://www.gartner.com/doc/2831117/market-guide-user-behavior-analytics Market Guide for User Behavior Analytics&lt;!-- Bot generated title --&gt;]&lt;/ref&gt;  Instead of tracking devices or security events, UBA tracks a system's users.&lt;ref&gt;[http://searchsecurity.techtarget.com/feature/The-hunt-for-data-analytics-Is-your-SIEM-on-the-endangered-list The hunt for data analytics: Is your SIEM on the endangered list?&lt;!-- Bot generated title --&gt;]&lt;/ref&gt; [[Big data]] platforms like [[Apache Hadoop]] are increasing UBA functionality by allowing them to analyze [[petabyte]]s worth of data to detect [[insider threat]]s and [[advanced persistent threat]]s.&lt;ref&gt;{{Cite journal|last=Ahlm|first=Eric|last2=Litan|first2=Avivah|date=26 April 2016|title=Market Trends: User and Entity Behavior Analytics Expand Their Market Reach|url=https://www.gartner.com/doc/reprints?id=1-370BP2V&amp;ct=160518&amp;st=sb|journal=Gartner|access-date=15 July 2016}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=http://www.cloudera.com/solutions/cybersecurity.html|title=Cybersecurity at petabyte scale|access-date=15 July 2016}}&lt;/ref&gt;

== Purpose ==
The problem UBA responds to, as described by [[Nemertes Research]] CEO Johna Till Johnson, is that "[[Security system]]s provide so much information that it's tough to uncover information that truly indicates a potential for real attack. Analytics tools help make sense of the vast amount of data that [[SIEM]], [[Intrusion detection system|IDS]]/IPS, [[system log]]s, and other tools gather. UBA tools use a specialized type of security analytics that focuses on the behavior of systems and the people using them. UBA technology first evolved in the field of marketing, to help companies understand and predict consumer-[[buying pattern]]s. But as it turns out, UBA can be extraordinarily useful in the security context too." &lt;ref&gt;[http://searchsecurity.techtarget.com/feature/User-behavioral-analytics-tools-can-thwart-security-attacks User behavioral analytics tools can thwart security attacks&lt;!-- Bot generated title --&gt;]&lt;/ref&gt;

== Market developments ==
Developments in UBA technology led Gartner to evolve the category to '''user and entity behavior analytics''' ("'''UEBA'''"). In September 2015, Gartner published the Market Guide for User and Entity Analytics by Vice President and Distinguished Analyst, Avivah Litan, that provided a thorough definition and explanation. UEBA was referred to in earlier Gartner reports but not in much depth. Expanding the definition from UBA includes devices, applications, [[server (computing)|server]]s, [[data]], or anything with an [[IP address]]. It moves beyond the fraud-oriented UBA focus to a broader one encompassing "malicious and abusive behavior that otherwise went unnoticed by existing security monitoring systems, such as SIEM and DLP."&lt;ref&gt;{{Cite web|url=https://www.gartner.com/doc/3134524/market-guide-user-entity-behavior|title=Market Guide for User and Entity Behavior Analytics|website=www.gartner.com|access-date=2016-11-10}}&lt;/ref&gt; The addition of "entity" reflects that devices may play a role in a network attack and may also be valuable in uncovering attack activity. "When end users have been compromised, [[malware]] can lay dormant and go undetected for months. Rather than trying to find where the outsider entered, UEBAs allow for quicker detection by using algorithms to detect insider threats."&lt;ref&gt;{{Cite web|url=http://www.csoonline.com/article/2998174/security-awareness/user-entity-behavior-analytics-next-step-in-security-visibilty.html|title=User entity behavior analytics, next step in security {{sic|hide=y|nolink=y|reason=typo in source|visibil|ty}}|last=Zurkus|first=Kacy|website=CSO Online|date=27 October 2015|access-date=2016-06-06}}&lt;/ref&gt;

Particularly in the [[computer security]] market, there are many vendors for UEBA applications. They can be "differentiated by whether they are designed to monitor on-premises or [[Cloud computing|cloud]]-based [[software as a service]] (SaaS) applications; the methods in which they obtain the source data; the type of analytics they use (i.e., packaged analytics, user-driven or vendor-written), and the service delivery method (i.e., on-premises or a cloud-based)."&lt;ref&gt;{{Cite web|url=http://www.gartner.com/smarterwithgartner/detect-security-breaches-early-by-analyzing-behavior/|title=Detect Security Breaches Early by Analyzing Behavior - Smarter With Gartner|date=2015-06-04|website=Smarter With Gartner|language=en-US|access-date=2016-06-06}}&lt;/ref&gt; 
According to the 2015 market guide released by Gartner, "the UEBA market grew substantially in 2015; UEBA vendors grew their customer base, market consolidation began, and Gartner client interest in UEBA and security analytics increased."&lt;ref name=":0"&gt;{{Cite web|url=https://www.gartner.com/doc/reprints?id=1-2NK6M1R&amp;ct=150922&amp;st=sb|title=Market Guide for User and Entity Behavior Analytics|date=September 22, 2015|publisher=Gartner, Inc.|access-date=June 6, 2016}}&lt;/ref&gt; The report further projected, "Over the next three years, leading UEBA platforms will become preferred systems for security operations and investigations at some of the organizations they serve. It will be—and in some cases already is—much easier to discover some security events and analyze individual offenders in UEBA than it is in many legacy security monitoring systems."&lt;ref name=":0" /&gt;

==See also==
* [[Behavioral analytics]]
* [[Network behavior anomaly detection]]

==References==
{{Reflist}}

[[Category:Artificial intelligence]]
[[Category:Machine learning]]
[[Category:Computer security]]
[[Category:Human behavior]]

==External links==

*[https://gurucul.com/tag/abcs-of-ueba ABC's Of UBA]</text>
      <sha1>r2zplv9lypa039wu334agin82xn9ne9</sha1>
    </revision>
  </page>
  <page>
    <title>Word2vec</title>
    <ns>0</ns>
    <id>47527969</id>
    <revision>
      <id>1001737145</id>
      <parentid>1000931521</parentid>
      <timestamp>2021-01-21T02:29:09Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 21 templates: hyphenate params (4×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="17917" xml:space="preserve">{{machine learning bar}}
{{confusing|date=July 2020}}
'''Word2vec''' is a technique for [[natural language processing]]. The word2vec algorithm uses a [[neural network]] model to learn word associations from a large [[corpus of text]]. Once trained, such a model can detect [[synonym]]ous words or suggest additional words for a partial sentence. As the name implies, word2vec represents each distinct word with a particular list of numbers called a [[vector (geometry)|vector]]. The vectors are chosen carefully such that a simple mathematical function (the [[cosine similarity]] between the vectors) indicates the level of [[semantic similarity]] between the words represented by those vectors.

==Approach==
Word2vec is a group of related models that are used to produce [[word embedding]]s. These models are shallow, two-layer [[neural network]]s that are trained to reconstruct linguistic contexts of words. Word2vec takes as its input a large [[Text corpus|corpus of text]] and produces a [[vector space]], typically of several hundred [[dimensions]], with each unique word in the [[Corpus linguistics|corpus]] being assigned a corresponding vector in the space. [[Word vectors]] are positioned in the vector space such that words that share common contexts in the corpus are located close to one another in the space.&lt;ref name="mikolov"&gt;{{cite arXiv|first=Tomas |last=Mikolov |title=Efficient Estimation of Word Representations in Vector Space|eprint=1301.3781|display-authors=etal|class=cs.CL |year=2013 }}&lt;/ref&gt;

==History==
Word2vec was created, patented,&lt;ref name="pat"&gt;{{cite patent|title=Computing numeric representations of words in a high-dimensional space |url=https://patents.google.com/patent/US9037464B1/en}}&lt;/ref&gt; and published in 2013 by a team of researchers led by [[Tomas Mikolov]] at [[Google]]
over two papers.&lt;ref&gt;{{cite arXiv|first=Tomas |last=Mikolov |title=Efficient Estimation of Word Representations in Vector Space|eprint=1301.3781|display-authors=etal|class=cs.CL |year=2013 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last1=Mikolov |first1=Tomas |date=2013 |title=Distributed representations of words and phrases and their compositionality. |journal=Advances in Neural Information Processing Systems |arxiv=1310.4546 }}&lt;/ref&gt; Other researchers helpfully analysed and explained the algorithm.&lt;ref name="explain"&gt;{{cite arXiv |first1=Yoav |last1=Goldberg |first2=Omer |last2=Levy |title=word2vec Explained: Deriving Mikolov et al.'s Negative-Sampling Word-Embedding Method|eprint=1402.3722|class=cs.CL |year=2014 }}&lt;/ref&gt;&lt;ref name="extensions"&gt;{{cite AV media
|first=Radim|last=Řehůřek|title=Word2vec and friends|medium=Youtube video|url=https://www.youtube.com/watch?v=wTp3P2UnTfQ|access-date=2015-08-14}}&lt;/ref&gt; Embedding vectors created using the Word2vec algorithm have some advantages compared to earlier algorithms&lt;ref name="mikolov" /&gt; such as [[latent semantic analysis]].

==CBOW and skip grams==
Word2vec can utilize either of two model architectures to produce a [[distributed representation]] of words: [[continuous bag-of-words]] (CBOW) or continuous [[skip-gram]]. In the continuous bag-of-words architecture, the model predicts the current word from a window of surrounding context words. The order of context words does not influence prediction ([[bag-of-words]] assumption). In the continuous skip-gram architecture, the model uses the current word to predict the surrounding window of context words.  The skip-gram architecture weighs nearby context words more heavily than more distant context words.&lt;ref name="mikolov"/&gt;&lt;ref name="mikolov-nips"&gt;{{cite conference |first1=Tomas |last1=Mikolov |first2=Ilya |last2=Sutskever |first3=Kai |last3=Chen |first4=Greg S. |last4=Corrado |first5=Jeff |last5=Dean |title=Distributed representations of words and phrases and their compositionality |conference=[[Advances in Neural Information Processing Systems]] |year=2013|arxiv=1310.4546|bibcode=2013arXiv1310.4546M }}&lt;/ref&gt; According to the authors' note,&lt;ref name=":1"&gt;{{Cite web|url=https://code.google.com/archive/p/word2vec/|title=Google Code Archive - Long-term storage for Google Code Project Hosting.|website=code.google.com|access-date=2016-06-13}}&lt;/ref&gt; CBOW is faster while skip-gram is slower but does a better job for infrequent words.

== Parametrization ==
Results of word2vec training can be sensitive to [[Parameter|parametrization]]. The following are some important parameters in word2vec training.

=== Training algorithm ===
A Word2vec model can be trained with hierarchical [[Softmax function|softmax]] and/or [[negative sampling]]. To approximate the [[conditional log-likelihood]] a model seeks to maximize, the hierarchical softmax method uses a [[Huffman coding|Huffman tree]] to reduce calculation. The negative sampling method, on the other hand, approaches the maximization problem by minimizing the [[log-likelihood]] of sampled negative instances. According to the authors, hierarchical softmax works better for infrequent words while negative sampling works better for frequent words and better with low dimensional vectors.&lt;ref name=":1" /&gt; As training epochs increase, hierarchical softmax stops being useful.&lt;ref&gt;{{Cite web|url=https://groups.google.com/forum/#!msg/word2vec-toolkit/WUWad9fL0jU/LdbWy1jQjUIJ|title=Parameter (hs &amp; negative)|website=Google Groups|access-date=2016-06-13}}&lt;/ref&gt;

=== Sub-sampling ===
High-frequency words often provide little information. Words with a frequency above a certain threshold may be subsampled to increase training speed.&lt;ref&gt;{{Cite web|url=http://jmlr.csail.mit.edu/papers/volume9/vandermaaten08a/vandermaaten08a.pdf|title=Visualizing Data using t-SNE|website= Journal of Machine Learning Research, 2008. Vol. 9, pg. 2595|access-date=2017-03-18}}&lt;/ref&gt;

=== Dimensionality ===
Quality of word embedding increases with higher dimensionality. But after reaching some point, marginal gain will diminish.&lt;ref name="mikolov" /&gt; Typically, the dimensionality of the vectors is set to be between 100 and 1,000.

=== Context window ===
The size of the context window determines how many words before and after a given word would be included as context words of the given word. According to the authors' note, the recommended value is 10 for skip-gram and 5 for CBOW.&lt;ref name=":1" /&gt;

==Extensions==
An extension of word2vec to construct embeddings from entire documents (rather than the individual words) has been proposed.&lt;ref name="doc2vec"&gt;{{cite arXiv
|first=Quoc|last=Le|title=Distributed Representations of Sentences and Documents. |eprint=1405.4053|display-authors=etal|class=cs.CL|year=2014}}&lt;/ref&gt; This extension is called paragraph2vec or doc2vec and has been implemented in the C, Python&lt;ref name="doc2vec_python"&gt;{{cite web
|title=Doc2Vec tutorial using Gensim|url=https://medium.com/@klintcho/doc2vec-tutorial-using-gensim-ab3ac03d3a1|access-date=2015-08-02|display-authors=etal}}&lt;/ref&gt;&lt;ref name="doc2vec_imdb"&gt;{{cite web
|title=Doc2vec for IMDB sentiment analysis|url=https://github.com/piskvorky/gensim/blob/develop/docs/notebooks/doc2vec-IMDB.ipynb|access-date=2016-02-18|display-authors=etal}}&lt;/ref&gt; and Java/Scala&lt;ref name="doc2vec_java"&gt;{{cite web
|title=Doc2Vec and Paragraph Vectors for Classification|url=http://deeplearning4j.org/doc2vec.html|access-date=2016-01-13|display-authors=etal}}&lt;/ref&gt; tools (see below), with the Java and Python versions also supporting inference of document embeddings on new, unseen documents.

==Word vectors for bioinformatics: BioVectors==
An extension of word vectors for n-grams in [[biological]] sequences (e.g. [[DNA]], [[RNA]], and [[Protein]]s) for [[bioinformatic]]s applications have been proposed by Asgari and Mofrad.&lt;ref name=":0"&gt;{{cite journal|last1=Asgari|first1=Ehsaneddin|last2=Mofrad|first2=Mohammad R.K.|title=Continuous Distributed Representation of Biological Sequences for Deep Proteomics and Genomics|journal=PLOS ONE|date=2015|volume=10|issue=11|page=e0141287|doi=10.1371/journal.pone.0141287|pmid=26555596|pmc=4640716|arxiv=1503.05140|bibcode=2015PLoSO..1041287A}}&lt;/ref&gt; Named bio-vectors (BioVec) to refer to biological sequences in general with protein-vectors (ProtVec) for proteins (amino-acid sequences) and gene-vectors (GeneVec) for gene sequences, this representation can be widely used in applications of machine learning in proteomics and genomics. The results suggest that BioVectors can characterize biological sequences in terms of biochemical and biophysical interpretations of the underlying patterns.&lt;ref name=":0"/&gt; A similar variant, dna2vec, has shown that there is correlation between [[Needleman–Wunsch algorithm|Needleman-Wunsch]] similarity score and [[cosine similarity]] of dna2vec word vectors.&lt;ref&gt;{{cite arXiv|eprint=1701.06279|first=Patrick|last=Ng|title=dna2vec: Consistent vector representations of variable-length k-mers|date=2017|class=q-bio.QM}}&lt;/ref&gt;

== Word vectors for Radiology: Intelligent Word Embedding (IWE) ==
An extension of word vectors for creating a dense vector representation of unstructured radiology reports has been proposed by Banerjee et al.&lt;ref&gt;{{Cite journal|last1=Banerjee|first1=Imon|last2=Chen|first2=Matthew C.|last3=Lungren|first3=Matthew P.|last4=Rubin|first4=Daniel L.|title=Radiology report annotation using intelligent word embeddings: Applied to multi-institutional chest CT cohort|journal=Journal of Biomedical Informatics|volume=77|pages=11–20|doi=10.1016/j.jbi.2017.11.012|pmid=29175548|pmc=5771955|year=2018}}&lt;/ref&gt; One of the biggest challenges with Word2Vec is how to handle unknown or out-of-vocabulary (OOV) words and morphologically similar words. This can particularly be an issue in domains like medicine where synonyms and related words can be used depending on the preferred style of radiologist, and words may have been used infrequently in a large corpus. If the word2vec model has not encountered a particular word before, it will be forced to use a random vector, which is generally far from its ideal representation.

IWE combines Word2vec with a semantic dictionary mapping technique to tackle the major challenges of [[information extraction]] from clinical texts, which include ambiguity of free text narrative style, lexical variations, use of ungrammatical and telegraphic phases, arbitrary ordering of words, and frequent appearance of abbreviations and acronyms.  Of particular interest, the IWE model (trained on the one institutional dataset) successfully translated to a different institutional dataset which demonstrates good generalizability of the approach across institutions.

==Analysis==
The reasons for successful [[word embedding]] learning in the word2vec framework are poorly understood. Goldberg and Levy point out that the word2vec objective function causes words that occur in similar contexts to have similar embeddings (as measured by [[cosine similarity]]) and note that this is in line with J. R. Firth's [[Distributional semantics|distributional hypothesis]]. However, they note that this explanation is "very hand-wavy" and argue that a more formal explanation would be preferable.&lt;ref name="explain" /&gt;

Levy et al. (2015)&lt;ref&gt;{{cite journal|last1=Levy|first1=Omer|last2=Goldberg|first2=Yoav|last3=Dagan|first3=Ido|title=Improving Distributional Similarity with Lessons Learned from Word Embeddings|journal=Transactions of the Association for Computational Linguistics|date=2015|volume=3|pages=211–225|location=Transactions of the Association for Computational Linguistics|doi=10.1162/tacl_a_00134|url=http://www.aclweb.org/anthology/Q15-1016|doi-access=free}}&lt;/ref&gt; show that much of the superior performance of word2vec or similar embeddings in downstream tasks is not a result of the models per se, but of the choice of specific hyperparameters. Transferring these hyperparameters to more 'traditional' approaches yields similar performances in downstream tasks. Arora et al. (2016)&lt;ref&gt;{{Cite journal|last=Arora |display-authors=et al|first=S|date=Summer 2016|title=A Latent Variable Model Approach to PMI-based Word Embeddings|url=http://aclweb.org/anthology/Q16-1028|journal=Transactions of Assoc. Of Comp. Linguistics|volume=4|pages=385–399|via=ACLWEB|doi=10.1162/tacl_a_00106|doi-access=free}}&lt;/ref&gt; explain word2vec and related algorithms as performing inference for a simple [[generative model]] for text, which involves a random walk generation process based upon loglinear topic model. They use this to explain some properties of word embeddings, including their use to solve analogies.

== Preservation of semantic and syntactic relationships ==
The word embedding approach is able to capture multiple different degrees of similarity between words. Mikolov et al. (2013)&lt;ref&gt;{{Cite journal|last1=Mikolov|first1=Tomas|last2=Yih|first2=Wen-tau|last3=Zweig|first3=Geoffrey|date=2013|title=Linguistic Regularities in Continuous Space Word Representations.|journal=HLT-Naacl|pages=746–751}}&lt;/ref&gt; found that semantic and syntactic patterns can be reproduced using vector arithmetic. Patterns such as “Man is to Woman as Brother is to Sister” can be generated through algebraic operations on the vector representations of these words such that the vector representation of “Brother” - “Man” + “Woman” produces a result which is closest to the vector representation of “Sister” in the model. Such relationships can be generated for a range of semantic relations (such as Country–Capital) as well as syntactic relations (e.g. present tense–past tense).

== Assessing the quality of a model ==
Mikolov et al. (2013)&lt;ref name="mikolov" /&gt; develop an approach to assessing the quality of a word2vec model which draws on the semantic and syntactic patterns discussed above. They developed a set of 8,869 semantic relations and 10,675 syntactic relations which they use as a benchmark to test the accuracy of a model. When assessing the quality of a vector model, a user may draw on this accuracy test which is implemented in word2vec,&lt;ref&gt;{{Cite web|url=https://radimrehurek.com/gensim/models/word2vec.html|title=Gensim - Deep learning with word2vec|access-date=10 June 2016}}&lt;/ref&gt; or develop their own test set which is meaningful to the corpora which make up the model. This approach offers a more challenging test than simply arguing that the words most similar to a given test word are intuitively plausible.&lt;ref name="mikolov" /&gt;

=== Parameters and model quality ===
The use of different model parameters and different corpus sizes can greatly affect the quality of a word2vec model. Accuracy can be improved in a number of ways, including the choice of model architecture (CBOW or Skip-Gram), increasing the training data set, increasing the number of vector dimensions, and increasing the window size of words considered by the algorithm. Each of these improvements comes with the cost of increased computational complexity and therefore increased model generation time.&lt;ref name="mikolov" /&gt;

In models using large corpora and a high number of dimensions, the skip-gram model yields the highest overall accuracy, and consistently produces the highest accuracy on semantic relationships, as well as yielding the highest syntactic accuracy in most cases. However, the CBOW is less computationally expensive and yields similar accuracy results.&lt;ref name="mikolov" /&gt;

Accuracy increases overall as the number of words used increases, and as the number of dimensions increases. Mikolov et al.&lt;ref name="mikolov" /&gt; report that doubling the amount of training data results in an increase in computational complexity equivalent to doubling the number of vector dimensions.

Altszyler and coauthors (2017) studied Word2vec performance in two semantic tests for different corpus size.&lt;ref name="Altszyler"&gt;{{Cite journal|author1=Altszyler, E. |author2=Ribeiro, S. | author3= Sigman, M.|author4=Fernández Slezak, D. |title=The interpretation of dream meaning: Resolving ambiguity using Latent Semantic Analysis in a small corpus of text|volume=56|journal=Consciousness and Cognition|date=2017|pages=178–187|doi=10.1016/j.concog.2017.09.004 |pmid=28943127 |arxiv=1610.01520|s2cid=195347873 }}&lt;/ref&gt; They found that Word2vec has a steep [[Learning curve (machine learning)|learning curve]], outperforming another word-embedding technique ([[Latent semantic analysis|LSA]]) when it is trained with medium to large corpus size (more than 10 million words). However, with a small training corpus LSA showed better performance. Additionally they show that the best parameter setting depends on the task and the training corpus. Nevertheless, for skip-gram models trained in medium size corpora, with 50 dimensions, a window size of 15 and 10 negative samples seems to be a good parameter setting.

== See also ==
{{Div col|colwidth=20em}}
* [[Autoencoder]]
* [[Document-term matrix]]
* [[Feature extraction]]
* [[Feature learning]]
* [[Language model#Neural network|Neural network language models]]
* [[Vector space model]]
* [[Thought vector]]
* [[fastText]]
* [[GloVe (machine learning)|GloVe]]
* [[Normalized compression distance]]
{{Div col end}}

==References==
{{Reflist}}

==External links==
* [https://wikipedia2vec.github.io/demo/ Wikipedia2Vec][http://arxiv.org/abs/1812.06280] ([https://wikipedia2vec.github.io/wikipedia2vec/ introduction])

===Implementations===
* [https://github.com/tmikolov/word2vec C]
* [https://github.com/eabdullin/Word2Vec.Net C#]
* [https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/examples/tutorials/word2vec/word2vec_basic.py Python (TensorFlow)]
* [http://radimrehurek.com/gensim/models/word2vec.html Python (Gensim)]
* [https://github.com/deeplearning4j/deeplearning4j Java/Scala]

{{Natural Language Processing}}
{{Differentiable computing}}

{{Use dmy dates|date=April 2017}}

[[Category:Free science software]]
[[Category:Natural language processing toolkits]]
[[Category:Artificial neural networks]]
[[Category:Machine learning]]</text>
      <sha1>ee7x8si1t0l20drffl1pk71imk00uxl</sha1>
    </revision>
  </page>
  <page>
    <title>Stochastic block model</title>
    <ns>0</ns>
    <id>47845063</id>
    <revision>
      <id>1003823495</id>
      <parentid>1000493806</parentid>
      <timestamp>2021-01-30T21:30:25Z</timestamp>
      <contributor>
        <username>Sandstein</username>
        <id>359256</id>
      </contributor>
      <minor/>
      <comment>Removing link(s): [[Wikipedia:Articles for deletion/Threshold effect]] closed as delete ([[WP:XFDC|XFDcloser]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="12361" xml:space="preserve">The '''stochastic block model''' is a [[generative model]] for random [[Graph (discrete mathematics)|graphs]]. This model tends to produce graphs containing ''communities'', subsets characterized by being connected with one another with particular edge densities. For example, edges may be more common within communities than between communities. The stochastic block model is important in [[statistics]], [[machine learning]], and [[network science]], where it serves as a useful benchmark for the task of recovering [[community structure]] in graph data.

== Definition == 
The stochastic block model takes the following parameters:
* The number &lt;math&gt;n&lt;/math&gt; of vertices;
* a partition of the vertex set &lt;math&gt;\{1,\ldots,n\}&lt;/math&gt; into disjoint subsets &lt;math&gt;C_1,\ldots,C_r&lt;/math&gt;, called ''communities'';
* a symmetric &lt;math&gt;r \times r&lt;/math&gt; matrix &lt;math&gt;P&lt;/math&gt; of edge probabilities.

The edge set is then sampled at random as follows: any two vertices &lt;math&gt;u \in C_i&lt;/math&gt; and &lt;math&gt;v \in C_j&lt;/math&gt; are connected by an edge with probability &lt;math&gt;P_{ij}&lt;/math&gt;. An example problem is: given a graph with  &lt;math&gt;n&lt;/math&gt; vertices, where the edges are sampled as described, recover the groups  &lt;math&gt;C_1,\ldots,C_r&lt;/math&gt;.

== Special cases ==
If the probability matrix is a constant, in the sense that &lt;math&gt;P_{ij} = p&lt;/math&gt; for all &lt;math&gt;i,j&lt;/math&gt;, then the result is the [[Erdős–Rényi model]] &lt;math&gt;G(n,p)&lt;/math&gt;. This case is degenerate—the partition into communities becomes irrelevant—but it illustrates a close relationship to the Erdős–Rényi model.

The ''planted partition model'' is the special case that the values of the probability matrix &lt;math&gt;P&lt;/math&gt; are a constant &lt;math&gt;p&lt;/math&gt; on the diagonal and another constant &lt;math&gt;q&lt;/math&gt; off the diagonal. Thus two vertices within the same community share an edge with probability &lt;math&gt;p&lt;/math&gt;, while two vertices in different communities share an edge with probability &lt;math&gt;q&lt;/math&gt;. Sometimes it is this restricted model that is called the stochastic block model. The case where &lt;math&gt;p &gt; q&lt;/math&gt; is called an ''assortative'' model, while the case &lt;math&gt;p &lt; q&lt;/math&gt; is called ''disassortative''.

Returning to the general stochastic block model, a model is called ''strongly assortative'' if &lt;math&gt;P_{ii} &gt; P_{jk}&lt;/math&gt; whenever &lt;math&gt;j \neq k&lt;/math&gt;: all diagonal entries dominate all off-diagonal entries. A model is called ''weakly assortative'' if &lt;math&gt;P_{ii} &gt; P_{ij}&lt;/math&gt; whenever &lt;math&gt;i \neq j&lt;/math&gt;: each diagonal entry is only required to dominate the rest of its own row and column.&lt;ref name="al14" /&gt; ''Disassortative'' forms of this terminology exist, by reversing all inequalities. Algorithmic recovery is often easier against block models with assortative or disassortative conditions of this form.&lt;ref name="al14" /&gt;

== Typical statistical tasks ==
Much of the literature on algorithmic community detection addresses three statistical tasks: detection, partial recovery, and exact recovery.

=== Detection ===
The goal of detection algorithms is simply to determine, given a sampled graph, whether the graph has latent community structure. More precisely, a graph might be generated, with some known prior probability, from a known stochastic block model, and otherwise from a similar [[Erdos-Renyi model]]. The algorithmic task is to correctly identify which of these two underlying models generated the graph.&lt;ref name="mns12" /&gt;

=== Partial recovery ===
In partial recovery, the goal is to approximately determine the latent partition into communities, in the sense of finding a partition that is correlated with the true partition significantly better than a random guess.&lt;ref name="mas13" /&gt;

=== Exact recovery ===
In exact recovery, the goal is to recover the latent partition into communities exactly. The community sizes and probability matrix may be known&lt;ref name="as15a" /&gt; or unknown.&lt;ref name="as15b" /&gt;

== Statistical lower bounds and threshold behavior ==
Stochastic block models exhibit a sharp threshold effect reminiscent of [[percolation threshold]]s.&lt;ref name="decelle11"/&gt;&lt;ref name="mns12" /&gt;&lt;ref name="abh14" /&gt; Suppose that we allow the size &lt;math&gt;n&lt;/math&gt; of the graph to grow, keeping the community sizes in fixed proportions. If the probability matrix remains fixed, tasks such as partial and exact recovery become feasible for all non-degenerate parameter settings. However, if we scale down the probability matrix at a suitable rate as &lt;math&gt;n&lt;/math&gt; increases, we observe a sharp phase transition: for certain settings of the parameters, it will become possible to achieve recovery with probability tending to 1, whereas on the opposite side of the parameter threshold, the probability of recovery tends to 0 no matter what algorithm is used.

For partial recovery, the appropriate scaling is to take &lt;math&gt;P_{ij} = \tilde P_{ij} / n&lt;/math&gt; for fixed &lt;math&gt;\tilde P&lt;/math&gt;, resulting in graphs of constant average degree. In the case of two equal-sized communities, in the assortative planted partition model with probability matrix
&lt;math display="block"&gt; P = \left(\begin{array}{cc} \tilde p/n &amp; \tilde q/n \\ \tilde q/n &amp; \tilde p/n \end{array} \right), &lt;/math&gt;
partial recovery is feasible&lt;ref name="mas13" /&gt; with probability &lt;math&gt;1 - o(1)&lt;/math&gt; whenever &lt;math&gt;(\tilde p - \tilde q)^2 &gt; 2(\tilde p + \tilde q)&lt;/math&gt;, whereas any [[estimator]] fails&lt;ref name="mns12" /&gt; partial recovery with probability &lt;math&gt;1-o(1)&lt;/math&gt; whenever &lt;math&gt;(\tilde p - \tilde q)^2 &lt; 2(\tilde p + \tilde q)&lt;/math&gt;.

For exact recovery, the appropriate scaling is to take &lt;math&gt;P_{ij} = \tilde P_{ij} \log n / n&lt;/math&gt;, resulting in graphs of logarithmic average degree. Here a similar threshold exists: for the assortative planted partition model with &lt;math&gt;r&lt;/math&gt; equal-sized communities, the threshold lies at &lt;math&gt;\sqrt{\tilde p} - \sqrt{\tilde q} = \sqrt{r}&lt;/math&gt;. In fact, the exact recovery threshold is known for the fully general stochastic block model.&lt;ref name="as15a" /&gt;
&lt;!---
it'd be great to have plots of these thresholds ---&gt;

== Algorithms == 
In principle, exact recovery can be solved in its feasible range using [[maximum likelihood]], but this amounts to solving a constrained or [[Regularization (mathematics)|regularized]] cut problem such as minimum bisection that is typically [[NP-complete]]. Hence, no known efficient algorithms will correctly compute the maximum-likelihood estimate in the worst case.

However, a wide variety of algorithms perform well in the average case, and many high-probability performance guarantees have been proven for algorithms in both the partial and exact recovery settings. Successful algorithms include [[spectral clustering]] of the vertices,&lt;ref name="krzakala-pnas"/&gt;&lt;ref name="mas13" /&gt;&lt;ref name="as15a" /&gt;&lt;ref name="lr15" /&gt; [[semidefinite programming]],&lt;ref name="al14" /&gt;&lt;ref name="abh14" /&gt; forms of [[belief propagation]],&lt;ref name="decelle11"/&gt;&lt;ref name="mns13" /&gt; and community detection &lt;ref name="fat19"/&gt; among others.

== Variants ==
Several variants of the model exist. One minor tweak allocates vertices to communities randomly, according to a [[categorical distribution]], rather than in a fixed partition.&lt;ref name="as15a" /&gt; More significant variants include the geometric block model,&lt;ref name="gbm" /&gt; censored block model and the mixed-membership block model.&lt;ref name="ar1"/&gt;

== Topic models ==
Stochastic Block Model have been recognised to be a [[topic model]] on bipartite networks.&lt;ref name="gerlachnetwork"&gt;{{cite journal
| author1 = Martin Gerlach |author2=Tiago Peixoto |author3=Eduardo Altmann
| title = A network approach to topic models 
| page=eaaq1360
| journal=Science Advances
|  date = 2018 |doi = 10.1126/sciadv.aaq1360 | volume=4 | issue=7
|pmid=30035215 |pmc=6051742 |arxiv=1708.01677 |bibcode=2018SciA....4.1360G }}&lt;/ref&gt; In a network of documents and words, Stochastic Block Model can identify topics: group of words with a similar meaning.

==References==
{{reflist|refs=
&lt;ref name="decelle11"&gt;{{cite journal| 
last1 = Decelle| first1 = Aurelien |
last2 = Krzakala| first2 = Florent |
last3 = Moore| first3 = Cristopher |
last4 = Zdeborová | first4 = Lenka | author4-link = Lenka Zdeborová |
title = Asymptotic analysis of the stochastic block model for modular networks and its algorithmic applications |
arxiv = 1109.3041 | 
date = September 2011 | doi=10.1103/PhysRevE.84.066106 | volume=84 | journal=Physical Review E| issue = 6 |bibcode = 2011PhRvE..84f6106D | pmid=22304154 | page=066106}}&lt;/ref&gt;
&lt;ref name="abh14"&gt;{{cite arXiv| last1 = Abbe| first1 = Emmanuel| last2 = Bandeira| first2 = Afonso S.| last3 = Hall| first3 = Georgina| title = Exact Recovery in the Stochastic Block Model|eprint= 1405.3267| date = May 2014  | class = cs.SI}}&lt;/ref&gt;
&lt;ref name="as15a"&gt;{{cite arXiv| last1 = Abbe| first1 = Emmanuel| last2 = Sandon| first2 = Colin| title = Community detection in general stochastic block models: fundamental limits and efficient recovery algorithms|eprint= 1503.00609| date = March 2015  | class = math.PR}}&lt;/ref&gt;
&lt;ref name="as15b"&gt;{{cite arXiv| last1 = Abbe| first1 = Emmanuel| last2 = Sandon| first2 = Colin| title = Recovering communities in the general stochastic block model without knowing the parameters|eprint= 1506.03729|  date = June 2015  | class = math.PR}}&lt;/ref&gt;
&lt;ref name="lr15"&gt;{{Cite journal| doi = 10.1214/14-AOS1274| issn = 0090-5364| volume = 43| issue = 1| pages = 215–237| last1 = Lei| first1 = Jing| last2 = Rinaldo| first2 = Alessandro| title = Consistency of spectral clustering in stochastic block models| journal = The Annals of Statistics| date = February 2015 | arxiv = 1312.2050}}&lt;/ref&gt;
&lt;ref name="gbm"&gt;{{Cite journal| last1 = Galhotra| first1 = Sainyam| last2 = Mazumdar| first2 = Arya| last3 = Pal| first3 = Soumyabrata| 
last4 = Saha| first4 = Barna| title = The Geometric Block Model| journal = AAAI| date = February 2018 | arxiv = 1709.05510}}&lt;/ref&gt;
&lt;ref name="krzakala-pnas"&gt;{{cite journal| 
last1 = Krzakala| first1 = Florent| 
last2 = Moore| first2 = Cristopher|
last3 = Mossel| first3 = Elchanan| 
last4 = Neeman| first4 = Joe| 
last5 = Sly| first5 = Allan| 
last6 = Lenka| first6 = Lenka| 
last7 = Zhang| first7 = Pan| 
title = Spectral redemption in clustering sparse networks | journal = Proceedings of the National Academy of Sciences| date = October 2013 | doi = 10.1073/pnas.1312486110 |arxiv = 1306.5550|bibcode = 2013PNAS..11020935K | volume=110 | issue = 52| pages=20935–20940| pmid = 24277835| pmc = 3876200}}&lt;/ref&gt;
&lt;ref name="mns12"&gt;{{cite arXiv| last1 = Mossel| first1 = Elchanan| last2 = Neeman| first2 = Joe| last3 = Sly| first3 = Allan| title = Stochastic Block Models and Reconstruction|eprint= 1202.1499|  date = February 2012  | class = math.PR}}&lt;/ref&gt;
&lt;ref name="mns13"&gt;{{cite journal| last1 = Mossel| first1 = Elchanan| last2 = Neeman| first2 = Joe| last3 = Sly| first3 = Allan| title = Belief Propagation, Robust Reconstruction, and Optimal Recovery of Block Models| journal = The Annals of Applied Probability|arxiv= 1309.1380| date = September 2013 | volume = 26| issue = 4| pages = 2211–2256| doi = 10.1214/15-AAP1145| bibcode = 2013arXiv1309.1380M}}&lt;/ref&gt;
&lt;ref name="mas13"&gt;{{cite arXiv| last = Massoulie| first = Laurent| title = Community detection thresholds and the weak Ramanujan property|eprint= 1311.3085| date = November 2013 | class = cs.SI}}&lt;/ref&gt;
&lt;ref name="al14"&gt;{{cite arXiv| last1 = Amini| first1 = Arash A.| last2 = Levina| first2 = Elizaveta|author2-link= Elizaveta Levina| title = On semidefinite relaxations for the block model|eprint= 1406.5647|  date = June 2014 | class = cs.LG}}&lt;/ref&gt;
&lt;ref name="ar1"&gt;{{cite journal| 
last1 = Airoldi| first1 = Edoardo|authorlink1=Edoardo Airoldi| 
last2 = Blei| first2 = David|
last3 = Feinberg| first3 = Stephen| 
last4 = Xing| first4 = Eric| 
title = Mixed membership stochastic blockmodels| journal = Journal of Machine Learning Research : JMLR|arxiv = 0705.4485|  date = May 2007  | volume = 9| pages = 1981–2014| pmid = 21701698| pmc = 3119541| bibcode = 2007arXiv0705.4485A}}&lt;/ref&gt;
&lt;ref name="fat19"&gt;{{cite arXiv| last = Fathi| first = Reza| title = Efficient Distributed Community Detection in the Stochastic Block Model|eprint= 1904.07494| date = April 2019 | class = cs.DC}}&lt;/ref&gt;
}}

[[Category:Machine learning]]
[[Category:Random graphs]]
[[Category:Networks]]</text>
      <sha1>iqcow57ovx6pwtl74gfv2rsc31c1h0p</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Machine learning task</title>
    <ns>14</ns>
    <id>47991509</id>
    <revision>
      <id>982070220</id>
      <parentid>683599642</parentid>
      <timestamp>2020-10-06T00:36:37Z</timestamp>
      <contributor>
        <username>Allforrous</username>
        <id>12120664</id>
      </contributor>
      <comment>Commonscat template.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="83" xml:space="preserve">{{Commonscat}}

Category for machine learning tasks.

[[Category:Machine learning]]</text>
      <sha1>3ptq50jsino1mzevq89hfwgsb053bz9</sha1>
    </revision>
  </page>
  <page>
    <title>Relational data mining</title>
    <ns>0</ns>
    <id>926722</id>
    <revision>
      <id>913181387</id>
      <parentid>871007663</parentid>
      <timestamp>2019-08-30T12:42:17Z</timestamp>
      <contributor>
        <username>Jarble</username>
        <id>7226930</id>
      </contributor>
      <comment>adding links to references using [[Google Scholar]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2996" xml:space="preserve">'''Relational data mining''' is the [[data mining]] technique for relational
databases.&lt;ref&gt;Dzeroski, Saso, Lavrač, Nada (Eds.), Relational Data Mining, Springer 2001 [https://www.springer.com/computer/database+management+%26+information+retrieval/book/978-3-540-42289-1]&lt;/ref&gt; Unlike traditional data mining algorithms, which look for
patterns in a single table ([[propositional patterns]]), 
relational data mining algorithms look for patterns among multiple tables
([[relational patterns]]). For most types of propositional
patterns, there are corresponding relational patterns. For example,
there are relational [[classification rule]]s ('''relational classification'''), relational [[Decision tree learning|regression tree]], and relational [[association rule]]s&lt;!-- minor weasel words follow but left as a prompt in case some one can add actual information:, and so on--&gt;.

There are several approaches to relational data mining:
# [[Inductive_logic_programming|Inductive Logic Programming]] (ILP)
# [[Statistical_relational_learning|Statistical Relational Learning]] (SRL)
# Graph Mining
# Propositionalization
# Multi-view learning

==Algorithms==
'''Multi-Relation Association Rules''': Multi-Relation Association Rules (MRAR) is a new class of association rules which in contrast to primitive, simple and even multi-relational association rules (that are usually extracted from multi-relational databases), each rule item consists of one entity but several relations. These relations indicate indirect relationship between the entities. Consider the following MRAR where the first item consists of three relations ''live in'', ''nearby'' and ''humid'': “Those who ''live in'' a place which is ''near by'' a city with ''humid'' climate type and also are ''younger'' than 20 -&gt; their ''health condition'' is good”. Such association rules are extractable from RDBMS data or semantic web data.&lt;ref name="MRAR: Mining Multi-Relation Association Rules"&gt;Ramezani, Reza, Mohamad Saraee, and Mohammad Ali Nematbakhsh; ''[http://usir.salford.ac.uk/id/eprint/42504/1/MRAR_Saraee.pdf MRAR: Mining Multi-Relation Association Rules]'', Journal of Computing and Security, 1, no. 2 (2014)&lt;/ref&gt;

==Software==
* [http://www.kiminkii.com/safarii.html Safarii]: a Data Mining environment for analysing large relational databases based on a multi-relational data mining engine.
* [http://www.dataconda.net Dataconda]: a software, free for research and teaching purposes, that helps mining relational databases without the use of SQL.

==Datasets==
* [http://relational.fit.cvut.cz Relational dataset repository]: a collection of publicly available relational datasets.

==See also==
*[[Data mining]]
*[[Structure mining]]
*[[Database mining]]

==References==
{{Reflist}}

== External links ==
* [http://www-ai.ijs.si/SasoDzeroski/RDMBook/ Web page for a text book on relational data mining]


[[Category:Machine learning]]
[[Category:Data processing]]
[[Category:Relational model]]


{{database-stub}}</text>
      <sha1>nui7qrg6pt2lptk84wrl2wtdzle6l2s</sha1>
    </revision>
  </page>
  <page>
    <title>The Master Algorithm</title>
    <ns>0</ns>
    <id>47937215</id>
    <revision>
      <id>997403241</id>
      <parentid>976222837</parentid>
      <timestamp>2020-12-31T09:45:18Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 7 templates: del empty params (5×); hyphenate params (6×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="5338" xml:space="preserve">{{short description|Book by Pedro Domingos}}
{{infobox book|&lt;!-- See Wikipedia:WikiProject_Novels or Wikipedia:WikiProject_Books --&gt;
| name = The Master Algorithm:&lt;br /&gt; How the Quest for the Ultimate Learning Machine Will Remake Our World
| image = 'The_Master_Algorithm'_2016_-_book_cover.jpg
| caption = 
| border = yes
| author = [[Pedro Domingos]]
| country = United States
| genre = [[Philosophy]], [[popular science]]
| subject = [[Artificial intelligence]]
| language = English
| publisher = [[Basic Books]]
| release_date = September 22, 2015
| media_type = Print, e-book, audiobook
| pages = 352 pp.
| isbn = 978-0465065707
| preceded_by = 
}}

'''''The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World''''' is a book by [[Pedro Domingos]] released in 2015. Domingos wrote the book in order to generate interest from people outside the field.

==Overview==
The book outlines five tribes of machine learning: [[inductive reasoning]], [[connectionism]], [[evolutionary computation]], [[Bayes' theorem]] and [[Analogical modeling|analogical modelling]]. The author explains these tribes to the reader by referring to more understandable processes of [[logic]], connections made in the [[brain]], [[natural selection]], [[probability]] and [[Similarity (psychology)|similarity]] judgements. Throughout the book, it is suggested that each different tribe has the potential to contribute to a unifying "master algorithm".

Towards the end of the book the author pictures a "master [[algorithm]]" in the near future, where [[machine learning algorithm]]s asymptotically grow to a perfect understanding of how the world and people in it work.&lt;ref name="MyUser_Slate.com_September_26_2015c"&gt;{{cite web|url=http://www.slate.com/articles/technology/bitwise/2015/09/pedro_domingos_master_algorithm_how_machine_learning_is_reshaping_how_we.2.html|title=Pedro Domingos' Master Algorithm: How machine learning is reshaping how we live.|access-date=September 26, 2015|newspaper=Slate.com}}&lt;/ref&gt; Although the algorithm doesn't yet exist, he briefly reviews his own invention of the [[Markov logic network]].&lt;ref name="Dom2015"&gt;{{cite book|title=The Master Algorithm: How machine learning is reshaping how we live.|last=Domingos|first=Pedro|date=2015|pages=246–7}}&lt;/ref&gt;

==In the media==
In 2016 [[Bill Gates]] recommended the book, alongside [[Nick Bostrom]]'s ''[[Superintelligence (book)|Superintelligence]]'', as one of two books everyone should read to understand AI.&lt;ref&gt;{{cite news|last1=Ha|first1=Thu-Huong|title=Bill Gates says these are the two books we should all read to understand AI|url=https://qz.com/698334/bill-gates-says-these-are-the-two-books-we-should-all-read-to-understand-ai/|access-date=4 March 2018|work=Quartz|date=2016}}&lt;/ref&gt; In 2018 the book was noted to be on Chinese President [[Xi Jinping]]'s bookshelf.&lt;ref&gt;{{cite news|last1=Huang|first1=Zheping|title=The two books helping China's Xi Jinping understand artificial intelligence|url=https://qz.com/1170185/the-master-algorithm-and-augmented-the-two-books-helping-chinas-xi-jinping-understand-ai/|access-date=4 March 2018|work=Quartz|date=2018}}&lt;/ref&gt;

===Reception===
A computer science educator stated in ''[[Times Higher Education]]'' that the examples are clear and accessible.&lt;ref&gt;{{cite news|title=The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World, by Pedro Domingos|url=https://www.timeshighereducation.com/books/review-the-master-algorithm-pedro-domingos-allen-lane|access-date=4 March 2018|work=Times Higher Education (THE)|date=17 September 2015|language=en}}&lt;/ref&gt; In contrast, ''[[The Economist]]'' agreed Domingos "does a good job" but complained that he "constantly invents metaphors that grate or confuse".&lt;ref&gt;"Machines for thinking: artificial intelligence." The Economist, 3 Oct. 2015, p. 86(US).&lt;/ref&gt; ''[[Kirkus Reviews]]'' praised the book, stating that "Readers unfamiliar with logic and computer theory will have a difficult time, but those who persist will discover fascinating insights."&lt;ref&gt;{{cite news|title=THE MASTER ALGORITHM by Pedro Domingos {{!}} Kirkus Reviews|url=https://www.kirkusreviews.com/book-reviews/pedro-domingos/the-master-algorithm/|access-date=4 March 2018|date=2015|language=en-us}}&lt;/ref&gt;

A ''[[New Scientist]]'' review called it "compelling but rather unquestioning".&lt;ref&gt;{{cite news|title=&lt;em&gt;The Master Algorithm&lt;/em&gt;: A world remade by machines that learn|url=https://www.newscientist.com/article/mg22830450-900-the-master-algorithm-a-world-remade-by-machines-that-learn/|access-date=4 March 2018|work=New Scientist|date=2015}}&lt;/ref&gt;

==References==
{{Reflist}}

* https://www.wsj.com/articles/the-sum-of-human-knowledge-1442610803
* http://www.kdnuggets.com/2015/09/book-master-algorithm-pedro-domingos.html
* http://www.kdnuggets.com/2014/08/interview-pedro-domingos-master-algorithm-new-deep-learning.html (interview)

== External links ==
* {{official website|https://www.basicbooks.com/titles/pedro-domingos/the-master-algorithm/9780465061921/}}

{{DEFAULTSORT:Master Algorithm}}
[[Category:Machine learning]]
[[Category:2015 non-fiction books]]


{{tech-book-stub}}
[[Category:Computer science books]]
[[Category:Algorithms]]
[[Category:Philosophy of computer science]]
[[Category:Philosophy of artificial intelligence]]</text>
      <sha1>4l9qn06ufyemj9399hdmkbswfh0a3wy</sha1>
    </revision>
  </page>
  <page>
    <title>Committee machine</title>
    <ns>0</ns>
    <id>9583985</id>
    <revision>
      <id>977678578</id>
      <parentid>796476989</parentid>
      <timestamp>2020-09-10T08:40:39Z</timestamp>
      <contributor>
        <ip>62.91.78.226</ip>
      </contributor>
      <comment>/* Dynamic structures */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1844" xml:space="preserve">A '''committee machine''' is a type of [[artificial neural network]] using a [[Divide and rule|divide and conquer]] strategy in which the responses of multiple neural networks (experts) are combined into a single response.&lt;ref&gt;HAYKIN, S. Neural Networks - A Comprehensive Foundation. Second edition. Pearson Prentice Hall: 1999.&lt;/ref&gt;  The combined response of the committee machine is supposed to be superior to those of its constituent experts.  Compare with [[ensembles of classifiers]].

== Types ==

===Static structures===
In this class of committee machines, the responses of several predictors (experts) are combined by means of a mechanism that does not involve the input signal, hence the designation static. This category includes  the following methods:
*[[Ensemble averaging]]
In ensemble averaging, outputs of different predictors are linearly combined to produce an overall output.
*[[Boosting (meta-algorithm)|Boosting]]
In boosting, a weak algorithm is converted into one that achieves arbitrarily high accuracy.

===Dynamic structures===
In this second class of committee machines, the input signal is directly involved in actuating the mechanism that integrates the outputs of the individual experts into an overall output, hence the designation dynamic. There are two kinds of dynamic structures:
*[[Mixture of experts]]
In mixture of experts, the individual responses of the experts are non-linearly combined by means of a single gating network.
*Hierarchical mixture of experts
In hierarchical mixture of experts, the individual responses of the individual experts are non-linearly combined by means of several gating networks arranged in a hierarchical fashion.

== References ==
{{Reflist}}

[[Category:Artificial neural networks]]
[[Category:Machine learning]]
[[Category:Learning]]
[[Category:Artificial intelligence]]</text>
      <sha1>0ayzex2tjua79tfi5n6ly01r73rp2xz</sha1>
    </revision>
  </page>
  <page>
    <title>Matrix regularization</title>
    <ns>0</ns>
    <id>44628821</id>
    <revision>
      <id>994066325</id>
      <parentid>985708710</parentid>
      <timestamp>2020-12-13T23:04:08Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 9 templates: del empty params (3×); hyphenate params (2×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="14739" xml:space="preserve">In the field of [[statistical learning theory]], '''matrix regularization''' generalizes notions of vector regularization to cases where the object to be learned is a matrix. The purpose of regularization is to enforce conditions, for example sparsity or smoothness, that can produce stable predictive functions. For example, in the more common vector framework, [[Tikhonov regularization]] optimizes over

: &lt;math&gt;\min_x \|Ax - y\|^2 + \lambda \|x\|^2&lt;/math&gt;

to find a vector &lt;math&gt;x&lt;/math&gt; that is a stable solution to the regression problem. When the system is described by a matrix rather than a vector, this problem  can be written as

: &lt;math&gt;\min_X \|AX - Y\|^2 + \lambda \|X\|^2,&lt;/math&gt;

where the vector norm enforcing a regularization penalty on &lt;math&gt;x&lt;/math&gt; has been extended to a matrix norm on &lt;math&gt;X&lt;/math&gt;.

Matrix regularization has applications in [[matrix completion]], [[multivariate regression]], and [[multi-task learning]]. Ideas of feature and group selection can also be extended to matrices, and these can be generalized to the nonparametric case of [[multiple kernel learning]].

== Basic definition ==

Consider a matrix &lt;math&gt;W&lt;/math&gt; to be learned from a set of examples, &lt;math&gt;S=(X_i^t,y_i^t)&lt;/math&gt;, where &lt;math&gt;i&lt;/math&gt; goes from &lt;math&gt;1&lt;/math&gt; to &lt;math&gt;n&lt;/math&gt;, and &lt;math&gt;t&lt;/math&gt; goes from &lt;math&gt;1&lt;/math&gt; to &lt;math&gt;T&lt;/math&gt;. Let each input matrix &lt;math&gt;X_i&lt;/math&gt; be &lt;math&gt;\in \mathbb{R}^{DT}&lt;/math&gt;, and let &lt;math&gt;W&lt;/math&gt; be of size &lt;math&gt;D \times T&lt;/math&gt;. A general model for the output &lt;math&gt;y&lt;/math&gt; can be posed as

: &lt;math&gt;y_i^t = \langle W, X_i^t \rangle_F,&lt;/math&gt;

where the inner product is the [[Frobenius inner product]]. For different applications the matrices &lt;math&gt;X_i&lt;/math&gt; will have different forms,&lt;ref name=Notes&gt;{{cite book |first=Lorenzo |last=Rosasco |first2=Tomaso |last2=Poggio |author-link2=Tomaso Poggio |chapter=A Regularization Tour of Machine Learning |title=MIT-9.520 Lectures Notes |type=Manuscript |date=December 2014 |url=https://www.mit.edu/~9.520/fall15/Classes/learning_problem.html }}&lt;/ref&gt; but for each of these the optimization problem to infer &lt;math&gt;W&lt;/math&gt; can be written as

: &lt;math&gt;\min_{W \in \mathcal{H}} E(W) + R(W),&lt;/math&gt;

where &lt;math&gt;E&lt;/math&gt; defines the empirical error for a given &lt;math&gt;W&lt;/math&gt;, and &lt;math&gt;R(W)&lt;/math&gt; is a matrix regularization penalty. The function &lt;math&gt;R(W)&lt;/math&gt; is typically chosen to be convex and is often selected to enforce sparsity (using &lt;math&gt;\ell^1&lt;/math&gt;-norms) and/or smoothness (using &lt;math&gt;\ell^2&lt;/math&gt;-norms). Finally, &lt;math&gt;W&lt;/math&gt; is in the space of matrices &lt;math&gt;\mathcal{H}&lt;/math&gt; with Frobenius inner product &lt;math&gt;\langle \dots \rangle_F&lt;/math&gt;.

== General applications ==

=== Matrix completion ===

In the problem of [[matrix completion]], the matrix &lt;math&gt;X_i^t&lt;/math&gt; takes the form

: &lt;math&gt;X_i^t = e_t \otimes e_i',&lt;/math&gt;

where &lt;math&gt;(e_t)_t&lt;/math&gt; and &lt;math&gt;(e_i')_i&lt;/math&gt; are the canonical basis in &lt;math&gt;\mathbb{R}^T&lt;/math&gt; and &lt;math&gt;\mathbb{R}^D&lt;/math&gt;. In this case the role of the Frobenius inner product is to select individual elements &lt;math&gt;w_i^t&lt;/math&gt; from the matrix &lt;math&gt;W&lt;/math&gt;. Thus, the output &lt;math&gt;y&lt;/math&gt; is a sampling of entries from the matrix &lt;math&gt;W&lt;/math&gt;.

The problem of reconstructing &lt;math&gt;W&lt;/math&gt; from a small set of sampled entries is possible only under certain restrictions on the matrix, and these restrictions can be enforced by a regularization function. For example, it might be assumed that &lt;math&gt;W&lt;/math&gt; is low-rank, in which case the regularization penalty can take the form of a nuclear norm.&lt;ref name="Candès, Emmanuel J 2009 pp. 717"&gt;{{cite journal |title=Exact Matrix Completion via Convex Optimization |last=Candès |first=Emmanuel J. |author-link=Emmanuel Candès |last2=Recht |first2=Benjamin |year=2009 |journal=Foundations of Computational Mathematics |volume=9 |issue=6 |pages=717–772 |doi=10.1007/s10208-009-9045-5 |doi-access=free }}&lt;/ref&gt;

: &lt;math&gt;R(W) = \lambda \|W\|_* = \lambda \sum |\sigma_i|,&lt;/math&gt;

where &lt;math&gt;\sigma_i&lt;/math&gt;, with &lt;math&gt;i&lt;/math&gt; from &lt;math&gt;1&lt;/math&gt; to &lt;math&gt;\min D, T&lt;/math&gt;, are the singular values of &lt;math&gt;W&lt;/math&gt;.

=== Multivariate regression ===

Models used in [[multivariate regression]] are parameterized by a matrix of coefficients. In the Frobenius inner product above, each matrix &lt;math&gt;X&lt;/math&gt; is

: &lt;math&gt;X_i^t=e_t\otimes x_i \, &lt;/math&gt;

such that the output of the inner product is the dot product of one row of the input with one column of the coefficient matrix. The familiar form of such models is

: &lt;math&gt;Y=XW+b \, &lt;/math&gt;

Many of the vector norms used in single variable regression can be extended to the multivariate case. One example is the squared Frobenius norm, which can be viewed as an &lt;math&gt;\ell^2&lt;/math&gt;-norm acting either entrywise, or on the singular values of the matrix:

: &lt;math&gt;R(W)=\lambda \|W\|_F^2=\lambda \sum\sum |w_{ij}|^2=\lambda \operatorname{Tr}(W^*W)=\lambda \sum \sigma_i^2.&lt;/math&gt;

In the multivariate case the effect of regularizing with the Frobenius norm is the same as the vector case; very complex models will have larger norms, and, thus, will be penalized more.

=== Multi-task learning ===

The setup for multi-task learning is almost the same as the setup for multivariate regression. The primary difference is that the input variables are also indexed by task (columns of &lt;math&gt;Y&lt;/math&gt;). The representation with the Frobenius inner product is then

: &lt;math&gt;X_i^t=e_t\otimes x_i^t.&lt;/math&gt;

The role of matrix regularization in this setting can be the same as in multivariate regression, but matrix norms can also be used to couple learning problems across tasks. In particular, note that for the optimization problem

: &lt;math&gt;\min_W \|XW-Y\|_2^2 + \lambda \|W\|_2^2&lt;/math&gt;

the solutions corresponding to each column of &lt;math&gt;Y&lt;/math&gt; are decoupled. That is, the same solution can be found by solving the joint problem, or by solving an isolated regression problem for each column. The problems can be coupled by adding an additional regulatization penalty on the covariance of solutions

: &lt;math&gt;\min_{W,\Omega} \|XW-Y\|_2^2 + \lambda_1 \|W\|_2^2 + \lambda_2 \operatorname{Tr}(W^T \Omega^{-1} W)&lt;/math&gt;

where &lt;math&gt;\Omega&lt;/math&gt; models the relationship between tasks. This scheme can be used to both enforce similarity of solutions across tasks, and to learn the specific structure of task similarity by alternating between optimizations of &lt;math&gt;W&lt;/math&gt; and &lt;math&gt;\Omega&lt;/math&gt;.&lt;ref&gt;{{cite paper |last=Zhang |last2=Yeung |date=2012 |arxiv=1203.3536 |title=A Convex Formulation for Learning Task Relationships in Multi-Task Learning |work=Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial Intelligence (UAI2010) |bibcode=2012arXiv1203.3536Z }}&lt;/ref&gt; When the relationship between tasks is known to lie on a graph, the [[Laplacian matrix]] of the graph can be used to couple the learning problems.

== Spectral regularization ==

[[Regularization by spectral filtering]] has been used to find stable solutions to problems such as those discussed above by addressing ill-posed matrix inversions (see for example  [[Regularization by spectral filtering#Filter function for Tikhonov regularization|Filter function for Tikhonov regularization]]). In many cases the regularization function acts on the input (or kernel) to ensure a bounded inverse by eliminating small singular values, but it can also be useful to have spectral norms that act on the matrix that is to be learned.

There are a number of matrix norms that act on the singular values of the matrix. Frequently used examples include the [[Schatten norm|Schatten p-norms]], with ''p''&amp;nbsp;=&amp;nbsp;1&amp;nbsp;or&amp;nbsp;2. For example, matrix regularization with a Schatten 1-norm, also called the nuclear norm, can be used to enforce sparsity in the spectrum of a matrix. This has been used in the context of matrix completion when the matrix in question is believed to have a restricted rank.&lt;ref name="Candès, Emmanuel J 2009 pp. 717"/&gt; In this case the optimization problem becomes:

: &lt;math&gt;\min \|W\|_*&lt;/math&gt; subject to &lt;math&gt;W_{i,j}=Y_{ij}.&lt;/math&gt;

Spectral Regularization is also used to enforce a reduced rank coefficient matrix in multivariate regression.&lt;ref&gt;{{cite journal |first=Alan J. |last=Izenman |title=Reduced Rank Regression for the Multivariate Linear Model |journal=[[Journal of Multivariate Analysis]] |volume=5 |issue=2 |pages=248–264 |year=1975 |doi=10.1016/0047-259X(75)90042-1 }}&lt;/ref&gt; In this setting, a reduced rank coefficient matrix can be found by keeping just the top &lt;math&gt;n&lt;/math&gt; singular values, but this can be extended to keep any reduced set of singular values and vectors.

== Structured sparsity ==

Sparse optimization has become the focus of much research interest as a way to find solutions that depend on a small number of variables (see e.g. the  [[Lasso (statistics)|Lasso method]]). In principle, entry-wise sparsity can be enforced by penalizing the entry-wise &lt;math&gt;\ell^0&lt;/math&gt;-norm of the matrix, but the &lt;math&gt;\ell^0&lt;/math&gt;-norm is not convex. In practice this can be implemented by convex relaxation to the &lt;math&gt;\ell^1&lt;/math&gt;-norm. While entry-wise regularization with an &lt;math&gt;\ell^1&lt;/math&gt;-norm will find solutions with a small number of nonzero elements, applying an &lt;math&gt;\ell^1&lt;/math&gt;-norm to different groups of variables can enforce structure in the sparsity of solutions.&lt;ref&gt;{{cite journal |last=Kakade |last2=Shalev-Shwartz |last3=Tewari |title=Regularization Techniques for Learning with Matrices |journal=Journal of Machine Learning Research |volume=13 |year=2012 |pages=1865–1890 |url=http://www.jmlr.org/papers/v13/kakade12a.html }}&lt;/ref&gt;

The most straightforward example of structured sparsity uses the &lt;math&gt;\ell_{p,q}&lt;/math&gt; norm with &lt;math&gt;p=2&lt;/math&gt; and &lt;math&gt;q=1&lt;/math&gt;:

: &lt;math&gt;\|W\|_{2,1}=\sum \|w_i\|_2.&lt;/math&gt;

For example, the &lt;math&gt;\ell_{2,1}&lt;/math&gt; norm is used in multi-task learning to group features across tasks, such that all the elements in a given row of the coefficient matrix can be forced to zero as a group.&lt;ref&gt;{{cite journal |first=A. |last=Argyriou |first2=T. |last2=Evgeniou |first3=M. |last3=Pontil |doi=10.1007/s10994-007-5040-8 |title=Convex multi-task feature learning |journal=[[Machine Learning (journal)|Machine Learning]] |volume=73 |issue=3 |pages=243–272 |year=2008 |doi-access=free }}&lt;/ref&gt; The grouping effect is achieved by taking the &lt;math&gt;\ell^2&lt;/math&gt;-norm of each row, and then taking the total penalty to be the sum of these row-wise norms. This regularization results in rows that will tend to be all zeros, or dense. The same type of regularization can be used to enforce sparsity column-wise by taking the &lt;math&gt;\ell^2&lt;/math&gt;-norms of each column.

More generally, the &lt;math&gt;\ell_{2,1}&lt;/math&gt; norm can be applied to arbitrary groups of variables:

: &lt;math&gt;R(W)=\lambda \sum_g^G \sqrt{\sum_j^{|G_g|} |w_g^j|^2}=\lambda \sum_g^G \|w_g\|_g&lt;/math&gt;

where the index &lt;math&gt;g&lt;/math&gt; is across groups of variables, and &lt;math&gt;|G_g|&lt;/math&gt; indicates the cardinality of group &lt;math&gt;g&lt;/math&gt;.

Algorithms for solving these group sparsity problems extend the more well-known Lasso and group Lasso methods by allowing overlapping groups, for example, and have been implemented via [[matching pursuit]]:&lt;ref&gt;{{cite journal |last=Huang |last2=Zhang |last3=Metaxas |title=Learning with Structured Sparsity |journal=Journal of Machine Learning Research |volume=12 |year=2011 |pages=3371–3412 |url=http://www.jmlr.org/papers/v12/huang11b.html }}&lt;/ref&gt; and [[proximal gradient method]]s.&lt;ref&gt;{{cite journal |last=Chen |first=Xi |first2=Qihang |last2=Lin |first3=Seyoung |last3=Kim |first4=Jaime G. |last4=Carbonell |first5=Eric P. |last5=Xing |display-authors=1 |title=Smoothing Proximal Gradient Method for General Structured Sparse Regression |journal=Annals of Applied Statistics |year=2012 |volume=6 |issue=2 |pages=719–752 |doi=10.1214/11-AOAS514 |doi-access=free }}&lt;/ref&gt; By writing the proximal gradient with respect to a given coefficient, &lt;math&gt;w_g^i&lt;/math&gt;, it can be seen that this norm enforces a group-wise soft threshold&lt;ref name=Notes /&gt;

: &lt;math&gt;\operatorname{prox}_{\lambda,R_g}(w_g)^i=\left(w_g^i-\lambda \frac{w_g^i}{\|w_g\|_g}\right)\mathbf{1}_{\|w_g\|_g\geq \lambda}.&lt;/math&gt;

where &lt;math&gt;\mathbf{1}_{\|w_g\|_g\geq \lambda}&lt;/math&gt; is the indicator function for group norms &lt;math&gt;\geq \lambda&lt;/math&gt;.

Thus, using &lt;math&gt;\ell_{2,1}&lt;/math&gt; norms it is straightforward to enforce structure in the sparsity of a matrix either row-wise, column-wise, or in arbitrary blocks. By enforcing group norms on blocks in multivariate or multi-task regression, for example, it is possible to find groups of input and output variables, such that defined subsets of output variables (columns in the matrix &lt;math&gt;Y&lt;/math&gt;) will depend on the same sparse set of input variables.

== Multiple kernel selection ==

The ideas of structured sparsity and [[feature selection]] can be extended to the nonparametric case of [[multiple kernel learning]].&lt;ref&gt;{{cite journal |last=Sonnenburg |last2=Ratsch |last3=Schafer |last4=Scholkopf |title=Large Scale Multiple Kernel Learning |journal=Journal of Machine Learning Research |volume=7 |year=2006 |pages=1531–1565 |url=http://www.jmlr.org/papers/v7/sonnenburg06a.html }}&lt;/ref&gt; This can be useful when there are multiple types of input data (color and texture, for example) with different appropriate kernels for each, or when the appropriate kernel is unknown. If there are two kernels, for example, with feature maps &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt; that lie in corresponding [[reproducing kernel Hilbert space]]s &lt;math&gt;\mathcal{H_A},\mathcal{H_B}&lt;/math&gt;, then a larger space, &lt;math&gt;\mathcal{H_D}&lt;/math&gt;, can be created as the sum of two spaces:

: &lt;math&gt;\mathcal{H_D}: f=h+h'; h\in \mathcal{H_A}, h'\in \mathcal{H_B}&lt;/math&gt;

assuming linear independence in &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt;. In this case the &lt;math&gt;\ell_{2,1}&lt;/math&gt;-norm is again the sum of norms:

: &lt;math&gt;\|f\|_{\mathcal{H_D},1}=\|h\|_{\mathcal{H_A}}+\|h'\|_{\mathcal{H_B}}&lt;/math&gt;

Thus, by choosing a matrix regularization function as this type of norm, it is possible to find a solution that is sparse in terms of which kernels are used, but dense in the coefficient of each used kernel. Multiple kernel learning can also be used as a form of nonlinear variable selection, or as a model aggregation technique (e.g. by taking the sum of squared norms and relaxing sparsity constraints). For example, each kernel can be taken to be the Gaussian kernel with a different width.

== See also ==
* [[Regularization (mathematics)]]

== References ==
{{reflist}}

[[Category:Estimation theory]]
[[Category:Machine learning]]
[[Category:Matrices]]</text>
      <sha1>mdg8dtgkjh2w5kydf9sk11u2cjc7krx</sha1>
    </revision>
  </page>
  <page>
    <title>Manifold regularization</title>
    <ns>0</ns>
    <id>48777199</id>
    <revision>
      <id>1000158791</id>
      <parentid>978038473</parentid>
      <timestamp>2021-01-13T21:47:11Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 27 templates: hyphenate params (12×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="26724" xml:space="preserve">[[File:Example of unlabeled data in semisupervised learning.png|thumb|250px|Manifold regularization can classify data when labeled data (black and white circles) are sparse, by taking advantage of unlabeled data (gray circles). Without many labeled data points, [[supervised learning]] algorithms can only learn very simple decision boundaries (top panel). Manifold learning can draw a decision boundary between the natural classes of the unlabeled data, under the assumption that close-together points probably belong to the same class, and so the decision boundary should avoid areas with many unlabeled points. This is one version of [[semi-supervised learning]].]]

In [[machine learning]], '''Manifold regularization''' is a technique for using the shape of a dataset to constrain the functions that should be learned on that dataset. In many machine learning problems, the data to be learned do not cover the entire input space. For example, a [[facial recognition system]] may not need to classify any possible image, but only the subset of images that contain faces. The technique of manifold learning assumes that the relevant subset of data comes from a [[manifold]], a mathematical structure with useful properties. The technique also assumes that the function to be learned is ''smooth'': data with different labels are not likely to be close together, and so the labeling function should not change quickly in areas where there are likely to be many data points. Because of this assumption, a manifold regularization algorithm can use unlabeled data to inform where the learned function is allowed to change quickly and where it is not, using an extension of the technique of [[Tikhonov regularization]]. Manifold regularization algorithms can extend [[supervised learning]] algorithms in [[semi-supervised learning]] and [[Transduction (machine learning)|transductive learning]] settings, where unlabeled data are available. The technique has been used for applications including medical imaging, geographical imaging, and object recognition.

== Manifold regularizer ==

=== Motivation ===

Manifold regularization is a type of [[Regularization (mathematics)|regularization]], a family of techniques that reduces [[overfitting]] and ensures that a problem is [[well-posed problem|well-posed]] by penalizing complex solutions. In particular, manifold regularization extends the technique of [[Tikhonov regularization]] as applied to [[Reproducing kernel Hilbert spaces]] (RKHSs). Under standard Tikhonov regularization on RKHSs, a learning algorithm attempts to learn a function &lt;math&gt;f&lt;/math&gt; from among a hypothesis space of functions &lt;math&gt;\mathcal{H}&lt;/math&gt;. The hypothesis space is an RKHS, meaning that it is associated with a [[Kernel method|kernel]] &lt;math&gt;K&lt;/math&gt;, and so every candidate function &lt;math&gt;f&lt;/math&gt; has a [[Norm (mathematics)|norm]] &lt;math&gt;\left\| f \right\|_K&lt;/math&gt;, which represents the complexity of the candidate function in the hypothesis space. When the algorithm considers a candidate function, it takes its norm into account in order to penalize complex functions.

Formally, given a set of labeled training data &lt;math&gt;(x_1, y_1), \ldots, (x_{\ell}, y_{\ell})&lt;/math&gt; with &lt;math&gt;x_i \in X, y_i \in Y&lt;/math&gt; and a [[loss function]] &lt;math&gt;V&lt;/math&gt;, a learning algorithm using Tikhonov regularization will attempt to solve the expression

: &lt;math&gt; \underset{f \in \mathcal{H}}{\arg\!\min} \frac{1}{\ell} \sum_{i=1}^{\ell} V(f(x_i), y_i) + \gamma \left\| f \right\|_K^2 &lt;/math&gt;

where &lt;math&gt;\gamma&lt;/math&gt; is a [[Hyperparameter optimization|hyperparameter]] that controls how much the algorithm will prefer simpler functions to functions that fit the data better.

[[File:Lle hlle swissroll.png|thumb|right|300px|A two-dimensional [[manifold]] embedded in three-dimensional space (top-left). Manifold regularization attempts to learn a function that is smooth on the unrolled manifold (top-right).]]

Manifold regularization adds a second regularization term, the ''intrinsic regularizer'', to the ''ambient regularizer'' used in standard Tikhonov regularization. Under the [[Semi-supervised learning#Manifold assumption|manifold assumption]] in machine learning, the data in question do not come from the entire input space &lt;math&gt;X&lt;/math&gt;, but instead from a nonlinear [[manifold]] &lt;math&gt;M\subset X&lt;/math&gt;. The geometry of this manifold, the intrinsic space, is used to determine the regularization norm.&lt;ref name="Belkin et al. 2006"&gt;{{Cite journal| volume = 7| pages = 2399–2434| last1 = Belkin| first1 = Mikhail| last2 = Niyogi| first2 = Partha| last3 = Sindhwani| first3 = Vikas| title = Manifold regularization: A geometric framework for learning from labeled and unlabeled examples| journal = The Journal of Machine Learning Research| access-date = 2015-12-02| date = 2006| url = http://dl.acm.org/citation.cfm?id=1248632}}&lt;/ref&gt;

=== Laplacian norm ===

There are many possible choices for &lt;math&gt;\left\| f \right\|_I&lt;/math&gt;. Many natural choices involve the [[Differential geometry|gradient on the manifold]] &lt;math&gt; \nabla_{M} &lt;/math&gt;, which can provide a measure of how smooth a target function is. A smooth function should change slowly where the input data are dense; that is, the gradient &lt;math&gt; \nabla_{M} f(x) &lt;/math&gt; should be small where the ''marginal probability density'' &lt;math&gt;\mathcal{P}_X(x) &lt;/math&gt;, the [[probability density]] of a randomly drawn data point appearing at &lt;math&gt;x&lt;/math&gt;, is large. This gives one appropriate choice for the intrinsic regularizer:

: &lt;math&gt; \left\| f \right\|_I^2 = \int_{x \in M} \left\| \nabla_{M} f(x) \right\|^2 \, d \mathcal{P}_X(x) &lt;/math&gt;

In practice, this norm cannot be computed directly because the marginal distribution &lt;math&gt;\mathcal{P}_X&lt;/math&gt; is unknown, but it can be estimated from the provided data. In particular, if the distances between input points are interpreted as a graph, then the [[Laplacian matrix]] of the graph can help to estimate the marginal distribution. Suppose that the input data include &lt;math&gt;\ell&lt;/math&gt; labeled examples (pairs of an input &lt;math&gt;x&lt;/math&gt; and a label &lt;math&gt;y&lt;/math&gt;) and &lt;math&gt;u&lt;/math&gt; unlabeled examples (inputs without associated labels). Define &lt;math&gt;W&lt;/math&gt; to be a matrix of edge weights for a graph, where &lt;math&gt;W_{ij}&lt;/math&gt; is a distance measure between the data points &lt;math&gt;x_i&lt;/math&gt; and &lt;math&gt;x_j&lt;/math&gt;. Define &lt;math&gt;D&lt;/math&gt; to be a diagonal matrix with &lt;math&gt;D_{ii} = \sum_{j=1}^{\ell + u} W_{ij}&lt;/math&gt; and &lt;math&gt;L&lt;/math&gt; to be the Laplacian matrix &lt;math&gt;D-W&lt;/math&gt;. Then, as the number of data points &lt;math&gt;\ell + u&lt;/math&gt; increases, &lt;math&gt;L&lt;/math&gt; converges to the [[Laplace–Beltrami operator]] &lt;math&gt;\Delta_{M}&lt;/math&gt;, which is the [[divergence]] of the gradient &lt;math&gt;\nabla_M&lt;/math&gt;.&lt;ref&gt;{{Cite book
| publisher = Springer
| pages = 470–485
| last1 = Hein
| first1 = Matthias
| last2 = Audibert
| first2 = Jean-Yves
| last3 = Von Luxburg
| first3 = Ulrike
| title = Learning theory
| volume = 3559
| chapter = From graphs to manifolds–weak and strong pointwise consistency of graph laplacians
| date = 2005
| doi = 10.1007/11503415_32
| series = Lecture Notes in Computer Science
| isbn = 978-3-540-26556-6
| citeseerx = 10.1.1.103.82
}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|
 publisher = Springer
| pages = 486–500
| last1 = Belkin
| first1 = Mikhail
| last2 = Niyogi
| first2 = Partha
| title = Learning theory
| volume = 3559
| chapter = Towards a theoretical foundation for Laplacian-based manifold methods
| date = 2005
| doi = 10.1007/11503415_33
| series = Lecture Notes in Computer Science
| isbn = 978-3-540-26556-6
| citeseerx = 10.1.1.127.795
}}&lt;/ref&gt; Then, if &lt;math&gt;\mathbf{f}&lt;/math&gt; is a vector of the values of &lt;math&gt;f&lt;/math&gt; at the data, &lt;math&gt;\mathbf{f} = [f(x_1), \ldots, f(x_{l+u})]^{\mathrm{T}}&lt;/math&gt;, the intrinsic norm can be estimated:

: &lt;math&gt; \left\| f \right\|_I^2 = \frac{1}{(\ell+u)^2} \mathbf{f}^{\mathrm{T}} L \mathbf{f} &lt;/math&gt;

As the number of data points &lt;math&gt;\ell + u&lt;/math&gt; increases, this empirical definition of &lt;math&gt; \left\| f \right\|_I^2&lt;/math&gt; converges to the definition when &lt;math&gt;\mathcal{P}_X&lt;/math&gt; is known.&lt;ref name="Belkin et al. 2006" /&gt;

=== Solving the regularization problem ===

Using the weights &lt;math&gt;\gamma_A&lt;/math&gt; and &lt;math&gt;\gamma_I&lt;/math&gt; for the ambient and intrinsic regularizers, the final expression to be solved becomes:

: &lt;math&gt; \underset{f \in \mathcal{H}}{\arg\!\min} \frac{1}{\ell} \sum_{i=1}^{\ell} V(f(x_i), y_i) + \gamma_A \left\| f \right\|_K^2 + \frac{\gamma_I}{(\ell+u)^2} \mathbf{f}^{\mathrm{T}} L \mathbf{f} &lt;/math&gt;

As with other [[kernel methods]], &lt;math&gt;\mathcal{H}&lt;/math&gt; may be an infinite-dimensional space, so if the regularization expression cannot be solved explicitly, it is impossible to search the entire space for a solution. Instead, a [[representer theorem]] shows that under certain conditions on the choice of the norm &lt;math&gt;\left\| f \right\|_I&lt;/math&gt;, the optimal solution &lt;math&gt;f^*&lt;/math&gt; must be a linear combination of the kernel centered at each of the input points: for some weights &lt;math&gt;\alpha_i&lt;/math&gt;,

: &lt;math&gt; f^*(x) = \sum_{i=1}^{\ell + u} \alpha_i K(x_i, x) &lt;/math&gt;

Using this result, it is possible to search for the optimal solution &lt;math&gt;f^*&lt;/math&gt; by searching the finite-dimensional space defined by the possible choices of &lt;math&gt;\alpha_i&lt;/math&gt;.&lt;ref name="Belkin et al. 2006" /&gt;

== Applications ==

Manifold regularization can extend a variety of algorithms that can be expressed using Tikhonov regularization, by choosing an appropriate loss function &lt;math&gt;V&lt;/math&gt; and hypothesis space &lt;math&gt;\mathcal{H}&lt;/math&gt;. Two commonly used examples are the families of [[support vector machines]] and [[Least squares#Regularized versions|regularized least squares]] algorithms. (Regularized least squares includes the ridge regression algorithm; the related algorithms of LASSO and [[elastic net regularization]] can be expressed as support vector machines.&lt;ref&gt;{{cite book
|title=An Equivalence between the Lasso and Support Vector Machines
|last=Jaggi|first=Martin
|editor-last1=Suykens|editor-first1=Johan
|editor-last2=Signoretto|editor-first2=Marco
|editor-last3=Argyriou|editor-first3=Andreas
|year=2014
|publisher=Chapman and Hall/CRC}}&lt;/ref&gt;&lt;ref&gt;
{{cite conference
|last1=Zhou
|first1=Quan
|last2=Chen
|first2=Wenlin
|last3=Song
|first3=Shiji
|last4=Gardner
|first4=Jacob
|last5=Weinberger
|first5=Kilian
|last6=Chen
|first6=Yixin
|title=A Reduction of the Elastic Net to Support Vector Machines with an Application to GPU Computing
|url=https://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/view/9856
|conference=[[Association for the Advancement of Artificial Intelligence]]}}&lt;/ref&gt;) The extended versions of these algorithms are called Laplacian Regularized Least Squares (abbreviated LapRLS) and Laplacian Support Vector Machines (LapSVM), respectively.&lt;ref name="Belkin et al. 2006" /&gt;

=== Laplacian Regularized Least Squares (LapRLS) ===

Regularized least squares (RLS) is a family of [[Regression analysis|regression algorithms]]: algorithms that predict a value &lt;math&gt;y = f(x)&lt;/math&gt; for its inputs &lt;math&gt;x&lt;/math&gt;, with the goal that the predicted values should be close to the true labels for the data. In particular, RLS is designed to minimize the [[mean squared error]] between the predicted values and the true labels, subject to regularization. Ridge regression is one form of RLS; in general, RLS is the same as ridge regression combined with the [[kernel method]].{{Citation needed|reason=Kernel ridge regression can be seen to have the same form as RLS in a general RKHS, but it is difficult to find a source that discusses the connection in detail.|date=December 2015}} The problem statement for RLS results from choosing the loss function &lt;math&gt;V&lt;/math&gt; in Tikhonov regularization to be the mean squared error:

: &lt;math&gt; f^* = \underset{f \in \mathcal{H}}{\arg\!\min} \frac{1}{\ell} \sum_{i=1}^{\ell} (f(x_i) - y_i)^2 + \gamma \left\| f \right\|_K^2 &lt;/math&gt;

Thanks to the [[representer theorem]], the solution can be written as a weighted sum of the kernel evaluated at the data points:

: &lt;math&gt; f^*(x) = \sum_{i=1}^{\ell} \alpha_i^* K(x_i, x) &lt;/math&gt;

and solving for &lt;math&gt;\alpha^*&lt;/math&gt; gives:

: &lt;math&gt; \alpha^* = (K + \gamma \ell I)^{-1} Y &lt;/math&gt;

where &lt;math&gt;K&lt;/math&gt; is defined to be the kernel matrix, with &lt;math&gt;K_{ij} = K(x_i, x_j)&lt;/math&gt;, and &lt;math&gt;Y&lt;/math&gt; is the vector of data labels.

Adding a Laplacian term for manifold regularization gives the Laplacian RLS statement:

: &lt;math&gt; f^* = \underset{f \in \mathcal{H}}{\arg\!\min} \frac{1}{\ell} \sum_{i=1}^{\ell} (f(x_i) - y_i)^2 + \gamma_A \left\| f \right\|_K^2 + \frac{\gamma_I}{(\ell+u)^2} \mathbf{f}^{\mathrm{T}} L \mathbf{f} &lt;/math&gt;

The representer theorem for manifold regularization again gives

: &lt;math&gt; f^*(x) = \sum_{i=1}^{\ell + u} \alpha_i^* K(x_i, x) &lt;/math&gt;

and this yields an expression for the vector &lt;math&gt;\alpha^*&lt;/math&gt;. Letting &lt;math&gt;K&lt;/math&gt; be the kernel matrix as above, &lt;math&gt;Y&lt;/math&gt; be the vector of data labels, and &lt;math&gt;J&lt;/math&gt; be the &lt;math&gt; (\ell + u) \times (\ell + u) &lt;/math&gt; block matrix &lt;math&gt;\begin{bmatrix} I_{\ell} &amp; 0 \\ 0 &amp; 0_u \end{bmatrix} &lt;/math&gt;:

: &lt;math&gt; \alpha^* = \underset{\alpha \in \mathbf{R}^{\ell + u}}{\arg\!\min} \frac{1}{\ell} (Y - J K \alpha)^{\mathrm{T}} (Y - J K \alpha) + \gamma_A \alpha^{\mathrm{T}} K \alpha + \frac{\gamma_I}{(\ell + u)^2} \alpha^{\mathrm{T}} K L K \alpha &lt;/math&gt;

with a solution of

: &lt;math&gt; \alpha^* = \left( JK + \gamma_A \ell I + \frac{\gamma_I \ell}{(\ell + u)^2} L K \right)^{-1} Y &lt;/math&gt;&lt;ref name="Belkin et al. 2006" /&gt;

LapRLS has been applied to problems including sensor networks,&lt;ref&gt;{{Cite conference
| publisher = Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999
| volume = 21
| pages = 988
| last1 = Pan
| first1 = Jeffrey Junfeng
| last2 = Yang
| first2 = Qiang
| last3 = Chang
| first3 = Hong
| last4 = Yeung
| first4 = Dit-Yan
| title = A manifold regularization approach to calibration reduction for sensor-network based tracking
| book-title = Proceedings of the national conference on artificial intelligence| access-date = 2015-12-02
| date = 2006
| url = http://www.aaai.org/Papers/AAAI/2006/AAAI06-155.pdf}}&lt;/ref&gt;
[[medical imaging]],&lt;ref&gt;{{Cite conference| publisher = IEEE| pages = 1628–1631| last1 = Zhang| first1 = Daoqiang| last2 = Shen| first2 = Dinggang| title = Semi-supervised multimodal classification of Alzheimer's disease| book-title = Biomedical Imaging: From Nano to Macro, 2011 IEEE International Symposium on| date = 2011| doi = 10.1109/ISBI.2011.5872715}}&lt;/ref&gt;&lt;ref&gt;{{Cite book| publisher = Springer| pages = 264–271| last1 = Park| first1 = Sang Hyun| last2 = Gao| first2 = Yaozong| last3 = Shi| first3 = Yinghuan| last4 = Shen| first4 = Dinggang| title = Machine Learning in Medical Imaging| volume = 8679| chapter = Interactive Prostate Segmentation Based on Adaptive Feature Selection and Manifold Regularization| date = 2014| doi = 10.1007/978-3-319-10581-9_33| series = Lecture Notes in Computer Science| isbn = 978-3-319-10580-2}}&lt;/ref&gt;
object detection,&lt;ref&gt;{{Cite journal| last = Pillai| first = Sudeep| title = Semi-supervised Object Detector Learning from Minimal Labels| access-date = 2015-12-15| url = http://people.csail.mit.edu/spillai/data/papers/ssl-cv-project-paper.pdf}}&lt;/ref&gt;
[[spectroscopy]],&lt;ref&gt;{{Cite journal| volume = 11| issue = 1| pages = 416–419| last1 = Wan| first1 = Songjing| last2 = Wu| first2 = Di| last3 = Liu| first3 = Kangsheng| title = Semi-Supervised Machine Learning Algorithm in Near Infrared Spectral Calibration: A Case Study on Diesel Fuels| journal = Advanced Science Letters| date = 2012| doi=10.1166/asl.2012.3044}}&lt;/ref&gt;
[[document classification]],&lt;ref&gt;{{Cite journal| volume = 8| issue = 4| pages = 1011–1018| last1 = Wang| first1 = Ziqiang| last2 = Sun| first2 = Xia| last3 = Zhang| first3 = Lijie| last4 = Qian| first4 = Xu| title = Document Classification based on Optimal Laprls| journal = Journal of Software| date = 2013| doi=10.4304/jsw.8.4.1011-1018}}&lt;/ref&gt;
drug-protein interactions,&lt;ref&gt;{{Cite journal| volume = 4| issue = Suppl 2| pages = –6| last1 = Xia| first1 = Zheng| last2 = Wu| first2 = Ling-Yun| last3 = Zhou| first3 = Xiaobo| last4 = Wong| first4 = Stephen TC| title = Semi-supervised drug-protein interaction prediction from heterogeneous biological spaces| journal = BMC Systems Biology| date = 2010| citeseerx = 10.1.1.349.7173| doi = 10.1186/1752-0509-4-S2-S6| pmid = 20840733| pmc = 2982693}}&lt;/ref&gt;
and compressing images and videos.&lt;ref&gt;{{Cite conference| publisher = ACM| pages = 161–168| last1 = Cheng| first1 = Li| last2 = Vishwanathan| first2 = S. V. N.| title = Learning to compress images and videos| book-title = Proceedings of the 24th international conference on Machine learning| access-date = 2015-12-16| date = 2007| url = http://dl.acm.org/citation.cfm?id=1273517}}&lt;/ref&gt;

=== Laplacian Support Vector Machines (LapSVM) ===

[[Support vector machines]] (SVMs) are a family of algorithms often used for [[Statistical classification|classifying data]] into two or more groups, or ''classes''. Intuitively, an SVM draws a boundary between classes so that the closest labeled examples to the boundary are as far away as possible. This can be directly expressed as a [[linear program]], but it is also equivalent to Tikhonov regularization with the [[hinge loss]] function, &lt;math&gt;V(f(x), y) = \max(0, 1 - yf(x))&lt;/math&gt;:

: &lt;math&gt; f^* = \underset{f \in \mathcal{H}}{\arg\!\min} \frac{1}{\ell} \sum_{i=1}^{\ell} \max(0, 1 - y_if(x_i)) + \gamma \left\| f \right\|_K^2 &lt;/math&gt;&lt;ref&gt;{{Cite journal| volume = 48| issue = 1–3| pages = 115–136| last1 = Lin| first1 = Yi| last2 = Wahba| first2 = Grace| last3 = Zhang| first3 = Hao| last4 = Lee| first4 = Yoonkyung|author4-link= Yoonkyung Lee | title = Statistical properties and adaptive tuning of support vector machines| journal = Machine Learning| date = 2002| doi=10.1023/A:1013951620650| doi-access = free}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal| volume = 6| pages = 69–87| last1 = Wahba| first1 = Grace| last2 = others| title = Support vector machines, reproducing kernel Hilbert spaces and the randomized GACV| journal = Advances in Kernel Methods-Support Vector Learning| date = 1999| citeseerx = 10.1.1.53.2114}}&lt;/ref&gt;

Adding the intrinsic regularization term to this expression gives the LapSVM problem statement:

: &lt;math&gt; f^* = \underset{f \in \mathcal{H}}{\arg\!\min} \frac{1}{\ell} \sum_{i=1}^{\ell} \max(0, 1 - y_if(x_i)) + \gamma_A \left\| f \right\|_K^2 + \frac{\gamma_I}{(\ell+u)^2} \mathbf{f}^{\mathrm{T}} L \mathbf{f} &lt;/math&gt;

Again, the representer theorem allows the solution to be expressed in terms of the kernel evaluated at the data points:

: &lt;math&gt; f^*(x) = \sum_{i=1}^{\ell + u} \alpha_i^* K(x_i, x) &lt;/math&gt;

&lt;math&gt;\alpha&lt;/math&gt; can be found by writing the problem as a linear program and solving the [[Duality (optimization)|dual problem]]. Again letting &lt;math&gt;K&lt;/math&gt; be the kernel matrix and &lt;math&gt;J&lt;/math&gt; be the block matrix &lt;math&gt;\begin{bmatrix} I_{\ell} &amp; 0 \\ 0 &amp; 0_u \end{bmatrix} &lt;/math&gt;, the solution can be shown to be

: &lt;math&gt;\alpha = \left( 2 \gamma_A I + 2 \frac{\gamma_I}{(\ell + u)^2} L K \right)^{-1} J^{\mathrm{T}} Y \beta^* &lt;/math&gt;

where &lt;math&gt;\beta^*&lt;/math&gt; is the solution to the dual problem

:&lt;math&gt; \begin{align}
&amp; &amp; \beta^* = \max_{\beta \in \mathbf{R}^{\ell}} &amp; \sum_{i=1}^{\ell} \beta_i - \frac{1}{2} \beta^{\mathrm{T}} Q \beta \\
&amp; \text{subject to} &amp;&amp; \sum_{i=1}^{\ell} \beta_i y_i = 0 \\
&amp; &amp;&amp; 0 \le \beta_i \le \frac{1}{\ell}\; i = 1, \ldots, \ell
\end{align} &lt;/math&gt;

and &lt;math&gt;Q&lt;/math&gt; is defined by

: &lt;math&gt; Q = YJK \left( 2 \gamma_A I + 2 \frac{\gamma_I}{(\ell + u)^2} L K \right)^{-1} J^{\mathrm{T}} Y &lt;/math&gt;&lt;ref name="Belkin et al. 2006" /&gt;

LapSVM has been applied to problems including geographical imaging,&lt;ref&gt;{{Cite journal| volume = 48| issue = 11| pages = 4110–4121| last1 = Kim| first1 = Wonkook| last2 = Crawford| first2 = Melba M.| title = Adaptive classification for hyperspectral image data using manifold regularization kernel machines| journal =  IEEE Transactions on Geoscience and Remote Sensing| date = 2010| doi = 10.1109/TGRS.2010.2076287| s2cid = 29580629}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal| volume = 31| issue = 1| pages = 45–54| last1 = Camps-Valls| first1 = Gustavo| last2 = Tuia| first2 = Devis| last3 = Bruzzone| first3 = Lorenzo| last4 = Atli Benediktsson| first4 = Jon| title = Advances in hyperspectral image classification: Earth monitoring with statistical learning methods| journal = IEEE Signal Processing Magazine| date = 2014| doi=10.1109/msp.2013.2279179| arxiv = 1310.5107| bibcode = 2014ISPM...31...45C| s2cid = 11945705}}&lt;/ref&gt;&lt;ref&gt;{{Cite conference| publisher = IEEE| pages = 1521–1524| last1 = Gómez-Chova| first1 = Luis| last2 = Camps-Valls| first2 = Gustavo| last3 = Muñoz-Marí| first3 = Jordi| last4 = Calpe| first4 = Javier| title = Semi-supervised cloud screening with Laplacian SVM| book-title = Geoscience and Remote Sensing Symposium, 2007. IGARSS 2007. IEEE International| date = 2007| doi = 10.1109/IGARSS.2007.4423098}}&lt;/ref&gt;
medical imaging,&lt;ref&gt;{{Cite book| publisher = Springer| pages = 82–90| last1 = Cheng| first1 = Bo| last2 = Zhang| first2 = Daoqiang| last3 = Shen| first3 = Dinggang| title = Medical Image Computing and Computer-Assisted Intervention–MICCAI 2012| volume = 7510| chapter = Domain transfer learning for MCI conversion prediction| issue = Pt 1| date = 2012| doi = 10.1007/978-3-642-33415-3_11| pmid = 23285538| pmc = 3761352| series = Lecture Notes in Computer Science| isbn = 978-3-642-33414-6}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal| volume = 37| issue = 8| pages = 4155–4172| last1 = Jamieson| first1 = Andrew R.| last2 = Giger| first2 = Maryellen L.| last3 = Drukker| first3 = Karen| last4 = Pesce| first4 = Lorenzo L.| title = Enhancement of breast CADx with unlabeled dataa)| journal = Medical Physics| date = 2010| doi=10.1118/1.3455704| pmid = 20879576| pmc = 2921421| bibcode = 2010MedPh..37.4155J}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal| volume = 1| issue = 2| pages = 151–155| last1 = Wu| first1 = Jiang| last2 = Diao| first2 = Yuan-Bo| last3 = Li| first3 = Meng-Long| last4 = Fang| first4 = Ya-Ping| last5 = Ma| first5 = Dai-Chuan| title = A semi-supervised learning based method: Laplacian support vector machine used in diabetes disease diagnosis| journal = Interdisciplinary Sciences: Computational Life Sciences| date = 2009| doi=10.1007/s12539-009-0016-2| pmid = 20640829| s2cid = 21860700}}&lt;/ref&gt;
face recognition,&lt;ref&gt;{{Cite journal| volume = 4| issue = 17| last1 = Wang| first1 = Ziqiang| last2 = Zhou| first2 = Zhiqiang| last3 = Sun| first3 = Xia| last4 = Qian| first4 = Xu| last5 = Sun| first5 = Lijun| title = Enhanced LapSVM Algorithm for Face Recognition.| journal = International Journal of Advancements in Computing Technology| access-date = 2015-12-16| date = 2012| url = http://search.ebscohost.com/login.aspx?direct=true&amp;profile=ehost&amp;scope=site&amp;authtype=crawler&amp;jrnl=20058039&amp;AN=98908455&amp;h=8QzzRizi2IKxCZ4EHJjzxbGY%2FQazcifd58fcAGEG17GiFk0wZE59DrEge0xfEGhXRqsBaMwuBNyenVSP6sjwsA%3D%3D&amp;crl=c}}&lt;/ref&gt;
machine maintenance,&lt;ref&gt;{{Cite journal| volume = 38| issue = 8| pages = 10199–10204| last1 = Zhao| first1 = Xiukuan| last2 = Li| first2 = Min| last3 = Xu| first3 = Jinwu| last4 = Song| first4 = Gangbing| title = An effective procedure exploiting unlabeled data to build monitoring system| journal = Expert Systems with Applications| date = 2011| doi=10.1016/j.eswa.2011.02.078}}&lt;/ref&gt;
and [[brain-computer interfaces]].&lt;ref&gt;{{Cite journal| volume = 7| issue = 1| pages = 22–26| last1 = Zhong| first1 = Ji-Ying| last2 = Lei| first2 = Xu| last3 = Yao| first3 = D.| title = Semi-supervised learning based on manifold in BCI| journal = Journal of Electronics Science and Technology of China| access-date = 2015-12-16| date = 2009| url = http://www.journal.uestc.edu.cn/archives/2009/1/7/22-2677907.pdf}}&lt;/ref&gt;

== Limitations ==

* Manifold regularization assumes that data with different labels are not likely to be close together. This assumption is what allows the technique to draw information from unlabeled data, but it only applies to some problem domains. Depending on the structure of the data, it may be necessary to use a different semi-supervised or transductive learning algorithm.&lt;ref&gt;{{Cite journal| last = Zhu| first = Xiaojin| title = Semi-supervised learning literature survey| date = 2005| citeseerx = 10.1.1.99.9681}}&lt;/ref&gt;
* In some datasets, the intrinsic norm of a function &lt;math&gt;\left\| f \right\|_I&lt;/math&gt; can be very close to the ambient norm &lt;math&gt;\left\| f \right\|_K&lt;/math&gt;: for example, if the data consist of two classes that lie on perpendicular lines, the intrinsic norm will be equal to the ambient norm. In this case, unlabeled data have no effect on the solution learned by manifold regularization, even if the data fit the algorithm's assumption that the separator should be smooth. Approaches related to [[co-training]] have been proposed to address this limitation.&lt;ref&gt;{{Cite conference| publisher = ACM| pages = 976–983| last1 = Sindhwani| first1 = Vikas| last2 = Rosenberg| first2 = David S.| title = An RKHS for multi-view learning and manifold co-regularization| book-title = Proceedings of the 25th international conference on Machine learning| access-date = 2015-12-02| date = 2008| url = http://dl.acm.org/citation.cfm?id=1390279}}&lt;/ref&gt;
* If there are a very large number of unlabeled examples, the kernel matrix &lt;math&gt;K&lt;/math&gt; becomes very large, and a manifold regularization algorithm may become prohibitively slow to compute. Online algorithms and sparse approximations of the manifold may help in this case.&lt;ref&gt;{{Cite book| pages = 393–407| last1 = Goldberg| first1 = Andrew| last2 = Li| first2 = Ming| last3 = Zhu| first3 = Xiaojin| title = Online manifold regularization: A new learning setting and empirical study| journal = Machine Learning and Knowledge Discovery in Databases| volume = 5211| date = 2008| doi = 10.1007/978-3-540-87479-9_44| series = Lecture Notes in Computer Science| isbn = 978-3-540-87478-2}}&lt;/ref&gt;

== Software ==
* The [http://manifold.cs.uchicago.edu/manifold_regularization/software.html ManifoldLearn library] and the [http://www.dii.unisi.it/~melacci/lapsvmp/ Primal LapSVM library] implement LapRLS and LapSVM in [[MATLAB]].
* The [http://dlib.net/ml.html Dlib library] for [[C++]] includes a linear manifold regularization function.

== See also ==
* [[Manifold learning]]
* [[Semi-supervised learning]]
* [[Transduction (machine learning)]]
* [[Spectral graph theory]]
* [[Reproducing kernel Hilbert space]]
* [[Tikhonov regularization]]
* [[Differential geometry]]

== References ==
{{Reflist}}

[[Category:Machine learning]]</text>
      <sha1>0nmg27u8nr2pli2w2t7fa9n94ho2iwr</sha1>
    </revision>
  </page>
  <page>
    <title>Error tolerance (PAC learning)</title>
    <ns>0</ns>
    <id>48833041</id>
    <revision>
      <id>950642337</id>
      <parentid>915019376</parentid>
      <timestamp>2020-04-13T03:42:58Z</timestamp>
      <contributor>
        <username>Benjamin Schulz</username>
        <id>38931008</id>
      </contributor>
      <comment>replace broken link on reference.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="11157" xml:space="preserve">{{Use dmy dates|date=September 2017}}

{{machine learning bar}}

==Error tolerance (PAC learning)==
In [[Probably approximately correct learning|PAC learning]], '''error tolerance''' refers to the ability of an [[algorithm]] to learn when the examples received have been corrupted in some way. In fact, this is a very common and important issue since in many applications it is not possible to access noise-free data. Noise can interfere with the learning process at different levels: the algorithm may receive data that have been occasionally mislabeled, or the inputs may have some false information, or the classification of the examples may have been maliciously adulterated.

==Notation and the Valiant learning model==
In the following, let &lt;math&gt;X&lt;/math&gt; be our &lt;math&gt;n&lt;/math&gt;-dimensional input space. Let &lt;math&gt;\mathcal{H}&lt;/math&gt; be a class of functions that we wish to use in order to learn a &lt;math&gt;\{0,1\}&lt;/math&gt;-valued target function &lt;math&gt;f&lt;/math&gt; defined over &lt;math&gt;X&lt;/math&gt;. Let &lt;math&gt;\mathcal{D}&lt;/math&gt; be the distribution of the inputs over &lt;math&gt;X&lt;/math&gt;. The goal of a learning algorithm &lt;math&gt;\mathcal{A}&lt;/math&gt; is to choose the best function &lt;math&gt;h \in \mathcal{H}&lt;/math&gt; such that it minimizes &lt;math&gt;error(h) = P_{x \sim \mathcal{D} }( h(x) \neq f(x))&lt;/math&gt;. Let us suppose we have a function &lt;math&gt;size(f)&lt;/math&gt; that can measure the complexity of &lt;math&gt;f&lt;/math&gt;. Let &lt;math&gt; \text{Oracle}(x)&lt;/math&gt; be an oracle that, whenever called, returns an example &lt;math&gt;x&lt;/math&gt; and its correct label &lt;math&gt;f(x)&lt;/math&gt;.

When no noise corrupts the data, we can define '''learning in the Valiant setting''':&lt;ref&gt;Valiant, L. G. (August 1985). ''[http://www.ijcai.org/Past%20Proceedings/IJCAI-85-VOL1/PDF/107.pdf Learning Disjunction of Conjunctions]''. In IJCAI (pp. 560–566).&lt;/ref&gt;&lt;ref&gt;Valiant, Leslie G. "A theory of the learnable." Communications of the ACM 27.11 (1984): 1134–1142.&lt;/ref&gt;

'''Definition:'''
We say that &lt;math&gt;f&lt;/math&gt; is efficiently learnable using &lt;math&gt;\mathcal{H}&lt;/math&gt; in the [[Leslie Valiant|Valiant]] setting if there exists a learning algorithm &lt;math&gt;\mathcal{A}&lt;/math&gt; that has access to &lt;math&gt; \text{Oracle}(x)&lt;/math&gt; and a polynomial &lt;math&gt;p(\cdot,\cdot,\cdot,\cdot)&lt;/math&gt; such that for any &lt;math&gt;0 &lt; \varepsilon \leq 1&lt;/math&gt; and &lt;math&gt;0 &lt; \delta \leq 1&lt;/math&gt; it outputs, in a number of calls to the oracle bounded by &lt;math&gt;p\left(\frac{1}{\varepsilon},\frac{1}{\delta},n,\text{size}(f)\right)&lt;/math&gt; , a function &lt;math&gt;h \in \mathcal{H}&lt;/math&gt; that satisfies with probability at least &lt;math&gt;1-\delta&lt;/math&gt; the condition &lt;math&gt;\text{error}(h) \leq \varepsilon&lt;/math&gt;.

In the following we will define learnability of &lt;math&gt;f&lt;/math&gt; when data have suffered some modification.&lt;ref&gt;Laird, P. D. (1988). ''[https://link.springer.com/content/pdf/bfm%3A978-1-4613-1685-5%2F1.pdf Learning from good and bad data]''. Kluwer Academic Publishers.&lt;/ref&gt;&lt;ref&gt;Kearns, Michael. "Efficient noise-tolerant learning from statistical queries." Journal of the ACM 45.6 (1998): 983–1006.&lt;/ref&gt;&lt;ref&gt;Brunk, Clifford A., and Michael J. Pazzani. "An investigation of noise-tolerant relational concept learning algorithms." Proceedings of the 8th International Workshop on Machine Learning. 1991.&lt;/ref&gt;

==Classification noise==
In the classification noise model&lt;ref name = "kv"&gt;Kearns, M. J., &amp; Vazirani, U. V. (1994). An introduction to computational learning theory, chapter 5. MIT press.&lt;/ref&gt; a '''noise rate''' &lt;math&gt;0 \leq \eta &lt; \frac{1}{2}&lt;/math&gt; is introduced. Then, instead of &lt;math&gt;Oracle(x)&lt;/math&gt; that returns always the correct label of example &lt;math&gt;x&lt;/math&gt;, algorithm &lt;math&gt; \mathcal{A}&lt;/math&gt; can only call a faulty oracle &lt;math&gt;Oracle(x,\eta)&lt;/math&gt; that will flip the label of &lt;math&gt;x&lt;/math&gt; with probability &lt;math&gt;\eta&lt;/math&gt;. As in the Valiant case, the goal of a learning algorithm &lt;math&gt;\mathcal{A}&lt;/math&gt; is to choose the best function &lt;math&gt;h \in \mathcal{H}&lt;/math&gt; such that it minimizes &lt;math&gt;error(h) = P_{x \sim \mathcal{D} }( h(x) \neq f(x))&lt;/math&gt;. In applications it is difficult to have access to the real value of &lt;math&gt;\eta&lt;/math&gt;, but we assume we have access to its upperbound &lt;math&gt;\eta_B&lt;/math&gt;.&lt;ref&gt;Angluin, D., &amp; Laird, P. (1988). ''[http://homepages.math.uic.edu/~lreyzin/papers/angluin88b.pdf Learning from noisy examples]''. Machine Learning, 2(4), 343–370.&lt;/ref&gt; Note that if we allow the noise rate to be &lt;math&gt;1/2&lt;/math&gt;, then learning becomes impossible in any amount of computation time, because every label conveys no information about the target function.

'''Definition:'''
We say that &lt;math&gt;f&lt;/math&gt; is efficiently learnable using &lt;math&gt;\mathcal{H}&lt;/math&gt; in the '''classification noise model''' if there exists a learning algorithm &lt;math&gt;\mathcal{A}&lt;/math&gt; that has access to &lt;math&gt;Oracle(x,\eta)&lt;/math&gt; and a polynomial &lt;math&gt;p(\cdot,\cdot,\cdot,\cdot)&lt;/math&gt; such that for any &lt;math&gt;0 \leq \eta \leq \frac{1}{2}&lt;/math&gt;,  &lt;math&gt;0\leq \varepsilon \leq 1&lt;/math&gt; and &lt;math&gt;0\leq \delta \leq 1&lt;/math&gt; it outputs, in a number of calls to the oracle bounded by &lt;math&gt;p\left(\frac{1}{1-2\eta_B}, \frac{1}{\varepsilon},\frac{1}{\delta},n,size(f)\right)&lt;/math&gt; , a function &lt;math&gt;h \in \mathcal{H}&lt;/math&gt;  that satisfies with probability at least &lt;math&gt;1-\delta&lt;/math&gt; the condition &lt;math&gt;error(h) \leq \varepsilon&lt;/math&gt;.

==Statistical query learning==
Statistical Query Learning&lt;ref name = "kearns"&gt;Kearns, M. (1998). ''[www.cis.upenn.edu/~mkearns/papers/sq-journal.pdf Efficient noise-tolerant learning from statistical queries]''. Journal of the ACM, 45(6), 983–1006.&lt;/ref&gt; is a kind of [[Active learning (machine learning)|active learning]] problem in which the learning algorithm &lt;math&gt;\mathcal{A}&lt;/math&gt; can decide if to request information about the likelihood &lt;math&gt;P_{f(x)}&lt;/math&gt; that a function &lt;math&gt;f&lt;/math&gt; correctly labels example &lt;math&gt;x&lt;/math&gt;, and receives an answer accurate within a tolerance &lt;math&gt;\alpha&lt;/math&gt;. Formally, whenever the learning algorithm &lt;math&gt;\mathcal{A}&lt;/math&gt; calls the oracle &lt;math&gt;Oracle(x,\alpha)&lt;/math&gt;, it receives as feedback probability &lt;math&gt;Q_{f(x)}&lt;/math&gt;, such that &lt;math&gt;Q_{f(x)} - \alpha \leq P_{f(x)} \leq Q_{f(x)} + \alpha&lt;/math&gt;.

'''Definition:'''
We say that &lt;math&gt;f&lt;/math&gt; is efficiently learnable using &lt;math&gt;\mathcal{H}&lt;/math&gt; in the '''statistical query learning model''' if there exists a learning algorithm &lt;math&gt;\mathcal{A}&lt;/math&gt; that has access to &lt;math&gt;Oracle(x,\alpha)&lt;/math&gt; and polynomials &lt;math&gt;p(\cdot,\cdot,\cdot)&lt;/math&gt;, &lt;math&gt;q(\cdot,\cdot,\cdot)&lt;/math&gt;, and &lt;math&gt;r(\cdot,\cdot,\cdot)&lt;/math&gt; such that for any  &lt;math&gt;0 &lt; \varepsilon \leq 1&lt;/math&gt; the following hold:
# &lt;math&gt;Oracle(x,\alpha)&lt;/math&gt; can evaluate &lt;math&gt;P_{f(x)}&lt;/math&gt; in time &lt;math&gt;q\left(\frac{1}{\varepsilon},n,size(f)\right)&lt;/math&gt;;
# &lt;math&gt;\frac{1}{\alpha}&lt;/math&gt; is bounded by &lt;math&gt;r\left(\frac{1}{\varepsilon},n,size(f)\right)&lt;/math&gt;
# &lt;math&gt;\mathcal{A}&lt;/math&gt; outputs a model &lt;math&gt;h&lt;/math&gt; such that &lt;math&gt;err(h)&lt;\varepsilon&lt;/math&gt;, in a number of calls to the oracle bounded by &lt;math&gt;p\left(\frac{1}{\varepsilon},n,size(f)\right)&lt;/math&gt;.

Note that the confidence parameter &lt;math&gt;\delta&lt;/math&gt; does not appear in the definition of learning. This is because the main purpose of &lt;math&gt;\delta&lt;/math&gt; is to allow the learning algorithm a small probability of failure due to an unrepresentative sample. Since now &lt;math&gt;Oracle(x,\alpha)&lt;/math&gt; always guarantees to meet the approximation criterion &lt;math&gt;Q_{f(x)} - \alpha \leq P_{f(x)} \leq Q_{f(x)} + \alpha&lt;/math&gt;, the failure probability is no longer needed.

The statistical query model is strictly weaker than the PAC model: any efficiently SQ-learnable class is efficiently PAC learnable in the presence of classification noise, but there exist efficient PAC-learnable problems such as [[Parity (mathematics)|parity]] that are not efficiently SQ-learnable.&lt;ref name = "kearns" /&gt;

==Malicious classification==
In the malicious classification model&lt;ref&gt;Kearns, M., &amp; Li, M. (1993). ''[www.cis.upenn.edu/~mkearns/papers/malicious.pdf Learning in the presence of malicious errors]''. SIAM Journal on Computing, 22(4), 807–837.&lt;/ref&gt; an adversary generates errors to foil the learning algorithm. This setting describes situations of [[Burst error|error burst]], which may occur when for a limited time transmission equipment malfunctions repeatedly. Formally, algorithm &lt;math&gt;\mathcal{A}&lt;/math&gt; calls an oracle &lt;math&gt;Oracle(x,\beta)&lt;/math&gt; that returns a correctly labeled example &lt;math&gt;x&lt;/math&gt; drawn, as usual, from distribution &lt;math&gt;\mathcal{D}&lt;/math&gt; over the input space with probability &lt;math&gt;1- \beta&lt;/math&gt;, but it returns with probability &lt;math&gt;\beta&lt;/math&gt; an example drawn from a distribution that is not related to &lt;math&gt;\mathcal{D}&lt;/math&gt;. 
Moreover, this maliciously chosen example may strategically selected by an adversary who has knowledge of &lt;math&gt;f&lt;/math&gt;, &lt;math&gt;\beta&lt;/math&gt;, &lt;math&gt;\mathcal{D}&lt;/math&gt;, or the current progress of the learning algorithm.

'''Definition:'''
Given a bound &lt;math&gt;\beta_B&lt;  \frac{1}{2} &lt;/math&gt; for &lt;math&gt;0 \leq \beta &lt; \frac{1}{2}&lt;/math&gt;, we say that &lt;math&gt;f&lt;/math&gt; is efficiently learnable using &lt;math&gt;\mathcal{H}&lt;/math&gt; in the malicious classification model, if there exist a learning algorithm &lt;math&gt;\mathcal{A}&lt;/math&gt; that has access to &lt;math&gt;Oracle(x,\beta)&lt;/math&gt; and a polynomial &lt;math&gt;p(\cdot,\cdot,\cdot,\cdot,\cdot)&lt;/math&gt; such that for any  &lt;math&gt;0 &lt; \varepsilon \leq 1&lt;/math&gt;, &lt;math&gt;0 &lt; \delta \leq 1&lt;/math&gt; it outputs, in a number of calls to the oracle bounded by &lt;math&gt;p\left(\frac{1}{1/2 - \beta_B},\frac{1}{\varepsilon},\frac{1}{\delta},n,size(f)\right)&lt;/math&gt; , a function &lt;math&gt;h \in \mathcal{H}&lt;/math&gt;  that satisfies with probability at least &lt;math&gt;1-\delta&lt;/math&gt; the condition &lt;math&gt;error(h) \leq \varepsilon&lt;/math&gt;.

==Errors in the inputs: nonuniform random attribute noise==
In the nonuniform random attribute noise&lt;ref&gt;Goldman, S. A., &amp; Robert, H. (1991). Sloan. The difficulty of random attribute noise. Technical Report WUCS 91 29, Washington University, Department of Computer Science.&lt;/ref&gt;&lt;ref&gt;Sloan, R. H. (1989). ''[http://dspace.mit.edu/bitstream/handle/1721.1/38339/20770411.pdf?sequence=1 Computational learning theory: New models and algorithms]'' (Doctoral dissertation, Massachusetts Institute of Technology).&lt;/ref&gt; model the algorithm is learning a [[Boolean function]], a malicious oracle &lt;math&gt;Oracle(x,\nu)&lt;/math&gt; may flip each &lt;math&gt;i&lt;/math&gt;-th bit of example &lt;math&gt;x=(x_1,x_2,\ldots,x_n)&lt;/math&gt; independently with probability &lt;math&gt;\nu_i \leq \nu&lt;/math&gt;.

This type of error can irreparably foil the algorithm, in fact the following theorem holds:

In the nonuniform random attribute noise setting, an algorithm &lt;math&gt;\mathcal{A}&lt;/math&gt; can output a function &lt;math&gt;h \in \mathcal{H}&lt;/math&gt; such that &lt;math&gt;error(h)&lt;\varepsilon &lt;/math&gt; only if &lt;math&gt;\nu &lt; 2\varepsilon &lt;/math&gt;.

== See also==

{{columns-list|
* [[Machine learning]]
* [[Data mining]]
* [[Probably approximately correct learning]]
* [[Adversarial machine learning]]
}}

==References==
{{Reflist}}

[[Category:Theoretical computer science]]
[[Category:Computational learning theory]]
[[Category:Machine learning]]</text>
      <sha1>84jvnke3tjaxovphhw4cucfe8c2q5lm</sha1>
    </revision>
  </page>
  <page>
    <title>Multiple instance learning</title>
    <ns>0</ns>
    <id>48841414</id>
    <revision>
      <id>972908596</id>
      <parentid>960523259</parentid>
      <timestamp>2020-08-14T11:45:23Z</timestamp>
      <contributor>
        <username>Hobbes1651</username>
        <id>8188928</id>
      </contributor>
      <minor/>
      <comment>Add missing period at end of sentence.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="34127" xml:space="preserve">{{Machine learning bar}}
In [[machine learning]], '''multiple-instance learning''' (MIL) is a type of [[supervised learning]].  Instead of receiving a set of instances which are individually labeled, the learner receives a set of labeled ''bags'', each containing many instances. In the simple case of multiple-instance [[binary classification]], a bag may be labeled negative if all the instances in it are negative.  On the other hand, a bag is labeled positive if there is at least one instance in it which is positive.  From a collection of labeled bags, the learner tries to either (i) induce a concept that will label individual instances correctly or (ii) learn how to label bags without inducing the concept.

Babenko (2008)&lt;ref name = Babenko&gt;Babenko, Boris. "Multiple instance learning: algorithms and applications." View Article PubMed/NCBI Google Scholar (2008).&lt;/ref&gt; gives a simple example for MIL. Imagine several people, and each of them has a key chain that contains few keys. Some of these people are able to enter a certain room, and some aren’t. The task is then to predict whether a certain key or a certain key chain can get you into that room. To solve this problem we need to find the exact key that is common for all the “positive” key chains. If we can correctly identify this key, we can also correctly classify an entire key chain - positive if it contains the required key, or negative if it doesn't.

==Machine learning==
Depending on the type and variation in training data, machine learning can be roughly categorized into three frameworks: supervised learning, unsupervised learning, and reinforcement learning. '''Multiple instance learning (MIL)''' falls under the supervised learning framework, where every training instance has a label, either discrete or real valued. MIL deals with problems with incomplete knowledge of labels in training sets. More precisely, in multiple-instance learning, the training set consists of labeled “bags”, each of which is a collection of unlabeled instances. A bag is positively labeled if at least one instance in it is positive, and is negatively labeled if all instances in it are negative. The goal of the MIL is to predict the labels of new, unseen bags.

==History==
Keeler et al.,&lt;ref name = Keeler&gt;Keeler, James D., David E. Rumelhart, and Wee-Kheng Leow. Integrated Segmentation and Recognition of Hand-Printed Numerals. Microelectronics and Computer Technology Corporation, 1991.&lt;/ref&gt; in his work in the early 1990s was the first one to explore the area of MIL. The actual term multi-instance learning was introduced in the middle of the 1990s, by Dietterich et al. while they were investigating the problem of drug activity prediction.&lt;ref name = Dietterich&gt;Dietterich, Thomas G., Richard H. Lathrop, and Tomás Lozano-Pérez. "Solving the multiple instance problem with axis-parallel rectangles." Artificial intelligence 89.1 (1997): 31-71.&lt;/ref&gt; They tried to create a learning systems that could predict whether new molecule was qualified to make some drug, or not, through analyzing a collection of known molecules. Molecules can have many alternative low-energy states, but only one, or some of them, are qualified to make a drug. The problem arose because scientists could only determine if molecule is qualified, or not, but they couldn't say exactly which of its low-energy shapes are responsible for that.
				
One of the proposed ways to solve this problem was to use supervised learning, and regard all the low-energy shapes of the qualified molecule as positive training instances, while all of the low-energy shapes of unqualified molecules as negative instances. Dietterich et al. showed that such method would have a high false positive noise, from all low-energy shapes that are mislabeled as positive, and thus wasn't really useful.&lt;ref name="Dietterich"/&gt; Their approach was to regard each molecule as a labeled bag, and all the alternative low-energy shapes of that molecule as instances in the bag, without individual labels. Thus formulating multiple-instance learning.  
					
Solution to the multiple instance learning problem that Dietterich et al. proposed is the axis-parallel rectangle (APR) algorithm.&lt;ref name="Dietterich"/&gt; It attempts to search for appropriate axis-parallel rectangles constructed by the conjunction of the features. They tested the algorithm on Musk dataset,&lt;ref name=Musk&gt;C. Blake, E. Keogh, and C.J. Merz. UCI repository of machine learning databases [http://www.ics.uci.edu/amlearn/MLRepository.html]{{dead link|date=February 2018 |bot=InternetArchiveBot |fix-attempted=yes }}, Department of Information and Computer Science, University of California, Irvine, CA, 1998.&lt;/ref&gt; which is a concrete test data of drug activity prediction and the most popularly used benchmark in multiple-instance learning. APR algorithm achieved the best result, but APR was designed with Musk data in mind.

Problem of multi-instance learning is not unique to drug finding. In 1998, Maron and Ratan found another application of multiple instance learning to scene classification in machine vision, and devised Diverse Density framework.&lt;ref name = Maron&gt;O. Maron and A.L. Ratan. Multiple-instance learning for natural scene classification. In Proceedings of the 15th International Conference on Machine Learning, Madison, WI, pp.341–349, 1998.&lt;/ref&gt; Given an image, an instance is taken to be one or more fixed-size subimages, and the bag of instances is taken to be the entire image. An image is labeled positive if it contains the target scene - a waterfall, for example - and negative otherwise. Multiple instance learning can be used to learn the properties of the subimages which characterize the target scene. From there on, these frameworks have been applied to a wide spectrum of applications, ranging from image concept learning and text categorization, to stock market prediction.

==Examples==
Take image classification for example.{{harvtxt|Amores|2013}} Given an image, we want to know its target class based on its visual content. For instance, the target class might be "beach", where the image contains both "sand" and "water". In '''MIL''' terms, the image is described as a ''bag'' &lt;math&gt;X = \{X_1,..,X_N\}&lt;/math&gt;, where each &lt;math&gt;X_i&lt;/math&gt; is the feature vector (called ''instance'') extracted from the corresponding &lt;math&gt;i&lt;/math&gt;-th region in the image and &lt;math&gt;N&lt;/math&gt; is the total regions (instances) partitioning the image. The bag is labeled ''positive'' ("beach") if it contains both "sand" region instances and "water" region instances.

Examples of where MIL is applied are:
* Molecule activity
* Predicting binding sites of [[Calmodulin]] binding proteins&lt;ref name=pmid22962461&gt;{{cite journal |doi=10.1093/bioinformatics/bts416 |pmid=22962461 |pmc=3436843 |title=Multiple instance learning of Calmodulin binding sites |journal=Bioinformatics |volume=28 |issue=18 |pages=i416–i422 |year=2012 |last1=Minhas |first1=F. u. A. A |last2=Ben-Hur |first2=A }}&lt;/ref&gt;
* Predicting function for alternatively spliced isoforms {{harvtxt|Li|Menon|et al.|2014}},{{harvtxt|Eksi|Li|Menon|et al.|2013}}
* Image classification {{harvtxt|Maron|Ratan|1998}}
* Text or document categorization {{harvtxt|Kotzias et al.| 2015}}
* Predicting functional binding sites of MicroRNA targets {{harvtxt|Bandyopadhyay|Ghosh|et al.|2015}}
* Medical image classification {{harvtxt|Zhu et al.| 2016}}, {{harvtxt|P.J.Sudharshan et al.| 2019}}
Numerous researchers have worked on adapting classical classification techniques, such as [[support vector machines]] or [[Boosting (meta-algorithm)|boosting]], to work within the context of multiple-instance learning.

== Definitions ==
If the space of instances is &lt;math&gt;\mathcal{X}&lt;/math&gt;, then the set of bags is the set of functions &lt;math&gt;\mathbb{N}^\mathcal{X} = \{B: \mathcal{X} \rightarrow \mathbb{N} \}&lt;/math&gt;, which is isomorphic to the set of multi-subsets of &lt;math&gt;\mathcal{X}&lt;/math&gt;. For each bag &lt;math&gt;B \in \mathbb{N}^\mathcal{X}&lt;/math&gt; and each instance &lt;math&gt;x \in \mathcal{X} &lt;/math&gt;, &lt;math&gt;B(x)&lt;/math&gt; is viewed as the number of times &lt;math&gt;x&lt;/math&gt; occurs in &lt;math&gt;B&lt;/math&gt;.&lt;ref name = Review&gt;Foulds, James, and Eibe Frank. “A review of multi-instance learning assumptions.” The Knowledge Engineering Review 25.01 (2010): 1-25.&lt;/ref&gt; Let &lt;math&gt;\mathcal{Y}&lt;/math&gt; be the space of labels, then a "multiple instance concept" is a map &lt;math&gt;c: \mathbb{N}^\mathcal{X} \rightarrow \mathcal{Y}&lt;/math&gt;. The goal of MIL is to learn such a concept. The remainder of the article will focus on [[binary classification]], where &lt;math&gt;\mathcal{Y} = \{0, 1\}&lt;/math&gt;.

== Assumptions ==
Most of the work on multiple instance learning, including Dietterich et al. (1997) and Maron &amp; Lozano-Pérez (1997) early papers,&lt;ref name = Dietterich /&gt;&lt;ref name = Perez&gt;Maron, Oded, and Tomás Lozano-Pérez. "A framework for multiple-instance learning." Advances in neural information processing systems (1998): 570-576&lt;/ref&gt; make the assumption regarding the relationship between the instances within a bag and the class label of the bag. Because of its importance, that assumption is often called standard MI assumption.

=== Standard assumption ===
The standard assumption takes each instance &lt;math&gt;x \in \mathcal{X}&lt;/math&gt; to have an associated label &lt;math&gt;y \in \{0,1\}&lt;/math&gt; which is hidden to the learner. The pair &lt;math&gt;(x,y)&lt;/math&gt; is called an "instance-level concept". A bag is now viewed as a multiset of instance-level concepts, and is labeled positive if at least one of its instances has a positive label, and negative if all of its instances have negative labels. Formally, let &lt;math&gt;B = \{ (x_1, y_1), \ldots, (x_n, y_n) \}&lt;/math&gt; be a bag. The label of &lt;math&gt;B&lt;/math&gt; is then &lt;math&gt;c(B) = 1 - \prod_{i=1}^n (1 - y_i)&lt;/math&gt;. Standard MI assumption is asymmetric, which means that if the positive and negative labels are reversed, the assumption has a different meaning. Because of that, when we use this assumption, we need to be clear which label should be the positive one.

Standard assumption might be viewed as too strict, and therefore in the recent years, researchers tried to relax that position, which gave rise to other more loose assumptions.&lt;ref name = Xu&gt;Xu, X. Statistical learning in multiple instance problems. Master’s thesis, University of Waikato (2003).&lt;/ref&gt; Reason for this is the belief that standard MI assumption is appropriate for the Musk dataset, but since MIL can be applied to numerous other problems, some different assumptions could probably be more appropriate. Guided by that idea, Weidmann &lt;ref name = Weidmann&gt;Weidmann, Nils B. “Two-level classification for generalized multi-instance data.” Diss. Albert-Ludwigs-Universität, 2003.&lt;/ref&gt; formulated a hierarchy of generalized instance-based assumptions for MIL. It consists of the standard MI assumption and three types of generalized MI assumptions, each more general than the last, standard &lt;math&gt;\subset&lt;/math&gt; presence-based &lt;math&gt;\subset&lt;/math&gt; threshold-based &lt;math&gt;\subset&lt;/math&gt; count-based, with the count-based assumption being the most general and the standard assumption being the least general. One would expect an algorithm which performs well under one of these assumptions to perform at least as well under the less general assumptions.

=== Presence-, threshold-, and count-based assumptions ===
The presence-based assumption is a generalization of the standard assumption, wherein a bag must contain one or more instances that belong to a set of required instance-level concepts in order to be labeled positive. Formally, let &lt;math&gt;C_R \subseteq \mathcal{X} \times \mathcal{Y}&lt;/math&gt; be the set of required instance-level concepts, and let &lt;math&gt;\#(B, c_i)&lt;/math&gt; denote the number of times the instance-level concept &lt;math&gt;c_i&lt;/math&gt; occurs in the bag &lt;math&gt;B&lt;/math&gt;. Then &lt;math&gt;c(B) = 1 \Leftrightarrow \#(B, c_i) \geq 1&lt;/math&gt; for all &lt;math&gt;c_i \in C_R&lt;/math&gt;. Note that, by taking &lt;math&gt;C_R&lt;/math&gt; to contain only one instance-level concept, the presence-based assumption reduces to the standard assumption.

A further generalization comes with the threshold-based assumption, where each required instance-level concept must occur not only once in a bag, but some minimum (threshold) number of times in order for the bag to be labeled positive. With the notation above, to each required instance-level concept &lt;math&gt;c_i \in C_R&lt;/math&gt; is associated a threshold &lt;math&gt;l_i \in \mathbb{N}&lt;/math&gt;. For a bag &lt;math&gt;B&lt;/math&gt;, &lt;math&gt;c(B) = 1 \Leftrightarrow \#(B, c_i) \geq l_i&lt;/math&gt; for all &lt;math&gt;c_i \in C_R&lt;/math&gt;.

The count-based assumption is a final generalization which enforces both lower and upper bounds for the number of times a required concept can occur in a positively labeled bag. Each required instance-level concept &lt;math&gt;c_i \in C_R&lt;/math&gt; has a lower threshold &lt;math&gt;l_i \in \mathbb{N}&lt;/math&gt; and upper threshold &lt;math&gt;u_i \in \mathbb{N}&lt;/math&gt; with &lt;math&gt;l_i \leq u_i&lt;/math&gt;. A bag &lt;math&gt;B&lt;/math&gt; is labeled according to &lt;math&gt;c(B) = 1 \Leftrightarrow l_i \leq \#(B, c_i) \leq u_i&lt;/math&gt; for all &lt;math&gt;c_i \in C_R&lt;/math&gt;.

=== GMIL assumption===
Scott, Zhang, and Brown (2005) &lt;ref name = GMIL&gt;Scott, Stephen, Jun Zhang, and Joshua Brown. "On generalized multiple-instance learning." International Journal of Computational Intelligence and Applications 5.01 (2005): 21-35.&lt;/ref&gt; describe another generalization of the standard model, which they call "generalized multiple instance learning" (GMIL). The GMIL assumption specifies a set of required instances &lt;math&gt;Q \subseteq \mathcal{X}&lt;/math&gt;. A bag &lt;math&gt;X&lt;/math&gt; is labeled positive if it contains instances which are sufficiently close to at least &lt;math&gt;r&lt;/math&gt; of the required instances &lt;math&gt;Q&lt;/math&gt;.&lt;ref name=GMIL /&gt; Under only this condition, the GMIL assumption is equivalent to the presence-based assumption.&lt;ref name = Review /&gt; However, Scott et al. describe a further generalization in which there is a set of attraction points &lt;math&gt;Q \subseteq \mathcal{X}&lt;/math&gt; and a set of repulsion points &lt;math&gt;\overline{Q} \subseteq \mathcal{X}&lt;/math&gt;. A bag is labeled positive if and only if it contains instances which are sufficiently close to at least &lt;math&gt;r&lt;/math&gt; of the attraction points and are sufficiently close to at most &lt;math&gt;s&lt;/math&gt; of the repulsion points.&lt;ref name=GMIL /&gt; This condition is strictly more general than the presence-based, though it does not fall within the above hierarchy.

=== Collective assumption ===
In contrast to the previous assumptions where the bags were viewed as fixed, the collective assumption views a bag &lt;math&gt;B&lt;/math&gt; as a distribution &lt;math&gt;p(x|B)&lt;/math&gt; over instances &lt;math&gt;\mathcal{X}&lt;/math&gt;, and similarly view labels as a distribution &lt;math&gt;p(y|x)&lt;/math&gt; over instances. The goal of an algorithm operating under the collective assumption is then to model the distribution &lt;math&gt;p(y|B) = \int_\mathcal{X} p(y|x)p(x|B)dx&lt;/math&gt;.

Since &lt;math&gt;p(x|B)&lt;/math&gt; is typically considered fixed but unknown, algorithms instead focus on computing the empirical version: &lt;math&gt;\widehat{p}(y|B) = \frac{1}{n_B} \sum_{i=1}^{n_B} p(y|x_i)&lt;/math&gt;, where &lt;math&gt;n_B&lt;/math&gt; is the number of instances in bag &lt;math&gt;B&lt;/math&gt;. Since &lt;math&gt;p(y|x)&lt;/math&gt; is also typically taken to be fixed but unknown, most collective-assumption based methods focus on learning this distribution, as in the single-instance version.&lt;ref name = Review /&gt;&lt;ref name = Xu /&gt;

While the collective assumption weights every instance with equal importance, Foulds extended the collective assumption to incorporate instance weights. The weighted collective assumption is then that &lt;math&gt;\widehat{p}(y|B) = \frac{1}{w_B} \sum_{i=1}^{n_B} w(x_i) p(y|x_i)&lt;/math&gt;, where &lt;math&gt;w: \mathcal{X} \rightarrow \mathbb{R}^+&lt;/math&gt; is a weight function over instances and &lt;math&gt;w_B = \sum_{x \in B} w(x)&lt;/math&gt;.&lt;ref name = Review /&gt;

== Algorithms ==
[[File:Mildiag.jpg|thumbnail|left|MIL Framework]] There are two major flavors of algorithms for Multiple Instance Learning: instance-based and metadata-based, or embedding-based algorithms. The term "instance-based" denotes that the algorithm attempts to find a set of representative instances based on an MI assumption and classify future bags from these representatives. By contrast, metadata-based algorithms make no assumptions about the relationship between instances and bag labels, and instead try to extract instance-independent information (or metadata) about the bags in order to learn the concept.&lt;ref name = Xu /&gt; For a survey of some of the modern MI algorithms see Foulds and Frank. &lt;ref name = Review /&gt;
  
=== Instance-based algorithms ===
The earliest proposed MI algorithms were a set of "iterated-discrimination" algorithms developed by Dietterich et al., and Diverse Density developed by Maron and Lozano-Pérez.&lt;ref name = Dietterich /&gt;&lt;ref name = Perez /&gt; Both of these algorithms operated under the standard assumption.

====Iterated-discrimination====
Broadly, all of the iterated-discrimination algorithms consist of two phases. The first phase is to grow an [[Axis-aligned object|axis parallel rectangle]] (APR) which contains at least one instance from each positive bag and no instances from any negative bags. This is done iteratively: starting from a random instance &lt;math&gt;x_1 \in B_1&lt;/math&gt; in a positive bag, the APR is expanded to the smallest APR covering any instance &lt;math&gt;x_2&lt;/math&gt; in a new positive bag &lt;math&gt;B_2&lt;/math&gt;. This process is repeated until the APR covers at least one instance from each positive bag. Then, each instance &lt;math&gt;x_i&lt;/math&gt; contained in the APR is given a "relevance", corresponding to how many negative points it excludes from the APR if removed. The algorithm then selects candidate representative instances in order of decreasing relevance, until no instance contained in a negative bag is also contained in the APR. The algorithm repeats these growth and representative selection steps until convergence, where APR size at each iteration is taken to be only along candidate representatives.

After the first phase, the APR is thought to tightly contain only the representative attributes. The second phase expands this tight APR as follows: a Gaussian distribution is centered at each attribute and a looser APR is drawn such that positive instances will fall outside the tight APR with fixed probability.&lt;ref name = Musk /&gt; Though iterated discrimination techniques work well with the standard assumption, they do not generalize well to other MI assumptions.&lt;ref name = Review /&gt;

====Diverse Density====
In its simplest form, Diverse Density (DD) assumes a single representative instance &lt;math&gt;t^*&lt;/math&gt; as the concept. This representative instance must be "dense" in that it is much closer to instances from positive bags than from negative bags, as well as "diverse" in that it is close to at least one instance from each positive bag.

Let &lt;math&gt;\mathcal{B}^+ = \{B_i^+\}_1^m&lt;/math&gt; be the set of positively labeled bags and let &lt;math&gt;\mathcal{B}^- = \{B_i^-\}_1^n&lt;/math&gt; be the set of negatively labeled bags, then the best candidate for the representative instance is given by &lt;math&gt;\hat{t} = \arg \max_t DD(t)&lt;/math&gt;, where the diverse density &lt;math&gt;DD(t) = Pr \left(t|\mathcal{B}^+, \mathcal{B}^- \right) = \arg \max_t \prod_{i=1}^m Pr \left(t|B_i^+\right) \prod_{i=1}^n Pr \left(t|B_i^-\right)&lt;/math&gt; under the assumption that bags are independently distributed given the concept &lt;math&gt;t^*&lt;/math&gt;. Letting &lt;math&gt;B_{ij}&lt;/math&gt; denote the jth instance of bag i, the noisy-or model gives:
: &lt;math&gt; Pr(t|B_i^+) = 1 - \prod_j \left( 1 -Pr\left(t|B_{ij}^+\right) \right)&lt;/math&gt;
: &lt;math&gt; Pr(t|B_i^-) = \prod_j \left( 1 - Pr\left(t|B_{ij}^-\right) \right) &lt;/math&gt;
&lt;math&gt;P(t|B_{ij})&lt;/math&gt; is taken to be the scaled distance &lt;math&gt;P(t|B_{ij}) \propto \exp \left( - \sum_{k} s_k^2 \left( x_k - (B_{ij})_k \right)^2 \right)&lt;/math&gt; where &lt;math&gt;s = (s_k)&lt;/math&gt; is the scaling vector. This way, if every positive bag has an instance close to &lt;math&gt;t&lt;/math&gt;, then &lt;math&gt;Pr(t|B_i^+)&lt;/math&gt; will be high for each &lt;math&gt;i&lt;/math&gt;, but if any negative bag &lt;math&gt;B_i^-&lt;/math&gt; has an instance close to &lt;math&gt;t&lt;/math&gt;, &lt;math&gt;Pr(t|B_i^-)&lt;/math&gt; will be low. Hence, &lt;math&gt;DD(t)&lt;/math&gt; is high only if every positive bag has an instance close to &lt;math&gt;t&lt;/math&gt; and no negative bags have an instance close to &lt;math&gt;t&lt;/math&gt;. The candidate concept &lt;math&gt;\hat{t}&lt;/math&gt; can be obtained through gradient methods. Classification of new bags can then be done by evaluating proximity to &lt;math&gt;\hat{t}&lt;/math&gt;.&lt;ref name="Perez"/&gt; Though Diverse Density was originally proposed by Maron et al. in 1998, more recent MIL algorithms use the DD framework, such as EM-DD in 2001 &lt;ref&gt;Zhang, Qi, and Sally A. Goldman. "EM-DD: An improved multiple-instance learning technique." Advances in neural information processing systems. (2001): 1073 - 80&lt;/ref&gt; and DD-SVM in 2004,&lt;ref&gt;Chen, Yixin, and James Z. Wang. "Image categorization by learning and reasoning with regions." The Journal of Machine Learning Research 5 (2004): 913-939&lt;/ref&gt; and MILES in 2006 &lt;ref name = Review /&gt;

A number of single-instance algorithms have also been adapted to a multiple-instance context under the standard assumption, including
* [[Support vector machines]]&lt;ref&gt;Andrews, Stuart, Ioannis Tsochantaridis, and Thomas Hofmann. "Support vector machines for multiple-instance learning." Advances in neural information processing systems (2003). pp 561 - 658&lt;/ref&gt;
* Artificial [[neural networks]]&lt;ref&gt;Zhou, Zhi-Hua, and Min-Ling Zhang. "Neural networks for multi-instance learning." Proceedings of the International Conference on Intelligent Information Technology, Beijing, China. (2002). pp 455 - 459&lt;/ref&gt;
* [[Decision trees]]&lt;ref&gt;Blockeel, Hendrik, David Page, and Ashwin Srinivasan. "Multi-instance tree learning." Proceedings of the 22nd international conference on Machine learning. ACM, 2005. pp 57- 64&lt;/ref&gt;
* [[Boosting (machine learning)|Boosting]]&lt;ref&gt;Auer, Peter, and Ronald Ortner. "A boosting approach to multiple instance learning." Machine Learning: ECML 2004. Springer Berlin Heidelberg, 2004. 63-74.&lt;/ref&gt;

Post 2000, there was a movement away from the standard assumption and the development of algorithms designed to tackle the more general assumptions listed above.&lt;ref name = Xu /&gt;

* Weidmann &lt;ref name = Weidmann /&gt; proposes a Two-Level Classification (TLC) algorithm to learn concepts under the count-based assumption. The first step tries to learn instance-level concepts by building a decision tree from each instance in each bag of the training set. Each bag is then mapped to a feature vector based on the counts in the decision tree. In the second step, a single-instance algorithm is run on the feature vectors to learn the concept 
* Scott et al. &lt;ref name=GMIL /&gt; proposed an algorithm, GMIL-1, to learn concepts under the GMIL assumption in 2005. GMIL-1 enumerates all axis-parallel rectangles &lt;math&gt;\{R_i\}_{i \in I}&lt;/math&gt; in the original space of instances, and defines a new [[feature (machine learning)|feature space]] of Boolean vectors. A bag &lt;math&gt;B&lt;/math&gt; is mapped to a vector &lt;math&gt;\mathbf{b} = (b_i)_{i \in I}&lt;/math&gt; in this new feature space, where &lt;math&gt;b_i = 1&lt;/math&gt; if APR &lt;math&gt;R_i&lt;/math&gt; covers &lt;math&gt;B&lt;/math&gt;, and &lt;math&gt;b_i = 0&lt;/math&gt; otherwise. A single-instance algorithm can then be applied to learn the concept in this new feature space.

Because of the high dimensionality of the new feature space and the cost of explicitly enumerating all APRs of the original instance space, GMIL-1 is inefficient both in terms of computation and memory. GMIL-2 was developed as a refinement of GMIL-1 in an effort to improve efficiency. GMIL-2 pre-processes the instances to find a set of candidate representative instances. GMIL-2 then maps each bag to a Boolean vector, as in GMIL-1, but only considers APRs corresponding to unique subsets of the candidate representative instances. This significantly reduces the memory and computational requirements.&lt;ref name = Review /&gt;

* Xu (2003) &lt;ref name = Xu /&gt; proposed several algorithms based on logistic regression and boosting methods to learn concepts under the collective assumption.

=== Metadata-based (or embedding-based) algorithms ===
By mapping each bag to a feature vector of metadata, metadata-based algorithms allow the flexibility of using an arbitrary single-instance algorithm to perform the actual classification task. Future bags are simply mapped (embedded) into the feature space of metadata and labeled by the chosen classifier. Therefore, much of the focus for metadata-based algorithms is on what features or what type of embedding leads to effective classification. Note that some of the previously mentioned algorithms, such as TLC and GMIL could be considered metadata-based.

* One approach is to let the metadata for each bag be some set of statistics over the instances in the bag. The SimpleMI algorithm takes this approach, where the metadata of a bag is taken to be a simple summary statistic, such as the average or minimum and maximum of each instance variable taken over all instances in the bag. There are other algorithms which use more complex statistics, but SimpleMI was shown to be surprisingly competitive for a number of datasets, despite its apparent lack of complexity.&lt;ref name = Review /&gt;
* Another common approach is to consider the geometry of the bags themselves as metadata. This is the approach taken by the MIGraph and miGraph algorithms, which represent each bag as a graph whose nodes are the instances in the bag. There is an edge between two nodes if the distance (up to some metric on the instance space) between the corresponding instances is less than some threshold. Classification is done via an SVM with a graph kernel (MIGraph and miGraph only differ in their choice of kernel).&lt;ref name = Review /&gt; Similar approaches are taken by MILES &lt;ref&gt;{{Cite journal|last=Chen|first=Yixin|last2=Bi|first2=Jinbo|last3=Wang|first3=J. Z.|date=2006-12-01|title=MILES: Multiple-Instance Learning via Embedded Instance Selection|journal=IEEE Transactions on Pattern Analysis and Machine Intelligence|volume=28|issue=12|pages=1931–1947|doi=10.1109/TPAMI.2006.248|pmid=17108368|issn=0162-8828}}&lt;/ref&gt; and MInD.&lt;ref&gt;{{Cite journal|last=Cheplygina|first=Veronika|last2=Tax|first2=David M. J.|last3=Loog|first3=Marco|date=2015-01-01|title=Multiple instance learning with bag dissimilarities|journal=Pattern Recognition|volume=48|issue=1|pages=264–275|doi=10.1016/j.patcog.2014.07.022|arxiv=1309.5643}}&lt;/ref&gt; MILES represents a bag by its similarities to instances in the training set, while MInD represents a bag by its distances to other bags.
* A modification of k-nearest neighbors (kNN) can also be considered a metadata-based algorithm with geometric metadata, though the mapping between bags and metadata features is not explicit. However, it is necessary to specify the metric used to compute the distance between bags. Wang and Zucker (2000) &lt;ref&gt;Wang, Jun, and Jean-Daniel Zucker. “Solving multiple-instance problem: A lazy learning approach.” ICML (2000): 1119-25&lt;/ref&gt; suggest the (maximum and minimum, respectively) Hausdorff metrics for bags &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt;:
: &lt;math&gt; H(A,B) = \max \left\{ \max_A \min_B \| a - b \|, \max_B \min_A \| a - b \| \right\} &lt;/math&gt;
: &lt;math&gt; h_1(A,B) = \min_A \min_B \| a - b \| &lt;/math&gt;
They define two variations of kNN, Bayesian-kNN and citation-kNN, as adaptations of the traditional nearest-neighbor problem to the multiple-instance setting.

== Generalizations ==
So far this article has considered multiple instance learning exclusively in the context of binary classifiers. However, the generalizations of single-instance binary classifiers can carry over to the multiple-instance case.

* One such generalization is the multiple-instance multiple-label problem (MIML), where each bag can now be associated with any subset of the space of labels. Formally, if &lt;math&gt;\mathcal{X}&lt;/math&gt; is the space of features and &lt;math&gt;\mathcal{Y}&lt;/math&gt; is the space of labels, an MIML concept is a map &lt;math&gt;c: \mathbb{N}^\mathcal{X} \rightarrow 2^\mathcal{Y}&lt;/math&gt;. Zhou and Zhang (2006) &lt;ref&gt;Zhou, Zhi-Hua, and Min-Ling Zhang. "Multi-instance multi-label learning with application to scene classification." Advances in Neural Information Processing Systems. 2006. pp 1609 - 16&lt;/ref&gt; propose a solution to the MIML problem via a reduction to either a multiple-instance or multiple-concept problem.
* Another obvious generalization is to multiple-instance regression. Here, each bag is associated with a single real number as in standard regression. Much like the standard assumption, MI regression assumes there is one instance in each bag, called the "prime instance", which determines the label for the bag (up to noise). The ideal goal of MI regression would be to find a hyperplane which minimizes the square loss of the prime instances in each bag, but the prime instances are hidden. In fact, Ray and Page (2001) &lt;ref&gt;Ray, Soumya, and David Page. “Multiple instance regression.” ICML. Vol. 1. 2001. pp 425 - 32&lt;/ref&gt; show that finding a best fit hyperplane which fits one instance from each bag is intractable if there are fewer than three instances per bag, and instead develop an algorithm for approximation. Many of the algorithms developed for MI classification may also provide good approximations to the MI regression problem.&lt;ref name = Review /&gt;

==See also==
*[[Supervised learning]]
*[[Multi-label classification]]

== References ==
{{reflist}}

==Further reading==
Recent reviews of the MIL literature include:
*{{harvtxt|Amores|2013}}, which provides an extensive review and comparative study of the different paradigms, 
*{{harvtxt|Foulds|Frank|2010}}, which provides a thorough review of the different assumptions used by different paradigms in the literature.
*{{cite journal |doi=10.1016/S0004-3702(96)00034-3 |title=Solving the multiple instance problem with axis-parallel rectangles |journal=Artificial Intelligence |volume=89 |issue=1–2 |pages=31–71 |year=1997 |last1=Dietterich |first1=Thomas G |last2=Lathrop |first2=Richard H |last3=Lozano-Pérez |first3=Tomás }}
*{{cite book |doi=10.1007/978-3-319-47759-6 |title=Multiple Instance Learning |year=2016 |last1=Herrera |first1=Francisco |last2=Ventura |first2=Sebastián |last3=Bello |first3=Rafael |last4=Cornelis |first4=Chris |last5=Zafra |first5=Amelia |last6=Sánchez-Tarragó |first6=Dánel |last7=Vluymans |first7=Sarah |isbn=978-3-319-47758-9 }}
*{{cite journal |doi=10.1016/j.artint.2013.06.003 |title=Multiple instance classification: Review, taxonomy and comparative study |journal=Artificial Intelligence |volume=201 |pages=81–105 |year=2013 |last1=Amores |first1=Jaume |doi-access=free }}
*{{cite journal |doi=10.1017/S026988890999035X |title=A review of multi-instance learning assumptions |journal=The Knowledge Engineering Review |volume=25 |pages=1–25 |year=2010 |last1=Foulds |first1=James |last2=Frank |first2=Eibe |citeseerx=10.1.1.148.2333 }}
*{{cite book
 | first1 = James D. | last1 = Keeler 	
 | first2 = David E. | last2 = Rumelhart 	
 | first3 = Wee-Kheng | last3 = Leow
 | chapter = Integrated segmentation and recognition of hand-printed numerals
 | year = 1990 | pages = 557–563
 | title = Proceedings of the 1990 Conference on Advances in Neural Information Processing Systems (NIPS 3)
 | isbn = 978-1-55860-184-0 }}
*{{cite journal |doi=10.1016/j.tig.2014.05.005 |pmid=24951248 |pmc=4112133 |title=The emerging era of genomic data integration for analyzing splice isoform function |journal=Trends in Genetics |volume=30 |issue=8 |pages=340–7 |year=2014 |last1=Li |first1=Hong-Dong |last2=Menon |first2=Rajasree |last3=Omenn |first3=Gilbert S |last4=Guan |first4=Yuanfang }}
*{{cite journal |doi=10.1371/journal.pcbi.1003314 |pmid=24244129 |pmc=3820534 |title=Systematically Differentiating Functions for Alternatively Spliced Isoforms through Integrating RNA-seq Data |journal=PLOS Computational Biology |volume=9 |issue=11 |pages=e1003314 |year=2013 |last1=Eksi |first1=Ridvan |last2=Li |first2=Hong-Dong |last3=Menon |first3=Rajasree |last4=Wen |first4=Yuchen |last5=Omenn |first5=Gilbert S |last6=Kretzler |first6=Matthias |last7=Guan |first7=Yuanfang |bibcode=2013PLSCB...9E3314E }}
*{{cite book
 | first1 = O. | last1 = Maron
 | first2 = A.L. | last2 = Ratan
 | chapter = Multiple-instance learning for natural scene classification
 |  year= 1998 | pages = 341–349
 | title = Proceedings of the Fifteenth International Conference on Machine Learning
 | isbn = 978-1-55860-556-5 }}
*{{cite book |doi=10.1145/2783258.2783380 |chapter=From Group to Individual Labels Using Deep Features |title=Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD '15 |pages=597–606 |year=2015 |last1=Kotzias |first1=Dimitrios |last2=Denil |first2=Misha |last3=De Freitas |first3=Nando |last4=Smyth |first4=Padhraic |isbn=9781450336642 }}
*{{cite conference
 |last1=Ray |first1=Soumya
 |first2=David |last2=Page
 |title=Multiple instance regression
 |conference=ICML
 |year=2001
 |url=http://pages.cs.wisc.edu/~sray/papers/mip.reg.icml01.pdf}}
*{{cite journal |doi=10.1038/srep08004 |bibcode=2015NatSR...5E8004B |pmid=25614300 |pmc=4648438 |title=MBSTAR: Multiple instance learning for predicting specific functional binding sites in microRNA targets |journal=Scientific Reports |volume=5 |pages=8004 |year=2015 |last1=Bandyopadhyay |first1=Sanghamitra |last2=Ghosh |first2=Dip |last3=Mitra |first3=Ramkrishna |last4=Zhao |first4=Zhongming }}
*{{cite book |doi=10.1007/978-3-319-66179-7_69 |chapter=Deep Multi-instance Networks with Sparse Label Assignment for Whole Mammogram Classification |title=Medical Image Computing and Computer-Assisted Intervention − MICCAI 2017 |volume=10435 |pages=603–11 |series=Lecture Notes in Computer Science |year=2017 |last1=Zhu |first1=Wentao |last2=Lou |first2=Qi |last3=Vang |first3=Yeeleng Scott |last4=Xie |first4=Xiaohui |isbn=978-3-319-66178-0 }}

[[Category:Machine learning]]</text>
      <sha1>4ptul73hhms9hh0z6dco7xb512qgkiw</sha1>
    </revision>
  </page>
  <page>
    <title>Learnable function class</title>
    <ns>0</ns>
    <id>48827727</id>
    <revision>
      <id>907904950</id>
      <parentid>802178390</parentid>
      <timestamp>2019-07-26T02:33:26Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Alter: journal. Removed accessdate with no specified URL. | You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]].| Activated by [[User:Chris Capoccia]] | [[Category:Pages using citations with accessdate and no URL]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="9310" xml:space="preserve">{{Orphan|date=July 2016}}

In [[statistical learning theory]], a '''learnable function class''' is a [[Set (mathematics)|set]] of [[Function (mathematics)|functions]] for which an algorithm can be devised to asymptotically minimize the [[expected risk]], uniformly over all probability distributions. The concept of learnable classes are closely related to [[Regularization (mathematics)|regularization]] in [[machine learning]], and provides large sample justifications for certain learning algorithms.

== Definition ==

=== Background ===
{{See also|Statistical learning theory}}
Let &lt;math&gt;\Omega = \mathcal{X} \times \mathcal{Y} = \{(x, y)\}&lt;/math&gt; be the sample space, where &lt;math&gt;y&lt;/math&gt; are the labels and &lt;math&gt;x&lt;/math&gt; are the covariates (predictors). &lt;math&gt;\mathcal{F} = \{ f: \mathcal{X} \mapsto \mathcal{Y} \}&lt;/math&gt; is a collection of mappings (functions) under consideration to link &lt;math&gt;x&lt;/math&gt; to &lt;math&gt;y&lt;/math&gt;. &lt;math&gt;L: \mathcal{Y} \times \mathcal{Y} \mapsto \mathbb{R}&lt;/math&gt; is a pre-given loss function (usually non-negative). Given a probability distribution &lt;math&gt;P(x, y)&lt;/math&gt; on &lt;math&gt;\Omega&lt;/math&gt;, define the expected risk &lt;math&gt;I_P( f )&lt;/math&gt; to be:
:&lt;math&gt;I_P (f) = \int L( f(x), y ) d P( x, y )&lt;/math&gt;
The general goal in statistical learning is to find the function in &lt;math&gt;\mathcal{F}&lt;/math&gt; that minimizes the expected risk. That is, to find solutions to the following problem:&lt;ref name="Vapnik2013"&gt;{{cite book|author=Vladimir N. Vapnik|title=The Nature of Statistical Learning Theory|url=https://books.google.com/books?id=EoDSBwAAQBAJ|date=17 April 2013|publisher=Springer Science &amp; Business Media|isbn=978-1-4757-2440-0}}&lt;/ref&gt;
:&lt;math&gt; \hat{f} = \arg \min_{f \in \mathcal{F}} I_P (f) &lt;/math&gt;
But in practice the distribution &lt;math&gt;P&lt;/math&gt; is unknown, and any learning task can only be based on finite samples. Thus we seek instead to find an algorithm that asymptotically minimizes the empirical risk, i.e., to find a sequence of functions &lt;math&gt;\{\hat{f}_n\}_{n=1}^\infty&lt;/math&gt; that satisfies
:&lt;math&gt;\lim_{n \rightarrow \infty} \mathbb{P}( I_P (\hat{f}_n) - \inf_{f \in \mathcal{F}}I_P( f ) &gt; \epsilon ) = 0&lt;/math&gt;
One usual algorithm to find such a sequence is through [[empirical risk minimization]].

=== Learnable function class ===
We can make the condition given in the above equation stronger by requiring that the convergence is uniform for all probability distributions. That is:

{{NumBlk|:|&lt;math&gt; \lim_{n \rightarrow \infty} \sup_P \mathbb{P}( I_P (\hat{f}_n) - \inf_{f \in \mathcal{F}}I_P( f ) &gt; \epsilon ) = 0&lt;/math&gt; |{{EquationRef|1}}}}

The intuition behind the more strict requirement is as such: the rate at which sequence &lt;math&gt;\{\hat{f}_n\}&lt;/math&gt; converges to the minimizer of the expected risk can be very different for different &lt;math&gt;P(x, y)&lt;/math&gt;. Because in real world the true distribution &lt;math&gt;P&lt;/math&gt; is always unknown, we would want to select a sequence that performs well under all cases.

However, by the [[no free lunch theorem]], such a sequence that satisfies ({{EquationNote|1}}) does not exist if &lt;math&gt;\mathcal{F}&lt;/math&gt; is too complex. This means we need to be careful and not allow too "many" functions in &lt;math&gt;\mathcal{F}&lt;/math&gt; if we want ({{EquationNote|1}}) to be a meaningful requirement. Specifically, function classes that ensure the existence of a sequence &lt;math&gt;\{\hat{f}_n\}&lt;/math&gt; that satisfies ({{EquationNote|1}}) are known as '''learnable classes'''.&lt;ref name="Vapnik2013" /&gt;

It is worth noting that at least for supervised classification and regression problems, if a function class is learnable, then the empirical risk minimization automatically satisfies ({{EquationNote|1}}).&lt;ref name=":0"&gt;{{cite journal |title = Learnability, stability and uniform convergence|journal = The Journal of Machine Learning Research}}&lt;/ref&gt; Thus in these settings not only do we know that the problem posed by ({{EquationNote|1}}) is solvable, we also immediately have an algorithm that gives the solution.

== Interpretations ==
If the true relationship between &lt;math&gt;y&lt;/math&gt; and &lt;math&gt;x&lt;/math&gt; is &lt;math&gt;y \sim f^*(x)&lt;/math&gt;, then by selecting the appropriate loss function, &lt;math&gt;f^*&lt;/math&gt; can always be expressed as the minimizer of the expected loss across all possible functions. That is,

:&lt;math&gt;f^* = \arg\min_{f \in \mathcal{F}^*} I_P( f )&lt;/math&gt;

Here we let &lt;math&gt;\mathcal{F}^*&lt;/math&gt; be the collection of all possible functions mapping &lt;math&gt;\mathcal{X}&lt;/math&gt; onto &lt;math&gt;\mathcal{Y}&lt;/math&gt;. &lt;math&gt;f^*&lt;/math&gt; can be interpreted as the actual data generating mechanism. However, the no free lunch theorem tells us that in practice, with finite samples we cannot hope to search for the expected risk minimizer over &lt;math&gt;\mathcal{F}^*&lt;/math&gt;. Thus we often consider a subset of &lt;math&gt;\mathcal{F}^*&lt;/math&gt;, &lt;math&gt;\mathcal{F}&lt;/math&gt;, to carry out searches on. By doing so, we risk that &lt;math&gt;f^*&lt;/math&gt; might not be an element of &lt;math&gt;\mathcal{F}&lt;/math&gt;. This tradeoff can be mathematically expressed as

{{NumBlk|:|&lt;math&gt; I_P (\hat{f}_n) - \inf_{f \in \mathcal{F}^*}I_P( f ) = \underbrace{I_P (\hat{f}_n) - \inf_{f \in \mathcal{F}}I_P( f )}_{(a)} + \underbrace{\inf_{f \in \mathcal{F}}I_P( f ) - \inf_{f \in \mathcal{F}^*}I_P( f )}_{(b)} &lt;/math&gt; |{{EquationRef|2}}}}

In the above decomposition, part &lt;math&gt;(b)&lt;/math&gt; does not depend on the data and is non-stochastic. It describes how far away our assumptions (&lt;math&gt;\mathcal{F}&lt;/math&gt;) are from the truth (&lt;math&gt;\mathcal{F}^*&lt;/math&gt;). &lt;math&gt;(b)&lt;/math&gt; will be strictly greater than 0 if we make assumptions that are too strong (&lt;math&gt;\mathcal{F}&lt;/math&gt; too small). On the other hand, failing to put enough restrictions on &lt;math&gt;\mathcal{F}&lt;/math&gt; will cause it to be not learnable, and part &lt;math&gt;(a)&lt;/math&gt; will not stochastically converge to 0. This is the well-known [[overfitting]] problem in statistics and machine learning literature.

== Example: Tikhonov regularization ==
A good example where learnable classes are used is the so-called [[Tikhonov regularization]] in [[reproducing kernel Hilbert space]] (RKHS). Specifically, let &lt;math&gt;\mathcal{F^*}&lt;/math&gt; be an RKHS, and &lt;math&gt;||\cdot||_2&lt;/math&gt; be the norm on &lt;math&gt;\mathcal{F^*}&lt;/math&gt; given by its inner product. It is shown in &lt;ref&gt;{{cite journal |title=Learnability in Hilbert spaces with reproducing kernels |journal=Journal of Complexity }}&lt;/ref&gt; that &lt;math&gt;\mathcal{F} = \{f: ||f||_2 \leq \gamma  \}&lt;/math&gt; is a learnable class for any finite, positive &lt;math&gt;\gamma&lt;/math&gt;. The empirical minimization algorithm to the [[Duality (mathematics)|dual form]] of this problem is

:&lt;math&gt;\arg\min_{f \in \mathcal{F}^*} \left\{ \sum_{i = 1}^n L( f(x_i), y_i) + \lambda ||f||_2 \right\}&lt;/math&gt;

This was first introduced by Tikhonov&lt;ref name="TikhonovArsenin1977"&gt;{{cite book|author1=Andreĭ Nikolaevich Tikhonov|author2=Vasiliĭ I︠A︡kovlevich Arsenin|title=Solutions of ill-posed problems|url=https://books.google.com/books?id=ECrvAAAAMAAJ|year=1977|publisher=Winston|isbn=978-0-470-99124-4}}&lt;/ref&gt; to solve ill-posed problems. Many statistical learning algorithms can be expressed in such a form (for example, the well-known [[ridge regression]]).

The tradeoff between &lt;math&gt;(a)&lt;/math&gt; and &lt;math&gt;(b)&lt;/math&gt; in ({{EquationNote|2}}) is geometrically more intuitive with Tikhonov regularization in RKHS. We can consider a sequence of &lt;math&gt;\{\mathcal{F}_\gamma\}&lt;/math&gt;, which are essentially balls in  &lt;math&gt;\mathcal{F^*}&lt;/math&gt; with centers at 0. As &lt;math&gt;\gamma&lt;/math&gt; gets larger, &lt;math&gt;\mathcal{F}_\gamma&lt;/math&gt; gets closer to the entire space, and &lt;math&gt;(b)&lt;/math&gt; is likely to become smaller. However we will also suffer smaller convergence rates in &lt;math&gt;(a)&lt;/math&gt;. The way to choose an optimal &lt;math&gt;\gamma&lt;/math&gt; in finite sample settings is usually through [[Cross-validation (statistics)|cross-validation]].

== Relationship to empirical process theory ==

Part &lt;math&gt;(a)&lt;/math&gt; in ({{EquationNote|2}}) is closely linked to [[empirical process]] theory in statistics, where the empirical risk &lt;math&gt;\{\sum_{i=1}^n L( y_i, f(x_i) ), f \in \mathcal{F}\}&lt;/math&gt; are known as empirical processes.&lt;ref name="vaartWellner2013"&gt;{{cite book|author1=A.W. van der vaart|author2=Jon Wellner|title=Weak Convergence and Empirical Processes: With Applications to Statistics|url=https://books.google.com/books?id=zdDkBwAAQBAJ&amp;pg=PA116|date=9 March 2013|publisher=Springer Science &amp; Business Media|isbn=978-1-4757-2545-2|pages=116–}}&lt;/ref&gt; In this field, the function class &lt;math&gt;\mathcal{F}&lt;/math&gt; that satisfies the stochastic convergence

{{NumBlk|:|&lt;math&gt; \sup_P \mathbb{E} \sup_{f \in \mathcal{F}} | \sum_{i=1}^n L( y_i, f(x_i) ) - I_P(f) | = 0  &lt;/math&gt; |{{EquationRef|3}}}}

are known as uniform [[Glivenko–Cantelli class]]es. It has been shown that under certain regularity conditions, learnable classes and uniformly Glivenko-Cantelli classes are equivalent.&lt;ref name="Vapnik2013" /&gt; Interplay between &lt;math&gt;(a)&lt;/math&gt; and &lt;math&gt;(b)&lt;/math&gt; in statistics literature is often known as the [[bias-variance tradeoff]].

However, note that in &lt;ref name=":0" /&gt; the authors gave an example of [[stochastic convex optimization]] for [[General Setting of Learning]] where learnability is not equivalent with uniform convergence.

== References ==
&lt;references /&gt;

[[Category:Machine learning]]</text>
      <sha1>cj33lvjzzt2m5zv9op6u80k1y1fj2yl</sha1>
    </revision>
  </page>
  <page>
    <title>Isotropic position</title>
    <ns>0</ns>
    <id>48987892</id>
    <revision>
      <id>948371138</id>
      <parentid>808763301</parentid>
      <timestamp>2020-03-31T17:48:49Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <comment>Add: arxiv, doi. Removed parameters. Some additions/deletions were actually parameter name changes. | You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | Activated by [[User:Zppix]] | [[Category:Machine learning‎]] | via #UCB_Category</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1726" xml:space="preserve">In the fields of [[machine learning]], the [[theory of computation]], and [[random matrix theory]], a probability distribution over vectors is said to be in '''isotropic position''' if its [[covariance matrix]] is equal to the [[identity matrix]]. 

== Formal definitions ==
Let &lt;math display="inline"&gt;D&lt;/math&gt; be a distribution over vectors in the vector space &lt;math display="inline"&gt;\mathbb{R}^n&lt;/math&gt;.
Then &lt;math display="inline"&gt;D&lt;/math&gt; is in isotropic position if, for vector &lt;math display="inline"&gt;v&lt;/math&gt; sampled from the distribution,
:&lt;math&gt;\mathbb{E}\, vv^T = \mathrm{Id}.&lt;/math&gt;

A ''set'' of vectors is said to be in isotropic position if the [[uniform distribution (continuous)|uniform distribution]] over that set is in isotropic position. In particular, every [[orthonormal]] set of vectors is isotropic.

As a related definition, a [[convex body]] &lt;math display="inline"&gt;K&lt;/math&gt; in &lt;math display="inline"&gt;\mathbb{R}^n&lt;/math&gt; is called isotropic if it has volume &lt;math display="inline"&gt;|K|=1&lt;/math&gt;, center of mass at the origin, and there is a constant &lt;math display="inline"&gt;\alpha&gt;0&lt;/math&gt; such that

:&lt;math&gt;\int_K \langle x, y \rangle^2 dx = \alpha^2 |y|^2,&lt;/math&gt;

for all vectors &lt;math display="inline"&gt;y&lt;/math&gt; in &lt;math display="inline"&gt;\mathbb{R}^n&lt;/math&gt;; here &lt;math display="inline"&gt;|\cdot|&lt;/math&gt; stands 
for the standard Euclidean norm.


== See also ==

* [[Whitening transformation]]

== References ==
* {{cite journal |first=M. |last=Rudelson |title=Random Vectors in the Isotropic Position |journal=[[Journal of Functional Analysis]] |volume=164 |year=1999 |issue=1 |pages=60–72 |doi=10.1006/jfan.1998.3384 |arxiv=math/9608208 }}

[[Category:Machine learning]]
[[Category:Random matrices]]</text>
      <sha1>i80b4oluooc07kjl2cu44onbkie1caz</sha1>
    </revision>
  </page>
  <page>
    <title>Structured sparsity regularization</title>
    <ns>0</ns>
    <id>48844125</id>
    <revision>
      <id>993961364</id>
      <parentid>945847119</parentid>
      <timestamp>2020-12-13T12:22:14Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 10 templates: del empty params (5×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="24628" xml:space="preserve">{{Orphan|date=December 2015}}

'''Structured sparsity regularization''' is a class of methods, and an area of research in [[statistical learning theory]], that extend and generalize sparsity regularization learning methods.&lt;ref name="rosPoggio"&gt;{{cite document|last = Rosasco|first = Lorenzo|author2 = Poggio, Tomasso|title = A Regularization Tour of Machine Learning |work=MIT-9.520 Lectures Notes|date=December 2014}}&lt;/ref&gt; Both sparsity and structured sparsity regularization methods seek to exploit the assumption that the output variable &lt;math&gt; Y &lt;/math&gt; (i.e., response, or [[Dependent and independent variables#Dependent variable|dependent variable]]) to be learned can be described by a reduced number of variables in the input space &lt;math&gt; X &lt;/math&gt; (i.e., the [[Domain of a function|domain]], space of [[Feature (machine learning)|features]] or [[Dependent and independent variables#Independent variable|explanatory variables]]). ''Sparsity regularization methods'' focus on selecting the input variables that best describe the output. ''Structured sparsity regularization methods'' generalize and extend sparsity regularization methods, by allowing for optimal selection over structures like groups or networks of input variables in &lt;math&gt; X &lt;/math&gt;.&lt;ref name="groupLasso" /&gt;&lt;ref name="latentLasso" /&gt;

Common motivation for the use of structured sparsity methods are model interpretability, [[Curse of dimensionality|high-dimensional learning]] (where dimensionality of &lt;math&gt; X &lt;/math&gt; may be higher than the number of observations &lt;math&gt; n &lt;/math&gt;), and reduction of [[Time complexity|computational complexity]].&lt;ref name="LR18" /&gt; Moreover, structured sparsity methods allow to incorporate prior assumptions on the structure of the input variables, such as overlapping groups,&lt;ref name="groupLasso" /&gt; non-overlapping groups, and acyclic graphs.&lt;ref name="latentLasso" /&gt; Examples of uses of structured sparsity methods include face recognition,&lt;ref name="face_recognition"&gt;{{cite journal|last = Jia|first = Kui|title = Robust and Practical Face Recognition via Structured Sparsity|year = 2012|display-authors=etal}}&lt;/ref&gt; [[Magnetic resonance imaging|magnetic resonance image (MRI)]] processing,&lt;ref name="MRI"&gt;{{cite book|last = Chen|first = Chen|chapter= Compressive Sensing MRI with Wavelet Tree Sparsity |chapter-url=https://papers.nips.cc/paper/4630-compressive-sensing-mri-with-wavelet-tree-sparsity |title= Proceedings of the 26th Annual Conference on Neural Information Processing Systems |pages = 1115–1123|year = 2012|display-authors=etal|publisher = Curran Associates}}&lt;/ref&gt; socio-linguistic analysis in natural language processing,&lt;ref name="sociolinguistic"&gt;{{cite journal|last = Eisenstein|first = Jacob|title = Discovering Sociolinguistic Associations with Structured Sparsity|journal = Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics|year = 2011|display-authors=etal}}&lt;/ref&gt; and analysis of genetic expression in breast cancer.&lt;ref name="genetic"&gt;{{cite journal|last = Jacob|first = Laurent|title = Group Lasso with Overlap and Graph Lasso|journal = Proceedings of the 26th International Conference on Machine Learning|year = 2009|display-authors=etal}}&lt;/ref&gt;

== Definition and related concepts ==

=== Sparsity regularization ===
Consider the linear kernel [[Regularization (mathematics)|regularized]] [[empirical risk minimization]] problem with a loss function &lt;math&gt; V(y_i, f(x)) &lt;/math&gt;  and the &lt;math&gt;\ell_0&lt;/math&gt; "norm" as the regularization penalty:
: &lt;math&gt;\min_{w\in\mathbb{R}^d} \frac{1}{n}\sum_{i=1}^n V(y_i, \langle w,x_i\rangle)  + \lambda \|w\|_0, &lt;/math&gt;
where &lt;math&gt; x, w \in \mathbb{R^d} &lt;/math&gt;, and &lt;math&gt;\|w\|_0&lt;/math&gt; denotes the &lt;math&gt;\ell_0&lt;/math&gt; "norm", defined as the number of nonzero entries of the vector &lt;math&gt;w&lt;/math&gt;. &lt;math&gt;f(x) = \langle w,x_i\rangle&lt;/math&gt;  is said to be '''sparse if'''  &lt;math&gt;\|w\|_0 = s &lt; d&lt;/math&gt;. Which means that the output &lt;math&gt;Y&lt;/math&gt; can be described by a small subset of input variables.

More generally, assume a dictionary &lt;math&gt; \phi_j : X \rightarrow \mathbb{R} &lt;/math&gt; with &lt;math&gt;j = 1,...,p &lt;/math&gt;  is given, such that the target function &lt;math&gt;f(x)&lt;/math&gt; of a learning problem can be written as:
: &lt;math&gt;f(x) = \sum_{j=1}^p \phi_j(x) w_j&lt;/math&gt;, &lt;math&gt; \forall x \in X &lt;/math&gt; 
The &lt;math&gt;\ell_0&lt;/math&gt; norm &lt;math&gt;\|f\|_0 = \|w\|_0&lt;/math&gt;  as the number of non-zero components of &lt;math&gt;w&lt;/math&gt; is defined as 
: &lt;math&gt;\|w\|_0 = | \{ j | w_j \neq 0, j \in\{ 1,...,p \}\} |&lt;/math&gt;, where &lt;math&gt;|A|&lt;/math&gt; is the cardinality of set &lt;math&gt;A&lt;/math&gt;.
&lt;math&gt;f&lt;/math&gt; is said to be sparse if &lt;math&gt;\|f\|_0 = \|w\|_0 = s &lt; d&lt;/math&gt;.

However, while using the &lt;math&gt;\ell_0&lt;/math&gt; norm for regularization favors sparser solutions, it is computationally difficult to use and additionally is not convex. A computationally more feasible norm that favors sparser solutions is the &lt;math&gt;\ell_1&lt;/math&gt; norm; this has been shown to still favor sparser solutions and is additionally convex.&lt;ref name="LR18" /&gt;

=== Structured sparsity regularization ===
Structured sparsity regularization extends and generalizes the variable selection problem that characterizes sparsity regularization.&lt;ref name="groupLasso"&gt;{{cite journal|last = Yuan|first = M.|author2 = Lin, Y.|title = Model selection and estimation in regression with grouped variables|journal = J. R. Stat. Soc. B|year = 2006|volume = 68|issue = 1|pages = 49–67|doi = 10.1111/j.1467-9868.2005.00532.x|citeseerx = 10.1.1.79.2062}}&lt;/ref&gt;&lt;ref name="latentLasso" /&gt; Consider the above [[Regularization (mathematics)|regularized]] [[empirical risk minimization]] problem with a general kernel and associated feature map &lt;math&gt; \phi_j : X \rightarrow \mathbb{R} &lt;/math&gt; with &lt;math&gt;j = 1,...,p &lt;/math&gt;.
: &lt;math&gt;\min_{w\in\mathbb{R}^d} \frac{1}{n}\sum_{i=1}^n V(y_i, \langle w,\Phi(x_i)\rangle)  + \lambda \|w\|_0, &lt;/math&gt;
The regularization term &lt;math&gt;\lambda \|w\|_0 &lt;/math&gt; penalizes each &lt;math&gt;w_j&lt;/math&gt; component independently, which means that the algorithm will suppress input variables independently from each other.

In several situations we may want to impose more structure in the regularization process, so that, for example, input variables are suppressed according to predefined groups. '''Structured sparsity regularization methods''' allow to impose such structure by adding structure to the norms defining the regularization term.

== Structures and norms ==

=== Non-overlapping groups: group Lasso ===
The non-overlapping group case is the most basic instance of structured sparsity. In it, an ''a priori'' partition of the coefficient vector &lt;math&gt;w&lt;/math&gt; in &lt;math&gt;G&lt;/math&gt; non-overlapping groups is assumed. Let &lt;math&gt;w_g&lt;/math&gt; be the vector of coefficients in group &lt;math&gt;g&lt;/math&gt;, we can define a regularization term and its group norm as
: &lt;math&gt;\lambda R(w)=\lambda\sum _{{g=1}}^{G}\|w_{g}\|_{g} &lt;/math&gt;,
where &lt;math&gt; \|w_{g}\|_{g}&lt;/math&gt; is the group &lt;math&gt;\ell_2&lt;/math&gt; norm &lt;math&gt; \|w_{g}\|_{g}= \sqrt{ \sum _{{j=1}}^{{|G_{g}|}}(w_{g}^{j})^{2}} &lt;/math&gt; ,    &lt;math&gt;G_g&lt;/math&gt; is group &lt;math&gt;g&lt;/math&gt;, and &lt;math&gt;w_{g}^{j}&lt;/math&gt; is the ''j-th'' component of group &lt;math&gt;G_g&lt;/math&gt;.

The above norm is also referred to as '''group Lasso'''.&lt;ref name="groupLasso" /&gt; This regularizer will force entire coefficient groups towards zero, rather than individual coefficients. As the groups are non-overlapping, the set of non-zero coefficients can be obtained as the union of the groups that were not set to zero, and conversely for the set of zero coefficients.

=== Overlapping groups ===
Overlapping groups is the structure sparsity case where a variable can belong to more than one group &lt;math&gt;g&lt;/math&gt;. This case is often of interest as it can represent a more general class of  relationships among variables than non-overlapping groups can, such as tree structures or other type of graphs.&lt;ref name="latentLasso"&gt;{{cite arxiv |last1 = Obozinski|first1 = G.|last2 = Laurent | first2= J. | last3= Vert | first3= J.-P.|title = Group lasso with overlaps: the latent group lasso approach |year = 2011 |eprint = 1110.0413|class = stat.ML}}&lt;/ref&gt;&lt;ref name="genetic" /&gt;

There are two types of overlapping group sparsity regularization approaches, which are used to model different types of input variable relationships:

==== Intersection of complements: group Lasso  ====
The ''intersection of complements'' approach is used in cases when we want to select only those input variables that have positive coefficients in all groups they belong to.  Consider again the '''group Lasso''' for a [[Regularization (mathematics)|regularized]] [[empirical risk minimization]] problem:
: &lt;math&gt;\lambda R(w)=\lambda\sum _{{g=1}}^{G}\|w_{g}\|_{g} &lt;/math&gt;,
where &lt;math&gt; \|w_{g}\|_{g}&lt;/math&gt; is the group &lt;math&gt;\ell_2&lt;/math&gt; norm,    &lt;math&gt;G_g&lt;/math&gt; is group &lt;math&gt;g&lt;/math&gt;, and &lt;math&gt;w_{g}^{j}&lt;/math&gt; is the ''j-th'' component of group &lt;math&gt;G_g&lt;/math&gt;.

As in the non-overlapping groups case, the ''group Lasso'' regularizer will potentially set entire groups of coefficients to zero. Selected variables are those with coefficients &lt;math&gt;w_j &gt; 0&lt;/math&gt;. However, as in this case groups may overlap, we take the '''intersection of the complements''' of those groups that are not set to zero.

This ''intersection of complements'' selection criteria implies the modeling choice that we allow some coefficients within a particular group &lt;math&gt;g&lt;/math&gt; to be set to zero, while others within the same group &lt;math&gt;g&lt;/math&gt; may remain positive. In other words, coefficients within a group may differ depending on the several group memberships that each variable within the group may have.

==== Union of groups: latent group Lasso  ====
A different approach is to consider union of groups for variable selection. This approach captures the modeling situation where variables can be selected as long as they belong at least to one group with positive coefficients. This modeling perspective implies that we want to preserve group structure.

The formulation of the union of groups approach is also referred to as '''latent group Lasso''', and requires to modify the group &lt;math&gt;\ell_2&lt;/math&gt; norm considered above and introduce the following regularizer &lt;ref name="latentLasso" /&gt;
: &lt;math&gt;R(w)=inf\left\{\sum _{g}\|w_{{g}}\|_{{g}}:w=\sum _{{g=1}}^{G}{\bar  {w}}_{g}\right\}&lt;/math&gt;
where &lt;math&gt;w\in {\mathbb  {R^{d}}}&lt;/math&gt;,  &lt;math&gt;w_{{g}}\in G_{g}&lt;/math&gt; is the vector of coefficients of group g, and &lt;math&gt;{\bar  {w}}_{g}\in {\mathbb  {R^{d}}}&lt;/math&gt; is a vector with coefficients &lt;math&gt;w_{g}^{j}&lt;/math&gt; for all variables  &lt;math&gt;j&lt;/math&gt;  in group  &lt;math&gt;g&lt;/math&gt; , and  &lt;math&gt;0&lt;/math&gt;  in all others, i.e., &lt;math&gt;{\bar  w}_{g}^{j}=w_{g}^{j}&lt;/math&gt; if  &lt;math&gt;j&lt;/math&gt;  in group  &lt;math&gt;g&lt;/math&gt;  and &lt;math&gt;{\bar  w}_{g}^{j}=0&lt;/math&gt; otherwise.

This regularizer can be interpreted as effectively replicating variables that belong to more than one group, therefore conserving group structure. As intended by the union of groups approach, requiring &lt;math&gt;w=\sum _{{g=1}}^{G}{\bar  {w}}_{g}&lt;/math&gt; produces a vector of weights w that effectively sums up the weights of all variables across all groups they belong to.

=== Issues with Group Lasso regularization and alternative approaches ===
The objective function using group lasso consists of an error function, which is generally required to be convex but not necessarily strongly convex, and a group &lt;math&gt;\ell_1&lt;/math&gt; regularization term.  An issue with this objective function is that it is convex but not necessarily strongly convex, and thus generally does not lead to unique solutions.&lt;ref name=":0" /&gt;

An example of a way to fix this is to introduce the squared &lt;math&gt;\ell_2&lt;/math&gt; norm of the weight vector as an additional regularization term while keeping the &lt;math&gt;\ell_1&lt;/math&gt; regularization term from the group lasso approach.&lt;ref name=":0" /&gt; If the coefficient of the squared  &lt;math&gt;\ell_2&lt;/math&gt; norm term is greater than &lt;math&gt;0&lt;/math&gt;, then because the squared  &lt;math&gt;\ell_2&lt;/math&gt; norm term is strongly convex, the resulting objective function will also be strongly convex.&lt;ref name=":0" /&gt; Provided that the  &lt;math&gt;\ell_2&lt;/math&gt; coefficient is suitably small but still positive, the weight vector minimizing the resulting objective function is generally very close to a weight vector that minimizes the objective function that would result from removing the group  &lt;math&gt;\ell_2&lt;/math&gt; regularization term altogether from the original objective function; the latter scenario corresponds to the group Lasso approach.&lt;ref name=":0" /&gt; Thus this approach allows for simpler optimization while maintaining sparsity.&lt;ref name=":0" /&gt;

=== Norms based on the structure over Input variables ===
''See: [[Submodular set function]]''

Besides the norms discussed above, other norms used in structured sparsity methods include hierarchical norms and norms defined on grids. These norms arise from submodular functions and allow the incorporation of prior assumptions on the structure of the input variables. In the context of hierarchical norms, this structure can be represented as a [[directed acyclic graph]] over the variables while in the context of grid-based norms, the structure can be represented using a grid.&lt;ref name=":2" /&gt;&lt;ref name=":3" /&gt;&lt;ref name=":4" /&gt;&lt;ref name=":1" /&gt;&lt;ref name=":5" /&gt;&lt;ref name=":6" /&gt;

==== Hierarchical Norms ====
''See:'' [[Unsupervised learning]]

Unsupervised learning methods are often used to learn the parameters of [[latent variable model]]s. Latent variable models are statistical models where in addition to the observed variables, a set of latent variables also exists which is not observed. Often in such models, "hierarchies" are assumed between the variables of the system; this system of hierarchies can be represented using directed acyclic graphs.

Hierarchies of latent variables have emerged as a natural structure in several applications, notably to model text documents.&lt;ref name=":3"&gt;Bengio, Y. "Learning deep architectures for AI". Foundations and Trends in Machine Learning, 2(1), 2009.&lt;/ref&gt;  Hierarchical models using Bayesian non-parametric methods have been used to learn [[topic model]]s,&lt;ref name=":2"&gt;Blei, D., Ng, A., and Jordan, M. Latent dirichlet allocation. J. Mach. Learn. Res., 3:993–1022, 2003.&lt;/ref&gt; which are statistical models for discovering the abstract "topics" that occur in a collection of documents. Hierarchies have also been considered in the context of kernel methods.&lt;ref name=":1"&gt;{{Cite journal|arxiv=0904.3523|last1=Jenatton|first1=Rodolphe|title=Structured Variable Selection with Sparsity-Inducing Norms|journal=Journal of Machine Learning Research |volume=12|issue=2011|pages=2777–2824|last2=Audibert|first2=Jean-Yves|last3=Bach|first3=Francis|year=2011|bibcode=2009arXiv0904.3523J}}&lt;/ref&gt; Hierarchical norms have been applied to bioinformatics,&lt;ref name=":4"&gt;S. Kim and E. Xing. Tree-guided group Lasso for multi-task regression with structured sparsity. In Proc. ICML, 2010.&lt;/ref&gt; computer vision and topic models.&lt;ref name=":5"&gt;R. Jenatton, J. Mairal, G. Obozinski, and F. Bach. Proximal methods for sparse hierarchical dictionary learning. In Proc. ICML, 2010.&lt;/ref&gt;

==== Norms defined on grids ====
If the structure assumed over variables is in the form of a 1D, 2D or 3D grid, then submodular functions based on overlapping groups can be considered as norms, leading to stable sets equal to rectangular or convex shapes.&lt;ref name=":1" /&gt; Such methods have applications in computer vision&lt;ref name=":6"&gt;R. Jenatton, G. Obozinski, and F. Bach. Structured sparse principal component analysis. In ''Proc. AISTATS'', 2009.&lt;/ref&gt;

== Algorithms for computation ==

=== Best subset selection problem ===
The problem of choosing the best subset of input variables can be naturally formulated under a penalization framework as:&lt;ref name="LR18"&gt;L. Rosasco. Lecture 10 of the Lecture Notes for 9.520: Statistical Learning Theory and Applications. Massachusetts Institute of Technology, Fall 2014. Available at https://www.mit.edu/~9.520/fall14/slides/class18/class18_sparsity.pdf&lt;/ref&gt;
: &lt;math&gt;\min_{w\in\mathbb{R}^d} \frac{1}{n}\sum_{i=1}^n V(y_i, w, x_i)  + \lambda \|w\|_0, &lt;/math&gt;
Where &lt;math&gt;\|w\|_0&lt;/math&gt; denotes the &lt;math&gt;\ell_0&lt;/math&gt; "norm", defined as the number of nonzero entries of the vector &lt;math&gt;w&lt;/math&gt;.

Although this formulation makes sense from a modeling perspective, it is computationally unfeasible, as it is equivalent to an exhaustive search evaluating all possible subsets of variables.&lt;ref name="LR18" /&gt;

Two main approaches for solving the optimization problem are: 1) greedy methods, such as [[Stepwise regression|step-wise regression]] in statistics, or [[matching pursuit]] in [[signal processing]]; and 2) convex relaxation formulation approaches and [[Proximal gradient methods for learning|proximal gradient]] optimization methods.

=== Convex relaxation ===
A natural approximation for the best subset selection problem is the &lt;math&gt;\ell_1&lt;/math&gt; norm regularization:&lt;ref name="LR18" /&gt;
: &lt;math&gt; \min_{w\in\mathbb{R}^d}  \frac{1}{n}\sum_{i=1}^n V(y_i, w, x_i) + \lambda \|w\|_1&lt;/math&gt;
Such as scheme is called [[basis pursuit]] or the [[Lasso (statistics)|Lasso]], which substitutes the &lt;math&gt;\ell_0&lt;/math&gt; "norm" for the convex, non-differentiable &lt;math&gt;\ell_1&lt;/math&gt; norm.

=== Proximal gradient methods ===
{{Main article|Proximal gradient methods for learning|l1=Proximal gradient methods}}

[[Proximal gradient methods for learning|Proximal gradient methods]], also called forward-backward splitting, are optimization methods useful for minimizing functions with a [[Convex function|convex]] and [[Differentiable function|differentiable]] component, and a convex potentially non-differentiable component.

As such, proximal gradient methods are useful for solving sparsity and structured sparsity regularization problems&lt;ref name=":0"&gt;{{cite arXiv|last = Villa|first = S.|author2 = Rosasco, L.|author3 = Mosci, S.|author4 = Verri, A.|title = Proximal methods for the latent group lasso penalty|year = 2012|eprint = 1209.0368|class = math.OC}}&lt;/ref&gt; of the following form: 
: &lt;math&gt; \min_{w\in\mathbb{R}^d}  \frac{1}{n}\sum_{i=1}^n V(y_i, w, x_i) + R(w)&lt;/math&gt;
Where &lt;math&gt;V(y_i, w, x_i) &lt;/math&gt; is a convex and differentiable [[loss function]] like the [[Loss function#Quadratic loss function|quadratic loss]], and &lt;math&gt;R(w) &lt;/math&gt; is a convex potentially non-differentiable regularizer such as the &lt;math&gt;\ell_1&lt;/math&gt; norm.

== Connections to Other Areas of Machine Learning ==

=== Connection to Multiple Kernel Learning ===
{{main article|Multiple kernel learning}}

Structured Sparsity regularization can be applied in the context of [[multiple kernel learning]].&lt;ref name=":7"&gt;{{Cite journal|title = MIT 9.520 course notes Fall 2015, chapter 6|last = Rosasco|first = Lorenzo|date = Fall 2015|last2 = Poggio, Tomaso}}&lt;/ref&gt; Multiple kernel learning refers to a set of machine learning methods that use a predefined set of kernels and learn an optimal linear or non-linear combination of kernels as part of the algorithm.

In the algorithms mentioned above, a whole space was taken into consideration at once and was partitioned into groups, i.e. subspaces. A complementary point of view is to consider the case in which distinct spaces are combined to obtain a new one. It is useful to discuss this idea considering finite dictionaries. Finite dictionaries with linearly independent elements - these elements are also known as atoms - refer to finite sets of linearly independent basis functions, the linear combinations of which define hypothesis spaces. Finite dictionaries can be used to define specific kernels, as will be shown.&lt;ref name=":7" /&gt; Assume for this example that rather than only one dictionary, several finite dictionaries are considered.

For simplicity, the case in which there are only two dictionaries &lt;math&gt;A = \{a_j: X \rightarrow \R, j=1,...,p\} &lt;/math&gt; and &lt;math&gt;B = \{b_t: X \rightarrow \R, t=1,...,q\} &lt;/math&gt; where &lt;math&gt;q&lt;/math&gt; and &lt;math&gt;p&lt;/math&gt; are integers, will be considered. The atoms in &lt;math&gt;A&lt;/math&gt; as well as the atoms in &lt;math&gt;B&lt;/math&gt; are assumed to be linearly independent. Let &lt;math&gt;D = \{d_k: X \rightarrow \R, k=1,...,p+q\} = A \cup B &lt;/math&gt; be the union of the two dictionaries. Consider the linear space of functions &lt;math&gt;H &lt;/math&gt; given by linear combinations of the form

&lt;math&gt;f(x) = \sum_{i=1}^{p+q}{w^j d_j(x)} = \sum_{j=1}^{p}{w_A^j a_j(x)} + \sum_{t=1}^{q}{w_B^t b_t(x)}, x \in X &lt;/math&gt;

for some coefficient vectors &lt;math&gt;w_A \in \R^p, w_B \in \R^q &lt;/math&gt;, where &lt;math&gt;w=(w_A,w_B) &lt;/math&gt;. Assume the atoms in &lt;math&gt;D &lt;/math&gt; to still be linearly independent, or equivalently, that the map &lt;math&gt;w = (w_A, w_B) \mapsto f &lt;/math&gt; is one to one. The functions in the space &lt;math&gt;H &lt;/math&gt; can be seen as the sums of two components, one in the space &lt;math&gt;H_A &lt;/math&gt;, the linear combinations of atoms in  &lt;math&gt;A&lt;/math&gt; and one in &lt;math&gt;H_B &lt;/math&gt;, the linear combinations of the atoms in &lt;math&gt;B&lt;/math&gt;.

One choice of norm on this space is &lt;math&gt;||f|| = ||w_A|| + ||w_B|| &lt;/math&gt;. Note that we can now view &lt;math&gt;H &lt;/math&gt; as a function space in which  &lt;math&gt;H_A &lt;/math&gt;,  &lt;math&gt;H_B &lt;/math&gt; are subspaces. In view of the linear independence assumption, &lt;math&gt;H &lt;/math&gt; can be identified with &lt;math&gt;\R^{p+q} &lt;/math&gt; and &lt;math&gt;H_A, H_B &lt;/math&gt; with &lt;math&gt;\R^p, \R^q &lt;/math&gt; respectively. The norm mentioned above can be seen as the group norm in  &lt;math&gt;H &lt;/math&gt;associated to the subspaces  &lt;math&gt;H_A &lt;/math&gt;,  &lt;math&gt;H_B &lt;/math&gt;, providing a connection to structured sparsity regularization.

Here, &lt;math&gt;H_A &lt;/math&gt;,  &lt;math&gt;H_B &lt;/math&gt; and &lt;math&gt;H &lt;/math&gt; can be seen to be the reproducing kernel Hilbert spaces with corresponding feature maps &lt;math&gt;\Phi_A : X \rightarrow \R^p &lt;/math&gt;, given by &lt;math&gt;\Phi_A(x) = (a_1(x),...,a_p(x)) &lt;/math&gt;, &lt;math&gt;\Phi_B : X \rightarrow \R^q &lt;/math&gt;, given by &lt;math&gt;\Phi_B(x) = (b_1(x),...,b_q(x)) &lt;/math&gt;, and &lt;math&gt;\Phi: X \rightarrow \R^{p+q} &lt;/math&gt;, given by the concatenation of &lt;math&gt;\Phi_A, \Phi_B &lt;/math&gt;, respectively.

In the structured sparsity regularization approach to this scenario, the relevant groups of variables which the group norms consider correspond to the subspaces &lt;math&gt;H_A &lt;/math&gt; and &lt;math&gt;H_B &lt;/math&gt;. This approach promotes setting the groups of coefficients corresponding to these subspaces to zero as opposed to only individual coefficients, promoting sparse multiple kernel learning.

The above reasoning directly generalizes to any finite number of dictionaries, or feature maps. It can be extended to feature maps inducing infinite dimensional hypothesis

spaces.&lt;ref name=":7" /&gt;

==== When Sparse Multiple Kernel Learning is useful ====
Considering sparse multiple kernel learning is useful in several situations including the following:
* Data fusion: When each kernel corresponds to a different kind of modality/feature.
* Nonlinear variable selection: Consider kernels &lt;math&gt;K_g&lt;/math&gt; depending only one dimension of the input.

Generally sparse multiple kernel learning is particularly useful when there are many kernels and model selection and interpretability are important.&lt;ref name=":7" /&gt;

== Additional uses and applications ==
Structured sparsity regularization methods have been used in a number of settings where it is desired to impose an ''a priori'' input variable structure to the regularization process. Some such applications are:
* [[Compressed sensing|Compressive sensing]] in [[magnetic resonance imaging]] (MRI), reconstructing MR images from a small number of measurements, potentially yielding significant reductions in MR scanning time&lt;ref name="MRI" /&gt;
* Robust [[Facial recognition system|face recognition]] in the presence of misalignment, occlusion and illumination variation&lt;ref name="face_recognition" /&gt;
* Uncovering [[Sociolinguistics|socio-linguistic]] associations between lexical frequencies used by Twitter authors, and the socio-demographic variables of their geographic communities&lt;ref name="sociolinguistic" /&gt;
* Gene selection analysis of breast cancer data using priors of overlapping groups, e.g., biologically meaningful gene sets&lt;ref name="genetic" /&gt;

== See also ==
* [[Statistical learning theory]]
* [[Regularization (mathematics)#Regularization in statistics and machine learning|Regularization]]
* [[Sparse approximation]]
* [[Proximal gradient method]]s
* [[Convex analysis]]
* [[Feature selection]]

== References ==
{{reflist}}

[[Category:Machine learning]]
[[Category:First order methods|First order methods]]
[[Category:Convex optimization]]</text>
      <sha1>r70xyqnkne21i5upabhq7wz0l8v3uh7</sha1>
    </revision>
  </page>
  <page>
    <title>Validation set</title>
    <ns>0</ns>
    <id>39945557</id>
    <redirect title="Training, validation, and test sets" />
    <revision>
      <id>966458832</id>
      <parentid>866599529</parentid>
      <timestamp>2020-07-07T07:18:36Z</timestamp>
      <contributor>
        <username>Dexbot</username>
        <id>16752040</id>
      </contributor>
      <minor/>
      <comment>Bot: Fixing broken section link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="145" xml:space="preserve">#REDIRECT [[Training, validation, and test sets#Validation dataset]] {{R to section}}

[[Category:Machine learning]]
[[Category:Model selection]]</text>
      <sha1>dn1572uay7xs98cs8i5jqfhg7fm8lsg</sha1>
    </revision>
  </page>
  <page>
    <title>Sparse dictionary learning</title>
    <ns>0</ns>
    <id>48813654</id>
    <revision>
      <id>1000477732</id>
      <parentid>982834056</parentid>
      <timestamp>2021-01-15T07:56:21Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>References after punctuation per [[WP:REFPUNCT]], [[WP:CITEFOOT]], [[WP:PAIC]] + other fixes</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="23302" xml:space="preserve">&lt;br /&gt;{{Machine learning bar}}'''Sparse coding''' is a [[representation learning]] method which aims at finding a [[Sparse matrix|sparse]] representation of the input data (also known as ''sparse coding'') in the form of a linear combination of basic elements as well as those basic elements themselves. These elements are called ''atoms'' and they compose a ''dictionary''. Atoms in the dictionary are not required to be [[Orthogonal basis|orthogonal]], and they may be an over-complete spanning set. This problem setup also allows the dimensionality of the signals being represented to be higher than the one of the signals being observed. The above two properties lead to having seemingly redundant atoms that allow multiple representations of the same signal but also provide an improvement in [[sparsity]] and flexibility of the representation.

One of the most important applications of sparse dictionary learning is in the field of '''''[[compressed sensing]]''''' or '''''[[Detection theory|signal recovery]]'''''. In compressed sensing, a high-dimensional signal can be recovered with only a few linear measurements provided that the signal is sparse or nearly sparse. Since not all signals satisfy this sparsity condition, it is of great importance to find a sparse representation of that signal such as the '''''[[wavelet transform]]''''' or the directional gradient of a rasterized matrix. Once a matrix or a high dimensional vector is transferred to a sparse space, different recovery algorithms like '''''[[basis pursuit]]''''', CoSaMP&lt;ref&gt;{{Cite journal|last=Needell|first=D.|last2=Tropp|first2=J.A.|title=CoSaMP: Iterative signal recovery from incomplete and inaccurate samples|journal=Applied and Computational Harmonic Analysis|volume=26|issue=3|pages=301–321|doi=10.1016/j.acha.2008.07.002|year=2009|arxiv=0803.2392}}&lt;/ref&gt; or '''''fast non-iterative algorithms'''''&lt;ref&gt;Lotfi, M.; Vidyasagar, M."[[arxiv:1708.03608|A Fast Non-iterative Algorithm for Compressive Sensing Using Binary Measurement Matrices]]"&lt;/ref&gt; can be used to recover the signal.

One of the key principles of dictionary learning is that the dictionary has to be inferred from the input data. The emergence of sparse dictionary learning methods was stimulated by the fact that in [[signal processing]] one typically wants to represent the input data using as few components as possible. Before this approach the general practice was to use predefined dictionaries (such as [[Fourier transform|fourier]] or [[Wavelet transform|wavelet]] transforms). However, in certain cases a dictionary that is trained to fit the input data can significantly improve the sparsity, which has applications in data decomposition, compression and analysis and has been used in the fields of image [[Noise reduction|denoising]] and [[Image classification|classification]], video and [[Audio signal processing|audio processing]]. Sparsity and overcomplete dictionaries have immense applications in image compression, image fusion and inpainting.  
[[File:Dic_learning.jpg|thumb|Image Denoising by Dictionary Learning]]

== Problem statement ==
Given the input dataset &lt;math&gt;X = [x_1, ..., x_K], x_i \in \mathbb{R}^d&lt;/math&gt; we wish to find a dictionary &lt;math&gt;\mathbf{D} \in \mathbb{R}^{d \times n}: D = [d_1, ..., d_n]&lt;/math&gt; and a representation &lt;math&gt;R = [r_1,...,r_K], r_i \in \mathbb{R}^n&lt;/math&gt; such that both &lt;math&gt;\|X-\mathbf{D}R\|^2_F&lt;/math&gt; is minimized and the representations &lt;math&gt;r_i&lt;/math&gt; are sparse enough. This can be formulated as the following [[optimization problem]]:

&lt;math&gt;\underset{\mathbf{D} \in \mathcal{C}, r_i \in \mathbb{R}^n}{\text{argmin}} \sum_{i=1}^K\|x_i-\mathbf{D}r_i\|_2^2+\lambda \|r_i\|_0&lt;/math&gt;, where &lt;math&gt;\mathcal{C} \equiv \{\mathbf{D} \in \mathbb{R}^{d \times n}: \|d_i\|_2 \leq 1 \,\, \forall i =1,...,n \}&lt;/math&gt;, &lt;math&gt;\lambda&gt;0&lt;/math&gt;

&lt;math&gt;\mathcal{C}&lt;/math&gt; is required to constrain &lt;math&gt;\mathbf{D}&lt;/math&gt; so that its atoms would not reach arbitrarily high values allowing for arbitrarily low (but non-zero) values of &lt;math&gt;r_i&lt;/math&gt;.&lt;math&gt;\lambda&lt;/math&gt; controls the trade off between the sparsity and the minimization error.

The minimization problem above is not convex because of the [[L0 norm|ℓ&lt;sub&gt;0&lt;/sub&gt;-"norm"]] and solving this problem is NP-hard.&lt;ref&gt;A. M. Tillmann, "[[doi:10.1109/LSP.2014.2345761|On the Computational Intractability of Exact and Approximate Dictionary Learning]]", IEEE Signal Processing Letters 22(1), 2015: 45–49.&lt;/ref&gt; In some cases ''[[L1-norm|L]]''&lt;sup&gt;[[L1-norm|1]]&lt;/sup&gt;[[L1-norm|-norm]] is known to ensure sparsity&lt;ref&gt;{{Cite journal|title = For most large underdetermined systems of linear equations the minimal 𝓁1-norm solution is also the sparsest solution|journal = Communications on Pure and Applied Mathematics|date = 2006-06-01|issn = 1097-0312|pages = 797–829|volume = 59|issue = 6|doi = 10.1002/cpa.20132|first = David L.|last = Donoho}}&lt;/ref&gt; and so the above becomes a [[convex optimization]] problem with respect to each of the variables &lt;math&gt;\mathbf{D}&lt;/math&gt; and &lt;math&gt;\mathbf{R}&lt;/math&gt; when the other one is fixed, but it is not jointly convex in &lt;math&gt;(\mathbf{D}, \mathbf{R})&lt;/math&gt;.

=== Properties of the dictionary ===
The dictionary &lt;math&gt;\mathbf{D}&lt;/math&gt; defined above can be "undercomplete" if &lt;math&gt;n &lt; d&lt;/math&gt; or "overcomplete" in case &lt;math&gt;n&gt;d&lt;/math&gt; with the latter being a typical assumption for a sparse dictionary learning problem. The case of a complete dictionary does not provide any improvement from a representational point of view and thus isn't considered.

Undercomplete dictionaries represent the setup in which the actual input data lies in a lower-dimensional space. This case is strongly related to [[dimensionality reduction]] and techniques like [[principal component analysis]] which require atoms &lt;math&gt;d_1,...,d_n&lt;/math&gt; to be orthogonal.   The choice of these subspaces is crucial for efficient dimensionality reduction, but it is not trivial.  And dimensionality reduction based on dictionary representation can be extended to address specific tasks such as data analysis or classification. However, their main downside is limiting the choice of atoms.

Overcomplete dictionaries, however, do not require the atoms to be orthogonal (they will never be a [[Basis (linear algebra)|basis]] anyway) thus allowing for more flexible dictionaries and richer data representations.

An overcomplete dictionary which allows for sparse representation of signal can be a famous transform matrix (wavelets transform, fourier transform) or it can be formulated so that its elements are changed in such a way that it sparsely represents the given signal in a best way. Learned dictionaries are capable of giving sparser solutions as compared to predefined transform matrices.

== Algorithms ==
As the optimization problem described above can be solved as a convex problem with respect to either dictionary or sparse coding while the other one of the two is fixed, most of the algorithms are based on the idea of iteratively updating one and then the other.

The problem of finding an optimal sparse coding &lt;math&gt;R&lt;/math&gt; with a given dictionary &lt;math&gt;\mathbf{D}&lt;/math&gt; is known as [[sparse approximation]] (or sometimes just sparse coding problem). There has been developed a number of algorithms to solve it (such as [[matching pursuit]] and [[Lasso (statistics)|LASSO]]) which are incorporated into the algorithms described below.

=== Method of optimal directions (MOD) ===
The method of optimal directions (or MOD) was one of the first methods introduced to tackle the sparse dictionary learning problem.&lt;ref&gt;{{Cite book|title = Method of optimal directions for frame design|journal =  1999 IEEE International Conference on Acoustics, Speech, and Signal Processing, 1999. Proceedings|date = 1999-01-01|pages = 2443–2446 vol.5|volume = 5|doi = 10.1109/ICASSP.1999.760624|first = K.|last = Engan|author-link=Kjersti Engan|first2 = S.O.|last2 = Aase|first3 = J.|last3 = Hakon Husoy|isbn = 978-0-7803-5041-0|url = https://www.semanticscholar.org/paper/684732677d91a93b115f57e8d671ef7f5f13ee14}}&lt;/ref&gt; The core idea of it is to solve the minimization problem subject to the limited number of non-zero components of the representation vector:

&lt;math&gt;\min_{\mathbf{D}, R}\{\|X-\mathbf{D}R\|^2_F\} \,\, \text{s.t.}\,\, \forall i \,\,\|r_i\|_0 \leq T &lt;/math&gt;

Here, &lt;math&gt;F&lt;/math&gt; denotes the [[Frobenius norm]]. MOD alternates between getting the [[Sparse approximation|sparse coding]] using a method such as [[matching pursuit]] and updating the dictionary by computing the analytical solution of the problem given by &lt;math&gt;\mathbf{D} = XR^+ &lt;/math&gt; where &lt;math&gt;R^+ &lt;/math&gt; is a [[Moore–Penrose pseudoinverse|Moore-Penrose pseudoinverse]]. After this update &lt;math&gt;\mathbf{D} &lt;/math&gt; is renormalized to fit the constraints and the new sparse coding is obtained again. The process is repeated until convergence (or until a sufficiently small residue).

MOD has proved to be a very efficient method for low-dimensional input data &lt;math&gt;X &lt;/math&gt; requiring just a few iterations to converge. However, due to the high complexity of the matrix-inversion operation, computing the pseudoinverse in high-dimensional cases is in many cases intractable. This shortcoming has inspired the development of other dictionary learning methods.

=== K-SVD ===
{{main|K-SVD}}[[K-SVD]] is an algorithm that performs [[Singular value decomposition|SVD]] at its core to update the atoms of the dictionary one by one and basically is a generalization of [[K-means clustering|K-means]]. It enforces that each element of the input data &lt;math&gt;x_i&lt;/math&gt; is encoded by a linear combination of not more than &lt;math&gt;T_0 &lt;/math&gt; elements in a way identical to the MOD approach:

&lt;math&gt;\min_{\mathbf{D}, R}\{\|X-\mathbf{D}R\|^2_F\} \,\, \text{s.t.}\,\, \forall i \,\,\|r_i\|_0 \leq T_0 &lt;/math&gt;

This algorithm's essence is to first fix the dictionary, find the best possible &lt;math&gt;R &lt;/math&gt; under the above constraint (using [[Matching pursuit#Extensions|Orthogonal Matching Pursuit]]) and then iteratively update the atoms of dictionary &lt;math&gt;\mathbf{D}&lt;/math&gt; in the following manner:

&lt;math&gt;
\|X - \mathbf{D}R\|^2_F =  \left| X - \sum_{i = 1}^K d_i x^i_T\right|^2_F = \| E_k - d_k x^k_T\|^2_F
&lt;/math&gt;

The next steps of the algorithm include [[Low-rank approximation|rank-1 approximation]] of the residual matrix &lt;math&gt;
E_k
&lt;/math&gt;, updating &lt;math&gt;
d_k
&lt;/math&gt; and enforcing the sparsity of &lt;math&gt;
x_k
&lt;/math&gt; after the update. This algorithm is considered to be standard for dictionary learning and is used in a variety of applications. However, it shares weaknesses with MOD being efficient only for signals with relatively low dimensionality and having the possibility for being stuck at local minima.

=== Stochastic gradient descent ===
{{Main|Stochastic gradient descent}}One can also apply a widespread stochastic gradient descent method with iterative projection to solve this problem.&lt;ref&gt;{{Cite journal|title = Sparse and Redundant Modeling of Image Content Using an Image-Signature-Dictionary|journal = SIAM Journal on Imaging Sciences|pages = 228–247|volume = 1|issue = 3|doi = 10.1137/07070156x|first = Michal|last = Aharon|first2 = Michael|last2 = Elad|year = 2008|citeseerx = 10.1.1.298.6982}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|title = Yair Censor and Stavros A. Zenios, Parallel Optimization — Theory, Algorithms, and Applications. Oxford University Press, New York/Oxford, 1997, xxviii+539 pages. (US $ 85.00) |isbn=978-0-19-510062-4 |journal = Journal of Global Optimization|date = 2000-01-01|issn = 0925-5001|pages = 107–108|volume = 16|issue = 1|doi = 10.1023/A:1008311628080|first = János D.|last = Pintér|url=https://www.semanticscholar.org/paper/b31b0f7ff361e51600dcf715b17777ec364dc4c9 }}&lt;/ref&gt; The idea of this method is to update the dictionary using the first order stochastic gradient and project it on the constraint set &lt;math&gt;\mathcal{C}&lt;/math&gt;. The step that occurs at i-th iteration is described by this expression:

&lt;math&gt;\mathbf{D}_i = \text{proj}_{\mathcal{C}} \left\{\mathbf{D}_{i-1}-\delta_i\nabla_{\mathbf{D}}\sum_{i \in S}\|x_i-\mathbf{D}r_i\|_2^2+\lambda\|r_i\|_1 \right\}&lt;/math&gt;, where &lt;math&gt;S&lt;/math&gt; is a random subset of &lt;math&gt;\{1...K\}&lt;/math&gt; and &lt;math&gt;\delta_i&lt;/math&gt; is a gradient step.

=== Lagrange dual method ===
An algorithm based on solving a [[Duality (optimization)|dual Lagrangian problem]] provides an efficient way to solve for the dictionary having no complications induced by the sparsity function.&lt;ref&gt;Lee, Honglak, et al. "Efficient sparse coding algorithms." ''Advances in neural information processing systems''. 2006.&lt;/ref&gt; Consider the following Lagrangian:

&lt;math&gt;\mathcal{L}(\mathbf{D}, \Lambda) = \text{tr}\left((X-\mathbf{D}R)^T(X-\mathbf{D}R)\right) + \sum_{j=1}^n\lambda_i \left({\sum_{i=1}^d\mathbf{D}_{ij}^2-c} \right)&lt;/math&gt;, where &lt;math&gt;c&lt;/math&gt; is a constraint on the norm of the atoms and &lt;math&gt;\lambda_i&lt;/math&gt; are the so-called dual variables forming the diagonal matrix &lt;math&gt;\Lambda&lt;/math&gt;.

We can then provide an analytical expression for the Lagrange dual after minimization over &lt;math&gt;\mathbf{D}&lt;/math&gt;:

&lt;math&gt;\mathcal{D}(\Lambda) = \min_{\mathbf{D}}\mathcal{L}(\mathbf{D}, \Lambda) = \text{tr}(X^TX-XR^T(RR^T+\Lambda)^{-1}(XR^T)^T-c\Lambda)&lt;/math&gt;.

After applying one of the optimization methods to the value of the dual (such as [[Newton's method in optimization|Newton's method]] or [[Conjugate gradient method|conjugate gradient]]) we get the value of &lt;math&gt;\mathbf{D}&lt;/math&gt;:

&lt;math&gt;\mathbf{D}^T=(RR^T+\Lambda)^{-1}(XR^T)^T&lt;/math&gt;

Solving this problem is less computational hard because the amount of dual variables &lt;math&gt;n&lt;/math&gt; is a lot of times much less than the amount of variables in the primal problem.

===[[Lasso (statistics)|LASSO]]===
In this approach, the optimization problem is formulated as:

&lt;math&gt;\min_{r \in \mathbb{R}^n}\{\,\,\|r\|_1\} \,\, \text{subject to}\,\,\|X-\mathbf{D}R\|^2_F &lt; \epsilon &lt;/math&gt;, where &lt;math&gt;\epsilon &lt;/math&gt; is the permitted error in the reconstruction '''LASSO.'''

It finds an estimate of &lt;math&gt;r_i &lt;/math&gt; by minimizing the least square error subject to a ''[[L1-norm|L]]''&lt;sup&gt;[[L1-norm|1]]&lt;/sup&gt;[[L1-norm|-norm]] constraint in the solution vector, formulated as:

&lt;math&gt;\min_{r \in \mathbb{R}^n} \,\, \dfrac{1}{2}\,\,\|X-\mathbf{D}r\|^2_F + \lambda \,\,\|r\|_1 &lt;/math&gt;, where &lt;math&gt;\lambda &gt; 0 &lt;/math&gt; controls the trade-off between sparsity and the reconstruction error. This gives the global optimal solution.&lt;ref&gt;{{Cite web|url=http://home.iitk.ac.in/~saurabhk/EE609A_12011_12807637_.pdf|title=Dictionary Learning Based Applications in Image Processing using Convex Optimisation|last=Kumar|first=Abhay|last2=Kataria|first2=Saurabh}}&lt;/ref&gt; See also [https://www.di.ens.fr/~fbach/mairal_icml09.pdf Online dictionary learning for Sparse coding]

=== Parametric training methods ===
Parametric training methods are aimed to incorporate the best of both worlds — the realm of analytically constructed dictionaries and the learned ones.&lt;ref&gt;{{Cite journal|title = Dictionaries for Sparse Representation Modeling|journal = Proceedings of the IEEE|date = 2010-06-01|issn = 0018-9219|pages = 1045–1057|volume = 98|issue = 6|doi = 10.1109/JPROC.2010.2040551|first = R.|last = Rubinstein|first2 = A.M.|last2 = Bruckstein|first3 = M.|last3 = Elad|citeseerx = 10.1.1.160.527}}&lt;/ref&gt; This allows to construct more powerful generalized dictionaries that can potentially be applied to the cases of arbitrary-sized signals. Notable approaches include: 
* Translation-invariant dictionaries.&lt;ref&gt;{{Cite journal|title = Family of Iterative LS-based Dictionary Learning Algorithms, ILS-DLA, for Sparse Signal Representation|journal = Digit. Signal Process.|date = 2007-01-01|issn = 1051-2004|pages = 32–49|volume = 17|issue = 1|doi = 10.1016/j.dsp.2006.02.002|first = Kjersti|last = Engan|author-link=Kjersti Engan|first2 = Karl|last2 = Skretting|first3 = John H\a akon|last3 = Husøy}}&lt;/ref&gt; These dictionaries are composed by the translations of the atoms originating from the dictionary constructed for a finite-size signal patch. This allows the resulting dictionary to provide a representation for the arbitrary-sized signal. 
* Multiscale dictionaries.&lt;ref&gt;{{Cite journal|title = Learning Multiscale Sparse Representations for Image and Video Restoration|journal = Multiscale Modeling &amp; Simulation|date = 2008-01-01|issn = 1540-3459|pages = 214–241|volume = 7|issue = 1|doi = 10.1137/070697653|first = J.|last = Mairal|first2 = G.|last2 = Sapiro|first3 = M.|last3 = Elad|citeseerx = 10.1.1.95.6239}}&lt;/ref&gt; This method focuses on constructing a dictionary that is composed of differently scaled dictionaries to improve sparsity. 
* Sparse dictionaries.&lt;ref&gt;{{Cite journal|title = Double Sparsity: Learning Sparse Dictionaries for Sparse Signal Approximation|journal = IEEE Transactions on Signal Processing|date = 2010-03-01|issn = 1053-587X|pages = 1553–1564|volume = 58|issue = 3|doi = 10.1109/TSP.2009.2036477|first = R.|last = Rubinstein|first2 = M.|last2 = Zibulevsky|first3 = M.|last3 = Elad|citeseerx = 10.1.1.183.992|bibcode = 2010ITSP...58.1553R}}&lt;/ref&gt; This method focuses on not only providing a sparse representation but also constructing a sparse dictionary which is enforced by the expression &lt;math&gt;\mathbf{D} = \mathbf{B}\mathbf{A}  &lt;/math&gt; where &lt;math&gt;\mathbf{B}&lt;/math&gt; is some pre-defined analytical dictionary with desirable properties such as fast computation and &lt;math&gt;\mathbf{A}&lt;/math&gt; is a sparse matrix. Such formulation allows to directly combine the fast implementation of analytical dictionaries with the flexibility of sparse approaches.

=== Online dictionary learning ([https://www.di.ens.fr/~fbach/mairal_icml09.pdf LASSO approach]) ===
Many common approaches to sparse dictionary learning rely on the fact that the whole input data &lt;math&gt;X&lt;/math&gt; (or at least a large enough training dataset) is available for the algorithm. However, this might not be the case in the real-world scenario as the size of the input data might be too big to fit it into memory. The other case where this assumption can not be made is when the input data comes in a form of a [[Stream (computing)|stream]]. Such cases lie in the field of study of [[Online machine learning|online learning]] which essentially suggests iteratively updating the model upon the new data points &lt;math&gt;x&lt;/math&gt; becoming available.

A dictionary can be learned in an online manner the following way:&lt;ref&gt;{{Cite journal|title = Online Learning for Matrix Factorization and Sparse Coding|url = http://dl.acm.org/citation.cfm?id=1756006.1756008|journal = J. Mach. Learn. Res.|date = 2010-03-01|issn = 1532-4435|pages = 19–60|volume = 11|first = Julien|last = Mairal|first2 = Francis|last2 = Bach|first3 = Jean|last3 = Ponce|first4 = Guillermo|last4 = Sapiro|bibcode = 2009arXiv0908.0050M|arxiv = 0908.0050}}&lt;/ref&gt;
# For &lt;math&gt;t = 1...T:&lt;/math&gt;
# Draw a new sample &lt;math&gt;x_t&lt;/math&gt;
# Find a sparse coding using [[Least-angle regression|LARS]]: &lt;math&gt;r_t = \underset{r \in \mathbb{R}^n}{\text{argmin}}\left(\frac{1}{2}\|x_t-\mathbf{D}_{t-1}r\|+\lambda\|r\|_1\right)&lt;/math&gt;
# Update dictionary using [[Coordinate descent|block-coordinate]] approach: &lt;math&gt;\mathbf{D}_t = \underset{\mathbf{D} \in \mathcal{C}}{\text{argmin}}\frac{1}{t}\sum_{i=1}^t\left(\frac{1}{2}\|x_i-\mathbf{D}r_i\|^2_2+\lambda\|r_i\|_1\right)&lt;/math&gt;

This method allows us to gradually update the dictionary as new data becomes available for sparse representation learning and helps drastically reduce the amount of memory needed to store the dataset (which often has a huge size).

== Applications ==
The dictionary learning framework, namely the linear decomposition of an input signal using a few basis elements learned from data itself, has led to state-of-art results in various image and video processing tasks. This technique can be applied to classification problems in a way that if we have built specific dictionaries for each class, the input signal can be classified by finding the dictionary corresponding to the sparsest representation.

It also has properties that are useful for signal denoising since usually one can learn a dictionary to represent the meaningful part of the input signal in a sparse way but the noise in the input will have a much less sparse representation.&lt;ref&gt;Aharon, M, M Elad, and A Bruckstein. 2006. "K-SVD: An Algorithm for Designing Overcomplete Dictionaries for Sparse Representation." Signal Processing, IEEE Transactions on 54 (11): 4311-4322&lt;/ref&gt;

Sparse dictionary learning has been successfully applied to various image, video and audio processing tasks as well as to texture synthesis&lt;ref&gt;{{Cite journal|title = Sparse Modeling of Textures|journal = Journal of Mathematical Imaging and Vision|date = 2008-11-06|issn = 0924-9907|pages = 17–31|volume = 34|issue = 1|doi = 10.1007/s10851-008-0120-3|first = Gabriel|last = Peyré|url = https://hal.archives-ouvertes.fr/hal-00359747/file/08-JMIV-Peyre-SparseTextures.pdf}}&lt;/ref&gt; and unsupervised clustering.&lt;ref&gt;{{Cite book|title = Classification and clustering via dictionary learning with structured incoherence and shared features|url = http://www.computer.org/csdl/proceedings/cvpr/2010/6984/00/05539964-abs.html|publisher = IEEE Computer Society|journal = 2014 IEEE Conference on Computer Vision and Pattern Recognition|date = 2010-01-01|location = Los Alamitos, CA, USA|isbn = 978-1-4244-6984-0|pages = 3501–3508|volume = 0|doi = 10.1109/CVPR.2010.5539964|first = Ignacio|last = Ramirez|first2 = Pablo|last2 = Sprechmann|first3 = Guillermo|last3 = Sapiro}}&lt;/ref&gt; In evaluations with the [[Bag-of-words model in computer vision|Bag-of-Words]] model,&lt;ref&gt;{{Cite journal|last=Koniusz|first=Piotr|last2=Yan|first2=Fei|last3=Mikolajczyk|first3=Krystian|date=2013-05-01|title=Comparison of mid-level feature coding approaches and pooling strategies in visual concept detection|journal=Computer Vision and Image Understanding|volume=117|issue=5|pages=479–492|doi=10.1016/j.cviu.2012.10.010|issn=1077-3142|citeseerx=10.1.1.377.3979}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Koniusz|first=Piotr|last2=Yan|first2=Fei|last3=Gosselin|first3=Philippe Henri|last4=Mikolajczyk|first4=Krystian|date=2017-02-24|title=Higher-order occurrence pooling for bags-of-words: Visual concept detection|journal=IEEE Transactions on Pattern Analysis and Machine Intelligence|volume=39|issue=2|pages=313–326|doi=10.1109/TPAMI.2016.2545667|pmid=27019477|issn=0162-8828|hdl=10044/1/39814|url=http://spiral.imperial.ac.uk/bitstream/10044/1/39814/2/pkpami2e-peter.pdf}}&lt;/ref&gt; sparse coding was found empirically to outperform other coding approaches on the object category recognition tasks.

Dictionary learning is used to analyse medical signals in detail. Such medical signals include those from electroencephalography (EEG), electrocardiography (ECG), magnetic resonance imaging (MRI), functional MRI (fMRI), and ultrasound computer tomography (USCT), where different assumptions are used to analyze each signal.

== See also ==
* [[Sparse approximation]]
* [[Sparse PCA]]
* [[Matrix factorization]]
* [[K-SVD]]
* [[Sparse coding|Neural sparse coding]]
* [[SimCO]]

== References ==
&lt;references /&gt;

[[Category:Machine learning]]
[[Category:Unsupervised learning]]</text>
      <sha1>m3cg9cr5zp6wn4dvnl1q637f7x244vn</sha1>
    </revision>
  </page>
  <page>
    <title>Darkforest</title>
    <ns>0</ns>
    <id>49316492</id>
    <revision>
      <id>973131863</id>
      <parentid>948088887</parentid>
      <timestamp>2020-08-15T15:13:54Z</timestamp>
      <contributor>
        <username>Ghettoblaster</username>
        <id>6603820</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="12896" xml:space="preserve">{{About|Facebook's Go-playing computer program||Dark Forest (disambiguation){{!}}Dark Forest}}
'''Darkforest''' is a [[computer go]] program developed by [[Facebook]], based on [[deep learning]] techniques using a [[convolutional neural network]]. Its updated version &lt;!-- not a typo --&gt;'''Darkfores2'''&lt;!-- not a typo --&gt; combines the techniques of its predecessor with  [[Monte Carlo tree search]].&lt;ref name="facebook-paper2"&gt;{{Cite arXiv|eprint=1511.06410v1|last1=Tian|first1=Yuandong|title=Better Computer Go Player with Neural Network and Long-term Prediction|last2=Zhu|first2=Yan|class=cs.LG|year=2015}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.technologyreview.com/s/544181/how-facebooks-ai-researchers-built-a-game-changing-go-engine/|title=How Facebook's AI Researchers Built a Game-Changing Go Engine|date=December 4, 2015|website=MIT Technology Review|access-date=2016-02-03}}&lt;/ref&gt; The MCTS effectively takes tree search methods commonly seen in computer chess programs and randomizes them.&lt;ref name=":1"&gt;{{Cite web|url=http://www.techtimes.com/articles/128636/20160128/facebook-ai-go-player-gets-smarter-with-neural-network-and-long-term-prediction-to-master-worlds-hardest-game.htm|title=Facebook AI Go Player Gets Smarter With Neural Network And Long-Term Prediction To Master World's Hardest Game|date=2016-01-28|website=Tech Times|access-date=2016-04-24}}&lt;/ref&gt; With the update, the system is known as '''Darkfmcts3'''.&lt;ref name=":2"&gt;{{Cite web|url=https://venturebeat.com/2016/01/26/facebooks-artificially-intelligent-go-player-is-getting-smarter/|title=Facebook's artificially intelligent Go player is getting smarter|website=VentureBeat|date=27 January 2016|access-date=2016-04-24}}&lt;/ref&gt;

Darkforest is of similar strength to programs like [[Crazy Stone (software)|CrazyStone]] and Zen.&lt;ref&gt;{{Cite web | url=http://livestream.com/oxuni/StracheyLectureDrDemisHassabis |title = Strachey Lecture - Dr Demis Hassabis by University of Oxford Live}}&lt;/ref&gt; It has been tested against a professional human player at the 2016 [[Computer Go UEC Cup|UEC cup]]. [[Google]]'s [[AlphaGo]] program won against a professional player in October 2015 using a similar combination of techniques.&lt;ref&gt;{{Cite news|url=https://www.theguardian.com/technology/2016/jan/28/go-playing-facebook-spoil-googles-ai-deepmind|title=No Go: Facebook fails to spoil Google's big AI day|last=90210|first=HAL|date=2016-01-28|newspaper=The Guardian|language=en-GB|issn=0261-3077|access-date=2016-02-01}}&lt;/ref&gt;

Darkforest is named after [[Liu Cixin]]'s science fiction novel ''[[The Dark Forest]]''.&lt;ref&gt;{{cite web|url=http://xw.qq.com/tech/20160301024236/TEC201603010242360D|title=FB围棋项目负责人谈人机大战|date=2016-03-01|publisher=Tencent|language=Chinese|trans-title=FB Go Project Manager Discusses Man vs Machine Showdown}}&lt;/ref&gt;

== Background ==
Competing with top human players in the ancient game of Go has been a long-term goal of artificial intelligence. Go’s high [[branching factor]] makes traditional search techniques ineffective, even on cutting-edge hardware, and Go’s [[evaluation function]] could change drastically with one stone change. However, by using a Deep [[Convolutional neural network|Convolutional Neural Network]] designed for long-term predictions, '''Darkforest''' has been able to substantially improve the win rate for bots over more traditional [[Monte Carlo tree search|Monte Carlo Tree Search]] based approaches.

=== Matches ===
Against human players, '''Darkfores2''' achieves a stable ''[[Go ranks and ratings|3d ranking]]'' on [[KGS Go Server]], which roughly corresponds to an advanced amateur human player. However, after adding [[Monte Carlo tree search|Monte Carlo Tree Search]] to '''Darkfores2''' to create a much stronger player named '''darkfmcts3,''' it can achieve a ''5d ranking'' on the KGS Go Server.

==== Against other AI ====
'''darkfmcts3''' is on par with state-of-the-art Go AIs such as Zen, DolBaram and [[Crazy Stone (software)|Crazy Stone]] but lags behind AlphaGo.&lt;ref&gt;{{Cite journal|title = Mastering the game of Go with deep neural networks and tree search|journal = [[Nature (journal)|Nature]]| issn= 0028-0836|pages = 484–489|volume = 529|issue = 7587|doi = 10.1038/nature16961|pmid = 26819042|first1 = David|last1 = Silver|author-link1=David Silver (programmer)|first2 = Aja|last2 = Huang|author-link2=Aja Huang|first3 = Chris J.|last3 = Maddison|first4 = Arthur|last4 = Guez|first5 = Laurent|last5 = Sifre|first6 = George van den|last6 = Driessche|first7 = Julian|last7 = Schrittwieser|first8 = Ioannis|last8 = Antonoglou|first9 = Veda|last9 = Panneershelvam|first10= Marc|last10= Lanctot|first11= Sander|last11= Dieleman|first12=Dominik|last12= Grewe|first13= John|last13= Nham|first14= Nal|last14= Kalchbrenner|first15= Ilya|last15= Sutskever|author-link15=Ilya Sutskever|first16= Timothy|last16= Lillicrap|first17= Madeleine|last17= Leach|first18= Koray|last18= Kavukcuoglu|first19= Thore|last19= Graepel|first20= Demis |last20=Hassabis|author-link20=Demis Hassabis|date= 28 January 2016|bibcode = 2016Natur.529..484S}}{{closed access}}&lt;/ref&gt; It won 3rd place in [https://www.gokgs.com/tournEntrants.jsp?sort=s&amp;id=1005 January 2016 KGS Bot Tournament] against other Go AIs.

=== News Coverage ===
After [[Google]]'s [[AlphaGo]] won against [[Fan Hui]] in 2015, [[Facebook]] made its AI's hardware designs public, alongside releasing the code behind DarkForest as open-source, along with heavy recruiting to strengthen its team of AI engineers.&lt;ref name=":1" /&gt;

== Style of play ==
'''Darkforest''' uses a neural network to sort through the 10&lt;sup&gt;100&lt;/sup&gt; board positions, and find the most powerful next move.&lt;ref name=":0"&gt;{{Cite web|url=https://www.technologyreview.com/s/544181/how-facebooks-ai-researchers-built-a-game-changing-go-engine/|title=How Facebook's AI Researchers Built a Game-Changing Go Engine|website=MIT Technology Review|access-date=2016-04-24}}&lt;/ref&gt; However, neural networks alone cannot match the level of good amateur players or the best search-based Go engines, and so '''Darkfores2''' combines the neural network approach with a search-based machine. A database of 250,000 real Go games were used in the development of '''Darkforest''', with 220,000 used as a training set and the rest used to test the neural network's ability to predict the next moves played in the real games.  This allows Darkforest to accurately evaluate the global state of the board, but local tactics were still poor. Search-based engines have poor global evaluation, but are good at local tactics. Combining these two approaches is difficult because search-based engines work much faster than neural networks, a problem which was solved in '''Darkfores2''' by running the processes in parallel with frequent communication between the two.&lt;ref name=":0" /&gt;

=== Conventional strategies ===
Go is generally played by analyzing the position of the stones on the board. Some advanced players have described it as playing in some part subconsciously. Unlike chess and checkers, where AI players can simply look farther forward at moves than human players, but with each round of Go having on average 250 possible moves, that approach is ineffective. Instead, neural networks copy human play by training the AI systems on images of successful moves, the AI can effectively learn how to interpret how the board looks, as many grandmasters do.&lt;ref name=":3"&gt;{{Cite journal|url=https://www.wired.com/2015/12/google-and-facebook-race-to-solve-the-ancient-game-of-go/|title=Google and Facebook Race to Solve the Ancient Game of Go With AI|journal=WIRED|date=7 December 2015|language=en-US|access-date=2016-04-24|last1=Metz|first1=Cade}}&lt;/ref&gt; In November 2015, Facebook demonstrated the combination of MCTS with neural networks, which played with a style that "felt human".&lt;ref name=":3" /&gt;

=== Flaws ===
It has been noted that Darkforest still has flaws in its play style. Sometimes the bot plays [[tenuki]] ("move elsewhere") pointlessly when local powerful moves are required. When the bot is losing, it shows the typical behavior of MCTS, it plays bad moves and loses more. The Facebook AI team has acknowledged these as areas of future improvement.&lt;ref&gt;{{Cite news|url=https://www.bbc.com/news/technology-35419141|title=Facebook trains AI to beat humans at Go board game - BBC News|work=BBC News|date=27 January 2016|language=en-GB|access-date=2016-04-24|last1=Kelion|first1=Leo}}&lt;/ref&gt;

== Program architecture ==
The family of '''Darkforest''' computer go programs is based on [[Convolutional neural network|convolution neural networks]].&lt;ref name=":1" /&gt; The most recent advances in '''Darkfmcts3''' combined convolutional neural networks with more traditional [[Monte Carlo tree search]].&lt;ref name=":1" /&gt; Darkfmcts3 is the most advanced version of Darkforest, which combines Facebook's most advanced convolutional neural network architecture from Darkfores2 with a [[Monte Carlo tree search]].

'''Darkfmcts3''' relies on a [[Convolutional neural network|convolution neural networks]] that predicts the next k moves based on the current state of play. It treats the board as a 19x19 image with multiple channels. Each channel represents a different aspect of board information based upon the specific style of play. For standard and extended play, there are 21 and 25 different channels, respectively. In standard play, each players [[List of Go terms#Liberty|liberties]] are represented as six binary channels or planes. The respective plane is true if the player one, two, or three or more liberties available. [[List of Go terms#Ko|Ko]] (i.e. illegal moves) is represented as one binary plane. Stone placement for each opponent and empty board positions are represented as three binary planes, and the duration since a stone has been placed is represented as real numbers on two planes, one for each player. Lastly, the opponents rank is represented by nine binary planes, where if all are true, the player is a 9d level, if 8 are true, a 8d level, and so forth. Extended play additionally considers the boarder (binary plane that is true at the border), position mask (represented as distance from the board center, i.e. &lt;math&gt; x^{(-0.5 * distance^2)}&lt;/math&gt;, where &lt;math&gt;x&lt;/math&gt; is a real number at a position), and each player's territory (binary, based on which player a location is closer to).

Darkfmct3 uses a 12-layer full convolutional network with a width of 384 nodes without weight sharing or pooling. Each convolutional layer is followed by a [[Rectifier (neural networks)|rectified linear unit]], a popular activation function for deep neural networks.&lt;ref&gt;{{cite journal|last2=Bengio|first2=Yoshua|last3=Hinton|first3=Geoffrey|date=27 May 2015|title=Deep learning|journal=Nature|volume=521|issue=7553|pages=436–444|doi=10.1038/nature14539|last1=LeCun|first1=Yann|pmid=26017442|bibcode=2015Natur.521..436L}}&lt;/ref&gt; A key innovation of Darkfmct3 compared to previous approaches is that it uses only one [[softmax function]] to predict the next move, which enables the approach to reduce the overall number of parameters.&lt;ref name=":1" /&gt; Darkfmct3 was trained against 300 random selected games from an empirical dataset representing different game stages. The learning rate was determined by vanilla [[stochastic gradient descent]].

Darkfmct3 [[Synchronization (computer science)|synchronously]] couples a convolutional neural network with a [[Monte Carlo tree search]]. Because the convolutional neural network is computationally taxing, the Monte Carlo tree search focuses computation on the more likely game play trajectories. By running the neural network synchronously with the Monte Carlo tree search, it is possible to guarantee that each node is expanded by the moves predicted by the neural network.

== Comparison with other systems ==
'''Darkfores2''' beats '''Darkforest''', its neural network-only predecessor, around 90% of the time, and Pachi, one of the best search-based engines, around 95% of the time.&lt;ref name=":0" /&gt; On the [[Go ranks and ratings|Kyu rating system]], Darkforest holds a 1-2d level. '''Darkfores2''' achieves a stable 3d level on KGS Go Server as a ranked bot.&lt;ref name="facebook-paper2" /&gt; With the added [[Monte Carlo tree search]], '''Darkfmcts3''' with 5,000 rollouts beats Pachi with 10k rollouts in all 250 games; with 75k rollouts it achieves a stable 5d level in KGS server, on par with state-of-the-art Go AIs (e.g., Zen, DolBaram, CrazyStone); with 110k rollouts, it won the 3rd place in January KGS Go Tournament.&lt;ref name=":2" /&gt;

== See also ==
* [[Go and mathematics]]

== References ==
{{Reflist}}

== External links ==
*[https://github.com/facebookresearch/darkforestGo Source code on Github]

[[Category:Artificial intelligence]]
[[Category:Computer Go]]
[[Category:Go software (game)]]
[[Category:Machine learning]]
[[Category:Facebook software]]</text>
      <sha1>qe8bksvxzxzf857aa81pm2gf6wyaxox</sha1>
    </revision>
  </page>
  <page>
    <title>Inauthentic text</title>
    <ns>0</ns>
    <id>5008963</id>
    <revision>
      <id>729903860</id>
      <parentid>703305514</parentid>
      <timestamp>2016-07-15T11:03:50Z</timestamp>
      <contributor>
        <username>Boson</username>
        <id>13662</id>
      </contributor>
      <comment>Tag as unreferenced</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2319" xml:space="preserve">{{Unreferenced|date=July 2016}}
An '''inauthentic text''' is a computer-generated expository document meant to appear as genuine, but which is actually meaningless.  Frequently they are created in order to be intermixed with genuine documents and thus manipulate the results of search engines, as with [[Spam blog]]s.  They are also carried along in email in order to fool [[spam filter]]s by giving the spam the superficial characteristics of legitimate text.

Sometimes nonsensical documents are created with computer assistance for humorous effect, as with [[Dissociated press]] or [[Flarf poetry]].  They have also been used to challenge the veracity of a publication&amp;mdash;[[MIT]] students submitted papers generated by a computer program called [[SCIgen]] to a conference, where they were initially accepted.  This led the students to claim that the bar for submissions was too low.

With the amount of computer generated text outpacing the ability of people to humans to curate it, there needs some means of distinguishing between the two.  Yet automated approaches to determining absolutely whether a text is authentic or not face intrinsic challenges of semantics.  [[Noam Chomsky]] coined the phrase "[[Colorless green ideas sleep furiously]]" giving an example of grammatically-correct, but semantically incoherent sentence; some will point out that in certain contexts one could give this sentence (or any phrase) meaning.

The first group to use the expression in this regard can be found below from [[Indiana University]].  Their work explains in detail an attempt to detect inauthentic texts and identify pernicious problems of inauthentic texts in cyberspace.  The site has a means of submitting text that assesses, based on supervised learning, whether a corpus is inauthentic or not.  Many users have submitted incorrect types of data and have correspondingly commented on the scores. This application is meant for a specific kind of data; therefore, submitting, say, an email, will not return a meaningful score.

==See also==
* [[Scraper site]]
* [[Spamdexing]]

==External links==
*[http://www.inauthentic.org An Inauthentic Paper Detector] from [[Indiana University]] School of Informatics

[[Category:Scientific misconduct]]
[[Category:Machine learning]]
[[Category:Semantics]]
[[Category:Fraud]]</text>
      <sha1>jugog2ah6b0zr2deaus880sxdzpctr7</sha1>
    </revision>
  </page>
  <page>
    <title>Bayesian structural time series</title>
    <ns>0</ns>
    <id>50211107</id>
    <revision>
      <id>944273586</id>
      <parentid>919257145</parentid>
      <timestamp>2020-03-06T20:03:02Z</timestamp>
      <contributor>
        <username>GregorB</username>
        <id>179697</id>
      </contributor>
      <comment>added [[Category:Time series]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="4508" xml:space="preserve">{{more footnotes|date=April 2016}}
'''Bayesian structural time series''' ('''BSTS''') model is a [[statistical]] technique used for [[feature selection]], time series forecasting, [[Nowcasting (economics)|nowcasting]], inferring causal impact and other applications. The model is designed to work with [[time series]] data.

The model has also promising application in the field of analytical [[marketing]]. In particular, it can be used in order to assess how much different marketing campaigns have contributed to the change in web search volumes, product sales, brand popularity and other relevant indicators. [[Difference in differences|Difference-in-differences]] models&lt;ref name=":0" /&gt; and [[interrupted time series]] designs&lt;ref&gt;{{cite web |url=https://www.insightsassociation.org/issues-policies/glossary/interrupted-time-series-design |website=Interrupted Time-Series Design |title= Interrupted Time-Series Design|publisher=Insights Association |accessdate=21 March 2019}}&lt;/ref&gt; are alternatives to this approach. "In contrast to classical difference-in-differences schemes, state-space models make it possible to (i) infer the temporal evolution of attributable impact, (ii) incorporate empirical priors on the parameters in a fully Bayesian treatment, and (iii) flexibly accommodate multiple sources of variation, including the time-varying influence of contemporaneous covariates, i.e., synthetic controls."&lt;ref name=":0" /&gt;

== General model description ==
The model consists of three main components:
# '''[[Kalman filter]]'''. The technique for time series decomposition. In this step, a researcher can add different state variables: trend, seasonality, regression, and others.
# '''[[Spike-and-slab variable selection|Spike-and-slab]] method.''' In this step, the most important regression predictors are selected.
# '''[[Ensemble learning|Bayesian model averaging]].''' Combining the results and prediction calculation.
The model could be used to discover the causations with its counterfactual prediction and the observed data.&lt;ref name=":0"&gt;{{Cite web|url=http://research.google.com/pubs/pub41854.html|title=Inferring causal impact using Bayesian structural time-series models|website=research.google.com|access-date=2016-04-17}}&lt;/ref&gt;

A possible drawback of the model can be its relatively complicated mathematical underpinning and difficult implementation as a computer program. However, the programming language [[R (programming language)|R]] has ready-to-use packages for calculating the BSTS model,&lt;ref&gt;{{Cite web|url=https://cran.r-project.org/web/packages/bsts/bsts.pdf|title=bsts}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://google.github.io/CausalImpact/CausalImpact.html|title=CausalImpact|website=google.github.io|access-date=2016-04-17}}&lt;/ref&gt; which do not require strong mathematical background from a researcher.

== See also ==
* [[Bayesian inference using Gibbs sampling]]
* [[Correlation does not imply causation]]

== References ==
{{Reflist}}

== Further reading ==
* Scott, S. L., &amp; Varian, H. R. 2014a. [http://people.ischool.berkeley.edu/~hal/Papers/2012/fat.pdf Bayesian variable selection for nowcasting economic time series]. ''Economic Analysis of the Digital Economy.''
* Scott, S. L., &amp; Varian, H. R. 2014b. [http://people.ischool.berkeley.edu/~hal/Papers/2013/pred-present-with-bsts.pdf Predicting the present with bayesian structural time series]. ''International Journal of Mathematical Modelling and Numerical Optimisation.''
* Varian, H. R. 2014. [http://people.ischool.berkeley.edu/~hal/Papers/2013/ml.pdf Big Data: New Tricks for Econometrics]. ''Journal of Economic Perspectives''
* Brodersen, K. H., Gallusser, F., Koehler, J., Remy, N., &amp; Scott, S. L. 2015. [http://research.google.com/pubs/pub41854.html Inferring causal impact using Bayesian structural time-series models]. ''The Annals of Applied Statistics.''
* R package [https://cran.r-project.org/web/packages/bsts/bsts.pdf "bsts"].
* R package [https://google.github.io/CausalImpact/CausalImpact.html "CausalImpact"].
* O’Hara, R. B., &amp; Sillanpää, M. J. 2009. [https://projecteuclid.org/euclid.ba/1340370391 A review of Bayesian variable selection methods: what, how and which]. ''Bayesian analysis.''
* [[Jennifer A. Hoeting|Hoeting, J. A.]], Madigan, D., Raftery, A. E., &amp; Volinsky, C. T. 1999. [https://projecteuclid.org/euclid.ss/1009212519 Bayesian model averaging: a tutorial]. ''Statistical science.''

[[Category:Machine learning]]
[[Category:Bayesian statistics]]
[[Category:Time series]]</text>
      <sha1>kdgzkh3irfdjjgs6s6rolnl1dt0ahzl</sha1>
    </revision>
  </page>
  <page>
    <title>Semantic folding</title>
    <ns>0</ns>
    <id>50222574</id>
    <revision>
      <id>990709831</id>
      <parentid>990421072</parentid>
      <timestamp>2020-11-26T02:06:42Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 14 templates: del empty params (17×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="12107" xml:space="preserve">'''Semantic folding''' theory describes a procedure for encoding the [[semantics]] of [[natural language]] text in a semantically grounded [[Binary number|binary representation]]. This approach provides a framework for modelling how language data is processed by the [[neocortex]].{{r|webber}}

==Theory==
Semantic folding theory draws inspiration from [[Douglas Hofstadter|Douglas R. Hofstadter]]'s ''Analogy as the Core of Cognition'' which suggests that the brain makes sense of the world by identifying and applying [[Analogy|analogies]].{{r|hofstadter}} The theory hypothesises that semantic data must therefore be introduced to the neocortex in such a form as to allow the application of a [[similarity measure]] and offers, as a solution, the [[sparse matrix|sparse]] [[bit array|binary vector]] employing a two-dimensional topographic [[semantic space]] as a distributional reference frame. The theory builds on the computational theory of the human cortex known as [[hierarchical temporal memory]] (HTM), and positions itself as a complementary theory for the representation of language semantics.

A particular strength claimed by this approach is that the resulting binary representation enables complex semantic operations to be performed simply and efficiently at the most basic computational level.

== Two-dimensional semantic space ==
Analogous to the structure of the neocortex, Semantic Folding theory posits the implementation of a semantic space as a two-dimensional grid. This grid is populated by context-vectors&lt;ref group="note"&gt;A context-vector is defined as a vector containing all the words in a particular context.&lt;/ref&gt; in such a way as to place similar context-vectors closer to each other, for instance, by using competitive learning principles. This [[vector space model]] is presented in the theory as an equivalence to the well known word space model&lt;ref name=":0"&gt;{{Cite web|url=http://su.diva-portal.org/smash/get/diva2:189276/FULLTEXT01|title=The Word-Space Model|last=Sahlgreen|first=Magnus|date=2006}}&lt;/ref&gt; described in the [[Information retrieval|Information Retrieval]] literature.

Given a semantic space (implemented as described above) a word-vector&lt;ref group="note"&gt;A word-vector or word-SDR is referred to as a Semantic Fingerprint in Semantic Folding theory.&lt;/ref&gt; can be obtained for any given word Y by employing the following [[algorithm]]:

For each position X in the semantic map (where X represents [[Cartesian coordinate system|cartesian coordinates]])
     if the word Y is contained in the context-vector at position X
          then add 1 to the corresponding position in the word-vector for Y
     else 
          add 0 to the corresponding position in the word-vector for Y

The result of this process will be a word-vector containing all the contexts in which the word Y appears and will therefore be representative of the semantics of that word in the semantic space. It can be seen that the resulting word-vector is also in a sparse distributed representation (SDR) format [Schütze, 1993] &amp; [Sahlgreen, 2006].&lt;ref name=":0" /&gt;&lt;ref&gt;{{Cite journal|title=Word Space|pages = 895–902|last=Schütze|first=Hinrich|date=1993|citeseerx = 10.1.1.41.8856}}&lt;/ref&gt; Some properties of word-SDRs that are of particular interest with respect to [[computational semantics]] are:&lt;ref name=":1" /&gt;
* high [[Noise and Resistance|noise resistance]]: As a result of similar contexts being placed closer together in the underlying map, word-SDRs are highly tolerant of false or shifted "bits".
* [[Boolean algebra|boolean]] logic: It is possible to manipulate word-SDRs in a meaningful way using boolean (OR, AND, exclusive-OR) and/or [[Arithmetical operations|arithmetical]] (SUBtract) functions .
* sub-sampling: Word-SDRs can be sub-sampled to a high degree without any appreciable loss of semantic information.
* topological two-dimensional representation: The SDR representation maintains the topological distribution of the underlying map therefore words with similar meanings will have similar word-vectors. This suggests that a variety of measures can be applied to the calculation of [[semantic similarity]], from a simple overlap of vector elements, to a range of distance measures such as: [[Euclidean distance]], [[Hamming distance]], [[Jaccard index|Jaccard distance]], [[cosine similarity]], [[Levenshtein distance]], [[Sørensen–Dice coefficient|Sørensen-Dice index]], etc.

== Semantic spaces ==
Semantic spaces&lt;ref group="note"&gt;also referred to as distributed semantic spaces or distributed semantic memory&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last1=Baroni|first1=Marco|last2=Lenci|first2=Alessandro|title=Distributional Memory: A General Framework for Corpus-Based Semantics|journal=Computational Linguistics|volume=36|issue=4|pages=673–721|doi=10.1162/coli_a_00016|year=2010|citeseerx=10.1.1.331.3769|s2cid=5584134}}&lt;/ref&gt; in the natural language domain aim to create representations of natural language that are capable of capturing meaning. The original motivation for semantic spaces stems from two core challenges of natural language: [[Vocabulary mismatch]] (the fact that the same meaning can be expressed in many ways) and [[ambiguity]] of natural language (the fact that the same term can have several meanings).

The application of semantic spaces in [[natural language processing]] (NLP) aims at overcoming limitations of [[Rule-based system|rule-based]] or model-based approaches operating on the [[Keyword research|keyword]] level. The main drawback with these approaches is their brittleness, and the large manual effort required to create either rule-based NLP systems or training corpora for model learning.&lt;ref&gt;{{Cite journal|author1=Scott C. Deerwester |author2=Susan T. Dumais |author3=Thomas K. Landauer |author4=George W. Furnas |author5=Richard A. Harshen |date=1990|title=Indexing by Latent Semantic Analysis|url=http://lsa.colorado.edu/papers/JASIS.lsi.90.pdf|journal=Journal of the American Society for Information Science}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|author1=Xing Wei |author2=W. Bruce Croft |date=2007|title=Investigating retrieval performance with manually-built topic models|url=http://dl.acm.org/citation.cfm?id=1931390.1931423|journal=Proceeding RIAO '07 Large Scale Semantic Access to Content (Text, Image, Video, and Sound)|pages=333–349 |series=Riao '07 }}&lt;/ref&gt; Rule-based and [[machine learning]]-based models are fixed on the keyword level and break down if the vocabulary differs from that defined in the rules or from the training material used for the statistical models.

Research in semantic spaces dates back more than 20 years. In 1996, two papers were published that raised a lot of attention around the general idea of creating semantic spaces: [[latent semantic analysis]]&lt;ref&gt;{{Cite web|url=http://lsa.colorado.edu/papers/plato/plato.annote.html|title=LSA: A Solution to Plato's Problem|website=lsa.colorado.edu|access-date=2016-04-19}}&lt;/ref&gt; from [[Microsoft]] and [[Hyperspace Analogue to Language]]&lt;ref&gt;{{Cite journal|last1=Lund|first1=Kevin|last2=Burgess|first2=Curt|date=1996-06-01|title=Producing high-dimensional semantic spaces from lexical co-occurrence|journal=Behavior Research Methods, Instruments, &amp; Computers|language=en|volume=28|issue=2|pages=203–208|doi=10.3758/BF03204766|issn=0743-3808|doi-access=free}}&lt;/ref&gt; from the [[University of California, Riverside|University of California]]. However, their adoption was limited by the large computational effort required to construct and use those semantic spaces. A breakthrough with regard to the [[Accuracy and precision|accuracy]] of modelling associative relations between words (e.g. "spider-web", "lighter-cigarette", as opposed to synonymous relations such as "whale-dolphin", "astronaut-driver") was achieved by [[explicit semantic analysis]] (ESA)&lt;ref&gt;{{Cite journal|author1=Evgeniy Gabrilovich  |author2=Shaul Markovitch |name-list-style=amp |date=2007|title=Computing Semantic Relatedness using Wikipedia-based Explicit Semantic Analysis|url=https://www.cs.technion.ac.il/~gabr/papers/ijcai-2007-sim.pdf|journal=Proc. 20th Int'l Joint Conf. On Artificial Intelligence (IJCAI). Pp. 1606–1611.}}&lt;/ref&gt; in 2007. ESA was a novel (non-machine learning) based approach that represented words in the form of vectors with 100,000 [[dimension]]s (where each dimension represents an Article in [[Wikipedia]]). However practical applications of the approach are limited due to the large number of required dimensions in the vectors.

More recently, advances in [[Neural networks|neural networking]] techniques in combination with other new approaches ([[tensor]]s) led to a host of new recent developments: [[Word2vec]]&lt;ref&gt;{{cite arXiv|eprint=1310.4546|title=Distributed Representations of Words and Phrases and their Compositionality|author1=Tomas Mikolov |author2=Ilya Sutskever |author3=Kai Chen |author4=Greg Corrado |author5=Jeffrey Dean |date=2013|class=cs.CL}}&lt;/ref&gt; from [[Google]] and [[GloVe (machine learning)|GloVe]]&lt;ref&gt;{{Cite web|url=http://www-nlp.stanford.edu/pubs/glove.pdf|title=GloVe: Global Vectors for Word Representation|author1=Jeffrey Pennington |author2=Richard Socher |author3=Christopher D. Manning |date=2014}}&lt;/ref&gt; from [[Stanford University]].

Semantic folding represents a novel, biologically inspired approach to semantic spaces where each word is represented as a sparse binary vector with 16,000 dimensions (a semantic fingerprint) in a 2D semantic map (the semantic universe). Sparse binary representation are advantageous in terms of computational efficiency, and allow for the storage of very large numbers of possible patterns.&lt;ref name=":1"&gt;{{cite arXiv|eprint=1503.07469|title=Properties of Sparse Distributed Representations and their Application to Hierarchical Temporal Memory|author1=Subutai Ahmad |author2=Jeff Hawkins |date=2015|class=q-bio.NC}}&lt;/ref&gt;

==Visualization==
[[File:Semantic fingerprint comparing the terms "dog" and "car".png|thumb|Semantic fingerprint image comparing the terms "dog" and "car".]]
[[File:Semantic fingerprint comparing the terms "jaguar" and "Porsche".png|thumb|Semantic fingerprint image comparing the terms "jaguar" and "Porsche"]]
The topological distribution over a two-dimensional grid (outlined above) lends itself to a [[bitmap]] type visualization of the semantics of any word or text, where each active semantic feature can be displayed as e.g. a [[pixel]]. As can be seen in the images shown here, this representation allows for a direct visual comparison of the semantics of two (or more) linguistic items.

Image 1 clearly demonstrates that the two disparate terms "dog" and "car" have, as expected, very obviously different semantics.

Image 2 shows that only one of the meaning contexts of  "jaguar", that of "Jaguar" the car, overlaps with the meaning of Porsche (indicating partial similarity). Other meaning contexts of "jaguar" e.g. "jaguar" the animal clearly have different non-overlapping contexts.
The visualization of semantic similarity using Semantic Folding bears a strong resemblance to the [[fMRI]] images produced in a research study conducted by A.G. Huth et al.,&lt;ref&gt;{{cite journal|last1=Huth|first1=Alexander|title=Natural speech reveals the semantic maps that tile human cerebral cortex|journal=Nature|date=27 April 2016|issue=7600|pages=453–458|doi=10.1038/nature17637|volume=532|pmid=27121839|pmc=4852309|bibcode=2016Natur.532..453H}}&lt;/ref&gt; where it is claimed that words are grouped in the brain by meaning.

== Notes ==
{{reflist|group=note}}

== References ==
{{reflist|30em|refs=
&lt;ref name=hofstadter&gt;{{Cite web|url=https://mitpress.mit.edu/books/analogical-mind|title=The Analogical Mind|website=MIT Press|access-date=2016-04-18}}&lt;/ref&gt;
&lt;ref name=webber&gt;{{Cite journal|last=De Sousa Webber|first=Francisco|date=2015|title=Semantic Folding theory and its Application in Semantic Fingerprinting|arxiv=1511.08855|journal=Cornell University Library|bibcode=2015arXiv151108855D}}&lt;/ref&gt;

}}

[[Category:Computational linguistics]]
[[Category:Natural language processing]]
[[Category:Semantics]]
[[Category:Machine learning]]</text>
      <sha1>7ia85p41i0fmccqolqsba2nwtovsulm</sha1>
    </revision>
  </page>
  <page>
    <title>Spike-and-slab regression</title>
    <ns>0</ns>
    <id>50227596</id>
    <revision>
      <id>948377732</id>
      <parentid>931394752</parentid>
      <timestamp>2020-03-31T18:30:53Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <comment>Alter: title, template type. Add: bibcode, pages, issue, volume, journal, arxiv, doi, year, author pars. 1-2. Removed URL that duplicated unique identifier. Removed parameters. Formatted [[WP:ENDASH|dashes]]. Some additions/deletions were actually parameter name changes. | You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | Activated by [[User:Zppix]] | [[Category:Machine learning‎]] | via #UCB_Category</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="6721" xml:space="preserve">In statistics, '''spike-and-slab regression''' is a Bayesian [[Feature selection|variable selection]] technique that is particularly useful when the number of possible predictors is larger than the number of observations.&lt;ref&gt;{{Cite web|url=http://people.ischool.berkeley.edu/~hal/Papers/2013/ml.pdf|title=Big Data: New Tricks for Econometrics|last=|first=|date=|website=|publisher=|access-date=}}&lt;/ref&gt;

Initially, the idea of the spike-and-slab model was proposed by Mitchell &amp; Beauchamp (1988).&lt;ref&gt;{{Cite web|url=https://www2.stat.duke.edu/courses/Fall05/sta395/joelucas1.pdf|title=Bayesian variable selection in linear regression|last=|first=|date=|website=|publisher=|access-date=}}&lt;/ref&gt; The approach was further significantly developed by Madigan &amp; Raftery (1994)&lt;ref&gt;{{Cite web|url=http://www.stat.cmu.edu/~fienberg/Statistics36-756/MadiganRaftery-JASA-1994.pdf|title=Model selection and accounting for model uncertainty in graphical models using occam's window|last=|first=|date=|website=|publisher=|access-date=}}&lt;/ref&gt; and George &amp; McCulloch (1997).&lt;ref&gt;{{Cite web|url=http://www-stat.wharton.upenn.edu/~edgeorge/Research_papers/GeorgeMcCulloch97.pdf|title=Approaches for Bayesian variable selection|last=|first=|date=|website=|publisher=|access-date=}}&lt;/ref&gt; The final adjustments to the model were done by Ishwaran &amp; Rao (2005).&lt;ref&gt;{{Cite journal|title=Spike and slab variable selection: frequentist and Bayesian strategies|year=2005|doi=10.1214/009053604000001147|arxiv=math/0505633|last1=Ishwaran|first1=Hemant|last2=Rao|first2=J. Sunil|journal=The Annals of Statistics|volume=33|issue=2|pages=730–773|bibcode=2005math......5633I}}&lt;/ref&gt;

== Model description ==
Suppose we have ''P'' possible predictors in some model. Vector ''γ'' has a length equal to ''P'' and consists of zeros and ones. This vector indicates whether a particular variable is included in the regression or not. If no specific prior information on initial inclusion probabilities of particular variables is available, a [[Bernoulli distribution|Bernoulli prior]] distribution is a common default choice.&lt;ref name=":0"&gt;{{Cite web|url=http://people.ischool.berkeley.edu/~hal/Papers/2013/pred-present-with-bsts.pdf|title=Predicting the present with bayesian structural time series|last=|first=|date=|website=|publisher=|access-date=}}&lt;/ref&gt; Conditional on a predictor being in the regression, we identify a [[Prior probability|prior distribution]] for the model coefficient, which corresponds to that variable (''β''). A common choice on that step is to use a [[Normal distribution|Normal]] prior with mean equal to zero and a large variance calculated based on &lt;math&gt;(X^TX)^{-1}&lt;/math&gt; (where &lt;math&gt;X&lt;/math&gt; is a [[design matrix]] of explanatory variables of the model).&lt;ref&gt;{{Cite web|url=http://people.ischool.berkeley.edu/~hal/Papers/2012/fat.pdf|title=Bayesian variable selection for nowcasting economic time series|last=|first=|date=|website=|publisher=|access-date=}}&lt;/ref&gt;

A draw of ''γ'' from its prior distribution is a list of the variables included in the regression. Conditional on this set of selected variables, we take a draw from the prior distribution of the regression coefficients (if ''γ''&lt;sub&gt;''i''&lt;/sub&gt; = 1 then ''β''&lt;sub&gt;''i''&lt;/sub&gt; ≠ 0 and if ''γ''&lt;sub&gt;''i''&lt;/sub&gt; = 0 then ''β''&lt;sub&gt;''i''&lt;/sub&gt; = 0). ''βγ'' denotes the subset of ''β'' for which ''γ''&lt;sub&gt;''i''&lt;/sub&gt; = 1. In the next step, we calculate a [[posterior probability]] distribution for both inclusion and coefficients by applying a standard statistical procedure.&lt;ref&gt;{{Cite web|url=http://research.google.com/pubs/pub41854.html|title=Inferring causal impact using Bayesian structural time-series models|last=|first=|website=|year=2015|publisher=|access-date=}}&lt;/ref&gt; All steps of the described algorithm are repeated thousands of times using [[Markov chain Monte Carlo]] (MCMC) technique. As a result, we obtain a posterior distribution of ''γ'' (variable inclusion in the model), ''β'' (regression coefficient values) and the corresponding prediction of ''y''.

The model got its name (spike-and-slab) due to the shape of the two prior distributions. The "spike" is the probability of a particular coefficient in the model to be zero. The "slab" is the prior distribution for the regression coefficient values.

An advantage of Bayesian variable selection techniques is that they are able to make use of prior knowledge about the model. In the absence of such knowledge, some reasonable default values can be used; to quote Scott and Varian (2013): "For the analyst who prefers simplicity at the cost of some reasonable assumptions, useful prior information can be reduced to an expected model size, an expected ''R''&lt;sup&gt;2&lt;/sup&gt;, and a sample size ''ν'' determining the weight given to the guess at ''R''&lt;sup&gt;2&lt;/sup&gt;."&lt;ref name=":0" /&gt; Some researchers suggest the following default values: ''R''&lt;sup&gt;2&lt;/sup&gt; = 0.5, ''ν'' = 0.01, and {{pi}} = 0.5 (parameter of a prior Bernoulli distribution).&lt;ref name=":0" /&gt;

A possible drawback of the Spike-and-Slab model can be its mathematical complexity (in comparison to linear regression). A deep understanding of this model requires sound knowledge in [[stochastic process]]es. On the other hand, some modern statistical software (e.g. [[R (programming language)|R]]) have ready-to-use solutions for calculating various Bayesian variable selection models.&lt;ref&gt;{{Cite web|url=https://cran.r-project.org/web/packages/spikeslab/spikeslab.pdf|title=spikeslab|last=|first=|date=|website=|publisher=|access-date=}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://cran.r-project.org/web/packages/spikeSlabGAM/vignettes/UsingSpikeSlabGAM.pdf|title=spikeSlabGAM|last=|first=|date=|website=|publisher=|access-date=}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://cran.r-project.org/web/packages/bsts/bsts.pdf|title=bsts|last=|first=|date=|website=|publisher=|access-date=}}&lt;/ref&gt; In this case, it would be enough for a researcher to know the idea of the method, required model parameters and input variables. The analysis of the model outcomes (distribution of ''γ'', ''β'', and corresponding predictions of ''y'') can be more challenging in comparison to linear regression case. The spike-and-slab model produces inclusion probabilities for each of possible predictors. This can cause difficulties when comparing results to the studies with simple regression (usually only regression coefficients with corresponding statistics are available).

== See also ==
* [[Bayesian inference using Gibbs sampling]]
* [[Bayesian structural time series]]

== Notes ==

{{Empty section|date=April 2016}}

==References==
{{Reflist}}

[[Category:Machine learning]]
[[Category:Bayesian inference]]
[[Category:Bayesian statistics]]</text>
      <sha1>abk077134gmy857q98fdpux97vom5e2</sha1>
    </revision>
  </page>
  <page>
    <title>Glossary of artificial intelligence</title>
    <ns>0</ns>
    <id>50336055</id>
    <revision>
      <id>996932461</id>
      <parentid>993073777</parentid>
      <timestamp>2020-12-29T06:34:37Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 234 templates: hyphenate params (10×); del |ref=harv (2×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="238501" xml:space="preserve">{{short description|List of definitions of terms and concepts commonly used in the study of artificial intelligence}}
{{Use dmy dates|date=September 2017}}

This '''glossary of artificial intelligence''' is a list of definitions of terms and concepts relevant to the study of [[artificial intelligence]], its sub-disciplines, and related fields. Related glossaries include [[Glossary of computer science]], [[Glossary of robotics]], and [[Glossary of machine vision]].

{{compact ToC|side=yes|center=yes|nobreak=yes|seealso=yes|refs=yes|}}

{{Artificial intelligence}}

==A==
{{glossary}}
{{term|[[abductive logic programming]] (ALP)}}
{{defn|A high-level knowledge-representation framework that can be used to solve problems declaratively based on {{gli|abductive reasoning}}. It extends normal {{gli|logic programming}} by allowing some predicates to be incompletely defined, declared as abducible predicates.}}

{{term|[[abductive reasoning]]}}
{{ghat|Also '''abduction'''.}}
{{defn|A form of [[logical inference]] which starts with an observation or set of observations then seeks to find the simplest and most likely explanation. This process, unlike [[deductive reasoning]], yields a plausible conclusion but does not [[logical positivism|positively verify]] it.&lt;ref name="Josephson"&gt;For example: {{Cite book |title=Abductive Inference: Computation, Philosophy, Technology |date=1994 |publisher=Cambridge University Press |isbn=978-0521434614 |editor-last=Josephson |editor-first=John R. |location=Cambridge, UK; New York |doi=10.1017/CBO9780511530128 |oclc=28149683 |editor-last2=Josephson |editor-first2=Susan G.}}&lt;/ref&gt; abductive inference,&lt;ref name="Josephson" /&gt; or retroduction&lt;ref&gt;{{Cite web |url=http://www.commens.org/dictionary/term/retroduction |title=&lt;nowiki&gt;Retroduction |website=Commens – Digital Companion to C. S. Peirce |publisher=Mats Bergman, Sami Paavola &amp; João Queiroz |access-date=2014-08-24 |Dictionary |Commens&lt;/nowiki&gt;}}&lt;/ref&gt;}}

{{term|[[abstract data type]]}}
{{defn|A [[mathematical model]] for [[data type]]s, where a data type is defined by its behavior ([[Semantics (computer science)|semantics]]) from the point of view of a ''user'' of the data, specifically in terms of possible values, possible operations on data of this type, and the behavior of these operations.}}

{{term|[[abstraction (software engineering)|abstraction]]}}
{{defn|The process of removing physical, spatial, or temporal details&lt;ref&gt;{{Cite journal |last1=Colburn |first1=Timothy |last2=Shute |first2=Gary |date=2007-06-05 |title=Abstraction in Computer Science |journal=Minds and Machines  |volume=17 |issue=2 |pages=169–184 |doi=10.1007/s11023-007-9061-7 |s2cid=5927969 |issn=0924-6495}}&lt;/ref&gt; or [[Attribute (computing)|attributes]] in the study of objects or [[system]]s in order to more closely attend to other details of interest&lt;ref&gt;{{Cite journal |last1=Kramer |first1=Jeff |date=2007-04-01 |title=Is abstraction the key to computing? |journal=Communications of the ACM |volume=50 |issue=4 |pages=36–42 |citeseerx=10.1.1.120.6776 |doi=10.1145/1232743.1232745 |s2cid=12481509 |issn=0001-0782}}&lt;/ref&gt;}}

{{term|[[accelerating change]]}}
{{defn|A perceived increase in the rate of [[technological change]] throughout history, which may suggest faster and more profound change in the future and may or may not be accompanied by equally profound social and cultural change.}}

{{term|[[action language]]}}
{{defn|A language for specifying [[state transition system]]s, and is commonly used to create [[formal model]]s of the effects of actions on the world.&lt;ref&gt;Michael Gelfond, Vladimir Lifschitz (1998) "[http://www.ep.liu.se/ea/cis/1998/016/ Action Languages]", ''Linköping Electronic Articles in Computer and Information Science'', vol 3, nr ''16''.&lt;/ref&gt; Action languages are commonly used in the {{gli|artificial intelligence}} and [[robotics]] domains, where they describe how actions affect the states of systems over time, and may be used for [[automated planning]].}}

{{term|[[action model learning]]}}
{{defn|An area of machine learning concerned with creation and modification of software agent's knowledge about effects and preconditions of the actions that can be executed within its environment. This knowledge is usually represented in logic-based action description language and used as the input for automated planners.}}

{{term|[[action selection]]}}
{{defn|A way of characterizing the most basic problem of intelligent systems: what to do next. In artificial intelligence and computational cognitive science, "the action selection problem" is typically associated with intelligent agents and animats—artificial systems that exhibit complex behaviour in an agent environment.}}

{{term|[[activation function]]}}
{{defn|In {{gli|artificial neural network|artificial neural networks}}, the activation function of a node defines the output of that node given an input or set of inputs.}}

{{term|[[adaptive algorithm]]}}
{{defn|An algorithm that changes its behavior at the time it is run, based on ''a priori'' defined reward mechanism or criterion.}}

{{term|[[adaptive neuro fuzzy inference system]] (ANFIS)}}
{{ghat|Also '''adaptive network-based fuzzy inference system'''.}}
{{defn|A kind of {{gli|artificial neural network}} that is based on Takagi–Sugeno fuzzy [[inference system]]. The technique was developed in the early 1990s.&lt;ref&gt;{{Cite conference |last1=Jang |first1=Jyh-Shing R |year=1991 |title=Fuzzy Modeling Using Generalized Neural Networks and Kalman Filter Algorithm |url=http://www.aaai.org/Papers/AAAI/1991/AAAI91-119.pdf |conference=Proceedings of the 9th National Conference on Artificial Intelligence, Anaheim, CA, USA, July 14–19 |volume=2 |pages=762–767}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |last1=Jang |first1=J.-S.R. |s2cid=14345934 |year=1993 |title=ANFIS: adaptive-network-based fuzzy inference system |journal=IEEE Transactions on Systems, Man and Cybernetics |volume=23 |issue=3 |pages=665–685 |doi=10.1109/21.256541}}&lt;/ref&gt; Since it integrates both neural networks and {{gli|fuzzy logic}} principles, it has potential to capture the benefits of both in a single [[:wikt:framework|framework]]. Its inference system corresponds to a set of fuzzy [[Conditional (programming)|IF–THEN rules]] that have learning capability to approximate nonlinear functions.&lt;ref&gt;{{Citation |last1=Abraham |first1=A. |title=Fuzzy Systems Engineering: Theory and Practice |volume=181 |pages=53–83 |year=2005 |editor-last=Nedjah |editor-first=Nadia |series=Studies in Fuzziness and Soft Computing |chapter=Adaptation of Fuzzy Inference System Using Neural Learning |place=Germany |publisher=Springer Verlag |citeseerx=10.1.1.161.6135 |doi=10.1007/11339366_3 |isbn=978-3-540-25322-8 |editor2-last=De Macedo Mourelle |editor2-first=Luiza}}&lt;/ref&gt; Hence, ANFIS is considered to be a universal estimator.&lt;ref&gt;Jang, Sun, Mizutani (1997) – Neuro-Fuzzy and Soft Computing – Prentice Hall, pp 335–368, {{ISBN|0-13-261066-3}}&lt;/ref&gt; For using the ANFIS in a more efficient and optimal way, one can use the best parameters obtained by genetic algorithm.&lt;ref&gt;{{Cite journal |last1=Tahmasebi |first1=P. |year=2012 |title=A hybrid neural networks-fuzzy logic-genetic algorithm for grade estimation |journal=Computers &amp; Geosciences |volume=42 |pages=18–27 |bibcode=2012CG.....42...18T |doi=10.1016/j.cageo.2012.02.004 |pmc=4268588 |pmid=25540468}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |last1=Tahmasebi |first1=P. |year=2010 |title=Comparison of optimized neural network with fuzzy logic for ore grade estimation |url=https://www.researchgate.net/publication/266881168 |journal=Australian Journal of Basic and Applied Sciences |volume=4 |pages=764–772}}&lt;/ref&gt;}}

{{term|[[admissible heuristic]]}}
{{defn|In [[computer science]], specifically in {{gli|algorithm|algorithms}} related to {{gli|pathfinding}}, a [[heuristic function]] is said to be admissible if it never overestimates the cost of reaching the goal, i.e. the cost it estimates to reach the goal is not higher than the lowest possible cost from the current point in the path.&lt;ref&gt;{{Cite book |last1=Russell |first1=S.J. |title=Artificial Intelligence: A Modern Approach |title-link=Artificial Intelligence: A Modern Approach |last2=Norvig, P. |publisher=Prentice Hall |year=2002 |isbn=978-0-13-790395-5}}&lt;/ref&gt;}}

{{term|[[affective computing]]}}
{{ghat|Also '''artificial emotional intelligence''' or '''emotion AI'''.}}
{{defn|The study and development of systems and devices that can recognize, interpret, process, and simulate human [[Affect (psychology)|affects]]. Affective computing is an interdisciplinary field spanning [[computer science]], [[psychology]], and [[cognitive science]].&lt;ref name="TaoTan"&gt;{{Cite conference |last1=Tao |first1=Jianhua |last2=Tieniu Tan |year=2005 |title=Affective Computing: A Review |publisher=Springer |volume=[[LNCS]] 3784 |pages=981–995 |doi=10.1007/11573548 |book-title=Affective Computing and Intelligent Interaction}}&lt;/ref&gt;&lt;ref&gt;{{Cite news |last1=El Kaliouby |first1=Rana |url=https://www.technologyreview.com/s/609071/we-need-computers-with-empathy/ |archive-url=https://wayback.archive-it.org/all/20180707140902/https://www.technologyreview.com/s/609071/we-need-computers-with-empathy/ |url-status=dead |archive-date=7 July 2018 |title=We Need Computers with Empathy |date=Nov–Dec 2017 |work=Technology Review |issue=6 |volume=120 |page=8 |access-date=6 November 2018 }}&lt;/ref&gt;}}

{{term|[[agent architecture]]}}
{{defn|A [[blueprint]] for [[software agent]]s and {{gli|intelligent control}} systems, depicting the arrangement of components. The architectures implemented by {{gli|intelligent agent|intelligent agents}} are referred to as [[cognitive architecture]]s.&lt;ref&gt;[http://hri.cogs.indiana.edu/publications/aaai04ws.pdf Comparison of Agent Architectures] {{webarchive |url=https://web.archive.org/web/20080827222057/http://hri.cogs.indiana.edu/publications/aaai04ws.pdf |date=August 27, 2008 }}&lt;/ref&gt;}}

{{term|[[AI accelerator (computer hardware)|AI accelerator]]}}
{{defn|A class of [[microprocessor]]&lt;ref&gt;{{Cite web |url=https://www.v3.co.uk/v3-uk/news/3014293/intel-unveils-movidius-compute-stick-usb-ai-accelerator |title=Intel unveils Movidius Compute Stick USB AI Accelerator |date=2017-07-21 |url-status=dead |archive-url=https://web.archive.org/web/20170811193632/https://www.v3.co.uk/v3-uk/news/3014293/intel-unveils-movidius-compute-stick-usb-ai-accelerator |archive-date=11 August 2017 |access-date=28 November 2018}}&lt;/ref&gt; or computer system&lt;ref&gt;{{Cite web |url=https://insidehpc.com/2017/06/inspurs-unveils-gx4-ai-accelerator/ |title=Inspurs unveils GX4 AI Accelerator |date=2017-06-21}}&lt;/ref&gt; designed as [[hardware acceleration]] for {{gli|artificial intelligence}} applications, especially {{gli|artificial neural network|artificial neural networks}}, {{gli|machine vision}}, and {{gli|machine learning}}.}}

{{term|[[AI-complete]]}}
{{defn|In the field of artificial intelligence, the most difficult problems are informally known as AI-complete or AI-hard, implying that the difficulty of these computational problems is equivalent to that of solving the central artificial intelligence problem—making computers as intelligent as people, or {{gli|artificial general intelligence|strong AI}}.&lt;ref name="Shapiro92"&gt;Shapiro, Stuart C. (1992). [http://www.cse.buffalo.edu/~shapiro/Papers/ai.pdf Artificial Intelligence] In Stuart C. Shapiro (Ed.), ''Encyclopedia of Artificial Intelligence'' (Second Edition, pp.&amp;nbsp;54–57). New York: John Wiley. (Section 4 is on "AI-Complete Tasks".)&lt;/ref&gt; To call a problem AI-complete reflects an attitude that it would not be solved by a simple specific algorithm.}}

{{term|[[algorithm]]}}
{{defn|An unambiguous specification of how to solve a class of problems. Algorithms can perform calculation, data processing, and automated reasoning tasks.}}

{{term|[[algorithmic efficiency]]}}
{{defn|A property of an {{gli|algorithm}} which relates to the number of [[computational resource]]s used by the algorithm. An algorithm must be [[analysis of algorithms|analyzed]] to determine its resource usage, and the efficiency of an algorithm can be measured based on usage of different resources. Algorithmic efficiency can be thought of as analogous to engineering [[productivity]] for a repeating or continuous process.}}

{{term|[[algorithmic probability]]}}
{{defn|In [[algorithmic information theory]], algorithmic probability, also known as Solomonoff probability, is a mathematical method of assigning a prior [[probability]] to a given observation. It was invented by [[Ray Solomonoff]] in the 1960s.&lt;ref&gt;Solomonoff, R., "[http://world.std.com/~rjs/z138.pdf A Preliminary Report on a General Theory of Inductive Inference]", Report V-131, Zator Co., Cambridge, Ma. (Nov. 1960 revision of the Feb. 4, 1960 report).&lt;/ref&gt;}}

{{term|[[AlphaGo]]}}
{{defn|A [[computer program]] that plays the [[board game]] [[Go (game)|Go]].&lt;ref&gt;{{Cite news |url=https://www.bbc.com/news/technology-35785875 |title=Artificial intelligence: Google's AlphaGo beats Go master Lee Se-dol |date=2016-03-12 |work=BBC News |access-date=17 March 2016}}&lt;/ref&gt; It was developed by [[Alphabet Inc.]]'s [[Google DeepMind]] in London. AlphaGo has several versions including [[AlphaGo Zero]], [[AlphaGo Master]], [[AlphaGo Lee]], etc.&lt;ref&gt;{{Cite web |url=https://deepmind.com/research/alphago/ |title=AlphaGo {{!}} DeepMind |website=DeepMind}}&lt;/ref&gt; In October 2015, AlphaGo became the first [[computer Go]] program to beat a human [[professional Go player]] without [[Go handicaps|handicaps]] on a full-sized 19&amp;times;19 board.&lt;ref name="googlego"&gt;{{Cite web |url=http://googleresearch.blogspot.com/2016/01/alphago-mastering-ancient-game-of-go.html |title=Research Blog: AlphaGo: Mastering the ancient game of Go with Machine Learning |date=27 January 2016 |website=Google Research Blog}}&lt;/ref&gt;&lt;ref name="bbcgo"&gt;{{Cite news |url=https://www.bbc.com/news/technology-35420579 |title=Google achieves AI 'breakthrough' by beating Go champion |date=27 January 2016 |work=[[BBC News]]}}&lt;/ref&gt;}}

{{term|[[ambient intelligence]] (AmI)}}
{{defn|Electronic environments that are sensitive and responsive to the presence of people.}}

{{term|[[analysis of algorithms]]}}
{{defn|The determination of the [[computational complexity]] of algorithms, that is the amount of time, storage and/or other resources necessary to [[computation|execute them]]. Usually, this involves determining a [[Function (mathematics)|function]] that relates the length of an algorithm's input to the number of steps it takes (its [[time complexity]]) or the number of storage locations it uses (its [[space complexity]]).}}

{{term|[[analytics]]}}
{{defn|The discovery, interpretation, and communication of meaningful patterns in data.}}

{{term|[[answer set programming]] (ASP)}}
{{defn|A form of [[declarative programming]] oriented towards difficult (primarily [[NP-hard]]) [[search algorithm|search problems]]. It is based on the [[stable model semantics|stable model]] (answer set) semantics of [[logic programming]].  In ASP, search problems are reduced to computing stable models, and ''answer set solvers''—programs for generating stable models—are used to perform search.}}

{{term|[[anytime algorithm]]}}
{{defn|An {{gli|algorithm}} that can return a valid solution to a problem even if it is interrupted before it ends.}}

{{term|[[application programming interface]] (API)}}
{{defn|A set of subroutine definitions, [[communication protocols]], and tools for building software. In general terms, it is a set of clearly defined methods of communication among various components. A good API makes it easier to develop a [[computer program]] by providing all the building blocks, which are then put together by the [[programmer]]. An API may be for a web-based system, [[operating system]], [[database system]], computer hardware, or [[Library (computing)|software library]].}}

{{term|[[approximate string matching]]}}
{{ghat|Also '''fuzzy string searching'''.}}
{{defn|The technique of finding [[String (computing)|strings]] that match a [[pattern]] approximately (rather than exactly). The problem of approximate string matching is typically divided into two sub-problems: finding approximate [[substring]] matches inside a given string and finding dictionary strings that match the pattern approximately.}}

{{term|[[approximation error]]}}
{{defn|The discrepancy between an exact value and some approximation to it.}}

{{term|[[argumentation framework]]}}
{{ghat|Also '''argumentation system'''.}}
{{defn|A way to deal with contentious information and draw conclusions from it. In an abstract argumentation framework,&lt;ref&gt;See Dung (1995)&lt;/ref&gt; entry-level information is a set of abstract arguments that, for instance, represent data or a proposition. Conflicts between arguments are represented by a [[binary relation]] on the set of arguments. In concrete terms, you represent an argumentation framework with a [[directed graph]] such that the nodes are the arguments, and the arrows represent the attack relation.  There exist some extensions of the Dung's framework, like the logic-based argumentation frameworks&lt;ref&gt;See Besnard and Hunter (2001)&lt;/ref&gt; or the value-based argumentation frameworks.&lt;ref&gt;see Bench-Capon (2002)&lt;/ref&gt;}}

{{anchor|artificial general intelligence}}{{term|[[artificial general intelligence]] (AGI)}}
{{defn|}}

{{term|[[artificial immune system]] (AIS)}}
{{defn|A class of computationally intelligent, [[rule-based machine learning]] systems inspired by the principles and processes of the vertebrate [[immune system]]. The algorithms are typically modeled after the immune system's characteristics of [[learning]] and [[memory]] for use in [[Problem solving|problem-solving]].}}

{{anchor|artificial intelligence}}{{term|[[artificial intelligence]] (AI)}}
{{ghat|Also '''machine intelligence'''.}}
{{defn|Any [[intelligence]] demonstrated by [[machine]]s, in contrast to the natural intelligence&lt;!-- boldface per WP:R#PLA --&gt; displayed by humans and other animals. In [[computer science]], AI research is defined as the study of "{{gli|intelligent agent|intelligent agents}}": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals.&lt;ref name="Definition of AI"&gt;
Definition of AI as the study of [[intelligent agents]]:
* {{Harvnb|Poole|Mackworth|Goebel|1998|loc=[http://people.cs.ubc.ca/~poole/ci/ch1.pdf p. 1]}}, which provides the version that is used in this article. Note that they use the term "computational intelligence" as a synonym for artificial intelligence.
* {{Harvtxt|Russell|Norvig|2003}} (who prefer the term "rational agent") and write "The whole-agent view is now widely accepted in the field" {{Harv|Russell|Norvig|2003|p=55}}.
* {{Harvnb|Nilsson|1998}}
&lt;!-- These textbooks are the most widely used in academic AI. --&gt;
* {{Harvnb|Legg|Hutter|2007}}.
&lt;/ref&gt; Colloquially, the term "artificial intelligence" is applied when a machine mimics "cognitive" functions that humans associate with other [[human mind]]s, such as "learning" and "problem solving".{{sfn|Russell|Norvig|2009|p=2}}}}

{{term|[[AIML|Artificial Intelligence Markup Language]]}}
{{defn|An [[XML]] dialect for creating [[natural language]] software agents.}}

{{anchor|artificial neural network}}{{term|[[artificial neural network]] (ANN)}}
{{ghat|Also '''connectionist system'''.}}
{{defn|Any computing system vaguely inspired by the [[biological neural network]]s that constitute animal [[brain]]s.}}

{{term|[[Association for the Advancement of Artificial Intelligence]] (AAAI)}}
{{defn|An international, nonprofit, scientific society devoted to promote research in, and responsible use of, {{gli|artificial intelligence}}. AAAI also aims to increase public understanding of artificial intelligence (AI), improve the teaching and training of AI practitioners, and provide guidance for research planners and funders concerning the importance and potential of current AI developments and future directions.&lt;ref&gt;{{Cite web |url=http://www.aaai.org/Organization/bylaws.php |title=AAAI Corporate Bylaws}}&lt;/ref&gt;}}

{{term|[[asymptotic computational complexity]]}}
{{defn|In {{gli|computational complexity theory}}, asymptotic computational complexity is the usage of [[asymptotic analysis]] for the estimation of computational complexity of {{gli|algorithm|algorithms}} and [[computational problem]]s, commonly associated with the usage of the [[big O notation]].}}

{{term|[[attributional calculus]]}}
{{defn|A logic and representation system defined by [[Ryszard S. Michalski]]. It combines elements of [[predicate logic]], [[propositional calculus]], and [[multi-valued logic]]. Attributional calculus provides a formal language for ''natural induction'', an inductive learning process whose results are in forms natural to people.}}

{{anchor|augmented reality}}{{term|[[augmented reality]] (AR)}}
{{defn|An interactive experience of a real-world environment where the objects that reside in the real-world are "augmented" by computer-generated perceptual information, sometimes across multiple sensory modalities, including [[visual]], [[Hearing|auditory]], [[haptic perception|haptic]], [[Somatosensory system|somatosensory]], and [[olfactory]].&lt;ref&gt;{{Cite news |url=http://images.huffingtonpost.com/2016-05-13-1463155843-8474094-AR_history_timeline.jpg |title=The Lengthy History of Augmented Reality |date=May 15, 2016 |work=HuffPost}}&lt;/ref&gt;&lt;ref&gt;{{Cite book |last1=Schueffel |first1=Patrick |url=http://www.heg-fr.ch/EN/School-of-Management/Communication-and-Events/events/Pages/EventViewer.aspx?Event=patrick-schuffel.aspx |title=The Concise Fintech Compendium |publisher=School of Management Fribourg/Switzerland |year=2017 |location=Fribourg |access-date=8 December 2018 |archive-url=https://web.archive.org/web/20171024205446/http://www.heg-fr.ch/EN/School-of-Management/Communication-and-Events/events/Pages/EventViewer.aspx?Event=patrick-schuffel.aspx |archive-date=24 October 2017 |url-status=dead}}&lt;/ref&gt;}}

{{term|[[automata theory]]}}
{{defn|The study of [[abstract machine]]s and [[automaton|automata]], as well as the [[computational problem]]s that can be solved using them. It is a theory in [[theoretical computer science]] and [[discrete mathematics]] (a subject of study in both [[mathematics]] and [[computer science]]).}}

{{term|[[automated planning and scheduling]]}}
{{ghat|Also simply '''AI planning'''.}}
{{defn|A branch of {{gli|artificial intelligence}} that concerns the realization of [[strategy|strategies]] or action sequences, typically for execution by {{gli|intelligent agent|intelligent agents}}, [[autonomous robot]]s and [[unmanned vehicle]]s. Unlike classical [[control system|control]] and [[Statistical classification|classification]] problems, the solutions are complex and must be discovered and optimized in multidimensional space. Planning is also related to [[decision theory]].&lt;ref&gt;{{Citation |last1=Ghallab |first1=Malik |title=Automated Planning: Theory and Practice |url=http://www.laas.fr/planning/ |year=2004 |publisher=[[Morgan Kaufmann]] |isbn=978-1-55860-856-6 |last2=Nau |first2=Dana S. |last3=Traverso |first3=Paolo}}&lt;/ref&gt;}}

{{term|[[automated reasoning]]}}
{{defn|An area of [[computer science]] and [[mathematical logic]] dedicated to understanding different aspects of [[reasoning]]. The study of automated reasoning helps produce [[computer programs]] that allow computers to reason completely, or nearly completely, automatically. Although automated reasoning is considered a sub-field of {{gli|artificial intelligence}}, it also has connections with [[theoretical computer science]], and even [[philosophy]].}}

{{anchor|autonomic computing}}{{term|[[autonomic computing]] (AC)}}
{{defn|The [[Self-management (computer science)|self-managing]] characteristics of [[distributed computing]] resources, adapting to unpredictable changes while hiding intrinsic complexity to operators and users. Initiated by [[IBM]] in 2001, this initiative ultimately aimed to develop computer systems capable of self-management, to overcome the rapidly growing complexity of computing [[systems management]], and to reduce the barrier that complexity poses to further growth.&lt;ref name="Kephart"&gt;{{Citation |last1=Kephart |first1=J.O. |title=The vision of autonomic computing |journal=Computer |volume=36 |pages=41–52 |year=2003 |citeseerx=10.1.1.70.613 |doi=10.1109/MC.2003.1160055 |last2=Chess |first2=D.M.}}&lt;/ref&gt;}}

{{term|[[autonomous car]]}}
{{ghat|Also '''self-driving car''', '''robot car''', and '''driverless car'''.}}
{{defn|A [[Vehicular automation|vehicle]] that is capable of sensing its environment and moving with little or no [[User interface|human input]].&lt;ref&gt;{{Cite conference |last1=Gehrig |first1=Stefan K. |last2=Stein |first2=Fridtjof J. |year=1999 |title=Dead reckoning and cartography using stereo vision for an automated car |conference=IEEE/RSJ International Conference on Intelligent Robots and Systems |location=Kyongju |volume=3 |pages=1507–1512 |doi=10.1109/IROS.1999.811692 |isbn=0-7803-5184-3}}&lt;/ref&gt;&lt;ref&gt;{{Cite news |url=https://www.reuters.com/article/us-autos-selfdriving-uber-idUSKBN1GV296 |title=Self-driving Uber car kills Arizona woman crossing street |date=20 March 2018 |work=Reuters}}&lt;/ref&gt;&lt;ref name="thrun2010toward"&gt;{{Cite journal |last1=Thrun |first1=Sebastian |year=2010 |title=Toward Robotic Cars |journal=Communications of the ACM |volume=53 |issue=4 |pages=99–106 |doi=10.1145/1721654.1721679|s2cid=207177792 }}&lt;/ref&gt;}}

{{term|[[autonomous robot]]}}
{{defn|A [[robot]] that performs [[Behavior-based robotics|behaviors]] or tasks with a high degree of [[autonomy]]. Autonomous robotics is usually considered to be a subfield of {{gli|artificial intelligence}}, [[robotics]], and [[Information engineering (field)|information engineering]].&lt;ref&gt;{{Cite web |url=http://www.robots.ox.ac.uk/ |title=Information Engineering Main/Home Page |publisher=University of Oxford  |access-date=2018-10-03}}&lt;/ref&gt;}}
{{glossaryend}}

{{Compact ToC|side=yes|center=yes|top=yes|num=yes|extlinks=yes|seealso=yes|refs=yes|nobreak=yes|}}

==B==
{{glossary}}
{{term|[[backpropagation]]}}
{{defn|A method used in {{gli|artificial neural network|artificial neural networks}} to calculate a gradient that is needed in the calculation of the [[Artificial neural network#Components of an artificial neural network|weights]] to be used in the network.&lt;ref&gt;Goodfellow, Ian; Bengio, Yoshua; Courville, Aaron (2016) ''Deep Learning''. MIT Press. p. 196. {{ISBN|9780262035613}}&lt;/ref&gt; Backpropagation is shorthand for "the backward propagation of errors", since an error is computed at the output and distributed backwards throughout the network's layers. It is commonly used to train {{gli|deep neural network|deep neural networks}},&lt;ref&gt;{{Cite journal |last1=Nielsen |first1=Michael A. |year=2015 |title=Chapter 6 |url=http://neuralnetworksanddeeplearning.com/chap6.html |journal=Neural Networks and Deep Learning}}&lt;/ref&gt; a term referring to neural networks with more than one hidden layer.&lt;ref&gt;{{Cite web |url=http://ufldl.stanford.edu/wiki/index.php/Deep_Networks:_Overview |title=Deep Networks: Overview - Ufldl |website=ufldl.stanford.edu |access-date=2017-08-04}}&lt;/ref&gt;}}

{{anchor|backpropagation through time}}{{term|[[backpropagation through time]] (BPTT)}}
{{defn|A gradient-based technique for training certain types of {{gli|recurrent neural network|recurrent neural networks}}. It can be used to train [[Recurrent neural network#Elman networks and Jordan networks|Elman networks]]. The algorithm was independently derived by numerous researchers&lt;ref&gt;{{Cite book |last1=Mozer |first1=M. C. |title=Backpropagation: Theory, architectures, and applications |publisher=Hillsdale, NJ: Lawrence Erlbaum Associates |year=1995 |editor-last=Chauvin |editor-first=Y. |pages=137–169 |language=en |chapter=A Focused Backpropagation Algorithm for Temporal Pattern Recognition |access-date=2017-08-21 |editor-last2=Rumelhart |editor-first2=D. |chapter-url=https://www.researchgate.net/publication/243781476}}&lt;/ref&gt;&lt;ref&gt;{{Cite techreport |title=The utility driven dynamic error propagation network |last=Robinson |first=A. J. |last2=Fallside |first2=F. |name-list-style=amp |institution=Cambridge University, Engineering Department |number=CUED/F-INFENG/TR.1 |year=1987 |url=https://www.bibsonomy.org/bibtex/269a88ecbac9a51cbf0b4be189c412820/idsia}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |last1=Werbos |first1=Paul J. |year=1988 |title=Generalization of backpropagation with application to a recurrent gas market model |url=https://zenodo.org/record/1258627 |journal=Neural Networks |volume=1 |issue=4 |pages=339–356 |doi=10.1016/0893-6080(88)90007-x}}&lt;/ref&gt;}}

{{term|[[backward chaining]]}}
{{ghat|Also '''backward reasoning'''.}}
{{defn|An [[inference]] method described colloquially as working backward from the goal. It is used in [[automated theorem prover]]s, [[inference engine]]s, [[proof assistant]]s, and other {{gli|artificial intelligence}} applications.&lt;ref&gt;{{Cite book |last1=Feigenbaum |first1=Edward |url=https://archive.org/details/riseofexpertco00feig |title=The Rise of the Expert Company |publisher=Times Books |year=1988 |isbn=978-0-8129-1731-4 |page=[https://archive.org/details/riseofexpertco00feig/page/317 317] |url-access=registration}}&lt;/ref&gt;}}

{{term|[[bag-of-words model]]}}
{{defn|A simplifying representation used in [[natural language processing]] and [[information retrieval]] (IR). In this model, a text (such as a sentence or a document) is represented as the [[multiset|bag (multiset)]] of its words, disregarding grammar and even word order but keeping [[Multiplicity (mathematics)|multiplicity]]. The bag-of-words model has also been used for {{gli|bag-of-words model in computer vision|computer vision}}.&lt;ref name="sivic"&gt;{{Cite journal |last1=Sivic |first1=Josef |date=April 2009 |title=Efficient visual search of videos cast as text retrieval |url=https://www.di.ens.fr/~josef/publications/sivic09a.pdf |journal=IEEE Transactions on Pattern Analysis and Machine Intelligence |volume=31 |issue=4 |pages=591–605 |citeseerx=10.1.1.174.6841 |doi=10.1109/TPAMI.2008.111 |pmid=19229077|s2cid=9899337 }}&lt;/ref&gt; The bag-of-words model is commonly used in methods of [[document classification]] where the (frequency of) occurrence of each word is used as a [[Feature (machine learning)|feature]] for training a [[Statistical classification|classifier]].&lt;ref&gt;McTear et al 2016, p. 167.&lt;/ref&gt;}}

{{term|[[bag-of-words model in computer vision]]}}
{{defn|In computer vision, the bag-of-words model (BoW model) can be applied to [[image classification]], by treating [[image feature]]s as words.  In document classification, a [[bag of words]] is a [[sparse vector]] of occurrence counts of words; that is, a sparse [[histogram]] over the vocabulary. In [[computer vision]], a ''bag of visual words'' is a vector of occurrence counts of a vocabulary of local image features.}}

{{term|[[batch normalization]]}}
{{defn|A technique for improving the performance and stability of {{gli|artificial neural network|artificial neural networks}}. It is a technique to provide any layer in a neural network with inputs that are zero mean/unit variance.&lt;ref&gt;{{Cite web |url=https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html |title=Understanding the backward pass through Batch Normalization Layer |website=kratzert.github.io |access-date=24 April 2018}}&lt;/ref&gt; Batch normalization was introduced in a 2015 paper.&lt;ref&gt;{{Cite journal |last1=Ioffe |first1=Sergey |last2=Szegedy |first2=Christian |year=2015 |title=Batch Normalization: Accelerating Deep Network Training b y Reducing Internal Covariate Shift |url=https://archive.org/details/arxiv-1502.03167 |arxiv=1502.03167 |bibcode=2015arXiv150203167I}}&lt;/ref&gt;&lt;ref&gt;{{Cite web |url=https://medium.com/deeper-learning/glossary-of-deep-learning-batch-normalisation-8266dcd2fa82 |title=Glossary of Deep Learning: Batch Normalisation |date=2017-06-27 |website=medium.com |access-date=24 April 2018}}&lt;/ref&gt; It is used to normalize the input layer by adjusting and scaling the activations.&lt;ref&gt;{{Cite web |url=https://towardsdatascience.com/batch-normalization-in-neural-networks-1ac91516821c |title=Batch normalization in Neural Networks |date=2017-10-20 |website=towardsdatascience.com |access-date=24 April 2018}}&lt;/ref&gt;}}

{{term|[[Bayesian programming]]}}
{{defn|A formalism and a methodology for having a technique to specify [[Probability distribution|probabilistic models]] and solve problems when less than the necessary information is available.}}

{{term|[[bees algorithm]]}}
{{defn|A population-based {{gli|search algorithm}} which was developed by Pham, Ghanbarzadeh and et al. in 2005.&lt;ref name="Pham &amp; al, 2005"&gt;Pham DT, Ghanbarzadeh A, Koc E, Otri S, Rahim S and Zaidi M. The Bees Algorithm. Technical Note, Manufacturing Engineering Centre, Cardiff University, UK, 2005.&lt;/ref&gt; It mimics the food foraging behaviour of honey bee colonies. In its basic version the algorithm performs a kind of neighbourhood search combined with global search, and can be used for both [[combinatorial optimization]] and [[continuous optimization]]. The only condition for the application of the bees algorithm is that some measure of distance between the solutions is defined. The effectiveness and specific abilities of the bees algorithm have been proven in a number of studies.&lt;ref name="Pham &amp; Castellani, 2009"&gt;Pham, D.T., Castellani, M. (2009), [http://pic.sagepub.com/content/223/12/2919.short The Bees Algorithm – Modelling Foraging Behaviour to Solve Continuous Optimisation Problems]. Proc. ImechE, Part C, 223(12), 2919-2938.&lt;/ref&gt;&lt;ref&gt;{{Cite journal |last1=Pham |first1=D. T. |last2=Castellani |first2=M. |year=2014 |title=Benchmarking and comparison of nature-inspired population-based continuous optimisation algorithms |journal=Soft Computing |volume=18 |issue=5 |pages=871–903 |doi=10.1007/s00500-013-1104-9|s2cid=35138140 }}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |last1=Pham |first1=Duc Truong |last2=Castellani |first2=Marco |year=2015 |title=A comparative study of the Bees Algorithm as a tool for function optimisation |journal=Cogent Engineering |volume=2 |doi=10.1080/23311916.2015.1091540 |doi-access=free}}&lt;/ref&gt;&lt;ref name="Nasrinpour &amp; Massah &amp; Teshnehlab 2017"&gt;{{Cite journal |last1=Nasrinpour |first1=H. R. |last2=Massah Bavani |first2=A. |last3=Teshnehlab |first3=M. |year=2017 |title=Grouped Bees Algorithm: A Grouped Version of the Bees Algorithm |url=http://www.mdpi.com/2073-431X/6/1/5 |journal=Computers |volume=6 |issue=1 |page=5 |doi=10.3390/computers6010005 |doi-access=free}}&lt;/ref&gt;}}

{{anchor|behavior informatics}}{{term|[[behavior informatics]] (BI)}}
{{defn|The informatics of behaviors so as to obtain behavior intelligence and behavior insights.&lt;ref&gt;{{Cite journal |last1=Cao |first1=Longbing |year=2010 |title=In-depth Behavior Understanding and Use: the Behavior Informatics Approach |journal=Information Science |volume=180 |issue=17 |pages=3067–3085 |doi=10.1016/j.ins.2010.03.025|arxiv=2007.15516 |s2cid=7400761 }}&lt;/ref&gt;}}

{{term|[[behavior tree (artificial intelligence, robotics and control)|behavior tree]] (BT)}}
{{defn|A [[mathematical model]] of [[Automated planning and scheduling|plan]] execution used in [[computer science]], [[robotics]], [[control systems]] and [[Artificial intelligence (video games)|video games]]. They describe switchings between a finite set of tasks in a modular fashion. Their strength comes from their ability to create very complex tasks composed of simple tasks, without worrying how the simple tasks are implemented. BTs present some similarities to [[State machine|hierarchical state machines]] with the key difference that the main building block of a behavior is a task rather than a state. Its ease of human understanding make BTs less error-prone and very popular in the game developer community. BTs have shown to generalize several other control architectures.&lt;ref name="Colledanchise TRO16"&gt;Colledanchise Michele, and Ögren Petter 2016. [http://michelecolledanchise.com/tro16colledanchise.pdf How Behavior Trees Modularize Hybrid Control Systems and Generalize Sequential Behavior Compositions, the Subsumption Architecture, and Decision Trees. In IEEE Transactions on Robotics vol.PP, no.99, pp.1-18 (2016)]&lt;/ref&gt;&lt;ref name="Colledanchise BOOK17"&gt;Colledanchise Michele, and Ögren Petter 2017. [https://arxiv.org/abs/1709.00084 Behavior Trees in Robotics and AI: An Introduction.]&lt;/ref&gt;}}

{{term|[[belief-desire-intention software model]] (BDI)}}
{{defn|A software model developed for programming {{gli|intelligent agent|intelligent agents}}. Superficially characterized by the implementation of an agent's ''beliefs'', ''desires'' and ''intentions'', it actually uses these concepts to solve a particular problem in agent programming. In essence, it provides a mechanism for separating the activity of selecting a plan (from a plan library or an external planner application) from the execution of currently active plans. Consequently, BDI agents are able to balance the time spent on deliberating about plans (choosing what to do) and executing those plans (doing it). A third activity, creating the plans in the first place (planning), is not within the scope of the model, and is left to the system designer and programmer.}}

{{term|[[bias–variance tradeoff]]}}
{{defn|In [[statistics]] and {{gli|machine learning}}, the bias–variance tradeoff is the property of a set of predictive models whereby models with a lower [[Bias of an estimator|bias]] in [[statistical parameter|parameter]] [[estimation theory|estimation]] have a higher [[variance]] of the parameter estimates across [[sample (statistics)|samples]], and vice versa.}}

{{term|[[big data]]}}
{{defn|A term used to refer to [[data set]]s that are too large or complex for traditional [[data processing|data-processing]] [[application software]] to adequately deal with. Data with many cases (rows) offer greater [[statistical power]], while data with higher complexity (more attributes or columns) may lead to a higher [[false discovery rate]].&lt;ref&gt;{{Cite journal |last1=Breur |first1=Tom |date=July 2016 |title=Statistical Power Analysis and the contemporary "crisis" in social sciences |journal=Journal of Marketing Analytics  |volume=4 |issue=2–3 |pages=61–65 |doi=10.1057/s41270-016-0001-3 |issn=2050-3318 |doi-access=free}}&lt;/ref&gt;}}

{{term|[[Big O notation]]}}
{{defn|A mathematical notation that describes the [[asymptotic analysis|limiting behavior]] of a [[function (mathematics)|function]] when the [[Argument of a function|argument]] tends towards a particular value or infinity.  It is a member of a family of notations invented by [[Paul Gustav Heinrich Bachmann|Paul Bachmann]],&lt;ref name="Bachmann"&gt;{{Cite book |last1=Bachmann |first1=Paul |url=https://archive.org/stream/dieanalytischeza00bachuoft#page/402/mode/2up |title=Analytische Zahlentheorie |date=1894 |publisher=Teubner |volume=2 |location=Leipzig |language=de |trans-title=Analytic Number Theory |author-link=Paul Bachmann}}&lt;/ref&gt; [[Edmund Landau]],&lt;ref name="Landau"&gt;{{Cite book |last1=Landau |first1=Edmund |url=https://archive.org/details/handbuchderlehre01landuoft |title=Handbuch der Lehre von der Verteilung der Primzahlen |date=1909 |publisher=B. G. Teubner |location=Leipzig |page=883 |language=de |trans-title=Handbook on the theory of the distribution of the primes |author-link=Edmund Landau}}&lt;/ref&gt; and others, collectively called Bachmann–Landau notation or asymptotic notation.}}

{{term|[[binary tree]]}}
{{defn|A [[tree structure|tree]] [[data structure]] in which each node has at most two [[child node|children]], which are referred to as the ''{{visible anchor|left child}}'' and the ''{{visible anchor|right child}}''. A [[recursive definition]] using just [[set theory]] notions is that a (non-empty) binary tree is a [[tuple]] (''L'', ''S'', ''R''), where ''L'' and ''R'' are binary trees or the [[empty set]] and ''S'' is a [[singleton set]].&lt;ref name="GarnierTaylor2009"&gt;{{Cite book |editor-last=Garnier |editor-first=Rowan |url=https://books.google.com/books?id=WnkZSSc4IkoC&amp;pg=PA620 |title=Discrete Mathematics: Proofs, Structures and Applications, Third Edition |last1=John |first1=Taylor |publisher=CRC Press |year=2009 |isbn=978-1-4398-1280-8 |page=620}}&lt;/ref&gt; Some authors allow the binary tree to be the empty set as well.&lt;ref name="Skiena2009"&gt;{{Cite book |last1=Skiena |first1=Steven S |url=https://books.google.com/books?id=7XUSn0IKQEgC&amp;pg=PA77 |title=The Algorithm Design Manual |publisher=Springer Science &amp; Business Media |year=2009 |isbn=978-1-84800-070-4 |page=77}}&lt;/ref&gt;}}

{{term|[[blackboard system]]}}
{{defn|An {{gli|artificial intelligence}} approach based on the [[blackboard design pattern|blackboard architectural model]],&lt;ref&gt;{{Cite journal |last1=Erman |first1=L. D. |last2=Hayes-Roth |first2=F. |last3=Lesser |first3=V. R. |last4=Reddy |first4=D. R. |year=1980 |title=The Hearsay-II Speech-Understanding System: Integrating Knowledge to Resolve Uncertainty |journal=ACM Computing Surveys |volume=12 |issue=2 |pages=213 |doi=10.1145/356810.356816|s2cid=118556 }} &lt;!-- Erman, Hayes-Roth, &amp; Reddy (1980). "The Hearsay-II Speech-Understanding System: Integrating Knowledge to Resolve Uncertainty" --&gt;&lt;/ref&gt;&lt;ref&gt;{{Cite journal |last1=Corkill |first1=Daniel D. |date=September 1991 |title=Blackboard Systems |url=http://bbtech.com/papers/ai-expert.pdf |journal=AI Expert |volume=6 |issue=9 |pages=40&amp;ndash;47}}&lt;/ref&gt;&lt;ref&gt;* {{Cite techreport |first=H. Yenny |last=Nii |title=Blackboard Systems |number=STAN-CS-86-1123 |institution=Department of Computer Science, Stanford University |year=1986 |url=http://i.stanford.edu/pub/cstr/reports/cs/tr/86/1123/CS-TR-86-1123.pdf |access-date=2013-04-12}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |last1=Hayes-Roth |first1=B. |year=1985 |title=A blackboard architecture for control |journal=Artificial Intelligence |volume=26 |issue=3 |pages=251–321 |doi=10.1016/0004-3702(85)90063-3}} &lt;!-- Hayes-Roth (1985). "A blackboard architecture for control" --&gt;&lt;/ref&gt; where a common knowledge base, the "blackboard", is iteratively updated by a diverse group of specialist knowledge sources, starting with a problem specification and ending with a solution.  Each knowledge source updates the blackboard with a partial solution when its internal constraints match the blackboard state.  In this way, the specialists work together to solve the problem.}}

{{term|[[Boltzmann machine]]}}
{{ghat|Also '''stochastic Hopfield network with hidden units'''.}}
{{defn|A type of [[stochastic neural network|stochastic]] [[recurrent neural network]] and [[Markov random field]].&lt;ref&gt;{{Cite journal |last1=Hinton |first1=Geoffrey E. |date=2007-05-24 |title=Boltzmann machine |journal=Scholarpedia  |volume=2 |issue=5 |pages=1668 |bibcode=2007SchpJ...2.1668H |doi=10.4249/scholarpedia.1668 |issn=1941-6016 |doi-access=free}}&lt;/ref&gt;  Boltzmann machines can be seen as the [[stochastic process|stochastic]], [[generative model|generative]] counterpart of [[Hopfield network]]s.}}

{{term|[[Boolean satisfiability problem]]}}
{{ghat|Also '''propositional satisfiability problem'''; abbreviated '''SATISFIABILITY''' or '''SAT'''.}}
{{defn|The problem of determining if there exists an [[Interpretation (logic)|interpretation]] that [[Satisfiability|satisfies]] a given [[Boolean logic|Boolean]] [[Formula (mathematical logic)|formula]]. In other words, it asks whether the variables of a given Boolean formula can be consistently replaced by the values TRUE or FALSE in such a way that the formula [[Validity (logic)|evaluates to TRUE]]. If this is the case, the formula is called ''satisfiable''. On the other hand, if no such assignment exists, the function expressed by the formula is [[Contradiction#Contradiction in formal logic|FALSE]] for all possible variable assignments and the formula is ''unsatisfiable''. For example, the formula "''a'' AND NOT ''b''" is satisfiable because one can find the values ''a''&amp;nbsp;=&amp;nbsp;TRUE and ''b''&amp;nbsp;=&amp;nbsp;FALSE, which make (''a'' AND NOT ''b'')&amp;nbsp;=&amp;nbsp;TRUE. In contrast, "''a'' AND NOT ''a''" is unsatisfiable.}}

{{term|[[brain technology]]}}
{{ghat|Also '''self-learning know-how system'''.}}
{{defn|A technology that employs the latest findings in [[neuroscience]]. The term was first introduced by the Artificial Intelligence Laboratory in [[Zurich, Switzerland]], in the context of the [[ROBOY]] project.&lt;ref&gt;[http://www.nzz.ch/aktuell/zuerich/uebersicht/die-zangengeburt-eines-designierten-stammvaters-1.18029566# ''NZZ- Die Zangengeburt eines möglichen Stammvaters'']. Website [[Neue Zürcher Zeitung]]. Seen 16. August 2013.&lt;/ref&gt; Brain Technology can be employed in robots,&lt;ref&gt;[http://www.roboy.org/mediaundnews.html ''Official Homepage Roboy''] {{Webarchive|url=https://web.archive.org/web/20130803052035/http://www.roboy.org/mediaundnews.html |date=2013-08-03 }}. Website Roboy. Seen 16. August 2013.&lt;/ref&gt; [[Starmind International|know-how management systems]]&lt;ref&gt;[http://www.starmind.com/ ''Official Homepage Starmind'']. Website Starmind. Seen 16. August 2013.&lt;/ref&gt; and any other application with self-learning capabilities. In particular, Brain Technology applications allow the visualization of the underlying learning architecture often coined as "know-how maps".}}

{{term|[[branching factor]]}}
{{defn|In [[computing]], [[tree data structure]]s, and [[game theory]], the number of [[child node|children]] at each {{gli|node}}, the [[outdegree]]. If this value is not uniform, an ''average branching factor'' can be calculated.}}

{{term|[[brute-force search]]}}
{{ghat|Also '''exhaustive search''' or '''generate and test'''.}}
{{defn|A very general [[problem-solving]] technique and [[algorithmic paradigm]] that consists of systematically enumerating all possible candidates for the solution and checking whether each candidate satisfies the problem's statement.}}
{{glossaryend}}

{{Compact ToC|side=yes|center=yes|top=yes|num=yes|extlinks=yes|seealso=yes|refs=yes|nobreak=yes|}}

==C==
{{glossary}}
{{term|[[capsule neural network]] (CapsNet)}}
{{defn|A machine learning system that is a type of {{gli|artificial neural network}} (ANN) that can be used to better model hierarchical relationships. The approach is an attempt to more closely mimic biological neural organization.&lt;ref&gt;{{Cite arXiv |eprint=1710.09829 |class=cs.CV |first1=Sara |last1=Sabour |first2=Nicholas |last2=Frosst |title=Dynamic Routing Between Capsules |date=2017-10-26 |last3=Hinton |first3=Geoffrey E.}}&lt;/ref&gt;}}

{{anchor|case-based reasoning}}{{term|[[case-based reasoning]] (CBR)}}
{{defn|Broadly construed, the process of solving new problems based on the solutions of similar past problems.}}

{{term|[[chatbot]]}}
{{ghat|Also '''smartbot''', '''talkbot''', '''chatterbot''', '''bot''', '''IM bot''', '''interactive agent''', '''conversational interface''', or '''artificial conversational entity'''.}}
{{defn|A [[computer program]] or an {{gli|artificial intelligence}} which conducts a [[conversation]] via auditory or textual methods.&lt;ref name="target"&gt;{{Cite web |url=http://searchdomino.techtarget.com/sDefinition/0,,sid4_gci935566,00.html |title=What is a chatbot? |website=techtarget.com |access-date=30 January 2017}}&lt;/ref&gt;}}

{{term|[[cloud robotics]]}}
{{defn|A field of [[robotics]] that attempts to invoke cloud technologies such as [[cloud computing]], [[cloud storage]], and other [[Internet technologies]] centred on the benefits of converged infrastructure and shared services for robotics. When connected to the cloud, robots can benefit from the powerful computation, storage, and communication resources of modern [[data center]] in the cloud, which can process and share information from various robots or agent (other machines, smart objects, humans, etc.). Humans can also delegate tasks to robots remotely through [[network (computing)|network]]s. Cloud computing technologies enable robot systems to be endowed with powerful capability whilst reducing costs through cloud technologies. Thus, it is possible to build lightweight, low cost, smarter robots have intelligent "brain" in the cloud. The "brain" consists of [[data center]], [[knowledge base]], task planners, [[deep learning]], information processing, environment models, communication support, etc.&lt;ref name="RASrobot"&gt;{{Cite journal |last1=Civera |first1=Javier |last2=Ciocarlie |first2=Matei |last3=Aydemir |first3=Alper |last4=Bekris |first4=Kostas |last5=Sarma |first5=Sanjay |s2cid=16080778 |year=2015 |title=Guest Editorial Special Issue on Cloud Robotics and Automation |journal=IEEE Transactions on Automation Science and Engineering |volume=12 |issue=2 |pages=396–397 |doi=10.1109/TASE.2015.2409511}}&lt;/ref&gt;&lt;ref&gt;{{Cite web |url=https://www.roboearth.org/ |title=Robo Earth - Tech News |website=Robo Earth}}&lt;/ref&gt;&lt;ref name="kengoldberg"&gt;{{Cite web |url=http://goldberg.berkeley.edu/cloud-robotics |title=Cloud Robotics and Automation |last1=Goldberg |first1=Ken}}&lt;/ref&gt;&lt;ref name="sites.google.com"&gt;{{Cite web |url=https://sites.google.com/site/ruijiaoli/blogs/page |title=Cloud Robotics-Enable cloud computing for robots |last1=Li |first1=R |access-date=7 December 2014}}&lt;/ref&gt;}}

{{term|[[cluster analysis]]}}
{{ghat|Also '''clustering'''.}}
{{defn|The task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense) to each other than to those in other groups (clusters). It is a main task of exploratory [[data mining]], and a common technique for [[statistics|statistical]] [[data analysis]], used in many fields, including {{gli|machine learning}}, [[pattern recognition]], [[image analysis]], [[information retrieval]], [[bioinformatics]], [[data compression]], and [[computer graphics]].}}

{{term|[[Cobweb (clustering)|Cobweb]]}}
{{defn|An incremental system for hierarchical [[conceptual clustering]]. COBWEB was invented by Professor [[Douglas H. Fisher (Computer Science)|Douglas H. Fisher]], currently at Vanderbilt University.&lt;ref&gt;{{Cite journal |last1=Fisher |first1=Douglas |year=1987 |title=Knowledge acquisition via incremental conceptual clustering |journal=Machine Learning |volume=2 |issue=2 |pages=139–172 |doi=10.1007/BF00114265 |doi-access=free}}&lt;/ref&gt;&lt;ref&gt;{{Cite conference |last1=Fisher |first1=Douglas H. |date=July 1987 |title=Improving inference through conceptual clustering |conference=AAAI Conference |location=Seattle Washington |pages=461–465 |book-title=Proceedings of the 1987 AAAI Conferences}}&lt;/ref&gt; COBWEB incrementally organizes observations into a [[classification tree]]. Each node in a classification tree represents a class (concept) and is labeled by a probabilistic concept that summarizes the attribute-value distributions of objects classified under the node. This classification tree can be used to predict missing attributes or the class of a new object.&lt;ref&gt;{{Cite book |last1=Iba |first1=William |last2=Langley |first2=Pat |title=Formal approaches in categorization |date=2011-01-27 |publisher=Cambridge University Press |isbn=9780521190480 |editor-last=Pothos |editor-first=Emmanuel M. |editor-last2=Wills |editor-first2=Andy J. |location=Cambridge |pages=253–273 |chapter=Cobweb models of categorization and probabilistic concept formation}}&lt;/ref&gt;}}

{{term|[[cognitive architecture]]}}
{{defn|The [[Institute of Creative Technologies]] defines cognitive architecture as: "hypothesis about the fixed structures that provide a mind, whether in natural or artificial systems, and how they work together – in conjunction with knowledge and skills embodied within the architecture – to yield intelligent behavior in a diversity of complex environments."&lt;ref&gt;Refer to the ICT website: http://cogarch.ict.usc.edu/&lt;/ref&gt;}}

{{term|[[cognitive computing]]}}
{{defn|In general, the term cognitive computing has been used to refer to new hardware and/or software that [[Neuromorphic computing|mimics the functioning]] of the [[human brain]]&lt;ref&gt;{{Cite web |url=http://labs.hpe.com/research/next-next/brain/ |title=Hewlett Packard Labs}}&lt;/ref&gt;&lt;ref&gt;Terdiman, Daniel (2014) .IBM's TrueNorth processor mimics the human brain.http://www.cnet.com/news/ibms-truenorth-processor-mimics-the-human-brain/&lt;/ref&gt;&lt;ref&gt;Knight, Shawn (2011). ''[http://www.techspot.com/news/45138-ibm-unveils-cognitive-computing-chips-that-mimic-human-brain.html IBM unveils cognitive computing chips that mimic human brain]'' TechSpot: August 18, 2011, 12:00 PM&lt;/ref&gt;&lt;ref&gt;Hamill, Jasper (2013). ''[https://www.theregister.co.uk/2013/08/08/ibm_unveils_computer_architecture_based_upon_your_brain/ Cognitive computing: IBM unveils software for its brain-like SyNAPSE chips]'' The Register: August 8, 2013&lt;/ref&gt;&lt;ref name="Denning"&gt;{{Cite journal |last1=Denning. |first1=P.J. |year=2014 |title=Surfing Toward the Future |journal=Communications of the ACM |volume=57 |issue=3 |pages=26–29 |doi=10.1145/2566967|s2cid=20681733 }}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |last1=Ludwig |first1=Lars |year=2013 |title=Extended Artificial Memory. Toward an integral cognitive theory of memory and technology. |url=https://kluedo.ub.uni-kl.de/frontdoor/index/index/docId/3662 |format=pdf |publisher=Technical University of Kaiserslautern |access-date=2017-02-07}}&lt;/ref&gt; and helps to improve human decision-making.&lt;ref&gt;{{Cite web |url=http://www.hpl.hp.com/research/ |title=Research at HP Labs}}&lt;/ref&gt;&lt;ref&gt;{{Cite web |url=http://thesiliconreview.com/magazines/automate-complex-workflows-using-tactical-cognitive-computing-coseer/ |title=Automate Complex Workflows Using Tactical Cognitive Computing: Coseer |website=thesiliconreview.com |access-date=2017-07-31}}&lt;/ref&gt; In this sense, CC is a new type of computing with the goal of more accurate models of how the human brain/[[mind]] senses, [[Reasoning|reasons]], and responds to stimulus.}}

{{term|[[cognitive science]]}}
{{defn|The interdisciplinary scientific study of the [[mind]] and its processes.&lt;ref&gt;Cognitive science is an interdisciplinary field of researchers from Linguistics, psychology, neuroscience, philosophy, computer science, and anthropology that seek to understand the mind. [http://www.aft.org/newspubs/periodicals/ae/summer2002/willingham.cfm How We Learn: Ask the Cognitive Scientist]&lt;/ref&gt;}}

{{term|[[combinatorial optimization]]}}
{{defn|In [[Operations Research]], [[applied mathematics]] and [[theoretical computer science]], combinatorial optimization &lt;!-- synonymous or subfield?: discrete optimization{{Citation needed|date=May 2012}} --&gt; is a topic that consists of finding an optimal object from a [[finite set]] of objects.&lt;ref&gt;Schrijver, Alexander (February 1, 2006). A Course in Combinatorial Optimization (PDF), page 1.&lt;/ref&gt;}}

{{term|[[committee machine]]}}
{{defn|A type of {{gli|artificial neural network}} using a [[Divide and rule|divide and conquer]] strategy in which the responses of multiple neural networks (experts) are combined into a single response.&lt;ref&gt;HAYKIN, S. Neural Networks - A Comprehensive Foundation. Second edition. Pearson Prentice Hall: 1999.&lt;/ref&gt;  The combined response of the committee machine is supposed to be superior to those of its constituent experts. Compare [[ensembles of classifiers]].}}

{{term|[[commonsense knowledge (artificial intelligence)|commonsense knowledge]]}}
{{defn|In {{gli|artificial intelligence}} research, commonsense knowledge consists of facts about the everyday world, such as "Lemons are sour", that all humans are expected to know.  The first AI program to address common sense knowledge was [[Advice Taker]] in 1959 by John McCarthy.&lt;ref&gt;{{Cite web |url=http://www-formal.stanford.edu/jmc/mcc59/mcc59.html |title=PROGRAMS WITH COMMON SENSE |website=www-formal.stanford.edu |access-date=2018-04-11}}&lt;/ref&gt;}}

{{term|[[commonsense reasoning]]}}
{{defn|A branch of artificial intelligence concerned with simulating the human ability to make presumptions about the type and essence of ordinary situations they encounter every day.&lt;ref&gt;{{Cite magazine |last1=Davis |first1=Ernest |last2=Marcus |first2=Gary |year=2015 |title=Commonsense reasoning |url=http://cacm.acm.org/magazines/2015/9/191169-commonsense-reasoning-and-commonsense-knowledge-in-artificial-intelligence/fulltext |magazine=Communications of the ACM |volume=58 |pages=92–103 |doi=10.1145/2701413 |number=9}}&lt;/ref&gt;}}

{{term|[[computational chemistry]]}}
{{defn|A branch of [[chemistry]] that uses [[computer simulation]] to assist in solving chemical problems.}}

{{term|[[computational complexity theory]]}}
{{defn|Focuses on classifying computational problems according to their inherent difficulty, and relating these classes to each other. A computational problem is a task solved by a computer. A computation problem is solvable by mechanical application of mathematical steps, such as an algorithm.}}

{{term|[[computational creativity]]}}
{{ghat|Also '''artificial creativity''', '''mechanical creativity''', '''creative computing''', or '''creative computation'''.}}
{{defn|A multidisciplinary endeavour that includes the fields of {{gli|artificial intelligence}}, [[cognitive psychology]], [[philosophy]], and [[the arts]].}}

{{term|[[computational cybernetics]]}}
{{defn|The integration of [[cybernetics]] and {{gli|computational intelligence}} techniques.}}

{{term|[[computational humor]]}}
{{defn|A branch of [[computational linguistics]] and {{gli|artificial intelligence}} which uses [[computer]]s in [[humor research]].&lt;ref&gt;Hulstijn, J, and Nijholt, A. (eds.). Proceedings of the International Workshop on Computational Humor. Number 12 in Twente Workshops on Language Technology, Enschede, Netherlands. University of Twente, 1996.&lt;/ref&gt;}}

{{anchor|computational intelligence}}{{term|[[computational intelligence]] (CI)}}
{{defn|Usually refers to the ability of a [[computer]] to learn a specific task from data or experimental observation.}}

{{term|[[computational learning theory]]}}
{{defn|In [[computer science]], computational learning theory (or just learning theory) is a subfield of {{gli|artificial intelligence}} devoted to studying the design and analysis of {{gli|machine learning}} algorithms.&lt;ref name="ACL"&gt;{{Cite web |url=http://www.learningtheory.org/ |title=ACL - Association for Computational Learning}}&lt;/ref&gt;}}

{{term|[[computational linguistics]]}}
{{defn|An [[interdisciplinary]] field concerned with the statistical or rule-based modeling of [[natural language]] from a computational perspective, as well as the study of appropriate computational approaches to linguistic questions.}}

{{term|[[computational mathematics]]}}
{{defn|The mathematical research in areas of science where [[computation|computing]] plays an essential role.}}

{{term|[[computational neuroscience]]}}
{{ghat|Also '''theoretical neuroscience''' or '''mathematical neuroscience'''.}} 
{{defn|A branch of [[neuroscience]] which employs mathematical models, theoretical analysis and abstractions of the brain to understand the principles that govern the [[Developmental neuroscience|development]], [[Neuroanatomy|structure]], [[Neurophysiology|physiology]], and [[Cognitive neuroscience|cognitive abilities]] of the [[nervous system]].&lt;ref&gt;Trappenberg, Thomas P. (2002). Fundamentals of Computational Neuroscience. United States: Oxford University Press Inc. p. 1. {{ISBN|978-0-19-851582-1}}.&lt;/ref&gt;&lt;ref&gt;What is computational neuroscience? Patricia S. Churchland, Christof Koch, Terrence J. Sejnowski. in Computational Neuroscience pp.46-55. Edited by Eric L. Schwartz. 1993. MIT Press {{Cite web |url=http://mitpress.mit.edu/catalog/item/default.asp?ttype=2&amp;tid=7195 |title=Archived copy |url-status=dead |archive-url=https://web.archive.org/web/20110604124206/http://mitpress.mit.edu/catalog/item/default.asp?ttype=2&amp;tid=7195 |archive-date=2011-06-04 |access-date=2009-06-11}}&lt;/ref&gt;&lt;ref&gt;{{Cite web |url=https://mitpress.mit.edu/books/theoretical-neuroscience |title=Theoretical Neuroscience |website=The MIT Press  |url-status=dead |archive-url=https://web.archive.org/web/20180531150713/http://mitpress.mit.edu/books/theoretical-neuroscience |archive-date=31 May 2018 |access-date=2018-05-24}}&lt;/ref&gt;&lt;ref&gt;{{Cite book |last1=Gerstner |first1=W. |title=Neuronal Dynamics |last2=Kistler, W. |last3=Naud, R. |last4=Paninski, L. |publisher=Cambridge University Press |year=2014 |isbn=9781107447615 |location=Cambridge, UK}}&lt;/ref&gt;}}

{{term|[[computational number theory]]}}
{{ghat|Also '''algorithmic number theory'''.}}
{{defn|The study of {{gli|algorithm|algorithms}} for performing [[number theory|number theoretic]] [[computations]].}}

{{term|[[computational problem]]}}
{{defn|In [[theoretical computer science]], a computational problem is a [[mathematical object]] representing a collection of questions that [[computers]] might be able to solve.}}

{{term|[[computational statistics]]}}
{{ghat|Also '''statistical computing'''.}}
{{defn|The interface between [[statistics]] and {{gli|computer science}}.}}

{{anchor|computer-automated design}}{{term|[[computer-automated design]] (CAutoD)}}
{{defn|Design automation usually refers to [[electronic design automation]], or [[Design Automation]] which is a [[Product Configurator]]. Extending [[Computer-Aided Design]] (CAD), automated design and computer-automated design&lt;ref name="IBM"&gt;{{Cite journal |last1=Kamentsky |first1=L.A. |last2=Liu |first2=C.-N. |year=1963 |title=Computer-Automated Design of Multifont Print Recognition Logic |url=http://domino.research.ibm.com/tchjr/journalindex.nsf/0/a5cb0910ea78194885256bfa00683e5a?OpenDocument |journal=IBM Journal of Research and Development |volume=7 |issue=1 |page=2 |doi=10.1147/rd.71.0002}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |last1=Brncick |first1=M |year=2000 |title=Computer automated design and computer automated manufacture |journal=Phys Med Rehabil Clin N Am |volume=11 |issue=3 |pages=701–13 |doi=10.1016/s1047-9651(18)30806-4 |pmid=10989487}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |last1=Li |first1=Y. |display-authors=etal |year=2004 |title=CAutoCSD - Evolutionary search and optimisation enabled computer automated control system design [https://link.springer.com/content/pdf/10.1007%2Fs11633-004-0076-8.pdf abstract] |journal=International Journal of Automation and Computing |volume=1 |issue=1 |pages=76–88 |doi=10.1007/s11633-004-0076-8|s2cid=55417415 }}&lt;/ref&gt; are concerned with a broader range of applications, such as [[automotive engineering]], [[civil engineering]],&lt;ref&gt;{{Cite journal |last1=Kramer |first1=GJE |last2=Grierson |first2=DE |title=Computer automated design of structures under dynamic loads |journal=Computers &amp; Structures |year=1989 |volume=32 |issue=2 |pages=313–325 |doi=10.1016/0045-7949(89)90043-6}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |last1=Moharrami |first1=H |last2=Grierson |first2=DE |title=Computer‐Automated Design of Reinforced Concrete Frameworks |journal=Journal of Structural Engineering |year=1993 |volume=119 |issue=7 |pages=2036–2058 |doi=10.1061/(asce)0733-9445(1993)119:7(2036)}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |last1=Xu |first1=L |last2=Grierson |first2=DE |title=Computer‐Automated Design of Semirigid Steel Frameworks |journal=Journal of Structural Engineering |year=1993 |volume=119 |issue=6 |pages=1740–1760 |doi=10.1061/(asce)0733-9445(1993)119:6(1740)}}&lt;/ref&gt;&lt;ref&gt;Barsan, GM; Dinsoreanu, M, (1997). Computer-automated design based on structural performance criteria, Mouchel Centenary Conference on Innovation in Civil and Structural Engineering, AUG 19-21, CAMBRIDGE ENGLAND, INNOVATION IN CIVIL AND STRUCTURAL ENGINEERING, 167-172&lt;/ref&gt; [[composite material]] design, [[control engineering]],&lt;ref&gt;{{Cite journal |last1=Li |first1=Yun |year=1996 |title=Genetic algorithm automated approach to the design of sliding mode control systems |journal=International Journal of Control |volume=63 |issue=4 |pages=721–739 |doi=10.1080/00207179608921865}}&lt;/ref&gt; dynamic [[system identification]] and optimization,&lt;ref&gt;{{Cite journal |last1=Li |first1=Yun |last2=Chwee Kim |first2=Ng |last3=Chen Kay |first3=Tan |year=1995 |title=Automation of Linear and Nonlinear Control Systems Design by Evolutionary Computation |url=https://www.sciencedirect.com/science/article/pii/S1474667017451585/pdf?md5=b7aedf998282848dfcf44a1ea2f003dd&amp;pid=1-s2.0-S1474667017451585-main.pdf |journal=IFAC Proceedings Volumes |volume=28 |issue=16 |pages=85–90 |doi=10.1016/S1474-6670(17)45158-5}}&lt;/ref&gt; [[financial]] systems, industrial equipment, {{gli|mechatronics|mechatronic}} systems, [[steel construction]],&lt;ref&gt;Barsan, GM, (1995) Computer-automated design of semirigid steel frameworks according to EUROCODE-3, Nordic Steel Construction Conference 95, JUN 19-21, 787-794&lt;/ref&gt; structural [[optimization (mathematics)|optimisation]],&lt;ref&gt;{{Cite journal |last1=Gray |first1=Gary J. |last2=Murray-Smith |first2=David J. |last3=Li |first3=Yun |display-authors=etal |year=1998 |title=Nonlinear model structure identification using genetic programming |url=https://www.sciencedirect.com/science/article/pii/S0967066198000872/pdf?md5=5ad89d3029a3ebad83086271f3c78f75&amp;pid=1-s2.0-S0967066198000872-main.pdf |journal=Control Engineering Practice |volume=6 |issue=11 |pages=1341–1352 |doi=10.1016/s0967-0661(98)00087-2}}&lt;/ref&gt; and the invention of novel systems. More recently, traditional CAD simulation is seen to be transformed to CAutoD by biologically inspired {{gli|machine learning}},&lt;ref&gt;[https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6052374 Zhan, Z.H., et al. (2011). Evolutionary computation meets machine learning: a survey, IEEE Computational Intelligence Magazine, 6(4), 68-75.]&lt;/ref&gt; including heuristic [[search algorithm|search techniques]] such as [[evolutionary computation]],&lt;ref&gt;[http://ti.arc.nasa.gov/m/pub-archive/768h/0768%20(Hornby).pdf Gregory S. Hornby (2003). Generative Representations for Computer-Automated Design Systems, NASA Ames Research Center, Mail Stop 269-3, Moffett Field, CA 94035-1000]&lt;/ref&gt;&lt;ref&gt;[https://www.msu.edu/~jclune/webfiles/publications/2011-CluneLipson-Evolving3DObjectsWithCPPNs-ECAL.pdf J. Clune and H. Lipson (2011). Evolving three-dimensional objects with a generative encoding inspired by developmental biology. Proceedings of the European Conference on Artificial Life. 2011.]&lt;/ref&gt; and {{gli|swarm intelligence}} algorithms.&lt;ref&gt;{{Cite journal |last1=Zhan |first1=Z.H. |display-authors=etal |year=2009 |title=Adaptive Particle Swarm Optimization |journal=IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics) |volume=39 |issue=6 |pages=1362–1381 |doi=10.1109/tsmcb.2009.2015956 |pmid=19362911|s2cid=11191625 |url=http://eprints.gla.ac.uk/7645/1/7645.pdf }}&lt;/ref&gt;}}

{{term|[[machine listening|computer audition]] (CA)}}
{{defn|See ''{{gli|machine listening}}''.}}

{{term|[[computer science]]}}
{{defn|The theory, experimentation, and engineering that form the basis for the design and use of [[computer]]s. It involves the study of {{gli|algorithm|algorithms}} that process, store, and communicate [[digital data|digital]] [[information]]. A [[computer scientist]] specializes in the theory of computation and the design of computational systems.&lt;ref&gt;{{Cite web |url=http://wordnetweb.princeton.edu/perl/webwn?s=computer%20scientist |title=WordNet Search—3.1 |publisher=Wordnetweb.princeton.edu |access-date=14 May 2012}}&lt;/ref&gt;}}

{{term|[[computer vision]]}}
{{defn|An [[Interdisciplinarity|interdisciplinary scientific field]] that deals with how computers can be made to gain high-level understanding from [[digital image]]s or [[video]]s. From the perspective of [[engineering]], it seeks to automate tasks that the [[human visual system]] can do.&lt;ref&gt;Dana H. Ballard; Christopher M. Brown (1982). Computer Vision. Prentice Hall. {{ISBN|0-13-165316-4}}.&lt;/ref&gt;&lt;ref&gt;Huang, T. (1996-11-19). Vandoni, Carlo, E, ed. Computer Vision : Evolution And Promise (PDF). 19th CERN School of Computing. Geneva: CERN. pp. 21–25. {{doi|10.5170/CERN-1996-008.21}}. {{ISBN|978-9290830955}}.&lt;/ref&gt;&lt;ref&gt;Milan Sonka; Vaclav Hlavac; Roger Boyle (2008). Image Processing, Analysis, and Machine Vision. Thomson. {{ISBN|0-495-08252-X}}.&lt;/ref&gt;}}

{{term|[[concept drift]]}}
{{defn|In {{gli|predictive analytics}} and {{gli|machine learning}}, the concept drift means that the statistical properties of the target variable, which the model is trying to predict, change over time in unforeseen ways. This causes problems because the predictions become less accurate as time passes.}}

{{term|[[connectionism]]}}
{{defn|An approach in the fields of [[cognitive science]], that hopes to explain [[mind|mental]] phenomena using {{gli|artificial neural network|artificial neural networks}}.&lt;ref&gt;{{Cite book |last1=Garson |first1=James |url=https://plato.stanford.edu/archives/fall2018/entries/connectionism/ |title=The Stanford Encyclopedia of Philosophy |date=27 November 2018 |publisher=Metaphysics Research Lab, Stanford University |editor-last=Zalta |editor-first=Edward N. |via=Stanford Encyclopedia of Philosophy}}&lt;/ref&gt;}}

{{term|[[consistent heuristic]]}}
{{defn|In the study of [[shortest path problem|path-finding problems]] in {{gli|artificial intelligence}}, a [[heuristic function]] is said to be consistent, or monotone, if its estimate is always less than or equal to the estimated distance from any neighboring vertex to the goal, plus the cost of reaching that neighbor.}}

{{term|[[constrained conditional model]] (CCM)}}
{{defn|A {{gli|machine learning}} and inference framework that augments the learning of conditional (probabilistic or discriminative) models with declarative constraints.}}

{{term|[[constraint logic programming]]}}
{{defn|A form of [[constraint programming]], in which [[logic programming]] is extended to include concepts from [[constraint satisfaction]]. A constraint logic program is a logic program that contains constraints in the body of clauses. An example of a clause including a constraint is {{code|2=prolog|A(X,Y) :- X+Y&gt;0, B(X), C(Y)}}. In this clause, {{code|2=prolog|X+Y&gt;0}} is a constraint; &lt;code&gt;A(X,Y)&lt;/code&gt;, &lt;code&gt;B(X)&lt;/code&gt;, and &lt;code&gt;C(Y)&lt;/code&gt; are [[Literal (mathematical logic)|literals]] as in regular logic programming. This clause states one condition under which the statement &lt;code&gt;A(X,Y)&lt;/code&gt; holds: &lt;code&gt;X+Y&lt;/code&gt; is greater than zero and both &lt;code&gt;B(X)&lt;/code&gt; and &lt;code&gt;C(Y)&lt;/code&gt; are true.}}

{{term|[[constraint programming]]}}
{{defn|A [[programming paradigm]] wherein [[Finitary relation|relation]]s between [[variable (mathematics)|variable]]s are stated in the form of [[constraint (mathematics)|constraint]]s. Constraints differ from the common [[Language primitive|primitives]] of [[imperative programming]] languages in that they do not specify a step or sequence of steps to execute, but rather the properties of a solution to be found.}}

{{term|[[constructed language]]}}
{{ghat|Also '''conlang'''.}} 
{{defn|A language whose [[phonology]], [[grammar]], and [[vocabulary]] are consciously devised, instead of having developed [[natural language|naturally]]. Constructed languages may also be referred to as artificial, planned, or invented languages.&lt;ref&gt;{{Cite web |url=http://www.eurovision.tv/page/news?id=554&amp;_t=ishtar_for_belgium_to_belgrade |title=Ishtar for Belgium to Belgrade |publisher=European Broadcasting Union |access-date=19 May 2013}}&lt;/ref&gt;}}

{{term|[[control theory]]}}
{{defn|In [[Control engineering|control systems engineering]] is a subfield of mathematics that deals with the control of continuously operating [[dynamical system]]s in engineered processes and machines. The objective is to develop a control model for controlling such systems using a control action in an optimum manner without ''delay or overshoot'' and ensuring control [[Stability theory|stability]].}}

{{term|[[convolutional neural network]]}}
{{defn|In [[deep learning]], a convolutional neural network (CNN, or ConvNet) is a class of [[deep neural network]]s, most commonly applied to analyzing visual imagery. CNNs use a variation of [[multilayer perceptron]]s designed to require minimal [[Data pre-processing|preprocessing]].&lt;ref name="LeCun"&gt;{{Cite web |url=http://yann.lecun.com/exdb/lenet/ |title=LeNet-5, convolutional neural networks |last1=LeCun |first1=Yann |access-date=16 November 2013}}&lt;/ref&gt; They are also known as shift invariant or space invariant artificial neural networks (SIANN), based on their shared-weights architecture and [[translation invariance]] characteristics.&lt;ref&gt;Zhang, Wei (1988). "Shift-invariant pattern recognition neural network and its optical architecture". Proceedings of annual conference of the Japan Society of Applied Physics.&lt;/ref&gt;&lt;ref&gt;{{Cite journal |last1=Zhang |first1=Wei |year=1990 |title=Parallel distributed processing model with local space-invariant interconnections and its optical architecture |journal=Applied Optics |volume=29 |issue=32 |pages=4790–7 |bibcode=1990ApOpt..29.4790Z |doi=10.1364/AO.29.004790 |pmid=20577468}}&lt;/ref&gt;}}

{{term|[[crossover (genetic algorithm)|crossover]]}}
{{ghat|Also '''recombination'''.}}
{{defn|In {{gli|genetic algorithm|genetic algorithms}} and {{gli|evolutionary computation}}, a [[genetic operator]] used to combine the [[chromosome (genetic algorithm)|genetic information]] of two parents to generate new offspring. It is one way to stochastically generate new [[candidate solution|solutions]] from an existing population, and analogous to the [[chromosomal crossover|crossover]] that happens during [[sexual reproduction]] in biological organisms. Solutions can also be generated by [[cloning]] an existing solution, which is analogous to [[asexual reproduction]]. Newly generated solutions are typically {{gli|mutation|mutated}} before being added to the population.}}
{{glossaryend}}

{{Compact ToC|side=yes|center=yes|top=yes|num=yes|extlinks=yes|seealso=yes|refs=yes|nobreak=yes|}}

==D==
{{glossary}}
{{term|[[Darkforest]]}}
{{defn|A [[computer go]] program developed by [[Facebook]], based on {{gli|deep learning}} techniques using a [[convolutional neural network]]. Its updated version &lt;!-- not a typo --&gt;Darkfores2&lt;!-- not a typo --&gt; combines the techniques of its predecessor with [[Monte Carlo tree search]].&lt;ref name="facebook-paper2"&gt;{{Cite arXiv |eprint=1511.06410v1 |class=cs.LG |first1=Yuandong |last1=Tian |first2=Yan |last2=Zhu |title=Better Computer Go Player with Neural Network and Long-term Prediction |year=2015}}&lt;/ref&gt;&lt;ref&gt;{{Cite web |url=https://www.technologyreview.com/s/544181/how-facebooks-ai-researchers-built-a-game-changing-go-engine/ |title=How Facebook's AI Researchers Built a Game-Changing Go Engine |date=December 4, 2015 |website=MIT Technology Review |access-date=2016-02-03}}&lt;/ref&gt; The MCTS effectively takes tree search methods commonly seen in computer chess programs and randomizes them.&lt;ref&gt;{{Cite web |url=http://www.techtimes.com/articles/128636/20160128/facebook-ai-go-player-gets-smarter-with-neural-network-and-long-term-prediction-to-master-worlds-hardest-game.htm |title=Facebook AI Go Player Gets Smarter With Neural Network And Long-Term Prediction To Master World's Hardest Game |date=2016-01-28 |website=Tech Times |access-date=2016-04-24}}&lt;/ref&gt; With the update, the system is known as Darkfmcts3.&lt;ref name=":2"&gt;{{Cite web |url=https://venturebeat.com/2016/01/26/facebooks-artificially-intelligent-go-player-is-getting-smarter/ |title=Facebook's artificially intelligent Go player is getting smarter |date=2016-01-27 |website=VentureBeat |access-date=2016-04-24}}&lt;/ref&gt;}}

{{term|[[Dartmouth workshop]]}}
{{defn|The Dartmouth Summer Research Project on Artificial Intelligence was the name of a 1956 summer workshop now considered by many&lt;ref&gt;Solomonoff, R.J.The Time Scale of Artificial Intelligence; Reflections on Social Effects, Human Systems Management, Vol 5 1985, Pp 149-153&lt;/ref&gt;&lt;ref&gt;Moor, J., The Dartmouth College Artificial Intelligence Conference: The Next Fifty years, AI Magazine, Vol 27, No., 4, Pp. 87-9, 2006&lt;/ref&gt; (though not all&lt;ref&gt;Kline, Ronald R., Cybernetics, Automata Studies and the Dartmouth Conference on Artificial Intelligence, IEEE Annals of the History of Computing, October–December, 2011, IEEE Computer Society&lt;/ref&gt;) to be the [[wikt:seminal|seminal]] event for {{gli|artificial intelligence}} as a field.}}

{{term|[[data augmentation]]}}
{{defn|Data augmentation in data analysis are techniques used to increase the amount of data. It helps reduce [[overfitting]] when training a [[machine learning]].}}

{{term|[[data fusion]]}}
{{defn|The process of integrating multiple data sources to produce more consistent, accurate, and useful information than that provided by any individual data source.&lt;ref name="dca"&gt;{{Cite journal |last1=Haghighat |first1=Mohammad |last2=Abdel-Mottaleb |first2=Mohamed |last3=Alhalabi |first3=Wadee |year=2016 |title=Discriminant Correlation Analysis: Real-Time Feature Level Fusion for Multimodal Biometric Recognition |url=https://zenodo.org/record/889881 |journal=IEEE Transactions on Information Forensics and Security |volume=11 |issue=9 |pages=1984–1996 |doi=10.1109/TIFS.2016.2569061|s2cid=15624506 }}&lt;/ref&gt;}}

{{term|[[data integration]]}}
{{defn|The process of combining [[data]] residing in different sources and providing users with a unified view of them.&lt;ref name="refone"&gt;{{Cite conference |last1=Lenzerini |first1=Maurizio |year=2002 |title=Data Integration: A Theoretical Perspective |url=http://www.dis.uniroma1.it/~lenzerin/homepagine/talks/TutorialPODS02.pdf |pages=233–246 |book-title=PODS 2002}}&lt;/ref&gt; This process becomes significant in a variety of situations, which include both commercial (such as when two similar companies need to merge their [[database]]s) and scientific (combining research results from different [[bioinformatics]] repositories, for example) domains. Data integration appears with increasing frequency as the volume (that is, [[big data]]) and the need to share existing data [[Information explosion|explodes]].&lt;ref name="DataExplode"&gt;{{Cite news |last1=Lane |first1=Frederick |url=http://www.toptechnews.com/story.xhtml?story_id=01300000E3D0&amp;full_skip=1 |title=IDC: World Created 161 Billion Gigs of Data in 2006 |year=2006}}&lt;/ref&gt; It has become the focus of extensive theoretical work, and numerous open problems remain unsolved.}}

{{term|[[data mining]]}}
{{defn|The process of discovering patterns in large data sets involving methods at the intersection of machine learning, statistics, and database systems.}}

{{term|[[data science]]}}
{{defn|An interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract [[knowledge]] and insights from [[data]] in various forms, both structured and unstructured,&lt;ref&gt;{{Cite journal |last1=Dhar |first1=V. |year=2013 |title=Data science and prediction |url=http://cacm.acm.org/magazines/2013/12/169933-data-science-and-prediction/fulltext |journal=Communications of the ACM |volume=56 |issue=12 |pages=64–73 |doi=10.1145/2500499|s2cid=6107147 }}&lt;/ref&gt;&lt;ref&gt;{{Cite web |url=http://simplystatistics.org/2013/12/12/the-key-word-in-data-science-is-not-data-it-is-science/ |title=The key word in 'Data Science' is not Data, it is Science |last1=Leek |first1=Jeff |author-link=Jeffrey T. Leek |date=2013-12-12 |publisher=Simply Statistics}}&lt;/ref&gt; similar to [[data mining]]. Data science is a "concept to unify statistics, data analysis, machine learning and their related methods" in order to "understand and analyze actual phenomena" with data.&lt;ref name="Hayashi"&gt;{{Cite book |last1=Hayashi |first1=Chikio |title=Data Science, Classification, and Related Methods |date=1998-01-01 |publisher=Springer Japan |isbn=9784431702085 |editor-last=Hayashi |editor-first=Chikio |series=Studies in Classification, Data Analysis, and Knowledge Organization |pages=40–51 |language=en |chapter=What is Data Science? Fundamental Concepts and a Heuristic Example |doi=10.1007/978-4-431-65950-1_3 |editor-last2=Yajima |editor-first2=Keiji |editor-last3=Bock |editor-first3=Hans-Hermann |editor-last4=Ohsumi |editor-first4=Noboru |editor-last5=Tanaka |editor-first5=Yutaka |editor-last6=Baba |editor-first6=Yasumasa |chapter-url=https://www.springer.com/book/9784431702085}}&lt;/ref&gt; It employs techniques and theories drawn from many fields within the context of [[mathematics]], [[statistics]], [[information science]], and [[computer science]].}}

{{term|[[data set]]}}
{{ghat|Also '''dataset'''.}}
{{defn|A collection of [[data]]. Most commonly a data set corresponds to the contents of a single [[table (database)|database table]], or a single statistical [[data matrix (multivariate statistics)|data matrix]], where every [[column (database)|column]] of the table represents a particular variable, and each [[row (database)|row]] corresponds to a given member of the data set in question. The data set lists values for each of the variables, such as height and weight of an object, for each member of the data set.  Each value is known as a datum. The data set may comprise data for one or more members, corresponding to the number of rows.}}

{{term|[[data warehouse]] (DW or DWH)}}
{{ghat|Also '''enterprise data warehouse''' ('''EDW''').}}
{{defn|A system used for [[Business reporting|reporting]] and [[data analysis]].&lt;ref&gt;{{Cite conference |last1=Dedić |first1=Nedim |last2=Stanier |first2=Clare |year=2016 |editor-last=Hammoudi |editor-first=Slimane |editor2-last=Maciaszek |editor2-first=Leszek |editor3-last=Missikoff |editor3-first=Michele M. Missikoff |editor4-last=Camp |editor4-first=Olivier |editor5-last=Cordeiro |editor5-first=José |title=An Evaluation of the Challenges of Multilingualism in Data Warehouse Development |url=http://eprints.staffs.ac.uk/2770/ |conference=International Conference on Enterprise Information Systems, 25–28 April 2016, Rome, Italy |publisher=SciTePress |volume=1 |pages=196–206 |doi=10.5220/0005858401960206 |isbn=978-989-758-187-8 |doi-access=free |conference-url=https://eprints.staffs.ac.uk/2770/1/ICEIS_2016_Volume_1.pdf |journal=Proceedings of the 18th International Conference on Enterprise Information Systems (ICEIS 2016)}}&lt;/ref&gt; DWs are central repositories of integrated data from one or more disparate sources. They store current and historical data in one single place&lt;ref name="rjmetrics"&gt;{{Cite web |url=https://blog.rjmetrics.com/2014/12/04/10-common-mistakes-when-building-a-data-warehouse/ |title=9 Reasons Data Warehouse Projects Fail |date=4 December 2014 |publisher=blog.rjmetrics.com |access-date=2017-04-30}}&lt;/ref&gt;}}

{{term|[[Datalog]]}}
{{defn|A [[Declarative programming|declarative]] {{gli|logic programming}} language that syntactically is a subset of {{gli|Prolog}}. It is often used as a [[query language]] for [[deductive database]]s. In recent years, Datalog has found new application in [[data integration]], [[information extraction]], [[Computer network|networking]], [[program analysis]], [[security]], and [[cloud computing]].&lt;ref&gt;{{Citation |last1=Huang |last2=Green |last3=Loo |title=SIGMOD 2011 |url=http://www.cs.ucdavis.edu/~green/papers/sigmod906t-huang.pdf |contribution=Datalog and Emerging applications |publisher=UC Davis}}.&lt;/ref&gt;}}

{{term|[[decision boundary]]}}
{{defn|In the case of {{gli|backpropagation}}-based {{gli|artificial neural network|artificial neural networks}} or [[perceptron]]s, the type of decision boundary that the network can learn is determined by the number of hidden layers the network has. If it has no hidden layers, then it can only learn linear problems. If it has one hidden layer, then it can learn any [[continuous function]] on [[Compact space|compact subsets]] of [[Euclidean space|R&lt;sup&gt;n&lt;/sup&gt;]] as shown by the [[Universal approximation theorem]], thus it can have an arbitrary decision boundary.}}

{{term|[[decision support system]] (DSS)}}
{{defn|Aan [[Information systems|information system]] that supports business or organizational [[decision-making]] activities. DSSs serve the management, operations and planning levels of an organization (usually mid and higher management) and help people make decisions about problems that may be rapidly changing and not easily specified in advance—i.e. unstructured and semi-structured decision problems. Decision support systems can be either fully computerized or human-powered, or a combination of both.}}

{{term|[[decision theory]]}}
{{ghat|Also '''theory of choice'''.}}
{{defn|The study of the reasoning underlying an [[agent (economics)|agent's]] choices.&lt;ref&gt;Steele, Katie and Stefánsson, H. Orri, "Decision Theory", The Stanford Encyclopedia of Philosophy (Winter 2015 Edition), Edward N. Zalta (ed.), URL = [http://plato.stanford.edu/archives/win2015/entries/decision-theory]&lt;/ref&gt; Decision theory can be broken into two branches: [[Norm (philosophy)|normative]] decision theory, which gives advice on how to make the [[optimal decision|best decisions]] given a set of uncertain beliefs and a set of [[Value (personal and cultural)|values]], and descriptive decision theory which analyzes how existing, possibly irrational agents actually make decisions.}}

{{term|[[decision tree learning]]}}
{{defn|Uses a [[decision tree]] (as a [[Predictive modelling|predictive model]]) to go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves). It is one of the predictive modeling approaches used in [[statistics]], [[data mining]] and {{gli|machine learning}}.}}

{{term|[[declarative programming]]}}
{{defn|A [[programming paradigm]]—a style of building the structure and elements of computer programs—that expresses the logic of a [[computation]] without describing its [[control flow]].&lt;ref&gt;{{Citation |last1=Lloyd |first1=J.W. |title=Practical Advantages of Declarative Programming}}&lt;/ref&gt;}}

{{term|[[deductive classifier]]}}
{{defn|A type of {{gli|artificial intelligence}} [[inference engine]]. It takes as input a set of declarations in a [[frame language]] about a domain such as medical research or molecular biology. For example, the names of [[Class hierarchy|classes, sub-classes]], properties, and restrictions on allowable values.}}

{{term|[[Deep Blue (chess computer)|Deep Blue]]}}
{{defn|was a [[Computer chess|chess-playing computer]] developed by [[IBM]]. It is known for being the first computer chess-playing system to win both a chess game and a chess match against a reigning world champion under regular time controls.}}

{{term|[[deep learning]]}}
{{ghat|Also '''deep structured learning''' or '''hierarchical learning'''.}}
{{defn|Part of a broader family of {{gli|machine learning}} methods based on [[learning representation|learning data representation]]s, as opposed to task-specific algorithms. Learning can be [[Supervised learning|supervised]], [[Semi-supervised learning|semi-supervised]], or [[Unsupervised learning|unsupervised]].&lt;ref name="pami"/&gt;&lt;ref&gt;{{Cite journal |last1=Schmidhuber |first1=J |year=2015 |title=Deep Learning in Neural Networks: An Overview |journal=Neural Networks |volume=61 |pages=85–117 |arxiv=1404.7828 |doi=10.1016/j.neunet.2014.09.003 |pmid=25462637|s2cid=11715509 }}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |last1=Bengio |first1=Yoshua |last2=LeCun |first2=Yann |last3=Hinton |first3=Geoffrey |year=2015 |title=Deep Learning |journal=Nature |volume=521 |issue=7553 |pages=436–444 |bibcode=2015Natur.521..436L |doi=10.1038/nature14539 |pmid=26017442|s2cid=3074096 }}&lt;/ref&gt;}}

{{term|[[DeepMind Technologies]]}}
{{defn|A [[United Kingdom|British]] {{gli|artificial intelligence}} company founded in September 2010, currently owned by [[Alphabet Inc.]] The company is based in [[London]], with research centres in [[Canada]],&lt;ref&gt;{{Cite web |url=https://deepmind.com/about/ |title=About Us {{!}} DeepMind |website=DeepMind}}&lt;/ref&gt; [[France]],&lt;ref&gt;{{Cite web |url=https://deepmind.com/blog/a-return-to-paris/ |title=A return to Paris {{!}} DeepMind |website=DeepMind}}&lt;/ref&gt; and the [[United States]]. [[List of mergers and acquisitions by Google|Acquired]] by [[Google]] in 2014, the company has created a [[neural network]] that learns how to play [[video games]] in a fashion similar to that of humans,&lt;ref name="arxiv medium"&gt;{{Cite web |url=https://medium.com/the-physics-arxiv-blog/the-last-ai-breakthrough-deepmind-made-before-google-bought-it-for-400m-7952031ee5e1 |title=The Last AI Breakthrough DeepMind Made Before Google Bought It |date=2014-01-29 |publisher=The Physics [[arXiv]] Blog |access-date=12 October 2014}}&lt;/ref&gt; as well as a [[neural Turing machine]],&lt;ref name="arxiv"&gt;{{Cite arXiv |eprint=1410.5401 |class=cs.NE |first1=Alex |last1=Graves |first2=Greg |last2=Wayne |author-link=Alex Graves (computer scientist) |title=Neural Turing Machines |last3=Danihelka |first3=Ivo |year=2014}}&lt;/ref&gt; or a neural network that may be able to access an external memory like a conventional [[Turing machine]], resulting in a computer that mimics the [[short-term memory]] of the human brain.&lt;ref&gt;[http://www.technologyreview.com/view/533741/best-of-2014-googles-secretive-deepmind-startup-unveils-a-neural-turing-machine/ Best of 2014: Google's Secretive DeepMind Startup Unveils a "Neural Turing Machine"], ''[[MIT Technology Review]]''&lt;/ref&gt;&lt;ref name="DNCnature2016"&gt;{{Cite journal |last1=Graves |first1=Alex |author-link=Alex Graves (computer scientist) |last2=Wayne |first2=Greg |last3=Reynolds |first3=Malcolm |last4=Harley |first4=Tim |last5=Danihelka |first5=Ivo |last6=Grabska-Barwińska |first6=Agnieszka |last7=Colmenarejo |first7=Sergio Gómez |last8=Grefenstette |first8=Edward |last9=Ramalho |first9=Tiago |date=12 October 2016 |title=Hybrid computing using a neural network with dynamic external memory |journal=Nature  |volume=538 |issue=7626 |pages=471–476 |bibcode=2016Natur.538..471G |doi=10.1038/nature20101 |issn=1476-4687 |pmid=27732574|s2cid=205251479 |url=https://ora.ox.ac.uk/objects/uuid:dd8473bd-2d70-424d-881b-86d9c9c66b51 }}&lt;/ref&gt; The company made headlines in 2016 after its [[AlphaGo]] program beat human professional [[Go (game)|Go]] player [[Lee Sedol]], the world champion, in [[AlphaGo versus Lee Sedol|a five-game match]], which was the subject of a documentary film.&lt;ref&gt;{{Citation |last1=Kohs |first1=Greg |title=AlphaGo |date=29 September 2017 |url=https://www.imdb.com/title/tt6700846/ |others=Ioannis Antonoglou, Lucas Baker, Nick Bostrom |access-date=9 January 2018}}&lt;/ref&gt; A more general program, [[AlphaZero]], beat the most powerful programs playing [[Go (game)|Go]], [[chess]], and [[shogi]] (Japanese chess) after a few days of play against itself using {{gli|reinforcement learning}}.&lt;ref&gt;{{Cite arXiv |eprint=1712.01815 |class=cs.AI |first1=David |last1=Silver |first2=Thomas |last2=Hubert |author-link=David Silver (programmer) |title=Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm |date=5 December 2017 |first3=Julian |last3=Schrittwieser |first4=Ioannis |last4=Antonoglou |first5=Matthew |last5=Lai |first6=Arthur |last6=Guez |first7=Marc |last7=Lanctot |first8=Laurent |last8=Sifre |first9=Dharshan |last9=Kumaran |first10=Thore |last10=Graepel |first11=Timothy |last11=Lillicrap |first12=Karen |last12=Simonyan |first13=Demis |last13=Hassabis |author-link13=Demis Hassabis}}&lt;/ref&gt;}}

{{term|[[default logic]]}}
{{defn|A [[non-monotonic logic]] proposed by [[Raymond Reiter]] to formalize reasoning with default assumptions.}}

{{term|[[description logic]] (DL)}}
{{defn|A family of formal [[knowledge representation]] languages. Many DLs are more expressive than [[propositional logic]] but less expressive than [[first-order logic]]. In contrast to the latter, the core reasoning problems for DLs are (usually) {{gli|decision problem|decidable}}, and efficient decision procedures have been designed and implemented for these problems. There are general, spatial, temporal, spatiotemporal, and fuzzy descriptions logics, and each description logic features a different balance between DL expressivity and {{gli|knowledge representation and reasoning|reasoning}} [[Complexity class|complexity]] by supporting different sets of mathematical constructors.&lt;ref&gt;{{Cite book |last1=Sikos |first1=Leslie F. |url=https://www.springer.com/us/book/9783319540658 |title=Description Logics in Multimedia Reasoning |date=2017 |publisher=Springer International Publishing |isbn=978-3-319-54066-5 |location=Cham |doi=10.1007/978-3-319-54066-5|s2cid=3180114 }}&lt;/ref&gt;}}

{{term|[[developmental robotics]] (DevRob)}}
{{ghat|Also '''epigenetic robotics'''.}}
{{defn|A scientific field which aims at studying the developmental mechanisms, architectures, and constraints that allow lifelong and open-ended learning of new skills and new knowledge in embodied [[machine]]s.}}

{{term|[[diagnosis (artificial intelligence)|diagnosis]]}}
{{defn|Concerned with the development of algorithms and techniques that are able to determine whether the behaviour of a system is correct. If the system is not functioning correctly, the algorithm should be able to determine, as accurately as possible, which part of the system is failing, and which kind of fault it is facing. The computation is based on ''observations'', which provide information on the current behaviour.}}

{{term|[[dialogue system]]}}
{{ghat|Also '''conversational agent''' ('''CA''').}}
{{defn|A computer system intended to converse with a human with a coherent structure. Dialogue systems have employed text, speech, graphics, haptics, gestures, and other modes for communication on both the input and output channel.}}

{{term|[[dimensionality reduction]]}}
{{ghat|Also '''dimension reduction'''.}} 
{{defn|The process of reducing the number of random variables under consideration&lt;ref&gt;{{Cite journal |last1=Roweis |first1=S. T. |last2=Saul |first2=L. K. |year=2000 |title=Nonlinear Dimensionality Reduction by Locally Linear Embedding |journal=Science |volume=290 |issue=5500 |pages=2323–2326 |bibcode=2000Sci...290.2323R |citeseerx=10.1.1.111.3313 |doi=10.1126/science.290.5500.2323 |pmid=11125150}}&lt;/ref&gt; by obtaining a set of principal variables. It can be divided into [[feature selection]] and [[feature extraction]].&lt;ref&gt;{{Cite book |last1=Pudil |first1=P. |title=Feature Extraction, Construction and Selection |url=https://archive.org/details/featureextractio00liuh |url-access=limited |last2=Novovičová |first2=J. |year=1998 |isbn=978-1-4613-7622-4 |editor-last=Liu |editor-first=Huan |pages=[https://archive.org/details/featureextractio00liuh/page/n120 101] |chapter=Novel Methods for Feature Subset Selection with Respect to Problem Knowledge |doi=10.1007/978-1-4615-5725-8_7 |editor-last2=Motoda |editor-first2=Hiroshi}}&lt;/ref&gt;}}

{{term|[[discrete system]]}}
{{defn|Any system with a countable number of states. Discrete systems may be contrasted with continuous systems, which may also be called analog systems. A final discrete system is often modeled with a directed [[Graph (discrete mathematics)|graph]] and is analyzed for correctness and complexity according to [[computational theory]]. Because discrete systems have a countable number of states, they may be described in precise [[mathematical models]]. A [[computer]] is a [[finite state machine]] that may be viewed as a discrete system. Because computers are often used to model not only other discrete systems but continuous systems as well, methods have been developed to represent real-world continuous systems as discrete systems. One such method involves sampling a continuous signal at [[discrete time]] intervals.}}

{{term|[[distributed artificial intelligence]] (DAI)}}
{{ghat|Also '''decentralized artificial intelligence'''.}}
{{defn|A subfield of {{gli|artificial intelligence}} research dedicated to the development of distributed solutions for problems. DAI is closely related to and a predecessor of the field of [[multi-agent system]]s.&lt;ref&gt;Demazeau, Yves, and J-P. Müller, eds. Decentralized Ai. Vol. 2. Elsevier, 1990.&lt;/ref&gt;}}

{{term|[[dynamic epistemic logic]] (DEL)}}
{{defn|A logical framework dealing with knowledge and information change. Typically, DEL focuses on situations involving multiple [[Intelligent agent|agents]] and studies how their knowledge changes when [[Event (philosophy)|events]] occur.}}

{{glossaryend}}

{{Compact ToC|side=yes|center=yes|top=yes|num=yes|extlinks=yes|seealso=yes|refs=yes|nobreak=yes|}}

==E==
{{glossary}}
{{term|[[eager learning]]}}
{{defn|A learning method in which the system tries to construct a general, input-independent target function during training of the system, as opposed to [[lazy learning]], where generalization beyond the training data is delayed until a query is made to the system.&lt;ref&gt;{{Cite conference |last1=Hendrickx |first1=Iris |last2=Van den Bosch, Antal |author-link2=Antal van den Bosch |date=October 2005 |title=Hybrid algorithms with Instance-Based Classification |url=https://books.google.com/books?id=GtcevX7n90wC&amp;pg=PA158 |publisher=Springer |pages=158–169 |isbn=9783540292432 |book-title=Machine Learning: ECML2005}}&lt;/ref&gt;}}

{{term|[[Ebert test]]}}
{{defn|A test which gauges whether a computer-based [[speech synthesis|synthesized voice]]&lt;ref name=twsL35/&gt;&lt;ref name="twsL34"&gt;{{Cite news |last1=Lee |first1=Jennifer |url=http://bits.blogs.nytimes.com/2011/03/07/roger-ebert-tests-his-vocal-cords-and-comedic-delivery/?src=me |title=Roger Ebert Tests His Vocal Cords, and Comedic Delivery |date=March 7, 2011 |work=The New York Times |access-date=2011-09-12 |quote=Now perhaps, there is the Ebert Test, a way to see if a synthesized voice can deliver humor with the timing to make an audience laugh.... He proposed the Ebert Test as a way to gauge the humanness of a synthesized voice.}}&lt;/ref&gt; can tell a [[humor|joke]] with sufficient skill to cause people to [[laughter|laugh]].&lt;ref name="twsL41"&gt;{{Cite news |url=http://www.tips-tricks.co.in/2011/03/roger-eberts-inspiring-digital.html |title=Roger Ebert's Inspiring Digital Transformation |date=March 5, 2011 |access-date=2011-09-12 |url-status=dead |archive-url=https://web.archive.org/web/20110325160035/http://www.tips-tricks.co.in/2011/03/roger-eberts-inspiring-digital.html |archive-date=25 March 2011 |publisher=Tech News |quote=Meanwhile, the technology that enables Ebert to "speak" continues to see improvements – for example, adding more realistic inflection for question marks and exclamation points. In a test of that, which Ebert called the "Ebert test" for computerized voices,}}&lt;/ref&gt; It was proposed by [[film critic]] [[Roger Ebert]] at the [[TED (conference)|2011 TED conference]] as a challenge to [[software developers]] to have a computerized voice master the inflections, delivery, timing, and intonations of a speaking human.&lt;ref name="twsL35"&gt;{{Cite news |last1=Ostrow |first1=Adam |url=http://mashable.com/2011/03/05/roger-ebert-ted-talk/ |title=Roger Ebert's Inspiring Digital Transformation |date=March 5, 2011 |access-date=2011-09-12 |publisher=Mashable Entertainment |quote=With the help of his wife, two colleagues and the Alex-equipped MacBook that he uses to generate his computerized voice, famed film critic Roger Ebert delivered the final talk at the TED conference on Friday in Long Beach, California....}}&lt;/ref&gt; The test is similar to the [[Turing test]] proposed by [[Alan Turing]] in 1950 as a way to gauge a computer's ability to exhibit intelligent behavior by generating performance indistinguishable from a [[human being]].&lt;ref name="twsL37"&gt;{{Cite news |last1=Pasternack |first1=Alex |url=http://www.motherboard.tv/2011/4/18/a-macbook-may-have-given-roger-ebert-his-voice-but-an-ipod-saved-his-life-video |title=A MacBook May Have Given Roger Ebert His Voice, But An iPod Saved His Life (Video) |date=Apr 18, 2011 |access-date=2011-09-12 |url-status=dead |archive-url=https://web.archive.org/web/20110906063605/http://motherboard.tv/2011/4/18/a-macbook-may-have-given-roger-ebert-his-voice-but-an-ipod-saved-his-life-video |archive-date=6 September 2011 |publisher=Motherboard |quote=He calls it the "Ebert Test," after Turing's AI standard...}}&lt;/ref&gt;}}

{{term|[[echo state network]] (ESN)}}
{{defn|A [[recurrent neural network]] with a sparsely connected hidden layer (with typically 1% connectivity). The connectivity and weights of hidden [[Artificial neuron|neurons]] are fixed and randomly assigned. The weights of output neurons can be learned so that the network can (re)produce specific temporal patterns. The main interest of this network is that although its behaviour is non-linear, the only weights that are modified during training are for the synapses that connect the hidden neurons to output neurons. Thus, the error function is quadratic with respect to the parameter vector and can be differentiated easily to a linear system.&lt;ref&gt;{{Cite journal |last1=Jaeger |first1=Herbert |last2=Haas |first2=Harald |year=2004 |title=Harnessing Nonlinearity: Predicting Chaotic Systems and Saving Energy in Wireless Communication |url=http://www.columbia.edu/cu/biology/courses/w4070/Reading_List_Yuste/haas_04.pdf |journal=Science |volume=304 |issue=5667 |pages=78–80 |doi=10.1126/science.1091277 |pmid=15064413 |bibcode=2004Sci...304...78J|s2cid=2184251 }}&lt;/ref&gt;&lt;ref&gt;Herbert Jaeger (2007) [http://www.scholarpedia.org/article/Echo_State_Network Echo State Network.] Scholarpedia.&lt;/ref&gt;}}

{{term|[[embodied agent]]}}
{{ghat|Also '''interface agent'''.}}
{{defn|An {{gli|intelligent agent}} that interacts with the environment through a physical body within that environment. Agents that are represented graphically with a body, for example a human or a cartoon animal, are also called embodied agents, although they have only virtual, not physical, embodiment.&lt;ref&gt;{{Cite journal |last1=Serenko |first1=Alexander |last2=Bontis |first2=Nick |last3=Detlor |first3=Brian |year=2007 |title=End-user adoption of animated interface agents in everyday work applications |url=http://www.aserenko.com/papers/Serenko_Bontis_Detlor_end_user_adoption_agent.pdf |journal=Behaviour and Information Technology |volume=26 |issue=2 |pages=119–132 |doi=10.1080/01449290500260538|s2cid=2175427 }}&lt;/ref&gt;}}

{{term|[[embodied cognitive science]]}}
{{defn|An interdisciplinary field of research, the aim of which is to explain the mechanisms underlying intelligent behavior. It comprises three main methodologies: 1) the modeling of psychological and biological systems in a holistic manner that considers the mind and body as a single entity, 2) the formation of a common set of general principles of intelligent behavior, and 3) the experimental use of robotic agents in controlled environments.}}

{{term|[[error-driven learning]]}}
{{defn|A sub-area of {{gli|machine learning}} concerned with how an {{gli|intelligent agent|agent}} ought to take actions in an [[Environment (systems)|environment]] so as to minimize some error feedback. It is a type of {{gli|reinforcement learning}}.}}

{{term|[[ensemble averaging (machine learning)|ensemble averaging]]}}
{{defn|In {{gli|machine learning}}, particularly in the creation of {{gli|artificial neural network|artificial neural networks}}, ensemble averaging is the process of creating multiple models and combining them to produce a desired output, as opposed to creating just one model.}}

{{term|[[ethics of artificial intelligence]]}}
{{defn|The part of the [[ethics of technology]] specific to artificial intelligence.}}

{{anchor|evolutionary algorithm}}{{term|[[evolutionary algorithm]] (EA)}}
{{defn|A subset of {{gli|evolutionary computation}},&lt;ref name="EVOALG"&gt;{{Cite journal |last1=Vikhar |first1=P. A. |year=2016 |title=Evolutionary algorithms: A critical review and its future prospects |journal=Proceedings of the 2016 International Conference on Global Trends in Signal Processing, Information Computing and Communication (ICGTSPICC) |publisher=Jalgaon, 2016, pp. 261-265 |pages=261–265 |doi=10.1109/ICGTSPICC.2016.7955308 |isbn=978-1-5090-0467-6|s2cid=22100336 }}&lt;/ref&gt; a generic population-based [[metaheuristic]] [[optimization (mathematics)|optimization]] {{gli|algorithm}}. An EA uses mechanisms inspired by [[biological evolution]], such as [[reproduction]], [[mutation]], [[genetic recombination|recombination]], and [[natural selection|selection]]. [[Candidate solution]]s to the [[optimization problem]] play the role of individuals in a population, and the [[fitness function]] determines the quality of the solutions (see also [[loss function]]). [[Evolution]] of the population then takes place after the repeated application of the above operators.}}

{{term|[[evolutionary computation]]}}
{{defn|A family of {{gli|algorithm|algorithms}} for [[global optimization]] inspired by [[biological evolution]], and the subfield of {{gli|artificial intelligence}} and [[soft computing]] studying these algorithms. In technical terms, they are a family of population-based [[trial and error]] problem solvers with a [[metaheuristic]] or [[stochastic optimization]] character.}}

{{term|[[evolving classification function]] (ECF)}}
{{defn|Evolving classifier functions or evolving [[classifier (mathematics)|classifier]]s are used for classifying and clustering in the field of {{gli|machine learning}} and {{gli|artificial intelligence}}, typically employed for [[data stream mining]] tasks in dynamic and changing environments.}}

{{term|[[existential risk from artificial general intelligence|existential risk]]}}
{{defn|The hypothesis that substantial progress in {{gli|artificial general intelligence}} (AGI) could someday result in [[human extinction]] or some other unrecoverable [[global catastrophic risk|global catastrophe]].&lt;ref name="aima"&gt;{{Cite book |last1=Russell |first1=Stuart |title=Artificial Intelligence: A Modern Approach |title-link=Artificial Intelligence: A Modern Approach |last2=Norvig |first2=Peter |date=2009 |publisher=Prentice Hall |isbn=978-0-13-604259-4 |chapter=26.3: The Ethics and Risks of Developing Artificial Intelligence |author-link=Stuart J. Russell |author-link2=Peter Norvig}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |last1=Bostrom |first1=Nick |author-link=Nick Bostrom |year=2002 |title=Existential risks |journal=[[Journal of Evolution and Technology]] |volume=9 |issue=1 |pages=1–31}}&lt;/ref&gt;&lt;ref&gt;{{Cite news |url=http://www.slate.com/articles/technology/future_tense/2016/04/killer_a_i_101_a_cheat_sheet_to_the_terminology_the_ethical_debates_the.html |title=Your Artificial Intelligence Cheat Sheet |date=1 April 2016 |work=[[Slate (magazine)|Slate]] |access-date=16 May 2016}}&lt;/ref&gt;}}

{{term|[[expert system]]}}
{{defn|A computer system that emulates the decision-making ability of a human expert.&lt;ref name="Jackson1998"&gt;{{Citation |last1=Jackson |first1=Peter |title=Introduction To Expert Systems |page=2 |year=1998 |edition=3 |publisher=Addison Wesley |isbn=978-0-201-87686-4}}&lt;/ref&gt; Expert systems are designed to solve complex problems by [[automated reasoning|reasoning]] through bodies of knowledge, represented mainly as [[Rule-based system|if–then rules]] rather than through conventional [[Procedural programming|procedural code]].&lt;ref&gt;{{Cite web |url=https://www.pcmag.com/encyclopedia_term/0,2542,t=conventional+programming&amp;i=40325,00.asp |title=Conventional programming |work=PC Magazine |access-date=2013-09-15}}&lt;/ref&gt;}}
{{glossaryend}}

==F==
{{glossary}}
{{term|[[fast-and-frugal trees]]}}
{{defn|A type of [[classification tree]]. Fast-and-frugal trees can be used as decision-making tools which operate as lexicographic classifiers, and, if required, associate an action (decision) to each class or category.&lt;ref name="naive"&gt;Martignon, Laura; Vitouch, Oliver; Takezawa, Masanori; Forster, Malcolm. [https://www.researchgate.net/publication/27278577_Naive_and_Yet_Enlightened_From_Natural_Frequencies_to_Fast_and_Frugal_Decision_Trees "Naive and Yet Enlightened: From Natural Frequencies to Fast and Frugal Decision Trees"], published in ''Thinking : Psychological perspectives on reasoning, judgement and decision making'' (David Hardman and Laura Macchi; editors), Chichester: John Wiley &amp; Sons, 2003.&lt;/ref&gt;}}

{{term|[[feature extraction]]}}
{{defn|In {{gli|machine learning}}, [[pattern recognition]], and [[image processing]], feature extraction starts from an initial set of measured data and builds derived values ([[Feature (machine learning)|features]]) intended to be informative and non-redundant, facilitating the subsequent learning and generalization steps, and in some cases leading to better human interpretations.}}

{{term|[[feature learning]]}}
{{defn|In {{gli|machine learning}}, feature learning or representation learning&lt;ref name="pami"&gt;{{Cite journal |last1=Bengio |first1=Y. |last2=Courville |first2=A. |last3=Vincent |first3=P. |year=2013 |title=Representation Learning: A Review and New Perspectives |journal=IEEE Transactions on Pattern Analysis and Machine Intelligence |volume=35 |issue=8 |pages=1798–1828 |arxiv=1206.5538 |doi=10.1109/tpami.2013.50 |pmid=23787338|s2cid=393948 }}&lt;/ref&gt; is a set of techniques that allows a system to automatically discover the representations needed for feature detection or classification from raw data. This replaces manual [[feature engineering]] and allows a machine to both learn the features and use them to perform a specific task.}}

{{term|[[feature selection]]}}
{{defn|In {{gli|machine learning}} and [[statistics]], feature selection, also known as variable selection, attribute selection or variable subset selection, is the process of selecting a subset of relevant [[Feature (machine learning)|features]] (variables, predictors) for use in model construction.}}

{{term|[[federated learning]]}}
{{defn|A type of machine learning that allows for training on multiple devices with decentralized data, thus helping preserve the privacy of individual users and their data.}}

{{term|[[first-order logic]]}}
{{ghat|Also known as '''first-order predicate calculus''' and '''predicate logic'''.}}
{{defn|A collection of [[formal system]]s used in [[mathematics]], [[philosophy]], [[linguistics]], and [[computer science]]. First-order logic uses [[Quantification (logic)|quantified variables]] over non-logical objects and allows the use of sentences that contain variables, so that rather than propositions such as ''Socrates is a man'' one can have expressions in the form "there exists X such that X is [[Socrates]] and X is a man" and ''there exists'' is a quantifier while ''X'' is a variable.&lt;ref name="auto"&gt;Hodgson, Dr. J. P. E., [http://people.sju.edu/~jhodgson/ugai/1order.html "First Order Logic"], [[Saint Joseph's University]], [[Philadelphia]], 1995.&lt;/ref&gt; This distinguishes it from [[propositional logic]], which does not use quantifiers or relations.&lt;ref&gt;[[George Edward Hughes|Hughes, G. E.]], &amp; [[Max Cresswell|Cresswell, M. J.]], ''A New Introduction to Modal Logic'' ([[London]]: [[Routledge]], 1996), [https://books.google.cz/books?id=_CB5wiBeaA4C&amp;pg=PA161#v=onepage&amp;q&amp;f=false p.161].&lt;/ref&gt;}}

{{term|[[fluent (artificial intelligence)|fluent]]}}
{{defn|A condition that can change over time. In logical approaches to reasoning about actions, fluents can be represented in [[first-order logic]] by [[Predicate (logic)|predicate]]s having an argument that depends on time.}}

{{term|[[formal language]]}}
{{defn|A set of [[String (computer science)|words]] whose [[Symbol (formal)|letters]] are taken from an [[Alphabet (computer science)|alphabet]] and are [[Well-formedness|well-formed]] according to a specific set of rules.}}

{{term|[[forward chaining]]}}
{{ghat|Also '''forward reasoning'''.}} 
{{defn|One of the two main methods of reasoning when using an [[inference engine]] and can be described [[logically]] as repeated application of ''[[modus ponens]]''. Forward chaining is a popular implementation strategy for [[expert system]]s, [[business rules engine|business]] and [[Production system (computer science)|production rule systems]]. The opposite of forward chaining is {{gli|backward chaining}}.  Forward chaining starts with the available [[data]] and uses inference rules to extract more data (from an end user, for example) until a [[goal]] is reached. An [[inference engine]] using forward chaining searches the inference rules until it finds one where the [[antecedent (logic)|antecedent]] (If clause) is known to be true. When such a rule is found, the engine can conclude, or infer, the [[consequent]] (Then clause), resulting in the addition of new [[information]] to its data.&lt;ref&gt;{{Cite book |last1=Feigenbaum |first1=Edward |url=https://archive.org/details/riseofexpertco00feig |title=The Rise of the Expert Company |publisher=Times Books |year=1988 |isbn=978-0-8129-1731-4 |page=[https://archive.org/details/riseofexpertco00feig/page/318 318] |url-access=registration}}&lt;/ref&gt;}}

{{term|[[frame (artificial intelligence)|frame]]}}
{{defn|An artificial intelligence [[data structure]] used to divide [[knowledge]] into substructures by representing "[[stereotype]]d situations". Frames are the primary data structure used in artificial intelligence {{gli|frame language}}.}}

{{term|[[frame language]]}}
{{defn|A technology used for [[knowledge representation]] in artificial intelligence. Frames are stored as [[Ontology (information science)|ontologies]] of [[Set theory|sets]] and subsets of the [[Frame (artificial intelligence)|frame concepts]]. They are similar to class hierarchies in [[object-oriented languages]] although their fundamental design goals are different. Frames are focused on explicit and intuitive representation of knowledge whereas objects focus on [[Encapsulation (object-oriented programming)|encapsulation]] and [[information hiding]]. Frames originated in AI research and objects primarily in [[software engineering]]. However, in practice the techniques and capabilities of frame and object-oriented languages overlap significantly.}}

{{term|[[frame problem]]}}
{{defn|The problem of finding adequate collections of axioms for a viable description of a robot environment.&lt;ref&gt;{{Cite journal |last1=Hayes |first1=Patrick |title=The Frame Problem and Related Problems in Artificial Intelligence |url=http://aitopics.org/sites/default/files/classic/Webber-Nilsson-Readings/Rdgs-NW-Hayes-FrameProblem.pdf |publisher=University of Edinburgh}}&lt;/ref&gt;}}

{{term|[[friendly artificial intelligence]]}}
{{ghat|Also '''friendly AI''' or '''FAI'''.}}
{{defn|A hypothetical {{gli|artificial general intelligence}} (AGI) that would have a positive effect on humanity. It is a part of the [[ethics of artificial intelligence]] and is closely related to [[machine ethics]]. While machine ethics is concerned with how an artificially intelligent agent should behave, friendly artificial intelligence research is focused on how to practically bring about this behaviour and ensuring it is adequately constrained.}}

{{term|[[futures studies]]}}
{{defn|The study of postulating possible, probable, and preferable [[future]]s and the worldviews and myths that underlie them.&lt;ref name="Sardar, Z. 2010 pp. 177"&gt;{{Cite journal |last1=Sardar |first1=Z |year=2010 |title=The Namesake: Futures; futures studies; futurology; futuristic; Foresight -- What's in a name? |journal=Futures |volume=42 |issue=3 |pages=177–184 |doi=10.1016/j.futures.2009.11.001}}&lt;/ref&gt;}}

{{term|[[fuzzy control system]]}}
{{defn|A [[control system]] based on {{gli|fuzzy logic}}—a [[mathematics|mathematical]] system that analyzes [[analog signal|analog]] input values in terms of [[mathematical logic|logic]]al variables that take on continuous values between 0 and 1, in contrast to classical or [[Digital data|digital]] logic, which operates on discrete values of either 1 or 0 (true or false, respectively).&lt;ref name="Pedrycz"&gt;{{Cite book |last1=Pedrycz |first1=Witold |title=Fuzzy control and fuzzy systems |publisher=Research Studies Press Ltd. |year=1993 |edition=2}}&lt;/ref&gt;&lt;ref name="Hájek"&gt;{{Cite book |last1=Hájek |first1=Petr |title=Metamathematics of fuzzy logic |publisher=Springer Science &amp; Business Media |year=1998 |edition=4}}&lt;/ref&gt;}}

{{term|[[fuzzy logic]]}}
{{defn|A simple form for the [[many-valued logic]], in which the [[truth value]]s of variables may have any degree of "''Truthfulness''" that can be represented by any real number in the range between 0 (as in Completely False) and 1 (as in Completely True) inclusive. Consequently, It is employed to handle the concept of partial truth, where the truth value may range between completely true and completely false. In contrast to [[Boolean algebra|Boolean logic]], where the truth values of variables may have the integer values 0 or 1 only.}}

{{term|[[fuzzy rule]]}}
{{defn|A rule used within {{gli|fuzzy logic|fuzzy logic systems}} to infer an output based on input variables.}}

{{term|[[fuzzy set]]}}
{{defn|In classical [[set theory]], the membership of elements in a set is assessed in binary terms according to a [[Principle of bivalence|bivalent condition]] &amp;mdash; an element either belongs or does not belong to the set. By contrast, fuzzy set theory permits the gradual assessment of the membership of elements in a set; this is described with the aid of a [[Membership function (mathematics)|membership function]] valued in the real unit interval [0,&amp;nbsp;1]. Fuzzy sets generalize classical sets, since the [[indicator function]]s (aka ''characteristic functions'') of classical sets are special cases of the membership functions of fuzzy sets, if the latter only take values 0 or 1.&lt;ref name=":0"&gt;D. Dubois and H. Prade (1988) Fuzzy Sets and Systems. Academic Press, New York.&lt;/ref&gt; In fuzzy set theory, classical bivalent sets are usually called [[Crisp set|''crisp'' sets]]. The fuzzy set theory can be used in a wide range of domains in which information is incomplete or imprecise, such as [[bioinformatics]].&lt;ref&gt;{{Cite journal |last1=Liang |first1=Lily R. |last2=Lu |first2=Shiyong |last3=Wang |first3=Xuena |last4=Lu |first4=Yi |last5=Mandal |first5=Vinay |last6=Patacsil |first6=Dorrelyn |last7=Kumar |first7=Deepak |year=2006 |title=FM-test: A fuzzy-set-theory-based approach to differential gene expression data analysis |journal=BMC Bioinformatics |volume=7 |pages=S7 |doi=10.1186/1471-2105-7-S4-S7 |pmc=1780132 |pmid=17217525}}&lt;/ref&gt;}}
{{glossaryend}}

{{Compact ToC|side=yes|center=yes|top=yes|num=yes|extlinks=yes|seealso=yes|refs=yes|nobreak=yes|}}

==G==
{{glossary}}
{{term|[[game theory]]}}
{{defn|The study of [[mathematical model]]s of strategic interaction between rational decision-makers.&lt;ref name="Myerson"&gt;[[Roger B. Myerson|Myerson, Roger B.]] (1991). ''Game Theory: Analysis of Conflict,'' Harvard University Press, p.&amp;nbsp;[https://books.google.com/books?id=E8WQFRCsNr0C&amp;printsec=find&amp;pg=PA1 1]. Chapter-preview links, pp. [https://books.google.com/books?id=E8WQFRCsNr0C&amp;printsec=find&amp;pg=PR7 vii–xi].&lt;/ref&gt;}}

{{term|[[general game playing]] (GGP)}}
{{defn|General game playing is the design of artificial intelligence programs to be able to run and play more than one game successfully.&lt;ref&gt;{{cite journal |last1=Pell |first1=Barney |editor1=H. van den Herik | editor2=L. Allis|title=Metagame: a new challenge for games and learning. |date=1992 |url=https://svn.sable.mcgill.ca/sable/courses/COMP763/oldpapers/pell-92-metagame.pdf |trans-title=Heuristic programming in artificial intelligence 3–the third computerolympiad |location=Ellis-Horwood}}&lt;/ref&gt;&lt;ref name="pellfirst"&gt;{{cite journal |last1=Pell |first1=Barney |title=A Strategic Metagame Player for General Chess-Like Games |journal=Computational Intelligence |date=1996 |volume=12 |issue=1 |pages=177–198 |doi=10.1111/j.1467-8640.1996.tb00258.x |s2cid=996006 |language=en |issn=1467-8640}}&lt;/ref&gt;&lt;ref name="ggppell"&gt;{{cite journal |last1=Genesereth |first1=Michael |last2=Love |first2=Nathaniel |last3=Pell |first3=Barney |title=General Game Playing: Overview of the AAAI Competition |journal=AI Magazine |date=15 June 2005 |volume=26 |issue=2 |pages=62 |doi=10.1609/aimag.v26i2.1813 |language=en |issn=2371-9621}}&lt;/ref&gt;}}

{{term|[[generative adversarial network]] (GAN)}}
{{defn|A class of {{gli|machine learning}} systems. Two [[neural network]]s contest with each other in a [[zero-sum game]] framework.}}

{{anchor|genetic algorithm}}{{term|[[genetic algorithm]] (GA)}}
{{defn|A [[metaheuristic]] inspired by the process of [[natural selection]] that belongs to the larger class of [[evolutionary algorithm]]s (EA). Genetic algorithms are commonly used to generate high-quality solutions to [[Optimization (mathematics)|optimization]] and [[Search algorithm|search problem]]s by relying on bio-inspired operators such as [[Mutation (genetic algorithm)|mutation]], [[crossover (genetic algorithm)|crossover]] and [[selection (genetic algorithm)|selection]].{{sfn|Mitchell|1996|p=2}}}}

{{term|[[genetic operator]]}}
{{defn|An [[Operator (programming)|operator]] used in [[genetic algorithms]] to guide the algorithm towards a solution to a given problem. There are three main types of operators ([[Mutation (genetic algorithm)|mutation]], [[Crossover (genetic algorithm)|crossover]] and [[selection (genetic algorithm)|selection]]), which must work in conjunction with one another in order for the algorithm to be successful.}}

{{term|[[glowworm swarm optimization]]}}
{{defn|A {{gli|swarm intelligence}} [[Mathematical optimization|optimization]] {{gli|algorithm}} based on the behaviour of [[glowworm]]s (also known as fireflies or lightning bugs).}}

{{term|[[graph (abstract data type)]]}}
{{defn|In [[computer science]], a graph is an [[abstract data type]] that is meant to implement the [[Graph (discrete mathematics)|undirected graph]] and [[directed graph]] concepts from [[mathematics]]; specifically, the field of {{gli|graph theory}}.}}

{{term|[[graph (discrete mathematics)]]}}
{{defn|In mathematics, and more specifically in {{gli|graph theory}}, a graph is a structure amounting to a set of objects in which some pairs of the objects are in some sense "related". The objects correspond to mathematical abstractions called ''[[Vertex (graph theory)|vertices]]'' (also called ''nodes'' or ''points'') and each of the related pairs of vertices is called an ''edge'' (also called an ''arc'' or ''line'').&lt;ref&gt;{{Cite book |last1=Trudeau |first1=Richard J. |url=http://store.doverpublications.com/0486678709.html |title=Introduction to Graph Theory |publisher=Dover Pub. |year=1993 |isbn=978-0-486-67870-2 |edition=Corrected, enlarged republication. |location=New York |pages=19 |quote=A graph is an object consisting of two sets called its ''vertex set'' and its ''edge set''. |access-date=8 August 2012}}&lt;/ref&gt;}}

{{term|[[graph database]] (GDB)}}
{{defn|A [[database]] that uses [[Graph (data structure)|graph structures]] for [[Semantic query|semantic queries]] with [[Node (graph theory)|node]]s, [[Edge (graph theory)|edge]]s, and properties to represent and store data. A key concept of the system is the ''graph'' (or ''edge'' or ''relationship''), which directly relates data items in the store a collection of nodes of data and edges representing the relationships between the nodes. The relationships allow data in the store to be linked together directly, and in many cases retrieved with one operation. Graph databases hold the relationships between data as a priority. Querying relationships within a graph database is fast because they are perpetually stored within the database itself. Relationships can be intuitively visualized using graph databases, making it useful for heavily inter-connected data.&lt;ref&gt;{{Cite journal |last1=Yoon |first1=Byoung-Ha |last2=Kim |first2=Seon-Kyu |last3=Kim |first3=Seon-Young |date=March 2017 |title=Use of Graph Database for the Integration of Heterogeneous Biological Data |journal=Genomics &amp; Informatics |volume=15 |issue=1 |pages=19–27 |doi=10.5808/GI.2017.15.1.19 |issn=1598-866X |pmc=5389944 |pmid=28416946}}&lt;/ref&gt;&lt;ref&gt;{{Cite book |last1=Bourbakis |first1=Nikolaos G. |url=https://books.google.com/books?id=mV3wxKLHlnwC&amp;q=%22gdb%22+%22graph+database%22&amp;pg=PA381 |title=Artificial Intelligence and Automation |publisher=World Scientific |year=1998 |isbn=9789810226374 |page=381 |access-date=2018-04-20}}&lt;/ref&gt;}}

{{term|[[graph theory]]}}
{{defn|The study of ''[[graph (discrete mathematics)|graph]]s'', which are mathematical structures used to model pairwise relations between objects.}}

{{term|[[graph traversal]]}}
{{ghat|Also '''graph search'''.}}
{{defn|The process of visiting (checking and/or updating) each vertex in a [[Graph (discrete mathematics)|graph]]. Such traversals are classified by the order in which the vertices are visited. [[Tree traversal]] is a special case of graph traversal.}}
{{glossaryend}}

==H==
{{glossary}}
{{term|[[halting problem]]}}
{{defn|}}

{{term|[[heuristic (computer science)|heuristic]]}}
{{defn|A technique designed for [[problem solving|solving a problem]] more quickly when classic methods are too slow, or for finding an approximate solution when classic methods fail to find any exact solution.  This is achieved by trading optimality, completeness, [[Accuracy and precision|accuracy]], or [[Accuracy and precision|precision]] for speed.  In a way, it can be considered a shortcut.  A heuristic function, also called simply a heuristic, is a [[Function (mathematics)|function]] that ranks alternatives in {{gli|search algorithm|search algorithms}} at each branching step based on available information to decide which branch to follow. For example, it may approximate the exact solution.&lt;ref&gt;{{Cite book |last1=Pearl |first1=Judea |title=Heuristics: intelligent search strategies for computer problem solving |url=https://archive.org/details/intelligentsearc00jude |url-access=limited |publisher=Addison-Wesley Pub. Co., Inc., Reading, MA |year=1984 |location=United States |page=[https://archive.org/details/intelligentsearc00jude/page/n21 3] |bibcode=1985hiss.book.....P |osti=5127296}}&lt;/ref&gt;}}

{{anchor|hidden layer}}{{term|hidden layer}}
{{defn|An internal layer of neurons in an {{gli|artificial neural network}}, not dedicated to input or output.}}

{{anchor|hidden unit}}{{term|hidden unit}}
{{defn|A neuron in a hidden layer in an {{gli|artificial neural network}}.}}

{{term|[[hyper-heuristic]]}}
{{defn|A {{gli|heuristic}} search method that seeks to automate the process of selecting, combining, generating, or adapting several simpler heuristics (or components of such heuristics) to efficiently solve computational search problems, often by the incorporation of {{gli|machine learning}} techniques. One of the motivations for studying hyper-heuristics is to build systems which can handle classes of problems rather than solving just one problem.&lt;ref&gt;E. K. Burke, E. Hart, [[Graham Kendall|G. Kendall]], J. Newall, P. Ross, and S. Schulenburg, Hyper-heuristics: An emerging direction in modern search technology, Handbook of Metaheuristics (F. Glover and G. Kochenberger, eds.), Kluwer, 2003, pp. 457–474.&lt;/ref&gt;&lt;ref name="Ross05"&gt;P. Ross, Hyper-heuristics, Search Methodologies: Introductory Tutorials in Optimization and Decision Support Techniques (E. K. Burke and [[Graham Kendall|G. Kendall]], eds.), Springer, 2005, pp. 529-556.&lt;/ref&gt;&lt;ref name="Ozcan08"&gt;{{Cite journal |last1=Ozcan |first1=E. |last2=Bilgin |first2=B. |last3=Korkmaz |first3=E. E. |year=2008 |title=A Comprehensive Analysis of Hyper-heuristics |journal=Intelligent Data Analysis |volume=12 |issue=1 |pages=3–23 |doi=10.3233/ida-2008-12102}}&lt;/ref&gt;}}
{{glossaryend}}

==I==
{{glossary}}
{{term|[[IEEE Computational Intelligence Society]]}}
{{defn|A [[professional society]] of the [[Institute of Electrical and Electronics Engineers]] (IEEE) focussing on "the theory, design, application, and development of biologically and linguistically motivated computational paradigms emphasizing [[neural networks]], connectionist systems, [[genetic algorithms]], [[evolutionary programming]], fuzzy systems, and hybrid intelligent systems in which these paradigms are contained".&lt;ref name="IEEE CIS Scope"&gt;{{Cite web |url=http://cis.ieee.org/scope.html |title=IEEE CIS Scope |url-status=dead |archive-url=https://web.archive.org/web/20160604143046/http://cis.ieee.org/scope.html |archive-date=4 June 2016 |access-date=18 March 2019}}&lt;/ref&gt;}}

{{term|[[incremental learning]]}}
{{defn|A method of {{gli|machine learning}}, in which input data is continuously used to extend the existing model's knowledge i.e. to further train the model. It represents a dynamic technique of [[supervised learning]] and [[unsupervised learning]] that can be applied when training data becomes available gradually over time or its size is out of system memory limits. Algorithms that can facilitate incremental learning are known as incremental machine learning algorithms.}}

{{term|[[inference engine]]}}
{{defn|A component of the system that applies logical rules to the knowledge base to deduce new information.}}

{{term|[[information integration]] (II)}}
{{defn|The merging of information from heterogeneous sources with differing conceptual, contextual and typographical representations. It is used in [[data mining]] and consolidation of data from unstructured or semi-structured resources. Typically, ''information integration'' refers to textual representations of knowledge but is sometimes applied to [[rich-media]] content. Information fusion, which is a related term, involves the combination of information into a new set of information towards reducing redundancy and uncertainty.&lt;ref name="dca" /&gt;}}

{{term|[[Information Processing Language]] (IPL)}}
{{defn|A [[programming language]] that includes features intended to help with programs that perform simple problem solving actions such as lists, [[dynamic memory allocation]], [[data type]]s, [[Recursion (computer science)|recursion]], [[Subroutine|functions]] as arguments, generators, and [[cooperative multitasking]].  IPL invented the concept of list processing, albeit in an [[Assembly language|assembly-language]] style.}}

{{term|[[intelligence amplification]] (IA)}}
{{ghat|Also '''cognitive augmentation''', '''machine augmented intelligence''', and '''enhanced intelligence'''.}}
{{defn|The effective use of [[information technology]] in augmenting [[Intelligence#Human intelligence|human intelligence]].}}

{{term|[[intelligence explosion]]}}
{{defn|A possible outcome of humanity building {{gli|artificial general intelligence}} (AGI). AGI would be capable of recursive self-improvement leading to rapid emergence of ASI ([[Superintelligence|artificial superintelligence]]), the limits of which are unknown, at the time of the technological singularity.}}

{{anchor|intelligent agent}}{{term|[[intelligent agent]] (IA)}}
{{defn|An [[autonomous]] entity which acts, directing its activity towards achieving goals (i.e. it is an [[Software agent|agent]]), upon an [[Environment (biophysical)|environment]] using observation through sensors and consequent actuators (i.e. it is intelligent). Intelligent agents may also [[machine learning|learn]] or use [[knowledge representation|knowledge]] to achieve their goals. They may be very simple or [[Complexity|very complex]].}}

{{term|[[intelligent control]]}}
{{defn|A class of [[Control theory|control]] techniques that use various {{gli|artificial intelligence}} computing approaches like [[artificial neural networks|neural networks]], [[Bayesian probability]], {{gli|fuzzy logic}}, {{gli|machine learning}}, {{gli|reinforcement learning}}, [[evolutionary computation]] and [[genetic algorithm]]s.&lt;ref&gt;{{Cite web |url=https://engineering.purdue.edu/ManLab/control/intell_control.htm |title=Control of Machining Processes - Purdue ME Manufacturing Laboratories |website=engineering.purdue.edu}}&lt;/ref&gt;}}

{{term|[[intelligent personal assistant]]}}
{{ghat|Also '''virtual assistant''' or '''personal digital assistant'''.}}
{{defn|A [[software agent]] that can perform tasks or services for an individual based on verbal commands. Sometimes the term "[[chatbot]]" is used to refer to virtual assistants generally or specifically accessed by [[online chat]] (or in some cases online chat programs that are exclusively for entertainment purposes).  Some virtual assistants are able to interpret human speech and respond via synthesized voices. Users can ask their assistants questions, control [[home automation]] devices and media playback via voice, and manage other basic tasks such as email, to-do lists, and calendars with verbal commands.&lt;ref&gt;{{Cite journal |last1=Hoy |first1=Matthew B. |year=2018 |title=Alexa, Siri, Cortana, and More: An Introduction to Voice Assistants |journal=Medical Reference Services Quarterly |volume=37 |issue=1 |pages=81–88 |doi=10.1080/02763869.2018.1404391 |pmid=29327988|s2cid=30809087 }}&lt;/ref&gt;}}

{{term|[[interpretation (logic)|interpretation]]}}
{{defn|An assignment of meaning to the [[symbol (formal)|symbols]] of a {{gli|formal language}}. Many formal languages used in [[mathematics]], [[logic]], and [[theoretical computer science]] are defined in solely [[syntax|syntactic]] terms, and as such do not have any meaning until they are given some interpretation. The general study of interpretations of formal languages is called [[formal semantics (logic)|formal semantics]].}}

{{term|[[intrinsic motivation (artificial intelligence)|intrinsic motivation]]}}
{{defn|An [[intelligent agent]] is intrinsically motivated to act if the information content alone, of the experience resulting from the action, is the motivating factor. Information content in this context is measured in the [[information-theoretic|information theory]] sense as quantifying uncertainty. A typical intrinsic motivation is to search for unusual (surprising) situations, in contrast to a typical extrinsic motivation such as the search for food. Intrinsically motivated artificial agents display behaviours akin to [[exploration]] and [[curiosity]].&lt;ref&gt;{{Cite book |last1=Oudeyer |first1=Pierre-Yves |title=Proc. of the 8th Conf. on Epigenetic Robotics |last2=Kaplan |first2=Frederic |date=2008 |volume=5 |pages=29–31 |chapter=How can we define intrinsic motivation?}}&lt;/ref&gt;}}

{{term|[[issue tree]]}}
{{ghat|Also '''logic tree'''.}}
{{defn|A graphical breakdown of a question that dissects it into its different components vertically and that progresses into details as it reads to the right.&lt;ref&gt;{{Cite document |last1=Chevallier |first1=Arnaud |s2cid=157255130 |title=Strategic thinking in complex problem solving |date=2016 |publisher=[[Oxford University Press]] |isbn=9780190463908 |location=Oxford; New York |doi=10.1093/acprof:oso/9780190463908.001.0001 |oclc=940455195}}&lt;/ref&gt;{{rp|47}}  Issue trees are useful in [[problem solving]] to identify the root causes of a problem as well as to identify its potential solutions. They also provide a reference point to see how each piece fits into the whole picture of a problem.&lt;ref&gt;{{Cite web |url=http://interactive.cabinetoffice.gov.uk/strategy/survivalguide/skills/s_issue.htm |title=Strategy survival guide: Issue trees |date=July 2004 |publisher=Government of the United Kingdom |location=London |archive-url=https://web.archive.org/web/20120217163843/http://interactive.cabinetoffice.gov.uk/strategy/survivalguide/skills/s_issue.htm |archive-date=2012-02-17 |access-date=2018-10-06 }} Also available in [http://webarchive.nationalarchives.gov.uk/20060213205515/http://strategy.gov.uk/downloads/survivalguide/downloads/ssg_v2.1.pdf PDF format].&lt;/ref&gt;}}
{{glossaryend}}

{{Compact ToC|side=yes|center=yes|top=yes|num=yes|extlinks=yes|seealso=yes|refs=yes|nobreak=yes|}}

==J==
{{glossary}}
{{term|[[junction tree algorithm]]}}
{{ghat|Also '''Clique Tree'''.}}
{{defn|A method used in {{gli|machine learning}} to extract [[marginal distribution|marginalization]] in general [[Graph (discrete mathematics)|graph]]s. In essence, it entails performing [[belief propagation]] on a modified graph called a [[junction tree]]. The graph is called a tree because it branches into different sections of data; [[Vertex (graph theory)|nodes]] of variables are the branches.&lt;ref name=":1"&gt;{{Cite web |url=https://ai.stanford.edu/~paskin/gm-short-course/lec3.pdf |title=A Short Course on Graphical Models |last1=Paskin |first1=Mark |website=Stanford}}&lt;/ref&gt;}}
{{glossaryend}}

==K==
{{glossary}}
{{term|[[kernel method]]}}
{{defn|In {{gli|machine learning}}, kernel methods are a class of algorithms for [[pattern analysis]], whose best known member is the [[support vector machine]] (SVM). The general task of pattern analysis is to find and study general types of relations (for example [[Cluster analysis|clusters]], [[ranking]]s, [[principal components]], [[correlation]]s, [[Statistical classification|classifications]]) in datasets.}}

{{term|[[KL-ONE]]}}
{{defn|A well-known [[knowledge representation]] system in the tradition of [[semantic networks]] and [[Frame (Artificial intelligence)|frames]]; that is, it is a [[frame language]]. The system is an attempt to overcome semantic indistinctness in semantic network representations and to explicitly represent conceptual information as a structured inheritance network.&lt;ref&gt;{{Cite journal |last1=Woods |first1=W. A. |last2=Schmolze |first2=J. G. |year=1992 |title=The KL-ONE family |journal=Computers &amp; Mathematics with Applications |volume=23 |issue=2–5 |pages=133 |doi=10.1016/0898-1221(92)90139-9 |author-link1=William Aaron Woods}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |last1=Brachman |first1=R. J. |last2=Schmolze |first2=J. G. |year=1985 |title=An Overview of the KL-ONE Knowledge Representation System |url=http://dli.iiit.ac.in/vdata/IJCAI/IJCAI-83-VOL-1/PDF/072.pdf |journal=Cognitive Science |volume=9 |issue=2 |pages=171 |doi=10.1207/s15516709cog0902_1 |author-link1=Ronald J. Brachman}}&lt;/ref&gt;&lt;ref&gt;{{Cite book |last1=Duce |first1=D.A. |last2=Ringland |first2=G.A. |url=https://archive.org/details/approachestoknow0000unse |title=Approaches to Knowledge Representation, An Introduction |publisher=Research Studies Press, Ltd. |year=1988 |isbn=978-0-86380-064-1 |url-access=registration}}&lt;/ref&gt;}}

{{term|[[knowledge acquisition]]}}
{{defn|The process used to define the rules and ontologies required for a [[knowledge-based system]]. The phrase was first used in conjunction with [[expert systems]] to describe the initial tasks associated with developing an expert system, namely finding and interviewing [[knowledge domain|domain]] experts and capturing their knowledge via [[Rule-based system|rules]], [[Object-oriented programming|objects]], and [[Frame language|frame-based]] [[Ontologies (computer science)|ontologies]].}}

{{anchor|knowledge-based system}}{{term|[[knowledge-based system]] (KBS)}}
{{defn|A [[computer program]] that [[automated reasoning|reasons]] and uses a [[knowledge base]] to [[problem solving|solve]] [[complex systems|complex problems]]. The term is broad and refers to many different kinds of systems. The one common theme that unites all knowledge based systems is an attempt to represent knowledge explicitly and a [[reasoning system]] that allows it to derive new knowledge. Thus, a knowledge-based system has two distinguishing features: a [[knowledge base]] and an [[inference engine]].}}

{{term|[[knowledge engineering]] (KE)}}
{{defn|All technical, scientific, and social aspects involved in building, maintaining, and using {{gli|knowledge-based system|knowledge-based systems}}.}}

{{term|[[knowledge extraction]]}}
{{defn|The creation of [[Knowledge representation and reasoning|knowledge]] from structured ([[relational databases]], [[XML]]) and unstructured ([[text (literary theory)|text]], documents, [[image]]s) sources. The resulting knowledge needs to be in a machine-readable and machine-interpretable format and must [[Knowledge representation and reasoning|represent knowledge]] in a manner that facilitates inferencing. Although it is methodically similar to [[information extraction]] ([[Natural language processing|NLP]]) and [[extract, transform, load|ETL]] (data warehouse), the main criteria is that the extraction result goes beyond the creation of structured information or the transformation into a [[Database schema|relational schema]]. It requires either the reuse of existing [[Knowledge representation and reasoning|formal knowledge]] (reusing identifiers or [[ontologies]]) or the generation of a schema based on the source data.}}

{{term|[[knowledge Interchange Format]] (KIF)}}
{{defn|A computer language designed to enable systems to share and re-use information from [[knowledge-based systems]]. KIF is similar to [[frame language]]s such as [[KL-ONE]] and [[LOOM (ontology)|LOOM]] but unlike such language its primary role is not intended as a framework for the expression or use of knowledge but rather for the interchange of knowledge between systems. The designers of KIF likened it to [[PostScript]]. PostScript was not designed primarily as a language to store and manipulate documents but rather as an interchange format for systems and devices to share documents. In the same way KIF is meant to facilitate sharing of knowledge across different systems that use different languages, formalisms, platforms, etc.}}

{{anchor|knowledge representation and reasoning}}{{term|[[knowledge representation and reasoning]] (KR² or KR&amp;R)}}
{{defn|The field of {{gli|artificial intelligence}} dedicated to representing information about the world in a form that a computer system can utilize to solve complex tasks such as [[Computer-aided diagnosis|diagnosing a medical condition]] or [[natural language user interface|having a dialog in a natural language]]. Knowledge representation incorporates findings from psychology&lt;ref&gt;{{Cite book |last1=Schank |first1=Roger |title=Scripts, Plans, Goals, and Understanding: An Inquiry Into Human Knowledge Structures |last2=Robert Abelson |date=1977 |publisher=Lawrence Erlbaum Associates, Inc.}}&lt;/ref&gt; about how humans solve problems and represent knowledge in order to design [[Formalism (mathematics)|formalisms]] that will make complex systems easier to design and build.  Knowledge representation and reasoning also incorporates findings from [[logic]] to automate various kinds of ''reasoning'', such as the application of rules or the relations of [[Set theory|sets]] and [[subset]]s.&lt;ref&gt;{{Cite news |url=https://deepminds.science/knowledge-representation-neural-networks/ |title=Knowledge Representation in Neural Networks - deepMinds |date=2018-08-16 |work=deepMinds |access-date=2018-08-16 }}&lt;/ref&gt; Examples of knowledge representation formalisms include [[Semantic network|semantic nets]], [[systems architecture]], [[Frame (artificial intelligence)|frames]], rules, and [[Ontology (information science)|ontologies]]. Examples of [[automated reasoning]] engines include [[inference engine]]s, [[automated theorem proving|theorem prover]]s, and classifiers.}}
{{glossaryend}}

==L==
{{glossary}}
{{term|[[lazy learning]]}}
{{defn|In {{gli|machine learning}}, lazy learning is a learning method in which generalization of the [[training data]] is, in theory, delayed until a query is made to the system, as opposed to in [[eager learning]], where the system tries to generalize the training data before receiving queries.}}

{{term|[[Lisp (programming language)]] (LISP)}}
{{defn|A family of [[programming language]]s with a long history and a distinctive, fully [[parenthesized]] [[Polish notation#Computer programming|prefix notation]].&lt;ref&gt;{{Cite book |last1=Reilly |first1=Edwin D. |url=https://archive.org/details/milestonesincomp0000reil |title=Milestones in computer science and information technology |publisher=Greenwood Publishing Group |year=2003 |isbn=978-1-57356-521-9 |pages=[https://archive.org/details/milestonesincomp0000reil/page/156 156]–157 |url-access=registration}}&lt;/ref&gt;}}

{{term|[[logic programming]]}}
{{defn|A type of [[programming paradigm]] which is largely based on [[formal logic]]. Any program written in a logic {{gli|programming language}} is a set of sentences in logical form, expressing facts and rules about some problem domain. Major logic programming language families include {{gli|Prolog}}, {{gli|answer set programming}} (ASP), and {{gli|Datalog}}.}}

{{anchor|long short-term memory}}{{term|[[long short-term memory]] (LSTM)}}
{{defn|An artificial {{gli|recurrent neural network}} architecture&lt;ref&gt;{{Cite journal |last1=Hochreiter |first1=Sepp |last2=Schmidhuber |first2=Jürgen |year=1997 |title=Long short-term memory |journal=Neural Computation |volume=9 |issue=8 |pages=1735–1780 |doi=10.1162/neco.1997.9.8.1735 |pmid=9377276|s2cid=1915014 }}&lt;/ref&gt; used in the field of {{gli|deep learning}}. Unlike standard [[feedforward neural network]]s, LSTM has feedback connections that make it a "general purpose computer" (that is, it can compute anything that a {{gli|Turing machine}} can).&lt;ref name="Siegelmann92"&gt;{{Cite book |last1=Siegelmann |first1=Hava T. |title=On the Computational Power of Neural Nets |last2=Sontag |first2=Eduardo D. |date=1992 |work=ACM |isbn=978-0897914970 |volume=COLT '92 |pages=440–449 |doi=10.1145/130385.130432|s2cid=207165680 }}&lt;/ref&gt; It can not only process single data points (such as images), but also entire sequences of data (such as speech or video).}}
{{glossaryend}}

==M==
{{glossary}}
{{anchor|machine vision}}{{term|[[machine vision]] (MV)}}
{{defn|The technology and methods used to provide imaging-based automatic inspection and analysis for such applications as automatic inspection, [[process control]], and robot guidance, usually in industry.  Machine vision is a term encompassing a large number of technologies, software and hardware products, integrated systems, actions, methods and expertise. Machine vision as a [[systems engineering]] discipline can be considered distinct from [[computer vision]], a form of [[computer science]].  It attempts to integrate existing technologies in new ways and apply them to solve real world problems. The term is the prevalent one for these functions in industrial automation environments but is also used for these functions in other environments such as security and vehicle guidance.}}

{{term|[[Markov chain]]}}
{{defn|A [[stochastic model]] describing a [[sequence]] of possible events in which the probability of each event depends only on the state attained in the previous event.&lt;ref&gt;{{Cite book |last1=Gagniuc |first1=Paul A. |title=Markov Chains: From Theory to Implementation and Experimentation |publisher=John Wiley &amp; Sons |year=2017 |isbn=978-1-119-38755-8 |location=USA, NJ |pages=1–235}}&lt;/ref&gt;&lt;ref&gt;{{Cite web |url=https://en.oxforddictionaries.com/definition/us/markov_chain |title=Markov chain {{!}} Definition of Markov chain in US English by Oxford Dictionaries |website=Oxford Dictionaries {{!}} English |access-date=2017-12-14}}&lt;/ref&gt;&lt;ref&gt;[https://brilliant.org/wiki/markov-chains/ Definition at Brilliant.org "Brilliant Math and Science Wiki"]. Retrieved 12 May 2019&lt;/ref&gt;}}

{{term|[[Markov decision process]] (MDP)}}
{{defn|A [[discrete time]] [[stochastic]] [[Optimal control theory|control]] process. It provides a mathematical framework for modeling [[decision making]] in situations where outcomes are partly [[Randomness#In mathematics|random]] and partly under the control of a decision maker. MDPs are useful for studying [[optimization problem]]s solved via [[dynamic programming]] and {{gli|reinforcement learning}}.}}

{{term|[[mathematical optimization]]}}
{{ghat|Also '''mathematical programming'''.}}
{{defn|In [[mathematics]], [[computer science]], and [[operations research]], the selection of a best element (with regard to some criterion) from some set of available alternatives.&lt;ref&gt;"[http://glossary.computing.society.informs.org/index.php?page=nature.html The Nature of Mathematical Programming] {{webarchive|url=https://web.archive.org/web/20140305080324/http://glossary.computing.society.informs.org/index.php?page=nature.html |date=2014-03-05 }}," ''Mathematical Programming Glossary'', INFORMS Computing Society.&lt;/ref&gt;}}

{{anchor|machine learning}}{{term|[[machine learning]] (ML)}}
{{defn|The [[Branches of science|scientific study]] of {{gli|algorithm|algorithms}} and [[statistical model]]s that [[computer systems]] use in order to perform a specific task effectively without using explicit instructions, relying on patterns and inference instead.}}

{{term|[[machine listening]]}}
{{ghat|Also '''computer audition''' ('''CA''').}}
{{defn|A general field of study of {{gli|algorithm|algorithms}} and systems for audio understanding by machine.&lt;ref&gt;{{Cite book |last1=Wang |first1=Wenwu |url=https://www.igi-global.com/book/machine-audition-principles-algorithms-systems/40288 |title=Machine Audition: Principles, Algorithms and Systems |date=1 July 2010 |publisher=IGI Global |isbn=9781615209194 |via=igi-global.com}}&lt;/ref&gt;&lt;ref&gt;{{Cite web |url=http://epubs.surrey.ac.uk/596085/1/Wang_Preface_MA_2010.pdf |title=Machine Audition: Principles, Algorithms and Systems}}&lt;/ref&gt;}}

{{term|[[machine perception]]}}
{{defn|The capability of a computer system to interpret data in a manner that is similar to the way humans use their senses to relate to the world around them.&lt;ref&gt;Malcolm Tatum (October 3, 2012). "What is Machine Perception".&lt;/ref&gt;&lt;ref&gt;Alexander Serov (January 29, 2013). "Subjective Reality and Strong Artificial Intelligence" (PDF).&lt;/ref&gt;&lt;ref&gt;{{Cite web |url=http://www.ccs.fau.edu/~hahn/mpcr/ |title=Machine Perception &amp; Cognitive Robotics Laboratory |website=ccs.fau.edu |access-date=2016-06-18}}&lt;/ref&gt;}}

{{term|[[mechanism design]]}}
{{defn|A field in [[economics]] and [[game theory]] that takes an [[engineering]] approach to designing economic mechanisms or [[Economic incentive|incentives]], toward desired objectives, in [[Strategy (game theory)|strategic settings]], where players act [[Rational choice theory|rationally]]. Because it starts at the end of the game, then goes backwards, it is also called reverse game theory. It has broad applications, from economics and politics (markets, auctions, voting procedures) to networked-systems (internet interdomain routing, sponsored search auctions).}}

{{term|[[mechatronics]]}}
{{ghat|Also '''mechatronic engineering'''.}}
{{defn|A [[multidisciplinary]] branch of engineering that focuses on the engineering of both [[Electrical engineering|electrical]] and [[mechanical engineering|mechanical systems]], and also includes a combination of [[robotics]], [[electronics]], [[computer engineering|computer]], [[telecommunications]], [[systems engineering|systems]], [[control engineering|control]], and [[Product engineering|product]] engineering.&lt;ref&gt;{{Cite web |url=http://www.mme.uwaterloo.ca/undergrad/mechatronics/prospective/prospective.html |title=What is Mechatronics Engineering? |website=Prospective Student Information |publisher=University of Waterloo |url-status=dead |archive-url=https://web.archive.org/web/20111006100431/http://www.mme.uwaterloo.ca/undergrad/mechatronics/prospective/prospective.html |archive-date=6 October 2011 |access-date=30 May 2011}}&lt;/ref&gt;&lt;ref name="CZU"&gt;{{Cite web |url=http://mechatronics.tul.cz |title=Mechatronics (Bc., Ing., PhD.) |access-date=15 April 2011}}&lt;/ref&gt;}}

{{term|[[metabolic network reconstruction and simulation]]}}
{{defn|Allows for an in-depth insight into the molecular mechanisms of a particular organism. In particular, these models correlate the [[genome]] with molecular physiology.&lt;ref name="Franke_2005"&gt;{{Cite journal |last1=Franke |last2=Siezen |first2=Teusink |year=2005 |title=Reconstructing the metabolic network of a bacterium from its genome. |journal=Trends in Microbiology |volume=13 |issue=11 |pages=550–558 |doi=10.1016/j.tim.2005.09.001 |pmid=16169729}}&lt;/ref&gt;}}

{{term|[[metaheuristic]]}}
{{defn|In [[computer science]] and [[mathematical optimization]], a metaheuristic is a higher-level [[procedure (computer science)|procedure]] or [[Heuristic (computer science)|heuristic]] designed to find, generate, or select a heuristic (partial {{gli|search algorithm}}) that may provide a sufficiently good solution to an [[optimization problem]], especially with incomplete or imperfect information or limited computation capacity.&lt;ref&gt;{{Cite journal |last1=Balamurugan |first1=R. |last2=Natarajan |first2=A.M. |last3=Premalatha |first3=K. |year=2015 |title=Stellar-Mass Black Hole Optimization for Biclustering Microarray Gene Expression Data |journal=Applied Artificial Intelligence |volume=29 |issue=4 |pages=353–381 |doi=10.1080/08839514.2015.1016391|s2cid=44624424 }}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |last1=Bianchi |first1=Leonora |last2=Dorigo |first2=Marco |last3=Maria Gambardella |first3=Luca |last4=Gutjahr |first4=Walter J. |year=2009 |title=A survey on metaheuristics for stochastic combinatorial optimization |journal=Natural Computing |volume=8 |issue=2 |pages=239–287 |doi=10.1007/s11047-008-9098-4|s2cid=9141490 |url=http://doc.rero.ch/record/319945/files/11047_2008_Article_9098.pdf }}&lt;/ref&gt; Metaheuristics sample a set of solutions which is too large to be completely sampled.}}

{{term|[[model checking]]}}
{{defn|In [[computer science]], model checking or property checking is, for a given model of a system, exhaustively and automatically checking whether this model meets a given [[formal specification|specification]]. Typically, one has hardware or software systems in mind, whereas the specification contains safety requirements such as the absence of [[deadlock]]s and similar critical states that can cause the system to [[Crash (computing)|crash]]. Model checking is a technique for automatically verifying correctness properties of ''finite-state'' systems.}}

{{term|''[[modus ponens]]''}}
{{defn|In [[propositional calculus|propositional logic]], ''modus ponens'' is a [[rule of inference]].&lt;ref&gt;Herbert B. Enderton, 2001, A Mathematical Introduction to Logic Second Edition Enderton:110, Harcourt Academic Press, Burlington MA, {{ISBN|978-0-12-238452-3}}.&lt;/ref&gt; It can be summarized as "''P [[material conditional|implies]] Q'' and ''P'' is asserted to be true, therefore ''Q'' must be true."}}

{{term|''[[modus tollens]]''}}
{{defn|In [[propositional calculus|propositional logic]], ''modus tollens'' is a [[Validity (logic)|valid]] [[Logical form|argument form]] and a [[rule of inference]].  It is an application of the general truth that if a statement is true, then so is its [[contrapositive]].  The inference rule ''modus tollens'' asserts that the [[inference]] from ''P implies Q'' to ''the negation of Q implies the negation of P'' is valid.}}

{{term|[[Monte Carlo tree search]]}}
{{defn|In [[computer science]], Monte Carlo tree search (MCTS) is a [[heuristic (computer science)|heuristic]] {{gli|search algorithm}} for some kinds of [[decision process]]es.}}

{{anchor|multi-agent system}}{{term|[[multi-agent system]] (MAS)}}
{{ghat|Also '''self-organized system'''.}}
{{defn|A computerized system composed of multiple interacting {{gli|intelligent agent|intelligent agents}}. Multi-agent systems can solve problems that are difficult or impossible for an individual agent or a [[monolithic system]] to solve. Intelligence may include [[Scientific method|method]]ic, [[Function (computer science)|functional]], [[Algorithm|procedural]] approaches, [[algorithm]]ic [[search algorithm|search]] or {{gli|reinforcement learning}}.}}

{{term|[[multi-swarm optimization]]}}
{{defn|A variant of [[particle swarm optimization]] (PSO) based on the use of multiple sub-swarms instead of one (standard) swarm. The general approach in multi-swarm optimization is that each sub-swarm focuses on a specific region while a specific diversification method decides where and when to launch the sub-swarms. The multi-swarm framework is especially fitted for the optimization on multi-modal problems, where multiple (local) optima exist.}}

{{term|[[mutation (genetic algorithm)|mutation]]}}
{{defn|A [[genetic operator]] used to maintain [[genetic diversity]] from one generation of a population of [[genetic algorithm]] [[chromosome (genetic algorithm)|chromosomes]] to the next. It is analogous to biological [[mutation]]. Mutation alters one or more gene values in a chromosome from its initial state. In mutation, the solution may change entirely from the previous solution. Hence GA can come to a better solution by using mutation. Mutation occurs during evolution according to a user-definable mutation probability. This probability should be set low. If it is set too high, the search will turn into a primitive random search.}}

{{term|[[Mycin]]}}
{{defn|An early {{gli|backward chaining}} [[expert system]] that used {{gli|artificial intelligence}} to identify bacteria causing severe infections, such as [[bacteremia]] and [[meningitis]], and to recommend [[antibiotic]]s, with the dosage adjusted for patient's body weight – the name derived from the antibiotics themselves, as many antibiotics have the suffix "-mycin". The MYCIN system was also used for the diagnosis of blood clotting diseases.}}

{{glossaryend}}

{{Compact ToC|side=yes|center=yes|top=yes|num=yes|extlinks=yes|seealso=yes|refs=yes|nobreak=yes|}}

==N==
{{glossary}}
{{term|[[naive Bayes classifier]]}}
{{defn|In {{gli|machine learning}}, naive Bayes classifiers are a family of simple [[Probabilistic classification|probabilistic classifier]]s based on applying [[Bayes' theorem]] with strong (naive) [[statistical independence|independence]] assumptions between the features.}}

{{term|[[naive semantics]]}}
{{defn|An approach used in computer science for [[knowledge representation|representing basic knowledge]] about a specific domain, and has been used in applications such as the representation of the meaning of natural language sentences in artificial intelligence applications. In a general setting the term has been used to refer to the use of a limited store of generally understood knowledge about a specific domain in the world, and has been applied to fields such as the knowledge based design of data schemas.&lt;ref&gt;"[http://portal.acm.org/citation.cfm?id=628188 Naive Semantics to Support Automated Database Design]", '''IEEE Transactions on Knowledge and Data Engineering'', Volume 14, issue 1 (January 2002) by V. C. Storey, R. C. Goldstein and
H. Ullrich&lt;/ref&gt;}}

{{term|[[name binding]]}}
{{defn|In programming languages, name binding is the association of entities (data and/or code) with [[identifier]]s.&lt;ref name="tkac08"&gt;{{Citation  |title=Using early binding and late binding in Automation |date=May 11, 2007 |url=http://support.microsoft.com/kb/245115 |publisher=Microsoft |access-date=May 11, 2009}}&lt;/ref&gt; An identifier bound to an object is said to [[Reference (computer science)|reference]] that object. [[Machine language]]s have no built-in notion of identifiers, but name-object bindings as a service and notation for the programmer is implemented by programming languages. Binding is intimately connected with [[scoping]], as scope determines which names bind to which objects – at which locations in the program code ([[Scope (computer science)#Lexical scoping|lexically]]) and in which one of the possible execution paths ([[Scope (computer science)#Dynamic scoping|temporally]]).  Use of an identifier &lt;code&gt;id&lt;/code&gt; in a context that establishes a binding for &lt;code&gt;id&lt;/code&gt; is called a binding (or defining) occurrence. In all other occurrences (e.g., in expressions, assignments, and subprogram calls), an identifier stands for what it is bound to; such occurrences are called applied occurrences.}}

{{term|[[named-entity recognition]] (NER)}}
{{ghat|Also '''entity identification''', '''entity chunking''', and '''entity extraction'''.}}
{{defn|A subtask of [[information extraction]] that seeks to locate and classify [[named entity]] mentions in [[unstructured data|unstructured text]] into pre-defined categories such as the person names, organizations, locations, [[medical classification|medical codes]], time expressions, quantities, monetary values, percentages, etc.}}

{{term|[[named graph]]}}
{{defn|A key concept of [[Semantic Web]] architecture in which a set of [[Resource Description Framework]] statements (a [[Graph (discrete mathematics)|graph]]) are identified using a [[URI]],&lt;ref&gt;strictly speaking a URIRef&lt;/ref&gt; allowing descriptions to be made of that set of statements such as context, provenance information or other such [[metadata]].  Named graphs are a simple extension of the RDF data model&lt;ref&gt;http://www.w3.org/TR/PR-rdf-syntax/ "Resource Description Framework (RDF) Model and Syntax Specification"&lt;/ref&gt; through which graphs can be created but the model lacks an effective means of distinguishing between them once published on the [[World Wide Web|Web]] at large.}}

{{term|[[natural language generation]] (NLG)}}
{{defn|A software process that transforms structured data into plain-English content.  It can be used to produce long-form content for organizations to automate custom reports, as well as produce custom content for a web or mobile application. It can also be used to generate short blurbs of text in interactive conversations (a [[chatbot]]) which might even be read out loud by a [[text-to-speech]] system.}}

{{anchor|natural language processing}}{{term|[[natural language processing]] (NLP)}}
{{defn|A subfield of computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of [[natural language]] data.}}

{{term|[[natural language programming]]}}
{{defn|An [[ontology (information science)|ontology]]-assisted way of [[programming language|programming]] in terms of [[natural language|natural-language]] sentences, e.g. [[English language|English]].&lt;ref&gt;Miller, Lance A. "Natural language programming: Styles, strategies, and contrasts." IBM Systems Journal 20.2 (1981): 184–215.&lt;/ref&gt;}}

{{term|[[network motif]]}}
{{defn|All networks, including biological networks, social networks, technological networks (e.g., computer networks and electrical circuits) and more, can be represented as [[complex network|graphs]], which include a wide variety of subgraphs. One important local property of networks are so-called network motifs, which are defined as recurrent and [[statistically significant]] sub-graphs or patterns.}}

{{term|[[neural machine translation]] (NMT)}}
{{defn|An approach to [[machine translation]] that uses a large {{gli|artificial neural network}} to predict the likelihood of a sequence of words, typically modeling entire sentences in a single integrated model.}}

{{term|[[neural Turing machine]] (NTM)}}
{{defn|A [[recurrent neural network]] model. NTMs combine the fuzzy [[pattern matching]] capabilities of [[neural network]]s with the [[algorithm]]ic power of [[programmable computer]]s. An NTM has a neural network controller coupled to [[Auxiliary memory|external memory]] resources, which it interacts with through attentional mechanisms. The memory interactions are differentiable end-to-end, making it possible to optimize them using [[gradient descent]].&lt;ref name="MyUser_Https:_May_17_2016c"&gt;{{Cite web |url=https://www.linkedin.com/pulse/deep-minds-interview-googles-alex-graves-koray-sophie-curtis |title=Deep Minds: An Interview with Google's Alex Graves &amp; Koray Kavukcuoglu |access-date=May 17, 2016}}&lt;/ref&gt; An NTM with a [[long short-term memory]] (LSTM) network controller can infer simple algorithms such as copying, sorting, and associative recall from examples alone.&lt;ref&gt;Graves, Alex; Wayne, Greg; Danihelka, Ivo (2014). "Neural Turing Machines". arXiv:1410.5401 [cs.NE].&lt;/ref&gt;}}

{{term|[[neuro-fuzzy]]}}
{{defn|Combinations of {{gli|artificial neural network|artificial neural networks}} and {{gli|fuzzy logic}}.}}

{{term|[[neurocybernetics]]}}
{{ghat|Also '''brain–computer interface''' ('''BCI'''), '''neural-control interface''' ('''NCI'''), '''mind-machine interface''' ('''MMI'''), '''direct neural interface''' ('''DNI'''), or '''brain–machine interface''' ('''BMI''').}}
{{defn|A direct communication pathway between an enhanced or wired [[brain]] and an external device. BCI differs from [[Neuromodulation (medicine)|neuromodulation]] in that it allows for bidirectional information flow. BCIs are often directed at researching, mapping, assisting, augmenting, or repairing human cognitive or sensory-motor functions.&lt;ref name="Krucoff 584"&gt;{{Cite journal |last1=Krucoff |first1=Max O. |last2=Rahimpour |first2=Shervin |last3=Slutzky |first3=Marc W. |last4=Edgerton |first4=V. Reggie |last5=Turner |first5=Dennis A. |date=2016-01-01 |title=Enhancing Nervous System Recovery through Neurobiologics, Neural Interface Training, and Neurorehabilitation |journal=Frontiers in Neuroscience |volume=10 |pages=584 |doi=10.3389/fnins.2016.00584 |pmc=5186786 |pmid=28082858}}&lt;/ref&gt;}}

{{term|[[neuromorphic engineering]]}}
{{ghat|Also '''neuromorphic computing'''.}}
{{defn|A concept describing the use of [[very-large-scale integration]] (VLSI) systems containing electronic [[analog circuit]]s to mimic neuro-biological architectures present in the nervous system.&lt;ref&gt;{{Cite journal |last1=Mead |first1=Carver |year=1990 |title=Neuromorphic electronic systems |url=https://authors.library.caltech.edu/53090/1/00058356.pdf |journal=Proceedings of the IEEE |volume=78 |issue=10 |pages=1629–1636 |citeseerx=10.1.1.161.9762 |doi=10.1109/5.58356}}&lt;/ref&gt; In recent times, the term ''neuromorphic'' has been used to describe analog, digital, mixed-mode analog/digital VLSI, and software systems that implement models of [[neural system]]s (for [[perception]], [[motor control]], or [[multisensory integration]]). The implementation of neuromorphic computing on the hardware level can be realized by oxide-based [[memristor]]s,&lt;ref name="Maan 1–13"&gt;{{Cite journal |last1=Maan |first1=A. K. |last2=Jayadevi |first2=D. A. |last3=James |first3=A. P. |date=2016-01-01 |title=A Survey of Memristive Threshold Logic Circuits |journal=IEEE Transactions on Neural Networks and Learning Systems |volume=PP |issue=99 |pages=1734–1746 |arxiv=1604.07121 |bibcode=2016arXiv160407121M |doi=10.1109/TNNLS.2016.2547842 |issn=2162-237X |pmid=27164608|s2cid=1798273 }}&lt;/ref&gt; spintronic memories,&lt;ref&gt;"[https://www.academia.edu/37832670/A_Survey_of_Spintronic_Architectures_for_Processing-in-Memory_and_Neural_Networks  A Survey of Spintronic Architectures for Processing-in-Memory and Neural Networks]", JSA, 2018&lt;/ref&gt; threshold switches, and [[transistor]]s.&lt;ref&gt;{{Cite journal |last1=Zhou |first1=You |last2=Ramanathan |first2=S. |date=2015-08-01 |title=Mott Memory and Neuromorphic Devices |journal=Proceedings of the IEEE |volume=103 |issue=8 |pages=1289–1310 |doi=10.1109/JPROC.2015.2431914 |s2cid=11347598 |issn=0018-9219|url=https://zenodo.org/record/895565 }}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |last1=Monroe |first1=D. |year=2014 |title=Neuromorphic computing gets ready for the (really) big time |journal=[[Communications of the ACM]] |volume=57 |issue=6 |pages=13–15 |doi=10.1145/2601069|s2cid=20051102 }}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |last1=Zhao |first1=W. S. |last2=Agnus |first2=G. |last3=Derycke |first3=V. |last4=Filoramo |first4=A. |last5=Bourgoin |first5=J. -P. |last6=Gamrat |first6=C. |year=2010 |title=Nanotube devices based crossbar architecture: Toward neuromorphic computing |url=https://zenodo.org/record/3428659 |journal=Nanotechnology |volume=21 |issue=17 |pages=175202 |bibcode=2010Nanot..21q5202Z |doi=10.1088/0957-4484/21/17/175202 |pmid=20368686}}&lt;/ref&gt;&lt;ref name="humanbrainproject"&gt;{{YouTube|id=6RoiZ90mGfw|title=The Human Brain Project SP 9: Neuromorphic Computing Platform}}&lt;/ref&gt;}}

{{term|[[node (computer science)|node]]}}
{{defn|A basic unit of a [[data structure]], such as a [[linked list]] or [[Tree (data structure)|tree]] data structure. Nodes contain [[data]] and also may link to other nodes. Links between nodes are often implemented by [[Pointer (computer programming)|pointers]].}}

{{term|[[nondeterministic algorithm]]}}
{{defn|An {{gli|algorithm}} that, even for the same input, can exhibit different behaviors on different runs, as opposed to a [[deterministic algorithm]].}}

{{term|[[nouvelle AI]]}}
{{defn|Nouvelle AI differs from {{gli|artificial intelligence|classical AI}} by aiming to produce robots with intelligence levels similar to insects. Researchers believe that intelligence can emerge organically from simple behaviors as these intelligences interacted with the "real world", instead of using the constructed worlds which symbolic AIs typically needed to have programmed into them.&lt;ref&gt;{{Cite web |url=http://www.alanturing.net/turing_archive/pages/reference%20articles/what_is_AI/What%20is%20AI11.html |title=What is Artificial Intelligence? |last1=Copeland |first1=Jack |date=May 2000 |website=AlanTuring.net |access-date=7 November 2015}}&lt;/ref&gt;}}

{{term|[[NP (complexity)|NP]]}}
{{defn|In {{gli|computational complexity theory}}, NP (nondeterministic polynomial time) is a [[complexity class]] used to classify [[decision problem]]s.  NP is the [[Set (mathematics)|set]] of decision problems for which the [[Computational complexity theory#Problem instances|problem instances]], where the answer is "yes", have [[mathematical proof|proofs]] verifiable in [[polynomial time]].&lt;ref name="kleinberg2006"&gt;{{Cite book |last1=Kleinberg |first1=Jon |url=https://archive.org/details/algorithmdesign0000klei |title=Algorithm Design |last2=Tardos |first2=Éva |publisher=Addison-Wesley |year=2006 |isbn=0-321-37291-3 |edition=2nd |page=[https://archive.org/details/algorithmdesign0000klei/page/464 464] |url-access=registration}}&lt;/ref&gt;&lt;ref group="Note"&gt;''polynomial time'' refers to how quickly the number of operations needed by an algorithm, relative to the size of the problem, grows. It is therefore a measure of efficiency of an algorithm.&lt;/ref&gt;}}

{{term|[[NP-completeness]]}}
{{defn|In {{gli|computational complexity theory}}, a problem is NP-complete when it can be solved by a restricted class of [[brute force search]] algorithms and it can be used to simulate any other problem with a similar algorithm. More precisely, each input to the problem should be associated with a set of solutions of polynomial length, whose validity can be tested quickly (in [[polynomial time]]&lt;ref&gt;{{Cite book |last1=Cobham |first1=Alan |title=Proc. Logic, Methodology, and Philosophy of Science II |publisher=North Holland |year=1965 |chapter=The intrinsic computational difficulty of functions |author-link=Alan Cobham}}&lt;/ref&gt;), such that the output for any input is "yes" if the solution set is non-empty and "no" if it is empty.}}

{{term|[[NP-hardness]]}}
{{ghat|Also '''[[NP (complexity)|non-deterministic polynomial-time]] hardness'''.}}
{{defn|In {{gli|computational complexity theory}}, the defining property of a class of problems that are, informally, "at least as hard as the hardest problems in NP". A simple example of an NP-hard problem is the [[subset sum problem]].}}
{{glossaryend}}

==O==
{{glossary}}
{{term|[[Occam's razor]]}}
{{ghat|Also '''Ockham's razor''' or '''Ocham's razor'''.}}
{{defn|The problem-solving principle that states that when presented with competing [[hypothesis|hypotheses]] that make the same predictions, one should select the solution with the fewest assumptions;&lt;ref&gt;{{Cite web |url=http://math.ucr.edu/home/baez/physics/General/occam.html |title=What is Occam's Razor? |website=math.ucr.edu |access-date=2019-06-01}}&lt;/ref&gt; the principle is not meant to filter out hypotheses that make different predictions. The idea is attributed to the English [[Franciscan]] friar [[William of Ockham]] ({{c.}} 1287–1347), a [[Scholasticism|scholastic]] philosopher and [[Catholic theology|theologian]].}}

{{term|[[offline learning]]}}
{{defn|}}

{{term|[[online machine learning]]}}
{{defn|A method of {{gli|machine learning}} in which data becomes available in a sequential order and is used to update the best predictor for future data at each step, as opposed to batch learning techniques which generate the best predictor by learning on the entire training data set at once. Online learning is a common technique used in areas of machine learning where it is computationally infeasible to train over the entire dataset, requiring the need of [[out-of-core]] algorithms. It is also used in situations where it is necessary for the algorithm to dynamically adapt to new patterns in the data, or when the data itself is generated as a function of time.}}

{{term|[[ontology learning]]}}
{{ghat|Also '''ontology extraction''', '''ontology generation''', or '''ontology acquisition'''.}}
{{defn|The automatic or semi-automatic creation of [[ontology (information science)|ontologies]], including extracting the corresponding [[Domain of discourse|domain's]] terms and the relationships between the [[Conceptualization (information science)|concepts]] that these terms represent from a [[Text corpus|corpus]] of natural language text, and encoding them with an [[ontology language]] for easy retrieval.}}

{{term|[[OpenAI]]}}
{{defn|The for-profit corporation OpenAI LP, whose [[parent company|parent organization]] is the non-profit organization OpenAI Inc&lt;ref&gt;"OpenAI shifts from nonprofit to 'capped-profit' to attract capital". TechCrunch. Retrieved 2019-05-10.&lt;/ref&gt; that conducts research in the field of {{gli|artificial intelligence}} (AI) with the stated aim to promote and develop {{gli|friendly artificial intelligence|friendly AI}} in such a way as to benefit humanity as a whole.}}

{{term|[[OpenCog]]}}
{{defn|A project that aims to build an {{gli|open-source software|open-source}} artificial intelligence framework. OpenCog Prime is an architecture for robot and virtual [[embodied cognition]] that defines a set of interacting components designed to give rise to human-equivalent {{gli|artificial general intelligence}} (AGI) as an [[emergent phenomenon]] of the whole system.&lt;ref&gt;{{Cite web |url=http://www.cybertechnews.org/?p=915 |title=OpenCog: Open-Source Artificial General Intelligence for Virtual Worlds {{!}} CyberTech News |date=2009-03-06 |url-status=bot: unknown |archive-url=https://web.archive.org/web/20090306053354/http://www.cybertechnews.org/?p=915 |archive-date=2009-03-06 |access-date=2016-10-01}}&lt;/ref&gt;}}

{{term|[[Open Mind Common Sense]]}}
{{defn|An artificial intelligence project based at the [[Massachusetts Institute of Technology]] (MIT) [[MIT Media Lab|Media Lab]] whose goal is to build and utilize a large [[commonsense knowledge base]] from the contributions of many thousands of people across the Web.}}

{{anchor|open-source software}}{{term|[[open-source software]] (OSS)}}
{{defn|A type of [[computer software]] in which [[source code]] is released under a [[Open-source license|license]] in which the [[copyright]] holder grants users the rights to study, change, and [[Software distribution|distribute the software]] to anyone and for any purpose.&lt;ref&gt;{{Cite book |last1=St. Laurent |first1=Andrew M. |url=https://books.google.com/books?id=04jG7TTLujoC&amp;pg=PA4 |title=Understanding Open Source and Free Software Licensing |publisher=O'Reilly Media |year=2008 |isbn=9780596553951 |page=4}}&lt;/ref&gt; Open-source [[software]] may be developed in a [[Open-source model|collaborative public manner]]. Open-source software is a prominent example of [[open collaboration]].&lt;ref name="Open Collaboration"&gt;{{Cite journal |last1=Levine |first1=Sheen S. |last2=Prietula |first2=Michael J. |date=2013-12-30 |title=Open Collaboration for Innovation: Principles and Performance |journal=Organization Science |volume=25 |issue=5 |pages=1414–1433 |arxiv=1406.7541 |doi=10.1287/orsc.2013.0872 |s2cid=6583883 |issn=1047-7039}}&lt;/ref&gt;}}
{{glossaryend}}

==P==
{{glossary}}
{{term|[[partial order reduction]]}}
{{defn|A technique for reducing the size of the [[State transition system|state-space]] to be searched by a [[model checking]] or [[automated planning and scheduling]] [[algorithm]]. It exploits the commutativity of concurrently executed [[Transition (computer science)|transitions]], which result in the same state when executed in different orders.}}

{{term|[[partially observable Markov decision process]] (POMDP)}}
{{defn|A generalization of a [[Markov decision process]] (MDP). A POMDP models an agent decision process in which it is assumed that the system dynamics are determined by an MDP, but the agent cannot directly observe the underlying state. Instead, it must maintain a probability distribution over the set of possible states, based on a set of observations and observation probabilities, and the underlying MDP.}}

{{term|[[particle swarm optimization]] (PSO)}}
{{defn|A computational method that [[Mathematical optimization|optimizes]] a problem by [[iterative method|iteratively]] trying to improve a [[candidate solution]] with regard to a given measure of quality. It solves a problem by having a population of candidate solutions, here dubbed [[Point particle|particle]]s, and moving these particles around in the [[Optimization (mathematics)#Concepts and notation|search-space]] according to simple [[formula|mathematical formulae]] over the particle's position and velocity. Each particle's movement is influenced by its local best known position, but is also guided toward the best known positions in the search-space, which are updated as better positions are found by other particles. This is expected to move the swarm toward the best solutions.}}

{{term|[[pathfinding]]}}
{{ghat|Also '''pathing'''.}}
{{defn|The plotting, by a computer application, of the shortest route between two points. It is a more practical variant on [[Maze#Solving mazes|solving mazes]]. This field of research is based heavily on [[Dijkstra's algorithm]] for finding a shortest path on a [[Glossary of graph theory#Weighted graphs and networks|weighted graph]].}}

{{term|[[pattern recognition]]}}
{{defn|Concerned with the automatic discovery of regularities in data through the use of computer algorithms and with the use of these regularities to take actions such as classifying the data into different categories.&lt;ref&gt;Bishop, Christopher M. (2006). Pattern Recognition and Machine Learning (PDF). Springer. p. vii. Pattern recognition has its origins in engineering, whereas machine learning grew out of computer science. However, these activities can be viewed as two facets of the same field, and together they have undergone substantial development over the past ten years.&lt;/ref&gt;}}

{{term|[[predicate logic]]}}
{{ghat|Also '''first-order logic''', '''predicate logic''', and '''first-order predicate calculus'''.}}
{{defn|A collection of [[formal system]]s used in [[mathematics]], [[philosophy]], [[linguistics]], and [[computer science]]. First-order logic uses [[Quantification (logic)|quantified variables]] over non-logical objects and allows the use of sentences that contain variables, so that rather than propositions such as ''Socrates is a man'' one can have expressions in the form "there exists x such that x is Socrates and x is a man" and ''there exists'' is a quantifier while ''x'' is a variable.&lt;ref name="auto" /&gt; This distinguishes it from [[propositional logic]], which does not use quantifiers or [[finitary relation|relation]]s;&lt;ref&gt;[[George Edward Hughes|Hughes, G. E.]], &amp; [[Max Cresswell|Cresswell, M. J.]], ''[https://books.google.com/books?id=Dsn1xWNB4MEC&amp;printsec=frontcover#v=onepage&amp;q=%22first-order%20logic%22&amp;f=false A New Introduction to Modal Logic]'' ([[London]]: [[Routledge]], 1996), [https://books.google.cz/books?id=_CB5wiBeaA4C&amp;pg=PA161#v=onepage&amp;q&amp;f=false p.161].&lt;/ref&gt; in this sense, propositional logic is the foundation of first-order logic.}}

{{term|[[predictive analytics]]}}
{{defn|A variety of statistical techniques from [[data mining]], [[predictive modelling]], and {{gli|machine learning}}, that analyze current and historical facts to make predictions about future or otherwise unknown events.&lt;ref name="Nyce"&gt;{{Citation |last1=Nyce |first1=Charles |title=Predictive Analytics White Paper |url=https://www.the-digital-insurer.com/wp-content/uploads/2013/12/78-Predictive-Modeling-White-Paper.pdf |page=1 |year=2007 |publisher=American Institute for Chartered Property Casualty Underwriters/Insurance Institute of America}}&lt;/ref&gt;&lt;ref name="Eckerson"&gt;{{Citation |last1=Eckerson |first1=Wayne |title=Extending the Value of Your Data Warehousing Investment |date=May 10, 2007 |url=http://tdwi.org/articles/2007/05/10/predictive-analytics.aspx?sc_lang=en |publisher=The Data Warehouse Institute}}&lt;/ref&gt;}}

{{term|[[principal component analysis]] (PCA)}}
{{defn|A statistical procedure that uses an [[orthogonal transformation]] to convert a set of observations of possibly correlated variables (entities each of which takes on various numerical values) into a set of values of [[Correlation and dependence|linearly uncorrelated]] variables called principal components. This transformation is defined in such a way that the first principal component has the largest possible [[variance]] (that is, accounts for as much of the variability in the data as possible), and each succeeding component, in turn, has the highest variance possible under the constraint that it is [[orthogonal]] to the preceding components. The resulting vectors (each being a [[linear combination]] of the variables and containing ''n'' observations) are an uncorrelated [[orthogonal basis set]]. PCA is sensitive to the relative scaling of the original variables.}}

{{term|[[principle of rationality]]}}
{{ghat|Also '''rationality principle'''.}}
{{defn|A principle coined by [[Karl R. Popper]] in his Harvard Lecture of 1963, and published in his book ''Myth of Framework''.&lt;ref&gt;[[Karl R. Popper]], ''The Myth of Framework'', London (Routledge) 1994, chap. 8.&lt;/ref&gt; It is related to what he called the 'logic of the situation' in an ''Economica'' article of 1944/1945, published later in his book ''The Poverty of Historicism''.&lt;ref&gt;[[Karl R. Popper]], ''The Poverty of Historicism'', London (Routledge) 1960, chap. iv, sect. 31.&lt;/ref&gt; According to Popper's rationality principle, agents act in the most adequate way according to the objective situation. It is an idealized conception of human behavior which he used to drive his model of [[situational analysis]].}}

{{term|[[probabilistic programming]] (PP)}}
{{defn|A [[programming paradigm]] in which [[probabilistic model]]s are specified and inference for these models is performed automatically.&lt;ref name="physorg"&gt;{{Cite news |url=http://phys.org/news/2015-04-probabilistic-lines-code-thousands.html |title=Probabilistic programming does in 50 lines of code what used to take thousands |date=April 13, 2015 |work=phys.org |access-date=2015-04-13}}&lt;/ref&gt; It represents an attempt to unify probabilistic modeling and traditional general-purpose programming in order to make the former easier and more widely applicable.&lt;ref&gt;{{Cite web |url=http://probabilistic-programming.org/wiki/Home |title=Probabilistic Programming |website=probabilistic-programming.org |url-status=dead |archive-url=https://web.archive.org/web/20160110035042/http://probabilistic-programming.org/wiki/Home |archive-date=10 January 2016 |access-date=31 July 2019}}&lt;/ref&gt;&lt;ref name="Pfeffer2014"&gt;Pfeffer, Avrom (2014), ''Practical Probabilistic Programming'', Manning Publications. p.28. {{ISBN|978-1 6172-9233-0}}&lt;/ref&gt; It can be used to create systems that help make decisions in the face of uncertainty.  Programming languages used for probabilistic programming are referred to as "Probabilistic programming languages" (PPLs).}}

{{term|[[production system (computer science)|production system]]}}
{{defn|}}

{{term|[[programming language]]}}
{{defn|A {{gli|formal language}}, which comprises a [[Instruction set|set of instructions]] that produce various kinds of [[Input/output|output]]. Programming languages are used in [[computer programming]] to implement {{gli|algorithm|algorithms}}.}}

{{term|[[Prolog]]}}
{{defn|A {{gli|logic programming}} language associated with artificial intelligence and [[computational linguistics]].&lt;ref name="Clocksin2003"&gt;{{Cite book |last1=Clocksin |first1=William F. |title=Programming in Prolog |last2=Mellish |first2=Christopher S. |publisher=Springer-Verlag |year=2003 |isbn=978-3-540-00678-7 |location=Berlin ; New York}}&lt;/ref&gt;&lt;ref name="Bratko2012"&gt;{{Cite book |last1=Bratko |first1=Ivan |title=Prolog programming for artificial intelligence |publisher=Addison Wesley |year=2012 |isbn=978-0-321-41746-6 |edition=4th |location=Harlow, England ; New York}}&lt;/ref&gt;&lt;ref name="Covington1994"&gt;{{Cite book |last1=Covington |first1=Michael A. |title=Natural language processing for Prolog programmers |publisher=Prentice Hall |year=1994 |isbn=978-0-13-629213-5 |location=Englewood Cliffs, N.J.}}&lt;/ref&gt;  Prolog has its roots in [[first-order logic]], a [[formal logic]], and unlike many other [[programming language]]s, Prolog is intended primarily as a [[declarative programming|declarative]] programming language: the program logic is expressed in terms of relations, represented as facts and [[Rule of inference|rules]].  A computation is initiated by running a ''query'' over these relations.&lt;ref&gt;Lloyd, J. W. (1984). Foundations of logic programming. Berlin: Springer-Verlag. {{ISBN|978-3-540-13299-8}}.&lt;/ref&gt;}}

{{term|[[propositional calculus]]}}
{{ghat|Also '''propositional logic''', '''statement logic''', '''sentential calculus''', '''sentential logic''', and '''[[zeroth-order logic]]'''.}}
{{defn|A branch of [[logic]] which deals with [[propositions]] (which can be true or false) and argument flow. Compound propositions are formed by connecting propositions by [[logical connective]]s. The propositions without logical connectives are called atomic propositions. Unlike [[first-order logic]], propositional logic does not deal with non-logical objects, predicates about them, or quantifiers. However, all the machinery of propositional logic is included in first-order logic and higher-order logics. In this sense, propositional logic is the foundation of first-order logic and higher-order logic.}}

{{term|[[Python (programming language)|Python]]}}
{{defn|An [[interpreted language|interpreted]], [[high-level programming language|high-level]], [[general-purpose programming language|general-purpose]] {{gli|programming language}} created by [[Guido van Rossum]] and first released in 1991. Python's design philosophy emphasizes [[code readability]] with its notable use of [[Off-side rule|significant whitespace]]. Its language constructs and [[object-oriented programming|object-oriented]] approach aim to help programmers write clear, logical code for small and large-scale projects.&lt;ref&gt;Kuhlman, Dave. "A Python Book: Beginning Python, Advanced Python, and Python Exercises". Section 1.1. Archived from the original (PDF) on 23 June 2012.&lt;/ref&gt;}}
{{glossaryend}}

{{Compact ToC|side=yes|center=yes|top=yes|num=yes|extlinks=yes|seealso=yes|refs=yes|nobreak=yes|}}

==Q==
{{glossary}}
{{term|[[qualification problem]]}}
{{defn|In philosophy and artificial intelligence (especially {{gli|knowledge-based system|knowledge-based systems}}), the qualification problem is concerned with the impossibility of listing ''all'' of the [[precondition]]s required for a real-world action to have its intended effect.&lt;ref name="reiter"&gt;{{Cite book |last1=Reiter |first1=Raymond |title=Knowledge in Action: Logical Foundations for Specifying and Implementing Dynamical Systems |url=https://archive.org/details/knowledgeactionl00reit_022 |url-access=limited |publisher=The MIT Press |year=2001 |isbn=9780262527002 |location=Cambridge, Massachusetts |pages=[https://archive.org/details/knowledgeactionl00reit_022/page/n40 20]–22}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |last1=Thielscher |first1=Michael |date=September 2001 |title=The Qualification Problem: A solution to the problem of anomalous models |journal=Artificial Intelligence |volume=131 |issue=1–2 |pages=1–37 |doi=10.1016/S0004-3702(01)00131-X}}&lt;/ref&gt; It might be posed as ''how to deal with the things that prevent me from achieving my intended result''. It is strongly connected to, and opposite the [[ramification problem|ramification side]] of, the [[frame problem]].&lt;ref name="reiter" /&gt;}}

{{term|[[quantifier (logic)|quantifier]]}}
{{defn|In [[logic]], quantification specifies the quantity of specimens in the [[domain of discourse]] that satisfy an [[open formula]]. The two most common quantifiers mean "[[Universal quantification|for all]]" and "[[Existential quantification|there exists]]". For example, in arithmetic, quantifiers allow one to say that the natural numbers go on forever, by writing that ''for all'' n (where n is a natural number), there is another number (say, the successor of n) which is one bigger than n.&lt;!--this is to answer {{Technical|date=March 2016}} by making at least the first paragraph somewhat approachable. Of course the rest must be technical.--&gt;}}

{{term|[[quantum computing]]}}
{{defn|The use of [[quantum mechanics|quantum-mechanical]] [[phenomena]] such as [[quantum superposition|superposition]] and [[quantum entanglement|entanglement]] to perform [[computation]]. A quantum computer is used to perform such computation, which can be implemented theoretically or physically.&lt;ref name="2018Report"&gt;{{Cite book |title=Quantum Computing : Progress and Prospects (2018) |publisher=National Academies Press |year=2019 |isbn=978-0-309-47969-1 |editor-last=Grumbling |editor-first=Emily |location=Washington, DC |page=I-5 |doi=10.17226/25196 |oclc=1081001288 |editor-last2=Horowitz |editor-first2=Mark}}&lt;/ref&gt;{{rp|I-5}}}}

{{term|[[query language]]}}
{{defn|Query languages or data query languages (DQLs) are [[computer language]]s used to make queries in [[database]]s and [[information system]]s.  Broadly, query languages can be classified according to whether they are database query languages or [[information retrieval query language]]s. The difference is that a database query language attempts to give factual answers to factual questions, while an information retrieval query language attempts to find documents containing information that is relevant to an area of inquiry.}}
{{glossaryend}}

==R==
{{glossary}}
{{term|[[R (programming language)|R programming language]]}}
{{defn|A {{gli|programming language}} and [[free software]] environment for [[statistical computing]] and graphics supported by the R Foundation for Statistical Computing.{{refn | R language and environment
{{Cite web |url=https://cran.r-project.org/doc/FAQ/R-FAQ.html#What-is-R_003f |title=R FAQ |last1=Hornik |first1=Kurt |date=2017-10-04 |website=The Comprehensive R Archive Network |at=2.1 What is R? |access-date=2018-08-06}}
R Foundation
{{Cite web |url=https://cran.r-project.org/doc/FAQ/R-FAQ.html#What-is-the-R-Foundation_003f |title=R FAQ |last1=Hornik |first1=Kurt |date=2017-10-04 |website=The Comprehensive R Archive Network |at=2.13 What is the R Foundation? |access-date=2018-08-06}}
The R Core Team asks authors who use R in their data analysis to cite the software using:
R Core Team (2016). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL http://www.R-project.org/.
}} The R language is widely used among [[statistician]]s and [[Data mining|data miners]] for developing [[statistical software]]{{refn | widely used
{{Cite journal |last1=Fox |first1=John |last2=Andersen|first2=Robert |name-list-style=amp |date=January 2005 |title=Using the R Statistical Computing Environment to Teach Social Statistics Courses |url=https://socialsciences.mcmaster.ca/jfox/Teaching-with-R.pdf |publisher=Department of Sociology, McMaster University |access-date=2018-08-06}}
{{Cite news |last1=Vance |first1=Ashlee |url=https://www.nytimes.com/2009/01/07/technology/business-computing/07program.html |title=Data Analysts Captivated by R's Power |date=2009-01-06 |work=[[The New York Times]] |access-date=2018-08-06 |quote=R is also the name of a popular programming language used by a growing number of data analysts inside corporations and academia. It is becoming their lingua franca...}}
}} and [[data analysis]].&lt;ref&gt;{{Cite news |last1=Vance |first1=Ashlee |url=https://www.nytimes.com/2009/01/07/technology/business-computing/07program.html |title=Data Analysts Captivated by R's Power |date=2009-01-06 |work=[[The New York Times]] |access-date=2018-08-06 |quote=R is also the name of a popular programming language used by a growing number of data analysts inside corporations and academia. It is becoming their lingua franca...}}&lt;/ref&gt;}}

{{term|[[radial basis function network]]}}
{{defn|In the field of [[mathematical modeling]], a radial basis function network is an {{gli|artificial neural network}} that uses [[radial basis function]]s as [[activation function]]s. The output of the network is a [[linear combination]] of radial basis functions of the inputs and neuron parameters. Radial basis function networks have many uses, including [[function approximation]], [[time series prediction]], [[Statistical classification|classification]], and system [[Control theory|control]]. They were first formulated in a 1988 paper by Broomhead and Lowe, both researchers at the [[Royal Signals and Radar Establishment]].&lt;ref&gt;{{Cite techreport |last1=Broomhead |first1=D. S. |last2=Lowe |first2=David |year=1988 |title=Radial basis functions, multi-variable functional interpolation and adaptive networks |institution=[[Royal Signals and Radar Establishment|RSRE]] |number=4148 |url=http://www.dtic.mil/cgi-bin/GetTRDoc?AD=ADA196234}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |last1=Broomhead |first1=D. S. |last2=Lowe |first2=David |year=1988 |title=Multivariable functional interpolation and adaptive networks |url=https://sci2s.ugr.es/keel/pdf/algorithm/articulo/1988-Broomhead-CS.pdf |journal=Complex Systems |volume=2 |pages=321–355}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |last1=Schwenker |first1=Friedhelm |last2=Kestler |first2=Hans A. |last3=Palm |first3=Günther |year=2001 |title=Three learning phases for radial-basis-function networks |journal=Neural Networks |volume=14 |issue=4–5 |pages=439–458 |doi=10.1016/s0893-6080(01)00027-2 |pmid=11411631}}&lt;/ref&gt;}}

{{term|[[random forest]]}}
{{ghat|Also '''random decision forest'''.}}
{{defn|An [[ensemble learning]] method for [[statistical classification|classification]], [[regression analysis|regression]] and other tasks that operates by constructing a multitude of [[decision tree learning|decision trees]] at training time and outputting the class that is the [[mode (statistics)|mode]] of the classes (classification) or mean prediction (regression) of the individual trees.&lt;ref&gt;Ho, Tin Kam (1995). Random Decision Forests (PDF). Proceedings of the 3rd International Conference on Document Analysis and Recognition, Montreal, QC, 14–16 August 1995. pp. 278–282. Archived from the original (PDF) on 17 April 2016. Retrieved 5 June 2016.&lt;/ref&gt;&lt;ref&gt;{{Cite journal |last1=Ho |first1=TK |year=1998 |title=The Random Subspace Method for Constructing Decision Forests |journal=IEEE Transactions on Pattern Analysis and Machine Intelligence |volume=20 |issue=8 |pages=832–844 |doi=10.1109/34.709601}}&lt;/ref&gt; Random decision forests correct for decision trees' habit of [[overfitting]] to their [[Test set|training set]].&lt;ref&gt;Hastie, Trevor; Tibshirani, Robert; Friedman, Jerome(2008). The Elements of Statistical Learning (2nd ed.). Springer. {{ISBN|0-387-95284-5}}.&lt;/ref&gt;}}

{{term|[[reasoning system]]}}
{{defn|In [[information technology]] a reasoning system is a [[software system]] that generates conclusions from available [[knowledge]] using [[logic]]al techniques such as [[Deductive reasoning|deduction]] and [[Inductive reasoning|induction]]. Reasoning systems play an important role in the implementation of artificial intelligence and [[knowledge-based systems]].}}

{{term|[[recurrent neural network]] (RNN)}}
{{defn|A class of {{gli|artificial neural network|artificial neural networks}} where connections between nodes form a [[directed graph]] along a temporal sequence. This allows it to exhibit temporal dynamic behavior. Unlike [[feedforward neural networks]], RNNs can use their internal state (memory) to process sequences of inputs. This makes them applicable to tasks such as unsegmented, connected [[handwriting recognition]]&lt;ref&gt;{{Cite journal |last1=Graves |first1=A. |last2=Liwicki |first2=M. |last3=Fernandez |first3=S. |last4=Bertolami |first4=R. |last5=Bunke |first5=H. |last6=Schmidhuber |first6=J. |author-link6=Jürgen Schmidhuber |year=2009 |title=A Novel Connectionist System for Improved Unconstrained Handwriting Recognition |url=http://www.idsia.ch/~juergen/tpami_2008.pdf |journal=IEEE Transactions on Pattern Analysis and Machine Intelligence |volume=31 |issue=5 |pages=855–868 |citeseerx=10.1.1.139.4502 |doi=10.1109/tpami.2008.137 |pmid=19299860|s2cid=14635907 }}&lt;/ref&gt; or [[speech recognition]].&lt;ref name="sak2014"&gt;{{Cite web |url=https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43905.pdf |title=Long Short-Term Memory recurrent neural network architectures for large scale acoustic modeling |last1=Sak |first1=Hasim |last2=Senior |first2=Andrew |year=2014 |url-status=dead |archive-url=https://web.archive.org/web/20180424203806/https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43905.pdf |archive-date=24 April 2018 |access-date=6 August 2019 |last3=Beaufays |first3=Francoise}}&lt;/ref&gt;&lt;ref name="liwu2015"&gt;{{Cite arXiv |eprint=1410.4281 |class=cs.CL |first1=Xiangang |last1=Li |first2=Xihong |last2=Wu |title=Constructing Long Short-Term Memory based Deep Recurrent Neural Networks for Large Vocabulary Speech Recognition |date=2014-10-15}}&lt;/ref&gt;}}

{{term|[[region connection calculus]]}}
{{defn|}}

{{term|[[reinforcement learning]] (RL)}}
{{defn|An area of {{gli|machine learning}} concerned with how [[software agent]]s ought to take [[Action selection|actions]] in an environment so as to maximize some notion of cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside [[supervised learning]] and [[unsupervised learning]].  It differs from supervised learning in that labelled input/output pairs need not be presented, and sub-optimal actions need not be explicitly corrected. Instead the focus is finding a balance between exploration (of uncharted territory) and exploitation (of current knowledge).&lt;ref name="kaelbling"&gt;{{Cite journal |last1=Kaelbling |first1=Leslie P. |last2=Littman |first2=Michael L. |author-link2=Michael L. Littman |last3=Moore |first3=Andrew W. |author-link3=Andrew W. Moore |year=1996 |title=Reinforcement Learning: A Survey |url=http://www.cs.washington.edu/research/jair/abstracts/kaelbling96a.html |url-status=dead |journal=Journal of Artificial Intelligence Research |volume=4 |pages=237–285 |arxiv=cs/9605103 |doi=10.1613/jair.301 |s2cid=1708582 |archive-url=http://webarchive.loc.gov/all/20011120234539/http://www.cs.washington.edu/research/jair/abstracts/kaelbling96a.html |archive-date=2001-11-20 |author-link1=Leslie P. Kaelbling}}&lt;/ref&gt;}}

{{term|[[reservoir computing]]}}
{{defn|A framework for computation that may be viewed as an extension of {{gli|neural network|neural networks}}.&lt;ref&gt;[[Benjamin Schrauwen|Schrauwen, Benjamin]], [[David Verstraeten]], and [[Jan Van Campenhout]]. "An overview of reservoir computing: theory, applications, and implementations." Proceedings of the European Symposium on Artificial Neural Networks ESANN 2007, pp. 471-482.&lt;/ref&gt; Typically an input signal is fed into a fixed (random) [[dynamical system]] called a ''reservoir'' and the dynamics of the reservoir map the input to a higher dimension. Then a simple ''readout'' mechanism is trained to read the state of the reservoir and map it to the desired output. The main benefit is that training is performed only at the readout stage and the reservoir is fixed. [[Liquid-state machine]]s&lt;ref&gt;{{Cite journal |last1=Mass |first1=Wolfgang |author-link=Wolfgang Maas |last2=Nachtschlaeger |first2=T. |last3=Markram |first3=H. |year=2002 |title=Real-time computing without stable states: A new framework for neural computation based on perturbations |journal=Neural Computation |volume=14 |issue=11 |pages=2531–2560|doi=10.1162/089976602760407955 |pmid=12433288 |s2cid=1045112 }}&lt;/ref&gt; and [[echo state network]]s&lt;ref&gt;[[Herbert Jaeger|Jaeger, Herbert]], "The echo state approach to analyzing and training recurrent neural networks." Technical Report 154 (2001), German National Research Center for Information Technology.&lt;/ref&gt; are two major types of reservoir computing.&lt;ref&gt;[http://www.scholarpedia.org/article/Echo_state_network Echo state network], Scholarpedia&lt;/ref&gt;}}

{{term|[[Resource Description Framework]] (RDF)}}
{{defn|A family of [[World Wide Web Consortium]] (W3C) [[specification]]s&lt;ref&gt;{{Cite web |url=http://www.dblab.ntua.gr/~bikakis/XMLSemanticWebW3CTimeline.pdf |title=XML and Semantic Web W3C Standards Timeline |date=2012-02-04}}&lt;/ref&gt; originally designed as a [[metadata]] [[data model]]. It has come to be used as a general method for conceptual description or modeling of information that is implemented in [[web resource]]s, using a variety of syntax notations and [[data serialization]] formats. It is also used in [[knowledge management]] applications.}}

{{term|[[restricted Boltzmann machine]] (RBM)}}
{{defn|A [[generative model|generative]] [[stochastic neural network|stochastic]] {{gli|artificial neural network}} that can learn a [[probability distribution]] over its set of inputs.}}

{{term|[[Rete algorithm]]}}
{{defn|A [[pattern matching]] {{gli|algorithm}} for implementing [[rule-based system]]s. The algorithm was developed to efficiently apply many [[Rule of inference|rules]] or patterns to many objects, or [[fact]]s, in a [[knowledge base]]. It is used to determine which of the system's rules should fire based on its data store, its facts.}}

{{term|[[robotics]]}}
{{defn|An interdisciplinary branch of science and engineering that includes [[mechanical engineering]], [[electronic engineering]], [[Information engineering (field)|information engineering]], [[computer science]], and others. Robotics deals with the design, construction, operation, and use of [[robot]]s, as well as [[computer system]]s for their control, [[sensory feedback]], and [[information processing]].}}

{{term|[[rule-based system]]}}
{{defn|In [[computer science]], a rule-based system is used to store and manipulate knowledge to interpret information in a useful way. It is often used in artificial intelligence applications and research.  Normally, the term ''rule-based system'' is applied to systems involving human-crafted or curated rule sets.  Rule-based systems constructed using automatic rule inference, such as [[rule-based machine learning]], are normally excluded from this system type.}}
{{glossaryend}}

==S==
{{glossary}}
{{term|[[satisfiability]]}}
{{defn|In [[mathematical logic]], satisfiability and [[Validity (logic)|validity]] are elementary concepts of [[semantics]]. A [[formula (mathematical logic)|formula]] is ''satisfiable'' if it is possible to find an [[interpretation (logic)|interpretation]] ([[model theory|model]]) that makes the formula true.&lt;ref&gt;See, for example, Boolos and Jeffrey, 1974, chapter 11.&lt;/ref&gt;  A formula is ''valid'' if all interpretations make the formula true. The opposites of these concepts are unsatisfiability and invalidity, that is, a formula is ''unsatisfiable'' if none of the interpretations make the formula true, and ''invalid'' if some such interpretation makes the formula false. These four concepts are related to each other in a manner exactly analogous to [[Aristotle]]'s [[square of opposition]].}}

{{term|[[search algorithm]]}}
{{defn|Any {{gli|algorithm}} which solves the [[search problem]], namely, to retrieve information stored within some data structure, or calculated in the [[Feasible region|search space]] of a [[problem domain]], either with [[Continuous or discrete variable|discrete or continuous values]].}}

{{term|[[selection (genetic algorithm)|selection]]}}
{{defn|The stage of a {{gli|genetic algorithm}} in which individual genomes are chosen from a population for later breeding (using the [[Crossover (genetic algorithm)|crossover operator]]).}}

{{term|[[self-management (computer science)|self-management]]}}
{{defn|The process by which computer systems manage their own operation without human intervention.}}

{{term|[[semantic network]]}}
{{ghat|Also '''frame network'''.}}
{{defn|A [[knowledge base]] that represents [[Semantics|semantic]] relations between [[concept]]s in a network. This is often used as a form of [[Knowledge representation and reasoning|knowledge representation]]. It is a [[directed graph|directed]] or [[undirected graph]] consisting of [[vertex (graph theory)|vertices]], which represent [[concept]]s, and [[graph theory|edges]], which represent [[semantic relationship|semantic relations]] between concepts,&lt;ref name="Sowa"&gt;{{Cite encyclopedia |year=1987 |title=Semantic Networks |encyclopedia=Encyclopedia of Artificial Intelligence |url=http://www.jfsowa.com/pubs/semnet.htm |access-date=2008-04-29 |author-link=John F. Sowa |editor-last=Shapiro |editor-first=Stuart C |last1=Sowa |first1=John F.}}&lt;/ref&gt; mapping or connecting [[semantic field]]s.}}

{{term|[[semantic reasoner]]}}
{{ghat|Also '''reasoning engine''', '''rules engine''', or simply '''reasoner'''.}}
{{defn|A piece of software able to infer [[logical consequence]]s from a set of asserted facts or [[axioms]]. The notion of a semantic reasoner generalizes that of an [[inference engine]], by providing a richer set of mechanisms to work with. The [[inference rules]] are commonly specified by means of an [[ontology language]], and often a [[description logic]] language. Many reasoners use [[first-order predicate logic]] to perform reasoning; inference commonly proceeds by {{gli|forward chaining}} and {{gli|backward chaining}}.}}

{{term|[[semantic query]]}}
{{defn|Allows for queries and analytics of associative and [[Contextualization (computer science)|contextual]] nature. Semantic queries enable the retrieval of both explicitly and implicitly derived information based on syntactic, semantic and structural information contained in data. They are designed to deliver precise results (possibly the distinctive selection of one single piece of information) or to answer more fuzzy and wide-open questions through [[pattern matching]] and [[Reasoning system|digital reasoning]].}}

{{term|[[semantics (computer science)|semantics]]}}
{{defn|In [[programming language theory]], semantics is the field concerned with the rigorous mathematical study of the meaning of {{gli|programming language|programming languages}}. It does so by evaluating the meaning of [[programming language syntax|syntactically]] valid [[String (computer science)|strings]] defined by a specific programming language, showing the computation involved. In such a case that the evaluation would be of syntactically invalid strings, the result would be non-computation. Semantics describes the processes a computer follows when executing a program in that specific language. This can be shown by describing the relationship between the input and output of a program, or an explanation of how the program will be executed on a certain [[computer platform|platform]], hence creating a [[model of computation]].}}

{{term|[[sensor fusion]]}}
{{defn|The combining of [[sensor]]y data or data derived from disparate sources such that the resulting [[information]] has less uncertainty than would be possible when these sources were used individually.}}

{{term|[[separation logic]]}}
{{defn|An extension of [[Hoare logic]], a way of reasoning about programs. The assertion language of separation logic is a special case of the [[logic of bunched implications]] (BI).&lt;ref name="bi"&gt;{{Cite journal |last1=O'Hearn |first1=P. W. |last2=Pym |first2=D. J. |date=June 1999 |title=The Logic of Bunched Implications |journal=[[Bulletin of Symbolic Logic]] |volume=5 |pages=215–244 |citeseerx=10.1.1.27.4742 |doi=10.2307/421090 |jstor=421090 |number=2}}&lt;/ref&gt;}}

{{term|[[similarity learning]]}}
{{defn|An area of supervised {{gli|machine learning}} in artificial intelligence. It is closely related to [[regression (machine learning)|regression]] and [[classification in machine learning|classification]], but the goal is to learn from a similarity function that measures how similar or related two objects are. It has applications in [[ranking]], in [[recommendation systems]], visual identity tracking, face verification, and speaker verification.}}

{{term|[[simulated annealing]] (SA)}}
{{defn|A [[probabilistic algorithm|probabilistic technique]] for approximating the [[global optimum]] of a given [[function (mathematics)|function]]. Specifically, it is a [[metaheuristic]] to approximate [[global optimization]] in a large [[solution space|search space]] for an [[optimization problem]].}}

{{term|[[Artificial intelligence, situated approach|situated approach]]}}
{{defn|In artificial intelligence research, the situated approach builds agents that are designed to behave effectively successfully in their environment. This requires designing AI "from the bottom-up" by focussing on the basic perceptual and motor skills required to survive. The situated approach gives a much lower priority to abstract reasoning or problem-solving skills.}}

{{term|[[situation calculus]]}}
{{defn|A [[logic]] formalism designed for representing and reasoning about dynamical domains.}}

{{term|[[SLD resolution|Selective Linear Definite clause resolution]]}}
{{ghat|Also simply '''SLD resolution'''.}}
{{defn|The basic [[rule of inference|inference rule]] used in [[logic programming]]. It is a refinement of [[Resolution (logic)|resolution]], which is both [[Soundness|sound]] and refutation [[Completeness (logic)|complete]] for [[Horn clause]]s.}}

{{term|[[software]]}}
{{defn|A collection of [[data (computing)|data]] or [[computer]] instructions that tell the computer how to work. This is in contrast to [[Computer hardware|physical hardware]], from which the system is built and actually performs the work. In [[computer science]] and [[software engineering]], computer software is all [[information]] processed by [[computer system]]s, [[Computer program|program]]s and [[data]]. Computer software includes [[computer program]]s, [[Library (computing)|libraries]] and related non-executable [[Data (computing)|data]], such as [[Software documentation|online documentation]] or [[digital media]].}}

{{term|[[software engineering]]}}
{{defn|The application of [[engineering]] to the [[software development|development]] of [[software]] in a systematic method.&lt;ref name="BoDu04"&gt;{{harvnb |Abran |Moore |Bourque| Dupuis |2004 |pp=1–1}}&lt;/ref&gt;&lt;ref&gt;{{Cite web |url=http://computingcareers.acm.org/?page_id=12 |title=Computing Degrees &amp; Careers |year=2007 |publisher=ACM |url-status=dead |archive-url=https://web.archive.org/web/20110617053818/http://computingcareers.acm.org/?page_id=12 |archive-date=17 June 2011 |access-date=2010-11-23}}&lt;/ref&gt;&lt;ref&gt;{{Cite book |last1=Laplante |first1=Phillip |url=https://books.google.com/books?id=pFHYk0KWAEgC&amp;q=What%20Every%20Engineer%20Should%20Know%20about%20Software%20Engineering.&amp;pg=PA1 |title=What Every Engineer Should Know about Software Engineering |publisher=CRC |year=2007 |isbn=978-0-8493-7228-5 |location=Boca Raton |access-date=2011-01-21}}&lt;/ref&gt;}}

{{term|[[spatial-temporal reasoning]]}}
{{defn|An area of artificial intelligence which draws from the fields of [[computer science]], [[cognitive science]], and [[cognitive psychology]]. The theoretic goal—on the cognitive side—involves representing and reasoning spatial-temporal knowledge in mind. The applied goal—on the computing side—involves developing high-level control systems of automata for [[robotic navigation|navigating]] and understanding time and space.}}

{{term|[[SPARQL]]}}
{{defn|An [[RDF query language]]—that is, a [[Semantic Query|semantic]] [[query language]] for [[database]]s—able to retrieve and manipulate data stored in [[Resource Description Framework|Resource Description Framework (RDF)]] format.&lt;ref&gt;{{Cite web |url=http://www.eweek.com/development/sparql-will-make-the-web-shine |title=SPARQL Will Make the Web Shine |last1=Rapoza |first1=Jim |date=2 May 2006 |website=[[eWeek]] |access-date=2007-01-17}}&lt;/ref&gt;&lt;ref&gt;{{Cite book |last1=Segaran |first1=Toby |title=Programming the Semantic Web |url=https://archive.org/details/programmingseman00sega_683 |url-access=limited |last2=Evans |first2=Colin |last3=Taylor |first3=Jamie |publisher=O’Reilly Media, Inc., 1005 Gravenstein Highway North, Sebastopol, CA 95472 |year=2009 |isbn=978-0-596-15381-6 |page=[https://archive.org/details/programmingseman00sega_683/page/n101 84]}}&lt;/ref&gt;}}

{{term|[[speech recognition]]}}
{{defn|An interdisciplinary subfield of [[computational linguistics]] that develops methodologies and technologies that enables the recognition and [[translation]] of spoken language into text by computers. It is also known as automatic speech recognition (ASR), computer speech recognition or speech to text (STT). It incorporates knowledge and research in the [[linguistics]], [[computer science]], and [[electrical engineering]] fields.}}

{{anchor|spiking neural network}}{{term|[[spiking neural network]] (SNN)}}
{{defn|An {{gli|artificial neural network}} that more closely mimics a natural neural network.&lt;ref name="Maas 1996"&gt;{{Cite journal |last1=Maass |first1=Wolfgang |year=1997 |title=Networks of spiking neurons: The third generation of neural network models |journal=Neural Networks |volume=10 |issue=9 |pages=1659–1671 |doi=10.1016/S0893-6080(97)00011-7 |issn=0893-6080}}&lt;/ref&gt; In addition to [[Artificial neuron|neuronal]] and [[Electrical synapse|synaptic]] state, SNNs incorporate the concept of time into their [[Operating Model]].}}

{{term|[[state (computer science)|state]]}}
{{defn|In [[information technology]] and [[computer science]], a program is described as stateful if it is designed to remember preceding events or user interactions;&lt;ref&gt;{{Cite web |url=http://whatis.techtarget.com/definition/stateless |title=What is stateless? - Definition from WhatIs.com |website=techtarget.com}}&lt;/ref&gt; the remembered information is called the state of the system.}}

{{term|[[statistical classification]]}}
{{defn|In {{gli|machine learning}} and [[statistics]], classification is the problem of identifying to which of a set of [[categorical data|categories]] (sub-populations) a new observation belongs, on the basis of a [[training set]] of data containing observations (or instances) whose category membership is known.  Examples are assigning a given email to the [[Spam filtering|"spam" or "non-spam"]] class, and assigning a diagnosis to a given patient based on observed characteristics of the patient (sex, blood pressure, presence or absence of certain symptoms, etc.).  Classification is an example of [[pattern recognition]].}}

{{anchor|statistical relational learning}}{{term|[[statistical relational learning]] (SRL)}}
{{defn|A subdiscipline of artificial intelligence and {{gli|machine learning}} that is concerned with [[domain model]]s that exhibit both [[uncertainty]] (which can be dealt with using statistical methods) and complex, [[relation (mathematics)|relational]] structure.&lt;ref name="Getoor2007"&gt;[[Lise Getoor]] and [[Ben Taskar]]: ''[https://books.google.com/books?id=lSkIewOw2WoC&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false Introduction to statistical relational learning]'', MIT Press, 2007&lt;/ref&gt;&lt;ref&gt;Ryan A. Rossi, Luke K. McDowell, David W. Aha, and Jennifer Neville, "[http://www.jair.org/media/3659/live-3659-6589-jair.pdf  Transforming Graph Data for Statistical Relational Learning.]"  ''Journal of Artificial Intelligence Research (JAIR)'', '''Volume 45''' (2012), pp. 363-441.&lt;/ref&gt; Note that SRL is sometimes called Relational Machine Learning (RML) in the literature. Typically, the [[knowledge representation]] formalisms developed in SRL use (a subset of) [[first-order logic]] to describe relational properties of a domain in a general manner ([[universal quantification]]) and draw upon [[probabilistic graphical model]]s (such as [[Bayesian network]]s or [[Markov network]]s) to model the uncertainty; some also build upon the methods of [[inductive logic programming]].}}

{{term|[[stochastic optimization]] (SO)}}
{{defn|Any [[optimization (mathematics)|optimization]] [[iterative method|method]] that generates and uses [[random variable]]s. For stochastic problems, the random variables appear in the formulation of the optimization problem itself, which involves random [[objective function]]s or random constraints. Stochastic optimization methods also include methods with random iterates. Some stochastic optimization methods use random iterates to solve stochastic problems, combining both meanings of stochastic optimization.&lt;ref name="spall2003"&gt;{{Cite book |last1=Spall |first1=J. C. |url=http://www.jhuapl.edu/ISSO |title=Introduction to Stochastic Search and Optimization |publisher=Wiley |year=2003 |isbn=978-0-471-33052-3}}&lt;/ref&gt; Stochastic optimization methods generalize [[deterministic system (mathematics)|deterministic]] methods for deterministic problems.}}

{{term|[[stochastic semantic analysis]]}}
{{defn|An approach used in [[computer science]] as a [[semantic]] component of [[natural language understanding]]. Stochastic models generally use the definition of segments of words as basic semantic units for the semantic models, and in some cases involve a two layered approach.&lt;ref&gt;''Language Understanding Using Two-Level Stochastic Models'' by F. Pla, et al, 2001, Springer Lecture Notes in Computer Science {{ISBN|978-3-540-42557-1}}&lt;/ref&gt;}}

{{term|[[Stanford Research Institute Problem Solver]] (STRIPS)}}
{{defn|}}

{{term|[[subject-matter expert]]}}
{{defn|}}

{{term|[[superintelligence]]}}
{{defn|A hypothetical {{gli|intelligent agent|agent}} that possesses [[intelligence]] far surpassing that of the [[genius|brightest]] and most [[intellectual giftedness|gifted]] human minds. Superintelligence may also refer to a property of problem-solving systems (e.g., superintelligent language translators or engineering assistants) whether or not these high-level intellectual competencies are embodied in agents that act within the physical world. A superintelligence may or may not be created by an {{gli|intelligence explosion}} and be associated with a {{gli|technological singularity}}.}}

{{term|[[supervised learning]]}}
{{defn|The {{gli|machine learning}} task of learning a function that maps an input to an output based on example input-output pairs.&lt;ref&gt;Stuart J. Russell, Peter Norvig (2010) ''[[Artificial Intelligence: A Modern Approach]], Third Edition'', Prentice Hall {{ISBN|9780136042594}}.&lt;/ref&gt; It infers a function from ''{{vanchor|labeled [[training set|training data]]|LABELLED_DATA}}'' consisting of a set of ''training examples''.&lt;ref&gt;[[Mehryar Mohri]], Afshin Rostamizadeh, Ameet Talwalkar (2012) ''Foundations of Machine Learning'', The MIT Press {{ISBN|9780262018258}}.&lt;/ref&gt;  In supervised learning, each example is a ''pair'' consisting of an input object (typically a vector) and a desired output value (also called the ''supervisory signal'').  A supervised learning algorithm analyzes the training data and produces an inferred function, which can be used for mapping new examples. An optimal scenario will allow for the algorithm to correctly determine the class labels for unseen instances. This requires the learning algorithm to generalize from the training data to unseen situations in a "reasonable" way (see [[inductive bias]]).}}

{{term|[[support-vector machine]]s}}
{{defn|In {{gli|machine learning}}, support-vector machines (SVMs, also support-vector networks&lt;ref&gt;{{Cite journal |last1=Cortes |first1=Corinna |last2=Vapnik |first2=Vladimir N |year=1995 |title=Support-vector networks |journal=Machine Learning |volume=20 |issue=3 |pages=273–297 |doi=10.1007/BF00994018 |doi-access=free}}&lt;/ref&gt;) are [[supervised learning]] models with associated learning {{gli|algorithm|algorithms}} that analyze data used for [[Statistical classification|classification]] and [[regression analysis]].}}

{{anchor|swarm intelligence}}{{term|[[swarm intelligence]] (SI)}}
{{defn|The [[collective behavior]] of [[decentralization|decentralized]], [[Self-organization|self-organized]] systems, either natural or artificial. The expression was introduced in the context of cellular robotic systems.&lt;ref&gt;{{Cite book |last1=Beni|first1=G. |last2=Wang |first2=J. |title=Proceed. NATO Advanced Workshop on Robots and Biological Systems, Tuscany, Italy, June 26–30 (1989) |year=1993 |isbn=978-3-642-63461-1 |pages=703–712 |chapter=Swarm Intelligence in Cellular Robotic Systems |doi=10.1007/978-3-642-58069-7_38}}&lt;/ref&gt;}}

{{term|[[symbolic artificial intelligence]]}}
{{defn|The term for the collection of all methods in {{gli|artificial intelligence}} research that are based on high-level "symbolic" (human-readable) representations of problems, [[Formal logic|logic]], and {{gli|search algorithm|search}}.}}

{{anchor|synthetic intelligence}}{{term|[[synthetic intelligence]] (SI)}}
{{defn|An alternative term for {{gli|artificial intelligence}} which emphasizes that the intelligence of machines need not be an imitation or in any way artificial; it can be a genuine form of intelligence.{{sfn|Haugeland|1985|p=255}}{{sfn|Poole|Mackworth|Goebbel|1998|p=1}}}}

{{term|[[systems neuroscience]]}}
{{defn|A subdiscipline of [[neuroscience]] and [[systems biology]] that studies the structure and function of neural circuits and systems.  It is an umbrella term, encompassing a number of areas of study concerned with how [[neuron|nerve cells]] behave when connected together to form [[neural pathway]]s, [[neural circuit]]s, and larger [[large scale brain networks|brain networks]].}}
{{glossaryend}}

{{Compact ToC|side=yes|center=yes|top=yes|num=yes|extlinks=yes|seealso=yes|refs=yes|nobreak=yes|}}

==T==
{{glossary}}
{{term|[[technological singularity]]}}
{{ghat|Also simply '''the singularity'''.}}
{{defn|A [[hypothetical]] point in the future when technological growth becomes uncontrollable and irreversible, resulting in unfathomable changes to human civilization.&lt;ref&gt;{{Cite web |url=http://www.singularitysymposium.com/definition-of-singularity.html |title=Collection of sources defining "singularity" |website=singularitysymposium.com |access-date=17 April 2019}}&lt;/ref&gt;&lt;ref name="Singularity hypotheses"&gt;{{Cite book |last1=Eden |first1=Amnon H. |title=Singularity hypotheses: A Scientific and Philosophical Assessment |url=https://archive.org/details/singularityhypot00mueh |url-access=limited |last2=Moor, James H. |date=2012 |publisher=Springer |isbn=9783642325601 |location=Dordrecht |pages=[https://archive.org/details/singularityhypot00mueh/page/n9 1]–2}}&lt;/ref&gt;&lt;ref&gt;Cadwalladr, Carole (2014). "[https://www.theguardian.com/technology/2014/feb/22/robots-google-ray-kurzweil-terminator-singularity-artificial-intelligence Are the robots about to rise? Google's new director of engineering thinks so…]" ''The Guardian''. Guardian News and Media Limited.&lt;/ref&gt;}}

{{term|[[temporal difference learning]]}}
{{defn|A class of [[Model-free (reinforcement learning)|model-free]] {{gli|reinforcement learning}} methods which learn by [[Bootstrapping (statistics)|bootstrapping]] from the current estimate of the value function. These methods sample from the environment, like [[Monte Carlo method]]s, and perform updates based on current estimates, like [[dynamic programming]] methods.&lt;ref name="RSutton-1998"&gt;{{Cite book |last1=Sutton |first1=Richard |url=http://incompleteideas.net/sutton/book/the-book.html |title=Reinforcement Learning |last2=Andrew Barto |publisher=MIT Press |year=1998 |isbn=978-0-585-02445-5 |archive-url=https://web.archive.org/web/20170330005640/http://incompleteideas.net/sutton/book/the-book.html |archive-date=2017-03-30 |url-status=dead |name-list-style=amp}}&lt;/ref&gt;}}

{{term|[[tensor network theory]]}}
{{defn|A theory of [[brain]] function (particularly that of the [[cerebellum]]) that provides a mathematical model of the [[transformation geometry|transformation]] of sensory [[space-time]] coordinates into motor coordinates and vice versa by cerebellar [[neuronal networks]]. The theory was developed as a [[geometrization]] of brain function (especially of the [[central nervous system]]) using [[tensor]]s.&lt;!--  --&gt;&lt;ref name="Neuroscience1980-Pellionisz"&gt;{{Cite journal |last1=Pellionisz |first1=A. |last2=Llinás |first2=R. |year=1980 |title=Tensorial Approach To The Geometry Of Brain Function: Cerebellar Coordination Via A Metric Tensor |url=https://www.academia.edu/download/31409354/pellionisz_1980_cerebellar_coordination_via_a_metric_tensor_fullpaper.pdf |journal=Neuroscience |volume=5 |issue=7 |pages=1125––1136 |doi=10.1016/0306-4522(80)90191-8 |pmid=6967569|s2cid=17303132 }}&lt;/ref&gt;&lt;!--  --&gt;&lt;ref name="Neuroscience1985-Pellionisz"&gt;{{Cite journal |last1=Pellionisz |first1=A.  |last2=Llinás |first2=R. |year=1985 |title=Tensor Network Theory Of The Metaorganization Of Functional Geometries In The Central Nervous System |journal=Neuroscience |volume=16 |issue=2 |pages=245–273 |doi=10.1016/0306-4522(85)90001-6 |pmid=4080158|s2cid=10747593 }}&lt;/ref&gt;}}

{{term|[[TensorFlow]]}}
{{defn|A [[Free software|free]] and {{gli|open-source software|open-source}} [[Library (computing)|software library]] for [[dataflow programming|dataflow]] and [[differentiable programming|differentiable]] programming across a range of tasks. It is a symbolic math library, and is also used for {{gli|machine learning}} applications such as {{gli|neural network|neural networks}}.&lt;ref name="YoutubeClip"&gt;[https://www.youtube.com/watch?v=oZikw5k_2FM "TensorFlow: Open source machine learning"] "It is machine learning software being used for various kinds of perceptual and language understanding tasks" — Jeffrey Dean, minute 0:47 / 2:17 from YouTube clip&lt;/ref&gt;}}

{{term|[[theoretical computer science]] (TCS)}}
{{defn|A subset of general [[computer science]] and [[mathematics]] that focuses on more mathematical topics of computing and includes the [[theory of computation]].}}

{{term|[[theory of computation]]}}
{{defn|In [[theoretical computer science]] and [[mathematics]], the theory of computation is the branch that deals with how efficiently problems can be solved on a [[model of computation]], using an {{gli|algorithm}}. The field is divided into three major branches: [[automata theory]] and languages, [[computability theory]], and {{gli|computational complexity theory}}, which are linked by the question: ''"What are the fundamental capabilities and limitations of computers?".''&lt;ref name="Sipser-3rd"&gt;{{Cite book |last1=Sipser |first1=Michael |title=Introduction to the Theory of Computation 3rd |publisher=Cengage Learning |year=2013 |isbn=978-1-133-18779-0 |quote=central areas of the theory of computation: automata, computability, and complexity. (Page 1) |author-link=Michael Sipser}}&lt;/ref&gt;}}

{{term|[[Thompson sampling]]}}
{{defn|A {{gli|heuristic}} for choosing actions that addresses the exploration-exploitation dilemma in the [[multi-armed bandit]] problem. It consists in choosing the action that maximizes the expected reward with respect to a randomly drawn belief.&lt;ref&gt;{{Cite journal |last1=Thompson |first1=William R |year=1933 |title=On the likelihood that one unknown probability exceeds another in view of the evidence of two samples |journal=Biometrika |volume=25 |issue=3–4 |pages=285–294 |doi=10.1093/biomet/25.3-4.285}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |last1=Russo |first1=Daniel J. |last2=Van Roy |first2=Benjamin |last3=Kazerouni |first3=Abbas |last4=Osband |first4=Ian |last5=Wen |first5=Zheng |year=2018 |title=A Tutorial on Thompson Sampling |journal=Foundations and Trends in Machine Learning |volume=11 |issue=1 |pages=1–96 |arxiv=1707.02038 |doi=10.1561/2200000070|s2cid=3929917 }}&lt;/ref&gt;}}

{{term|[[time complexity]]}}
{{defn|The [[computational complexity]] that describes the amount of time it takes to run an {{gli|algorithm}}. Time complexity is commonly estimated by counting the number of elementary operations performed by the algorithm, supposing that each elementary operation takes a fixed amount of time to perform. Thus, the amount of time taken and the number of elementary operations performed by the algorithm are taken to differ by at most a [[constant factor]].}}

{{term|[[transhumanism]]}}
{{ghat|Abbreviated '''H+''' or '''h+'''.}}
{{defn|An international [[school of thought|philosophical movement]] that advocates for the transformation of the [[human condition]] by developing and making widely available sophisticated technologies to greatly [[human enhancement|enhance human]] intellect and physiology.&lt;ref name="Mercer"&gt;{{Cite book |last1=Mercer |first1=Calvin |title=Religion and Transhumanism: The Unknown Future of Human Enhancement |publisher=Praeger}}&lt;/ref&gt;&lt;ref name="Bostrom 2005"&gt;{{Cite journal |last1=Bostrom |first1=Nick |author-link=Nick Bostrom |year=2005 |title=A history of transhumanist thought |url=http://www.nickbostrom.com/papers/history.pdf |journal=[[Journal of Evolution and Technology]] |access-date=February 21, 2006}}&lt;/ref&gt;}}

{{term|[[transition system]]}}
{{defn|In [[theoretical computer science]], a transition system is a concept used in the study of [[computation]]. It is used to describe the potential behavior of {{gli|discrete system|discrete systems}}. It consists of [[state (computer science)|states]] and transitions between states, which may be labeled with labels chosen from a set; the same label may appear on more than one transition. If the label set is a [[Singleton (mathematics)|singleton]], the system is essentially unlabeled, and a simpler definition that omits the labels is possible.}}

{{term|[[tree traversal]]}}
{{ghat|Also '''tree search'''.}}
{{defn|A form of [[graph traversal]] and refers to the process of visiting (checking and/or updating) each node in a [[Tree (data structure)|tree data structure]], exactly once. Such traversals are classified by the order in which the nodes are visited.}}

{{term|[[true quantified Boolean formula]]}}
{{defn|In {{gli|computational complexity theory}}, the language TQBF is a {{gli|formal language}} consisting of the true quantified Boolean formulas.  A (fully) quantified Boolean formula is a formula in [[Quantification (logic)|quantified]] [[propositional logic]] where every variable is quantified (or [[Bound variable|bound]]), using either [[existential quantification|existential]] or [[universal quantification|universal]] quantifiers, at the beginning of the sentence. Such a formula is equivalent to either true or false (since there are no [[Bound variable|free]] variables). If such a formula evaluates to true, then that formula is in the language TQBF. It is also known as QSAT (Quantified {{gli|Boolean satisfiability problem|SAT}}).}}

{{term|[[Turing machine]]}}
{{defn|}}

{{term|[[Turing test]]}}
{{defn|A test of a machine's ability to exhibit intelligent behaviour equivalent to, or indistinguishable from, that of a human, developed by [[Alan Turing]] in 1950. Turing proposed that a human evaluator would [[natural language understanding|judge natural language conversations]] between a human and a machine designed to generate human-like responses. The evaluator would be aware that one of the two partners in conversation is a machine, and all participants would be separated from one another. The conversation would be limited to a text-only channel such as a [[keyboard (computing)|computer keyboard]] and [[visual display unit|screen]] so the result would not depend on the machine's ability to render words as speech.&lt;ref&gt;Turing originally suggested a [[teleprinter]], one of the few text-only communication systems available in 1950. {{Harv|Turing|1950|p=433}}&lt;/ref&gt; If the evaluator cannot reliably tell the machine from the human, the machine is said to have passed the test. The test results do not depend on the machine's ability to give correct answers to questions, only how closely its answers resemble those a human would give.}}

{{term|[[type system]]}}
{{defn|In {{gli|programming language|programming languages}}, a set of rules that assigns a property called [[type (computer science)|type]] to the various constructs of a [[computer program]], such as [[variable (computer science)|variables]], [[expression (computer science)|expressions]], [[function (computer science)|functions]], or [[modular programming|modules]].{{sfn|Pierce|2002|p=1|ps=: "A type system is a tractable syntactic method for proving the absence of certain program behaviors by classifying phrases according to the kinds of values they compute."}} These types formalize and enforce the otherwise implicit categories the programmer uses for [[algebraic data type]]s, data structures, or other components (e.g. "string", "array of float", "function returning boolean"). The main purpose of a type system is to reduce possibilities for [[bug (computer programming)|bugs]] in computer programs{{sfn|Cardelli|2004|p=1|ps=: "The fundamental purpose of a type system is to prevent the occurrence of execution errors during the running of a program."}} by defining [[Interface (computer science)|interfaces]] between different parts of a computer program, and then checking that the parts have been connected in a consistent way. This checking can happen statically (at [[compile time]]), dynamically (at [[run time (program lifecycle phase)|run time]]), or as a combination of static and dynamic checking. Type systems have other purposes as well, such as expressing business rules, enabling certain compiler optimizations, allowing for [[multiple dispatch]], providing a form of documentation, etc.}}
{{glossaryend}}

==U==
{{glossary}}
{{term|[[unsupervised learning]]}}
{{defn|A type of self-organized [[Hebbian learning]] that helps find previously unknown patterns in data set without pre-existing labels. It is also known as [[self-organization]] and allows modeling [[Probability density function|probability densities]] of given inputs.&lt;ref name="Hinton99a"&gt;{{Cite book |last1=Hinton |first1=Jeffrey |title=Unsupervised Learning: Foundations of Neural Computation |last2=Sejnowski |first2=Terrence |publisher=MIT Press |year=1999 |isbn=978-0262581684}}&lt;/ref&gt; It is one of the main three categories of machine learning, along with [[supervised learning|supervised]] and {{gli|reinforcement learning}}. Semi-supervised learning has also been described and is a hybridization of supervised and unsupervised techniques.}}
{{glossaryend}}

==V==
{{glossary}}
{{term|[[vision processing unit]] (VPU)}}
{{defn|A type of [[microprocessor]] designed to [[hardware acceleration|accelerate]] {{gli|machine vision}} tasks.&lt;ref&gt;{{Cite web |url=http://www.tomshardware.com/news/movidiud-myriad2-vpu-vision-processing-vr,30850.html |title=A third type of processor for AR/VR: Movidius' Myriad 2 VPU |last1=Colaner |first1=Seth |last2=Humrick |first2=Matthew |date=January 3, 2016 |website=Tom's Hardware}}&lt;/ref&gt;&lt;ref&gt;{{Cite web |url=http://www.digit.in/general/the-rise-of-vpus-giving-eyes-to-machines-29561.html |title=The rise of VPUs: Giving Eyes to Machines |last1=Banerje |first1=Prasid |date=March 28, 2016 |website=Digit.in}}&lt;/ref&gt;{{citation needed span|Value-alignment complete – Analogous to an [[AI-complete]] problem, a value-alignment complete problem is a problem where the [[AI control problem]] needs to be fully solved to solve it.|date=January 2019}}}}
{{glossaryend}}

==W==
{{glossary}}
{{term|[[Watson (computer)|Watson]]}}
{{defn|A [[question answering|question-answering]] computer system capable of answering questions posed in [[natural language]],&lt;ref name="ibm"&gt;{{Cite web |url=http://www.research.ibm.com/deepqa/faq.shtml |title=DeepQA Project: FAQ |website=IBM |access-date=February 11, 2011}}&lt;/ref&gt; developed in [[IBM]]'s DeepQA project by a research team led by [[principal investigator]] [[David Ferrucci]].&lt;ref&gt;{{Cite journal |last1=Ferrucci |first1=David |last2=Levas |first2=Anthony |last3=Bagchi |first3=Sugato |last4=Gondek |first4=David |last5=Mueller |first5=Erik T. |date=2013-06-01 |title=Watson: Beyond Jeopardy! |journal=Artificial Intelligence |volume=199 |pages=93–105 |doi=10.1016/j.artint.2012.06.009 |doi-access=free}}&lt;/ref&gt; Watson was named after IBM's first CEO, industrialist [[Thomas J. Watson]].&lt;ref name="NYT_20110208"&gt;{{Cite news |last1=Hale |first1=Mike |url=https://www.nytimes.com/2011/02/09/arts/television/09nova.html |title=Actors and Their Roles for $300, HAL? HAL! |date=February 8, 2011 |work=[[The New York Times]] |access-date=February 11, 2011}}&lt;/ref&gt;&lt;ref&gt;{{Cite web |url=http://www.research.ibm.com/deepqa/deepqa.shtml |title=The DeepQA Project |website=IBM Research |access-date=February 18, 2011}}&lt;/ref&gt;}}

{{term|[[weak AI]]}}
{{ghat|Also '''narrow AI'''.}}
{{defn|{{gli|artificial intelligence|Artificial intelligence}} that is focused on one narrow task.&lt;ref&gt;io9.com mentions narrow AI. Published 1 April 2013. Retrieved 16 February 2014: http://io9.com/how-much-longer-before-our-first-ai-catastrophe-464043243&lt;/ref&gt;&lt;ref&gt;AI researcher Ben Goertzel explains why he became interested in AGI instead of narrow AI. Published 18 Oct 2013. Retrieved 16 February 2014. http://intelligence.org/2013/10/18/ben-goertzel/&lt;/ref&gt;&lt;ref&gt;TechCrunch discusses AI App building regarding Narrow AI. Published 16 Oct 2015. Retrieved 17 Oct 2015. https://techcrunch.com/2015/10/15/machine-learning-its-the-hard-problems-that-are-valuable/&lt;/ref&gt;}}

{{term|[[World Wide Web Consortium]] (W3C)}}
{{defn|The main international [[standards organization]] for the [[World Wide Web]] (abbreviated WWW or W3).}}
{{glossaryend}}

{{Compact ToC|side=yes|center=yes|top=yes|num=yes|extlinks=yes|seealso=yes|refs=yes|nobreak=yes|}}

==See also==
* [[Artificial intelligence]]

==References==
{{reflist}}

==Notes==
{{reflist|group=Note}}

{{Software engineering}}
{{Computer science}}
{{Evolutionary computation}}
{{emerging technologies|topics=yes|infocom=yes}}
{{Robotics}}
{{Glossaries of science and engineering}}

[[Category:Glossaries of science|Artificial intelligence]]
[[Category:Artificial intelligence|Glossary of artificial intelligence]]
[[Category:Machine learning]]
[[Category:Glossaries of technology|Artificial intelligence]]</text>
      <sha1>b0w2gh7wtky8hvwocva77t9z9b0ff4q</sha1>
    </revision>
  </page>
  <page>
    <title>Multilinear subspace learning</title>
    <ns>0</ns>
    <id>30909817</id>
    <revision>
      <id>984974445</id>
      <parentid>971264886</parentid>
      <timestamp>2020-10-23T06:09:19Z</timestamp>
      <contributor>
        <username>The Eloquent Peasant</username>
        <id>18054835</id>
      </contributor>
      <comment>Adding [[Wikipedia:Short description|short description]]: "Approach to dimensionality reduction" ([[Wikipedia:Shortdesc helper|Shortdesc helper]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="17459" xml:space="preserve">{{short description|Approach to dimensionality reduction}}
[[File:Video represented as a third-order tensor.jpg|right|thumb|300px|A video or an image sequence represented as a third-order tensor of column x row x time for multilinear subspace learning.]]
'''Multilinear subspace learning''' is an approach to dimensionality reduction.&lt;ref name="Vasilescu2003"&gt;M. A. O. Vasilescu, D. Terzopoulos (2003) [http://www.cs.toronto.edu/~maov/tensorfaces/cvpr03.pdf "Multilinear Subspace Analysis of Image Ensembles"], "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR’03), Madison, WI, June, 2003"&lt;/ref&gt;&lt;ref name="Vasilescu2002tensorfaces"&gt;M. A. O. Vasilescu, D. Terzopoulos (2002) [http://www.cs.toronto.edu/~maov/tensorfaces/Springer%20ECCV%202002_files/eccv02proceeding_23500447.pdf "Multilinear Analysis of Image Ensembles: TensorFaces"],  Proc. 7th European Conference on Computer Vision (ECCV'02), Copenhagen, Denmark, May, 2002&lt;/ref&gt;&lt;ref name="Vasilescu2002hms"&gt;M. A. O. Vasilescu,(2002) [http://www.media.mit.edu/~maov/motionsignatures/hms_icpr02_corrected.pdf "Human Motion Signatures: Analysis, Synthesis, Recognition"], "Proceedings of International Conference on Pattern Recognition (ICPR 2002), Vol. 3, Quebec City, Canada, Aug, 2002, 456–460."&lt;/ref&gt;&lt;ref name="Vasilescu2007"/&gt;&lt;ref name="MSLbook"&gt;{{cite book
 |first=Haiping |last=Lu
 |first2=K.N. |last2=Plataniotis
 |first3=A.N. |last3=Venetsanopoulos
 |url=http://www.crcpress.com/product/isbn/9781439857243
 |title=Multilinear Subspace Learning: Dimensionality Reduction of Multidimensional Data
 |series=Chapman &amp; Hall/CRC Press Machine Learning and Pattern Recognition Series
 |publisher=Taylor and Francis   
 |isbn=978-1-4398572-4-3
 |year=2013
}}&lt;/ref&gt;   
[[Dimension reduction|Dimensionality reduction]] can be performed on a data [[tensor]] whose observations have been vectorized&lt;ref name="Vasilescu2003"/&gt; and organized into a data tensor, or whose observations are matrices that are concatenated into a data tensor.&lt;ref name="MSLsurvey"&gt;{{cite journal
 |first=Haiping |last=Lu
 |first2=K.N. |last2=Plataniotis
 |first3=A.N. |last3=Venetsanopoulos
 |url=http://www.dsp.utoronto.ca/~haiping/Publication/SurveyMSL_PR2011.pdf
 |title=A Survey of Multilinear Subspace Learning for Tensor Data
 |journal=Pattern Recognition
 |volume=44 |number=7 |pages=1540–1551 |year=2011
 |doi=10.1016/j.patcog.2011.01.004
}}&lt;/ref&gt;&lt;ref name="TSAnips"&gt;X. He, D. Cai, P. Niyogi, [http://books.nips.cc/papers/files/nips18/NIPS2005_0249.pdf Tensor subspace analysis], in: [[Advances in Neural Information Processing Systems]]c 18 (NIPS), 2005.&lt;/ref&gt;  Here are some examples of data tensors whose observations are vectorized  or whose observations are matrices concatenated into data tensor [[image]]s (2D/3D), [[video]] sequences (3D/4D), and [[Hyperspectral imaging|hyperspectral cubes]] (3D/4D).

The mapping from a [[high-dimensional vector space]] to a set of lower dimensional [[vector space|vector spaces]] is a [[Multilinear subspace learning#Multilinear projection|multilinear projection]].&lt;ref name="Vasilescu2007"&gt;{{cite conference
 |first=M.A.O. |last=Vasilescu
 |first2=D. |last2=Terzopoulos
 |title=Multilinear Projection for Appearance-Based Recognition in the Tensor Framework
 |conference=IEEE 11th [[International Conference on Computer Vision]]
 |pages=1–8 |year=2007
 |doi=10.1109/ICCV.2007.4409067
}}.  
&lt;/ref&gt; When observations are retained in the same organizational structure as the sensor provides them;  as matrices or higher order tensors, their representations are computed by performing N multiple linear projections.&lt;ref name="MSLsurvey"/&gt;

[[Multilinear subspace learning#Algorithms|Multilinear subspace learning algorithms]] are higher-order generalizations of [[linear subspace]] learning methods such as [[principal component analysis]] (PCA), [[independent component analysis]] (ICA), [[linear discriminant analysis]] (LDA) and [[canonical correlation|canonical correlation analysis]] (CCA).

== Background ==
With the advances in [[data acquisition]] and [[Computer data storage|storage technology]], [[big data]] (or massive data sets) are being generated on a daily basis in a wide range of emerging applications. Most of these big data are multidimensional. Moreover, they are usually very-[[high-dimensional]], with a large amount of redundancy, and only occupying a part of the input space. Therefore, [[Dimension reduction|dimensionality reduction]] is frequently employed to map [[high-dimensional data]] to a low-dimensional space while retaining as much information as possible.

[[Linear subspace]] learning algorithms are traditional dimensionality reduction techniques that represent input data as [[Coordinate vector|vector]]s and solve for an optimal [[linear mapping]] to a lower-dimensional space. Unfortunately, they often become inadequate when dealing with massive multidimensional data. They result in very-high-dimensional vectors, lead to the estimation of a large number of parameters.&lt;ref name="Vasilescu2003"/&gt;&lt;ref name="MSLsurvey"/&gt;&lt;ref name="TSAnips"/&gt;&lt;ref name="MPCA-Lu2008"&gt;H. Lu, K. N. Plataniotis, and A. N. Venetsanopoulos, "[https://dx.doi.org/10.1109/TNN.2007.901277 MPCA: Multilinear principal component analysis of tensor objects]," IEEE Trans. Neural Netw., vol. 19, no. 1, pp. 18–39, January  2008.&lt;/ref&gt;&lt;ref name="DATER"&gt;S. Yan, D. Xu, Q. Yang, L. Zhang, X. Tang, and H.-J. Zhang, "[http://portal.acm.org/citation.cfm?id=1068959 Discriminant analysis with tensor representation]," in Proc. [[IEEE Conference on Computer Vision and Pattern Recognition]], vol. I, June 2005, pp. 526–532.&lt;/ref&gt;

Multilinear Subspace Learning employ different types of data tensor analysis tools for dimensionality reduction.  Multilinear Subspace learning can be applied to observations whose measurements were vectorized and organized into a data tensor,&lt;ref name="Vasilescu2003"/&gt; or whose measurements are treated as a matrix and concatenated into a tensor.&lt;ref&gt;{{cite web |title=Future Directions in Tensor-Based Computation and Modeling |date=May 2009|url=http://www.cs.cornell.edu/cv/tenwork/finalreport.pdf}}&lt;/ref&gt;

== Algorithms ==

=== Multilinear principal component analysis ===
Historically, [[multilinear principal component analysis]] has been referred to as "M-mode PCA", a terminology which was coined by Peter Kroonenberg.&lt;ref name="Kroonenberg1980"&gt;P. M. Kroonenberg and J. de Leeuw, [https://doi.org/10.1007%2FBF02293599 Principal component analysis of three-mode data by means of alternating least squares algorithms], Psychometrika, 45 (1980), pp. 69–97.&lt;/ref&gt;  In 2005, Vasilescu and [[Demetri Terzopoulos|Terzopoulos]] introduced the Multilinear PCA&lt;ref name="MPCA-MICA2005"&gt;M. A. O. Vasilescu, D. Terzopoulos (2005) [http://www.media.mit.edu/~maov/mica/mica05.pdf "Multilinear Independent Component Analysis"], "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR’05), San Diego, CA, June 2005, vol.1, 547–553."&lt;/ref&gt; terminology as a way to better differentiate between multilinear tensor decompositions that computed 2nd order statistics associated with each data tensor mode(axis)s,&lt;ref name="Vasilescu2003"/&gt;&lt;ref name="Vasilescu2002tensorfaces"/&gt;&lt;ref name="Vasilescu2002hms"/&gt;&lt;ref name="Vasilescu2004"&gt;M.A.O. Vasilescu, D. Terzopoulos (2004) [http://www.media.mit.edu/~maov/tensortextures/Vasilescu_siggraph04.pdf "TensorTextures: Multilinear Image-Based Rendering", M. A. O. Vasilescu and D. Terzopoulos, Proc. ACM SIGGRAPH 2004 Conference Los Angeles, CA, August, 2004, in Computer Graphics Proceedings, Annual Conference Series, 2004, 336–342. ]&lt;/ref&gt;&lt;ref name="MPCA-Lu2008"/&gt;and subsequent work on Multilinear Independent Component Analysis&lt;ref name="MPCA-MICA2005"/&gt; that computed higher order statistics associated with each tensor mode/axis. MPCA is an extension of [[Principal component analysis|PCA]].

=== Multilinear independent component analysis ===
[[Multilinear independent component analysis]]&lt;ref name="MPCA-MICA2005"/&gt; is an extension of [[Independent component analysis|ICA]].

=== Multilinear linear discriminant analysis ===
*Multilinear extension of [[linear discriminant analysis|LDA]]
**TTP-based: Discriminant Analysis with Tensor Representation (DATER)&lt;ref name="DATER"/&gt;
**TTP-based: General tensor discriminant analysis (GTDA)&lt;ref&gt;D. Tao, X. Li, X. Wu, and S. J. Maybank, "[https://dx.doi.org/10.1109/TPAMI.2007.1096  General tensor discriminant analysis and gabor features for gait recognition]," IEEE Trans. Pattern Anal. Mach. Intell., vol. 29, no. 10, pp. 1700–1715, October  2007.&lt;/ref&gt;
**TVP-based: Uncorrelated Multilinear Discriminant Analysis (UMLDA)&lt;ref&gt;H. Lu, K. N. Plataniotis, and A. N. Venetsanopoulos, "[https://dx.doi.org/10.1109/TNN.2008.2004625 Uncorrelated multilinear discriminant analysis with regularization and aggregation for tensor object recognition]," IEEE Trans. Neural Netw., vol. 20, no. 1, pp. 103–123, January  2009.&lt;/ref&gt;

=== Multilinear canonical correlation analysis ===
*Multilinear extension of [[canonical correlation analysis|CCA]]
**TTP-based: Tensor Canonical Correlation Analysis (TCCA)&lt;ref&gt;
T.-K. Kim and R. Cipolla. "[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=4547427  Canonical correlation analysis of video volume tensors for action categorization and detection],"  IEEE Trans. Pattern Anal. Mach. Intell.,  vol. 31, no. 8, pp. 1415–1428, 2009.&lt;/ref&gt;
**TVP-based: Multilinear Canonical Correlation Analysis (MCCA)&lt;ref&gt;H.  Lu, "[http://www.dsp.utoronto.ca/~haiping/Publication/MCCA_IJCAI2013.pdf Learning Canonical Correlations of Paired Tensor Sets via Tensor-to-Vector Projection]," Proceedings of the 23rd International Joint Conference on Artificial Intelligence (IJCAI 2013), Beijing, China, August 3–9, 2013.&lt;/ref&gt;
**TVP-based: Bayesian Multilinear Canonical Correlation Analysis (BMTF)&lt;ref&gt;{{Cite book|title=Machine Learning and Knowledge Discovery in Databases|last=Khan|first=Suleiman A.|last2=Kaski|first2=Samuel|date=2014-09-15|publisher=Springer Berlin Heidelberg|isbn=9783662448472|editor-last=Calders|editor-first=Toon|series=Lecture Notes in Computer Science|pages=656–671|language=en|doi=10.1007/978-3-662-44848-9_42|editor-last2=Esposito|editor-first2=Floriana|editor-last3=Hüllermeier|editor-first3=Eyke|editor-last4=Meo|editor-first4=Rosa}}&lt;/ref&gt;

*A TTP is a direct projection of a high-dimensional tensor to a low-dimensional tensor of the same order, using ''N'' projection matrices for an ''N''th-order tensor. It can be performed in ''N'' steps with each step performing a tensor-matrix multiplication (product). The ''N'' steps are exchangeable.&lt;ref name="HOSVD"&gt;L.D.  Lathauwer,  B.D.  Moor,  J.  Vandewalle,  [http://portal.acm.org/citation.cfm?id=354398 A  multilinear  singular  value decomposition], SIAM Journal of Matrix Analysis and Applications vol. 21, no. 4, pp. 1253–1278, 2000&lt;/ref&gt; This projection is an extension of the [[higher-order singular value decomposition]]&lt;ref name="HOSVD"/&gt; (HOSVD) to subspace learning.&lt;ref name="MPCA-Lu2008"/&gt; Hence, its origin is traced back to the [[Tucker decomposition]]&lt;ref&gt;{{Cite journal
 | author = Ledyard R Tucker
 | title = Some mathematical notes on three-mode factor analysis
 | journal = [[Psychometrika]]
 | volume = 31
 | issue = 3
 |date=September 1966
 | doi = 10.1007/BF02289464
 | pages = 279–311
 | pmid = 5221127
| author-link = Ledyard R Tucker
 }}&lt;/ref&gt; in 1960s.

*A TVP is a direct projection of a high-dimensional tensor to a low-dimensional vector, which is also referred to as the rank-one projections. As TVP projects a tensor to a vector, it can be viewed as multiple projections from a tensor to a scalar. Thus, the TVP of a tensor to a ''P''-dimensional vector consists of ''P'' projections from the tensor to a scalar. The projection from a tensor to a scalar is an elementary multilinear projection (EMP). In EMP, a tensor is projected to a point through ''N'' unit projection vectors. It is the projection of a tensor on a single line (resulting a scalar), with one projection vector in each mode. Thus, the TVP of a tensor object to a vector in a ''P''-dimensional vector space consists of ''P'' EMPs. This projection is an extension of the [[CP decomposition|canonical decomposition]],&lt;ref&gt;{{Cite journal
 | author = J. D. Carroll &amp; J. Chang
 | title = Analysis of individual differences in multidimensional scaling via an ''n''-way generalization of 'Eckart–Young' decomposition
 | journal = [[Psychometrika]]
 | volume = 35
 | issue = 3
 | pages = 283–319
 | year = 1970
 | doi = 10.1007/BF02310791
}}&lt;/ref&gt; also known as the [[PARAFAC|parallel factors]] (PARAFAC) decomposition.&lt;ref&gt;R. A. Harshman, [http://publish.uwo.ca/~harshman/wpppfac0.pdf Foundations of the PARAFAC procedure: Models and conditions for an "explanatory" multi-modal factor analysis] {{webarchive|url=https://web.archive.org/web/20041010092429/http://publish.uwo.ca/~harshman/wpppfac0.pdf |date=2004-10-10 }}. UCLA Working Papers in Phonetics, 16, pp. 1–84, 1970.&lt;/ref&gt;

=== Typical approach in MSL ===
There are ''N'' sets of parameters to be solved, one in each mode. The solution to one set often depends on the other sets (except when ''N=1'', the linear case). Therefore, the suboptimal iterative procedure in&lt;ref&gt;L.  D.  Lathauwer,  B.  D.  Moor,  J.  Vandewalle,  [http://portal.acm.org/citation.cfm?id=354405 On  the  best  rank-1  and rank-(R1, R2, ..., RN ) approximation of higher-order tensors], SIAM Journal of Matrix Analysis and Applications 21 (4) (2000) 1324–1342.&lt;/ref&gt; is followed.

#Initialization of the projections in each mode
#For each mode, fixing the projection in all the other mode, and solve for the projection in the current mode.
#Do the mode-wise optimization for a few iterations or until convergence.

This is originated from the alternating least square method for multi-way data analysis.&lt;ref name="Kroonenberg1980"/&gt;

=== Pros and cons ===
[[File:Compactness Comparison of Linear and Multilinear Projections.png|right|thumb|360px|This figure compares the number of parameters to be estimated for the same amount of [[dimension reduction]] by vector-to-vector projection (VVP), (i.e., linear projection,) tensor-to-vector projection (TVP), and tensor-to-tensor projection (TTP).  Multilinear projections require much fewer parameters and the representations obtained are more compact. (This figure is produced based on Table 3 of the survey paper&lt;ref name="MSLsurvey"/&gt;)]]
The advantages of MSL over traditional linear subspace modeling, in common domains where the representation is naturally somewhat tensorial, are:&lt;ref name="MSLsurvey"/&gt;&lt;ref name="TSAnips"/&gt;&lt;ref name="MPCA-Lu2008"/&gt;&lt;ref name="DATER"/&gt;

*MSL preserves the structure and correlation that the original data had before projection, by operating on a natural tensorial representation of the multidimensional data.
*MSL can learn more compact representations than its linear counterpart; in other words, it needs to estimate a much smaller number of parameters. Thus, MSL can handle big tensor data more efficiently, by performing computations on a representation with many fewer dimensions. This leads to lower demand on computational resources.

However, MSL algorithms are iterative and are not guaranteed to converge; where an MSL algorithm does converge, it may do so at a [[local optimum]]. (In contrast, traditional linear subspace modeling techniques often produce an exact closed-form solution.) MSL convergence problems can often be mitigated by choosing an appropriate subspace dimensionality, and by appropriate strategies for initialization, for termination, and for choosing the order in which projections are solved.&lt;ref name="MSLsurvey"/&gt;&lt;ref name="TSAnips"/&gt;&lt;ref name="MPCA-Lu2008"/&gt;&lt;ref name="DATER"/&gt;

== Pedagogical resources ==
* '''Survey''': [https://dx.doi.org/10.1016/j.patcog.2011.01.004 A survey of multilinear subspace learning for tensor data] ([http://www.dsp.utoronto.ca/~haiping/Publication/SurveyMSL_PR2011.pdf open access version]).
* '''Lecture''': [http://videolectures.net/icml08_lu_ump/ Video lecture on UMPCA] at the 25th International Conference on Machine Learning (ICML 2008).

== Code ==
* [https://web.archive.org/web/20110717172720/http://csmr.ca.sandia.gov/~tgkolda/TensorToolbox/ MATLAB Tensor Toolbox] by [[Sandia National Laboratories]].
* [http://www.mathworks.com/matlabcentral/fileexchange/26168 The MPCA algorithm written in Matlab (MPCA+LDA included)].
* [http://www.mathworks.com/matlabcentral/fileexchange/35432 The UMPCA algorithm written in Matlab (data included)].
* [http://www.mathworks.fr/matlabcentral/fileexchange/35782 The UMLDA algorithm written in Matlab (data included)].

== Tensor data sets ==
* 3D gait data (third-order tensors): [http://www.dsp.utoronto.ca/~haiping/CodeData/USFGait17_128x88x20.zip 128x88x20(21.2M)]; [http://www.dsp.utoronto.ca/~haiping/CodeData/USFGait17_64x44x20.zip 64x44x20(9.9M)]; [http://www.dsp.utoronto.ca/~haiping/CodeData/USFGait17_32x22x10.zip 32x22x10(3.2M)];

== See also ==
*[[CP decomposition]]
*[[Dimension reduction]]
*[[Multilinear algebra]]
*[[Multilinear PCA|Multilinear Principal Component Analysis]]
*[[Tensor]]
*[[Tensor decomposition]]
*[[Tensor software]]
*[[Tucker decomposition]]

== References ==
{{Reflist|2}}

[[Category:Dimension reduction]]
[[Category:Machine learning]]
[[Category:Multilinear algebra]]
[[Category:Tensors]]</text>
      <sha1>433ly2gygfwwc6rsc1grc2brt9lkp9q</sha1>
    </revision>
  </page>
  <page>
    <title>Timeline of machine learning</title>
    <ns>0</ns>
    <id>50828755</id>
    <revision>
      <id>990854258</id>
      <parentid>950506236</parentid>
      <timestamp>2020-11-26T21:54:48Z</timestamp>
      <contributor>
        <ip>212.102.52.38</ip>
      </contributor>
      <comment>/* Timeline */ Add wikilink</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="26145" xml:space="preserve">This page is a '''timeline of [[machine learning]]'''. Major discoveries, achievements, milestones and other major events are included.

==Overview==
{| class="wikitable sortable"
|-
! Decade !! Summary
|-
| &lt;1950s|| Statistical methods are discovered and refined.
|-
| 1950s || Pioneering [[machine learning]] research is conducted using simple algorithms.
|-
| 1960s || [[Bayesian method]]s are introduced for [[Bayesian inference|probabilistic inference]] in machine learning.&lt;ref&gt;Solomonoff, Ray J. "A formal theory of inductive inference. Part II." Information and control 7.2 (1964): 224–254.&lt;/ref&gt;
|-
| 1970s || '[[AI Winter]]' caused by pessimism about machine learning effectiveness.
|-
| 1980s || Rediscovery of [[backpropagation]] causes a resurgence in machine learning research.
|-
| 1990s || Work on Machine learning shifts from a knowledge-driven approach to a data-driven approach. Scientists begin creating programs for computers to analyze large amounts of data and draw conclusions{{snd}} or "learn"{{snd}} from the results.&lt;ref name="Marr"&gt;{{cite news|last1=Marr|first1=Bernard|title=A Short History of Machine Learning – Every Manager Should Read|url=https://www.forbes.com/sites/bernardmarr/2016/02/19/a-short-history-of-machine-learning-every-manager-should-read/#2a1a75f9323f|work=Forbes|accessdate=28 Sep 2016}}&lt;/ref&gt; [[Support vector machines]] (SVMs) and &lt;ref&gt;{{cite journal|last1=Siegelmann|first1=Hava|first2=Eduardo|last2=Sontag|title=Computational Power of Neural Networks  |journal=Journal of Computer and System Sciences|volume=50|issue=1|year=1995 |pages=132–150|doi=10.1006/jcss.1995.1013}}&lt;/ref&gt;[[recurrent neural networks]] (RNNs) become popular. The fields of &lt;ref&gt;{{cite journal |last1=Siegelmann |first1=Hava  |title=Computation Beyond the Turing Limit  |journal=Journal of Computer and System Sciences  |volume=238 |issue=28 |year=1995 |pages=632–637|doi=10.1126/science.268.5210.545 |pmid=17756722 |bibcode=1995Sci...268..545S }}&lt;/ref&gt; computational complexity via neural networks and super-Turing computation started. 
|-
| 2000s || Support Vector Clustering &lt;ref&gt;{{cite journal |first1=Asa |last1=Ben-Hur |first2=David |last2=Horn |first3=Hava |last3=Siegelmann |first4=Vladimir|last4=Vapnik |title=Support vector clustering |journal=Journal of Machine Learning Research|volume=2 |year=2001 |pages=51–86}}&lt;/ref&gt;  and other [[Kernel methods]] &lt;ref&gt;{{cite journal |last1=Hofmann |first1=Thomas |first2=Bernhard |last2=Schölkopf |first3=Alexander J. |last3=Smola |title=Kernel methods in machine learning |journal=The Annals of Statistics |volume=36 |issue=3 |year=2008 |pages=1171–1220 |jstor=25464664 |doi=10.1214/009053607000000677|doi-access=free }}&lt;/ref&gt; and unsupervised machine learning methods become widespread.&lt;ref&gt;{{cite journal |first1=James |last1=Bennett |first2=Stan |last2=Lanning |title=The netflix prize |journal=Proceedings of KDD Cup and Workshop 2007 |date=2007 |url=https://www.cs.uic.edu/~liub/KDD-cup-2007/NetflixPrize-description.pdf}}&lt;/ref&gt;  
|-
| 2010s || [[Deep learning]] becomes feasible, which leads to machine learning becoming integral to many widely used software services and applications.
|}

==Timeline==
[[File:A simple neural network with two input units and one output unit.png|thumb|A simple neural network with two input units and one output unit]]

&lt;!-- Commented out: [[File:Watson Jeopardy.jpg|thumb|[[Ken Jennings]], Watson, and [[Brad Rutter]] in their Jeopardy! exhibition match]] --&gt;

{| class="wikitable sortable"
|-
! Year !! Event type !! Caption !! Event
|-
| 1763 || Discovery || The Underpinnings of [[Bayes' theorem|Bayes' Theorem]] || [[Thomas Bayes]]'s work ''[[An Essay towards solving a Problem in the Doctrine of Chances]]'' is published two years after his death, having been amended and edited by a friend of Bayes, [[Richard Price]].&lt;ref&gt;{{cite journal|last1=Bayes|first1=Thomas|title=An Essay towards solving a Problem in the Doctrine of Chance|journal=Philosophical Transactions|date=1 January 1763|volume=53|pages=370–418|doi=10.1098/rstl.1763.0053|jstor=105741|doi-access=free}}&lt;/ref&gt; The essay presents work which underpins [[Bayes theorem]].
|-
| 1805 || Discovery || Least Square || [[Adrien-Marie Legendre]] describes the "méthode des moindres carrés", known in English as the [[least squares]] method.&lt;ref&gt;{{cite book|last1=Legendre|first1=Adrien-Marie|title=Nouvelles méthodes pour la détermination des orbites des comètes|date=1805|publisher=Firmin Didot|location=Paris|page=viii|url=https://archive.org/details/bub_gb_FRcOAAAAQAAJ|accessdate=13 June 2016|language=French}}&lt;/ref&gt; The least squares method is used widely in [[data fitting]].
|-
| 1812 || || [[Bayes' theorem|Bayes' Theorem]] || [[Pierre-Simon Laplace]] publishes ''Théorie Analytique des Probabilités'', in which he expands upon the work of Bayes and defines what is now known as [[Bayes' Theorem]].&lt;ref&gt;{{cite web|last1=O'Connor|first1=J J|last2=Robertson|first2=E F|title=Pierre-Simon Laplace|url=http://www-history.mcs.st-and.ac.uk/Biographies/Laplace.html|publisher=School of Mathematics and Statistics, University of St Andrews, Scotland|accessdate=15 June 2016}}&lt;/ref&gt;
|-
| 1913 || Discovery || Markov Chains || [[Andrey Markov]] first describes techniques he used to analyse a poem. The techniques later become known as [[Markov chains]].&lt;ref&gt;{{cite journal|last1=Hayes|first1=Brian|title=First Links in the Markov Chain|url=http://www.americanscientist.org/issues/pub/first-links-in-the-markov-chain/|accessdate=15 June 2016|journal=American Scientist|issue=March–April 2013|publisher=Sigma Xi, The Scientific Research Society|page=92|doi=10.1511/2013.101.1|quote=Delving into the text of Alexander Pushkin's novel in verse Eugene Onegin, Markov spent hours sifting through patterns of vowels and consonants. On January 23, 1913, he summarized his findings in an address to the Imperial Academy of Sciences in St. Petersburg. His analysis did not alter the understanding or appreciation of Pushkin's poem, but the technique he developed—now known as a Markov chain—extended the theory of probability in a new direction.|volume=101|year=2013}}&lt;/ref&gt;
|-
| 1950 || || Turing's Learning Machine || [[Alan Turing]] proposes a 'learning machine' that could learn and become artificially intelligent. Turing's specific proposal foreshadows [[genetic algorithms]].&lt;ref&gt;{{cite journal|last1=Turing|first1=Alan|title=Computing Machinery and Intelligence|journal=Mind|date=October 1950|volume=59|issue=236|pages=433–460|doi=10.1093/mind/LIX.236.433|url=http://mind.oxfordjournals.org/content/LIX/236/433|accessdate=8 June 2016}}&lt;/ref&gt; 
|-
| 1951 || || First Neural Network Machine || [[Marvin Minsky]] and Dean Edmonds build the first neural network machine, able to learn, the [[Stochastic neural analog reinforcement calculator|SNARC]].&lt;ref&gt;{{Harvnb|Crevier|1993|pp=34–35}} and {{Harvnb|Russell|Norvig|2003|p=17}}&lt;/ref&gt;
|-
| 1952 || || Machines Playing Checkers || [[Arthur Samuel]] joins IBM's Poughkeepsie Laboratory and begins working on some of the very first machine learning programs, first creating programs that play [[checkers]].&lt;ref name="aaai"&gt;{{cite news|last1=McCarthy|first1=John|last2=Feigenbaum|first2=Ed|title=Arthur Samuel: Pioneer in Machine Learning|url=http://www.aaai.org/ojs/index.php/aimagazine/article/view/840/758|accessdate=5 June 2016|work=AI Magazine|issue=3|publisher=Association for the Advancement of Artificial Intelligence|page=10}}&lt;/ref&gt;
|-
| 1957 || Discovery || Perceptron || [[Frank Rosenblatt]] invents the [[perceptron]] while working at the [[Cornell Aeronautical Laboratory]].&lt;ref&gt;{{cite journal|last1=Rosenblatt|first1=Frank|title=The perceptron: A probabilistic model for information storage and organization in the brain|journal=Psychological Review|date=1958|volume=65|issue=6|pages=386–408|doi=10.1037/h0042519 |url=http://www.staff.uni-marburg.de/~einhaeus/GRK_Block/Rosenblatt1958.pdf|pmid=13602029}}&lt;/ref&gt; The invention of the perceptron generated a great deal of excitement and was widely covered in the media.&lt;ref&gt;{{cite news|last1=Mason|first1=Harding|last2=Stewart|first2=D|last3=Gill|first3=Brendan|title=Rival|url=http://www.newyorker.com/magazine/1958/12/06/rival-2|accessdate=5 June 2016|work=The New Yorker|date=6 December 1958}}&lt;/ref&gt;
|-
| 1963 || Achievement || Machines Playing Tic-Tac-Toe || [[Donald Michie]] creates a 'machine' consisting of 304 match boxes and beads, which uses [[reinforcement learning]] to play [[Tic-tac-toe]] (also known as noughts and crosses).&lt;ref&gt;{{cite web|last1=Child|first1=Oliver|title=Menace: the Machine Educable Noughts And Crosses Engine Read|url=http://chalkdustmagazine.com/features/menace-machine-educable-noughts-crosses-engine/#more-3326|website=Chalkdust Magazine |date=13 March 2016|accessdate=16 Jan 2018}}&lt;/ref&gt;
|- 
| 1967 || || Nearest Neighbor || The [[nearest neighbor algorithm]] was created, which is the start of basic pattern recognition. The algorithm was used to map routes.&lt;ref name="Marr" /&gt;
|-
| 1969 || || Limitations of Neural Networks || [[Marvin Minsky]] and [[Seymour Papert]] publish their book ''[[Perceptrons (book)|Perceptrons]]'', describing some of the limitations of perceptrons and neural networks. The interpretation that the book shows that neural networks are fundamentally limited is seen as a hindrance for research into neural networks.&lt;ref&gt;{{cite web|last1=Cohen|first1=Harvey|title=The Perceptron|url=http://harveycohen.net/image/perceptron.html|accessdate=5 June 2016}}&lt;/ref&gt;&lt;ref&gt;{{cite web|last1=Colner|first1=Robert|title=A brief history of machine learning|url=http://www.slideshare.net/bobcolner/a-brief-history-of-machine-learning|website=SlideShare|date=4 March 2016|accessdate=5 June 2016}}&lt;/ref&gt;
|-
| 1970 || || Automatic Differentiation (Backpropagation) || [[Seppo Linnainmaa]] publishes the general method for automatic differentiation (AD) of discrete connected networks of nested differentiable functions.&lt;ref name="lin1970"&gt;[[Seppo Linnainmaa]] (1970). "The representation of the cumulative rounding error of an algorithm as a Taylor expansion of the local rounding errors." Master's Thesis (in Finnish), Univ. Helsinki, 6–7.&lt;/ref&gt;&lt;ref name="lin1976"&gt;{{cite journal |first=Seppo |last=Linnainmaa |authorlink=Seppo Linnainmaa |year=1976 |title=Taylor expansion of the accumulated rounding error |journal=BIT Numerical Mathematics |volume=16 |issue=2 |pages=146–160 |doi=10.1007/BF01931367}}&lt;/ref&gt; This corresponds to the modern version of backpropagation, but is not yet named as such.&lt;ref name="grie2012"&gt;{{cite journal |last=Griewank |first=Andreas |year=2012 |title=Who Invented the Reverse Mode of Differentiation? |journal=Documenta Matematica, Extra Volume ISMP |pages=389–400}}&lt;/ref&gt;&lt;ref name="grie2008"&gt;Griewank, Andreas and Walther, A. ''Principles and Techniques of Algorithmic Differentiation, Second Edition''. SIAM, 2008.&lt;/ref&gt;&lt;ref name="schmidhuber2015"&gt;{{cite journal |authorlink=Jürgen Schmidhuber |last=Schmidhuber |first=Jürgen |year=2015 |title=Deep learning in neural networks: An overview |journal=Neural Networks |volume=61 |pages=85–117 |arxiv=1404.7828|bibcode=2014arXiv1404.7828S |doi=10.1016/j.neunet.2014.09.003 |pmid=25462637}}&lt;/ref&gt;&lt;ref name="scholarpedia2015"&gt;{{cite journal | last1 = Schmidhuber | first1 = Jürgen | authorlink = Jürgen Schmidhuber | year = 2015 | title = Deep Learning (Section on Backpropagation) | journal = Scholarpedia | volume = 10 | issue = 11| page = 32832 | doi = 10.4249/scholarpedia.32832 | bibcode = 2015SchpJ..1032832S | doi-access = free }}&lt;/ref&gt;
|- 
| 1979 || || Stanford Cart || Students at Stanford University develop a cart that can navigate and avoid obstacles in a room.&lt;ref name="Marr" /&gt;
|- 
| 1979 || Discovery || Neocognitron || [[Kunihiko Fukushima]] first publishes his work on the [[neocognitron]], a type of [[artificial neural network]] (ANN).&lt;ref&gt;{{cite journal
| last       = Fukushima
| first      = Kunihiko
| date       = October 1979
| title      = 位置ずれに影響されないパターン認識機構の神経回路のモデル --- ネオコグニトロン ---
| trans-title = Neural network model for a mechanism of pattern recognition unaffected by shift in position — Neocognitron —
| language   = Japanese
| url        = 
| journal    = Trans. IECE
| volume     = J62-A
| issue      = 10
| pages      = 658–665
| doi        = 
}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Fukushima|first1=Kunihiko|title=Neocognitron: A Self-organizing Neural Network Model for a Mechanism of Pattern The Recognitron Unaffected by Shift in Position|journal=Biological Cybernetics|date=April 1980|volume=36|issue=4|pages=193–202|url=http://www.cs.princeton.edu/courses/archive/spr08/cos598B/Readings/Fukushima1980.pdf|accessdate=5 June 2016|doi=10.1007/bf00344251|pmid=7370364}}&lt;/ref&gt; [[Neocognitron|Neocognition]] later inspires [[convolutional neural network]]s (CNNs).&lt;ref&gt;{{cite journal|last1=Le Cun|first1=Yann|title=Deep Learning|citeseerx=10.1.1.297.6176}}&lt;/ref&gt;
|-
| 1981 || || Explanation Based Learning || Gerald Dejong introduces Explanation Based Learning, where a computer algorithm analyses data and creates a general rule it can follow and discard unimportant data.&lt;ref name="Marr" /&gt;
|-
| 1982 || Discovery || Recurrent Neural Network || [[John Hopfield]] popularizes [[Hopfield networks]], a type of [[recurrent neural network]] that can serve as [[content-addressable memory]] systems.&lt;ref&gt;{{cite journal|last1=Hopfield|first1=John|title=Neural networks and physical systems with emergent collective computational abilities|journal=Proceedings of the National Academy of Sciences of the United States of America|date=April 1982|volume=79|issue=8|pages=2554–2558|url=http://www.pnas.org/content/79/8/2554.full.pdf|accessdate=8 June 2016|doi=10.1073/pnas.79.8.2554|pmid=6953413|pmc=346238|bibcode=1982PNAS...79.2554H}}&lt;/ref&gt;
|-
| 1985 || || NetTalk || A program that learns to pronounce words the same way a baby does, is developed by Terry Sejnowski.&lt;ref name="Marr" /&gt;
|- 
| 1986 || Application || Backpropagation || [[Seppo Linnainmaa]]'s reverse mode of [[automatic differentiation]] (first applied to neural networks by [[Paul Werbos]]) is used in experiments by [[David Rumelhart]], [[Geoff Hinton]] and [[Ronald J. Williams]] to learn [[Knowledge representation|internal representations]].&lt;ref&gt;{{cite journal|last1=Rumelhart|first1=David|last2=Hinton|first2=Geoffrey|last3=Williams|first3=Ronald|title=Learning representations by back-propagating errors|journal=Nature|date=9 October 1986|volume=323|issue=6088|pages=533–536|url=http://elderlab.yorku.ca/~elder/teaching/cosc6390psyc6225/readings/hinton%201986.pdf|accessdate=5 June 2016|doi=10.1038/323533a0|bibcode=1986Natur.323..533R}}&lt;/ref&gt;
|-
| 1989 || Discovery || Reinforcement Learning || Christopher Watkins develops [[Q-learning]], which greatly improves the practicality and feasibility of [[reinforcement learning]].&lt;ref&gt;{{cite journal|last1=Watksin|first1=Christopher|title=Learning from Delayed Rewards|date=1 May 1989|url=http://www.cs.rhul.ac.uk/~chrisw/new_thesis.pdf}}&lt;/ref&gt;
|-
| 1989 || Commercialization || Commercialization of Machine Learning on Personal Computers || Axcelis, Inc. releases [[Evolver (software)|Evolver]], the first software package to commercialize the use of genetic algorithms on personal computers.&lt;ref&gt;{{cite news|last1=Markoff|first1=John|title=BUSINESS TECHNOLOGY; What's the Best Answer? It's Survival of the Fittest|url=https://www.nytimes.com/1990/08/29/business/business-technology-what-s-the-best-answer-it-s-survival-of-the-fittest.html|accessdate=8 June 2016|work=New York Times|date=29 August 1990}}&lt;/ref&gt;
|-
| 1992 || Achievement || Machines Playing Backgammon || Gerald Tesauro develops [[TD-Gammon]], a computer [[backgammon]] program that uses an [[artificial neural network]] trained using [[temporal-difference learning]] (hence the 'TD' in the name). TD-Gammon is able to rival, but not consistently surpass, the abilities of top human backgammon players.&lt;ref&gt;{{cite journal|last1=Tesauro|first1=Gerald|title=Temporal Difference Learning and TD-Gammon|journal=Communications of the ACM|date=March 1995|volume=38|issue=3|doi=10.1145/203330.203343|url=http://www.bkgm.com/articles/tesauro/tdl.html|pages=58–68}}&lt;/ref&gt;
|-
| 1995 || Discovery || Random Forest Algorithm || Tin Kam Ho publishes a paper describing [[random forest|random decision forests]].&lt;ref&gt;{{cite journal|last1=Ho|first1=Tin Kam|title=Random Decision Forests|journal=Proceedings of the Third International Conference on Document Analysis and Recognition|date=August 1995|volume=1|pages=278–282|doi=10.1109/ICDAR.1995.598994|url=http://ect.bell-labs.com/who/tkh/publications/papers/odt.pdf|accessdate=5 June 2016|publisher=IEEE|location=Montreal, Quebec|isbn=0-8186-7128-9}}&lt;/ref&gt;
|-
| 1995 || Discovery || Support Vector Machines || [[Corinna Cortes]] and [[Vladimir Vapnik]] publish their work on [[support vector machines]].&lt;ref name="bhml"&gt;{{cite web|last1=Golge|first1=Eren|title=BRIEF HISTORY OF MACHINE LEARNING|url=http://www.erogol.com/brief-history-machine-learning/|website=A Blog From a Human-engineer-being|accessdate=5 June 2016}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Cortes|first1=Corinna|last2=Vapnik|first2=Vladimir|title=Support-vector networks|journal=Machine Learning|date=September 1995|volume=20|issue=3|pages=273–297|doi=10.1007/BF00994018|publisher=Kluwer Academic Publishers|issn=0885-6125|doi-access=free}}&lt;/ref&gt;
|-
| 1997 || Achievement || IBM Deep Blue Beats Kasparov || IBM's [[Deep Blue (chess computer)|Deep Blue]] beats the world champion at chess.&lt;ref name="Marr" /&gt;
|-
| 1997 || Discovery || LSTM || [[Sepp Hochreiter]] and [[Jürgen Schmidhuber]] invent [[long short-term memory]] (LSTM) recurrent neural networks,&lt;ref&gt;{{cite journal|last1=Hochreiter|first1=Sepp|last2=Schmidhuber|first2=Jürgen|title=Long Short-Term Memory|journal=Neural Computation|date=1997|volume=9|issue=8|pages=1735–1780|url=http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf|doi=10.1162/neco.1997.9.8.1735|pmid=9377276|url-status=dead|archiveurl=https://web.archive.org/web/20150526132154/http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf|archivedate=2015-05-26}}&lt;/ref&gt; greatly improving the efficiency and practicality of recurrent neural networks.
|-
| 1998 || || MNIST database || A team led by [[Yann LeCun]] releases the [[MNIST database]], a dataset comprising a mix of handwritten digits from [[American Census Bureau]] employees and American high school students.&lt;ref&gt;{{cite web|last1=LeCun|first1=Yann|last2=Cortes|first2=Corinna|last3=Burges|first3=Christopher|title=THE MNIST DATABASE of handwritten digits|url=http://yann.lecun.com/exdb/mnist/|accessdate=16 June 2016}}&lt;/ref&gt; The MNIST database has since become a benchmark for evaluating handwriting recognition.
|-
| 2002 || || Torch Machine Learning Library || [[Torch (machine learning)|Torch]], a software library for machine learning, is first released.&lt;ref&gt;{{cite journal|last1=Collobert|first1=Ronan|last2=Benigo|first2=Samy|last3=Mariethoz|first3=Johnny|title=Torch: a modular machine learning software library|date=30 October 2002|url=http://www.idiap.ch/ftp/reports/2002/rr02-46.pdf|accessdate=5 June 2016}}&lt;/ref&gt;
|-
| 2006 || || The Netflix Prize || The [[Netflix Prize]] competition is launched by [[Netflix]]. The aim of the competition was to use machine learning to beat Netflix's own recommendation software's accuracy in predicting a user's rating for a film given their ratings for previous films by at least 10%.&lt;ref&gt;{{cite web|title=The Netflix Prize Rules|url=http://www.netflixprize.com/rules|website=Netflix Prize|publisher=Netflix|accessdate=16 June 2016|url-status=dead|archiveurl=https://www.webcitation.org/65tSo1csp?url=http://www.netflixprize.com/rules|archivedate=3 March 2012}}&lt;/ref&gt; The prize was won in 2009.
|-
|2009
|Achievement
|ImageNet
|[[ImageNet]] is created. ImageNet is a large visual database envisioned by [[Fei-Fei Li]] from Stanford University, who realized that the best machine learning algorithms wouldn't work well if the data didn't reflect the real world.&lt;ref&gt;{{Cite web|url=https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/|title=ImageNet: the data that spawned the current AI boom — Quartz|last=Gershgorn|first=Dave|website=qz.com|language=en-US|access-date=2018-03-30}}&lt;/ref&gt; For many, ImageNet was the catalyst for the AI boom&lt;ref&gt;{{Cite news|url=https://www.nytimes.com/2016/07/19/technology/reasons-to-believe-the-ai-boom-is-real.html|title=Reasons to Believe the A.I. Boom Is Real|last=Hardy|first=Quentin|date=2016-07-18|work=The New York Times|access-date=2018-03-30|language=en-US|issn=0362-4331}}&lt;/ref&gt; of the 21st century. 
|-
| 2010 || || Kaggle Competition || [[Kaggle]], a website that serves as a platform for machine learning competitions, is launched.&lt;ref&gt;{{cite web|title=About|url=https://www.kaggle.com/about|website=Kaggle|publisher=Kaggle Inc|accessdate=16 June 2016}}&lt;/ref&gt;
|-
| 2010 || || Wall Street Journal Profiles Machine Learning Investing || The WSJ Profiles new wave of investing and focuses on RebellionResearch.com which would be the subject of author Scott Patterson's Novel, Dark Pools.&lt;ref&gt;{{cite web|title=About|url=https://www.wsj.com/articles/SB10001424052748703834604575365310813948080}}&lt;/ref&gt;
|-
| 2011 || Achievement || Beating Humans in Jeopardy || Using a combination of machine learning, [[natural language processing]] and information retrieval techniques, [[IBM]]'s [[Watson (computer)|Watson]] beats two human champions in a [[Jeopardy!]] competition.&lt;ref&gt;{{cite news|last1=Markoff|first1=John|title=Computer Wins on 'Jeopardy!': Trivial, It's Not|url=https://www.nytimes.com/2011/02/17/science/17jeopardy-watson.html?pagewanted=all&amp;_r=0|accessdate=5 June 2016|work=New York Times|date=17 February 2011|page=A1}}&lt;/ref&gt;
|-
| 2012 || Achievement || Recognizing Cats on YouTube || The [[Google Brain]] team, led by [[Andrew Ng]] and [[Jeff Dean (computer scientist)|Jeff Dean]], create a neural network that learns to recognize cats by watching unlabeled images taken from frames of [[YouTube]] videos.&lt;ref&gt;{{cite conference
 | last1 = Le | first1 = Quoc V.
 | last2 = Ranzato | first2 = Marc'Aurelio
 | last3 = Monga | first3 = Rajat
 | last4 = Devin | first4 = Matthieu
 | last5 = Corrado | first5 = Greg
 | last6 = Chen | first6 = Kai
 | last7 = Dean | first7 = Jeffrey
 | last8 = Ng | first8 = Andrew Y.
 | arxiv = 1112.6209
 | contribution = Building high-level features using large scale unsupervised learning
 | contribution-url = https://icml.cc/2012/papers/73.pdf
 | publisher = icml.cc / Omnipress
 | title = Proceedings of the 29th International Conference on Machine Learning, ICML 2012, Edinburgh, Scotland, UK, June 26 - July 1, 2012
 | year = 2012| bibcode = 2011arXiv1112.6209L}}&lt;/ref&gt;&lt;ref&gt;{{cite news|last1=Markoff|first1=John|title=How Many Computers to Identify a Cat? 16,000|url=https://www.nytimes.com/2012/06/26/technology/in-a-big-network-of-computers-evidence-of-machine-learning.html|accessdate=5 June 2016|work=New York Times|date=26 June 2012|page=B1}}&lt;/ref&gt;
|-
| 2014 || || Leap in Face Recognition || [[Facebook]] researchers publish their work on [[DeepFace]], a system that uses neural networks that identifies faces with 97.35% accuracy. The results are an improvement of more than 27% over previous systems and rivals human performance.&lt;ref&gt;{{cite journal|last1=Taigman|first1=Yaniv|last2=Yang|first2=Ming|last3=Ranzato|first3=Marc'Aurelio|last4=Wolf|first4=Lior|title=DeepFace: Closing the Gap to Human-Level Performance in Face Verification|journal=Conference on Computer Vision and Pattern Recognition|date=24 June 2014|url=https://research.facebook.com/publications/deepface-closing-the-gap-to-human-level-performance-in-face-verification/|accessdate=8 June 2016}}&lt;/ref&gt;
|-
| 2014 || || Sibyl || Researchers from [[Google]] detail their work on Sibyl,&lt;ref&gt;{{cite web |last1=Canini|first1=Kevin|last2=Chandra|first2=Tushar|last3=Ie|first3=Eugene|last4=McFadden|first4=Jim|last5=Goldman|first5=Ken|last6=Gunter|first6=Mike|last7=Harmsen|first7=Jeremiah|last8=LeFevre|first8=Kristen|last9=Lepikhin|first9=Dmitry|last10=Llinares|first10=Tomas Lloret|last11=Mukherjee|first11=Indraneel|last12=Pereira|first12=Fernando|last13=Redstone|first13=Josh|last14=Shaked|first14=Tal|last15=Singer|first15=Yoram|title=Sibyl: A system for large scale supervised machine learning|url=https://users.soe.ucsc.edu/~niejiazhong/slides/chandra.pdf|website=Jack Baskin School of Engineering|publisher=UC Santa Cruz|accessdate=8 June 2016}}&lt;/ref&gt; a proprietary platform for massively parallel machine learning used internally by Google to make predictions about user behavior and provide recommendations.&lt;ref&gt;{{cite news|last1=Woodie|first1=Alex|title=Inside Sibyl, Google's Massively Parallel Machine Learning Platform|url=http://www.datanami.com/2014/07/17/inside-sibyl-googles-massively-parallel-machine-learning-platform/|accessdate=8 June 2016|work=Datanami|publisher=Tabor Communications|date=17 July 2014}}&lt;/ref&gt;
|-
| 2016 || Achievement || Beating Humans in Go ||Google's [[AlphaGo]] program becomes the first [[Computer Go]] program to beat an unhandicapped professional human player&lt;ref&gt;{{cite web|title=Google achieves AI 'breakthrough' by beating Go champion|url=https://www.bbc.com/news/technology-35420579|website=BBC News|publisher=BBC|accessdate=5 June 2016|date=27 January 2016}}&lt;/ref&gt; using a combination of machine learning and tree search techniques.&lt;ref&gt;{{cite web|title=AlphaGo|url=https://www.deepmind.com/alpha-go.html|website=Google DeepMind|publisher=Google Inc|accessdate=5 June 2016}}&lt;/ref&gt; Later improved as [[AlphaGo Zero]] and then in 2017 generalized to Chess and more two-player games with [[AlphaZero]]. 
|}

==See also==
* [[History of artificial intelligence]]
* [[Machine learning]]
* [[Timeline of artificial intelligence]]
* [[Timeline of machine translation]]

==References==
{{Reflist|30em}}

{{Timelines of computing}}

[[Category:Machine learning]]
[[Category:Computing timelines|Machine learning]]</text>
      <sha1>nleppq9h0ozqg18mejo62gy2yymzcx4</sha1>
    </revision>
  </page>
  <page>
    <title>Cognitive robotics</title>
    <ns>0</ns>
    <id>2934910</id>
    <revision>
      <id>999898812</id>
      <parentid>999832759</parentid>
      <timestamp>2021-01-12T14:28:29Z</timestamp>
      <contributor>
        <username>MrOllie</username>
        <id>6908984</id>
      </contributor>
      <comment>Reverted to revision 980797315 by [[Special:Contributions/LearnMore|LearnMore]] ([[User talk:LearnMore|talk]]): Refspam, fringe</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="8684" xml:space="preserve">{{more footnotes|date=February 2012}}

'''Cognitive robotics ''' is concerned with endowing a robot with intelligent behavior by providing it with a processing architecture that will allow it to [[Robot learning|learn]] and reason about how to behave in response to complex goals in a complex world. Cognitive robotics may be considered the engineering branch of [[embodied cognitive science]] and [[embodied embedded cognition]].

==Core issues==

While traditional cognitive modeling approaches have assumed symbolic coding schemes as a means for depicting the world, translating the world into these kinds of symbolic representations has proven to be problematic if not untenable. [[philosophy of perception|Perception]] and [[motor cognition|action]] and the notion of [[Mental representation|symbolic representation]] are therefore core issues to be addressed in cognitive robotics.

==Starting point==

Cognitive robotics views animal cognition as a starting point for the development of robotic information processing, as opposed to more traditional [[Artificial Intelligence]] techniques. Target robotic cognitive capabilities include perception processing, attention allocation, [[anticipation (artificial intelligence)|anticipation]], planning, complex motor coordination, reasoning about other agents and perhaps even about their own mental states. Robotic cognition embodies the behavior of [[intelligent agent]]s in the physical world (or a virtual world, in the case of simulated cognitive robotics). Ultimately the robot must be able to act in the real world.

==Learning techniques==

===Motor Babble===
{{main|Motor babbling}}

A preliminary robot learning technique called [[motor babbling]] involves correlating pseudo-random complex motor movements by the robot with resulting visual and/or auditory feedback such that the robot may begin to ''expect'' a pattern of sensory feedback given a pattern of motor output. Desired sensory feedback may then be used to inform a motor control signal. This is thought to be analogous to how a baby learns to reach for objects or learns to produce speech sounds. For simpler robot systems, where for instance [[inverse kinematics]] may feasibly be used to transform anticipated feedback (desired motor result) into motor output, this step may be skipped.

===Imitation===

Once a robot can coordinate its motors to produce a desired result, the technique of ''learning by imitation'' may be used. The robot monitors the performance of another agent and then the robot tries to imitate that agent. It is often a challenge to transform imitation information from a complex scene into a desired motor result for the robot. Note that imitation is a high-level form of cognitive behavior and imitation is not necessarily required in a basic model of embodied animal cognition.

===Knowledge acquisition===

A more complex learning approach is "autonomous [[knowledge acquisition]]": the robot is left to explore the environment on its own. A system of goals and beliefs is typically assumed.

A somewhat more directed mode of exploration can be achieved by "curiosity" algorithms, such as Intelligent Adaptive Curiosity&lt;ref&gt;http://www.pyoudeyer.com/ims.pdf&lt;/ref&gt;&lt;ref&gt;http://www.pyoudeyer.com/oudeyer-kaplan-neurorobotics.pdf&lt;/ref&gt; or Category-Based Intrinsic Motivation.&lt;ref&gt;http://science.slc.edu/~jmarshall/papers/cbim-epirob09.pdf&lt;/ref&gt; These algorithms generally involve breaking sensory input into a finite number of categories and assigning some sort of prediction system (such as an [[Artificial Neural Network]]) to each. The prediction system keeps track of the error in its predictions over time. Reduction in prediction error is considered learning. The robot then preferentially explores categories in which it is learning (or reducing prediction error) the fastest.

==Other architectures==

Some researchers in cognitive robotics have tried using architectures such as ([[ACT-R]] and [[Soar (cognitive architecture)]]) as a basis of their cognitive robotics programs. These highly modular symbol-processing architectures have been used to simulate operator performance and human performance when modeling simplistic and symbolized laboratory data. The idea is to extend these architectures to handle real-world sensory input as that input continuously unfolds through time. What is needed is a way to somehow translate the world into a set of symbols and their relationships.

==Questions==

Some of the fundamental questions to still be answered in cognitive robotics are:
* How much human programming should or can be involved to support the learning processes?
* How can one quantify progress? Some of the adopted ways is the reward and punishment. But what kind of reward and what kind of punishment? In humans, when teaching a child for example, the reward would be candy or some encouragement, and the punishment can take many forms. But what is an effective way with robots?{{Citation needed|date=August 2019|reason=It seems that this passage contains confusion about reinforcement learning, a citation to a source that shows how to use 'reward and punishment' for 'progress quantification' is needed.}}

== Books ==
Cognitive Robotics book &lt;ref&gt;{{Cite web|title = Cognitive Robotics|url = https://www.crcpress.com/Cognitive-Robotics/Samani/9781482244564|website = CRC Press|accessdate = 2015-10-07}}&lt;/ref&gt; by Hooman Samani,&lt;ref&gt;{{Cite web|title = Hooman Samani|url = http://www.hoomansamani.com/|website = www.hoomansamani.com|accessdate = 2015-10-07}}&lt;/ref&gt; takes a multidisciplinary approach to cover various aspects of cognitive robotics such as artificial intelligence, physical, chemical, philosophical, psychological, social, cultural, and ethical aspects.

==See also==
*[[Artificial intelligence]]
*[[Intelligent agent]]
*[[Cognitive science]]
*[[Cybernetics]]
*[[Developmental robotics]]
*[[Embodied cognitive science]]
*[[Developmental robotics|Epigenetic robotics]]
*[[Evolutionary robotics]]
*[[Hybrid intelligent system]]
*[[Intelligent control]]

== References ==
{{Reflist}}
*[https://web.archive.org/web/20090314232056/http://www.ss-rics.org/ The Symbolic and Subsymbolic Robotic Intelligence Control System (SS-RICS)]
*[https://web.archive.org/web/20060617202124/http://www.cs.uu.nl/groups/IS/robotics/robotics.html Intelligent Systems Group - University of Utrecht]
*[http://www.cs.toronto.edu/cogrobo/main/ The Cognitive Robotics Group - University of Toronto]
* The [[IDSIA]] [http://robotics.idsia.ch/ Robotics Lab] and [http://www.idsia.ch/~juergen/cogbotlab.html Cognitive Robotics Lab] of [[Juergen Schmidhuber]]
*[https://web.archive.org/web/20060218074249/http://www.inl.gov/adaptiverobotics/humanoidrobotics/future.shtml What Does the Future Hold for Cognitive Robots? - Idaho National Laboratory]
*[http://www.nrl.navy.mil/aic/iss/aas/CognitiveRobots.php Cognitive Robotics at the Naval Research Laboratory]
*[http://cogrob.ensta.fr/ Cognitive robotics at ENSTA] autonomous embodied systems, evolving in complex and non-constraint environments, using mainly vision as sensor.
*[https://web.archive.org/web/20070504203412/http://eecs.vanderbilt.edu/CIS/cisHome.shtml The Center for Intelligent Systems - Vanderbilt University]
*[http://www.cor-lab.de/ Institute for Cognition and Robotics (CoR-Lab) at Bielefeld University]
*[http://mmi.tudelft.nl/SocioCognitiveRobotics/ SocioCognitive Robotics at Delft University of Technology]{{Dead link|date=July 2020 |bot=InternetArchiveBot |fix-attempted=yes }}
*[https://web.archive.org/web/20130521072036/http://www.aslab.upm.es/ Autonomous Systems Laboratory at Universidad Politecnica de Madrid]
*[https://www.inf.uni-hamburg.de/en/inst/ab/wtm/ Knowledge Technology at Universität Hamburg]
*[http://www.ida.liu.se/conferences/cogrob2014/ The Cognitive Robotics Association], founded in 1998, directed by Gerhard Lakemeyer, University of Aachen, organizes every two years the Cognitive Robotics Workshop and it is generously supported by [http://www.journals.elsevier.com/artificial-intelligence/ the AI journal]

== External links ==
* [[iCub]]
* [https://web.archive.org/web/20070619021836/http://mensnewsdaily.com/2007/05/16/robobusiness-robots-with-imagination/ RoboBusiness: Robots that Dream of Being Better]
* [https://web.archive.org/web/20071008234511/http://www.conscious-robots.com/en/conscious-machines/the-field-of-machine-consciousness/cognitive-rob.html www.Conscious-Robots.com]
* [https://web.archive.org/web/20160304222937/http://mailman.rwth-aachen.de/mailman/listinfo/cogrob-sc The cognitive Robotics Association]
{{Robotics}}

[[Category:Artificial intelligence]]
[[Category:Robotics]]
[[Category:Machine learning]]</text>
      <sha1>70ozfw6gt4n40uz0l7r997594dg8slj</sha1>
    </revision>
  </page>
  <page>
    <title>Algorithm selection</title>
    <ns>0</ns>
    <id>50773876</id>
    <revision>
      <id>997451180</id>
      <parentid>994071869</parentid>
      <timestamp>2020-12-31T15:39:05Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 11 templates: del empty params (1×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="14681" xml:space="preserve">{{Use dmy dates|date=September 2017}}

'''Algorithm selection''' (sometimes also called '''per-instance algorithm selection''' or '''offline algorithm selection''') is a meta-[[algorithmic technique]] to choose an algorithm from a portfolio on an instance-by-instance basis. It is motivated by the observation that on many practical problems, algorithms have different performances. That is, while one algorithm performs well on some instances, it performs poorly on others and vice versa for another algorithm. If we can identify when to use which algorithm, we can get the best of both worlds and improve overall performance. This is what algorithm selection aims to do. The only prerequisite for applying algorithm selection techniques is that there exists (or that there can be constructed) a set of complementary algorithms.

== Definition==

Given a portfolio &lt;math&gt;\mathcal{P}&lt;/math&gt; of algorithms &lt;math&gt;\mathcal{A} \in \mathcal{P}&lt;/math&gt;, a set of instances &lt;math&gt;i \in \mathcal{I}&lt;/math&gt; and a cost metric &lt;math&gt;m: \mathcal{P} \times \mathcal{I} \to \mathbb{R}&lt;/math&gt;, the algorithm selection problem consists of finding a mapping &lt;math&gt;s: \mathcal{I} \to \mathcal{P}&lt;/math&gt; from instances &lt;math&gt;\mathcal{I}&lt;/math&gt; to algorithms &lt;math&gt;\mathcal{P}&lt;/math&gt; such that the cost &lt;math&gt; \sum_{i \in \mathcal{I}} m(s(i),i)&lt;/math&gt; across all instances is optimized.&lt;ref&gt;{{Cite book |doi = 10.1016/S0065-2458(08)60520-3|chapter = The Algorithm Selection Problem |volume = 15|pages = 65–118|title= Advances in Computers |year = 1976|last1 = Rice|first1 = John R.|isbn = 9780120121151}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal |doi = 10.1016/j.artint.2016.04.003|title = ASlib: A benchmark library for algorithm selection|journal = Artificial Intelligence|volume = 237|pages = 41–58|year = 2016|last1 = Bischl|first1 = Bernd|last2 = Kerschke|first2 = Pascal|last3 = Kotthoff|first3 = Lars|last4 = Lindauer|first4 = Marius|last5 = Malitsky|first5 = Yuri|last6 = Fréchette|first6 = Alexandre|last7 = Hoos|first7 = Holger|last8 = Hutter|first8 = Frank|last9 = Leyton-Brown|first9 = Kevin|last10 = Tierney|first10 = Kevin|last11 = Vanschoren|first11 = Joaquin|arxiv = 1506.02465}}&lt;/ref&gt;

== Examples==

=== Boolean satisfiability problem (and other hard combinatorial problems)===
A well-known application of algorithm selection is the [[Boolean satisfiability problem]]. Here, the portfolio of algorithms is a set of (complementary) [[SAT solver]]s, the instances are Boolean formulas, the cost metric is for example average runtime or number of unsolved instances. So, the goal is to select a well-performing SAT solver for each individual instance. In the same way, algorithm selection can be applied to many other &lt;math&gt;\mathcal{NP}&lt;/math&gt;-hard problems (such as [[Linear programming|mixed integer programming]], [[Constraint satisfaction problem|CSP]], [[Automated planning and scheduling|AI planning]], [[Travelling salesman problem|TSP]], [[MAXSAT]], [[QBF]] and [[answer set programming]]). Competition-winning systems in SAT are SATzilla,&lt;ref name="zilla08"&gt;{{Cite journal|author=L. Xu|author2=F. Hutter|author3=H. Hoos|name-list-style=amp|author4=K. Leyton-Brown|date=2008|title=SATzilla: Portfolio-based Algorithm Selection for SAT|journal=Journal of Artificial Intelligence Research|volume=32|pages=565–606|arxiv=1111.2249|doi=10.1613/jair.2490}}&lt;/ref&gt; 3S&lt;ref&gt;{{Cite book|author1=S. Kadioglu |author2=Y. Malitsky |author3=A. Sabharwal |author4=H. Samulowitz |author5=M. Sellmann |date=2011|chapter=Algorithm Selection and Scheduling|title=Principles and Practice of Constraint Programming|volume=6876 |pages=454–469 |doi=10.1007/978-3-642-23786-7_35|editor=Lee, J.|series=Lecture Notes in Computer Science |isbn=978-3-642-23785-0 |citeseerx=10.1.1.211.1807 }}&lt;/ref&gt; and CSHC&lt;ref name="CSHC"&gt;{{Cite book|author1=Y. Malitsky |author2=A. Sabharwal |author3=H. Samulowitz |author4=M. Sellmann |date=2013|chapter=Algorithm Portfolios Based on Cost-Sensitive Hierarchical Clustering|title=Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence|pages=608–614|isbn=978-1-57735-633-2}}&lt;/ref&gt;

=== Machine learning===
In [[machine learning]], algorithm selection is better known as [[Meta learning (computer science)|meta-learning]]. The portfolio of algorithms consists of machine learning algorithms (e.g., Random Forest, SVM, DNN), the instances are data sets and the cost metric is for example the error rate. So, the goal is to predict which machine learning algorithm will have a small error on each data set.

== Instance features==

The algorithm selection problem is mainly solved with machine learning techniques. By representing the problem instances by numerical features &lt;math&gt;f&lt;/math&gt;, algorithm selection can be seen as a [[multi-class classification]] problem by learning a mapping &lt;math&gt; f_{i} \mapsto \mathcal{A}&lt;/math&gt; for a given instance &lt;math&gt;i&lt;/math&gt;.

Instance features are numerical representations of instances. For example, we can count the number of variables, clauses, average clause length for Boolean formulas,&lt;ref&gt;{{Cite journal|author1=E. Nudelman |author2=K. Leyton-Brown |author3=H. Hoos |author4=A. Devkar |author5=Y. Shoham |date=2004|title=Understanding Random SAT: Beyond the Clauses-to-Variables Ratio|url=https://ai.stanford.edu/~shoham/www%20papers/CP04randomsat.pdf|journal=Proccedings of CP}}&lt;/ref&gt; or number of samples, features, class balance for ML data sets to get an impression about their characteristics.

=== Static vs. probing features===

We distinguish between two kinds of features: 
# Static features are in most cases some counts and statistics (e.g., clauses-to-variables ratio in SAT). These features ranges from very cheap features (e.g. number of variables) to very complex features (e.g., statistics about variable-clause graphs).
# Probing features (sometimes also called landmarking features) are computed by running some analysis of algorithm behavior on an instance (e.g., accuracy of a cheap decision tree algorithm on an ML data set, or running for a short time a stochastic local search solver on a Boolean formula). These feature often cost more than simple static features.

=== Feature costs===

Depending on the used performance metric &lt;math&gt; m &lt;/math&gt;, feature computation can be associated with costs.
For example, if we use running time as performance metric, we include the time to compute our instance features into the performance of an algorithm selection system.
SAT solving is a concrete example, where such feature costs cannot be neglected, since instance features for [[Conjunctive normal form|CNF]] formulas can be either very cheap (e.g., to get the number of variables can be done in constant time for CNFs in the DIMACs format) or very expensive (e.g., graph features which can cost tens or hundreds of seconds).

It is important to take the overhead of feature computation into account in practice in such scenarios; otherwise a misleading impression of the performance of the algorithm selection approach is created. For example, if the decision which algorithm to choose can be made with perfect accuracy, but the features are the running time of the portfolio algorithms, there is no benefit to the portfolio approach. This would not be obvious if feature costs were omitted.

== Approaches==

=== Regression approach===

One of the first successful algorithm selection approaches predicted the performance of each algorithm &lt;math&gt;\hat{m}_{\mathcal{A}}: \mathcal{I} \to \mathbb{R}&lt;/math&gt; and selected the algorithm with the best predicted performance &lt;math&gt;arg\min_{\mathcal{A}\in\mathcal{P}} \hat{m}_{\mathcal{A}}(i) &lt;/math&gt; for an instance &lt;math&gt;i&lt;/math&gt;.&lt;ref name="zilla08" /&gt;

=== Clustering approach===

A common assumption is that the given set of instances &lt;math&gt;\mathcal{I}&lt;/math&gt; can be clustered into homogeneous subsets 
and for each of these subsets, there is one well-performing algorithm for all instances in there.
So, the training consists of identifying the homogeneous clusters via an unsupervised clustering approach and associating an algorithm with each cluster.
A new instance is assigned to a cluster and the associated algorithm selected.&lt;ref&gt;{{Cite journal|author1=S. Kadioglu |author2=Y. Malitsky |author3=M. Sellmann |author4=K. Tierney |date=2010|title=ISAC – Instance-Specific Algorithm Configuration|url=https://wiwi.uni-paderborn.de/fileadmin/dep3ls7/Downloads/Publikationen/PDFs/isac-ecai2010.pdf|journal=Proceedings of the European Conference on Artificial Intelligence}}&lt;/ref&gt;

A more modern approach is cost-sensitive [[hierarchical clustering]]&lt;ref name="CSHC"/&gt; using supervised learning to identify the homogeneous instance subsets.

=== Pairwise cost-sensitive classification approach===

A common approach for multi-class classification is to learn pairwise models between every pair of classes (here algorithms) 
and choose the class that was predicted most often by the pairwise models.
We can weight the instances of the pairwise prediction problem by the performance difference between the two algorithms.
This is motivated by the fact that we care most about getting predictions with large differences correct, but the penalty for an incorrect prediction is small if there is almost no performance difference.
Therefore, each instance &lt;math&gt;i&lt;/math&gt; for training a classification model &lt;math&gt;\mathcal{A}_1&lt;/math&gt; vs &lt;math&gt;\mathcal{A}_2&lt;/math&gt; is associated with a cost &lt;math&gt;|m(\mathcal{A}_1,i) - m(\mathcal{A}_2,i)| &lt;/math&gt;.&lt;ref&gt;{{Cite journal|author1=L. Xu |author2=F. Hutter |author3=J. Shen |author4=H. Hoos |author5=K. Leyton-Brown |date=2012|title=SATzilla2012: Improved Algorithm Selection Based on Cost-sensitive Classification Models|url=http://www.academia.edu/download/30605172/sc2012_proceedings.pdf#page=58|journal=Proceedings of the SAT Challenge 2012: Solver and Benchmark Descriptions}}&lt;/ref&gt;

== Requirements==
[[File:Portfolio correlation as.png|thumb|Clustering of SAT solvers from SAT12-INDU ASlib scenario according to the correlation coefficient of spearman.]]
[[File:Shapley Values on SAT12-INDU ASlib Scenario.png|thumb|Shapley values for complementary analysis on SAT12-INDU ASlib Scenario&lt;ref&gt;{{Cite journal|author=A. Frechette|author2=L. Kotthoff|author3=T. Michalak|author4=T. Rahwan|author5=H. Hoos|author6=K. Leyton-Brown|name-list-style=amp|date=2016|title=Using the Shapley Value to Analyze Algorithm Portfolios|url=https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/12495/12107|journal=Proceedings of the International Conference on AAAI}}&lt;/ref&gt;]]
The algorithm selection problem can be effectively applied under the following assumptions:
* The portfolio &lt;math&gt;\mathcal{P}&lt;/math&gt; of algorithms is complementary with respect to the instance set &lt;math&gt;\mathcal{I}&lt;/math&gt;, i.e.,  there is no single algorithm &lt;math&gt;\mathcal{A} \in \mathcal{P}&lt;/math&gt; that dominates the performance of all other algorithms over &lt;math&gt;\mathcal{I}&lt;/math&gt; (see figures to the right for examples on complementary analysis).
* In some application, the computation of instance features is associated with a cost. For example, if the cost metric is running time, we have also to consider the time to compute the instance features. In such cases, the cost to compute features should not be larger than the performance gain through algorithm selection.

== Application domains==

Algorithm selection is not limited to single domains but can be applied to any kind of algorithm if the above requirements are satisfied.
Application domains include:

* hard combinatorial problems:&lt;ref&gt;Kotthoff, Lars. "[https://www.aaai.org/ojs/index.php/aimagazine/article/download/2460/2438 Algorithm selection for combinatorial search problems: A survey]." Data Mining and Constraint Programming. Springer, Cham, 2016. 149-190.&lt;/ref&gt; [[Boolean satisfiability problem|SAT]], [[Linear programming|Mixed Integer Programming]], [[Constraint satisfaction problem|CSP]], [[Automated planning and scheduling|AI Planning]], [[Travelling salesman problem|TSP]], [[MAXSAT]], [[QBF]] and [[Answer Set Programming]]
* combinatorial auctions
* in machine learning, the problem is known as [[Meta learning (computer science)|meta-learning]]
* software design
* black-box optimization
* [[multi-agent system]]s
* numerical optimization
* linear algebra, differential equations
* [[evolutionary algorithm]]s
* [[vehicle routing problem]]
* power systems

For an extensive list of literature about algorithm selection, we refer to a literature overview.

== Variants of algorithm selection==

=== Online selection===

Online algorithm selection refers to switching between different algorithms during the solving process.  This is useful as a [[hyper-heuristic]]. In contrast, offline algorithm selection selects an algorithm for a given instance only once and before the solving process.

=== Computation of schedules===

An extension of algorithm selection is the per-instance algorithm scheduling problem, in which we do not select only one solver, but we select a time budget for each algorithm on a per-instance base. This approach improves the performance of selection systems in particular if the instance features are not very informative and a wrong selection of a single solver is likely.&lt;ref&gt;{{Cite journal|author1=M. Lindauer|author2=R. Bergdoll  |author3=F. Hutter|date=2016|title=An Empirical Study of Per-Instance Algorithm Scheduling|url=http://ml.informatik.uni-freiburg.de/papers/16-LION-ASschedules.pdf|journal=Proceedings of the International Conference on Learning and Intelligent Optimization|series=Lecture Notes in Computer Science|volume=10079|pages=253–259|doi=10.1007/978-3-319-50349-3_20|isbn=978-3-319-50348-6}}&lt;/ref&gt;

=== Selection of parallel portfolios===

Given the increasing importance of parallel computation,
an extension of algorithm selection for parallel computation is parallel portfolio selection,
in which we select a subset of the algorithms to simultaneously run in a parallel portfolio.&lt;ref&gt;{{Cite journal|author=M. Lindauer|author2=H. Hoos|name-list-style=amp|author3=F. Hutter|date=2015|title=From Sequential Algorithm Selection to Parallel Portfolio Selection|url=https://ml.informatik.uni-freiburg.de/papers/15-LION-ParallelAS.pdf|journal= Proceedings of the International Conference on Learning and Intelligent Optimization|series=Lecture Notes in Computer Science|volume=8994|pages=1–16|doi=10.1007/978-3-319-19084-6_1|isbn=978-3-319-19083-9}}&lt;/ref&gt;

== External links==

* [http://www.coseal.net/aslib/ Algorithm Selection Library (ASlib)]
* [https://larskotthoff.github.io/assurvey/ Algorithm selection literature]

== References==
{{Reflist}}

[[Category:Machine learning]]</text>
      <sha1>n2v2w4dcx285nn4x8hqzpdiod3mayrz</sha1>
    </revision>
  </page>
  <page>
    <title>Transfer learning</title>
    <ns>0</ns>
    <id>3920550</id>
    <revision>
      <id>1000361664</id>
      <parentid>997963621</parentid>
      <timestamp>2021-01-14T20:14:00Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>References after punctuation per [[WP:REFPUNCT]], [[WP:CITEFOOT]], [[WP:PAIC]] + other fixes</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="13707" xml:space="preserve">'''Transfer learning (TL)''' is a research problem in [[machine learning]] (ML) that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem.&lt;ref&gt;{{cite web |last1=West |first1=Jeremy |first2=Dan |last2=Ventura |first3=Sean |last3=Warnick |url=http://cpms.byu.edu/springresearch/abstract-entry?id=861 |title=Spring Research Presentation: A Theoretical Foundation for Inductive Transfer |publisher=Brigham Young University, College of Physical and Mathematical Sciences |year=2007 |access-date=2007-08-05 |url-status=dead |archive-url=https://web.archive.org/web/20070801120743/http://cpms.byu.edu/springresearch/abstract-entry?id=861 |archive-date=2007-08-01 }}&lt;/ref&gt; For example, knowledge gained while learning to [[Computer vision#Recognition|recognize]] cars could apply when trying to recognize trucks.  This area of research bears some relation to the long history of psychological literature on [[transfer of learning]], although formal ties between the two fields are limited. From the practical standpoint, reusing or transferring information from previously learned tasks for the learning of new tasks has the potential to significantly improve the sample efficiency of a [[reinforcement learning]] agent.&lt;ref&gt;{{Cite journal|last1=George Karimpanal|first1=Thommen|last2=Bouffanais|first2=Roland|date=2019|title=Self-organizing maps for storage and transfer of knowledge in reinforcement learning|journal=Adaptive Behavior|volume=27|issue=2|pages=111–126|doi=10.1177/1059712318818568|issn=1059-7123|arxiv=1811.08318|s2cid=53774629}}&lt;/ref&gt;

==History==
{{Undue weight section|date=June 2019}}
&lt;!--Overusage of publications by Lorien Pratt, likely by COI editor. Not a balanced view on the history of this topic, needs a broader range of sources.--&gt;

In 1976 Stevo Bozinovski and Ante Fulgosi published a paper explicitly addressing transfer learning in neural networks training.&lt;ref&gt;Stevo. Bozinovski and Ante Fulgosi (1976). "The influence of pattern similarity and transfer learning upon training of a base perceptron B2." (original in Croatian) Proceedings of Symposium Informatica 3-121-5, Bled.&lt;/ref&gt;&lt;ref&gt;Stevo Bozinovski (2020) "Reminder of the first paper on transfer learning in neural networks, 1976". Informatica 44: 291–302.&lt;/ref&gt; The paper gives a mathematical and geometrical model of transfer learning. In 1981 a report was given on application of transfer learning in training a neural network on a dataset of images representing letters of computer terminals. Both positive and negative transfer learning was experimentally demonstrated.&lt;ref&gt;S. Bozinovski (1981). "Teaching space: A representation concept for adaptive pattern classification." COINS Technical Report, University of Massachusetts at Amherst, No 81-28 [available online: UM-CS-1981-028.pdf]&lt;/ref&gt;

In 1993, Lorien Pratt published a paper on transfer in [[machine learning]], formulating the discriminability-based transfer (DBT) algorithm.&lt;ref&gt;{{cite book|url={{google books|plainurl=y|id=6tGHlwEACAAJ|page=204}}|title=NIPS Conference: Advances in Neural Information Processing Systems 5|last=Pratt|first=L. Y.|publisher=Morgan Kaufmann Publishers|year=1993|pp=204–211|chapter=Discriminability-based transfer between neural networks|chapter-url=http://papers.nips.cc/paper/641-discriminability-based-transfer-between-neural-networks.pdf}}&lt;/ref&gt;

In 1997, the journal ''Machine Learning''  published a special issue devoted to transfer learning,&lt;ref&gt;{{Cite web|url=https://link.springer.com/journal/10994/28/1/page/1|title=Machine Learning - Special Issue on Inductive Transfer|last1=Pratt|first1=L. Y.|last2=Thrun|first2=Sebastian|date=July 1997|website=link.springer.com|publisher=Springer|access-date=2017-08-10|volume=28|issue=1}}&lt;/ref&gt; and by 1998, the field had advanced to include [[multi-task learning]],&lt;ref&gt;Caruana, R., "Multitask Learning", pp. 95-134 in {{Harvnb|Pratt|Thrun|1998}}&lt;/ref&gt;  along with a more formal analysis of its theoretical foundations.&lt;ref&gt;Baxter, J., "Theoretical Models of Learning to Learn", pp. 71-95 {{Harvnb|Pratt|Thrun|1998}}&lt;/ref&gt; ''Learning to Learn'',{{sfn|Thrun|Pratt|2012}} edited by Pratt and [[Sebastian Thrun]], is a 1998 review of the subject.

Transfer learning has also been applied in cognitive science, with the journal ''Connection Science''
publishing a special issue on reuse of neural networks through transfer in 1996.&lt;ref&gt;{{Cite journal|url=http://www.tandfonline.com/toc/ccos20/8/2|title=Special Issue: Reuse of Neural Networks through Transfer|last=Pratt|first=L.|year=1996 |access-date=2017-08-10|journal=Connection Science|volume=8|issue=2}}&lt;/ref&gt;

[[Andrew Ng]] said in his NIPS 2016 tutorial &lt;ref&gt;{{Citation|title=NIPS 2016 tutorial: "Nuts and bolts of building AI applications using Deep Learning" by Andrew Ng|url=https://www.youtube.com/watch?v=wjqaz6m42wU|language=en|access-date=2019-12-28}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://nips.cc/Conferences/2016/Schedule?showEvent=6203|title=NIPS 2016 Schedule|website=nips.cc|access-date=2019-12-28}}&lt;/ref&gt;&lt;ref&gt;[https://media.nips.cc/Conferences/2016/Slides/6203-Slides.pdf Nuts and bolts of building AI applications using Deep Learning, slides]&lt;/ref&gt; that TL will be the next driver of ML commercial success after [[supervised learning]] to highlight the importance of TL.

== Definition ==
The definition of transfer learning is given in terms of domains and tasks. A domain &lt;math&gt;\mathcal{D}&lt;/math&gt; consists of: a [[feature space]] &lt;math&gt;\mathcal{X}&lt;/math&gt; and a [[marginal probability distribution]] &lt;math&gt;P(X)&lt;/math&gt;, where &lt;math&gt;X = \{x_1,...,x_n\}  \in \mathcal{X}&lt;/math&gt;. Given a specific domain, &lt;math&gt;\mathcal{D} = \{\mathcal{X}, P(X)\}&lt;/math&gt;, a task consists of two components: a label space &lt;math&gt;\mathcal{Y}&lt;/math&gt; and an objective predictive function &lt;math&gt;f:\mathcal{X} \rightarrow \mathcal{Y}  &lt;/math&gt;. The function &lt;math&gt;f&lt;/math&gt; is used to predict the corresponding label &lt;math&gt;f(x)&lt;/math&gt; of a new instance &lt;math&gt;x&lt;/math&gt;. This task, denoted by &lt;math&gt;\mathcal{T} = \{\mathcal{Y}, f(x)\}&lt;/math&gt;, is learned from the training data consisting of pairs &lt;math&gt;\{x_i, y_i\}&lt;/math&gt;, where &lt;math&gt;x_i \in X&lt;/math&gt; and &lt;math&gt;y_i \in \mathcal{Y}&lt;/math&gt;.&lt;ref name="Lin, Jung 2017"&gt;{{cite journal |last1=Lin |first1=Yuan-Pin |last2=Jung |first2=Tzyy-Ping |title=Improving EEG-Based Emotion Classification Using Conditional Transfer Learning |journal=Frontiers in Human Neuroscience |date=27 June 2017 |volume=11 |pages=334 |doi=10.3389/fnhum.2017.00334|pmid=28701938 |pmc=5486154 }} [[File:CC-BY icon.svg|50px]] Material was copied from this source, which is available under a [https://creativecommons.org/licenses/by/4.0/ Creative Commons Attribution 4.0 International License].&lt;/ref&gt;

Given a source domain &lt;math&gt;\mathcal{D}_S&lt;/math&gt; and learning task &lt;math&gt;\mathcal{T}_S&lt;/math&gt;, a target domain &lt;math&gt;\mathcal{D}_T&lt;/math&gt;and learning task &lt;math&gt;\mathcal{T}_T&lt;/math&gt;, where &lt;math&gt;\mathcal{D}_S \neq \mathcal{D}_T&lt;/math&gt;, or &lt;math&gt;\mathcal{T}_S \neq \mathcal{T}_T&lt;/math&gt;, transfer learning aims to help improve the learning of the target predictive function &lt;math&gt;f_T (\cdot)&lt;/math&gt; in &lt;math&gt;\mathcal{T}_T&lt;/math&gt; using the knowledge in &lt;math&gt;\mathcal{D}_S&lt;/math&gt; and &lt;math&gt;\mathcal{T}_S&lt;/math&gt;.&lt;ref name="Lin, Jung 2017"/&gt;

== Applications ==
Algorithms are available for transfer learning in [[Markov logic network]]s&lt;ref&gt;{{citation|title=Learning Proceedings of the 22nd AAAI Conference on Artificial Intelligence (AAAI-2007)|date=July 2007|last1=Mihalkova|last2=Huynh|last3=Mooney|first1=Lilyana|first2=Tuyen|first3=Raymond J.|contribution=Mapping and Revising Markov Logic Networks for Transfer|contribution-url=http://www.cs.utexas.edu/users/ml/papers/mihalkova-aaai07.pdf|location=Vancouver, BC|access-date=2007-08-05|pp=608–614}}&lt;/ref&gt; and [[Bayesian networks]].&lt;ref&gt;{{citation|last1=Niculescu-Mizil|title=Proceedings of the Eleventh International Conference on Artificial Intelligence and Statistics (AISTATS 2007)|date=March 21–24, 2007|last2=Caruana|first1=Alexandru|first2=Rich|contribution=Inductive Transfer for Bayesian Network Structure Learning|contribution-url=http://www.stat.umn.edu/~aistat/proceedings/data/papers/043.pdf|access-date=2007-08-05}}&lt;/ref&gt; Transfer learning has also been applied to cancer subtype discovery,&lt;ref name=":bmdl"&gt;Hajiramezanali, E. &amp; Dadaneh, S. Z. &amp; Karbalayghareh, A. &amp; Zhou, Z. &amp; Qian, X. Bayesian multi-domain learning for cancer subtype discovery from next-generation sequencing count data. 32nd Conference on Neural Information Processing Systems (NeurIPS 2018), Montréal, Canada. {{arXiv|1810.09433}}&lt;/ref&gt; [[Occupancy|building utilization]],&lt;ref&gt;{{Cite conference|last1=Arief-Ang|first1=I.B.|last2=Salim|first2=F.D.|last3=Hamilton|first3=M.|date=2017-11-08|title=DA-HOC: semi-supervised domain adaptation for room occupancy prediction using CO2 sensor data|url=https://dl.acm.org/citation.cfm?id=3137146|conference=4th ACM International Conference on Systems for Energy-Efficient Built Environments (BuildSys)|location=Delft, Netherlands|pages=1–10|doi=10.1145/3137133.3137146|isbn=978-1-4503-5544-5}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last1=Arief-Ang |first1=I.B. |last2=Hamilton |first2=M. |last3=Salim |first3=F.D. |date=2018-12-01 |title=A Scalable Room Occupancy Prediction with Transferable Time Series Decomposition of CO2 Sensor Data |journal=ACM Transactions on Sensor Networks  |volume=14 |issue=3–4 |pages=21:1–21:28 |doi=10.1145/3217214 |s2cid=54066723 }}&lt;/ref&gt; [[general game playing]],&lt;ref&gt;Banerjee, Bikramjit, and Peter Stone. "[http://www.aaai.org/Papers/IJCAI/2007/IJCAI07-107.pdf General Game Learning Using Knowledge Transfer]." IJCAI. 2007.&lt;/ref&gt; [[Document classification|text classification]],&lt;ref&gt;{{cite conference|last1=Do|first1=Chuong B.|last2=Ng|first2=Andrew Y.|year=2005|title=Neural Information Processing Systems Foundation, NIPS*2005|url=http://papers.nips.cc/paper/2843-transfer-learning-for-text-classification.pdf|access-date=2007-08-05|contribution=Transfer learning for text classification}}&lt;/ref&gt;&lt;ref&gt;{{cite conference|last1=Rajat|first1=Raina|last2=Ng|first2=Andrew Y.|last3=Koller|first3=Daphne|year=2006|title=Twenty-third International Conference on Machine Learning|url=https://ai.stanford.edu/~ang/papers/icml06-transferinformativepriors.pdf|access-date=2007-08-05|contribution=Constructing Informative Priors using Transfer Learning}}&lt;/ref&gt; digit recognition,&lt;ref&gt;{{Cite journal|last1=Maitra|first1=D. S.|last2=Bhattacharya|first2=U.|last3=Parui|first3=S. K.|date=August 2015|title=CNN based common approach to handwritten character recognition of multiple scripts|journal=2015 13th International Conference on Document Analysis and Recognition (ICDAR)|pages=1021–1025|doi=10.1109/ICDAR.2015.7333916|isbn=978-1-4799-1805-8|s2cid=25739012}}&lt;/ref&gt; medical imaging and [[E-mail filtering|spam filtering]].&lt;ref&gt;{{cite conference|last=Bickel|first=Steffen|year=2006|title=ECML-PKDD Discovery Challenge Workshop|url=http://www.ecmlpkdd2006.org/discovery_challenge2006_overview.pdf|access-date=2007-08-05|contribution=ECML-PKDD Discovery Challenge 2006 Overview}}&lt;/ref&gt;

In 2020 it was discovered that, due to their similar physical natures, transfer learning is possible between [[Electromyographic]] (EMG) signals from the muscles when classifying the behaviours of [[Electroencephalographic]] (EEG) brainwaves from the [[gesture recognition]] domain to the mental state recognition domain. It was also noted that this relationship worked vice versa, showing that EEG can likewise be used to classify EMG in addition.&lt;ref&gt;{{cite journal | last1=Bird | first1=Jordan J. | last2=Kobylarz | first2=Jhonatan | last3=Faria | first3=Diego R. | last4=Ekart | first4=Aniko | last5=Ribeiro | first5=Eduardo P. | title=Cross-Domain MLP and CNN Transfer Learning for Biological Signal Processing: EEG and EMG | journal=IEEE Access | publisher=Institute of Electrical and Electronics Engineers (IEEE) | volume=8 | year=2020 | issn=2169-3536 | doi=10.1109/access.2020.2979074 | pages=54789–54801| doi-access=free }}&lt;/ref&gt; The experiments noted that the accuracy of [[Artificial neural network|neural networks]] and [[convolutional neural network]]s were improved&lt;ref&gt;{{Cite journal|last=Maitra|first=Durjoy Sen|last2=Bhattacharya|first2=Ujjwal|last3=Parui|first3=Swapan K.|date=August 2015|title=CNN based common approach to handwritten character recognition of multiple scripts|url=https://ieeexplore.ieee.org/document/7333916/|journal=2015 13th International Conference on Document Analysis and Recognition (ICDAR)|pages=1021–1025|doi=10.1109/ICDAR.2015.7333916}}&lt;/ref&gt; through transfer learning both at the first epoch (prior to any learning, ie. compared to standard random weight distribution) and at the asymptote (the end of the learning process). That is, algorithms are improved by exposure to another domain. Moreover, the end user of a pre-trained model can change the structure of fully-connected layers to achieve a superior performance.&lt;ref&gt;[https://arxiv.org/abs/2007.03347 Kabir, H. M., Abdar, M., Jalali, S. M. J., Khosravi, A., Atiya, A. F., Nahavandi, S., &amp; Srinivasan, D. (2020). Spinalnet: Deep neural network with gradual input. arXiv preprint arXiv:2007.03347.]&lt;/ref&gt;

==See also==
* [[Crossover (genetic algorithm)]]
* [[Domain adaptation]]
* [[General game playing]]
* [[Multi-task learning]]
* [[Multitask optimization]]

==References==
{{Reflist}}

== Sources ==
* {{cite book|url={{google books|plainurl=y|id=X_jpBwAAQBAJ}}|title=Learning to Learn|last1=Thrun|first1=Sebastian|last2=Pratt|first2=Lorien|date=6 December 2012|publisher=Springer Science &amp; Business Media|isbn=978-1-4615-5529-2}}

[[Category:Machine learning]]</text>
      <sha1>57v6v79vyl33loeojjfndgg7jyzgk0x</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Genetic programming</title>
    <ns>14</ns>
    <id>3061615</id>
    <revision>
      <id>746268286</id>
      <parentid>388502966</parentid>
      <timestamp>2016-10-26T09:48:48Z</timestamp>
      <contributor>
        <username>Kri</username>
        <id>253188</id>
      </contributor>
      <comment>+ [[Category:Machine learning]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="571" xml:space="preserve">'''Genetic programming''' ('''GP''') is an automated methodology inspired by [[biological evolution]] to find [[computer programs]] that best perform a user-defined task. It is therefore a particular [[machine learning]] technique that uses an [[evolutionary algorithm]] to optimize a population of computer programs according to a [[fitness landscape]] determined by a program's ability to perform a given computational task.

{{Cat main|Genetic programming}}

[[Category:Evolutionary algorithms]]
[[Category:Genetics|Programming, genetic]]
[[Category:Machine learning]]</text>
      <sha1>gp1vlcmpkozot0o9kr1rtvx1o0fl60t</sha1>
    </revision>
  </page>
  <page>
    <title>Evolutionary programming</title>
    <ns>0</ns>
    <id>460689</id>
    <revision>
      <id>930472121</id>
      <parentid>919336921</parentid>
      <timestamp>2019-12-12T18:44:53Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead.) #IABot (v2.0</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2271" xml:space="preserve">'''Evolutionary programming''' is one of the four major [[evolutionary algorithm]] [[programming paradigms|paradigms]].  It is similar to [[genetic programming]], but the structure of the program to be optimized is fixed, while its numerical parameters are allowed to evolve.

It was first used by [[Lawrence J. Fogel]] in the US in 1960 in order to use simulated [[evolution]] as a learning process aiming to generate [[artificial intelligence]]. Fogel used [[finite-state machine]]s as predictors and evolved them.
Currently evolutionary programming is a wide [[evolutionary computing]] dialect with no fixed structure or ([[Genetic representation|representation]]), in contrast with some of the other dialects. It is becoming harder to distinguish from [[Evolution strategy|evolutionary strategies]].

Its main variation operator is [[Mutation (genetic algorithm)|mutation]]; members of the population are viewed as part of a specific species rather than members of the same species therefore each parent generates an offspring, using a (μ + μ){{Explain|date=April 2017}} [[Selection (genetic algorithm)|survivor selection]].

==See also==
* [[Artificial intelligence]]
* [[Genetic algorithm]]
* [[Genetic operator]]

==References==
* Fogel, L.J., Owens, A.J., Walsh, M.J. (1966), ''Artificial Intelligence through Simulated Evolution'', John Wiley.
* Fogel, L.J. (1999), ''Intelligence through Simulated Evolution : Forty Years of Evolutionary Programming'', John Wiley.
* Eiben, A.E., Smith, J.E. (2003), [http://www.cs.vu.nl/~gusz/ecbook/ecbook.html ''Introduction to Evolutionary Computing''], [http://www.springer.de Springer]. {{ISBN|3-540-40184-9}}

==External links==
* [https://web.archive.org/web/20120225015603/http://www.aip.de/~ast/EvolCompFAQ/Q1_2.htm The Hitch-Hiker's Guide to Evolutionary Computation: What's Evolutionary Programming (EP)?]
* [http://www.cleveralgorithms.com/nature-inspired/evolution/evolutionary_programming.html Evolutionary Programming by Jason Brownlee (PhD)]

{{Evolutionary computation}}

{{Authority control}}

{{DEFAULTSORT:Evolutionary Programming}}
[[Category:Evolutionary algorithms]]
[[Category:Optimization algorithms and methods]]
[[Category:Machine learning]]

{{compu-sci-stub}}

[[de:Evolutionäre Programmierung]]</text>
      <sha1>5f9lf8j9hphhv20sbvc1d9ud2nfkvc1</sha1>
    </revision>
  </page>
  <page>
    <title>Genetic algorithm</title>
    <ns>0</ns>
    <id>40254</id>
    <revision>
      <id>1000280478</id>
      <parentid>999648230</parentid>
      <timestamp>2021-01-14T13:23:38Z</timestamp>
      <contributor>
        <username>Jonathan A Jones</username>
        <id>1066098</id>
      </contributor>
      <comment>/* Commercial products */ circular reference</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="65160" xml:space="preserve">{{short description|Competitive algorithm for searching a problem space}}
{{Evolutionary algorithms}}
{{Use dmy dates|date=November 2020}}
[[Image:St 5-xband-antenna.jpg|thumb|The 2006 NASA [[Space Technology 5|ST5]] spacecraft antenna. This complicated shape was found by an evolutionary computer design program to create the best radiation pattern. It is known as an [[evolved antenna]].]]
&lt;!-- Deleted image removed: [[Image:ESA JAXA HUMIES Trajectory.png|thumb|The ESA/JAXA interplanetary Trajectory recipient of the [http://www.genetic-programming.org/combined.php 2013 gold HUMIES ] award. This complex tour of the Jovian Moons was found with the help of an evolutionary technique based on self-adaptation]] --&gt;
In [[computer science]] and [[operations research]], a '''genetic algorithm''' ('''GA''') is a [[metaheuristic]] inspired by the process of [[natural selection]] that belongs to the larger class of [[evolutionary algorithm]]s (EA). Genetic algorithms are commonly used to generate high-quality solutions to [[Optimization (mathematics)|optimization]] and [[Search algorithm|search problem]]s by relying on biologically inspired operators such as [[Mutation (genetic algorithm)|mutation]], [[crossover (genetic algorithm)|crossover]] and [[selection (genetic algorithm)|selection]].{{sfn|Mitchell|1996|p=2}}

== Methodology ==

=== Optimization problems ===
In a genetic algorithm, a [[population]] of [[candidate solution]]s (called individuals, creatures, or [[phenotype]]s) to an optimization problem is evolved toward better solutions. Each candidate solution has a set of properties (its [[chromosome]]s or [[genotype]]) which can be mutated and altered; traditionally, solutions are represented in binary as strings of 0s and 1s, but other encodings are also possible.{{sfn|Whitley|1994|p=66}}

The evolution usually starts from a population of randomly generated individuals, and is an [[Iteration|iterative process]], with the population in each iteration called a ''generation''. In each generation, the [[fitness (biology)|fitness]] of every individual in the population is evaluated; the fitness is usually the value of the [[objective function]] in the optimization problem being solved. The more fit individuals are [[Stochastics|stochastically]] selected from the current population, and each individual's genome is modified ([[Crossover (genetic algorithm)|recombined]] and possibly randomly mutated) to form a new generation. The new generation of candidate solutions is then used in the next iteration of the [[algorithm]]. Commonly, the algorithm terminates when either a maximum number of generations has been produced, or a satisfactory fitness level has been reached for the population.

A typical genetic algorithm requires:

# a [[genetic representation]] of the solution domain,
# a [[fitness function]] to evaluate the solution domain.

A standard representation of each candidate solution is as an [[bit array|array of bits]].{{sfn|Whitley|1994|p=66}} Arrays of other types and structures can be used in essentially the same way. The main property that makes these genetic representations convenient is that their parts are easily aligned due to their fixed size, which facilitates simple [[Crossover (genetic algorithm)|crossover]] operations. Variable length representations may also be used, but crossover implementation is more complex in this case. Tree-like representations are explored in [[genetic programming]] and graph-form representations are explored in [[evolutionary programming]]; a mix of both linear chromosomes and trees is explored in [[gene expression programming]].

Once the genetic representation and the fitness function are defined, a GA proceeds to initialize a population of solutions and then to improve it through repetitive application of the mutation, crossover, inversion and selection operators.

==== Initialization ====
The population size depends on the nature of the problem, but typically contains several hundreds or thousands of possible solutions. Often, the initial population is generated randomly, allowing the entire range of possible solutions (the [[Feasible region|search space]]). Occasionally, the solutions may be "seeded" in areas where optimal solutions are likely to be found.

==== Selection ====
{{Main|Selection (genetic algorithm)}}
During each successive generation, a portion of the existing population is [[selection (genetic algorithm)|selected]] to breed a new generation. Individual solutions are selected through a ''fitness-based'' process, where [[Fitness (biology)|fitter]] solutions (as measured by a [[fitness function]]) are typically more likely to be selected. Certain selection methods rate the fitness of each solution and preferentially select the best solutions. Other methods rate only a random sample of the population, as the former process may be very time-consuming.

The fitness function is defined over the genetic representation and measures the ''quality'' of the represented solution. The fitness function is always problem dependent. For instance, in the [[knapsack problem]] one wants to maximize the total value of objects that can be put in a knapsack of some fixed capacity. A representation of a solution might be an array of bits, where each bit represents a different object, and the value of the bit (0 or 1) represents whether or not the object is in the knapsack. Not every such representation is valid, as the size of objects may exceed the capacity of the knapsack. The ''fitness'' of the solution is the sum of values of all objects in the knapsack if the representation is valid, or 0 otherwise.

In some problems, it is hard or even impossible to define the fitness expression; in these cases, a [[Computer simulation|simulation]] may be used to determine the fitness function value of a [[phenotype]] (e.g. [[computational fluid dynamics]] is used to determine the air resistance of a vehicle whose shape is encoded as the phenotype), or even [[Interactive evolutionary computation|interactive genetic algorithms]] are used.

==== Genetic operators ====
{{Main|Crossover (genetic algorithm)|Mutation (genetic algorithm)}}

The next step is to generate a second generation population of solutions from those selected through a combination of [[genetic operator]]s: [[crossover (genetic algorithm)|crossover]] (also called recombination), and [[mutation (genetic algorithm)|mutation]].

For each new solution to be produced, a pair of "parent" solutions is selected for breeding from the pool selected previously. By producing a "child" solution using the above methods of crossover and mutation, a new solution is created which typically shares many of the characteristics of its "parents". New parents are selected for each new child, and the process continues until a new population of solutions of appropriate size is generated.
Although reproduction methods that are based on the use of two parents are more "biology inspired", some research&lt;ref&gt;Eiben, A. E. et al (1994). "Genetic algorithms with multi-parent recombination". PPSN III: Proceedings of the International Conference on Evolutionary Computation. The Third Conference on Parallel Problem Solving from Nature: 78&amp;ndash;87. {{ISBN|3-540-58484-6}}.&lt;/ref&gt;&lt;ref&gt;Ting, Chuan-Kang (2005). "On the Mean Convergence Time of Multi-parent Genetic Algorithms Without Selection". Advances in Artificial Life: 403&amp;ndash;412. {{ISBN|978-3-540-28848-0}}.&lt;/ref&gt; suggests that more than two "parents" generate higher quality chromosomes.

These processes ultimately result in the next generation population of chromosomes that is different from the initial generation. Generally, the average fitness will have increased by this procedure for the population, since only the best organisms from the first generation are selected for breeding, along with a small proportion of less fit solutions. These less fit solutions ensure genetic diversity within the genetic pool of the parents and therefore ensure the genetic diversity of the subsequent generation of children.

Opinion is divided over the importance of crossover versus mutation. There are many references in [[David B. Fogel|Fogel]] (2006) that support the importance of mutation-based search.

Although crossover and mutation are known as the main genetic operators, it is possible to use other operators such as regrouping, colonization-extinction, or migration in genetic algorithms.{{citation needed|date=November 2019}}

It is worth tuning parameters such as the [[Mutation (genetic algorithm)|mutation]] probability, [[Crossover (genetic algorithm)|crossover]] probability and population size to find reasonable settings for the problem class being worked on. A very small mutation rate may lead to [[genetic drift]] (which is non-[[Ergodicity|ergodic]] in nature). A recombination rate that is too high may lead to premature convergence of the genetic algorithm. A mutation rate that is too high may lead to loss of good solutions, unless [[#Elitism|elitist selection]] is employed. An adequate population size ensures sufficient genetic diversity for the problem at hand, but can lead to a waste of computational resources if set to a value larger than required.

==== Heuristics ====

In addition to the main operators above, other [[heuristic]]s may be employed to make the calculation faster or more robust. The ''speciation'' heuristic penalizes crossover between candidate solutions that are too similar; this encourages population diversity and helps prevent premature [[convergence (evolutionary computing)|convergence]] to a less optimal solution.&lt;ref&gt;{{Cite book|title=Handbook of Evolutionary Computation|last1=Deb|first1=Kalyanmoy|last2=Spears|first2=William M.|s2cid=3547258|publisher=Institute of Physics Publishing|year=1997|chapter=C6.2: Speciation methods}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|title=Handbook of Natural Computing|last=Shir|first=Ofer M.|date=2012|publisher=Springer Berlin Heidelberg|isbn=9783540929093|editor-last=Rozenberg|editor-first=Grzegorz|pages=1035–1069|language=en|chapter=Niching in Evolutionary Algorithms|doi=10.1007/978-3-540-92910-9_32|editor-last2=Bäck|editor-first2=Thomas|editor-last3=Kok|editor-first3=Joost N.}}&lt;/ref&gt;

==== Termination ====
This generational process is repeated until a termination condition has been reached. Common terminating conditions are:

* A solution is found that satisfies minimum criteria
* Fixed number of generations reached
* Allocated budget (computation time/money) reached
* The highest ranking solution's fitness is reaching or has reached a plateau such that successive iterations no longer produce better results
* Manual inspection
* Combinations of the above

== The building block hypothesis ==
Genetic algorithms are simple to implement, but their behavior is difficult to understand. In particular, it is difficult to understand why these algorithms frequently succeed at generating solutions of high fitness when applied to practical problems. The building block hypothesis (BBH) consists of:

# A description of a heuristic that performs adaptation by identifying and recombining "building blocks", i.e. low order, low defining-length [[Schema (genetic algorithms)|schemata]] with above average fitness.
# A hypothesis that a genetic algorithm performs adaptation by implicitly and efficiently implementing this heuristic.

Goldberg describes the heuristic as follows:

:"Short, low order, and highly fit schemata are sampled, [[crossover (genetic algorithm)|recombined]] [crossed over], and resampled to form strings of potentially higher fitness. In a way, by working with these particular schemata [the building blocks], we have reduced the complexity of our problem; instead of building high-performance strings by trying every conceivable combination, we construct better and better strings from the best partial solutions of past samplings.

:"Because highly fit schemata of low defining length and low order play such an important role in the action of genetic algorithms, we have already given them a special name: building blocks. Just as a child creates magnificent fortresses through the arrangement of simple blocks of wood, so does a genetic algorithm seek near optimal performance through the juxtaposition of short, low-order, high-performance schemata, or building blocks."{{sfn|Goldberg|1989|p=41}}

Despite the lack of consensus regarding the validity of the building-block hypothesis, it has been consistently evaluated and used as reference throughout the years. Many [[estimation of distribution algorithm]]s, for example, have been proposed in an attempt to provide an environment in which the hypothesis would hold.&lt;ref&gt;{{cite book|last1=Harik|first1=Georges R.|last2=Lobo|first2=Fernando G.|last3=Sastry|first3=Kumara|title=Linkage Learning via Probabilistic Modeling in the Extended Compact Genetic Algorithm (ECGA)|journal=Scalable Optimization Via Probabilistic Modeling|volume=33|date=1 January 2006|pages=39–61|doi=10.1007/978-3-540-34954-9_3|language=en|series=Studies in Computational Intelligence|isbn=978-3-540-34953-2}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last1=Pelikan|first1=Martin|last2=Goldberg|first2=David E.|last3=Cantú-Paz|first3=Erick|title=BOA: The Bayesian Optimization Algorithm|journal=Proceedings of the 1st Annual Conference on Genetic and Evolutionary Computation - Volume 1|date=1 January 1999|pages=525–532|url=http://dl.acm.org/citation.cfm?id=2933973|isbn=9781558606111|series=Gecco'99}}&lt;/ref&gt; Although good results have been reported for some classes of problems, skepticism concerning the generality and/or practicality of the building-block hypothesis as an explanation for GAs efficiency still remains. Indeed, there is a reasonable amount of work that attempts to understand its limitations from the perspective of estimation of distribution algorithms.&lt;ref&gt;{{cite book|last1=Coffin|first1=David|last2=Smith|first2=Robert E.|title=Linkage Learning in Estimation of Distribution Algorithms|journal=Linkage in Evolutionary Computation|volume=157|date=1 January 2008|pages=141–156|doi=10.1007/978-3-540-85068-7_7|language=en|series=Studies in Computational Intelligence|isbn=978-3-540-85067-0}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Echegoyen|first1=Carlos|last2=Mendiburu|first2=Alexander|last3=Santana|first3=Roberto|last4=Lozano|first4=Jose A.|title=On the Taxonomy of Optimization Problems Under Estimation of Distribution Algorithms|journal=Evolutionary Computation|date=8 November 2012|volume=21|issue=3|pages=471–495|doi=10.1162/EVCO_a_00095|pmid=23136917|s2cid=26585053|issn=1063-6560}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last1=Sadowski|first1=Krzysztof L.|last2=Bosman|first2=Peter A.N.|last3=Thierens|first3=Dirk|title=On the Usefulness of Linkage Processing for Solving MAX-SAT|journal=Proceedings of the 15th Annual Conference on Genetic and Evolutionary Computation|date=1 January 2013|pages=853–860|doi=10.1145/2463372.2463474|isbn=9781450319638|series=Gecco '13|hdl=1874/290291|s2cid=9986768}}&lt;/ref&gt;

== Limitations ==
There are limitations of the use of a genetic algorithm compared to alternative optimization algorithms:

* Repeated [[fitness function]] evaluation for complex problems is often the most prohibitive and limiting segment of artificial evolutionary algorithms. Finding the optimal solution to complex high-dimensional, multimodal problems often requires very expensive [[fitness function]] evaluations. In real world problems such as structural optimization problems, a single function evaluation may require several hours to several days of complete simulation. Typical optimization methods cannot deal with such types of problem. In this case, it may be necessary to forgo an exact evaluation and use an [[fitness approximation|approximated fitness]] that is computationally efficient. It is apparent that amalgamation of [[fitness approximation|approximate models]] may be one of the most promising approaches to convincingly use GA to solve complex real life problems.
* Genetic algorithms do not scale well with complexity. That is, where the number of elements which are exposed to mutation is large there is often an exponential increase in search space size. This makes it extremely difficult to use the technique on problems such as designing an engine, a house or a plane {{Citation needed|date=December 2020}}. In order to make such problems tractable to evolutionary search, they must be broken down into the simplest representation possible. Hence we typically see evolutionary algorithms encoding designs for fan blades instead of engines, building shapes instead of detailed construction plans, and airfoils instead of whole aircraft designs. The second problem of complexity is the issue of how to protect parts that have evolved to represent good solutions from further destructive mutation, particularly when their fitness assessment requires them to combine well with other parts.
* The "better" solution is only in comparison to other solutions. As a result, the stop criterion is not clear in every problem.
* In many problems, GAs have a tendency to converge towards [[local optimum|local optima]] or even arbitrary points rather than the [[global optimum]] of the problem. This means that it does not "know how" to sacrifice short-term fitness to gain longer-term fitness. The likelihood of this occurring depends on the shape of the [[fitness landscape]]: certain problems may provide an easy ascent towards a global optimum, others may make it easier for the function to find the local optima. This problem may be alleviated by using a different fitness function, increasing the rate of mutation, or by using selection techniques that maintain a diverse population of solutions,&lt;ref&gt;{{cite journal|last1=Taherdangkoo|first1=Mohammad|last2=Paziresh |first2=Mahsa |last3=Yazdi |first3=Mehran |last4= Bagheri |first4=Mohammad Hadi |title=An efficient algorithm for function optimization: modified stem cells algorithm|journal=Central European Journal of Engineering|date=19 November 2012|volume=3|issue=1|pages=36–50|doi=10.2478/s13531-012-0047-8|doi-access=free}}&lt;/ref&gt; although the [[No free lunch in search and optimization|No Free Lunch theorem]]&lt;ref&gt;Wolpert, D.H., Macready, W.G., 1995. No Free Lunch Theorems for Optimisation. Santa Fe Institute, SFI-TR-05-010, Santa Fe.&lt;/ref&gt; proves that there is no general solution to this problem. A common technique to maintain diversity is to impose a "niche penalty", wherein, any group of individuals of sufficient similarity (niche radius) have a penalty added, which will reduce the representation of that group in subsequent generations, permitting other (less similar) individuals to be maintained in the population. This trick, however, may not be effective, depending on the landscape of the problem. Another possible technique would be to simply replace part of the population with randomly generated individuals, when most of the population is too similar to each other. Diversity is important in genetic algorithms (and [[genetic programming]]) because crossing over a homogeneous population does not yield new solutions. In [[Evolution strategy|evolution strategies]] and [[evolutionary programming]], diversity is not essential because of a greater reliance on mutation.
* Operating on dynamic data sets is difficult, as genomes begin to converge early on towards solutions which may no longer be valid for later data. Several methods have been proposed to remedy this by increasing genetic diversity somehow and preventing early convergence, either by increasing the probability of mutation when the solution quality drops (called ''triggered hypermutation''), or by occasionally introducing entirely new, randomly generated elements into the gene pool (called ''random immigrants''). Again, [[Evolution strategy|evolution strategies]] and [[evolutionary programming]] can be implemented with a so-called "comma strategy" in which parents are not maintained and new parents are selected only from offspring. This can be more effective on dynamic problems.
* GAs cannot effectively solve problems in which the only fitness measure is a single right/wrong measure (like [[decision problem]]s), as there is no way to converge on the solution (no hill to climb). In these cases, a random search may find a solution as quickly as a GA. However, if the situation allows the success/failure trial to be repeated giving (possibly) different results, then the ratio of successes to failures provides a suitable fitness measure.
* For specific optimization problems and problem instances, other optimization algorithms may be more efficient than genetic algorithms in terms of speed of convergence. Alternative and complementary algorithms include [[Evolution strategy|evolution strategies]], [[evolutionary programming]], [[simulated annealing]], [[Gaussian adaptation]], [[hill climbing]], and [[swarm intelligence]] (e.g.: [[ant colony optimization]], [[particle swarm optimization]]) and methods based on [[integer linear programming]]. The suitability of genetic algorithms is dependent on the amount of knowledge of the problem; well known problems often have better, more specialized approaches.

== Variants ==

=== Chromosome representation ===
{{main | genetic representation }}
The simplest algorithm represents each chromosome as a [[Bit array|bit string]]. Typically, numeric parameters can be represented by [[integer]]s, though it is possible to use [[floating point]] representations. The floating point representation is natural to [[Evolution strategy|evolution strategies]] and [[evolutionary programming]]. The notion of real-valued genetic algorithms has been offered but is really a misnomer because it does not really represent the building block theory that was proposed by [[John Henry Holland]] in the 1970s. This theory is not without support though, based on theoretical and experimental results (see below). The basic algorithm performs crossover and mutation at the bit level. Other variants treat the chromosome as a list of numbers which are indexes into an instruction table, nodes in a [[linked list]], [[associative array|hashes]], [[object (computer science)|objects]], or any other imaginable [[data structure]]. Crossover and mutation are performed so as to respect data element boundaries. For most data types, specific variation operators can be designed. Different chromosomal data types seem to work better or worse for different specific problem domains.

When bit-string representations of integers are used, [[Gray coding]] is often employed. In this way, small changes in the integer can be readily affected through mutations or crossovers. This has been found to help prevent premature convergence at so-called ''Hamming walls'', in which too many simultaneous mutations (or crossover events) must occur in order to change the chromosome to a better solution.

Other approaches involve using arrays of real-valued numbers instead of bit strings to represent chromosomes. Results from the theory of schemata suggest that in general the smaller the alphabet, the better the performance, but it was initially surprising to researchers that good results were obtained from using real-valued chromosomes. This was explained as the set of real values in a finite population of chromosomes as forming a ''virtual alphabet'' (when selection and recombination are dominant) with a much lower cardinality than would be expected from a floating point representation.&lt;ref name=Goldberg1991&gt;{{cite book|last=Goldberg|first=David E.|title=Parallel Problem Solving from Nature|chapter=The theory of virtual alphabets|journal=Parallel Problem Solving from Nature, Lecture Notes in Computer Science|year=1991|volume=496|pages=13–22|doi=10.1007/BFb0029726|series=Lecture Notes in Computer Science|isbn=978-3-540-54148-6}}&lt;/ref&gt;&lt;ref name=Janikow1991&gt;{{cite journal|last1=Janikow|first1=C. Z.|first2=Z. |last2=Michalewicz |title=An Experimental Comparison of Binary and Floating Point Representations in Genetic Algorithms|journal=Proceedings of the Fourth International Conference on Genetic Algorithms|year=1991|pages=31–36|url=http://www.cs.umsl.edu/~janikow/publications/1991/GAbin/text.pdf|access-date=2 July 2013}}&lt;/ref&gt;

An expansion of the Genetic Algorithm accessible problem domain can be obtained through more complex encoding of the solution pools by concatenating several types of heterogenously encoded genes into one chromosome.&lt;ref name=Patrascu2014&gt;{{cite journal|last1=Patrascu|first1=M.|last2=Stancu|first2=A.F.|last3=Pop|first3=F.|title=HELGA: a heterogeneous encoding lifelike genetic algorithm for population evolution modeling and simulation|journal=Soft Computing|year=2014|volume=18|issue=12|pages=2565–2576|doi=10.1007/s00500-014-1401-y|s2cid=29821873}}&lt;/ref&gt; This particular approach allows for solving optimization problems that require vastly disparate definition domains for the problem parameters. For instance, in problems of cascaded controller tuning, the internal loop controller structure can belong to a conventional regulator of three parameters, whereas the external loop could implement a linguistic controller (such as a fuzzy system) which has an inherently different description. This particular form of encoding requires a specialized crossover mechanism that recombines the chromosome by section, and it is a useful tool for the modelling and simulation of complex adaptive systems, especially evolution processes.

=== Elitism ===
A practical variant of the general process of constructing a new population is to allow the best organism(s) from the current generation to carry over to the next, unaltered. This strategy is known as ''elitist selection'' and guarantees that the solution quality obtained by the GA will not decrease from one generation to the next.&lt;ref&gt;{{cite conference |last1=Baluja |first1=Shumeet |first2=Rich |last2=Caruana |title=Removing the genetics from the standard genetic algorithm |conference=[[International Conference on Machine Learning|ICML]] |year=1995 |url=http://www.ri.cmu.edu/pub_files/pub2/baluja_shumeet_1995_1/baluja_shumeet_1995_1.pdf}}&lt;/ref&gt;

=== Parallel implementations ===
[[parallel algorithm|Parallel]] implementations of genetic algorithms come in two flavors. Coarse-grained parallel genetic algorithms assume a population on each of the computer nodes and migration of individuals among the nodes. Fine-grained parallel genetic algorithms assume an individual on each processor node which acts with neighboring individuals for selection and reproduction.
Other variants, like genetic algorithms for [[online optimization]] problems, introduce time-dependence or noise in the fitness function.

=== Adaptive GAs ===
Genetic algorithms with adaptive parameters (adaptive genetic algorithms, AGAs) is another significant and promising variant of genetic algorithms. The probabilities of crossover (pc) and mutation (pm) greatly determine the degree of solution accuracy and the convergence speed that genetic algorithms can obtain. Instead of using fixed values of ''pc'' and ''pm'', AGAs utilize the population information in each generation and adaptively adjust the ''pc'' and ''pm'' in order to maintain the population diversity as well as to sustain the convergence capacity. In AGA (adaptive genetic algorithm),&lt;ref&gt;{{Cite journal |last1=Srinivas |first1=M. |last2=Patnaik |first2=L. |title=Adaptive probabilities of crossover and mutation in genetic algorithms |journal=IEEE Transactions on System, Man and Cybernetics |volume=24 |issue=4 |pages=656–667 |year=1994 |doi=10.1109/21.286385 |url=http://eprints.iisc.ac.in/6971/2/adaptive.pdf }}&lt;/ref&gt; the adjustment of ''pc'' and ''pm'' depends on the fitness values of the solutions. In ''CAGA'' (clustering-based adaptive genetic algorithm),&lt;ref&gt;{{cite journal |last1=Zhang |first1=J. |last2=Chung |first2=H. |last3=Lo, W. L. |title=Clustering-Based Adaptive Crossover and Mutation Probabilities for Genetic Algorithms |journal=IEEE Transactions on Evolutionary Computation |volume=11 |issue=3 |pages=326&amp;ndash;335 |year=2007 |doi=10.1109/TEVC.2006.880727 |s2cid=2625150 }}&lt;/ref&gt; through the use of clustering analysis to judge the optimization states of the population, the adjustment of ''pc'' and ''pm'' depends on these optimization states.
It can be quite effective to combine GA with other optimization methods. GA tends to be quite good at finding generally good global solutions, but quite inefficient at finding the last few mutations to find the absolute optimum. Other techniques (such as [[Hill climbing|simple hill climbing]]) are quite efficient at finding absolute optimum in a limited region. Alternating GA and hill climbing can improve the efficiency of GA {{Citation needed|date=July 2016}} while overcoming the lack of robustness of hill climbing.

This means that the rules of genetic variation may have a different meaning in the natural case. For instance &amp;ndash; provided that steps are stored in consecutive order &amp;ndash; crossing over may sum a number of steps from maternal DNA adding a number of steps from paternal DNA and so on. This is like adding vectors that more probably may follow a ridge in the phenotypic landscape. Thus, the efficiency of the process may be increased by many orders of magnitude. Moreover, the [[Chromosomal inversion|inversion operator]] has the opportunity to place steps in consecutive order or any other suitable order in favour of survival or efficiency.&lt;ref&gt;See for instance [http://www.thisurlisfalse.com/evolution-in-a-nutshell/ Evolution-in-a-nutshell] {{Webarchive|url=https://web.archive.org/web/20160415193505/http://www.thisurlisfalse.com/evolution-in-a-nutshell/ |date=15 April 2016 }} or example in [[travelling salesman problem]], in particular the use of an [[edge recombination operator]].&lt;/ref&gt;

A variation, where the population as a whole is evolved rather than its individual members, is known as gene pool recombination.

A number of variations have been developed to attempt to improve performance of GAs on problems with a high degree of fitness epistasis, i.e. where the fitness of a solution consists of interacting subsets of its variables. Such algorithms aim to learn (before exploiting) these beneficial phenotypic interactions. As such, they are aligned with the Building Block Hypothesis in adaptively reducing disruptive recombination. Prominent examples of this approach include the mGA,&lt;ref&gt;{{cite journal |url=http://www.complex-systems.com/issues/03-5.html |first1=D. E. |last1=Goldberg |first2=B. |last2=Korb |first3=K. |last3=Deb |title=Messy Genetic Algorithms : Motivation Analysis, and First Results |journal=Complex Systems |volume=5 |issue=3 |pages=493–530 |year=1989 }}&lt;/ref&gt; GEMGA&lt;ref&gt;[https://www.osti.gov/servlets/purl/524858 Gene expression: The missing link in evolutionary computation]&lt;/ref&gt; and LLGA.&lt;ref&gt;{{cite thesis |last=Harik |first=G. |date=1997 |title=Learning linkage to efficiently solve problems of bounded difficulty using genetic algorithms |type=PhD |publisher=Dept. Computer Science, University of Michigan, Ann Arbour |url=http://portal.acm.org/citation.cfm?id=269517 }}&lt;/ref&gt;

== Problem domains ==
Problems which appear to be particularly appropriate for solution by genetic algorithms include [[Timeline|timetabling]] and scheduling problems, and many scheduling software packages are based on GAs{{Citation needed|date=December 2011}}. GAs have also been applied to [[engineering]]&lt;ref&gt;Tomoiagă B, Chindriş M, Sumper A, Sudria-Andreu A, Villafafila-Robles R. [http://www.mdpi.com/1996-1073/6/3/1439/pdf Pareto Optimal Reconfiguration of Power Distribution Systems Using a Genetic Algorithm Based on NSGA-II. ] Energies. 2013; 6(3):1439-1455.&lt;/ref&gt; and to reducing the length of psychological questionnaires.&lt;ref name=Noetel2019&gt;{{cite journal |doi= 10.1016/j.psychsport.2019.101545 |title=Using genetic algorithms to abbreviate the Mindfulness Inventory for Sport: A substantive-methodological synthesis |journal= Psychology of Sport and Exercise |volume=45 |issue=101545|year=2019 |last1=Noetel |first1= Michael |last2=Ciarrochi |first2=Joseph|last3=Sahdra |first3=Baljinder|last4=Lonsdale |first4=Chris|page=101545 |url=http://psyarxiv.com/ykqbp/ | name-list-style = vanc}}&lt;/ref&gt; Genetic algorithms are often applied as an approach to solve [[global optimization]] problems.

As a general rule of thumb genetic algorithms might be useful in problem domains that have a complex [[fitness landscape]] as mixing, i.e., [[Mutation (genetic algorithm)|mutation]] in combination with [[Crossover (genetic algorithm)|crossover]], is designed to move the population away from [[local optima]] that a traditional [[hill climbing]] algorithm might get stuck in. Observe that commonly used crossover operators cannot change any uniform population. Mutation alone can provide ergodicity of the overall genetic algorithm process (seen as a [[Markov chain]]).

Examples of problems solved by genetic algorithms include: mirrors designed to funnel sunlight to a solar collector,&lt;ref&gt;{{cite web|last=Gross|first=Bill|title=A solar energy system that tracks the sun|url=http://www.ted.com/talks/bill_gross_on_new_energy.html|work=TED|access-date=20 November 2013}}&lt;/ref&gt; antennae designed to pick up radio signals in space,&lt;ref&gt;{{citation |first1=G. S. |last1=Hornby |first2=D. S. |last2=Linden |first3=J. D. |last3=Lohn |url=http://ti.arc.nasa.gov/m/pub-archive/1244h/1244%20(Hornby).pdf |title=Automated Antenna Design with Evolutionary Algorithms}}&lt;/ref&gt; walking methods for computer figures,&lt;ref&gt;{{Cite web | url=http://goatstream.com/research/papers/SA2013/index.html | title=Flexible Muscle-Based Locomotion for Bipedal Creatures}}&lt;/ref&gt; optimal design of aerodynamic bodies in complex flowfields&lt;ref&gt;{{Cite journal|last1=Evans|first1=B.|last2=Walton|first2=S.P.|date=December 2017|title=Aerodynamic optimisation of a hypersonic reentry vehicle based on solution of the Boltzmann–BGK equation and evolutionary optimisation|journal=Applied Mathematical Modelling|volume=52|pages=215–240|doi=10.1016/j.apm.2017.07.024|issn=0307-904X|url=https://cronfa.swan.ac.uk/Record/cronfa34688}}&lt;/ref&gt;

In his ''Algorithm Design Manual'', [[Steven Skiena|Skiena]] advises against genetic algorithms for any task:

{{blockquote|[I]t is quite unnatural to model applications in terms of genetic operators like mutation and crossover on bit strings. The pseudobiology adds another level of complexity between you and your problem. Second, genetic algorithms take a very long time on nontrivial problems. [...] [T]he analogy with evolution—where significant progress require [sic] millions of years—can be quite appropriate.
[...]
I have never encountered any problem where genetic algorithms seemed to me the right way to attack it. Further, I have never seen any computational results reported using genetic algorithms that have favorably impressed me. Stick to [[simulated annealing]] for your heuristic search voodoo needs.|Steven Skiena&lt;ref&gt;{{cite book |last=Skiena |first=Steven |author-link=Steven Skiena |title = The Algorithm Design Manual |publisher=[[Springer Science+Business Media]] |edition=2nd |year = 2010 |isbn=978-1-849-96720-4}}&lt;/ref&gt;{{rp|267}}}}

== History ==
In 1950, [[Alan Turing]] proposed a "learning machine" which would parallel the principles of evolution.&lt;ref name="mind.oxfordjournals.org"&gt;{{cite journal|last1=Turing|first1=Alan M.|title=Computing machinery and intelligence|journal=Mind|volume=LIX|issue=238|pages=433–460|doi=10.1093/mind/LIX.236.433|url=http://mind.oxfordjournals.org/content/LIX/236/433|date=October 1950}}&lt;/ref&gt; Computer simulation of evolution started as early as in 1954 with the work of [[Nils Aall Barricelli]], who was using the computer at the [[Institute for Advanced Study]] in [[Princeton, New Jersey]].&lt;ref name="Barricelli 1954 45–68"&gt;{{cite journal|last=Barricelli|first=Nils Aall|year=1954|author-link=Nils Aall Barricelli|title=Esempi numerici di processi di evoluzione|journal=Methodos|pages=45–68}}&lt;/ref&gt;&lt;ref name="Barricelli 1957 143–182"&gt;{{cite journal|last=Barricelli|first=Nils Aall|year=1957|author-link=Nils Aall Barricelli|title=Symbiogenetic evolution processes realized by artificial methods|journal=Methodos|pages=143–182}}&lt;/ref&gt; His 1954 publication was not widely noticed. Starting in 1957,&lt;ref name="Fraser 1957 484–491"&gt;{{cite journal|last=Fraser|first=Alex|author-link=Alex Fraser (scientist)|year=1957|title=Simulation of genetic systems by automatic digital computers. I. Introduction|journal=Aust. J. Biol. Sci.|volume=10|issue=4|pages=484–491|doi=10.1071/BI9570484|doi-access=free}}&lt;/ref&gt; the Australian quantitative geneticist [[Alex Fraser (scientist)|Alex Fraser]] published a series of papers on simulation of [[artificial selection]] of organisms with multiple loci controlling a measurable trait. From these beginnings, computer simulation of evolution by biologists became more common in the early 1960s, and the methods were described in books by Fraser and Burnell (1970)&lt;ref name="Fraser 1970"&gt;{{cite book|last1=Fraser|first1=Alex|author-link=Alex Fraser (scientist)|first2=Donald |last2=Burnell|year=1970|title=Computer Models in Genetics|publisher=McGraw-Hill|location=New York|isbn=978-0-07-021904-5}}&lt;/ref&gt; and Crosby (1973).&lt;ref name="Crosby 1973"&gt;{{cite book|last=Crosby|first=Jack L.|year=1973|title=Computer Simulation in Genetics|publisher=John Wiley &amp; Sons|location=London|isbn=978-0-471-18880-3}}&lt;/ref&gt; Fraser's simulations included all of the essential elements of modern genetic algorithms. In addition, [[Hans-Joachim Bremermann]] published a series of papers in the 1960s that also adopted a population of solution to optimization problems, undergoing recombination, mutation, and selection. Bremermann's research also included the elements of modern genetic algorithms.&lt;ref&gt;[http://berkeley.edu/news/media/releases/96legacy/releases.96/14319.html 02.27.96 - UC Berkeley's Hans Bremermann, professor emeritus and pioneer in mathematical biology, has died at 69]&lt;/ref&gt; Other noteworthy early pioneers include Richard Friedberg, George Friedman, and Michael Conrad. Many early papers are reprinted by [[David B. Fogel|Fogel]] (1998).&lt;ref&gt;{{cite book|last=Fogel|first=David B. (editor)|year=1998|title=Evolutionary Computation: The Fossil Record|publisher=IEEE Press|location=New York|isbn=978-0-7803-3481-6}}&lt;/ref&gt;

Although Barricelli, in work he reported in 1963, had simulated the evolution of ability to play a simple game,&lt;ref&gt;{{cite journal|last=Barricelli|first=Nils Aall|year=1963|title=Numerical testing of evolution theories. Part II. Preliminary tests of performance, symbiogenesis and terrestrial life|journal=Acta Biotheoretica|volume=16|issue=3–4|pages=99–126|doi=10.1007/BF01556602|s2cid=86717105}}&lt;/ref&gt; [[artificial evolution]] only became a widely recognized optimization method as a result of the work of [[Ingo Rechenberg]] and [[Hans-Paul Schwefel]] in the 1960s and early 1970s &amp;ndash; Rechenberg's group was able to solve complex engineering problems through [[Evolution strategy|evolution strategies]].&lt;ref&gt;{{cite book|last=Rechenberg|first=Ingo|year=1973|title=Evolutionsstrategie|place=Stuttgart|publisher=Holzmann-Froboog|isbn=978-3-7728-0373-4}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last=Schwefel|first=Hans-Paul|year=1974|title=Numerische Optimierung von Computer-Modellen (PhD thesis)}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last=Schwefel|first=Hans-Paul|year=1977|title=Numerische Optimierung von Computor-Modellen mittels der Evolutionsstrategie : mit einer vergleichenden Einführung in die Hill-Climbing- und Zufallsstrategie|place=Basel; Stuttgart | publisher=Birkhäuser| isbn=978-3-7643-0876-6}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last=Schwefel|first=Hans-Paul|year=1981|title=Numerical optimization of computer models (Translation of 1977 Numerische Optimierung von Computor-Modellen mittels der Evolutionsstrategie|place=Chichester ; New York|publisher=Wiley|isbn=978-0-471-09988-8}}&lt;/ref&gt; Another approach was the evolutionary programming technique of [[Lawrence J. Fogel]], which was proposed for generating artificial intelligence. [[Evolutionary programming]] originally used finite state machines for predicting environments, and used variation and selection to optimize the predictive logics. Genetic algorithms in particular became popular through the work of [[John Henry Holland|John Holland]] in the early 1970s, and particularly his book ''Adaptation in Natural and Artificial Systems'' (1975). His work originated with studies of [[cellular automata]], conducted by [[John Henry Holland|Holland]] and his students at the [[University of Michigan]]. Holland introduced a formalized framework for predicting the quality of the next generation, known as [[Holland's Schema Theorem]]. Research in GAs remained largely theoretical until the mid-1980s, when The First International Conference on Genetic Algorithms was held in [[Pittsburgh, Pennsylvania]].

===Commercial products===
In the late 1980s, General Electric started selling the world's first genetic algorithm product, a mainframe-based toolkit designed for industrial processes.&lt;ref&gt;{{Cite book|url=https://books.google.com/books?id=-MszVdu_PAMC&amp;q=general+electric+genetic+algorithm+mainframe|title=An Approach to Designing an Unmanned Helicopter Autopilot Using Genetic Algorithms and Simulated Annealing|last=Aldawoodi|first=Namir|year=2008|isbn=978-0549773498|pages=99|via=Google Books}}&lt;/ref&gt;{{Circular reference|date=January 2021}} 
In 1989, Axcelis, Inc. released [[Evolver (software)|Evolver]], the world's first commercial GA product for desktop computers. [[The New York Times]] technology writer [[John Markoff]] wrote&lt;ref&gt;{{cite news|last=Markoff|first=John|title=What's the Best Answer? It's Survival of the Fittest|newspaper=New York Times|url=https://www.nytimes.com/1990/08/29/business/business-technology-what-s-the-best-answer-it-s-survival-of-the-fittest.html|access-date=2016-07-13|date=29 August 1990}}&lt;/ref&gt; about Evolver in 1990, and it remained the only interactive commercial genetic algorithm until 1995.&lt;ref&gt;Ruggiero, Murray A.. (1 August 2009) [http://www.futuresmag.com/2009/08/01/fifteen-years-and-counting?t=technology&amp;page=2 Fifteen years and counting] {{Webarchive|url=https://web.archive.org/web/20160130054823/http://www.futuresmag.com/2009/08/01/fifteen-years-and-counting?t=technology&amp;page=2 |date=30 January 2016 }}. Futuresmag.com. Retrieved on 2013-08-07.&lt;/ref&gt; Evolver was sold to Palisade in 1997, translated into several languages, and is currently in its 6th version.&lt;ref&gt;[http://www.palisade.com/evolver/ Evolver: Sophisticated Optimization for Spreadsheets]. Palisade. Retrieved on 2013-08-07.&lt;/ref&gt; Since the 1990s, [[MATLAB]] has built in three [[derivative-free optimization]] heuristic algorithms (simulated annealing, particle swarm optimization, genetic algorithm) and two direct search algorithms (simplex search, pattern search).&lt;ref&gt;[https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8736798&amp;tag=1 Benchmarks for Evaluating Optimization Algorithms and Benchmarking MATLAB Derivative-Free Optimizers for Practitioners’Rapid Access], IEEE Access, vol.7, 2019.&lt;/ref&gt;

== Related techniques ==
{{See also|List of genetic algorithm applications}}

===Parent fields===
Genetic algorithms are a sub-field:
*[[Evolutionary algorithms]]
*[[Evolutionary computing]]
*[[Metaheuristic]]s
*[[Stochastic optimization]]
*[[Optimization (mathematics)|Optimization]]

===Related fields===

====Evolutionary algorithms====
{{More citations needed section|date=May 2011}}
{{main|Evolutionary algorithm}}
Evolutionary algorithms is a sub-field of [[Evolutionary Computation|evolutionary computing]].

* [[Evolution strategy|Evolution strategies]] (ES, see Rechenberg, 1994) evolve individuals by means of mutation and intermediate or discrete recombination. ES algorithms are designed particularly to solve problems in the real-value domain.&lt;ref&gt;{{cite book|last=Cohoon|first=J|display-authors=etal|title=Evolutionary algorithms for the physical design of VLSI circuits|url= https://www.ifte.de/mitarbeiter/lienig/cohoon.pdf|journal=Advances in Evolutionary Computing: Theory and Applications|publisher= Springer, pp. 683-712, 2003|isbn=978-3-540-43330-9|year=2002}}&lt;/ref&gt; They use self-adaptation to adjust control parameters of the search. De-randomization of self-adaptation has led to the contemporary Covariance Matrix Adaptation Evolution Strategy ([[CMA-ES]]).
* [[Evolutionary programming]] (EP) involves populations of solutions with primarily mutation and selection and arbitrary representations. They use self-adaptation to adjust parameters, and can include other variation operations such as combining information from multiple parents.
* [[Estimation of Distribution Algorithm]] (EDA) substitutes traditional reproduction operators by model-guided operators. Such models are learned from the population by employing machine learning techniques and represented as Probabilistic Graphical Models, from which new solutions can be sampled&lt;ref&gt;{{cite book|last1=Pelikan|first1=Martin|last2=Goldberg|first2=David E.|last3=Cantú-Paz|first3=Erick|title=BOA: The Bayesian Optimization Algorithm|journal=Proceedings of the 1st Annual Conference on Genetic and Evolutionary Computation - Volume 1|date=1 January 1999|pages=525–532|url=http://dl.acm.org/citation.cfm?id=2933973|isbn=9781558606111|series=Gecco'99}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last1=Pelikan|first1=Martin|title=Hierarchical Bayesian optimization algorithm : toward a new generation of evolutionary algorithms|date=2005|publisher=Springer|location=Berlin [u.a.]|isbn=978-3-540-23774-7|edition=1st}}&lt;/ref&gt; or generated from guided-crossover.&lt;ref&gt;{{cite book|last1=Thierens|first1=Dirk|chapter=The Linkage Tree Genetic Algorithm|journal=Parallel Problem Solving from Nature, PPSN XI|date=11 September 2010|pages=264–273|doi=10.1007/978-3-642-15844-5_27|language=en|isbn=978-3-642-15843-8}}&lt;/ref&gt;
* [[Gene expression programming]] (GEP) also uses populations of computer programs. These complex computer programs are encoded in simpler linear chromosomes of fixed length, which are afterwards expressed as expression trees. Expression trees or computer programs evolve because the chromosomes undergo mutation and recombination in a manner similar to the canonical GA. But thanks to the special organization of GEP chromosomes, these genetic modifications always result in valid computer programs.&lt;ref&gt;{{cite web|last=Ferreira|first=C|title=Gene Expression Programming: A New Adaptive Algorithm for Solving Problems|url= http://www.gene-expression-programming.com/webpapers/GEP.pdf|publisher= Complex Systems, Vol. 13, issue 2: 87-129.}}&lt;/ref&gt;
* [[Genetic programming]] (GP) is a related technique popularized by [[John Koza]] in which computer programs, rather than function parameters, are optimized. Genetic programming often uses [[Tree (data structure)|tree-based]] internal [[data structure]]s to represent the computer programs for adaptation instead of the [[List (computing)|list]] structures typical of genetic algorithms.
* [[Grouping genetic algorithm]] (GGA) is an evolution of the GA where the focus is shifted from individual items, like in classical GAs, to groups or subset of items.&lt;ref name="Falkenauer"&gt;{{cite book|last=Falkenauer|first=Emanuel|author-link=Emanuel Falkenauer|year=1997|title=Genetic Algorithms and Grouping Problems|publisher=John Wiley &amp; Sons Ltd|location=Chichester, England|isbn=978-0-471-97150-4}}&lt;/ref&gt; The idea behind this GA evolution proposed by [[Emanuel Falkenauer]] is that solving some complex problems, a.k.a. ''clustering'' or ''partitioning'' problems where a set of items must be split into disjoint group of items in an optimal way, would better be achieved by making characteristics of the groups of items equivalent to genes. These kind of problems include [[bin packing problem|bin packing]], line balancing, [[cluster analysis|clustering]] with respect to a distance measure, equal piles, etc., on which classic GAs proved to perform poorly. Making genes equivalent to groups implies chromosomes that are in general of variable length, and special genetic operators that manipulate whole groups of items. For bin packing in particular, a GGA hybridized with the Dominance Criterion of Martello and Toth, is arguably the best technique to date.
* [[Interactive evolutionary algorithm]]s are evolutionary algorithms that use human evaluation. They are usually applied to domains where it is hard to design a computational fitness function, for example, evolving images, music, artistic designs and forms to fit users' aesthetic preference.

====Swarm intelligence====
{{main|Swarm intelligence}}
Swarm intelligence is a sub-field of [[Evolutionary Computation|evolutionary computing]].

* [[Ant colony optimization]] ('''ACO''') uses many ants (or agents) equipped with a pheromone model to traverse the solution space and find locally productive areas. Although considered an [[Estimation of distribution algorithm]],&lt;ref&gt;{{cite journal|last1=Zlochin|first1=Mark|last2=Birattari|first2=Mauro|last3=Meuleau|first3=Nicolas|last4=Dorigo|first4=Marco|title=Model-Based Search for Combinatorial Optimization: A Critical Survey|journal=Annals of Operations Research|date=1 October 2004|volume=131|issue=1–4|pages=373–395|doi=10.1023/B:ANOR.0000039526.52305.af|language=en|issn=0254-5330|citeseerx=10.1.1.3.427|s2cid=63137}}&lt;/ref&gt;
* [[Particle swarm optimization]] (PSO) is a computational method for multi-parameter optimization which also uses population-based approach. A population (swarm) of candidate solutions (particles) moves in the search space, and the movement of the particles is influenced both by their own best known position and swarm's global best known position. Like genetic algorithms, the PSO method depends on information sharing among population members. In some problems the PSO is often more computationally efficient than the GAs, especially in unconstrained problems with continuous variables.&lt;ref&gt;Rania Hassan, Babak Cohanim, Olivier de Weck, Gerhard Vente
r (2005) [https://www.mit.edu/~deweck/PDF_archive/3%20Refereed%20Conference/3_50_AIAA-2005-1897.pdf A comparison of particle swarm optimization and the genetic algorithm]&lt;/ref&gt;

====Other evolutionary computing algorithms====

Evolutionary computation is a sub-field of the [[metaheuristic]] methods.

* [[Electimize algorithm]] is an evolutionary algorithm that simulates the phenomenon of electron flow and electrical conductivity. Some current research showed Electimize to be more efficient in solving NP-hard optimization problems than traditional evolutionary algorithms. The algorithm provides higher capacity in searching the solution space extensively, and identifying global optimal alternatives. Unlike other evolutionary algorithms, Electimize evaluates the quality of the values in the solution string independently.&lt;ref&gt;{{Cite journal|last1=Khalafallah Ahmed|last2=Abdel-Raheem Mohamed|date=2011-05-01|title=Electimize: New Evolutionary Algorithm for Optimization with Application in Construction Engineering|journal=Journal of Computing in Civil Engineering|volume=25|issue=3|pages=192–201|doi=10.1061/(ASCE)CP.1943-5487.0000080}}&lt;/ref&gt;
* [[Memetic algorithm]] (MA), often called ''hybrid genetic algorithm'' among others, is a population-based method in which solutions are also subject to local improvement phases. The idea of memetic algorithms comes from [[meme]]s, which unlike genes, can adapt themselves. In some problem areas they are shown to be more efficient than traditional evolutionary algorithms.
* [[Bacteriologic algorithm]]s (BA) inspired by [[evolutionary ecology]] and, more particularly, bacteriologic adaptation. Evolutionary ecology is the study of living organisms in the context of their environment, with the aim of discovering how they adapt. Its basic concept is that in a heterogeneous environment, there is not one individual that fits the whole environment. So, one needs to reason at the population level. It is also believed BAs could be successfully applied to complex positioning problems (antennas for cell phones, urban planning, and so on) or data mining.&lt;ref&gt;{{cite journal|url=http://www.irisa.fr/triskell/publis/2005/Baudry05d.pdf|first=Benoit|last=Baudry |author2=Franck Fleurey |author3-link=Jean-Marc Jézéquel|author3=Jean-Marc Jézéquel |author4=Yves Le Traon|title=Automatic Test Case Optimization: A Bacteriologic Algorithm|date=March–April 2005|pages=76–82|journal=IEEE Software|issue=2|doi=10.1109/MS.2005.30|volume=22|s2cid=3559602|access-date=9 August 2009}}&lt;/ref&gt;
* [[Cultural algorithm]] (CA) consists of the population component almost identical to that of the genetic algorithm and, in addition, a knowledge component called the belief space.
* [[Differential evolution]] (DS) inspired by migration of superorganisms.&lt;ref&gt;{{cite journal|last=Civicioglu|first=P.|title=Transforming Geocentric Cartesian Coordinates to Geodetic Coordinates by Using Differential Search Algorithm|journal=Computers &amp;Geosciences|year=2012|volume=46|pages=229–247|doi=10.1016/j.cageo.2011.12.011|bibcode=2012CG.....46..229C}}&lt;/ref&gt;
* [[Gaussian adaptation]] (normal or natural adaptation, abbreviated NA to avoid confusion with GA) is intended for the maximisation of manufacturing yield of signal processing systems. It may also be used for ordinary parametric optimisation. It relies on a certain theorem valid for all regions of acceptability and all Gaussian distributions. The efficiency of NA relies on information theory and a certain theorem of efficiency. Its efficiency is defined as information divided by the work needed to get the information.&lt;ref&gt;{{cite journal|last=Kjellström|first=G.|title= On the Efficiency of Gaussian Adaptation|journal=Journal of Optimization Theory and Applications|volume=71|issue=3|pages=589–597|date=December 1991|doi= 10.1007/BF00941405|s2cid=116847975}}&lt;/ref&gt; Because NA maximises mean fitness rather than the fitness of the individual, the landscape is smoothed such that valleys between peaks may disappear. Therefore it has a certain "ambition" to avoid local peaks in the fitness landscape. NA is also good at climbing sharp crests by adaptation of the moment matrix, because NA may maximise the disorder ([[average information]]) of the Gaussian simultaneously keeping the [[mean fitness]] constant.

====Other metaheuristic methods====

Metaheuristic methods broadly fall within [[Stochastic optimization|stochastic]] optimisation methods.

* [[Simulated annealing]] (SA) is a related global optimization technique that traverses the search space by testing random mutations on an individual solution. A mutation that increases fitness is always accepted. A mutation that lowers fitness is accepted probabilistically based on the difference in fitness and a decreasing temperature parameter. In SA parlance, one speaks of seeking the lowest energy instead of the maximum fitness. SA can also be used within a standard GA algorithm by starting with a relatively high rate of mutation and decreasing it over time along a given schedule.
* [[Tabu search]] (TS) is similar to simulated annealing in that both traverse the solution space by testing mutations of an individual solution. While simulated annealing generates only one mutated solution, tabu search generates many mutated solutions and moves to the solution with the lowest energy of those generated. In order to prevent cycling and encourage greater movement through the solution space, a tabu list is maintained of partial or complete solutions. It is forbidden to move to a solution that contains elements of the tabu list, which is updated as the solution traverses the solution space.
* [[Extremal optimization]] (EO) Unlike GAs, which work with a population of candidate solutions, EO evolves a single solution and makes [[local search (optimization)|local]] modifications to the worst components. This requires that a suitable representation be selected which permits individual solution components to be assigned a quality measure ("fitness"). The governing principle behind this algorithm is that of ''emergent'' improvement through selectively removing low-quality components and replacing them with a randomly selected component. This is decidedly at odds with a GA that selects good solutions in an attempt to make better solutions.

====Other stochastic optimisation methods====

* The [[Cross-entropy method|cross-entropy (CE) method]] generates candidate solutions via a parameterized probability distribution. The parameters are updated via cross-entropy minimization, so as to generate better samples in the next iteration.
* Reactive search optimization (RSO) advocates the integration of sub-symbolic machine learning techniques into search heuristics for solving complex optimization problems. The word reactive hints at a ready response to events during the search through an internal online feedback loop for the self-tuning of critical parameters. Methodologies of interest for Reactive Search include machine learning and statistics, in particular [[reinforcement learning]], [[Active learning (machine learning)|active or query learning]], [[neural networks]], and [[metaheuristics]].

==See also==
* [[Genetic programming]]
* [[List of genetic algorithm applications]]
* [[particle filter|Genetic algorithms in signal processing (a.k.a. particle filters)]]
* [[Propagation of schema]]
* [[Universal Darwinism]]
* [[Metaheuristics]]
* [[Learning classifier system]]
* [[Rule-based machine learning]]

== References ==
{{Reflist|30em}}

== Bibliography ==
{{Refbegin}}
* {{Cite book | title=Genetic Programming &amp;ndash; An Introduction | last1=Banzhaf | first1=Wolfgang | last2=Nordin | first2=Peter | last3=Keller | first3=Robert | last4=Francone | first4=Frank | year=1998 | isbn=978-1558605107 | publisher=Morgan Kaufmann | location=San Francisco, CA | url-access=registration | url=https://archive.org/details/geneticprogrammi00wolf }}
* {{Cite journal|last1=Bies|first1=Robert R. |last2=Muldoon |first2=Matthew F. |last3=Pollock |first3=Bruce G. |last4=Manuck |first4=Steven |last5=Smith |first5=Gwenn |last6=Sale |first6=Mark E. |year=2006|title=A Genetic Algorithm-Based, Hybrid Machine Learning Approach to Model Selection|journal=Journal of Pharmacokinetics and Pharmacodynamics|volume=33 |issue=2 |pages=196–221 |pmid=16565924 |doi=10.1007/s10928-006-9004-6 |s2cid=39571129 }}
* {{Cite journal|last1=Cha|first1=Sung-Hyuk|last2=Tappert |first2=Charles C. |year=2009|title=A Genetic Algorithm for Constructing Compact Binary Decision Trees|journal=Journal of Pattern Recognition Research |volume=4|issue=1|pages=1–13|doi=10.13176/11.44|citeseerx=10.1.1.154.8314 }}
* {{Cite journal|last=Fraser|first=Alex S.|year=1957|title=Simulation of Genetic Systems by Automatic Digital Computers. I. Introduction|journal=Australian Journal of Biological Sciences|volume=10|issue=4|pages=484–491|doi=10.1071/BI9570484 |doi-access=free}}
* {{Cite book| last=Goldberg | first=David | year=1989 | title=Genetic Algorithms in Search, Optimization and Machine Learning | isbn=978-0201157673 | publisher=Addison-Wesley Professional | location=Reading, MA }}
* {{Cite book| last=Goldberg | first=David | year=2002 | title=The Design of Innovation: Lessons from and for Competent Genetic Algorithms | publisher=Kluwer Academic Publishers | location=Norwell, MA | isbn=978-1402070983 }}
* {{Cite book| last=Fogel | first=David | title=Evolutionary Computation: Toward a New Philosophy of Machine Intelligence | publisher=IEEE Press | location=Piscataway, NJ | edition=3rd | isbn=978-0471669517 | year=2006 }}
* {{Cite book | last=Holland | first=John | title=Adaptation in Natural and Artificial Systems | publisher=MIT Press | location=Cambridge, MA | year=1992 | isbn=978-0262581110 | url-access=registration | url=https://archive.org/details/adaptationinnatu00holl }}
* {{Cite book | last=Koza | first=John | title=Genetic Programming: On the Programming of Computers by Means of Natural Selection | year = 1992 | publisher=MIT Press | location=Cambridge, MA | isbn=978-0262111706 }}
* {{Cite book | last=Michalewicz | first=Zbigniew | year=1996 | title=Genetic Algorithms + Data Structures = Evolution Programs | publisher=Springer-Verlag | isbn=978-3540606765 }}
* {{Cite book | last=Mitchell | first=Melanie | title=An Introduction to Genetic Algorithms | year=1996 | publisher=MIT Press | location=Cambridge, MA | isbn = 9780585030944 }}
* {{Cite book |last1=Poli |first1=R. |last2=Langdon |first2=W. B. |last3=McPhee |first3=N. F. |year=2008 |title=A Field Guide to Genetic Programming | publisher=Lulu.com, freely available from the internet | isbn = 978-1-4092-0073-4 }}{{self-published inline|date=February 2020}}
* Rechenberg, Ingo (1994): Evolutionsstrategie '94, Stuttgart: Fromman-Holzboog.
* {{cite journal |last1=Schmitt |first1=Lothar M. |last2=Nehaniv |first2=Chrystopher L. |last3=Fujii |first3=Robert H. |date=1998 |url=https://www.sciencedirect.com/science/article/pii/S0304397598000048/pdf?md5=28a658a4dc5aef635bbf3c8560129925&amp;pid=1-s2.0-S0304397598000048-main.pdf&amp;_valck=1 |title=Linear analysis of genetic algorithms |journal=Theoretical Computer Science |volume=208 |pages=111&amp;ndash;148 }}
* {{cite journal |last1=Schmitt |first1=Lothar M. |date=2001 |title=Theory of Genetic Algorithms |journal=Theoretical Computer Science |volume=259 |issue=1–2 |pages=1&amp;ndash;61 |doi=10.1016/S0304-3975(00)00406-0 }}
* {{cite journal |last1=Schmitt |first1=Lothar M. |date=2004 |title=Theory of Genetic Algorithms II: models for genetic operators over the string-tensor representation of populations and convergence to global optima for arbitrary fitness function under scaling |journal=Theoretical Computer Science |volume=310 |issue=1–3 |pages=181&amp;ndash;231 |doi=10.1016/S0304-3975(03)00393-1 }}
* Schwefel, Hans-Paul (1974): Numerische Optimierung von Computer-Modellen (PhD thesis). Reprinted by Birkhäuser (1977).
* {{Cite book | last=Vose | first=Michael | year=1999 | title=The Simple Genetic Algorithm: Foundations and Theory | publisher=MIT Press | location=Cambridge, MA | isbn=978-0262220583 | url-access=registration | url=https://archive.org/details/TheSimpleG_00_Vose }}
* {{Cite journal | last=Whitley | first=Darrell | title=A genetic algorithm tutorial | journal=Statistics and Computing | doi=10.1007/BF00175354 | volume=4 | issue=2 | pages=65–85 | year=1994 | url=http://cobweb.cs.uga.edu/~potter/CompIntell/ga_tutorial.pdf | citeseerx=10.1.1.184.3999 | s2cid=3447126 }}&lt;!--| access-date=5 January 2013--&gt;
* {{Cite book | last1=Hingston | first1=Philip | last2=Barone | first2=Luigi | last3=Michalewicz | first3=Zbigniew | title=Design by Evolution: Advances in Evolutionary Design | year=2008 | publisher=Springer | isbn=978-3540741091 }}
* {{Cite book | last1=Eiben | first1=Agoston | last2=Smith | first2=James | year=2003 | title=Introduction to Evolutionary Computing | publisher=Springer | isbn=978-3540401841 }}
{{Refend}}

== External links ==

=== Resources ===
* [https://web.archive.org/web/20160303215222/http://www.geneticprogramming.com/ga/index.htm] Provides a list of resources in the genetic algorithms field
* [https://www.staracle.com/general/evolutionaryAlgorithms.php An Overview of the History and Flavors of Evolutionary Algorithms]

=== Tutorials ===
* [https://www2.econ.iastate.edu/tesfatsi/holland.gaintro.htm Genetic Algorithms - Computer programs that "evolve" in ways that resemble natural selection can solve complex problems even their creators do not fully understand] An excellent introduction to GA by John Holland and with an application to the Prisoner's Dilemma
* [http://www.i4ai.org/EA-demo/ An online interactive Genetic Algorithm tutorial for a reader to practise or learn how a GA works]: Learn step by step or watch global convergence in batch, change the population size, crossover rates/bounds, mutation rates/bounds and selection mechanisms, and add constraints.
* [https://web.archive.org/web/20130615042000/http://samizdat.mines.edu/ga_tutorial/ga_tutorial.ps A Genetic Algorithm Tutorial by Darrell Whitley Computer Science Department Colorado State University] An excellent tutorial with much theory
* [http://cs.gmu.edu/~sean/book/metaheuristics/ "Essentials of Metaheuristics"], 2009 (225 p). Free open text by Sean Luke.
* [http://www.it-weise.de/projects/book.pdf Global Optimization Algorithms &amp;ndash; Theory and Application]
* [https://mpatacchiola.github.io/blog/2017/03/14/dissecting-reinforcement-learning-5.html Genetic Algorithms in Python] Tutorial with the intuition behind GAs and Python implementation.
* [http://www-personal.umich.edu/~axe/research/Evolving.pdf Genetic Algorithms evolves to solve the prisoner's dilemma.] Written by Robert Axelrod.

{{Authority control}}

{{DEFAULTSORT:Genetic Algorithm}}
[[Category:Genetic algorithms| ]]
[[Category:Evolutionary algorithms]]
[[Category:Search algorithms]]
[[Category:Cybernetics]]
[[Category:Digital organisms]]
[[Category:Machine learning]]

[[sv:Genetisk programmering#Genetisk algoritm]]</text>
      <sha1>3hadvs675evnusuwsinqqcrve7csork</sha1>
    </revision>
  </page>
  <page>
    <title>Multiplicative weight update method</title>
    <ns>0</ns>
    <id>52242050</id>
    <revision>
      <id>994954445</id>
      <parentid>991647024</parentid>
      <timestamp>2020-12-18T12:01:24Z</timestamp>
      <contributor>
        <username>WikiCleanerBot</username>
        <id>18872885</id>
      </contributor>
      <minor/>
      <comment>v2.04b - [[User:WikiCleanerBot#T20|Bot T20 CW#61]] - Fix errors for [[WP:WCW|CW project]] (Reference before punctuation)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="23718" xml:space="preserve">{{Use dmy dates|date=September 2017}}
The '''multiplicative weights update method''' is an [[algorithmic technique]] most commonly used for decision making and prediction, and also widely deployed in game theory and algorithm design. The simplest use case is the problem of prediction from expert advice, in which a decision maker needs to iteratively decide on an expert whose advice to follow. The method assigns initial weights to the experts (usually identical initial weights), and updates these weights multiplicatively and iteratively according to the feedback of how well an expert performed: reducing it in case of poor performance, and increasing it otherwise. &lt;ref name = ref1&gt;{{cite web|url=http://www.theoryofcomputing.org/articles/v008a006/v008a006.pdf |title=The Multiplicative Weights Update Method: A Meta-Algorithm and Applications |date=May 2012}}&lt;/ref&gt; It was discovered repeatedly in very diverse fields such as machine learning ([[AdaBoost]], [[Winnow (algorithm)|Winnow]], Hedge), [[Mathematical optimization|optimization]] (solving [[Linear programming|linear programs]]), theoretical computer science (devising fast algorithm for [[Linear programming|LPs]] and [[Semidefinite programming|SDPs]]), and [[game theory]].

==Name==
"Multiplicative weights" implies the iterative rule used in algorithms derived from the multiplicative weight update method.&lt;ref name=ref2&gt;{{cite web |url=https://www.cs.cmu.edu/afs/cs.cmu.edu/academic/class/15859-f11/www/notes/lecture16.pdf |title= The Multiplicative Weights Algorithm* |access-date=2016-11-09}}&lt;/ref&gt; It is given with different names in the different fields where it was discovered or rediscovered.

==History and background==
The earliest known version of this technique was in an algorithm named "[[fictitious play]]" which was proposed in [[game theory]] in the early 1950s. Grigoriadis and Khachiyan&lt;ref&gt;{{cite web |title= A sublinear-time randomized approximation algorithm for matrix games. |date=1995 }}&lt;/ref&gt; applied a randomized variant of "fictitious play" to solve two-player [[zero-sum game]]s efficiently using the multiplicative weights algorithm. In this case, player allocates higher weight to the actions that had a better outcome and choose his strategy relying on these weights. In [[machine learning]], Littlestone applied the earliest form of the multiplicative weights update rule in his famous [[Winnow (algorithm)|winnow algorithm]], which is similar to Minsky and Papert's earlier [[Perceptron|perceptron learning algorithm]]. Later, he generalized the winnow algorithm to weighted majority algorithm. Freund and Schapire followed his steps and generalized the winnow algorithm in the form of hedge algorithm.

The multiplicative weights algorithm is also widely applied in [[computational geometry]] such as [[Kenneth L. Clarkson|Clarkson's]] algorithm for [[Linear programming|linear programming (LP)]] with a bounded number of variables in linear time.&lt;ref name="KENNETH L. CLARKSON pp. 452"&gt;KENNETH L. CLARKSON. '' A Las Vegas algorithm for linear programming when the dimension is small.'', In Proc. 29th FOCS, pp. 452–456. IEEE Comp. Soc. Press, 1988.[doi:10.1109/SFCS.1988.21961] 123, 152.&lt;/ref&gt;&lt;ref name="KENNETH L. CLARKSON 1995"&gt;KENNETH L. CLARKSON. ''A Las Vegas algorithm for linear and integer programming when the dimension is small.'', J. ACM, 42:488–499, 1995. [doi:10.1145/201019.201036] 123, 152.&lt;/ref&gt; Later, Bronnimann and Goodrich employed analogous methods to find [[Set cover problem|set covers]] for [[hypergraph]]s with small [[VC dimension]].&lt;ref name="M.T. GOODRICH. 1995"&gt;H. BRONNIMANN AND ¨ M.T. GOODRICH. ''Almost optimal set covers in finite VC-dimension.'', Discrete Comput. Geom., 14:463–479, 1995. Preliminary version in 10th Ann. Symp. Comp. Geom. (SCG'94). [doi:10.1007/BF02570718] 123, 152&lt;/ref&gt;

In [[Operations research|operation research]] and on-line statistical decision making problem field, the weighted majority algorithm and its more complicated versions have been found independently.

In computer science field, some researchers have previously observed the close relationships between multiplicative update algorithms used in different contexts. Young discovered the similarities between fast LP algorithms and Raghavan's method of pessimistic estimators for derandomization of randomized rounding algorithms; Klivans and Servedio linked boosting algorithms in learning theory to proofs of Yao's XOR Lemma; Garg and Khandekar defined a common framework for convex optimization problems that contains Garg-Konemann and Plotkin-Shmoys-Tardos as subcases.&lt;ref name=ref4&gt;{{cite web |url=http://www.satyenkale.com/papers/mw-survey.pdf |title= The Multiplicative Weights Update Method: A Meta-Algorithm and Applications |date=2012}}&lt;/ref&gt;

==General setup==
A binary decision needs to be made based on n experts’ opinions to attain an associated payoff. In the first round, all experts’ opinions have the same weight. The decision maker will make the first decision based on the majority of the experts' prediction. Then, in each successive round, the decision maker will repeatedly update the weight of each expert's opinion depending on the correctness of his prior predictions. Real life examples includes predicting if it is rainy tomorrow or if the stock market will go up or go down.

==Algorithm analysis==

===Halving algorithm&lt;ref name=ref2&gt;{{cite web |url=https://www.cs.cmu.edu/afs/cs.cmu.edu/academic/class/15859-f11/www/notes/lecture16.pdf |title= The Multiplicative Weights Algorithm* |access-date=2016-11-09}}&lt;/ref&gt;===

Given a sequential game played between an adversary and an aggregator who is advised by N experts, the goal is for the aggregator to make as few mistakes as possible. Assume there is an expert among the N experts who always gives the correct prediction. In the halving algorithm, only the consistent experts are retained. Experts who make mistakes will be dismissed. For every decision, the aggregator decides by taking a majority vote among the remaining experts. Therefore, every time the aggregator makes a mistake, at least half of the remaining experts are dismissed. The aggregator makes at most  {{math|log&lt;sub&gt;''2''&lt;/sub&gt;(''N'')}} mistakes.&lt;ref name=ref2&gt;{{cite web |url=https://www.cs.cmu.edu/afs/cs.cmu.edu/academic/class/15859-f11/www/notes/lecture16.pdf |title= The Multiplicative Weights Algorithm* |access-date=2016-11-09}}&lt;/ref&gt;

===Weighted majority algorithm&lt;ref name=ref4 /&gt;&lt;ref name=ref5&gt;{{cite web |url=https://www.cs.princeton.edu/courses/archive/fall13/cos521/lecnotes/lec8.pdf |title= Lecture 8: Decision-making under total uncertainty: the multiplicative weight algorithm |date=2013}}&lt;/ref&gt;===

Unlike halving algorithm which dismisses experts who have made mistakes, weighted majority algorithm discounts their advice. Given the same "expert advice" setup, suppose we have n decisions, and we need to select one decision for each loop. In each loop, every decision incurs a cost. All costs will be revealed after making the choice. The cost is 0 if the expert is correct, and 1 otherwise. this algorithm's goal is to limit its cumulative losses to roughly the same as the best of experts.
The very first algorithm that makes choice based on majority vote every iteration does not work since the majority of the experts can be wrong consistently every time. The weighted majority algorithm corrects above trivial algorithm by keeping a weight of experts instead of fixing the cost at either 1 or 0.&lt;ref name=ref4 /&gt; This would make fewer mistakes compared to halving algorithm.

    '''Initialization''': 
       Fix an &lt;math&gt;\eta \le 1/2&lt;/math&gt;. For each expert, associate the weight &lt;math&gt;{w_i}^1&lt;/math&gt;≔1.
    '''For''' &lt;math&gt;t&lt;/math&gt; = &lt;math&gt;\mathit{1}&lt;/math&gt;, &lt;math&gt;\mathit{2}&lt;/math&gt;,…,&lt;math&gt;T&lt;/math&gt;
       '''1'''. Make the prediction given by the weighted majority of the experts' predictions based on their weights&lt;math&gt;\mathbb{w_1}^t,..., \mathbb{w_n}^t&lt;/math&gt;. That is, choose 0 or 1 depending on which prediction has a higher total weight of experts advising it (breaking ties arbitrarily). 
       '''2'''. For every expert i that predicted wrongly, decrease his weight for the next round by multiplying it by a factor of (1-η):
            &lt;math&gt;w_{i}^{t+1}&lt;/math&gt;=&lt;math&gt;(1-\eta) w_{i}^{t}&lt;/math&gt; (update rule)

If &lt;math&gt;\eta =0&lt;/math&gt;, the weight of the expert's advice will remain the same. When &lt;math&gt;\eta&lt;/math&gt; increases, the weight of the expert's advice will decrease. Note that some researchers fix &lt;math&gt;\eta =1/2&lt;/math&gt; in weighted majority algorithm.

After &lt;math&gt;T&lt;/math&gt; steps, let &lt;math&gt;m_i^T&lt;/math&gt; be the number of mistakes of expert i and &lt;math&gt;M^T&lt;/math&gt; be the number of mistakes our algorithm has made. Then we have the following bound for every &lt;math&gt;i&lt;/math&gt;:

     &lt;math&gt;M^T \leq 2(1+\eta) m_i^T+ \frac{2 \ln(n)}{\eta}&lt;/math&gt;.

In particular, this holds for i which is the best expert. Since the best expert will have the least &lt;math&gt;m_i^T&lt;/math&gt;, it will give the best bound on the number of mistakes made by the algorithm as a whole.

===Randomized weighted majority algorithm&lt;ref name=ref2 /&gt;&lt;ref name=ref6&gt;{{cite web |url=http://www.cs.princeton.edu/courses/archive/spr06/cos511/scribe_notes/0330.pdf |title=COS 511: Foundations of Machine Learning |date=20 March 2006}}&lt;/ref&gt;===
Given the same setup with N experts. Consider the special situation where the proportions of experts predicting positive and negative, counting the weights, are both close to 50%. Then, there might be a tie. Following the weight update rule in weighted majority algorithm, the predictions made by the algorithm would be randomized. The algorithm calculates the probabilities of experts predicting positive or negatives, and then makes a random decision based on the computed fraction:

predict  
:&lt;math&gt;
f(x) = \begin{cases}1 &amp; \text{with probability} \frac{q_1}{W}\\0 &amp; \text{otherwise}\end{cases}
&lt;/math&gt;

where    
  &lt;math&gt;W= \sum_{i} { w_i} = q_0 + q_1&lt;/math&gt;.

The number of mistakes made by the randomized weighted majority algorithm is bounded as: 
  &lt;math&gt;E\left [ \# \text{mistakes of the learner} \right ] \leq \alpha_\beta \left ( \# \text{ mistakes of the best expert} \right ) + c_\beta \ln(N) &lt;/math&gt;

where     &lt;math&gt;\alpha_\beta= \frac{\ln(\frac{1}{\beta})}{1-\beta}&lt;/math&gt; and          &lt;math&gt;c_\beta=\frac{1}{1-\beta}&lt;/math&gt;.

Note that only the learning algorithm is randomized. The underlying assumption is that the examples and experts' predictions are not random. The only randomness is the randomness where the learner makes his own prediction.
In this randomized algorithm, &lt;math&gt;\alpha_\beta \rightarrow 1&lt;/math&gt; if &lt;math&gt;\beta \rightarrow 1&lt;/math&gt;. Compared to weighted algorithm, this randomness halved the number of mistakes the algorithm is going to make.&lt;ref name=ref7 /&gt; However, it is important to note that in some research, people define &lt;math&gt;\eta =1/2&lt;/math&gt; in weighted majority algorithm and allow &lt;math&gt;0\leq \eta \leq 1&lt;/math&gt; in [[randomized weighted majority algorithm]].&lt;ref name=ref2 /&gt;

==Applications==
The multiplicative weights method is usually used to solve a constrained optimization problem. Let each expert be the constraint in the problem, and the events represent the points in the area of interest. The punishment of the expert corresponds to how well its corresponding constraint is satisfied on the point represented by an event.&lt;ref name=ref1 /&gt;

===Solving zero-sum games approximately (Oracle algorithm):&lt;ref name=ref1 /&gt;&lt;ref name=ref4 /&gt;&lt;ref name=ref7&gt;{{cite web |url= https://ocw.mit.edu/courses/mathematics/18-409-topics-in-theoretical-computer-science-an-algorithmists-toolkit-fall-2009/lecture-notes/MIT18_409F09_scribe24.pdfformat=PDF |title= An Algorithmist's Toolkit |date=8 December 2009 |access-date=2016-11-09}}&lt;/ref&gt;===

Suppose we were given the distribution &lt;math&gt;P&lt;/math&gt; on experts. Let &lt;math&gt;A&lt;/math&gt; = payoff matrix of a finite two-player zero-sum game, with &lt;math&gt;n&lt;/math&gt; rows.

When the row player &lt;math&gt;p_r&lt;/math&gt; uses plan &lt;math&gt;i&lt;/math&gt; and the column player &lt;math&gt;p_c&lt;/math&gt; uses plan &lt;math&gt;j&lt;/math&gt;, the payoff of player &lt;math&gt;p_c&lt;/math&gt; is &lt;math&gt;A \left ( i, j \right)&lt;/math&gt;≔&lt;math&gt;A_{ij}&lt;/math&gt;, assuming &lt;math&gt;A \left( i, j\right ) \in \left [ 0, 1 \right ]&lt;/math&gt;.

If player &lt;math&gt;p_r&lt;/math&gt; chooses action &lt;math&gt;i&lt;/math&gt; from a distribution &lt;math&gt;P&lt;/math&gt; over the rows, then the expected result for player &lt;math&gt;p_c&lt;/math&gt; selecting action &lt;math&gt;j&lt;/math&gt; is &lt;math&gt;A \left (P, j \right )=E_{i \in P} \left [A \left(i,j \right) \right]&lt;/math&gt;.

To maximize &lt;math&gt;A \left (P, j \right)&lt;/math&gt;, player &lt;math&gt;p_c&lt;/math&gt; should choose plan &lt;math&gt;j&lt;/math&gt;. Similarly, the expected payoff for player &lt;math&gt;p_l&lt;/math&gt; is &lt;math&gt;A \left (i,P\right )=E_{j\in P} \left [A \left(i,j \right) \right ]&lt;/math&gt;. Choosing plan &lt;math&gt;i&lt;/math&gt; would minimize this payoff. By John Von Neumann's Min-Max Theorem, we obtain:

                                           &lt;math&gt;\min_P \max_j A\left( P, j \right) = \max_Q \min_i A\left( i, Q \right) &lt;/math&gt;
where P and i changes over the distributions over rows, Q and j changes over the columns.

Then, let &lt;math&gt;\lambda^*&lt;/math&gt; denote the common value of above quantities, also named as the "value of the game". Let &lt;math&gt;\delta&gt;0&lt;/math&gt; be an error parameter. To solve the zero-sum game bounded by additive error of &lt;math&gt;\delta&lt;/math&gt;,

                                                  &lt;math&gt;\lambda^* - \delta \leq \min_i  A \left (i,q \right ) &lt;/math&gt;
                                                  &lt;math&gt;\max_j A \left(p, j \right) \leq \lambda^* +\delta &lt;/math&gt;

So there is an algorithm solving zero-sum game up to an additive factor of δ using O({{math|log&lt;sub&gt;''2''&lt;/sub&gt;(''n'')}}/&lt;math&gt;\delta^2&lt;/math&gt;) calls to ORACLE, with an additional processing time of O(n) per call&lt;ref name =ref7 /&gt;

Bailey and Piliouras showed that although the time average behavior of multiplicative weights update converges to Nash equilibria in zero-sum games the day-to-day (last iterate) behavior diverges away from it.&lt;ref name="Bailey and Piliouras EC18"&gt;Bailey, James P., and Georgios Piliouras. "Multiplicative weights update in zero-sum games." Proceedings of the 2018 ACM Conference on Economics and Computation. ACM, 2018.&lt;/ref&gt;

===Machine learning===
In machine learning, Littlestone and Warmuth generalized the winnow algorithm to the weighted majority algorithm.&lt;ref&gt;DEAN P. FOSTER AND RAKESH VOHRA (1999). ''Regret in the on-line decision problem'', p. 29. Games and Economic Behaviour&lt;/ref&gt; Later, Freund and Schapire generalized it in the form of hedge algorithm.&lt;ref name=ref8 /&gt; AdaBoost Algorithm formulated by Yoav Freund and Robert Schapire also employed the Multiplicative Weight Update Method.&lt;ref name=ref4 /&gt;

====Winnow algorithm====
Based on current knowledge in algorithms, multiplicative weight update method was first used in Littlestone's winnow algorithm.&lt;ref name=ref4 /&gt; It is used in machine learning to solve a linear program.

Given &lt;math&gt;m&lt;/math&gt; labeled examples &lt;math&gt; \left (a_1, l_1 \right ),\text{…} ,\left (a_m, l_m \right ) &lt;/math&gt; where &lt;math&gt;a_j \in \mathbb{R}^n&lt;/math&gt; are feature vectors, and &lt;math&gt;l_j \in \left \{-1,1 \right \} \quad&lt;/math&gt; are their labels.

The aim is to find non-negative weights such that for all examples, the sign of the weighted combination of the features matches its labels. That is, require that &lt;math&gt;l_j a_j x \geq 0&lt;/math&gt; for all &lt;math&gt;j&lt;/math&gt;. Without loss of generality, assume the total weight is 1 so that they form a distribution. Thus, for notational convenience, redefine &lt;math&gt;a_j&lt;/math&gt; to be &lt;math&gt;l_j a_j&lt;/math&gt;, the problem reduces to finding a solution to the following LP:

                      &lt;math&gt;\forall j=1,2,\text{…}, m : a_j x \geq 0&lt;/math&gt;,
                      &lt;math&gt;1*x=1&lt;/math&gt;,
                      &lt;math&gt;\forall i : x_i \geq 0&lt;/math&gt;.

This is general form of LP.

====Hedge algorithm &lt;ref name=ref2 /&gt;====
The hedge algorithm is similar to the weighted majority algorithm. However, their exponential update rules are different.&lt;ref name=ref2 /&gt;
It is generally used to solve the problem of binary allocation in which we need to allocate different portion of resources into N different options. The loss with every option is available at the end of every iteration. The goal is to reduce the total loss suffered for a particular allocation. The allocation for the following iteration is then revised, based on the total loss suffered in the current iteration using multiplicative update.&lt;ref name=ref16&gt;{{cite web |url=http://www.shivani-agarwal.net/Teaching/E0370/Aug-2011/Lectures/20-scribe1.pdf |title= Online Learning from Experts: Weighed Majority and Hedge |access-date=2016-12-07}}&lt;/ref&gt;

=====Analysis=====
Assume the learning rate &lt;math&gt;\eta &gt; 0&lt;/math&gt; and for &lt;math&gt;t \in [T]&lt;/math&gt;, &lt;math&gt;p^t&lt;/math&gt; is picked by Hedge. Then for all experts &lt;math&gt;i&lt;/math&gt;,

                                 &lt;math&gt;\sum_{t \leq T} p^t m^t \leq \sum_{t \leq T} m_i^t +\frac{\ln(N)}{\eta}+\eta T&lt;/math&gt;

'''Initialization''': Fix an &lt;math&gt;\eta &gt; 0&lt;/math&gt;. For each expert, associate the weight &lt;math&gt;w_i^1&lt;/math&gt; ≔1
'''For''' t=1,2,…,T:
       1. Pick the distribution &lt;math&gt;p_i^t= \frac{w_i^t}{\Phi t}&lt;/math&gt; where &lt;math&gt;\Phi t=\sum_i w_i^t&lt;/math&gt;.
       2. Observe the cost of the decision &lt;math&gt;m^t&lt;/math&gt;. 
       3. Set 
                               &lt;math&gt;w_i^{t + 1} = w_i^t \exp(-\eta m_i^t&lt;/math&gt;).

====AdaBoost algorithm====

[[AdaBoost|This algorithm]]&lt;ref name=ref8&gt;Yoav, Freund. Robert, E. Schapire (1996). ''TA Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting*'', p. 55. journal of computer and system sciences.&lt;/ref&gt; maintains a set of weights &lt;math&gt;w^t&lt;/math&gt; over the training examples. On every iteration &lt;math&gt;t&lt;/math&gt;, a distribution &lt;math&gt;p^t&lt;/math&gt; is computed by normalizing these weights. This distribution is fed to the weak learner WeakLearn which generates a hypothesis &lt;math&gt;h_t&lt;/math&gt; that (hopefully) has small error with respect to the distribution. Using the new hypothesis &lt;math&gt;h_t&lt;/math&gt;, AdaBoost generates the next weight vector &lt;math&gt;w^{t+1}&lt;/math&gt;. The process repeats. After T such iterations, the final hypothesis &lt;math&gt;h_f&lt;/math&gt; is the output. The hypothesis &lt;math&gt;h_f&lt;/math&gt; combines the outputs of the T weak hypotheses using a weighted majority vote.&lt;ref name=ref8 /&gt;

 '''Input''': 
       Sequence of &lt;math&gt;N&lt;/math&gt; labeled examples (&lt;math&gt;x_1&lt;/math&gt;,&lt;math&gt;y_1&lt;/math&gt;),…,(&lt;math&gt;x_N&lt;/math&gt;, &lt;math&gt;y_N&lt;/math&gt;)
       Distribution &lt;math&gt;D&lt;/math&gt; over the &lt;math&gt;N&lt;/math&gt; examples
       Weak learning algorithm "'WeakLearn"'
       Integer &lt;math&gt;T&lt;/math&gt; specifying number of iterations
 '''Initialize''' the weight vector: &lt;math&gt;w_{i}^{1} = D(i)&lt;/math&gt; for &lt;math&gt;i=1&lt;/math&gt;,..., &lt;math&gt;N&lt;/math&gt;.
 '''Do for''' &lt;math&gt;t=1&lt;/math&gt;,..., &lt;math&gt;N&lt;/math&gt;
       '''1'''. Set &lt;math&gt;p^t=\frac{w^t}{\sum_{i=1}^{N} w_{i}^{t}}&lt;/math&gt;.
       '''2'''. Call '''WeakLearn''', providing it with the distribution &lt;math&gt;p^t&lt;/math&gt;; get back a hypothesis &lt;math&gt;h_t: X\rightarrow&lt;/math&gt; [0,1].
       '''3'''. Calculate the error of &lt;math&gt;h_t:\epsilon_t = \sum_{i=1}^{N} p_{i}^{t}&lt;/math&gt;|&lt;math&gt;h_t(x_i)&lt;/math&gt;.
       '''4'''. Set &lt;math&gt;\beta_t = \frac{\epsilon_t}{1-\epsilon_t}&lt;/math&gt;.                                     
       '''5'''. Set the new weight vector to be &lt;math&gt;w_{i}^{t+1}=w_{i}^{t}\beta_{t}^{1-|h_t(x_i)-y_i|}&lt;/math&gt;.
 
 '''Output''' the hypothesis:

       &lt;math&gt;
       f(x) = \begin{cases}1 &amp; \text{if} \sum_{t=1}^{T} \log(1/\beta_t) h_{t}(x) \geq \frac{1}{2}\sum_{t=1}^{T} \log(1/\beta_t) \frac{q_1}{W}\\0 &amp; \text{otherwise}\end{cases}
       &lt;/math&gt;

===Solving linear programs approximately&lt;ref name=ref11&gt;{{cite web |url=http://tcs.epfl.ch/files/content/sites/tcs/files/Lec2-Fall14-Ver2.pdf |title= Fundamentals of Convex Optimization |access-date=2016-11-09}}&lt;/ref&gt;===

====Problem====
Given a &lt;math&gt;m \times n&lt;/math&gt; matrix &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;b \in \mathbb{R}^n&lt;/math&gt;, is there a &lt;math&gt;x&lt;/math&gt; such that &lt;math&gt;A x \geq b&lt;/math&gt;?

                       &lt;math&gt;\exists ? x: A x \geq b &lt;/math&gt;              (1)

====Assumption====
Using the oracle algorithm in solving zero-sum problem, with an error parameter &lt;math&gt; \epsilon &gt; 0&lt;/math&gt;, the output would either be a point &lt;math&gt;x&lt;/math&gt; such that &lt;math&gt;A x \geq b-\epsilon&lt;/math&gt; or a proof that &lt;math&gt;x&lt;/math&gt; does not exist, i.e., there is no solution to this linear system of inequalities.

====Solution====
Given vector &lt;math&gt;p \in \Delta_n&lt;/math&gt;, solves the following relaxed problem

                      &lt;math&gt;\exists ? x: p^{\textsf T}\!\!A x\geq p^\textsf{T}\!b&lt;/math&gt;             (2)

If there exists a x satisfying (1), then x satisfies (2) for all &lt;math&gt; p\in \Delta_n&lt;/math&gt;. The contrapositive of this statement is also true.
Suppose if oracle returns a feasible solution for a &lt;math&gt;p&lt;/math&gt;, the solution &lt;math&gt;x&lt;/math&gt; it returns has bounded width &lt;math&gt;\max_i |{(A x)}_i - b_i | \leq 1&lt;/math&gt;.
So if there is a solution to (1), then there is an algorithm that its output x satisfies the system (2) up to an additive error of &lt;math&gt;2\epsilon&lt;/math&gt;. The algorithm makes at most &lt;math&gt;\frac{\ln(m)}{\epsilon^2}&lt;/math&gt; calls to a width-bounded oracle for the problem (2). The contrapositive stands true as well. The multiplicative updates is applied in the algorithm in this case.

===Other applications===

====Evolutionary game theory====

Multiplicative weights update is the discrete-time variant of the [[replicator equation]] (replicator dynamics), which is a commonly used model in [[evolutionary game theory]]. It converges to [[Nash equilibrium]] when applied to a [[congestion game]].&lt;ref name="Kleinberg, Piliouras, Tardos 09"&gt;Kleinberg, Robert, Georgios Piliouras, and Eva Tardos. "Multiplicative updates outperform generic no-regret learning in congestion games." Proceedings of the forty-first annual ACM symposium on Theory of computing. ACM, 2009.&lt;/ref&gt;

====Operations research and online statistical decision-making&lt;ref name =ref4 /&gt;====
In [[operations research]] and on-line statistical decision making problem field, the weighted majority algorithm and its more complicated versions have been found independently.

====Computational geometry====
The multiplicative weights algorithm is also widely applied in [[computational geometry]],&lt;ref name =ref4 /&gt; such as [[Kenneth L. Clarkson|Clarkson]]'s algorithm for [[Linear programming|linear programming (LP)]] with a bounded number of variables in linear time.&lt;ref name="KENNETH L. CLARKSON pp. 452"/&gt;&lt;ref name="KENNETH L. CLARKSON 1995"/&gt; Later, Bronnimann and Goodrich employed analogous methods to find [[Set cover problem|Set Covers]] for [[hypergraph]]s with small [[VC dimension]].&lt;ref name="M.T. GOODRICH. 1995"/&gt;

====[[Gradient descent|Gradient descent method]]&lt;ref name=ref1 /&gt;====

====[[Matrix (mathematics)|Matrix]] multiplicative weights update&lt;ref name=ref1 /&gt;====

====Plotkin, Shmoys, Tardos framework for [[Packing problems|packing]]/[[Covering problems|covering LPs]]&lt;ref name=ref4 /&gt;====

====Approximating [[multi-commodity flow problem]]s&lt;ref name=ref4 /&gt;====

====O (logn)- approximation for many [[NP-hardness|NP-hard problems]]&lt;ref name=ref4 /&gt;====

====[[Learning theory (education)|Learning theory]] and [[Boosting (machine learning)|boosting]]&lt;ref name=ref4 /&gt;====

====Hard-core sets and the XOR lemma&lt;ref name=ref4 /&gt;====

====Hannan's algorithm and multiplicative weights&lt;ref name=ref4 /&gt;====

====Online [[convex optimization]]&lt;ref name=ref4 /&gt;====

==References==
{{Reflist}}

==External links==

[[Category:Algorithms]]
[[Category:Machine learning]]
[[Category:Randomized algorithms]]</text>
      <sha1>cxxetivq5vst01tfpptcmyer31y9w6l</sha1>
    </revision>
  </page>
  <page>
    <title>Multi-task learning</title>
    <ns>0</ns>
    <id>938663</id>
    <revision>
      <id>1000095705</id>
      <parentid>994548354</parentid>
      <timestamp>2021-01-13T15:19:07Z</timestamp>
      <contributor>
        <username>Kku</username>
        <id>5846</id>
      </contributor>
      <minor/>
      <comment>link [[adjacency matrix]] using [[:en:User:Edward/Find link|Find link]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="31079" xml:space="preserve">{{short description|Solving multiple machine learning tasks at the same time}}
'''Multi-task learning''' (MTL) is a subfield of [[machine learning]] in which multiple learning tasks are solved at the same time, while exploiting commonalities and differences across tasks. This can result in improved learning efficiency and prediction accuracy for the task-specific models, when compared to training the models separately.&lt;ref&gt;Baxter, J. (2000). A model of inductive bias learning" ''Journal of Artificial Intelligence Research'' 12:149--198, [http://www-2.cs.cmu.edu/afs/cs/project/jair/pub/volume12/baxter00a.pdf On-line paper]&lt;/ref&gt;&lt;ref&gt;[[Sebastian Thrun|Thrun, S.]] (1996). Is learning the n-th thing any easier than learning the first?. In Advances in Neural Information Processing Systems 8, pp. 640--646. MIT Press. [http://citeseer.ist.psu.edu/thrun96is.html Paper at Citeseer]&lt;/ref&gt;&lt;ref name=":2"&gt;{{Cite journal|url = http://www.cs.cornell.edu/~caruana/mlj97.pdf|title = Multi-task learning|last = Caruana|first = R.|date = 1997|journal = Machine Learning|doi = 10.1023/A:1007379606734|volume=28|pages=41–75}}&lt;/ref&gt; Early versions of MTL were called "hints".&lt;ref&gt;Suddarth, S., Kergosien, Y. (1990). Rule-injection hints as a means of improving network performance and learning time. EURASIP Workshop. Neural Networks pp. 120-129. Lecture Notes in Computer Science. Springer.&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Abu-Mostafa | first1 = Y. S. | year = 1990 | title = Learning from hints in neural networks | journal = Journal of Complexity | volume = 6 | issue = 2| pages = 192–198 | doi=10.1016/0885-064x(90)90006-y}}&lt;/ref&gt;

In a widely cited 1997 paper, Rich Caruana gave the following characterization:&lt;blockquote&gt;Multitask Learning is an approach to [[inductive transfer]] that improves [[Generalization error|generalization]] by using the domain information contained in the training signals of related tasks as an [[inductive bias]]. It does this by learning tasks in parallel while using a shared [[Representation learning|representation]]; what is learned for each task can help other tasks be learned better.&lt;ref name=":2"&gt;{{Cite journal|url = http://www.cs.cornell.edu/~caruana/mlj97.pdf|title = Multi-task learning|last = Caruana|first = R.|date = 1997|journal = Machine Learning|doi = 10.1023/A:1007379606734|volume=28|pages=41–75}}&lt;/ref&gt;&lt;/blockquote&gt;

In the classification context, MTL aims to improve the performance of multiple classification tasks by learning them jointly. One example is a spam-filter, which can be treated as distinct but related classification tasks across different users. To make this more concrete, consider that different people have different distributions of features which distinguish spam emails from legitimate ones, for example an English speaker may find that all emails in Russian are spam, not so for Russian speakers. Yet there is a definite commonality in this classification task across users, for example one common feature might be text related to money transfer. Solving each user's spam classification problem jointly via MTL can let the solutions inform each other and improve performance.&lt;ref name=":0"&gt;{{Cite web|url = http://www.cs.cornell.edu/~kilian/research/multitasklearning/multitasklearning.html|title = Multi-task Learning|last = Weinberger|first = Kilian}}&lt;/ref&gt; Further examples of settings for MTL include [[multiclass classification]] and [[multi-label classification]].&lt;ref name=":1"&gt;{{Cite arxiv|eprint = 1504.03101|title = Convex Learning of Multiple Tasks and their Structure|last = Ciliberto|first = C.|date = 2015 |class = cs.LG}}&lt;/ref&gt;

Multi-task learning works because [[Regularization (mathematics)|regularization]] induced by requiring an algorithm to perform well on a related task can be superior to regularization that prevents [[overfitting]] by penalizing all complexity uniformly. One situation where MTL may be particularly helpful is if the tasks share significant commonalities and are generally slightly under sampled.&lt;ref name=":bmdl"/&gt;&lt;ref name=":0" /&gt; However, as discussed below, MTL has also been shown to be beneficial for learning unrelated tasks.&lt;ref name=":bmdl"/&gt;&lt;ref name=":3"&gt;Romera-Paredes, B., Argyriou, A., Bianchi-Berthouze, N., &amp; Pontil, M., (2012) Exploiting Unrelated Tasks in Multi-Task Learning. http://jmlr.csail.mit.edu/proceedings/papers/v22/romera12/romera12.pdf&lt;/ref&gt;

==Methods==

===Task grouping and overlap===
Within the MTL paradigm, information can be shared across some or all of the tasks. Depending on the structure of task relatedness, one may want to share information selectively across the tasks. For example, tasks may be grouped or exist in a hierarchy, or be related according to some general metric. Suppose, as developed more formally below, that the parameter vector modeling each task is a [[linear combination]] of some underlying basis. Similarity in terms of this basis can indicate the relatedness of the tasks. For example, with [[Sparse array|sparsity]], overlap of nonzero coefficients across tasks indicates commonality. A task grouping then corresponds to those tasks lying in a subspace generated by some subset of basis elements, where tasks in different groups may be disjoint or overlap arbitrarily in terms of their bases.&lt;ref&gt;Kumar, A., &amp; Daume III, H., (2012) Learning Task Grouping and Overlap in Multi-Task Learning. http://icml.cc/2012/papers/690.pdf&lt;/ref&gt; Task relatedness can be imposed a priori or learned from the data.&lt;ref name=":1"/&gt;&lt;ref&gt;Jawanpuria, P., &amp; Saketha Nath, J., (2012) A Convex Feature Learning Formulation for Latent Task Structure Discovery. http://icml.cc/2012/papers/90.pdf&lt;/ref&gt; Hierarchical task relatedness can also be exploited implicitly without assuming a priori knowledge or learning relations explicitly.&lt;ref name=":bmdl"&gt;Hajiramezanali, E. &amp; Dadaneh, S. Z. &amp; Karbalayghareh, A. &amp; Zhou, Z. &amp; Qian, X. Bayesian multi-domain learning for cancer subtype discovery from next-generation sequencing count data. 32nd Conference on Neural Information Processing Systems (NIPS 2018), Montréal, Canada. {{ArXiv|1810.09433}}&lt;/ref&gt;&lt;ref&gt;Zweig, A. &amp; Weinshall, D. Hierarchical Regularization Cascade for Joint Learning. Proceedings: of 30th International Conference on Machine Learning (ICML), Atlanta GA, June 2013. http://www.cs.huji.ac.il/~daphna/papers/Zweig_ICML2013.pdf&lt;/ref&gt; For example, the explicit learning of sample relevance across tasks can be done to guarantee the effectiveness of joint learning across multiple domains.&lt;ref name=":bmdl"/&gt;

===Exploiting unrelated tasks===
One can attempt learning a group of principal tasks using a group of auxiliary tasks, unrelated to the principal ones. In many applications, joint learning of unrelated tasks which use the same input data can be beneficial. The reason is that prior knowledge about task relatedness can lead to sparser and more informative representations for each task grouping, essentially by screening out idiosyncrasies of the data distribution. Novel methods which builds on a prior multitask methodology by favoring a shared low-dimensional representation within each task grouping have been proposed. The programmer can impose a penalty on tasks from different groups which encourages the two representations to be [[orthogonal]]. Experiments on synthetic and real data have indicated that incorporating unrelated tasks can result in significant improvements over standard multi-task learning methods.&lt;ref name=":3"&gt;Romera-Paredes, B., Argyriou, A., Bianchi-Berthouze, N., &amp; Pontil, M., (2012) Exploiting Unrelated Tasks in Multi-Task Learning. http://jmlr.csail.mit.edu/proceedings/papers/v22/romera12/romera12.pdf&lt;/ref&gt;

=== Transfer of knowledge ===
Related to multi-task learning is the concept of knowledge transfer. Whereas traditional multi-task learning implies that a shared representation is developed concurrently across tasks, transfer of knowledge implies a sequentially shared representation. Large scale machine learning projects such as the deep [[convolutional neural network]] [[GoogLeNet]],&lt;ref&gt;{{Cite book|arxiv = 1409.4842 |doi = 10.1109/CVPR.2015.7298594 |isbn = 978-1-4673-6964-0|chapter = Going deeper with convolutions |title = 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) |pages = 1–9 |year = 2015 |last1 = Szegedy |first1 = Christian |last2 = Wei Liu |first2 = Youssef |last3 = Yangqing Jia |first3 = Tomaso |last4 = Sermanet |first4 = Pierre |last5 = Reed |first5 = Scott |last6 = Anguelov |first6 = Dragomir |last7 = Erhan |first7 = Dumitru |last8 = Vanhoucke |first8 = Vincent |last9 = Rabinovich |first9 = Andrew }}&lt;/ref&gt; an image-based object classifier, can develop robust representations which may be useful to further algorithms learning related tasks. For example, the pre-trained model can be used as a feature extractor to perform pre-processing for another learning algorithm. Or the pre-trained model can be used to initialize a model with similar architecture which is then fine-tuned to learn a different classification task.&lt;ref&gt;{{Cite web|url = https://www.mit.edu/~9.520/fall15/slides/class24/deep_learning_overview.pdf|title = Deep Learning Overview|last = Roig|first = Gemma}}&lt;/ref&gt;

=== Group online adaptive learning ===
Traditionally Multi-task learning and transfer of knowledge are applied to stationary learning settings. Their extension to non-stationary environments is termed Group online adaptive learning (GOAL).&lt;ref&gt;Zweig, A. &amp; Chechik, G. Group online adaptive learning. Machine Learning, DOI 10.1007/s10994-017- 5661-5, August 2017. http://rdcu.be/uFSv&lt;/ref&gt; Sharing information could be particularly useful if learners operate in continuously changing environments, because a learner could benefit from previous experience of another learner to quickly adapt to their new environment. Such group-adaptive learning has numerous applications, from predicting financial time-series, through content recommendation systems, to visual understanding for adaptive autonomous agents.

== Mathematics ==

=== Reproducing Hilbert space of vector valued functions (RKHSvv) ===
The MTL problem can be cast within the context of RKHSvv (a [[Complete metric space|complete]] [[inner product space]] of [[vector-valued function]]s equipped with a [[Reproducing kernel Hilbert space|reproducing kernel]]). In particular, recent focus has been on cases where task structure can be identified via a separable kernel, described below. The presentation here derives from Ciliberto et al., 2015.&lt;ref name=":1" /&gt;

==== RKHSvv concepts ====
Suppose the training data set is &lt;math&gt;\mathcal{S}_t =\{(x_i^t,y_i^t)\}_{i=1}^{n_t}&lt;/math&gt;, with &lt;math&gt;x_i^t\in\mathcal{X}&lt;/math&gt;, &lt;math&gt;y_i^t\in\mathcal{Y}&lt;/math&gt;, where {{mvar|t}} indexes task, and &lt;math&gt;t \in 1,...,T&lt;/math&gt;. Let &lt;math&gt;n=\sum_{t=1}^Tn_t &lt;/math&gt;. In this setting there is a consistent input and output space and the same [[loss function]] &lt;math&gt; \mathcal{L}:\mathbb{R}\times\mathbb{R}\rightarrow \mathbb{R}_+ &lt;/math&gt; for each task: . This results in the regularized machine learning problem: 
{{NumBlk|:|&lt;math display="block" id="1"&gt; \min_{f \in \mathcal{H}}\sum _{t=1} ^T \frac{1}{n_t} \sum _{i=1} ^{n_t} \mathcal{L}(y_i^t, f_t(x_i^t))+\lambda ||f||_\mathcal{H} ^2 &lt;/math&gt;|{{EquationRef|1}}}}
where &lt;math&gt; \mathcal{H} &lt;/math&gt; is a vector valued reproducing kernel Hilbert space with functions &lt;math&gt; f:\mathcal X \rightarrow \mathcal{Y}^T &lt;/math&gt; having components &lt;math&gt; f_t:\mathcal{X}\rightarrow \mathcal {Y} &lt;/math&gt;.

The reproducing kernel for the space &lt;math&gt; \mathcal{H} &lt;/math&gt; of functions   &lt;math&gt; f:\mathcal X \rightarrow \mathbb{R}^T &lt;/math&gt; is a symmetric matrix-valued function &lt;math&gt; \Gamma :\mathcal X\times \mathcal X \rightarrow \mathbb{R}^{T \times T} &lt;/math&gt;  , such that &lt;math&gt; \Gamma (\cdot ,x)c\in \mathcal{H} &lt;/math&gt; and the following reproducing property holds: 
{{NumBlk|:|&lt;math display="block"&gt; \langle f(x),c \rangle _ {\mathbb{R}^T} = \langle f,\Gamma (x,\cdot ) c \rangle _ {\mathcal {H}} &lt;/math&gt;|{{EquationRef|2}}}} The reproducing kernel gives rise to a representer theorem showing that any solution to equation {{EquationNote|1}} has the form: 
{{NumBlk|:|&lt;math display="block"&gt; f(x)=\sum _{t=1}^T \sum _{i=1}^{n_t} \Gamma(x,x_i^t)c_i^t &lt;/math&gt;|{{EquationRef|3}}}}

==== Separable kernels ====
The form of the kernel {{math|&amp;Gamma;}} induces both the representation of the [[feature space]] and structures the output across tasks. A natural simplification is to choose a ''separable kernel,'' which factors into separate kernels on the input space {{mathcal|X}} and on the tasks &lt;math&gt; \{1,...,T\} &lt;/math&gt;. In this case the kernel relating scalar components &lt;math&gt; f_t &lt;/math&gt; and &lt;math&gt; f_s &lt;/math&gt; is given by &lt;math display="inline"&gt; \gamma((x_i,t),(x_j,s )) = k(x_i,x_j)k_T(s,t)=k(x_i,x_j)A_{s,t} &lt;/math&gt;. For vector valued functions  &lt;math&gt; f\in \mathcal H &lt;/math&gt;  we can write &lt;math&gt;\Gamma(x_i,x_j)=k(x_i,x_j)A&lt;/math&gt;, where {{mvar|k}} is a scalar reproducing kernel, and {{mvar|A}} is a symmetric positive semi-definite &lt;math&gt;T\times T&lt;/math&gt; matrix. Henceforth denote &lt;math&gt; S_+^T=\{\text{PSD matrices} \} \subset \mathbb R^{T \times T} &lt;/math&gt; .

This factorization property, separability, implies the input feature space representation does not vary by task. That is, there is no interaction between the input kernel and the task kernel. The structure on tasks is represented solely by {{mvar|A}}. Methods for non-separable kernels {{math|&amp;Gamma;}} is an current field of research.

For the separable case, the representation theorem is reduced to &lt;math display="inline"&gt;f(x)=\sum _{i=1} ^N k(x,x_i)Ac_i&lt;/math&gt;. The model output on the training data is then {{mvar|KCA}} , where {{mvar|K}} is the &lt;math&gt;n \times n&lt;/math&gt; empirical kernel matrix with entries &lt;math display="inline"&gt;K_{i,j}=k(x_i,x_j)&lt;/math&gt;, and {{mvar|C}}  is the &lt;math&gt;n \times T&lt;/math&gt; matrix of rows &lt;math&gt;c_i&lt;/math&gt;.

With the separable kernel, equation  {{EquationNote|1}} can be rewritten as

{{NumBlk|:|&lt;math display="block" id="1"&gt; \min _{C\in \mathbb{R}^{n\times T}} V(Y,KCA) + \lambda tr(KCAC^{\top})&lt;/math&gt;|{{EquationRef|P}}}}

where {{mvar|V}} is a (weighted) average of {{mathcal|L}} applied entry-wise to {{mvar|Y}} and {{mvar|KCA}}. (The weight is zero if &lt;math&gt; Y_i^t &lt;/math&gt; is a missing observation).

Note the second term in {{EquationNote|P}} can be derived as follows:

:&lt;math&gt;\begin{align}
\|f\|^2_\mathcal{H} &amp;= \left\langle \sum _{i=1} ^n k(\cdot,x_i)Ac_i, \sum _{j=1} ^n k(\cdot ,x_j)Ac_j \right\rangle_{\mathcal H }
\\
&amp;= \sum _{i,j=1} ^n  \langle   k(\cdot,x_i)A c_i, k(\cdot ,x_j)Ac_j\rangle_{\mathcal H }   &amp; \text{(bilinearity)}
\\
&amp;= \sum _{i,j=1} ^n \langle k(x_i,x_j)A c_i, c_j\rangle_{\mathbb R^T }   &amp; \text{(reproducing property)}
\\
&amp;= \sum _{i,j=1} ^n k(x_i,x_j) c_i^\top A  c_j=tr(KCAC^\top ) 
\end{align}&lt;/math&gt;

==== Known task structure ====


===== Task structure representations =====
There are three largely equivalent ways to represent task structure: through a regularizer; through an output metric, and through an output mapping.

{{math_theorem|name=Regularizer|1=With the separable kernel, it can be shown (below) that &lt;math display="inline"&gt;||f||^2_\mathcal{H} = \sum_{s,t=1}^T A^\dagger _{t,s} \langle f_s, f_t \rangle _{\mathcal H_k} &lt;/math&gt;, where &lt;math&gt;A^\dagger _{t,s} &lt;/math&gt; is the  &lt;math&gt; t,s &lt;/math&gt; element of the pseudoinverse of &lt;math&gt; A &lt;/math&gt;, and &lt;math&gt;\mathcal H_k &lt;/math&gt; is the RKHS based on the scalar kernel &lt;math&gt; k &lt;/math&gt;, and &lt;math display="inline"&gt; f_t(x)=\sum _{i=1} ^n k(x,x_i)A_t^\top c_i &lt;/math&gt;. This formulation shows that &lt;math&gt;A^\dagger _{t,s} &lt;/math&gt; controls the weight of the penalty associated with &lt;math display="inline"&gt;\langle f_s, f_t \rangle _{\mathcal H_k} &lt;/math&gt;. (Note that &lt;math display="inline"&gt;\langle f_s, f_t \rangle _{\mathcal H_k} &lt;/math&gt; arises from &lt;math display="inline"&gt;||f_t||_{\mathcal H_k} = \langle f_t, f_t \rangle _{\mathcal H_k} &lt;/math&gt;.)

{{Proof|
&lt;math&gt;\begin{align}
\|f\|^2_\mathcal{H} &amp;= \left\langle \sum _{i=1} ^n \gamma ((x_i,t_i),\cdot )c_i^{t_i}, \sum _{j=1} ^n \gamma ((x_j,t_j), \cdot )c_j^{t_j}\right\rangle_{\mathcal H } \\
&amp;=\sum _{i,j=1} ^n c_i^{t_i} c_j^{t_j}  \gamma ((x_i,t_i),(x_j,t_j)) \\
&amp;=\sum _{i,j=1} ^n \sum _{s,t=1} ^T c_i^{t} c_j^{s}  k(x_i,x_j)A_{s,t} \\
&amp;=\sum _{i,j=1} ^n    k(x_i,x_j) \langle  c_i, A c_j\rangle_{\mathbb R^T} \\
&amp;=\sum _{i,j=1} ^n    k(x_i,x_j) \langle  c_i, A A^\dagger A c_j\rangle_{\mathbb R^T} \\
&amp;=\sum _{i,j=1} ^n    k(x_i,x_j) \langle  Ac_i,  A^\dagger A c_j\rangle_{\mathbb R^T} \\
&amp;=\sum _{i,j=1} ^n \sum _{s,t=1} ^T  (Ac_i)^t (A c_j)^s  k(x_i,x_j) A^\dagger_{s,t}  \\
&amp;= \sum _{s,t=1} ^T  A^\dagger_{s,t} \langle \sum _{i=1} ^n k(x_i,\cdot )(Ac_i)^t, \sum _{j=1} ^n   k(x_j,\cdot )(A c_j)^s   \rangle  _{\mathcal H_k}   \\
&amp;= \sum _{s,t=1} ^T  A^\dagger_{s,t} \langle f_t, f_s  \rangle  _{\mathcal H_k}   
\end{align}&lt;/math&gt;
}}}}
{{math_theorem|name=Output metric|an alternative output metric on &lt;math&gt;\mathcal Y^T &lt;/math&gt; can be induced by the inner product &lt;math&gt;\langle y_1,y_2 \rangle _\Theta=\langle y_1,\Theta y_2 \rangle_{\mathbb R^T}  &lt;/math&gt;. With the squared loss there is an equivalence between the separable kernels &lt;math&gt;k(\cdot,\cdot)I_T &lt;/math&gt; under the alternative metric, and &lt;math&gt;k(\cdot,\cdot)\Theta &lt;/math&gt;, under the canonical metric.}}

{{math_theorem|name=Output mapping|Outputs can be mapped as  &lt;math&gt;L:\mathcal Y^T \rightarrow \mathcal \tilde Y &lt;/math&gt;  to a higher dimensional space to encode complex structures such as trees, graphs and strings.  For linear maps {{mvar|L}}, with appropriate choice of separable kernel, it can be shown that  &lt;math&gt;A=L^\top L&lt;/math&gt;.}}

===== Task structure examples =====
Via the regularizer formulation, one can represent a variety of task structures easily. 
* Letting &lt;math display="inline"&gt;A^\dagger = \gamma I_T + ( \gamma - \lambda)\frac {1} T \mathbf{1}\mathbf{1}^\top &lt;/math&gt; (where &lt;math&gt;I_T &lt;/math&gt; is the ''T''x''T'' identity matrix, and &lt;math display="inline"&gt;\mathbf{1}\mathbf{1}^\top &lt;/math&gt; is the ''T''x''T'' matrix of ones) is equivalent to letting {{math|&amp;Gamma;}} control the variance &lt;math display="inline"&gt;\sum_t || f_t - \bar f|| _{\mathcal H_k} &lt;/math&gt;  of tasks from their mean &lt;math display="inline"&gt;\frac 1 T \sum_t f_t  &lt;/math&gt;. For example, blood levels of some biomarker may be taken on {{mvar|T}} patients at &lt;math&gt;n_t&lt;/math&gt; time points during the course of a day and interest may lie in regularizing the variance of the predictions across patients. 
* Letting &lt;math&gt; A^\dagger = \alpha I_T +(\alpha - \lambda )M &lt;/math&gt; , where &lt;math&gt; M_{t,s} = \frac 1 {|G_r|} \mathbb I(t,s\in G_r) &lt;/math&gt; is equivalent to letting &lt;math&gt; \alpha &lt;/math&gt; control the variance measured with respect to a group mean: &lt;math&gt; \sum _{r} \sum _{t \in G_r } ||f_t - \frac 1 {|G_r|} \sum _{s\in G_r)} f_s||  &lt;/math&gt;. (Here &lt;math&gt; |G_r| &lt;/math&gt; the cardinality of group r, and &lt;math&gt;  \mathbb I &lt;/math&gt; is the indicator function). For example, people in different political parties (groups) might be regularized together with respect to predicting the favorability rating of a politician. Note that this penalty reduces to the first when all tasks are in the same group.
* Letting &lt;math&gt; A^\dagger = \delta I_T + (\delta -\lambda)L  &lt;/math&gt;, where &lt;math&gt; L=D-M&lt;/math&gt; is the [[Laplacian matrix|Laplacian]] for the graph with [[adjacency matrix]] ''M'' giving pairwise similarities of tasks. This is equivalent to giving a larger penalty to the distance separating tasks ''t'' and ''s'' when they are more similar (according to the weight &lt;math&gt; M_{t,s} &lt;/math&gt;,) i.e. &lt;math&gt;\delta &lt;/math&gt; regularizes &lt;math&gt; \sum _{t,s}||f_t - f_s ||_{\mathcal H _k }^2 M_{t,s} &lt;/math&gt;.
* All of the above choices of A also induce the additional regularization term  &lt;math display="inline"&gt;\lambda \sum_t ||f|| _{\mathcal H_k} ^2 &lt;/math&gt; which penalizes complexity in f more broadly.

==== Learning tasks together with their structure ====
Learning problem {{EquationNote|P}} can be generalized to admit learning task matrix A as follows:
{{NumBlk|:|&lt;math display="block" id="1"&gt; \min _{C \in \mathbb{R}^{n\times T},A \in S_+^T} V(Y,KCA) + \lambda tr(KCAC^{\top})+F(A)&lt;/math&gt;|{{EquationRef|Q}}}}

Choice of &lt;math&gt;F:S_+^T\rightarrow \mathbb R_+&lt;/math&gt; must be designed to learn matrices ''A'' of a given type. See "Special cases" below.

===== Optimization of {{EquationNote|Q}} =====
Restricting to the case of [[Convex optimization|convex]] losses and [[Coercive function|coercive]] penalties Ciliberto ''et al.'' have shown that although {{EquationNote|Q}} is not convex jointly in ''C'' and ''A,'' a related problem is jointly convex.

Specifically on the convex set &lt;math&gt; \mathcal C=\{(C,A)\in \mathbb R^{n \times T}\times S_+^T | Range(C^\top KC)\subseteq Range(A)\}&lt;/math&gt;, the equivalent problem

{{NumBlk|:|&lt;math display="block" id="1"&gt; \min _{C ,A \in \mathcal C } V(Y,KC) + \lambda tr(A^\dagger C^{\top}KC)+F(A)&lt;/math&gt;|{{EquationRef|R}}}}

is convex with the same minimum value. And if &lt;math&gt; (C_R, A_R)&lt;/math&gt; is a minimizer for {{EquationNote|R}} then &lt;math&gt; (C_R A^\dagger _R, A_R)&lt;/math&gt; is a minimizer for {{EquationNote|Q}}.

{{EquationNote|R}} may be solved by a barrier method on a closed set by introducing the following perturbation:

{{NumBlk|:|&lt;math display="block" id="1"&gt; \min _{C \in \mathbb{R}^{n\times T},A \in S_+^T} V(Y,KC) + \lambda tr(A^\dagger (C^{\top}KC+\delta^2I_T))+F(A)&lt;/math&gt;|{{EquationRef|S}}}}

The perturbation via the barrier &lt;math&gt;\delta ^2 tr(A^\dagger)&lt;/math&gt; forces the objective functions to be equal to &lt;math&gt;+\infty&lt;/math&gt; on the boundary of &lt;math&gt;  R^{n \times T}\times S_+^T&lt;/math&gt; .

{{EquationNote|S}} can be solved with a block coordinate descent method, alternating in ''C'' and ''A.'' This results in a sequence of minimizers &lt;math&gt; (C_m,A_m)&lt;/math&gt; in {{EquationNote|S}} that converges to the solution in {{EquationNote|R}} as &lt;math&gt; \delta_m \rightarrow 0&lt;/math&gt;, and hence gives the solution to {{EquationNote|Q}}.

===== Special cases =====
'''[[Regularization by spectral filtering|Spectral penalties]]''' - Dinnuzo ''et al''&lt;ref&gt;{{Cite journal|url = http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Dinuzzo_54.pdf|title = Learning output kernels with block coordinate descent.|last = Dinuzzo|first = Francesco|date = 2011|journal = Proceedings of the 28th International Conference on Machine Learning (ICML-11)|archive-url = https://web.archive.org/web/20170808223410/http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Dinuzzo_54.pdf|archive-date = 2017-08-08|url-status = dead}}&lt;/ref&gt; suggested setting ''F'' as the Frobenius norm &lt;math&gt; \sqrt{tr(A^\top A)}&lt;/math&gt;. They optimized {{EquationNote|Q}} directly using block coordinate descent, not accounting for difficulties at the boundary of &lt;math&gt;\mathbb R^{n\times T} \times S_+^T&lt;/math&gt;.

'''Clustered tasks learning''' - Jacob ''et al''&lt;ref&gt;{{Cite journal|title = Clustered multi-task learning: A convex formulation|last = Jacob|first = Laurent|date = 2009|journal = Advances in Neural Information Processing Systems|bibcode = 2008arXiv0809.2085J|arxiv = 0809.2085}}&lt;/ref&gt; suggested to learn ''A'' in the setting where ''T''  tasks are organized in ''R'' disjoint clusters. In this case let &lt;math&gt; E\in \{0,1\}^{T\times R}&lt;/math&gt; be the matrix with &lt;math&gt; E_{t,r}=\mathbb I (\text{task }t\in \text{group }r)&lt;/math&gt;. Setting &lt;math&gt; M = I - E^\dagger E^T&lt;/math&gt;, and  &lt;math&gt; U = \frac 1 T \mathbf{11}^\top &lt;/math&gt;, the task matrix &lt;math&gt; A^\dagger  &lt;/math&gt;  can be parameterized as a function of &lt;math&gt; M  &lt;/math&gt;: &lt;math&gt; A^\dagger(M) = \epsilon _M U+\epsilon_B (M-U)+\epsilon (I-M)  &lt;/math&gt; , with terms that penalize the average, between clusters variance and within clusters variance respectively of the task predictions. M is not convex, but there is a convex relaxation &lt;math&gt; \mathcal S_c = \{M\in S_+^T:I-M\in S_+^T \land tr(M) = r \} &lt;/math&gt;. In this formulation,  &lt;math&gt; F(A)=\mathbb I(A(M)\in \{A:M\in \mathcal S_C\})  &lt;/math&gt;.

===== Generalizations =====
'''Non-convex penalties''' - Penalties can be constructed such that A is constrained to be a graph Laplacian, or that A has low rank factorization. However these penalties are not convex, and the analysis of the barrier method proposed by Ciliberto et al. does not go through in these cases.

'''Non-separable kernels''' - Separable kernels are limited, in particular they do not account for structures in the interaction space between the input and output domains jointly. Future work is needed to develop models for these kernels.

==Applications==

===Spam filtering===
Using the principles of MTL, techniques for collaborative [[spam filtering]] that facilitates personalization have been proposed. In large scale open membership email systems, most users do not label enough messages for an individual local [[classifier (mathematics)|classifier]] to be effective, while the data is too noisy to be used for a global filter across all users. A hybrid global/individual classifier can be effective at absorbing the influence of users who label emails very diligently from the general public. This can be accomplished while still providing sufficient quality to users with few labeled instances.&lt;ref&gt;Attenberg, J., Weinberger, K., &amp; Dasgupta, A. Collaborative Email-Spam Filtering with the Hashing-Trick. http://www.cse.wustl.edu/~kilian/papers/ceas2009-paper-11.pdf&lt;/ref&gt;

===Web search===
Using boosted [[decision trees]], one can enable implicit data sharing and regularization. This learning method can be used on web-search ranking data sets. One example is to use ranking data sets from several countries. Here, multitask learning is particularly helpful as data sets from different countries vary largely in size because of the cost of editorial judgments. It has been demonstrated that learning various tasks jointly can lead to significant improvements in performance with surprising reliability.&lt;ref&gt;Chappelle, O., Shivaswamy, P., &amp; Vadrevu, S. Multi-Task Learning for Boosting
with Application to Web Search Ranking. http://www.cse.wustl.edu/~kilian/papers/multiboost2010.pdf&lt;/ref&gt;

==Software package==
The Multi-Task Learning via StructurAl Regularization (MALSAR) Matlab package&lt;ref&gt;Zhou, J., Chen, J. and Ye, J. MALSAR: Multi-tAsk Learning via StructurAl Regularization. Arizona State University, 2012. http://www.public.asu.edu/~jye02/Software/MALSAR. [http://www.public.asu.edu/~jye02/Software/MALSAR/Manual.pdf On-line manual]&lt;/ref&gt;  implements the following multi-task learning algorithms:
* Mean-Regularized Multi-Task Learning&lt;ref&gt;Evgeniou, T., &amp; Pontil, M. (2004). [https://pdfs.semanticscholar.org/1ea1/91c70559d21be93a4d128f95943e80e1b4ff.pdf Regularized multi–task learning]. Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining (pp. 109–117).&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Evgeniou | first1 = T. | last2 = Micchelli | first2 = C. | last3 = Pontil | first3 = M. | year = 2005 | title = Learning multiple tasks with kernel methods | url = http://jmlr.org/papers/volume6/evgeniou05a/evgeniou05a.pdf | journal = Journal of Machine Learning Research | volume = 6 | page = 615 }}&lt;/ref&gt;
* Multi-Task Learning with Joint Feature Selection&lt;ref&gt;{{cite journal | last1 = Argyriou | first1 = A. | last2 = Evgeniou | first2 = T. | last3 = Pontil | first3 = M. | year = 2008a | title = Convex multi-task feature learning | journal = Machine Learning | volume = 73 | issue = 3| pages = 243–272 | doi=10.1007/s10994-007-5040-8| doi-access = free }}&lt;/ref&gt;
* Robust Multi-Task Feature Learning&lt;ref&gt;Chen, J., Zhou, J., &amp; Ye, J. (2011). [https://www.academia.edu/download/44101186/Integrating_low-rank_and_group-sparse_st20160325-15067-1mftmbg.pdf Integrating low-rank and group-sparse structures for robust multi-task learning]. Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining.&lt;/ref&gt;
* Trace-Norm Regularized Multi-Task Learning&lt;ref&gt;Ji, S., &amp; Ye, J. (2009). [http://www.machinelearning.org/archive/icml2009/papers/151.pdf An accelerated gradient method for trace norm minimization]. Proceedings of the 26th Annual International Conference on Machine Learning (pp. 457–464).&lt;/ref&gt;
* Alternating Structural Optimization&lt;ref&gt;{{cite journal | last1 = Ando | first1 = R. | last2 = Zhang | first2 = T. | year = 2005 | title = A framework for learning predictive structures from multiple tasks and unlabeled data | url = http://www.jmlr.org/papers/volume6/ando05a/ando05a.pdf | journal = The Journal of Machine Learning Research | volume = 6 | pages = 1817–1853 }}&lt;/ref&gt;&lt;ref&gt;Chen, J., Tang, L., Liu, J., &amp; Ye, J. (2009). [http://leitang.net/papers/ICML09_CASO.pdf A convex formulation for learning shared structures from multiple tasks]. Proceedings of the 26th Annual International Conference on Machine Learning (pp. 137–144).&lt;/ref&gt;
* Incoherent Low-Rank and Sparse Learning&lt;ref&gt;Chen, J., Liu, J., &amp; Ye, J. (2010). [https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3783291/ Learning incoherent sparse and low-rank patterns from multiple tasks]. Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining (pp. 1179–1188).&lt;/ref&gt;
* Robust Low-Rank Multi-Task Learning
* Clustered Multi-Task Learning&lt;ref&gt;Jacob, L., Bach, F., &amp; Vert, J. (2008). [https://hal-ensmp.archives-ouvertes.fr/docs/00/32/05/73/PDF/cmultitask.pdf Clustered multi-task learning: A convex formulation]. Advances in Neural Information Processing Systems， 2008&lt;/ref&gt;&lt;ref&gt;Zhou, J., Chen, J., &amp; Ye, J. (2011). [http://papers.nips.cc/paper/4292-clustered-multi-task-learning-via-alternating-structure-optimization.pdf Clustered multi-task learning via alternating structure optimization]. Advances in Neural Information Processing Systems.&lt;/ref&gt;
* Multi-Task Learning with Graph Structures

==See also==
{{div col}}
* [[Artificial intelligence]]
* [[Artificial neural network]]
* [[Automated machine learning]] (AutoML)
* [[Evolutionary computation]]
* [[General game playing]]
* [[Human-based genetic algorithm]]
* [[Kernel methods for vector output]]
* [[Multitask optimization]]
* [[Robot learning]]
* [[Transfer learning]]
{{div col end}}

==References==

{{Reflist}}

==External links==
* [https://web.archive.org/web/20041118134329/http://big.cs.uiuc.edu/webpage/cumulativeLearning/cumulativeLearning.html The Biosignals Intelligence Group at UIUC]
* [http://www.cse.wustl.edu/~kilian/research/multitasklearning/multitasklearning.html Washington University at St. Louis Depart. of Computer Science]

===Software===
* [http://www.public.asu.edu/~jye02/Software/MALSAR/index.html The Multi-Task Learning via Structural Regularization Package]
* [https://web.archive.org/web/20131224113826/http://klcl.pku.edu.cn/member/sunxu/code.htm Online Multi-Task Learning Toolkit (OMT)] A general-purpose online multi-task learning toolkit based on [[conditional random field]] models and [[stochastic gradient descent]] training ([[C Sharp (programming language)|C#]], [[.NET Framework|.NET]])

[[Category:Machine learning]]</text>
      <sha1>qmhdawagiimydwvmes6o55aah8mzc4w</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Unsupervised learning</title>
    <ns>14</ns>
    <id>52763828</id>
    <revision>
      <id>776659011</id>
      <parentid>758107912</parentid>
      <timestamp>2017-04-22T12:41:29Z</timestamp>
      <contributor>
        <username>Olexa Riznyk</username>
        <id>9148555</id>
      </contributor>
      <comment>+cat main</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="43" xml:space="preserve">{{Cat main}}

[[Category:Machine learning]]</text>
      <sha1>oskod0rsljwgi83u1nf88yucs3ce3zg</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Semisupervised learning</title>
    <ns>14</ns>
    <id>52763829</id>
    <revision>
      <id>920507164</id>
      <parentid>920507062</parentid>
      <timestamp>2019-10-10T06:27:47Z</timestamp>
      <contributor>
        <username>ChongDae</username>
        <id>243919</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="42" xml:space="preserve">{{Catmain}}

[[Category:Machine learning]]</text>
      <sha1>50bnxpixa00kyzxb5x1ufs26em8405y</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Supervised learning</title>
    <ns>14</ns>
    <id>52763867</id>
    <revision>
      <id>920507130</id>
      <parentid>920507082</parentid>
      <timestamp>2019-10-10T06:27:29Z</timestamp>
      <contributor>
        <username>ChongDae</username>
        <id>243919</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="41" xml:space="preserve">{{Catmain}}
[[Category:Machine learning]]</text>
      <sha1>5lky2oba771f9xcod4zawozl44io3m2</sha1>
    </revision>
  </page>
  <page>
    <title>Instance selection</title>
    <ns>0</ns>
    <id>53279262</id>
    <revision>
      <id>882670974</id>
      <parentid>880472259</parentid>
      <timestamp>2019-02-10T17:24:39Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Alter: title, template type. Add: series, volume, doi, chapter. Removed parameters. | You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[WP:UCB|User-activated]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="6482" xml:space="preserve">{{cleanup|date=March 2017|reason=Article needs linked into other articles in WP.}}

'''Instance selection''' (or dataset reduction, or dataset condensation) is an important [[data pre-processing]] step that can be applied in many [[machine learning]] (or [[data mining]]) tasks.&lt;ref name=GARCIA_2015&gt;S. García, J. Luengo, and F. Herrera, Data preprocessing in data mining. Springer, 2015.&lt;/ref&gt; Approaches for instance selection can be applied for reducing the original dataset to a manageable volume, leading to a reduction of the computational resources that are necessary for performing the learning process. Algorithms of instance selection can also be applied for removing noisy instances, before applying learning algorithms. This step can improve the accuracy in classification problems.

Algorithm for instance selection should identify a subset of the total available data to achieve the original purpose of the data mining (or machine learning) application as if the whole data had been used. Considering this, the optimal outcome of IS would be the minimum data subset that can accomplish the same task with no performance loss, in comparison with the performance achieved when the task is performed using the whole available data. Therefore, every instance selection strategy should deal with a trade-off between the reduction rate of the dataset and the classification quality.

== Instance selection algorithms ==

The literature provides several different algorithms for instance selection. They can be distinguished from each other according to several different criteria. Considering this, instance selection algorithms can be grouped in two main classes, according to what instances they select: algorithms that preserve the instances at the boundaries of classes and algorithms that preserve the internal instances of the classes. Within the category of algorithms that select instances at the boundaries it is possible to cite DROP3,&lt;ref name=DROP_2000&gt;D. R. Wilson and T. R. Martinez, Reduction techniques for instance-based learning algorithms, Machine learning, vol. 38, no. 3, pp. 257–286, 2000.&lt;/ref&gt; ICF&lt;ref name=ICF_2002&gt;H. Brighton and C. Mellish, Advances in instance selection for instance-based learning algorithms, Data mining and knowledge discovery, vol. 6, no. 2, pp. 153–172, 2002.&lt;/ref&gt; and LSBo.&lt;ref name=LSBo_LSSm_2015&gt;E. Leyva, A. González, and R. Pérez, Three new instance selection methods based on local sets: A comparative study with several approaches from a bi-objective perspective, Pattern Recognition, vol. 48, no. 4, pp. 1523–1537, 2015.&lt;/ref&gt; On the other hand, within the category of algorithms that select internal instances, it is possible to mention ENN&lt;ref name=ENN_1972&gt;D. L. Wilson, “Asymptotic properties of nearest neighbor rules using edited data,” Systems, Man and Cybernetics, IEEE Transactions on, no. 3, pp. 408–421, 1972.&lt;/ref&gt; and LSSm.&lt;ref name=LSBo_LSSm_2015 /&gt; In general, algorithm such as ENN and LSSm are used for removing harmful (noisy) instances from the dataset. They do not reduce the data as the algorithms that select border instances, but they remove instances at the boundaries that have a negative impact on the data mining task. They can be used by other instance selection algorithms, as a filtering step. For example, the ENN algorithm is used by DROP3 as the first step, and the LSSm algorithm is used by LSBo.

There is also another group of algorithms that adopt different selection criteria. For example, the algorithms LDIS,&lt;ref name=LDIS_2015&gt;Carbonera, Joel Luis, and Mara Abel. A density-based approach for instance selection. IEEE 27th International Conference on Tools with Artificial Intelligence (ICTAI), 2015.&lt;/ref&gt; CDIS&lt;ref name=CDIS_2016&gt;Carbonera, Joel Luis, and Mara Abel. A novel density-based approach for instance selection. IEEE 28th International Conference on Tools with Artificial Intelligence (ICTAI), 2016.&lt;/ref&gt; and XLDIS&lt;ref&gt;{{Citation|last=Carbonera|first=Joel Luís|chapter=An Efficient Approach for Instance Selection|date=2017|pages=228–243|publisher=Springer International Publishing|isbn=9783319642826|doi=10.1007/978-3-319-64283-3_17|title=Big Data Analytics and Knowledge Discovery|volume=10440|series=Lecture Notes in Computer Science}}&lt;/ref&gt; select the densest instances in a given arbitrary neighborhood. The selected instances can include both, border and internal instances. The LDIS and CDIS algorithms are very simple and select subsets that are very representative of the original dataset. Besides that, since they search by the representative instances in each class separately, they are faster (in terms of time complexity and effective running time) than other algorithms, such as DROP3 and ICF.

Besides that, there is a third category of algorithms that, instead of selecting actual instances of the dataset, select prototypes (that can be synthetic instances). In this category it is possible to include PSSA,&lt;ref&gt;{{Citation|last=Carbonera|first=Joel Luís|title=An Efficient Prototype Selection Algorithm Based on Spatial Abstraction|date=2018|work=Big Data Analytics and Knowledge Discovery|pages=177–192|publisher=Springer International Publishing|isbn=9783319985381|last2=Abel|first2=Mara|doi=10.1007/978-3-319-98539-8_14}}&lt;/ref&gt; PSDSP&lt;ref&gt;{{Citation|last=Carbonera|first=Joel Luís|title=An Efficient Prototype Selection Algorithm Based on Dense Spatial Partitions|date=2018|work=Artificial Intelligence and Soft Computing|pages=288–300|publisher=Springer International Publishing|isbn=9783319912615|last2=Abel|first2=Mara|doi=10.1007/978-3-319-91262-2_26}}&lt;/ref&gt; and PSSP.&lt;ref name="Carbonera"&gt;{{Cite book|last=Carbonera|first=Joel Luis|last2=Abel|first2=Mara|date=November 2017|title=Efficient Prototype Selection Supported by Subspace Partitions|journal=2017 IEEE 29th International Conference on Tools with Artificial Intelligence (ICTAI)|publisher=IEEE|doi=10.1109/ictai.2017.00142|isbn=9781538638767}}&lt;/ref&gt; The three algorithms adopt the notion of spatial partition (a hyperrectangle) for identifying similar instances and extract prototypes for each set of similar instances. In general, these approaches can also be modified for selecting actual instances of the datasets. The algorithm ISDSP&lt;ref name="Carbonera"/&gt; adopts a similar approach for selecting actual instances (instead of prototypes).

==References==
{{reflist}}

[[Category:Machine learning]]
[[Category:Data mining]]
[[Category:Computer science]]</text>
      <sha1>i82bfd1n2ufbhmp36q87hqpkzltszpu</sha1>
    </revision>
  </page>
  <page>
    <title>Machine learning control</title>
    <ns>0</ns>
    <id>53802271</id>
    <revision>
      <id>994773909</id>
      <parentid>994754869</parentid>
      <timestamp>2020-12-17T13:35:42Z</timestamp>
      <contributor>
        <username>MrOllie</username>
        <id>6908984</id>
      </contributor>
      <comment>Reverted to revision 986482891 by [[Special:Contributions/FrescoBot|FrescoBot]] ([[User talk:FrescoBot|talk]]): COI / refspam</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="6165" xml:space="preserve">'''Machine learning control (MLC)''' is a subfield of [[machine learning]], [[intelligent control]] and [[control theory]]
which solves [[optimal control]] problems with methods of [[machine learning]].
Key applications are complex nonlinear systems
for which [[linear control theory]] methods are not applicable.

== Types of problems and tasks ==
Four types of problems are commonly encountered.
* Control parameter identification: MLC translates to a parameter identification&lt;ref name=Baeck1993&gt;Thomas Bäck &amp; Hans-Paul Schwefel (Spring 1993) [http://doi.org/10.1162/evco.1993.1.1.1 "An overview of evolutionary algorithms for parameter optimization"], [[Evolutionary Computation (journal)|Journal of Evolutionary Computation (MIT Press)]], vol. 1, no. 1, pp. 1-23&lt;/ref&gt; if the structure of the control law is given but the parameters are unknown. One example is the [[genetic algorithm]] for optimizing coefficients of a [[PID controller]]&lt;ref name=Benard2015aiaa&gt;N. Benard, J. Pons-Prats, J. Periaux, G. Bugeda, J.-P. Bonnet &amp; E. Moreau, (2015) [https://arc.aiaa.org/doi/abs/10.2514/6.2015-2957 "Multi-Input Genetic Algorithm for Experimental Optimization of the Reattachment Downstream of a Backward-Facing Step with Surface Plasma Actuator"], Paper AIAA 2015-2957 at 46th AIAA Plasmadynamics and Lasers Conference, Dallas, TX, USA, pp. 1-23.&lt;/ref&gt; or discrete-time optimal control.&lt;ref&gt;Zbigniew Michalewicz, Cezary Z. Janikow &amp; Jacek B. Krawczyk (July 1992) [https://doi.org/10.1016/0898-1221(92)90094-X "A modified genetic algorithm for optimal control problems"], [Computers &amp; Mathematics with Applications], vol. 23, no 12, pp. 83-94.&lt;/ref&gt;
* Control design as regression problem of the first kind:  MLC approximates a general nonlinear mapping from sensor signals to actuation commands, if the sensor signals and the optimal actuation command are known for every state. One example is the computation of sensor feedback from a known [[full state feedback]]. A [[neural network]] is commonly used technique for this task.&lt;ref&gt;C. Lee, J. Kim, D. Babcock &amp; R. Goodman (1997) [https://dx.doi.org/10.1063/1.869290 "Application of neural networks to turbulence control for drag reduction"], [[Physics of Fluids]], vol. 6, no. 9, pp. 1740-1747&lt;/ref&gt;
* Control design as regression problem of the second kind: MLC may also identify arbitrary nonlinear control laws which minimize the cost function of the plant. In this case, neither a model, nor the control law structure,  nor the optimizing actuation command needs to be known. The optimization is only based on the control performance (cost function) as measured in the plant. [[Genetic programming]] is a powerful regression technique for this purpose.&lt;ref&gt;D. C. Dracopoulos &amp; S. Kent (December 1997) [http://doi.org/10.1007/BF01501508 "Genetic programming for prediction and control"], Neural Computing &amp; Applications (Springer), vol. 6, no. 4, pp. 214-228.&lt;/ref&gt;
* Reinforcement learning control: The control law may be continually updated over measured performance changes (rewards) using [[reinforcement learning]].&lt;ref&gt;Andrew G. Barto (December 1994) [http://doi.org/10.1016/0959-4388(94)90138-4 "Reinforcement learning control"], [[Current Opinion in Neurobiology]], vol. 6, no. 4, pp. 888–893&lt;/ref&gt;

MLC comprises, for instance, neural network control, 
genetic algorithm based control, 
genetic programming control,
reinforcement learning control, 
and has methodological overlaps with other data-driven control,
like [[artificial intelligence]] and [[robot control]].

== Applications ==
MLC has been successfully applied
to many nonlinear control problems,
exploring unknown and often unexpected actuation mechanisms.
Example applications include

* Altitude control of satellites.&lt;ref&gt;Dimitris. C. Dracopoulos &amp; Antonia. J. Jones (1994) 
[http://doi.org/10.1007/BF01414807 Neuro-genetic adaptive attitude control], Neural Computing &amp; Applications (Springer), vol. 2, no. 4, pp. 183-204.&lt;/ref&gt;
* Building thermal control.&lt;ref&gt;Jonathan A. Wright, Heather A. Loosemore &amp; Raziyeh Farmani (2002) [http://doi.org/10.1016/S0378-7788(02)00071-3 "Optimization of building thermal design and control by multi-criterion genetic algorithm], [Energy and Buildings], vol. 34, no. 9, pp. 959-972.&lt;/ref&gt;
* Feedback turbulence control.&lt;ref name=Benard2015aiaa /&gt;&lt;ref&gt;Steven J. Brunton &amp; Bernd R. Noack (2015)  [http://doi.org/10.1115/1.4031175 Closed-loop turbulence control: Progress and challenges], [[Applied Mechanics Reviews]], vol. 67, no. 5, article 050801, pp. 1-48.&lt;/ref&gt;
* Remotely operated under water vehicle.&lt;ref&gt;J. Javadi-Moghaddam, &amp; A. Bagheri (2010 [http://doi.org/10.1016/j.eswa.2009.06.015 "An adaptive neuro-fuzzy sliding mode based genetic algorithm control system for under water remotely operated vehicle"], [https://www.journals.elsevier.com/expert-systems-with-applications/ Expert Systems with Applications], vol. 37 no. 1, pp. 647-660.&lt;/ref&gt;
* Many more engineering MLC application are summarized in the review article of PJ Fleming &amp; RC Purshouse (2002).&lt;ref&gt;Peter J. Fleming, R. C. Purshouse (2002 [http://doi.org/10.1016/S0967-0661(02)00081-3 "Evolutionary algorithms in control systems engineering: a survey"]
[[:nl:Control Engineering Practice|Control Engineering Practice]], vol. 10, no. 11, pp. 1223-1241&lt;/ref&gt;

As for all general nonlinear methods,
MLC comes with no guaranteed convergence, 
optimality or robustness for a range of operating conditions.

== References ==
{{Reflist|30em}}

== Further reading ==
{{Refbegin|1}}
* [http://users.wmin.ac.uk/~dracopd/ Dimitris C Dracopoulos] (August 1997) [https://www.springer.com/fr/book/9783540761617 "Evolutionary Learning Algorithms for Neural Adaptive Control"], Springer. {{ISBN|978-3-540-76161-7}}.
* [http://laboratorios.fi.uba.ar/lfd/thomas-duriez/ Thomas Duriez], [http://faculty.washington.edu/sbrunton/home/ Steven L. Brunton] &amp; [[Bernd Noack|Bernd R. Noack]] (November 2016) [https://www.springer.com/fr/book/9783319406237 "Machine Learning Control - Taming Nonlinear Dynamics and Turbulence"], Springer. {{ISBN|978-3-319-40624-4}}.

[[Category:Machine learning]]
[[Category:Control theory]]
[[Category:Cybernetics]]</text>
      <sha1>7ez5q155aw6a01imypp65c845nnwrqx</sha1>
    </revision>
  </page>
  <page>
    <title>Machine learning in bioinformatics</title>
    <ns>0</ns>
    <id>53970843</id>
    <revision>
      <id>979025830</id>
      <parentid>979018451</parentid>
      <timestamp>2020-09-18T09:38:19Z</timestamp>
      <contributor>
        <username>Amkilpatrick</username>
        <id>10686528</id>
      </contributor>
      <comment>Undid revision 979018451 by [[Special:Contributions/Salamatshah6u8k|Salamatshah6u8k]] ([[User talk:Salamatshah6u8k|talk]]) Wikilink was sufficient</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="15674" xml:space="preserve">{{Use mdy dates|date=September 2017}}
'''[[Machine learning]]''', a subfield of [[computer science]] involving the development of algorithms that learn how to make predictions based on [[Database|data]], has a number of emerging applications in the field of [[bioinformatics]]. Bioinformatics deals with computational and mathematical approaches for understanding and processing biological data.&lt;ref&gt;{{cite journal 
| vauthors = Chicco D
| title = Ten quick tips for machine learning in computational biology 
| journal = BioData Mining
| volume = 10
| issue =  35
| pages = 35 
| date = December 2017 
| pmid = 29234465
| doi = 10.1186/s13040-017-0155-3
| pmc= 5721660}}&lt;/ref&gt;

Prior to the emergence of machine learning algorithms, bioinformatics algorithms had to be explicitly programmed by hand which, for problems such as [[protein structure prediction]], proves extremely difficult.&lt;ref name=":2"&gt;{{Cite journal|last=Yang|first=Yuedong|last2=Gao|first2=Jianzhao|last3=Wang|first3=Jihua|last4=Heffernan|first4=Rhys|last5=Hanson|first5=Jack|last6=Paliwal|first6=Kuldip|last7=Zhou|first7=Yaoqi|title=Sixty-five years of the long march in protein secondary structure prediction: the final stretch?|journal=Briefings in Bioinformatics|volume=19|issue=3|pages=482–494|doi=10.1093/bib/bbw129|pmid=28040746|pmc=5952956|date=May 2018}}&lt;/ref&gt; Machine learning techniques such as [[deep learning]] enable the algorithm to make use of automatic [[feature learning]] which means that based on the dataset alone, the algorithm can learn how to combine multiple [[Feature (machine learning)|features]] of the input data into a more abstract set of features from which to conduct further learning. This multi-layered approach to learning patterns in the input data allows such systems to make quite complex predictions when trained on large datasets. In recent years, the size and number of available biological datasets have skyrocketed, enabling bioinformatics researchers to make use of these machine learning systems.&lt;ref name=":0" /&gt; Machine learning has been applied to six biological domains: [[genomics]], [[proteomics]], [[microarrays]], [[systems biology]], [[evolution]], and [[text mining]].&lt;ref name=":0"&gt;{{Cite journal|last=Larrañaga|first=Pedro|last2=Calvo|first2=Borja|last3=Santana|first3=Roberto|last4=Bielza|first4=Concha|last5=Galdiano|first5=Josu|last6=Inza|first6=Iñaki|last7=Lozano|first7=José A.|last8=Armañanzas|first8=Rubén|last9=Santafé|first9=Guzmán|title=Machine learning in bioinformatics|journal=Briefings in Bioinformatics|volume=7|issue=1|pages=86–112|doi=10.1093/bib/bbk007|pmid=16761367|date=March 2006|doi-access=free}}&lt;/ref&gt;

== Applications ==

=== Genomics ===
[[File:Growth of GenBank.png|thumb|The exponential growth of GenBank, a genomic sequence database provided by the National center for Biotechnology Information (NCBI)]]
[[Genomics]] involves the study of the [[genome]], the complete [[DNA sequencing|DNA sequence]], of organisms. While genomic sequence data has historically been sparse due to the technical difficulty in sequencing a piece of DNA, the number of available sequences is growing exponentially.&lt;ref&gt;{{Cite web|url=https://www.ncbi.nlm.nih.gov/genbank/statistics/|title=GenBank and WGS Statistics|website=www.ncbi.nlm.nih.gov|language=en|access-date=2017-05-06}}&lt;/ref&gt; However, while [[raw data]] is becoming increasingly available and accessible, the biological interpretation of this data is occurring at a much slower pace.&lt;ref name=":1"&gt;{{Cite journal|last=Mathé|first=Catherine|last2=Sagot|first2=Marie-France|last3=Schiex|first3=Thomas|last4=Rouzé|first4=Pierre|date=October 1, 2002|title=Current methods of gene prediction, their strengths and weaknesses|journal=Nucleic Acids Research|volume=30|issue=19|pages=4103–4117|issn=1362-4962|pmc=140543|pmid=12364589|doi=10.1093/nar/gkf543}}&lt;/ref&gt; Therefore, there is an increasing need for the development of machine learning systems that can automatically determine the location of protein-encoding genes within a given DNA sequence.&lt;ref name=":1" /&gt; This is a problem in computational biology known as [[gene prediction]].

Gene prediction is commonly performed through a combination of what are known as extrinsic and intrinsic searches.&lt;ref name=":1" /&gt; For the extrinsic search, the input DNA sequence is run through a large database of sequences whose genes have been previously discovered and their locations annotated. A number of the sequence's genes can be identified by determining which strings of bases within the sequence are [[Homology (biology)|homologous]] to known gene sequences. However, given the limitation in size of the database of known and annotated gene sequences, not all the genes in a given input sequence can be identified through homology alone. Therefore, an intrinsic search is needed where a gene prediction program attempts to identify the remaining genes from the DNA sequence alone.&lt;ref name=":1" /&gt;

Machine learning has also been used for the problem of [[multiple sequence alignment]] which involves aligning many DNA or amino acid sequences in order to determine regions of similarity that could indicate a shared evolutionary history.&lt;ref name=":0" /&gt;
It can also be used to detect and visualize genome rearrangements.&lt;ref name="rearrang"&gt;{{cite journal|last=Pratas|first=D|author2=Silva, R|author3= Pinho, A|author4= Ferreira, P|title=An alignment-free method to find and visualise rearrangements between pairs of DNA sequences.|journal=Scientific Reports|date=May 18, 2015|volume=5|number=10203|pmid=25984837|doi=10.1038/srep10203|pages=10203|pmc=4434998|bibcode=2015NatSR...510203P}}&lt;/ref&gt;

=== Proteomics ===
[[File:C16orf95 protein secondary structure prediction.png|thumb|A protein's amino acid sequence annotated with the protein secondary structure. Each amino acid is labeled as either an alpha helix, a beta sheet, or a coil.]]
[[Protein]]s, strings of [[amino acid]]s, gain much of their function from [[protein folding]] in which they conform into a three-dimensional structure. This structure is composed of a number of layers of folding, including the [[Protein primary structure|primary structure]] (i.e. the flat string of amino acids), the [[Protein secondary structure|secondary structure]] ([[Alpha helix|alpha helices]] and [[beta sheet]]s), the [[Protein tertiary structure|tertiary structure]], and the [[Protein quaternary structure|quartenary structure]].

Protein secondary structure prediction is a main focus of this subfield as the further protein foldings (tertiary and quartenary structures) are determined based on the secondary structure.&lt;ref name=":2" /&gt; Solving the true structure of a protein is an incredibly expensive and time-intensive process, furthering the need for systems that can accurately predict the structure of a protein by analyzing the amino acid sequence directly.&lt;ref name=":2" /&gt;&lt;ref name=":0" /&gt; Prior to machine learning, researchers needed to conduct this prediction manually. This trend began in 1951 when Pauling and Corey released their work on predicting the hydrogen bond configurations of a protein from a polypeptide chain.&lt;ref&gt;{{Cite journal|last=Pauling|first=L.|last2=Corey|first2=R. B.|last3=Branson|first3=H. R.|date=April 1, 1951|title=The structure of proteins; two hydrogen-bonded helical configurations of the polypeptide chain|journal=Proceedings of the National Academy of Sciences of the United States of America|volume=37|issue=4|pages=205–211|issn=0027-8424|pmc=1063337|pmid=14816373|doi=10.1073/pnas.37.4.205|bibcode=1951PNAS...37..205P}}&lt;/ref&gt; Today, through the use of automatic feature learning, the best machine learning techniques are able to achieve an accuracy of 82-84%.&lt;ref name=":2" /&gt;&lt;ref name=":3" /&gt; The current state-of-the-art in secondary structure prediction uses a system called DeepCNF (deep convolutional neural fields) which relies on the machine learning model of [[artificial neural network]]s to achieve an accuracy of approximately 84% when tasked to classify the amino acids of a protein sequence into one of three structural classes (helix, sheet, or coil).&lt;ref name=":3"&gt;{{cite journal|last=Wang|first=Sheng|last2=Peng|first2=Jian|last3=Ma|first3=Jianzhu|last4=Xu|first4=Jinbo|date=December 1, 2015|title=Protein secondary structure prediction using deep convolutional neural fields|journal=Scientific Reports|volume=6|pages=18962|arxiv=1512.00843|bibcode=2016NatSR...618962W|doi=10.1038/srep18962|pmid=26752681|pmc=4707437}}&lt;/ref&gt; The theoretical limit for three-state protein secondary structure is 88–90%.&lt;ref name=":2" /&gt;

Machine learning has also been applied to proteomics problems such as [[Side chain|protein side-chain]] prediction, [[Turn (biochemistry)|protein loop]] modeling, and [[protein contact map]] prediction.&lt;ref name=":0" /&gt;

=== Microarrays ===
Microarrays, a type of [[lab-on-a-chip]], are used for automatically collecting data about large amounts of biological material. Machine learning can aid in the analysis of this data, and it has been applied to expression pattern identification, classification, and genetic network induction.&lt;ref name=":0" /&gt;
[[File:DNA-microarray analysis.jpg|thumb|A DNA-microarray analysis of Burkitt's lymphoma and diffuse large B-cell lymphoma (DLBCL) is shown and identifies differences in gene expression patterns.]]
This technology is especially useful for monitoring the expression of genes within a genome, aiding in diagnosing different types of cancer based on which genes are expressed.&lt;ref name=":4"&gt;{{Cite journal|last=Pirooznia|first=Mehdi|last2=Yang|first2=Jack Y.|last3=Yang|first3=Mary Qu|last4=Deng|first4=Youping|date=2008|title=A comparative study of different machine learning methods on microarray gene expression data|journal=BMC Genomics|volume=9|issue=1|pages=S13|doi=10.1186/1471-2164-9-S1-S13|issn=1471-2164|pmc=2386055|pmid=18366602}}&lt;/ref&gt; One of the main problems in this field is identifying which genes are expressed based on the collected data.&lt;ref name=":0" /&gt; In addition, due to the huge number of genes on which data is collected by the microarray, there is a large amount of irrelevant data to the task of expressed gene identification, further complicating this problem. Machine learning presents a potential solution to this problem as various classification methods can be used to perform this identification. The most commonly used methods are [[radial basis function network]]s, [[deep learning]], [[Naive Bayes classifier|Bayesian classification]], [[decision tree]]s, and [[random forest]].&lt;ref name=":4" /&gt;

=== Systems biology ===
Systems biology focuses on the study of the emergent behaviors from complex interactions of simple biological components in a system. Such components can include molecules such as DNA, RNA, proteins, and metabolites.&lt;ref&gt;{{Cite web|url=http://journal.frontiersin.org/researchtopic/2362/machine-learning-in-molecular-systems-biology|title=Machine Learning in Molecular Systems Biology|website=Frontiers|language=en|access-date=2017-06-09}}&lt;/ref&gt;

Machine learning has been used to aid in the modelling of these complex interactions in biological systems in domains such as genetic networks, signal transduction networks, and metabolic pathways.&lt;ref name=":0" /&gt; [[Graphical model|Probabilistic graphical models]], a machine learning technique for determining the structure between different variables, are one of the most commonly used methods for modeling genetic networks.&lt;ref name=":0" /&gt; In addition, machine learning has been applied to systems biology problems such as identifying [[DNA binding site|transcription factor binding sites]] using a technique known as [[Markov chain|Markov chain optimization]].&lt;ref name=":0" /&gt; [[Genetic algorithm]]s, machine learning techniques which are based on the natural process of evolution, have been used to model genetic networks and regulatory structures.&lt;ref name=":0" /&gt;

Other systems biology applications of machine learning include the task of enzyme function prediction, high throughput microarray data analysis, analysis of genome-wide association studies to better understand markers of disease, protein function prediction.&lt;ref&gt;{{Cite journal|last=d'Alché-Buc|first=Florence|last2=Wehenkel|first2=Louis|date=2008|title=Machine Learning in Systems Biology|journal=BMC Proceedings|volume=2|issue=4|pages=S1|doi=10.1186/1753-6561-2-S4-S1|pmid=19091048|pmc=2654969|issn=1753-6561}}&lt;/ref&gt;

=== Stroke Diagnosis ===
Machine learning methods for analysis of [[neuroimaging]] data are used to help diagnose [[stroke]]. Three-dimensional [[Convolutional neural network|CNN]] and [[Support-vector machine|SVM]] methods are often used. 
&lt;ref name="stroke1"&gt;{{cite journal |last1=Jiang |first1=Fei |title=Artificial intelligence in healthcare: past, present and future |journal=BMJ Journals Stroke and Vascular Neurology |date=2017 |volume=2 |issue=4 |pages=230–243 |doi=10.1136/svn-2017-000101 |pmid=29507784 |pmc=5829945 |url=https://svn.bmj.com/content/svnbmj/2/4/230.full.pdf |accessdate=23 January 2019}}&lt;/ref&gt;

=== Text mining ===
The increase in available biological publications led to the issue of the increase in difficulty in searching through and compiling all the relevant available information on a given topic across all sources. This task is known as [[knowledge extraction]]. This is necessary for biological data collection which can then in turn be fed into machine learning algorithms to generate new biological knowledge.&lt;ref name=":0" /&gt;&lt;ref name=":5"&gt;{{Cite journal|last=Krallinger|first=Martin|last2=Erhardt|first2=Ramon Alonso-Allende|last3=Valencia|first3=Alfonso|date=March 15, 2005|title=Text-mining approaches in molecular biology and biomedicine|journal=Drug Discovery Today|volume=10|issue=6|pages=439–445|doi=10.1016/S1359-6446(05)03376-3|pmid=15808823}}&lt;/ref&gt; Machine learning can be used for this knowledge extraction task using techniques such as [[natural language processing]] to extract the useful information from human-generated reports in a database. [[Text Nailing]], an alternative approach to machine learning, capable of extracting features from clinical narrative notes was introduced in 2017.

This technique has been applied to the search for novel drug targets, as this task requires the examination of information stored in biological databases and journals.&lt;ref name=":5" /&gt; Annotations of proteins in protein databases often do not reflect the complete known set of knowledge of each protein, so additional information must be extracted from biomedical literature. Machine learning has been applied to automatic annotation of the function of genes and proteins, determination of the [[Protein targeting|subcellular localization of a protein]], analysis of [[Gene expression|DNA-expression arrays]], large-scale [[List of protein interactions|protein interaction]] analysis, and molecule interaction analysis.&lt;ref name=":5" /&gt;

Another application of text mining is the detection and visualization of distinct DNA regions given sufficient reference data.&lt;ref name="sing"&gt;{{cite book|last=Pratas|first=D|author2=Hosseini, M|author3=Silva, R|author4= Pinho, A|author5= Ferreira, P|title=Visualization of Distinct DNA Regions of the Modern Human Relatively to a Neanderthal Genome|journal=Iberian Conference on Pattern Recognition and Image Analysis. Springer|volume=10255|pages=235–242|date= June 20–23, 2017|doi=10.1007/978-3-319-58838-4_26|series=Lecture Notes in Computer Science|isbn=978-3-319-58837-7}}&lt;/ref&gt;

==References==
{{reflist}}

__FORCETOC__

[[Category:Machine learning]]
[[Category:Bioinformatics]]
[[Category:Computer science]]
[[Category:Biology]]</text>
      <sha1>0xnl19ptpykmnq6rd0kh4ddf4h4w67m</sha1>
    </revision>
  </page>
  <page>
    <title>Labeled data</title>
    <ns>0</ns>
    <id>54033657</id>
    <revision>
      <id>994585318</id>
      <parentid>994555116</parentid>
      <timestamp>2020-12-16T14:02:55Z</timestamp>
      <contributor>
        <username>MrOllie</username>
        <id>6908984</id>
      </contributor>
      <comment>Reverted to revision 976994841 by [[Special:Contributions/GermanJoe|GermanJoe]] ([[User talk:GermanJoe|talk]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3860" xml:space="preserve">{{refimprove
| date = May 2017
}}{{Machine learning bar}}

'''Labeled data''' is a group of [[Sample (statistics)|samples]] that have been tagged with one or more labels. Labeling typically takes a set of unlabeled data and augments each piece of it with informative tags. For example, a data label might indicate whether a photo contains a horse or a cow, which words were uttered in an audio recording, what type of action is being performed in a video, what the topic of a news article is, what the overall sentiment of a tweet is, or whether a dot in an X-ray is a tumor.

Labels can be obtained by asking humans to make judgments about a given piece of unlabeled data. Labeled data is significantly more expensive to obtain than the raw unlabeled data.

==Crowdsourced labeled data==
In 2006 [[Fei-Fei Li]], the co-director of the Stanford Human-Centered AI Institute, set out to improve the [[artificial intelligence]] models and algorithms for image recognition by significantly enlarging the [[training data]]. The researchers downloaded millions of images from the [[World Wide Web]] and a team of undergraduates started to apply labels for objects to each image. In 2007 Li outsourced the data labelling work on [[Amazon Mechanical Turk]], a [[online marketplace]] for digital [[piece work]]. The 3.2 million images that were labelled by more than 49,000 workers formed the basis for [[ImageNet]], one of the largest hand-labeled database for [[outline of object recognition]].&lt;ref&gt;{{Cite book| authors = Mary L. Gray &amp; Siddharth Suri |title=Ghost Work: How to Stop Silicon Valley from Building a New Global Underclass|publisher=Houghton Mifflin Harcourt|year=2019|isbn=9781328566287|pages=7}}&lt;/ref&gt;

==Automated data labelling==
After obtaining a labeled dataset, [[machine learning]] models can be applied to the data so that new unlabeled data can be presented to the model and a likely label can be guessed or predicted for that piece of unlabeled data.&lt;ref&gt;Johnson, Leif. [https://stackoverflow.com/a/19172720 "What is the difference between labeled and unlabeled data?"], ''[[Stack Overflow]]'', 4 October 2013. Retrieved on 13 May 2017. {{CC-notice|cc=bysa3|url=https://stackoverflow.com/a/19172720|author=[https://stackoverflow.com/users/2014584/lmjohns3 lmjohns3]}}&lt;/ref&gt;

==Data-driven bias==
Algorithmic decision-making is subject to programmer-driven bias as well as data-driven bias. Training data that relies on bias labeled data will result in prejudices and omissions in a [[predictive model]], despite the machine learning algorithm being legitimate. The labelled data used to train a specific machine learning algorithm needs to be a statistically [[representative sample]] to not bias the results.&lt;ref&gt;{{Cite book| authors = Xianhong Hu, Neupane, Bhanu, Echaiz, Lucia Flores, Sibal, Prateek, Rivera Lam, Macarena |title=Steering AI and advanced ICTs for knowledge societies: a Rights, Openness, Access, and Multi-stakeholder Perspective|publisher=UNESCO Publishing|year=2019|isbn=9789231003639|pages=64}}&lt;/ref&gt; Because the labeled data available to train [[facial recognition system]]s has not been representative of a population, underrepresented groups in the labeled data are later often misclassified. In 2018 a study by [[Joy Buolamwini]] and [[Timnit Gebru]] demonstrated that two facial analysis datasets that have been used to train facial recognition algorithms, IJB-A and Adience, are composed of 79.6% and 86.2% lighter skinned humans respectively.&lt;ref&gt;{{Cite book| authors = Xianhong Hu, Neupane, Bhanu, Echaiz, Lucia Flores, Sibal, Prateek, Rivera Lam, Macarena |title=Steering AI and advanced ICTs for knowledge societies: a Rights, Openness, Access, and Multi-stakeholder Perspective|publisher=UNESCO Publishing|year=2019|isbn=9789231003639|pages=66}}&lt;/ref&gt;

==References==
{{Reflist}}

[[Category:Machine learning]]</text>
      <sha1>8o73bj2lgsavlad18hzyjyiizl5hiwv</sha1>
    </revision>
  </page>
  <page>
    <title>Caffe (software)</title>
    <ns>0</ns>
    <id>53631046</id>
    <revision>
      <id>983661597</id>
      <parentid>948381009</parentid>
      <timestamp>2020-10-15T14:28:24Z</timestamp>
      <contributor>
        <username>QuantumWasp</username>
        <id>40315822</id>
      </contributor>
      <minor/>
      <comment>/* History */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="5417" xml:space="preserve">{{Infobox software
| name                   = Caffe
| logo                   = 
| screenshot             =
| caption                =
| collapsible            =
| author                 = Yangqing Jia
| developer              = Berkeley Vision and Learning Center
| released               = 
| latest release version = 1.0&lt;ref&gt;{{Cite web|url=https://github.com/BVLC/caffe|title=BVLC/caffe|website=GitHub|date=31 March 2020}}&lt;/ref&gt;
| latest release date    = {{Start date and age|2017|04|18|df=yes}}
| latest preview version = 
| latest preview date    = 
| programming language   = [[C++]]
| operating system       = [[Linux]], [[macOS]], [[Microsoft Windows|Windows]]&lt;ref&gt;{{cite web|url=https://github.com/Microsoft/caffe|title=Microsoft/caffe|work=GitHub|date=30 March 2020}}&lt;/ref&gt;
| platform               =
| size                   =
| language               =
| genre                  = Library for [[deep learning]]
| license                = [[BSD License|BSD]]&lt;ref&gt;{{cite web|url=https://github.com/BVLC/caffe/blob/master/LICENSE|title=caffe/LICENSE at master|work=GitHub|date=31 March 2020}}&lt;/ref&gt;
| website                = {{url|http://caffe.berkeleyvision.org/}}
}}

{{machine learning bar}}

'''CAFFE''' (Convolutional Architecture for Fast Feature Embedding) is a [[deep learning]] framework, originally developed at [[University of California, Berkeley]]. It is [[Open-source software|open source]], under a [[BSD license]].&lt;ref&gt;{{cite web|url=https://github.com/BVLC/caffe/|title=BVLC/caffe|work=GitHub|date=31 March 2020}}&lt;/ref&gt; It is written in [[C++]], with a [[Python (programming language)|Python]] interface.&lt;ref&gt;{{cite web|url=https://deeplearning4j.org/compare-dl4j-torch7-pylearn#caffe|title=Comparing Frameworks: Deeplearning4j, Torch, Theano, TensorFlow, Caffe, Paddle, MxNet, Keras &amp; CNTK|access-date=2017-03-29|archive-url=https://web.archive.org/web/20170329233123/https://deeplearning4j.org/compare-dl4j-torch7-pylearn#caffe|archive-date=2017-03-29|url-status=dead}}&lt;/ref&gt;

== History ==
Yangqing Jia created the caffe project during his PhD at UC Berkeley.&lt;ref&gt;{{cite web|title=The Caffe Deep Learning Framework: An Interview with the Core Developers|date=17 January 2016|url=http://www.embedded-vision.com/industry-analysis/technical-articles/caffe-deep-learning-framework-interview-core-developers|publisher=Embedded Vision}}&lt;/ref&gt; It is currently hosted on [[GitHub]].&lt;ref&gt;{{cite web|title=Caffe: a fast open framework for deep learning.|date=31 March 2020|url=https://github.com/BVLC/caffe|publisher=GitHub}}&lt;/ref&gt;

== Features ==
Caffe supports many different types of deep learning architectures geared towards [[image classification]] and [[image segmentation]]. It supports [[Convolutional neural network|CNN]], RCNN, [[LSTM]] and fully connected neural network designs.&lt;ref&gt;{{cite web|title=Caffe tutorial - vision.princeton.edu|url=https://vision.princeton.edu/courses/COS598/2015sp/slides/Caffe/caffe_tutorial.pdf|archiveurl=https://web.archive.org/web/20170405073658/https://vision.princeton.edu/courses/COS598/2015sp/slides/Caffe/caffe_tutorial.pdf|archivedate=April 5, 2017}}&lt;/ref&gt; Caffe supports GPU- and CPU-based acceleration computational kernel libraries such as [[NVIDIA]] cuDNN and [[Math Kernel Library|Intel MKL]].&lt;ref&gt;{{Cite web|url=https://devblogs.nvidia.com/deep-learning-computer-vision-caffe-cudnn/|title=Deep Learning for Computer Vision with Caffe and cuDNN|date=October 16, 2014|website=NVIDIA Developer Blog}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://github.com/BVLC/caffe/blob/3d5bed06a9b6b8a5dfd3db8da33f2fa3bc9a1213/include/caffe/util/mkl_alternate.hpp|title=mkl_alternate.hpp|website=BVLC Caffe|access-date=2018-04-11}}&lt;/ref&gt;

== Applications ==
Caffe is being used in academic research projects, startup prototypes, and even large-scale industrial applications in vision, speech, and multimedia. [[Yahoo!]] has also integrated caffe with [[Apache Spark]] to create CaffeOnSpark, a distributed deep learning framework.&lt;ref&gt;{{Cite web|url=https://jaxenter.com/yahoo-enters-artificial-intelligence-race-with-caffeonspark-124324.html|title=Yahoo enters artificial intelligence race with CaffeOnSpark|date=February 29, 2016}}&lt;/ref&gt;

== Caffe2 ==
In April 2017, [[Facebook]] announced Caffe2,&lt;ref&gt;{{Cite web|url=http://caffe2.ai/blog/2017/04/18/caffe2-open-source-announcement.html|title=Caffe2 Open Source Brings Cross Platform Machine Learning Tools to Developers|first=Caffe2|last=Team|date=April 18, 2017|website=Caffe2}}&lt;/ref&gt; which included new features such as [[Recurrent neural network|Recurrent Neural Networks]].
At the end of March 2018, Caffe2 was merged into [[PyTorch]].&lt;ref&gt;{{Cite web|url=https://medium.com/@Synced/caffe2-merges-with-pytorch-a89c70ad9eb7|title=Caffe2 Merges With PyTorch|date=May 16, 2018|website=Medium}}&lt;/ref&gt;

==See also==
* [[Comparison of deep learning software]]

==References==
{{Reflist}}

==External links==
* {{Official website|http://caffe.berkeleyvision.org/}}
{{Deep Learning Software}}

{{DEFAULTSORT:Caffe}}
[[Category:Applied machine learning]]
[[Category:Artificial neural networks]]
[[Category:Data mining and machine learning software]]
[[Category:Deep learning]]
[[Category:Free science software]]
[[Category:Free statistical software]]
[[Category:Image processing]]
[[Category:Information technology companies of the United States]]
[[Category:Machine learning]]
[[Category:Software using the BSD license]]</text>
      <sha1>0gdd7v8z71rsb1uwqk540g6nu70h67u</sha1>
    </revision>
  </page>
  <page>
    <title>Occam learning</title>
    <ns>0</ns>
    <id>44577560</id>
    <revision>
      <id>965655834</id>
      <parentid>952542010</parentid>
      <timestamp>2020-07-02T16:40:22Z</timestamp>
      <contributor>
        <username>НСНУ</username>
        <id>12521734</id>
      </contributor>
      <minor/>
      <comment>/* Theorem (Occam learning implies PAC learning, cardinality version) */ a wikilink</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="10654" xml:space="preserve">{{Machine learning bar}}

In [[computational learning theory]], '''Occam learning''' is a model of algorithmic learning where the objective of the learner is to output a succinct representation of received training data. This is closely related to [[probably approximately correct learning|probably approximately correct (PAC) learning]], where the learner is evaluated on its predictive power of a test set.

Occam learnability implies PAC learning, and for a wide variety of [[concept class]]es, the converse is also true: PAC learnability implies Occam learnability.

==Introduction==
Occam Learning is named after [[Occam’s Razor#Science and the scientific method|Occam's razor]], which is a principle stating that, given all other things being equal, a shorter explanation for observed data should be favored over a lengthier explanation. The theory of Occam learning is a formal and mathematical justification for this principle. It was first shown by Blumer, et al.&lt;ref name="def" /&gt; that Occam learning implies PAC learning, which is the standard model of learning in computational learning theory. In other words, ''parsimony'' (of the output hypothesis) implies ''predictive power''.

==Definition of Occam learning==
The succinctness of a concept &lt;math&gt;c&lt;/math&gt; in [[concept class]] &lt;math&gt;\mathcal{C}&lt;/math&gt; can be expressed by the length &lt;math&gt;size(c)&lt;/math&gt; of the shortest bit string that can represent &lt;math&gt;c&lt;/math&gt; in &lt;math&gt;\mathcal{C}&lt;/math&gt;. Occam learning connects the succinctness of a learning algorithm's output to its predictive power on unseen data.

Let &lt;math&gt;\mathcal{C}&lt;/math&gt; and &lt;math&gt;\mathcal{H}&lt;/math&gt; be concept classes containing target concepts and hypotheses respectively. Then, for constants &lt;math&gt;\alpha \ge 0&lt;/math&gt; and &lt;math&gt;0 \le \beta &lt;1&lt;/math&gt;, a learning algorithm &lt;math&gt;L&lt;/math&gt; is an '''&lt;math&gt;(\alpha,\beta)&lt;/math&gt;-Occam algorithm''' for &lt;math&gt;\mathcal{C}&lt;/math&gt; using &lt;math&gt;\mathcal{H}&lt;/math&gt; iff, given a set &lt;math&gt;S = \{ x_1, \dots, x_m \}&lt;/math&gt; of &lt;math&gt;m&lt;/math&gt; samples labeled according to a concept &lt;math&gt;c \in \mathcal{C}&lt;/math&gt;, &lt;math&gt;L&lt;/math&gt; outputs a hypothesis &lt;math&gt;h \in \mathcal{H}&lt;/math&gt; such that
* &lt;math&gt;h&lt;/math&gt; is consistent with &lt;math&gt;c&lt;/math&gt; on &lt;math&gt;S&lt;/math&gt; (that is, &lt;math&gt; h(x)=c(x),\forall x \in S &lt;/math&gt;), and
* &lt;math&gt;size(h) \le (n \cdot size(c))^\alpha m^\beta &lt;/math&gt; &lt;ref name="kv"&gt;Kearns, M. J., &amp; Vazirani, U. V. (1994). An introduction to computational learning theory, chapter 2. MIT press.&lt;/ref&gt;&lt;ref name="def"&gt;Blumer, A., Ehrenfeucht, A., Haussler, D., &amp; Warmuth, M. K. (1987). ''[http://www.cse.buffalo.edu/~hungngo/classes/2008/694/papers/occam.pdf Occam's razor]''. Information processing letters, 24(6), 377-380.&lt;/ref&gt;
where &lt;math&gt;n&lt;/math&gt; is the maximum length of any sample &lt;math&gt;x \in S&lt;/math&gt;. An Occam algorithm is called ''efficient'' if it runs in time polynomial in &lt;math&gt;n&lt;/math&gt;, &lt;math&gt;m&lt;/math&gt;, and &lt;math&gt;size(c).&lt;/math&gt; We say a concept class &lt;math&gt;\mathcal{C}&lt;/math&gt; is ''Occam learnable'' with respect to a hypothesis class &lt;math&gt;\mathcal{H}&lt;/math&gt; if there exists an efficient Occam algorithm for  &lt;math&gt;\mathcal{C}&lt;/math&gt; using &lt;math&gt;\mathcal{H}.&lt;/math&gt;

==The relation between Occam and PAC learning==
Occam learnability implies PAC learnability, as the following theorem of Blumer, et al.&lt;ref name="kv" /&gt; shows:

=== Theorem (''Occam learning implies PAC learning'') ===
&lt;blockquote&gt;Let &lt;math&gt;L&lt;/math&gt; be an efficient  '''&lt;math&gt;(\alpha,\beta)&lt;/math&gt;'''-Occam algorithm for &lt;math&gt;\mathcal{C}&lt;/math&gt; using &lt;math&gt;\mathcal{H}&lt;/math&gt;. Then there exists a constant &lt;math&gt;a &gt; 0&lt;/math&gt; such that for any &lt;math&gt;0 &lt; \epsilon, \delta &lt; 1&lt;/math&gt;, for any distribution &lt;math&gt;\mathcal{D} &lt;/math&gt;, given &lt;math&gt;m \ge a \left( \frac 1 \epsilon \log \frac 1 \delta + \left(\frac {(n \cdot size(c))^\alpha)} \epsilon \right)^{\frac 1 {1-\beta}}\right)&lt;/math&gt;  samples drawn from &lt;math&gt;\mathcal{D} &lt;/math&gt; and labelled according to a concept &lt;math&gt;c \in \mathcal{C} &lt;/math&gt; of length &lt;math&gt;n&lt;/math&gt; bits each, the algorithm  &lt;math&gt;L&lt;/math&gt; will output a hypothesis  &lt;math&gt;h \in \mathcal{H} &lt;/math&gt; such that &lt;math&gt;error(h)\le \epsilon&lt;/math&gt; with probability at least &lt;math&gt;1-\delta&lt;/math&gt; .&lt;/blockquote&gt;Here, &lt;math&gt;error(h)&lt;/math&gt; is with respect to the concept &lt;math&gt;c&lt;/math&gt; and distribution &lt;math&gt;\mathcal{D} &lt;/math&gt;. This implies that the algorithm &lt;math&gt;L&lt;/math&gt; is also a PAC learner for the concept class &lt;math&gt;\mathcal{C}&lt;/math&gt; using hypothesis class &lt;math&gt;\mathcal{H}&lt;/math&gt;.  A slightly more general formulation is as follows:

=== Theorem (''Occam learning implies PAC learning, cardinality version'') ===
&lt;blockquote&gt;Let &lt;math&gt;0 &lt; \epsilon, \delta &lt; 1&lt;/math&gt;. Let &lt;math&gt;L&lt;/math&gt; be an algorithm such that, given &lt;math&gt;m&lt;/math&gt; samples drawn from a fixed but unknown distribution &lt;math&gt;\mathcal{D}&lt;/math&gt; and labeled according to a concept &lt;math&gt;c \in \mathcal{C} &lt;/math&gt; of length &lt;math&gt;n&lt;/math&gt; bits each, outputs a hypothesis &lt;math&gt;h \in \mathcal{H}_{n,m} &lt;/math&gt; that is consistent with the labeled samples. Then, there exists a constant &lt;math&gt;b&lt;/math&gt; such that if &lt;math&gt;\log |\mathcal{H}_{n,m}| \leq b \epsilon m - \log \frac{1}{\delta}&lt;/math&gt;, then &lt;math&gt;L&lt;/math&gt;  is guaranteed to output a hypothesis &lt;math&gt;h \in \mathcal{H}_{n,m} &lt;/math&gt; such that &lt;math&gt;error(h)\le \epsilon&lt;/math&gt; with probability at least &lt;math&gt;1-\delta&lt;/math&gt;.&lt;/blockquote&gt;

While the above theorems show that Occam learning is sufficient for PAC learning, it doesn't say anything about ''necessity.'' Board and Pitt show that, for a wide variety of concept classes, Occam learning is in fact necessary for PAC learning.&lt;ref&gt;Board, R., &amp; Pitt, L. (1990, April). On the necessity of Occam algorithms. In Proceedings of the twenty-second annual ACM symposium on Theory of computing (pp. 54-63). ACM.&lt;/ref&gt; They proved that for any concept class that is ''polynomially closed under exception lists,'' PAC learnability implies the existence of an Occam algorithm for that concept class. Concept classes that are polynomially closed under exception lists include Boolean formulas, circuits, [[Deterministic finite automaton|deterministic finite automata]], decision-lists, decision-trees, and other geometrically-defined concept classes.

A concept class &lt;math&gt;\mathcal{C}&lt;/math&gt; is polynomially closed under exception lists if there exists a polynomial-time algorithm &lt;math&gt;A&lt;/math&gt; such that, when given the representation of a concept &lt;math&gt;c \in \mathcal{C} &lt;/math&gt; and a finite list &lt;math&gt;E&lt;/math&gt; of ''exceptions'', outputs a representation of a concept &lt;math&gt;c' \in \mathcal{C}&lt;/math&gt; such that the concepts &lt;math&gt;c&lt;/math&gt; and &lt;math&gt;c'&lt;/math&gt; agree except on the set &lt;math&gt;E&lt;/math&gt;.

==Proof that Occam learning implies PAC learning==

We first prove the Cardinality version. Call a hypothesis &lt;math&gt;h\in \mathcal{H} &lt;/math&gt; ''bad'' if &lt;math&gt;error(h) \geq \epsilon&lt;/math&gt;, where again &lt;math&gt;error(h)&lt;/math&gt; is with respect to the true concept &lt;math&gt;c&lt;/math&gt; and the underlying distribution &lt;math&gt;\mathcal{D}&lt;/math&gt;. The probability that a set of samples &lt;math&gt;S&lt;/math&gt; is consistent with &lt;math&gt;h&lt;/math&gt; is at most &lt;math&gt;(1 - \epsilon)^m&lt;/math&gt;, by the independence of the samples. By the union bound, the probability that there exists a bad hypothesis in &lt;math&gt;\mathcal{H}_{n,m}&lt;/math&gt; is at most &lt;math&gt; | \mathcal{H}_{n,m} | (1 - \epsilon)^m&lt;/math&gt;, which is less than &lt;math&gt;\delta &lt;/math&gt; if &lt;math&gt;\log | \mathcal{H}_{n,m} |  \leq O(\epsilon m) - \log \frac{1}{\delta}&lt;/math&gt;. This concludes the proof of the second theorem above.

Using the second theorem, we can prove the first theorem. Since we have a &lt;math&gt;(\alpha,\beta)&lt;/math&gt;-Occam algorithm, this means that any hypothesis output by &lt;math&gt;L&lt;/math&gt; can be represented by at most &lt;math&gt; (n \cdot size(c))^\alpha m^\beta&lt;/math&gt; bits, and thus &lt;math&gt; \log |\mathcal{H}_{n,m}| \leq (n \cdot size(c))^\alpha m^\beta&lt;/math&gt;. This is less than &lt;math&gt;O(\epsilon m) - \log \frac{1}{\delta}&lt;/math&gt; if we set &lt;math&gt; m \geq a \left( \frac 1 \epsilon \log \frac 1 \delta + \left(\frac {(n \cdot size(c))^\alpha)} \epsilon \right)^{\frac 1 {1-\beta}}\right)&lt;/math&gt; for some constant &lt;math&gt;a &gt; 0&lt;/math&gt;. Thus, by the Cardinality version Theorem, &lt;math&gt;L&lt;/math&gt; will output a consistent hypothesis &lt;math&gt;h&lt;/math&gt; with probability at least &lt;math&gt;1 - \delta&lt;/math&gt;. This concludes the proof of the first theorem above.

==Improving sample complexity for common problems==
Though Occam and PAC learnability are equivalent, the Occam framework can be used to produce tighter bounds on the sample complexity of classical problems including conjunctions,&lt;ref name="kv" /&gt; conjunctions with few relevant variables,&lt;ref&gt;Haussler, D. (1988). ''[http://cs.ecs.baylor.edu/~hamerly/courses/5325_10s/papers/learning_theory/haussler1988inductive-bias.pdf Quantifying inductive bias: AI learning algorithms and Valiant's learning framework] {{Webarchive|url=https://web.archive.org/web/20130412062821/http://cs.ecs.baylor.edu/~hamerly/courses/5325_10s/papers/learning_theory/haussler1988inductive-bias.pdf |date=2013-04-12 }}''. Artificial intelligence, 36(2), 177-221.&lt;/ref&gt; and decision lists.&lt;ref&gt;Rivest, R. L. (1987). ''[http://people.csail.mit.edu/rivest/pubs/Riv87b.pdf Learning decision lists. Machine learning]'', 2(3), 229-246.&lt;/ref&gt;

== Extensions ==
Occam algorithms have also been shown to be successful for PAC learning in the presence of errors,&lt;ref&gt;Angluin, D., &amp; Laird, P. (1988). Learning from noisy examples. Machine Learning, 2(4), 343-370.&lt;/ref&gt;&lt;ref&gt;Kearns, M., &amp; Li, M. (1993). Learning in the presence of malicious errors. SIAM Journal on Computing, 22(4), 807-837.&lt;/ref&gt; probabilistic concepts,&lt;ref&gt;Kearns, M. J., &amp; Schapire, R. E. (1990, October). ''[http://www.cis.upenn.edu/~mkearns/papers/pconcepts.pdf Efficient distribution-free learning of probabilistic concepts]''. In Foundations of Computer Science, 1990. Proceedings., 31st Annual Symposium on (pp. 382-391). IEEE.&lt;/ref&gt; function learning&lt;ref&gt;Natarajan, B. K. (1993, August). Occam's razor for functions. In Proceedings of the sixth annual conference on Computational learning theory (pp. 370-376). ACM.&lt;/ref&gt; and Markovian non-independent examples.&lt;ref&gt;Aldous, D., &amp; Vazirani, U. (1990, October). ''[http://www.eecs.berkeley.edu/~vazirani/pubs/markovian.pdf A Markovian extension of Valiant's learning model]''. In Foundations of Computer Science, 1990. Proceedings., 31st Annual Symposium on (pp. 392-396). IEEE.&lt;/ref&gt;

==See also==
* [[Structural Risk Minimization]]
* [[Computational learning theory]]

==References==
{{reflist|30em}}

[[Category:Theoretical computer science]]
[[Category:Computational learning theory]]
[[Category:Machine learning]]</text>
      <sha1>1t09q3gsa8wrms79s4oxplyab62w9y9</sha1>
    </revision>
  </page>
  <page>
    <title>Right to explanation</title>
    <ns>0</ns>
    <id>54625345</id>
    <revision>
      <id>993793114</id>
      <parentid>989343531</parentid>
      <timestamp>2020-12-12T14:56:29Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 8 templates: del empty params (4×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="11597" xml:space="preserve">{{short description|Right to have algorithm explained}}
In the [[regulation]] of [[algorithm]]s, particularly [[artificial intelligence]] and its subfield of [[machine learning]], a '''right to explanation''' (or '''right to ''an'' explanation''') is a [[right]] to be given an [[explanation]] for an output of the algorithm. Such rights primarily refer to [[individual right]]s to be given an explanation for decisions that significantly affect an individual, particularly legally or financially. For example, a person who applies for a loan and is denied may ask for an explanation, which could be "[[Credit bureau]] X reports that you declared bankruptcy last year; this is the main factor in considering you too likely to default, and thus we will not give you the loan you applied for."

Some such [[legal right]]s already exist, while the scope of a general "right to explanation" is a matter of ongoing debate.

== Examples ==
=== Credit score in the United States ===
{{details|Credit score in the United States}}

[[Credit score in the United States]] – more generally, credit actions – have a well-established right to explanation. Under the [[Equal Credit Opportunity Act]] (Regulation B of the [[Code of Federal Regulations]]),
Title 12, Chapter X, Part 1002, [https://www.ecfr.gov/cgi-bin/text-idx?SID=1bb14fdfd1afc7d3f2d4756d223aeadb&amp;mc=true&amp;node=se12.8.1002_19 §1002.9], creditors are required to notify applicants of action taken in certain circumstances, and such notifications must provide specific reasons, as detailed in §1002.9(b)(2):&lt;ref&gt;[[Consumer Financial Protection Bureau]], [https://www.consumerfinance.gov/eregulations/1002-9/2011-31714#1002-9-b-2 §1002.9(b)(2)]&lt;/ref&gt;

{{quote|(2) Statement of specific reasons. The statement of reasons for adverse action required by paragraph (a)(2)(i) of this section must be specific and indicate the principal reason(s) for the adverse action. Statements that the adverse action was based on the creditor's internal standards or policies or that the applicant, joint applicant, or similar party failed to achieve a qualifying score on the creditor's credit scoring system are insufficient.}}

The [https://www.consumerfinance.gov/eregulations/1002-Subpart-Interp/2011-31714#1002-9-b-2-Interp-1 official interpretation] of this section details what types of statements are acceptable.

Credit agencies and data analysis firms such as [[FICO]] comply with this regulation by providing a list of reasons (generally at most 4, per interpretation of regulations), consisting of a numeric '''{{visible anchor|reason code}}''' (as identifier) and an associated explanation, identifying the main factors affecting a credit score.&lt;ref&gt;[http://www.creditscoring.com/creditscore/fico/factors/reason-codes.html US FICO credit risk score reason codes: Fundamental document from FICO listing all of the FICO credit score reasons that a score is not higher], March 31, 2010, by Greg Fisher&lt;/ref&gt; An example might be:&lt;ref&gt;{{Cite web|url=https://www.reasoncode.org/|title=ReasonCode.org &amp;#124; VantageScore Solutions|website=www.reasoncode.org}}&lt;/ref&gt;

:32: Balances on bankcard or revolving accounts too high compared to credit limits

=== European Union ===

The European Union [[General Data Protection Regulation]] (enacted 2016, taking effect 2018) extends the automated decision-making rights in the 1995 [[Data Protection Directive]] to provide a legally disputed form of a right to an explanation, stated as such in [https://www.privacy-regulation.eu/en/r71.htm Recital 71]: "[the data subject should have] the right ... to obtain an explanation of the decision reached". In full:

{{quote|
The data subject should have the right not to be subject to a decision, which may include a measure, evaluating personal aspects relating to him or her which is based solely on automated processing and which produces legal effects concerning him or her or similarly significantly affects him or her, such as automatic refusal of an online credit application or e-recruiting practices without any human intervention.

...

In any case, such processing should be subject to suitable safeguards, which should include specific information to the data subject and the right to obtain human intervention, to express his or her point of view, to obtain an explanation of the decision reached after such assessment and to challenge the decision.}}

However, the extent to which the regulations themselves provide a "right to explanation" is heavily debated.&lt;ref&gt;{{cite journal |last1=Goodman |first1=Bryce |title=European Union Regulations on Algorithmic Decision-Making and a 'Right to Explanation' |last2=Flaxman |first2=Seth |journal=AI Magazine |volume=38 |issue=3 |pages=50–57 |year=2017 |doi=10.1609/aimag.v38i3.2741|arxiv=1606.08813 |s2cid=7373959 }}&lt;/ref&gt;&lt;ref name=":0" /&gt;&lt;ref&gt;[https://iapp.org/news/a/is-there-a-right-to-explanation-for-machine-learning-in-the-gdpr/ Is there a 'right to explanation' for machine learning in the GDPR?], Jun 1, 2017, Andrew Burt&lt;/ref&gt; There are two main strands of criticism. There are significant legal issues with the right as found in Article 22 — as recitals are not binding, and the right to an explanation is not mentioned in the binding articles of the text, having been removed during the legislative process.&lt;ref name=":0"&gt;{{cite journal |ssrn=2903469 |last1=Wachter |first1=Sandra |last2=Mittelstadt |first2=Brent |last3=Floridi |first3=Luciano |title=Why a Right to Explanation of Automated Decision-Making Does Not Exist in the General Data Protection Regulation |date=December 28, 2016 |journal=International Data Privacy Law}}&lt;/ref&gt; In addition, there are significant restrictions on the types of automated decisions that are covered — which must be both "solely" based on automated processing, and have legal or similarly significant effects — which significantly limits the range of automated systems and decisions to which the right would apply.&lt;ref name=":0" /&gt; In particular, the right is unlikely to apply in many of the cases of algorithmic controversy that have been picked up in the media.&lt;ref name=":1"&gt;{{Cite journal|last1=Edwards|first1=Lilian|last2=Veale|first2=Michael|date=2017|title=Slave to the algorithm? Why a "right to an explanation" is probably not the remedy you are looking for|journal=Duke Law and Technology Review|ssrn=2972855}}&lt;/ref&gt;

A second potential source of such a right has been pointed to in Article 15, the "right of access by the data subject". This restates a similar provision from the 1995 Data Protection Directive, allowing the data subject access to "meaningful information about the logic involved" in the same significant, solely automated decision-making, found in Article 22. Yet this too suffers from alleged challenges that relate to the timing of when this right can be drawn upon, as well as practical challenges that mean it may not be binding in many cases of public concern.&lt;ref name=":0" /&gt;

=== France ===
In [[France]] the 2016 ''Loi pour une République numérique'' (Digital Republic Act or ''loi numérique'') amends the country's administrative code to introduce a new provision for the explanation of decisions made by public sector bodies about individuals.&lt;ref name=":2"&gt;{{Cite journal|last1=Edwards|first1=Lilian|last2=Veale|first2=Michael|date=2018|title=Enslaving the Algorithm: From a 'Right to an Explanation' to a 'Right to Better Decisions'?|journal=IEEE Security &amp; Privacy|volume=16|issue=3|pages=46–54|doi=10.1109/MSP.2018.2701152|ssrn=3052831|s2cid=4049746|url=https://strathprints.strath.ac.uk/63317/1/Edwards_Veale_SPM_2018_Enslaving_the_algorithm_from_a_right_to_an_explanation_to_a_right_to_better_decisions.pdf}}&lt;/ref&gt; It notes that where there is "a decision taken on the basis of an algorithmic treatment", the rules that define that treatment and its “principal characteristics” must be communicated to the citizen upon request, where there is not an exclusion (e.g. for national security or defence). These should include the following:
# the degree and the mode of contribution of the algorithmic processing to the decision- making;
# the data processed and its source;
# the treatment parameters, and where appropriate, their weighting, applied to the situation of the person concerned;
# the operations carried out by the treatment. 
Scholars have noted that this right, while limited to administrative decisions, goes beyond the GDPR right to explicitly apply to decision support rather than decisions "solely" based on automated processing, as well as provides a framework for explaining specific decisions.&lt;ref name=":2" /&gt; Indeed, the GDPR automated decision-making rights in the European Union, one of the places a "right to an explanation" has been sought within, find their origins in French law in the late 1970s.&lt;ref&gt;{{Cite journal|last=Bygrave|first=L A|date=2001|title=Minding the Machine: Article 15 of the EC Data Protection Directive and Automated Profiling|url=http://folk.uio.no/lee/oldpage/articles/Minding_machine.pdf|journal=Computer Law &amp; Security Review|volume=17|issue=1|doi=10.1016/S0267-3649(01)00104-2}}&lt;/ref&gt;

== Criticism ==

Some argue that a "right to explanation" is at best unnecessary, at worst harmful, and threatens to stifle innovation. Specific criticisms include: favoring human decisions over machine decisions; being redundant with existing laws; and focusing on process over outcome.&lt;ref&gt;[http://www.techzone360.com/topics/techzone/articles/2017/01/25/429101-eus-right-explanation-harmful-restriction-artificial-intelligence.htm EU's Right to Explanation: A Harmful Restriction on Artificial Intelligence], Nick Wallace, Center for Data Innovation, January 25, 2017&lt;/ref&gt;

More fundamentally, many algorithms used in machine learning are not easily explainable. For example, the output of a [[deep neural network]] depends on many layers of computations, connected in a complex way, and no one input or computation may be a dominant factor. The field of [[Explainable AI]] seeks to provide better explanations from existing algorithms, and algorithms that are more easily explainable, but it is a young and active field.&lt;ref&gt;{{cite arxiv|last=Miller|first=Tim|date=2017-06-22|title=Explanation in Artificial Intelligence: Insights from the Social Sciences|eprint=1706.07269|class=cs.AI}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last1=Mittelstadt|first1=Brent|last2=Russell|first2=Chris|last3=Wachter|first3=Sandra|date=2019|title=Explaining Explanations in AI|journal=Proceedings of the Conference on Fairness, Accountability, and Transparency - FAT* '19|pages=279–288|location=New York, New York, USA|publisher=ACM Press|doi=10.1145/3287560.3287574|isbn=978-1-4503-6125-5|s2cid=53214940|url=http://epubs.surrey.ac.uk/850740/1/Explaining%20Explanations%20in%20AI.pdf}}&lt;/ref&gt;

Similarly, human decisions often cannot be easily explained: they may be based on intuition or a "[[gut feeling]]" that is hard to put into words. Some would argue that machines should not be required to meet a higher standard than humans.

== See also ==
* [[Algorithmic transparency]]
* [[Explainable artificial intelligence]]
* [[Regulation of algorithms]]

== References ==
{{reflist}}

== External links ==
* [http://www.slate.com/articles/technology/future_tense/2017/05/why_artificial_intelligences_should_have_to_explain_their_actions.html Artificial Intelligence Owes You an Explanation], by John Frank Weaver, ''Slate'', May 8, 2017

[[Category:Accountability]]
[[Category:Algorithms]]
[[Category:Artificial intelligence]]
[[Category:Human rights]]
[[Category:Machine learning]]</text>
      <sha1>klmxpe7r06apiynhroblkhmqv8enuk7</sha1>
    </revision>
  </page>
  <page>
    <title>Highway network</title>
    <ns>0</ns>
    <id>55375136</id>
    <revision>
      <id>939741116</id>
      <parentid>932881860</parentid>
      <timestamp>2020-02-08T12:02:37Z</timestamp>
      <contributor>
        <username>Bellowhead678</username>
        <id>23824585</id>
      </contributor>
      <minor/>
      <comment>strucutre-&gt;structure - [[Wikipedia:Correct typos in one click|Fix a typo in one click]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2753" xml:space="preserve">{{About|a technique used in machine learning||Highway}}

In [[machine learning]], a '''highway network''' is an approach to optimizing networks and increasing their depth. Highway networks use learned gating mechanisms to regulate information flow, inspired by [[Long short-term memory|Long Short-Term Memory]] (LSTM) [[recurrent neural networks]]. The gating mechanisms allow neural networks to have paths for information to follow across different layers ("information highways").&lt;ref&gt;{{cite arxiv|last1=Srivastava|first1=Rupesh Kumar|last2=Greff|first2=Klaus|last3=Schmidhuber|first3=Jürgen|title=Highway Networks|eprint=1505.00387|date=2 May 2015|class=cs.LG}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Srivastava|first1=Rupesh K|last2=Greff|first2=Klaus|last3=Schmidhuber|first3=Juergen|title=Training Very Deep Networks|journal=Advances in Neural Information Processing Systems 28|date=2015|pages=2377–2385|url=http://papers.nips.cc/paper/5850-training-very-deep-networks|publisher=Curran Associates, Inc.}}&lt;/ref&gt;

Highway networks have been used as part of [[Semantic analysis (machine learning)|text sequence labeling]] and [[speech recognition]] tasks.&lt;ref&gt;{{cite arxiv|last1=Liu|first1=Liyuan|last2=Shang|first2=Jingbo|last3=Xu|first3=Frank F.|last4=Ren|first4=Xiang|last5=Gui|first5=Huan|last6=Peng|first6=Jian|last7=Han|first7=Jiawei|title=Empower Sequence Labeling with Task-Aware Neural Language Model|eprint=1709.04109|date=12 September 2017|class=cs.CL}}&lt;/ref&gt;&lt;ref&gt;{{cite arxiv|last1=Kurata|first1=Gakuto|last2=Ramabhadran|first2=Bhuvana|last3=Saon|first3=George|last4=Sethy|first4=Abhinav|title=Language Modeling with Highway LSTM|eprint=1709.06436|date=19 September 2017|class=cs.CL}}&lt;/ref&gt;

&lt;br /&gt;

== Model ==
The model has two gates in addition to the '''H(W&lt;sub&gt;H&lt;/sub&gt;, x)''' gate: the transform gate '''T(W&lt;sub&gt;T&lt;/sub&gt;, x''') and the carry gate '''C(W&lt;sub&gt;C&lt;/sub&gt;, x)'''. Those two last gates are non-linear transfer functions (by convention [[Sigmoid function]]). The '''H(W&lt;sub&gt;H&lt;/sub&gt;, x)''' function can be any desired transfer function.

The carry gate is defined as '''C(W&lt;sub&gt;C&lt;/sub&gt;, x) = 1 - T(W&lt;sub&gt;T&lt;/sub&gt;, x)'''. While the transform gate is just a gate with a sigmoid transfer function.

&lt;br /&gt;

=== Structure ===
The structure of a hidden layer follows the equation:

&lt;math&gt;
\begin{align}
y = H(x,W_{H}) \centerdot T(x,W_{T}) + x \centerdot C(x,W_{C}) = H(x,W_{H}) \centerdot T(x,W_{T}) + x \centerdot (1 - T(x,W_{T}))
\end{align}
&lt;/math&gt;


The advantage of a Highway Network over the common deep neural networks is that solves or prevents partially the [[Vanishing gradient problem]], thus leading to easier to optimize neural networks.

&lt;br /&gt;

==References==
{{reflist}}

[[Category:Machine learning]]


{{compu-ai-stub}}</text>
      <sha1>tf5pw7q8fuzik70ub64ewgyrx17hy50</sha1>
    </revision>
  </page>
  <page>
    <title>Random forest</title>
    <ns>0</ns>
    <id>1363880</id>
    <revision>
      <id>1004206103</id>
      <parentid>1003384117</parentid>
      <timestamp>2021-02-01T15:01:31Z</timestamp>
      <contributor>
        <ip>65.92.132.205</ip>
      </contributor>
      <comment>Included a short discussion on model compression for random forests</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="39469" xml:space="preserve">{{About|the machine learning technique|other kinds of random tree|Random tree}}
{{short description|A binary search tree based ensemble machine learning method}}
 
{{machine learning bar}}

[[File:Random forest diagram complete.png|thumb|Diagram of a random decision forest]]

'''Random forests''' or '''random decision forests''' are an [[ensemble learning]] method for [[statistical classification|classification]], [[regression analysis|regression]] and other tasks that operate by constructing a multitude of [[decision tree learning|decision trees]] at training time and outputting the class that is the [[mode (statistics)|mode]] of the classes (classification) or mean/average prediction (regression) of the individual trees.&lt;ref name="ho1995"/&gt;&lt;ref name="ho1998"/&gt; Random decision forests correct for decision trees' habit of [[overfitting]] to their [[Test set|training set]].{{r|elemstatlearn}}{{rp|587–588}} Random forests generally outperform [[Decision tree learning|decision trees]], but their accuracy is lower than gradient boosted trees. However, data characteristics can affect their performance.&lt;ref name=":02"&gt;{{Cite journal|last=Piryonesi S. Madeh|last2=El-Diraby Tamer E.|date=2020-06-01|title=Role of Data Analytics in Infrastructure Asset Management: Overcoming Data Size and Quality Problems|journal=Journal of Transportation Engineering, Part B: Pavements|volume=146|issue=2|pages=04020022|doi=10.1061/JPEODX.0000175}}&lt;/ref&gt;

The first algorithm for random decision forests was created by [[Tin Kam Ho]]&lt;ref name="ho1995"&gt;{{cite conference
 |first        = Tin Kam
 |last         = Ho
 |title        = Random Decision Forests
 |conference   = Proceedings of the 3rd International Conference on Document Analysis and Recognition, Montreal, QC, 14–16 August 1995
 |year         = 1995
 |pages        = 278–282
 |url          = http://ect.bell-labs.com/who/tkh/publications/papers/odt.pdf
 |access-date  = 5 June 2016
 |archive-url  = https://web.archive.org/web/20160417030218/http://ect.bell-labs.com/who/tkh/publications/papers/odt.pdf
 |archive-date = 17 April 2016
 |url-status     = dead
 |df           = dmy-all
}}&lt;/ref&gt; using the [[random subspace method]],&lt;ref name="ho1998"&gt;{{cite journal | first = Tin Kam | last = Ho | name-list-style = vanc | title = The Random Subspace Method for Constructing Decision Forests | journal = IEEE Transactions on Pattern Analysis and Machine Intelligence | year = 1998 | volume = 20 | issue = 8 | pages = 832–844 | doi = 10.1109/34.709601 | url = http://ect.bell-labs.com/who/tkh/publications/papers/df.pdf }}&lt;/ref&gt; which, in Ho's formulation, is a way to implement the "stochastic discrimination" approach to classification proposed by Eugene Kleinberg.&lt;ref name="kleinberg1990"&gt;{{cite journal |first=Eugene |last=Kleinberg | name-list-style = vanc |title=Stochastic Discrimination |journal=[[Annals of Mathematics and Artificial Intelligence]] |year=1990 |volume=1 |issue=1–4 |pages=207–239 |url=https://pdfs.semanticscholar.org/faa4/c502a824a9d64bf3dc26eb90a2c32367921f.pdf |doi=10.1007/BF01531079|citeseerx=10.1.1.25.6750 }}&lt;/ref&gt;&lt;ref name="kleinberg1996"&gt;{{cite journal |first=Eugene |last=Kleinberg | name-list-style = vanc |title=An Overtraining-Resistant Stochastic Modeling Method for Pattern Recognition |journal=[[Annals of Statistics]] |year=1996 |volume=24 |issue=6 |pages=2319–2349 |doi=10.1214/aos/1032181157 |mr=1425956|doi-access=free }}&lt;/ref&gt;&lt;ref name="kleinberg2000"&gt;{{cite journal|first=Eugene|last=Kleinberg| name-list-style = vanc |title=On the Algorithmic Implementation of Stochastic Discrimination|journal=IEEE Transactions on PAMI|year=2000|volume=22|issue=5|pages=473–490|url=https://pdfs.semanticscholar.org/8956/845b0701ec57094c7a8b4ab1f41386899aea.pdf|doi=10.1109/34.857004|citeseerx=10.1.1.33.4131}}&lt;/ref&gt;

An extension of the algorithm was developed by [[Leo Breiman]]&lt;ref name="breiman2001"&gt;{{cite journal | first = Leo | last = Breiman | author-link = Leo Breiman | name-list-style = vanc | title = Random Forests | journal = [[Machine Learning (journal)|Machine Learning]] | year = 2001 | volume = 45 | issue = 1 | pages = 5–32 | doi = 10.1023/A:1010933404324 | doi-access = free }}&lt;/ref&gt; and [[Adele Cutler]],&lt;ref name="rpackage"/&gt; who registered&lt;ref&gt;U.S. trademark registration number 3185828, registered 2006/12/19.&lt;/ref&gt; "Random Forests" as a [[trademark]] ({{As of|lc=y|2019}}, owned by [[Minitab|Minitab, Inc.]]).&lt;ref&gt;{{cite web|url=https://trademarks.justia.com/786/42/random-78642027.html|title=RANDOM FORESTS Trademark of Health Care Productivity, Inc. - Registration Number 3185828 - Serial Number 78642027 :: Justia Trademarks}}&lt;/ref&gt; The extension combines Breiman's "[[Bootstrap aggregating|bagging]]" idea and random selection of features, introduced first by Ho&lt;ref name="ho1995"/&gt; and later independently by Amit and [[Donald Geman|Geman]]&lt;ref name="amitgeman1997"&gt;{{cite journal | last = Amit | first = Yali | last2 = Geman | first2 = Donald | author-link2 = Donald Geman | name-list-style = vanc | title = Shape quantization and recognition with randomized trees | journal = [[Neural Computation (journal)|Neural Computation]] | year = 1997 | volume = 9 | issue = 7 | pages = 1545–1588 | doi = 10.1162/neco.1997.9.7.1545 | url = http://www.cis.jhu.edu/publications/papers_in_database/GEMAN/shape.pdf | citeseerx = 10.1.1.57.6069 }}&lt;/ref&gt; in order to construct a collection of decision trees with controlled variance.

Random forests are frequently used as "blackbox" models in businesses, as they generate reasonable predictions across a wide range of data while requiring little configuration in packages such as [[scikit-learn]].

== History ==
The general method of random decision forests was first proposed by Ho in 1995.&lt;ref name="ho1995"/&gt; Ho established that forests of trees splitting with oblique hyperplanes can gain accuracy as they grow without suffering from overtraining, as long as the forests are randomly restricted to be sensitive to only selected [[Feature (machine learning)|feature]] dimensions.  A subsequent work along the same lines&lt;ref name="ho1998"/&gt; concluded that other splitting methods behave similarly, as long as they are randomly forced to be insensitive to some feature dimensions.  Note that this observation of a more complex classifier (a larger forest) getting more accurate nearly monotonically is in sharp contrast to the common belief that the complexity of a classifier can only grow to a certain level of accuracy before being hurt by overfitting.  The explanation of the forest method's resistance to overtraining can be found in Kleinberg's theory of stochastic discrimination.&lt;ref name="kleinberg1990"/&gt;&lt;ref name="kleinberg1996"/&gt;&lt;ref name="kleinberg2000"/&gt;
 
The early development of Breiman's notion of random forests was influenced by the work of Amit and
Geman&lt;ref name="amitgeman1997"/&gt; who introduced the idea of searching over a random subset of the
available decisions when splitting a node, in the context of growing a single
[[Decision tree|tree]].  The idea of random subspace selection from Ho&lt;ref name="ho1998"/&gt; was also influential in the design of random forests.  In this method a forest of trees is grown,
and variation among the trees is introduced by projecting the training data
into a randomly chosen [[Linear subspace|subspace]] before fitting each tree or each node.  Finally, the idea of
randomized node optimization, where the decision at each node is selected by a
randomized procedure, rather than a deterministic optimization was first
introduced by Dietterich.&lt;ref&gt;{{cite journal | first = Thomas | last = Dietterich | title = An Experimental Comparison of Three Methods for Constructing Ensembles of Decision Trees: Bagging, Boosting, and Randomization | journal = [[Machine Learning (journal)|Machine Learning]] | volume = 40 | issue = 2 | year = 2000 | pages = 139–157 | doi = 10.1023/A:1007607513941 | doi-access = free }}&lt;/ref&gt;

The introduction of random forests proper was first made in a paper
by [[Leo Breiman]].&lt;ref name="breiman2001"/&gt;  This paper describes a method of building a forest of
uncorrelated trees using a [[Classification and regression tree|CART]] like procedure, combined with randomized node
optimization and [[Bootstrap aggregating|bagging]].  In addition, this paper combines several
ingredients, some previously known and some novel, which form the basis of the
modern practice of random forests, in particular:

# Using [[out-of-bag error]] as an estimate of the [[generalization error]].
# Measuring variable importance through permutation.

The report also offers the first theoretical result for random forests in the
form of a bound on the [[generalization error]] which depends on the strength of the
trees in the forest and their [[correlation]].

==Algorithm==

===Preliminaries: decision tree learning===
{{main|Decision tree learning}}
Decision trees are a popular method for various machine learning tasks. Tree learning "come[s] closest to meeting the requirements for serving as an off-the-shelf procedure for data mining", say [[Trevor Hastie|Hastie]] ''et al.'', "because it is invariant under scaling and various other transformations of feature values, is robust to inclusion of irrelevant features, and produces inspectable models. However, they are seldom accurate".&lt;ref name="elemstatlearn"&gt;{{ElemStatLearn}}&lt;/ref&gt;{{rp|352}}

In particular, trees that are grown very deep tend to learn highly irregular patterns: they [[overfitting|overfit]] their training sets, i.e. have [[Bias–variance tradeoff|low bias, but very high variance]]. Random forests are a way of averaging multiple deep decision trees, trained on different parts of the same training set, with the goal of reducing the variance.&lt;ref name="elemstatlearn"/&gt;{{rp|587–588}} This comes at the expense of a small increase in the bias and some loss of interpretability, but generally greatly boosts the performance in the final model.

Forests are like the pulling together of decision tree algorithm efforts. Taking the teamwork of many trees thus improving the performance of a single random tree. Though not quite similar, forests give the effects of a K-fold cross validation.

===Bagging===
{{main|Bootstrap aggregating}}
The training algorithm for random forests applies the general technique of [[bootstrap aggregating]], or bagging, to tree learners. Given a training set {{mvar|X}} = {{mvar|x&lt;sub&gt;1&lt;/sub&gt;}}, ..., {{mvar|x&lt;sub&gt;n&lt;/sub&gt;}} with responses {{mvar|Y}} = {{mvar|y&lt;sub&gt;1&lt;/sub&gt;}}, ..., {{mvar|y&lt;sub&gt;n&lt;/sub&gt;}}, bagging repeatedly (''B'' times) selects a [[Sampling (statistics)#Replacement of selected units|random sample with replacement]] of the training set and fits trees to these samples:

: For {{mvar|b}} = 1, ..., {{mvar|B}}:
:# Sample, with replacement, {{mvar|n}} training examples from {{mvar|X}}, {{mvar|Y}}; call these {{mvar|X&lt;sub&gt;b&lt;/sub&gt;}}, {{mvar|Y&lt;sub&gt;b&lt;/sub&gt;}}.
:# Train a classification or regression tree {{mvar|f&lt;sub&gt;b&lt;/sub&gt;}} on {{mvar|X&lt;sub&gt;b&lt;/sub&gt;}}, {{mvar|Y&lt;sub&gt;b&lt;/sub&gt;}}.

After training, predictions for unseen samples {{mvar|x'}} can be made by averaging the predictions from all the individual regression trees on {{mvar|x'}}:

:&lt;math&gt;\hat{f} = \frac{1}{B} \sum_{b=1}^Bf_b (x')&lt;/math&gt;

or by taking the majority vote in the case of classification trees.

This bootstrapping procedure leads to better model performance because it decreases the [[Bias–variance dilemma|variance]] of the model, without increasing the bias. This means that while the predictions of a single tree are highly sensitive to noise in its training set, the average of many trees is not, as long as the trees are not correlated. Simply training many trees on a single training set would give strongly correlated trees (or even the same tree many times, if the training algorithm is deterministic); bootstrap sampling is a way of de-correlating the trees by showing them different training sets.

Additionally, an estimate of the uncertainty of the prediction can be made as the standard deviation of the predictions from all the individual regression trees on {{mvar|x'}}:

:&lt;math&gt;\sigma = \sqrt{\frac{\sum_{b=1}^B (f_b(x')  - \hat{f})^2}{B-1} }.&lt;/math&gt;

The number of samples/trees, {{mvar|B}}, is a free parameter. Typically, a few hundred to several thousand trees are used, depending on the size and nature of the training set. An optimal number of trees {{mvar|B}} can be found using [[Cross-validation (statistics)|cross-validation]], or by observing the ''[[out-of-bag error]]'': the mean prediction error on each training sample {{mvar|xᵢ}}, using only the trees that did not have {{mvar|xᵢ}} in their bootstrap sample.&lt;ref name="islr"&gt;{{cite book |author1=Gareth James |author2=Daniela Witten |author3=Trevor Hastie |author4=Robert Tibshirani |title=An Introduction to Statistical Learning |publisher=Springer |year=2013 |url=http://www-bcf.usc.edu/~gareth/ISL/ |pages=316–321}}&lt;/ref&gt;
The training and test error tend to level off after some number of trees have been fit.

===From bagging to random forests===
{{main|Random subspace method}}
The above procedure describes the original bagging algorithm for trees. Random forests differ in only one way from this general scheme: they use a modified tree learning algorithm that selects, at each candidate split in the learning process, a [[Random subspace method|random subset of the features]]. This process is sometimes called "feature bagging". The reason for doing this is the correlation of the trees in an ordinary bootstrap sample: if one or a few [[Feature (machine learning)|features]] are very strong predictors for the response variable (target output), these features will be selected in many of the {{mvar|B}} trees, causing them to become correlated. An analysis of how bagging and random subspace projection contribute to accuracy gains under different conditions is given by Ho.&lt;ref name="ho2002"&gt;
{{cite journal | first = Tin Kam | last = Ho | title = A Data Complexity Analysis of Comparative Advantages of Decision Forest Constructors | journal = Pattern Analysis and Applications | volume = 5 | issue = 2 | year = 2002 | pages = 102–112 | url = http://ect.bell-labs.com/who/tkh/publications/papers/compare.pdf | doi = 10.1007/s100440200009 }}&lt;/ref&gt;

Typically, for a classification problem with {{mvar|p}} features, {{sqrt|{{mvar|p}}}} (rounded down) features are used in each split.&lt;ref name="elemstatlearn"/&gt;{{rp|592}}  For regression problems the inventors recommend {{mvar|p/3}} (rounded down) with a minimum node size of 5 as the default.&lt;ref name="elemstatlearn"/&gt;{{rp|592}} In practice the best values for these parameters will depend on the problem, and they should be treated as tuning parameters.&lt;ref name="elemstatlearn"/&gt;{{rp|592}}

===ExtraTrees===
Adding one further step of randomization yields ''extremely randomized trees'', or ExtraTrees. While similar to ordinary random forests in that they are an ensemble of individual trees, there are two main differences: first, each tree is trained using the whole learning sample (rather than a bootstrap sample), and second, the top-down splitting in the tree learner is randomized. Instead of computing the locally ''optimal'' cut-point for each feature under consideration (based on, e.g., [[information gain]] or the [[Gini impurity]]), a ''random'' cut-point is selected. This value is selected from a uniform distribution within the feature's empirical range (in the tree's training set). Then, of all the randomly generated splits, the split that yields the highest score is chosen to split the node. Similar to ordinary random forests, the number of randomly selected features to be considered at each node can be specified. Default values for this parameter are &lt;math&gt;\sqrt{p}&lt;/math&gt; for classification and &lt;math&gt;p&lt;/math&gt; for regression, where &lt;math&gt;p&lt;/math&gt; is the number of features in the model.&lt;ref&gt;{{Cite journal | doi = 10.1007/s10994-006-6226-1| title = Extremely randomized trees| journal = Machine Learning| volume = 63| pages = 3–42| year = 2006| vauthors = Geurts P, Ernst D, Wehenkel L | url = http://orbi.ulg.ac.be/bitstream/2268/9357/1/geurts-mlj-advance.pdf}}&lt;/ref&gt;

==Properties==

=== Variable importance ===

Random forests can be used to rank the importance of variables in a regression or classification problem in a natural way.  The following technique was described in Breiman's original paper&lt;ref name=breiman2001/&gt; and is implemented in the [[R (programming language)|R]] package ''randomForest''.&lt;ref name="rpackage"&gt;{{cite web |url=https://cran.r-project.org/web/packages/randomForest/randomForest.pdf |title=Documentation for R package randomForest |first1=Andy |last1=Liaw | name-list-style = vanc | date=16 October 2012 |access-date=15 March 2013}}
&lt;/ref&gt;

The first step in measuring the variable importance in a data set &lt;math&gt;\mathcal{D}_n =\{(X_i, Y_i)\}_{i=1}^n&lt;/math&gt; is to fit a random forest to the data.  During the fitting process the [[out-of-bag error]] for each data point is recorded and averaged over the forest (errors on an independent test set can be substituted if bagging is not used during training).

To measure the importance of the &lt;math&gt;j&lt;/math&gt;-th feature after training, the values of the &lt;math&gt;j&lt;/math&gt;-th feature are permuted among the training data and the out-of-bag error is again computed on this perturbed data set.  The importance score for the &lt;math&gt;j&lt;/math&gt;-th feature is computed by averaging the difference in out-of-bag error before and after the permutation over all trees.  The score is normalized by the standard deviation of these differences.

Features which produce large values for this score are ranked as more important than features which produce small values. The statistical definition of the variable importance measure was given and analyzed by Zhu ''et al.''&lt;ref&gt;{{cite journal | vauthors = Zhu R, Zeng D, Kosorok MR | title = Reinforcement Learning Trees | journal = Journal of the American Statistical Association | volume = 110 | issue = 512 | pages = 1770–1784 | date = 2015 | pmid = 26903687 | pmc = 4760114 | doi = 10.1080/01621459.2015.1036994 }}&lt;/ref&gt;

This method of determining variable importance has some drawbacks.  For data including categorical variables with different number of levels, random forests are biased in favor of those attributes with more levels. Methods such as [[partial permutation]]s&lt;ref&gt;{{cite conference
|author=Deng, H.|author2=Runger, G. |author3=Tuv, E.
 |title=Bias of importance measures for multi-valued attributes and solutions
|conference=Proceedings of the 21st International Conference on Artificial Neural Networks (ICANN)
|year=2011|pages=293–300
|url=https://www.researchgate.net/publication/221079908
}}&lt;/ref&gt;&lt;ref&gt;{{cite journal | vauthors = Altmann A, Toloşi L, Sander O, Lengauer T | title = Permutation importance: a corrected feature importance measure | journal = Bioinformatics | volume = 26 | issue = 10 | pages = 1340–7 | date = May 2010 | pmid = 20385727 | doi = 10.1093/bioinformatics/btq134 | url = http://bioinformatics.oxfordjournals.org/content/early/2010/04/12/bioinformatics.btq134.abstract | doi-access = free }}&lt;/ref&gt;&lt;ref name=":02"/&gt;
and growing unbiased trees&lt;ref&gt;{{cite journal | last = Strobl | first = Carolin | last2 = Boulesteix | first2 = Anne-Laure | last3 = Augustin | first3 = Thomas | name-list-style = vanc | title = Unbiased split selection for classification trees based on the Gini index | journal = Computational Statistics &amp; Data Analysis | volume = 52 | year = 2007 | pages = 483–501 | url = https://epub.ub.uni-muenchen.de/1833/1/paper_464.pdf | doi = 10.1016/j.csda.2006.12.030 | citeseerx = 10.1.1.525.3178 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Painsky|first1=Amichai|last2=Rosset|first2=Saharon| name-list-style = vanc |title=Cross-Validated Variable Selection in Tree-Based Methods Improves Predictive Performance|journal=IEEE Transactions on Pattern Analysis and Machine Intelligence|date=2017|volume=39|issue=11|pages=2142–2153|doi=10.1109/tpami.2016.2636831|pmid=28114007|arxiv=1512.03444}}&lt;/ref&gt; can be used to solve the problem.  If the data contain groups of correlated features of similar relevance for the output, then smaller groups are favored over larger groups.&lt;ref&gt;{{cite journal | vauthors = Tolosi L, Lengauer T | title = Classification with correlated features: unreliability of feature ranking and solutions | journal = Bioinformatics | volume = 27 | issue = 14 | pages = 1986–94 | date = July 2011 | pmid = 21576180 | doi = 10.1093/bioinformatics/btr300 | url = http://bioinformatics.oxfordjournals.org/content/27/14/1986.abstract | doi-access = free }}&lt;/ref&gt;

=== Relationship to nearest neighbors ===
A relationship between random forests and the [[K-nearest neighbor algorithm|{{mvar|k}}-nearest neighbor algorithm]] ({{mvar|k}}-NN) was pointed out by Lin and Jeon in 2002.&lt;ref name="linjeon02"&gt;{{Cite techreport  |first1=Yi |last1=Lin |first2=Yongho |last2=Jeon |title=Random forests and adaptive nearest neighbors |series=Technical Report No. 1055 |year=2002 |institution=University of Wisconsin |citeseerx=10.1.1.153.9168}}&lt;/ref&gt; It turns out that both can be viewed as so-called ''weighted neighborhoods schemes''. These are models built from a training set &lt;math&gt;\{(x_i, y_i)\}_{i=1}^n&lt;/math&gt; that make predictions &lt;math&gt;\hat{y}&lt;/math&gt; for new points {{mvar|x'}} by looking at the "neighborhood" of the point, formalized by a weight function {{mvar|W}}:

:&lt;math&gt;\hat{y} = \sum_{i=1}^n W(x_i, x') \, y_i.&lt;/math&gt;

Here, &lt;math&gt;W(x_i, x')&lt;/math&gt; is the non-negative weight of the {{mvar|i}}'th training point relative to the new point {{mvar|x'}} in the same tree. For any particular {{mvar|x'}}, the weights for points &lt;math&gt;x_i&lt;/math&gt; must sum to one. Weight functions are given as follows:

* In {{mvar|k}}-NN, the weights are &lt;math&gt;W(x_i, x') = \frac{1}{k}&lt;/math&gt; if {{mvar|x&lt;sub&gt;i&lt;/sub&gt;}} is one of the {{mvar|k}} points closest to {{mvar|x'}}, and zero otherwise.
* In a tree, &lt;math&gt;W(x_i, x') = \frac{1}{k'}&lt;/math&gt; if {{mvar|x&lt;sub&gt;i&lt;/sub&gt;}} is one of the {{mvar|k'}} points in the same leaf as {{mvar|x'}}, and zero otherwise.

Since a forest averages the predictions of a set of {{mvar|m}} trees with individual weight functions &lt;math&gt;W_j&lt;/math&gt;, its predictions are

:&lt;math&gt;\hat{y} = \frac{1}{m}\sum_{j=1}^m\sum_{i=1}^n W_{j}(x_i, x') \, y_i = \sum_{i=1}^n\left(\frac{1}{m}\sum_{j=1}^m W_{j}(x_i, x')\right) \, y_i.&lt;/math&gt;

This shows that the whole forest is again a weighted neighborhood scheme, with weights that average those of the individual trees. The neighbors of {{mvar|x'}} in this interpretation are the points &lt;math&gt;x_i&lt;/math&gt; sharing the same leaf in any tree &lt;math&gt;j&lt;/math&gt;. In this way, the neighborhood of {{mvar|x'}} depends in a complex way on the structure of the trees, and thus on the structure of the training set. Lin and Jeon show that the shape of the neighborhood used by a random forest adapts to the local importance of each feature.&lt;ref name="linjeon02"/&gt;

== Unsupervised learning with random forests ==
As part of their construction, random forest predictors naturally lead to a dissimilarity measure among the observations. One can also define a random forest dissimilarity measure between unlabeled data: the idea is to construct a random forest predictor that distinguishes the “observed” data from suitably generated synthetic data.&lt;ref name=breiman2001/&gt;&lt;ref&gt;{{cite journal |authors=Shi, T., Horvath, S. |year=2006 |title=Unsupervised Learning with Random Forest Predictors |journal=Journal of Computational and Graphical Statistics |volume=15 |issue=1 |pages=118–138  |doi=10.1198/106186006X94072 |jstor=27594168|citeseerx=10.1.1.698.2365 }}&lt;/ref&gt;
The observed data are the original unlabeled data and the synthetic data are drawn from a reference distribution. A random forest dissimilarity can be attractive because it handles mixed variable types very well, is invariant to monotonic transformations of the input variables, and is robust to outlying observations. The random forest dissimilarity easily deals with a large number of semi-continuous variables due to its intrinsic variable selection; for example, the "Addcl 1" random forest dissimilarity weighs the contribution of each variable according to how dependent it is on other variables. The random forest dissimilarity has been used in a variety of applications, e.g. to find clusters of patients based on tissue marker data.&lt;ref&gt;{{cite journal | vauthors = Shi T, Seligson D, Belldegrun AS, Palotie A, Horvath S | title = Tumor classification by tissue microarray profiling: random forest clustering applied to renal cell carcinoma | journal = Modern Pathology | volume = 18 | issue = 4 | pages = 547–57 | date = April 2005 | pmid = 15529185 | doi = 10.1038/modpathol.3800322 | doi-access = free }}&lt;/ref&gt;

== Variants ==
Instead of decision trees, linear models have been proposed and evaluated as base estimators in random forests, in particular [[multinomial logistic regression]] and [[naive Bayes classifier]]s.&lt;ref&gt;{{cite journal |authors=Prinzie, A., Van den Poel, D. |year=2008 |title=Random Forests for multiclass classification: Random MultiNomial Logit |journal=Expert Systems with Applications |volume=34 |issue=3 |pages=1721–1732 |doi=10.1016/j.eswa.2007.01.029}}&lt;/ref&gt;&lt;ref&gt;{{Cite conference | doi = 10.1007/978-3-540-74469-6_35 | contribution=Random Multiclass Classification: Generalizing Random Forests to Random MNL and Random NB|title=Database and Expert Systems Applications: 18th International Conference, DEXA 2007, Regensburg, Germany, September 3-7, 2007, Proceedings |editor1=Roland Wagner |editor2=Norman Revell |editor3=Günther Pernul| year=2007 | series=Lecture Notes in Computer Science | volume=4653 | pages=349–358 | last1 = Prinzie | first1 = Anita| isbn=978-3-540-74467-2 }}&lt;/ref&gt;

==Kernel random forest==
In machine learning, kernel random forests establish the connection between random forests and [[kernel method]]s. By slightly modifying their definition, random forests can be rewritten as [[kernel method]]s, which are more interpretable and easier to analyze.&lt;ref name="scornet2015random"&gt;{{cite arXiv
 |first=Erwan|last=Scornet
 |title=Random forests and kernel methods
   |year= 2015|eprint=1502.03836
|class=math.ST
 }}&lt;/ref&gt;

=== History ===
[[Leo Breiman]]&lt;ref name="breiman2000some"&gt;{{cite journal | first = Leo | last = Breiman | author-link = Leo Breiman | title = Some infinity theory for predictor ensembles | institution = Technical Report 579, Statistics Dept. UCB | year = 2000 | url = https://statistics.berkeley.edu/tech-reports/579 }}&lt;/ref&gt; was the first person to notice the link between random forest and [[kernel methods]]. He pointed out that random forests which are grown using [[i.i.d.]] random vectors in the tree construction are equivalent to a kernel acting on the true margin. Lin and Jeon&lt;ref name="lin2006random"&gt;{{cite journal | first = Yi | last = Lin | first2 = Yongho | last2 = Jeon | title = Random forests and adaptive nearest neighbors | journal = Journal of the American Statistical Association | volume = 101 | number = 474 | pages = 578–590 | year = 2006 | doi = 10.1198/016214505000001230 | citeseerx = 10.1.1.153.9168 }}&lt;/ref&gt; established the connection between random forests and adaptive nearest neighbor, implying that random forests can be seen as adaptive kernel estimates. Davies and Ghahramani&lt;ref name="davies2014random"&gt;{{cite arXiv |first=Alex |last=Davies |first2=Zoubin|last2=Ghahramani |title=The Random Forest Kernel and other kernels for big data from random partitions |eprint=1402.4293 |year= 2014 |class=stat.ML }}&lt;/ref&gt; proposed Random Forest Kernel and show that it can empirically outperform state-of-art kernel methods. Scornet&lt;ref name="scornet2015random"/&gt; first defined KeRF estimates and gave the explicit link between KeRF estimates and random forest. He also gave explicit expressions for kernels based on centered random forest&lt;ref name="breiman2004consistency"&gt;{{cite journal | first = Leo | last = Breiman | first2 = Zoubin | last2 = Ghahramani | name-list-style = vanc | title = Consistency for a simple model of random forests | journal = Statistical Department, University of California at Berkeley. Technical Report | number = 670 | year = 2004 | citeseerx = 10.1.1.618.90 }}&lt;/ref&gt; and uniform random forest,&lt;ref name="arlot2014analysis"&gt;{{cite arXiv |first=Sylvain |last=Arlot  | first2 = Robin | last2 = Genuer | name-list-style = vanc |title=Analysis of purely random forests bias |eprint=1407.3939 |year= 2014 |class=math.ST  }}&lt;/ref&gt; two simplified models of random forest. He named these two KeRFs Centered KeRF and Uniform KeRF, and proved upper bounds on their rates of consistency.

=== Notations and definitions ===
==== Preliminaries: Centered forests ====
Centered forest&lt;ref name="breiman2004consistency"/&gt; is a simplified model for Breiman's original random forest, which uniformly selects an attribute among all attributes and performs splits at the center of the cell along the pre-chosen attribute. The algorithm stops when a fully binary tree of level &lt;math&gt;k&lt;/math&gt; is built, where &lt;math&gt;k \in\mathbb{N} &lt;/math&gt; is a parameter of the algorithm.

==== Uniform forest ====
Uniform forest&lt;ref name="arlot2014analysis"/&gt; is another simplified model for Breiman's original random forest, which uniformly selects a feature among all features and performs splits at a point uniformly drawn on the side of the cell, along the preselected feature.

==== From random forest to KeRF ====
Given a training sample  &lt;math&gt;\mathcal{D}_n =\{(\mathbf{X}_i, Y_i)\}_{i=1}^n&lt;/math&gt; of &lt;math&gt;[0,1]^p\times\mathbb{R}&lt;/math&gt;-valued independent random variables distributed as the independent prototype pair &lt;math&gt;(\mathbf{X}, Y)&lt;/math&gt;, where &lt;math&gt;\operatorname{E}[Y^2]&lt;\infty&lt;/math&gt;. We aim at predicting the response &lt;math&gt;Y&lt;/math&gt;, associated with the random variable &lt;math&gt;\mathbf{X}&lt;/math&gt;, by estimating the regression function &lt;math&gt;m(\mathbf{x})=\operatorname{E}[Y \mid \mathbf{X} = \mathbf{x}]&lt;/math&gt;. A random regression forest is an ensemble of &lt;math&gt;M&lt;/math&gt; randomized regression trees. Denote &lt;math&gt;m_n(\mathbf{x},\mathbf{\Theta}_j)&lt;/math&gt; the predicted value at point &lt;math&gt;\mathbf{x}&lt;/math&gt; by the &lt;math&gt;j&lt;/math&gt;-th tree, where &lt;math&gt;\mathbf{\Theta}_1,\ldots,\mathbf{\Theta}_M &lt;/math&gt; are independent random variables, distributed as a generic random variable &lt;math&gt;\mathbf{\Theta}&lt;/math&gt;, independent of the sample &lt;math&gt;\mathcal{D}_n&lt;/math&gt;. This random variable can be used to describe the randomness induced by node splitting and the sampling procedure for tree construction. The trees are combined to form the finite forest estimate &lt;math&gt;m_{M, n}(\mathbf{x},\Theta_1,\ldots,\Theta_M) = \frac{1}{M}\sum_{j=1}^M m_n(\mathbf{x},\Theta_j)&lt;/math&gt;.
For regression trees, we have &lt;math&gt;m_n = \sum_{i=1}^n\frac{Y_i\mathbf{1}_{\mathbf{X}_i\in A_n(\mathbf{x},\Theta_j)}}{N_n(\mathbf{x}, \Theta_j)}&lt;/math&gt;, where &lt;math&gt;A_n(\mathbf{x},\Theta_j)&lt;/math&gt; is the cell containing &lt;math&gt;\mathbf{x}&lt;/math&gt;, designed with randomness &lt;math&gt;\Theta_j&lt;/math&gt; and dataset &lt;math&gt;\mathcal{D}_n&lt;/math&gt;, and &lt;math&gt; N_n(\mathbf{x}, \Theta_j) = \sum_{i=1}^n \mathbf{1}_{\mathbf{X}_i\in A_n(\mathbf{x}, \Theta_j)}&lt;/math&gt;.

Thus random forest estimates satisfy, for all &lt;math&gt;\mathbf{x}\in[0,1]^d&lt;/math&gt;, &lt;math&gt; m_{M,n}(\mathbf{x}, \Theta_1,\ldots,\Theta_M) =\frac{1}{M}\sum_{j=1}^M \left(\sum_{i=1}^n\frac{Y_i\mathbf{1}_{\mathbf{X}_i\in A_n(\mathbf{x},\Theta_j)}}{N_n(\mathbf{x}, \Theta_j)}\right)&lt;/math&gt;. Random regression forest has two level of averaging, first over the samples in the target cell of a tree, then over all trees. Thus the contributions of observations that are in cells with a high density of data points are smaller than that of observations which belong to less populated cells. In order to improve the random forest methods and compensate the misestimation, Scornet&lt;ref name="scornet2015random"/&gt; defined KeRF by

: &lt;math&gt; \tilde{m}_{M,n}(\mathbf{x}, \Theta_1,\ldots,\Theta_M) = \frac{1}{\sum_{j=1}^M N_n(\mathbf{x}, \Theta_j)}\sum_{j=1}^M\sum_{i=1}^n Y_i\mathbf{1}_{\mathbf{X}_i\in A_n(\mathbf{x}, \Theta_j)},&lt;/math&gt;

which is equal to the mean of the &lt;math&gt;Y_i&lt;/math&gt;'s falling in the cells containing &lt;math&gt;\mathbf{x}&lt;/math&gt; in the forest. If we define the connection function of the &lt;math&gt;M&lt;/math&gt; finite forest as &lt;math&gt;K_{M,n}(\mathbf{x}, \mathbf{z}) = \frac{1}{M} \sum_{j=1}^M \mathbf{1}_{\mathbf{z} \in A_n (\mathbf{x}, \Theta_j)}&lt;/math&gt;, i.e. the proportion of cells shared between &lt;math&gt;\mathbf{x}&lt;/math&gt; and &lt;math&gt;\mathbf{z}&lt;/math&gt;, then almost surely we have &lt;math&gt;\tilde{m}_{M,n}(\mathbf{x}, \Theta_1,\ldots,\Theta_M) =
\frac{\sum_{i=1}^n Y_i K_{M,n}(\mathbf{x}, \mathbf{x}_i)}{\sum_{\ell=1}^n K_{M,n}(\mathbf{x}, \mathbf{x}_{\ell})}&lt;/math&gt;, which defines the KeRF.

==== Centered KeRF ====
The construction of Centered KeRF of level &lt;math&gt;k&lt;/math&gt; is the same as for centered forest, except that predictions are made by &lt;math&gt;\tilde{m}_{M,n}(\mathbf{x}, \Theta_1,\ldots,\Theta_M) &lt;/math&gt;, the corresponding kernel function, or connection function is

: &lt;math&gt;
\begin{align}
K_k^{cc}(\mathbf{x},\mathbf{z}) = \sum_{k_1,\ldots,k_d, \sum_{j=1}^d k_j=k} &amp;
\frac{k!}{k_1!\cdots k_d!} \left(\frac 1 d \right)^k
\prod_{j=1}^d\mathbf{1}_{\lceil2^{k_j}x_j\rceil=\lceil2^{k_j}z_j\rceil}, \\
&amp; \text{ for all } \mathbf{x},\mathbf{z}\in[0,1]^d.
\end{align}
&lt;/math&gt;

==== Uniform KeRF ====
Uniform KeRF is built in the same way as uniform forest, except that predictions are made by &lt;math&gt;\tilde{m}_{M,n}(\mathbf{x}, \Theta_1,\ldots,\Theta_M) &lt;/math&gt;, the corresponding kernel function, or connection function is
:&lt;math&gt;K_k^{uf}(\mathbf{0},\mathbf{x}) =
\sum_{k_1,\ldots,k_d, \sum_{j=1}^d k_j=k}
\frac{k!}{k_1!\ldots k_d!}\left(\frac{1}{d}\right)^k
\prod_{m=1}^d\left(1-|x_m|\sum_{j=0}^{k_m-1}\frac{(-\ln|x_m|)^j}{j!}\right) \text{ for all } \mathbf{x}\in[0,1]^d.&lt;/math&gt;

=== Properties ===
==== Relation between KeRF and random forest ====
Predictions given by KeRF and random forests are close if the number of points in each cell is controlled:

&lt;blockquote&gt;
Assume that there exist sequences &lt;math&gt; (a_n),(b_n) &lt;/math&gt; such that, almost surely,
: &lt;math&gt; a_n\leq N_n(\mathbf{x},\Theta)\leq b_n \text{ and } a_n\leq \frac 1 M \sum_{m=1}^M N_n {\mathbf{x},\Theta_m}\leq b_n.
&lt;/math&gt;
Then almost surely,
:&lt;math&gt;|m_{M,n}(\mathbf{x}) - \tilde{m}_{M,n}(\mathbf{x})| \le\frac{b_n-a_n}{a_n} \tilde{m}_{M,n}(\mathbf{x}).
&lt;/math&gt;
&lt;/blockquote&gt;

==== Relation between infinite KeRF and infinite random forest ====
When the number of trees &lt;math&gt;M&lt;/math&gt; goes to infinity, then we have infinite random forest and infinite KeRF. Their estimates are close if the number of observations in each cell is bounded:

&lt;blockquote&gt;
Assume that there exist sequences &lt;math&gt;(\varepsilon_n), (a_n),(b_n)&lt;/math&gt; such that, almost surely
* &lt;math&gt;\operatorname{E}[N_n(\mathbf{x},\Theta)] \ge 1,&lt;/math&gt;
* &lt;math&gt;\operatorname{P}[a_n\le N_n(\mathbf{x},\Theta) \le b_n\mid \mathcal{D}_n] \ge 1-\varepsilon_n/2,&lt;/math&gt;
* &lt;math&gt;\operatorname{P}[a_n\le \operatorname{E}_\Theta [N_n(\mathbf{x},\Theta)] \le b_n\mid \mathcal{D}_n] \ge 1-\varepsilon_n/2,&lt;/math&gt;
Then almost surely,
: &lt;math&gt; |m_{\infty,n}(\mathbf{x})-\tilde{m}_{\infty,n}(\mathbf{x})| \le
\frac{b_n-a_n}{a_n}\tilde{m}_{\infty,n}(\mathbf{x}) + n \varepsilon_n \left( \max_{1\le i\le n} Y_i \right).&lt;/math&gt;
&lt;/blockquote&gt;

=== Consistency results ===
Assume that &lt;math&gt;Y = m(\mathbf{X}) + \varepsilon&lt;/math&gt;, where &lt;math&gt;\varepsilon&lt;/math&gt; is a centered Gaussian noise, independent of &lt;math&gt;\mathbf{X}&lt;/math&gt;, with finite variance &lt;math&gt;\sigma^2&lt;\infty&lt;/math&gt;. Moreover, &lt;math&gt;\mathbf{X}&lt;/math&gt; is uniformly distributed on &lt;math&gt;[0,1]^d&lt;/math&gt; and &lt;math&gt;m&lt;/math&gt; is [[Lipschitz]]. Scornet&lt;ref name="scornet2015random"/&gt; proved upper bounds on the rates of consistency for centered KeRF and uniform KeRF.

==== Consistency of centered KeRF ====
Providing &lt;math&gt;k\rightarrow\infty&lt;/math&gt; and &lt;math&gt;n/2^k\rightarrow\infty&lt;/math&gt;, there exists a constant &lt;math&gt;C_1&gt;0&lt;/math&gt; such that, for all &lt;math&gt;n&lt;/math&gt;,
&lt;math&gt; \mathbb{E}[\tilde{m}_n^{cc}(\mathbf{X}) - m(\mathbf{X})]^2 \le C_1 n^{-1/(3+d\log 2)}(\log n)^2&lt;/math&gt;.

==== Consistency of uniform KeRF ====
Providing &lt;math&gt;k\rightarrow\infty&lt;/math&gt; and &lt;math&gt;n/2^k\rightarrow\infty&lt;/math&gt;, there exists a constant &lt;math&gt;C&gt;0&lt;/math&gt; such that,
&lt;math&gt;\mathbb{E}[\tilde{m}_n^{uf}(\mathbf{X})-m(\mathbf{X})]^2\le Cn^{-2/(6+3d\log2)}(\log n)^2&lt;/math&gt;.

== Disadvantages ==
While random forests often achieve higher accuracy than a single decision tree, they sacrifice the intrinsic interpretability present in decision trees. Decision trees are among a fairly small family of machine learning models that are easily interpretable along with linear models, rule-based models, and attention-based models. This interpretability is one of the most desirable qualities of decision trees. It allows developers to confirm that the model has learned realistic information from the data and allows end-users to have trust and confidence in the decisions made by the model. For example, following the path that a decision tree takes to make its decision is quite trivial, but following the paths of 100's of trees is much harder. To achieve both performance and interpretability, some model compression techniques allow transforming a random forest into a minimal "born-again" decision tree that faithfully reproduces the same decision function.&lt;ref&gt;{{Cite journal|last=Vidal|first=Thibaut|last2=Schiffer|first2=Maximilian|date=2020|title=Born-Again Tree Ensembles|url=http://proceedings.mlr.press/v119/vidal20a.html|journal=International Conference on Machine Learning|language=en|publisher=PMLR|volume=119|pages=9743–9753}}&lt;/ref&gt;

== See also ==
*[[Boosting (machine learning)|Boosting]]
*[[Decision tree learning]]
*[[Ensemble learning]]
*[[Gradient boosting]]
*[[Non-parametric statistics]]
*[[Randomized algorithm]]

== References ==
{{Reflist|32em}}

== Further reading ==
{{Scholia|topic}}
{{refbegin}}
* {{cite conference |doi = 10.1007/978-3-540-74469-6_35 |chapter = Random Multiclass Classification: Generalizing Random Forests to Random MNL and Random NB |chapter-url = https://www.researchgate.net/publication/225175169 |title = Database and Expert Systems Applications |series = [[Lecture Notes in Computer Science]] |year = 2007 |last1 = Prinzie |first1 = Anita |last2 = Poel |first2 = Dirk | name-list-style = vanc |isbn = 978-3-540-74467-2 |volume = 4653 |pages = 349}}
* {{cite journal | vauthors = Denisko D, Hoffman MM | title = Classification and interaction in random forests | journal = Proceedings of the National Academy of Sciences of the United States of America | volume = 115 | issue = 8 | pages = 1690–1692 | date = February 2018 | pmid = 29440440 | doi = 10.1073/pnas.1800256115 | pmc=5828645}}
{{refend}}

== External links ==
* [https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm Random Forests classifier description] (Leo Breiman's site)
* [https://cran.r-project.org/doc/Rnews/Rnews_2002-3.pdf Liaw, Andy &amp; Wiener, Matthew "Classification and Regression by randomForest" R News (2002) Vol. 2/3 p. 18] (Discussion of the use of the random forest package for [[R programming language|R]])

[[Category:Classification algorithms]]
[[Category:Ensemble learning]]
[[Category:Decision trees]]
[[Category:Decision theory]]
[[Category:Computational statistics]]
[[Category:Machine learning]]</text>
      <sha1>1pm2imzwvhsnbfdi8742w9sb1vw6j9y</sha1>
    </revision>
  </page>
  <page>
    <title>Algorithmic bias</title>
    <ns>0</ns>
    <id>55817338</id>
    <revision>
      <id>1003423820</id>
      <parentid>1003423645</parentid>
      <timestamp>2021-01-28T22:42:00Z</timestamp>
      <contributor>
        <username>Encodejustice</username>
        <id>41062706</id>
      </contributor>
      <comment>/* Law enforcement and legal proceedings */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="101367" xml:space="preserve">{{short description|Technological phenomenon with social implications}}
{{good article}}
{{Artificial intelligence}}
[[File:02-Sandvig-Seeing-the-Sort-2014-WEB.png|thumb|A flow chart showing the decisions made by a [[recommendation engine]], circa 2001.&lt;ref&gt;{{Cite web|url=https://worldwide.espacenet.com/publicationDetails/biblio?CC=us&amp;NR=7113917&amp;KC=&amp;FT=E&amp;locale=en_EP|title=Patent #US2001021914|last=Jacobi|first=Jennifer|date=13 September 2001|website=Espacenet|access-date=4 July 2018}}&lt;/ref&gt;]]
'''Algorithmic bias''' describes systematic and repeatable errors in a computer system that create unfair outcomes, such as privileging one arbitrary group of users over others. Bias can emerge due to many factors, including but not limited to the design of the algorithm or the unintended or unanticipated use or decisions relating to the way data is coded, collected, selected or used to train the algorithm. Algorithmic bias is found across platforms, including but not limited to [[Search engine bias|search engine results]] and social media platforms, and can have impacts ranging from inadvertent privacy violations to reinforcing [[Bias|social biases]] of race, gender, sexuality, and ethnicity. The study of algorithmic bias is most concerned with algorithms that reflect "systematic and unfair" discrimination. This bias has only recently been addressed in legal frameworks, such as the 2018 European Union's [[General Data Protection Regulation]]. More comprehensive regulation is needed as emerging technologies become increasingly advanced and opaque.

As algorithms expand their ability to organize society, politics, institutions, and behavior, sociologists have become concerned with the ways in which unanticipated output and manipulation of data can impact the physical world. Because algorithms are often considered to be neutral and unbiased, they can inaccurately project greater authority than human expertise, and in some cases, reliance on algorithms can displace human responsibility for their outcomes. Bias can enter into algorithmic systems as a result of pre-existing cultural, social, or institutional expectations; because of technical limitations of their design; or by being used in unanticipated contexts or by audiences who are not considered in the software's initial design.

Algorithmic bias has been cited in cases ranging from election outcomes to the spread of [[online hate speech]]. It has also arisen in criminal justice, healthcare, and hiring, compounding existing racial, economic, and gender biases. The relative inability of facial recognition technology to accurately identify darker-skinned faces has been linked to multiple wrongful arrests of black men, an issue stemming from imbalanced datasets. Problems in understanding, researching, and discovering algorithmic bias persist due to the proprietary nature of algorithms, which are typically treated as trade secrets. Even when full transparency is provided, the complexity of certain algorithms poses a barrier to understanding their functioning. Furthermore, algorithms may change, or respond to input or output in ways that cannot be anticipated or easily reproduced for analysis. In many cases, even within a single website or application, there is no single "algorithm" to examine, but a network of many interrelated programs and data inputs, even between users of the same service.

== Definitions ==
[[File:A computer program for evaluating forestry opportunities under three investment criteria (1969) (20385500690).jpg|thumb|A 1969 diagram for how a simple computer program makes decisions, illustrating a very simple algorithm.]]
Algorithms are [[Algorithm characterizations|difficult to define]],&lt;ref name="Striphas"&gt;{{cite web|url=http://culturedigitally.org/2012/02/what-is-an-algorithm/|title=What is an Algorithm? – Culture Digitally|last1=Striphas|first1=Ted|website=culturedigitally.org|access-date=20 November 2017}}&lt;/ref&gt; but may be generally understood as lists of instructions that determine how programs read, collect, process, and analyze [[data]] to generate output.&lt;ref name="Cormen"&gt;{{cite book|title=Introduction to algorithms|url=https://archive.org/details/introductiontoal00corm_805|url-access=limited|last1=Cormen|first1=Thomas H.|last2=Leiserson|first2=Charles E.|last3=Rivest|first3=Ronald L.|last4=Stein|first4=Clifford|date=2009|publisher=MIT Press|isbn=978-0-262-03384-8|edition=3rd|location=Cambridge, Mass.|page=[https://archive.org/details/introductiontoal00corm_805/page/n25 5]}}&lt;/ref&gt;{{rp|13}} For a rigorous technical introduction, see [[Algorithm]]s. Advances in computer hardware have led to an increased ability to process, store and transmit data. This has in turn boosted the design and adoption of technologies such as [[machine learning]] and [[artificial intelligence]].&lt;ref name="Kitchen"&gt;{{cite journal|last1=Kitchin|first1=Rob|title=Thinking critically about and researching algorithms|journal=Information, Communication &amp; Society|date=25 February 2016|volume=20|issue=1|pages=14–29|doi=10.1080/1369118X.2016.1154087|s2cid=13798875|url=http://futuredata.stanford.edu/classes/cs345s/handouts/kitchin.pdf|access-date=19 November 2017}}&lt;/ref&gt;{{rp|14–15}} By analyzing and processing data, algorithms are the backbone of search engines,&lt;ref name="GoogleAlgorithms"&gt;{{cite web|author=Google|title=How Google Search Works|url=https://www.google.com/search/howsearchworks/algorithms/|access-date=19 November 2017}}&lt;/ref&gt; social media websites,&lt;ref name="Luckerson"&gt;{{cite web|last1=Luckerson|first1=Victor|title=Here's How Your Facebook News Feed Actually Works|url=http://time.com/collection-post/3950525/facebook-news-feed-algorithm/|website=TIME.com|access-date=19 November 2017}}&lt;/ref&gt; recommendation engines,&lt;ref name="Vanderbilt"&gt;{{Cite journal|last1=Vanderbilt|first1=Tom|title=The Science Behind the Netflix Algorithms That Decide What You'll Watch Next|url=https://www.wired.com/2013/08/qq_netflix-algorithm/|journal=Wired|access-date=19 November 2017|date=2013-08-07}}&lt;/ref&gt; online retail,&lt;ref name="AngwinMattu"&gt;{{cite web|last1=Angwin|first1=Julia|last2=Mattu|first2=Surya|title=Amazon Says It Puts Customers First. But Its Pricing Algorithm Doesn't — ProPublica|url=https://www.propublica.org/article/amazon-says-it-puts-customers-first-but-its-pricing-algorithm-doesnt|website=ProPublica|access-date=19 November 2017|date=20 September 2016}}&lt;/ref&gt; online advertising,&lt;ref name="Livingstone"&gt;{{cite web|last1=Livingstone|first1=Rob|title=The future of online advertising is big data and algorithms|url=http://theconversation.com/the-future-of-online-advertising-is-big-data-and-algorithms-69297|website=The Conversation|access-date=19 November 2017}}&lt;/ref&gt; and more.&lt;ref name="Hickman"&gt;{{Cite news|last1=Hickman|first1=Leo|title=How algorithms rule the world|url=https://www.theguardian.com/science/2013/jul/01/how-algorithms-rule-world-nsa|newspaper=The Guardian|access-date=19 November 2017|date=1 July 2013}}&lt;/ref&gt;

Contemporary [[Social science|social scientists]] are concerned with algorithmic processes embedded into hardware and software applications because of their political and social impact, and question the underlying assumptions of an algorithm's neutrality.&lt;ref name="Seaver"&gt;{{cite web|url=https://static1.squarespace.com/static/55eb004ee4b0518639d59d9b/t/55ece1bfe4b030b2e8302e1e/1441587647177/seaverMiT8.pdf|title=Knowing Algorithms|last1=Seaver|first1=Nick|publisher=Media in Transition 8, Cambridge, MA, April 2013|access-date=18 November 2017}}&lt;/ref&gt;{{rp|2}}&lt;ref name="Graham"&gt;{{cite journal|last1=Graham|first1=Stephen D.N.|title=Software-sorted geographies|journal=Progress in Human Geography|date=July 2016|volume=29|issue=5|pages=562–580|doi=10.1191/0309132505ph568oa|s2cid=19119278|url=http://dro.dur.ac.uk/194/1/194.pdf|type=Submitted manuscript}}&lt;/ref&gt;{{rp|563}}&lt;ref name="Tewell"&gt;{{cite journal|last1=Tewell|first1=Eamon|date=4 April 2016|title=Toward the Resistant Reading of Information: Google, Resistant Spectatorship, and Critical Information Literacy|url=http://muse.jhu.edu/article/613843|journal=Portal: Libraries and the Academy|volume=16|issue=2|pages=289–310|issn=1530-7131|access-date=19 November 2017|doi=10.1353/pla.2016.0017|s2cid=55749077}}&lt;/ref&gt;{{rp|294}}&lt;ref&gt;{{Cite web|url=https://hbr.org/2013/04/the-hidden-biases-in-big-data|title=The Hidden Biases in Big Data|last=Crawford|first=Kate|date=1 April 2013|website=Harvard Business Review}}&lt;/ref&gt; The term ''algorithmic bias'' describes systematic and repeatable errors that create unfair outcomes, such as privileging one arbitrary group of users over others. For example, a [[credit score]] algorithm may deny a loan without being unfair, if it is consistently weighing relevant financial criteria. If the algorithm recommends loans to one group of users, but denies loans to another set of nearly identical users based on unrelated criteria, and if this behavior can be repeated across multiple occurrences, an algorithm can be described as ''biased''.&lt;ref name="FriedmanNissenbaum" /&gt;{{rp|332}} This bias may be intentional or unintentional (for example, it can come from biased data obtained from a worker that previously did the job the algorithm is going to do from now on).

== Methods ==
Bias can be introduced to an algorithm in several ways. During the assemblage of a dataset, data may be collected, digitized, adapted, and entered into a [[database]] according to human-designed [[cataloging]] criteria.&lt;ref name="Gillespie et al"&gt;{{cite book|title=Media Technologies|last1=Gillespie|first1=Tarleton|last2=Boczkowski|first2=Pablo|last3=Foot|first3=Kristin|publisher=MIT Press|year=2014|isbn=9780262525374|location=Cambridge|pages=1–30 }}&lt;/ref&gt;{{rp|3}} Next, programmers assign priorities, or [[Hierarchy|hierarchies]], for how a program assesses and sorts that data. This requires human decisions about how data is categorized, and which data is included or discarded.&lt;ref name="Gillespie et al" /&gt;{{rp|4}} Some algorithms collect their own data based on human-selected criteria, which can also reflect the bias of human designers.&lt;ref name="Gillespie et al" /&gt;{{rp|8}} Other algorithms may reinforce stereotypes and preferences as they process and display "relevant" data for human users, for example, by selecting information based on previous choices of a similar user or group of users.&lt;ref name="Gillespie et al" /&gt;{{rp|6}}

Beyond assembling and processing data, bias can emerge as a result of design.&lt;ref name="TowCenter"&gt;{{cite web|last1=Diakopoulos|first1=Nicholas|title=Algorithmic Accountability: On the Investigation of Black Boxes {{!}}|url=https://towcenter.org/research/algorithmic-accountability-on-the-investigation-of-black-boxes-2/|website=towcenter.org|access-date=19 November 2017}}&lt;/ref&gt; For example, algorithms that determine the allocation of resources or scrutiny (such as determining school placements) may inadvertently discriminate against a category when determining risk based on similar users (as in credit scores).&lt;ref name="Lipartito"&gt;{{cite document|last1=Lipartito|first1=Kenneth|title=The Narrative and the Algorithm: Genres of Credit Reporting from the Nineteenth Century to Today|date=6 January 2011|doi=10.2139/ssrn.1736283|s2cid=166742927|url=https://mpra.ub.uni-muenchen.de/28142/1/MPRA_paper_28142.pdf|type=Submitted manuscript}}&lt;/ref&gt;{{rp|36}} Meanwhile, recommendation engines that work by associating users with similar users, or that make use of inferred marketing traits, might rely on inaccurate associations that reflect broad ethnic, gender, socio-economic, or racial stereotypes. Another example comes from determining criteria for what is included and excluded from results. This criteria could present unanticipated outcomes for search results, such as with flight-recommendation software that omits flights that do not follow the sponsoring airline's flight paths.&lt;ref name="TowCenter" /&gt; Algorithms may also display an ''uncertainty bias'', offering more confident assessments when larger [[data set]]s are available. This can skew algorithmic processes toward results that more closely correspond with larger samples, which may disregard data from underrepresented populations.&lt;ref name="GoodmanFlaxman2016"&gt;{{Cite journal|last1=Goodman|first1=Bryce|last2=Flaxman|first2=Seth|title=EU regulations on algorithmic decision-making and a "right to explanation"|journal=AI Magazine|volume=38|issue=3|pages=50|arxiv=1606.08813|doi=10.1609/aimag.v38i3.2741|year=2017|s2cid=7373959}}&lt;/ref&gt;{{rp|4}}

== History ==

=== Early critiques ===
[[File:Used Punchcard (5151286161).jpg|thumb|This card was used to load software into an old mainframe computer. Each byte (the letter 'A', for example) is entered by punching holes. Though contemporary computers are more complex, they reflect this human decision-making process in collecting and processing data.&lt;ref name="Weizenbaum1976" /&gt;{{rp|70}}&lt;ref name="Goffrey" /&gt;{{rp|16}}]]
The earliest computer programs were designed to mimic human reasoning and deductions, and were deemed to be functioning when they successfully and consistently reproduced that human logic. In his 1976 book ''[[Computer Power and Human Reason]]'', [[Artificial intelligence|Artificial Intelligence]] pioneer [[Joseph Weizenbaum]] suggested that bias could arise both from the data used in a program, but also from the way a program is coded.&lt;ref name="Weizenbaum1976" /&gt;{{rp|149}}

Weizenbaum wrote that [[Computer program|programs]] are a sequence of rules created by humans for a computer to follow. By following those rules consistently, such programs "embody law",&lt;ref name="Weizenbaum1976"&gt;{{cite book|last1=Weizenbaum|first1=Joseph|title=Computer power and human reason : from judgment to calculation|url=https://archive.org/details/computerpowerhum0000weiz|url-access=registration|date=1976|publisher=W.H. Freeman|location=San Francisco|isbn=978-0-7167-0464-5}}&lt;/ref&gt;{{rp|40}} that is, enforce a specific way to solve problems. The rules a computer follows are based on the assumptions of a computer programmer for how these problems might be solved. That means the code could incorporate the programmer's imagination of how the world works, including his or her biases and expectations.&lt;ref name="Weizenbaum1976" /&gt;{{rp|109}} While a computer program can incorporate bias in this way, Weizenbaum also noted that any data fed to a machine additionally reflects "human decisionmaking processes" as data is being selected.&lt;ref name="Weizenbaum1976" /&gt;{{rp|70, 105}}

Finally, he noted that machines might also transfer good information with [[unintended consequence]]s if users are unclear about how to interpret the results.&lt;ref name="Weizenbaum1976" /&gt;{{rp|65}} Weizenbaum warned against trusting decisions made by computer programs that a user doesn't understand, comparing such faith to a tourist who can find his way to a hotel room exclusively by turning left or right on a coin toss. Crucially, the tourist has no basis of understanding how or why he arrived at his destination, and a successful arrival does not mean the process is accurate or reliable.&lt;ref name="Weizenbaum1976" /&gt;{{rp|226}}

An early example of algorithmic bias resulted in as many as 60 women and ethnic minorities denied entry to [[St George's, University of London|St. George's Hospital Medical School]] per year from 1982 to 1986, based on implementation of a new computer-guidance assessment system that denied entry to women and men with "foreign-sounding names" based on historical trends in admissions.&lt;ref name="LowryMacpherson"&gt;{{cite journal|last1=Lowry|first1=Stella|last2=Macpherson|first2=Gordon|date=5 March 1988|title=A Blot on the Profession|url=http://europepmc.org/backend/ptpmcrender.fcgi?accid=PMC2545288&amp;blobtype=pdf|journal=British Medical Journal|volume=296|issue=6623|pages=657–8|access-date=17 November 2017|pmid=3128356|pmc=2545288|doi=10.1136/bmj.296.6623.657}}&lt;/ref&gt; While many schools at the time employed similar biases in their selection process, St. George was most notable for automating said bias through the use of an algorithm, thus gaining the attention of people on a much wider scale.

=== Contemporary critiques and responses ===
Though well-designed algorithms frequently determine outcomes that are equally (or more) equitable than the decisions of human beings, cases of bias still occur, and are difficult to predict and analyze.&lt;ref name="Miller"&gt;{{cite web |last1=Miller |first1=Alex P. |title=Want Less-Biased Decisions? Use Algorithms |url=https://hbr.org/2018/07/want-less-biased-decisions-use-algorithms |website=Harvard Business Review |access-date=31 July 2018 |date=26 July 2018}}&lt;/ref&gt; The complexity of analyzing algorithmic bias has grown alongside the complexity of programs and their design. Decisions made by one designer, or team of designers, may be obscured among the many pieces of code created for a single program; over time these decisions and their collective impact on the program's output may be forgotten.&lt;ref name="Introna1"&gt;{{cite journal|last1=Introna|first1=Lucas D.|s2cid=145190381|date=2 December 2011|title=The Enframing of Code|journal=Theory, Culture &amp; Society|volume=28|issue=6|pages=113–141|doi=10.1177/0263276411418131}}&lt;/ref&gt;{{rp|115}} In theory, these biases may create new patterns of behavior, or "scripts", in relationship to specific technologies as the code [[Cybernetics|interacts]] with other elements of society.&lt;ref name="Bogost"&gt;{{cite web|url=https://www.theatlantic.com/technology/archive/2015/01/the-cathedral-of-computation/384300/|title=The Cathedral of Computation|last1=Bogost|first1=Ian|website=The Atlantic|access-date=19 November 2017|date=2015-01-15}}&lt;/ref&gt; Biases may also impact how society shapes itself around the [[data point]]s that algorithms require. For example, if data shows a high number of arrests in a particular area, an algorithm may assign more police patrols to that area, which could lead to more arrests.&lt;ref name="IntronaWood"&gt;{{cite journal|last1=Introna|first1=Lucas|last2=Wood|first2=David|date=2004|title=Picturing algorithmic surveillance: the politics of facial recognition systems|url=http://nbn-resolving.de/urn:nbn:de:0168-ssoar-200675|journal=Surveillance &amp; Society|volume=2|pages=177–198|access-date=19 November 2017}}&lt;/ref&gt;{{rp|180}}

The decisions of algorithmic programs can be seen as more authoritative than the decisions of the human beings they are meant to assist,&lt;ref name="Introna2"&gt;{{cite journal|last1=Introna|first1=Lucas D.|date=21 December 2006|title=Maintaining the reversibility of foldings: Making the ethics (politics) of information technology visible|journal=Ethics and Information Technology|volume=9|issue=1|pages=11–25|doi=10.1007/s10676-006-9133-z|citeseerx=10.1.1.154.1313|s2cid=17355392}}&lt;/ref&gt;{{rp|15}} a process described by author [[Clay Shirky]] as "algorithmic authority".&lt;ref name="ShirkyAuthority"&gt;{{cite web|url=http://www.shirky.com/weblog/2009/11/a-speculative-post-on-the-idea-of-algorithmic-authority/|title=A Speculative Post on the Idea of Algorithmic Authority Clay Shirky|last1=Shirky|first1=Clay|website=www.shirky.com|access-date=20 November 2017}}&lt;/ref&gt; Shirky uses the term to describe "the decision to regard as authoritative an unmanaged process of extracting value from diverse, untrustworthy sources", such as search results.&lt;ref name="ShirkyAuthority" /&gt; This neutrality can also be misrepresented by the language used by experts and the media when results are presented to the public. For example, a list of news items selected and presented as "trending" or "popular" may be created based on significantly wider criteria than just their popularity.&lt;ref name="Gillespie et al" /&gt;{{rp|14}}

Because of their convenience and authority, algorithms are theorized as a means of delegating responsibility away from humans.&lt;ref name="Introna2" /&gt;{{rp|16}}&lt;ref name="Ziewitz1"&gt;{{cite journal|last1=Ziewitz|first1=Malte|title=Governing Algorithms: Myth, Mess, and Methods|journal=Science, Technology, &amp; Human Values|date=1 January 2016|volume=41|issue=1|pages=3–16|doi=10.1177/0162243915608948|s2cid=148023125|issn=0162-2439|url=http://revistas.ucm.es/index.php/ESMP/article/view/58040}}&lt;/ref&gt;{{rp|6}} This can have the effect of reducing alternative options, compromises, or flexibility.&lt;ref name="Introna2" /&gt;{{rp|16}} Sociologist [[Scott Lash]] has critiqued algorithms as a new form of "generative power", in that they are a virtual means of generating actual ends. Where previously human behavior generated data to be collected and studied, powerful algorithms increasingly could shape and define human behaviors.&lt;ref name="Lash"&gt;{{cite journal|last1=Lash|first1=Scott|date=30 June 2016|title=Power after Hegemony|journal=Theory, Culture &amp; Society|volume=24|issue=3|pages=55–78|doi=10.1177/0263276407075956|s2cid=145639801}}&lt;/ref&gt;{{rp|71}}

Concerns over the impact of algorithms on society have led to the creation of working groups in organizations such as [[Google]] and [[Microsoft]], which have co-created a working group named Fairness, Accountability,
and Transparency in Machine Learning.&lt;ref name="Garcia"&gt;{{cite journal |last1=Garcia |first1=Megan |title=Racist in the Machine |journal=World Policy Journal |date=1 January 2016 |volume=33 |issue=4 |pages=111–117 |doi=10.1215/07402775-3813015 |s2cid=151595343 }}&lt;/ref&gt;{{rp|115}} Ideas from Google have included community groups that patrol the outcomes of algorithms and vote to control or restrict outputs they deem to have negative consequences.&lt;ref name="Garcia" /&gt;{{rp|117}} In recent years, the study of the Fairness, Accountability,
and Transparency (FAT) of algorithms has emerged as its own interdisciplinary research area with an annual conference called FAT*.&lt;ref&gt;{{Cite web|url=https://fatconference.org/2018/press_release.html|title=ACM FAT* - 2018 Information for Press|website=fatconference.org|access-date=2019-02-26}}&lt;/ref&gt; Critics have suggested that FAT initiatives cannot serve effectively as independent watchdogs when many are funded by corporations building the systems being studied.&lt;ref name="Ochigame"&gt;{{cite web |last1=Ochigame |first1=Rodrigo |title=The Invention of "Ethical AI": How Big Tech Manipulates Academia to Avoid Regulation |url=https://theintercept.com/2019/12/20/mit-ethical-ai-artificial-intelligence/ |website=The Intercept |access-date=11 February 2020 |date=20 December 2019}}&lt;/ref&gt;

== Types ==

=== Pre-existing ===
Pre-existing bias in an algorithm is a consequence of underlying social and institutional [[Ideology|ideologies]]. Such ideas may influence or create personal biases within individual designers or programmers. Such prejudices can be explicit and conscious, or implicit and unconscious.&lt;ref name="FriedmanNissenbaum" /&gt;{{rp|334}}&lt;ref name="Tewell" /&gt;{{rp|294}} Poorly selected input data, or simply data from a biased source, will influence the outcomes created by machines.&lt;ref name="Goffrey"&gt;{{cite book|last1=Goffrey|first1=Andrew|editor1-last=Fuller|editor1-first=Matthew|title=Software studies: a lexicon|url=https://archive.org/details/softwarestudiesl00full_007|url-access=limited|date=2008|publisher=MIT Press|location=Cambridge, Mass.|isbn=978-1-4356-4787-9|pages=[https://archive.org/details/softwarestudiesl00full_007/page/n29 15]–20|chapter=Algorithm}}&lt;/ref&gt;{{rp|17}} Encoding pre-existing bias into software can preserve social and institutional bias, and, without correction, could be replicated in all future uses of that algorithm.&lt;ref name="Introna1" /&gt;{{rp|116}}&lt;ref name="Ziewitz1" /&gt;{{rp|8}}

An example of this form of bias is the British Nationality Act Program, designed to automate the evaluation of new British citizens after the 1981 [[British Nationality Act]].&lt;ref name="FriedmanNissenbaum" /&gt;{{rp|341}} The program accurately reflected the tenets of the law, which stated that "a man is the father of only his legitimate children, whereas a woman is the mother of all her children, legitimate or not."&lt;ref name="FriedmanNissenbaum" /&gt;{{rp|341}}&lt;ref name="SergotEtAl"&gt;{{cite journal|last1=Sergot|first1=MJ|last2=Sadri|first2=F|last3=Kowalski|first3=RA|last4=Kriwaczek|first4=F|last5=Hammond|first5=P|last6=Cory|first6=HT|title=The British Nationality Act as a Logic Program|journal=Communications of the ACM|date=May 1986|volume=29|issue=5|pages=370–386|url=https://web.stanford.edu/class/cs227/Readings/BritishNationalityAct.pdf|access-date=18 November 2017|doi=10.1145/5689.5920|s2cid=5665107}}&lt;/ref&gt;{{rp|375}} In its attempt to transfer a particular logic into an algorithmic process, the BNAP inscribed the logic of the British Nationality Act into its algorithm, which would perpetuate it even if the act was eventually repealed.&lt;ref name="FriedmanNissenbaum" /&gt;{{rp|342}}

=== Technical ===
[[File:Three Surveillance cameras.jpg|thumb|Facial recognition software used in conjunction with surveillance cameras was found to display bias in recognizing Asian and black faces over white faces.&lt;ref name="IntronaWood" /&gt;{{rp|191}}]]
Technical bias emerges through limitations of a program, computational power, its design, or other constraint on the system.&lt;ref name="FriedmanNissenbaum" /&gt;{{rp|332}} Such bias can also be a restraint of design, for example, a search engine that shows three results per screen can be understood to privilege the top three results slightly more than the next three, as in an airline price display.&lt;ref name="FriedmanNissenbaum" /&gt;{{rp|336}} Another case is software that relies on [[randomness]] for fair distributions of results. If the [[random number generation]] mechanism is not truly random, it can introduce bias, for example, by skewing selections toward items at the end or beginning of a list.&lt;ref name="FriedmanNissenbaum" /&gt;{{rp|332}}

A ''decontextualized algorithm'' uses unrelated information to sort results, for example, a flight-pricing algorithm that sorts results by alphabetical order would be biased in favor of American Airlines over United Airlines.&lt;ref name="FriedmanNissenbaum" /&gt;{{rp|332}} The opposite may also apply, in which results are evaluated in contexts different from which they are collected. Data may be collected without crucial external context: for example, when [[facial recognition system|facial recognition]] software is used by surveillance cameras, but evaluated by remote staff in another country or region, or evaluated by non-human algorithms with no awareness of what takes place beyond the camera's [[Visual field|field of vision]]. This could create an incomplete understanding of a crime scene, for example, potentially mistaking bystanders for those who commit the crime.&lt;ref name="Graham" /&gt;{{rp|574}}

Lastly, technical bias can be created by attempting to formalize decisions into concrete steps on the assumption that human behavior works in the same way. For example, software weighs data points to determine whether a defendant should accept a plea bargain, while ignoring the impact of emotion on a jury.&lt;ref name="FriedmanNissenbaum" /&gt;{{rp|332}} Another unintended result of this form of bias was found in the plagiarism-detection software [[Turnitin]], which compares student-written texts to information found online and returns a probability score that the student's work is copied. Because the software compares long strings of text, it is more likely to identify non-native speakers of English than native speakers, as the latter group might be better able to change individual words, break up strings of plagiarized text, or obscure copied passages through synonyms. Because it is easier for native speakers to evade detection as a result of the technical constraints of the software, this creates a scenario where Turnitin identifies foreign-speakers of English for plagiarism while allowing more native-speakers to evade detection.&lt;ref name="Introna2" /&gt;{{rp|21–22}}

=== Emergent ===
[[Emergent properties|Emergent]] bias is the result of the use and reliance on algorithms across new or unanticipated contexts.&lt;ref name="FriedmanNissenbaum" /&gt;{{rp|334}} Algorithms may not have been adjusted to consider new forms of knowledge, such as new drugs or medical breakthroughs, new laws, business models, or shifting cultural norms.&lt;ref name="FriedmanNissenbaum" /&gt;{{rp|334,336}} This may exclude groups through technology, without providing clear outlines to understand who is responsible for their exclusion.&lt;ref name="IntronaWood" /&gt;{{rp|179}}&lt;ref name="Tewell" /&gt;{{rp|294}} Similarly, problems may emerge when [[training data]] (the samples "fed" to a machine, by which it models certain conclusions) do not align with contexts that an algorithm encounters in the real world.&lt;ref name="Gillespie"&gt;{{cite web|url=http://culturedigitally.org/2014/06/algorithm-draft-digitalkeyword/|title=Algorithm [draft] [#digitalkeywords] – Culture Digitally|last1=Gillespie|first1=Tarleton|website=culturedigitally.org|access-date=20 November 2017}}&lt;/ref&gt;

In 1990, an example of emergent bias was identified in the software used to place US medical students into residencies, the National Residency Match Program (NRMP).&lt;ref name="FriedmanNissenbaum" /&gt;{{rp|338}} The algorithm was designed at a time when few married couples would seek residencies together. As more women entered medical schools, more students were likely to request a residency alongside their partners. The process called for each applicant to provide a list of preferences for placement across the US, which was then sorted and assigned when a hospital and an applicant both agreed to a match. In the case of married couples where both sought residencies, the algorithm weighed the location choices of the higher-rated partner first. The result was a frequent assignment of highly preferred schools to the first partner and lower-preferred schools to the second partner, rather than sorting for compromises in placement preference.&lt;ref name="FriedmanNissenbaum" /&gt;{{rp|338}}&lt;ref name="Roth"&gt;{{cite journal|last1=Roth|first1=A. E. 1524–1528.|title=New physicians: A natural experiment in market organization|journal=Science|date=14 December 1990|volume=250|issue=4987|pages=1524–1528|url=https://stanford.edu/~alroth/science.html|access-date=18 November 2017|bibcode=1990Sci...250.1524R|doi=10.1126/science.2274783|pmid=2274783|s2cid=23259274}}&lt;/ref&gt;

Additional emergent biases include:

==== Correlations ====
Unpredictable correlations can emerge when large data sets are compared to each other. For example, data collected about web-browsing patterns may align with signals marking sensitive data (such as race or sexual orientation). By selecting according to certain behavior or browsing patterns, the end effect would be almost identical to discrimination through the use of direct race or sexual orientation data.&lt;ref name="GoodmanFlaxman2016" /&gt;{{rp|6}} In other cases, the algorithm draws conclusions from correlations, without being able to understand those correlations. For example, one triage program gave lower priority to asthmatics who had pneumonia than asthmatics who did not have pneumonia. The program algorithm did this because it simply compared survival rates: asthmatics with pneumonia are at the highest risk. Historically, for this same reason, hospitals typically give such asthmatics the best and most immediate care.&lt;ref name="Kuang"&gt;{{cite news|last1=Kuang|first1=Cliff|title=Can A.I. Be Taught to Explain Itself?|url=https://www.nytimes.com/2017/11/21/magazine/can-ai-be-taught-to-explain-itself.html|access-date=26 November 2017|work=The New York Times|date=21 November 2017}}&lt;/ref&gt;

==== Unanticipated uses ====
Emergent bias can occur when an algorithm is used by unanticipated audiences. For example, machines may require that users can read, write, or understand numbers, or relate to an interface using metaphors that they do not understand.&lt;ref name="FriedmanNissenbaum" /&gt;{{rp|334}} These exclusions can become compounded, as biased or exclusionary technology is more deeply integrated into society.&lt;ref name="IntronaWood" /&gt;{{rp|179}}

Apart from exclusion, unanticipated uses may emerge from the end user relying on the software rather than their own knowledge. In one example, an unanticipated user group led to algorithmic bias in the UK, when the British National Act Program was created as a [[Proof of concept|proof-of-concept]] by computer scientists and immigration lawyers to evaluate suitability for [[British nationality law|British citizenship]]. The designers had access to legal expertise beyond the end users in immigration offices, whose understanding of both software and immigration law would likely have been unsophisticated. The agents administering the questions relied entirely on the software, which excluded alternative pathways to citizenship, and used the software even after new case laws and legal interpretations led the algorithm to become outdated. As a result of designing an algorithm for users assumed to be legally savvy on immigration law, the software's algorithm indirectly led to bias in favor of applicants who fit a very narrow set of legal criteria set by the algorithm, rather than by the more broader criteria of British immigration law.&lt;ref name="FriedmanNissenbaum" /&gt;{{rp|342}}

==== Feedback loops ====
Emergent bias may also create a [[feedback loop]], or recursion, if data collected for an algorithm results in real-world responses which are fed back into the algorithm.&lt;ref name="JouvenalPredPol"&gt;{{cite web|last1=Jouvenal|first1=Justin|title=Police are using software to predict crime. Is it a 'holy grail' or biased against minorities?|url=https://www.washingtonpost.com/local/public-safety/police-are-using-software-to-predict-crime-is-it-a-holy-grail-or-biased-against-minorities/2016/11/17/525a6649-0472-440a-aae1-b283aa8e5de8_story.html|website=Washington Post|access-date=25 November 2017|date=17 November 2016}}&lt;/ref&gt;&lt;ref name="Chamma"&gt;{{cite web|last1=Chamma|first1=Maurice|title=Policing the Future|url=https://www.themarshallproject.org/2016/02/03/policing-the-future?ref=hp-2-111#.UyhBLnmlj|website=The Marshall Project|access-date=25 November 2017|date=2016-02-03}}&lt;/ref&gt; For example, simulations of the [[predictive policing]] software (PredPol), deployed in Oakland, California, suggested an increased police presence in black neighborhoods based on crime data reported by the public.&lt;ref name="LumIsaac"&gt;{{cite journal|last1=Lum|first1=Kristian|last2=Isaac|first2=William|title=To predict and serve?|journal=Significance|date=October 2016|volume=13|issue=5|pages=14–19|doi=10.1111/j.1740-9713.2016.00960.x|doi-access=free}}&lt;/ref&gt; The simulation showed that the public reported crime based on the sight of police cars, regardless of what police were doing. The simulation interpreted police car sightings in modeling its predictions of crime, and would in turn assign an even larger increase of police presence within those neighborhoods.&lt;ref name="JouvenalPredPol" /&gt;&lt;ref name="SmithPredPol"&gt;{{cite web|last1=Smith|first1=Jack|title=Predictive policing only amplifies racial bias, study shows|url=https://mic.com/articles/156286/crime-prediction-tool-pred-pol-only-amplifies-racially-biased-policing-study-shows|website=Mic|access-date=25 November 2017}}&lt;/ref&gt;&lt;ref name="LumIsaacFAQ"&gt;{{cite web|last1=Lum|first1=Kristian|last2=Isaac|first2=William|title=FAQs on Predictive Policing and Bias|url=https://hrdag.org/2016/11/04/faqs-predpol/|website=HRDAG|access-date=25 November 2017|date=1 October 2016}}&lt;/ref&gt; The [[Human Rights Data Analysis Group]], which conducted the simulation, warned that in places where racial discrimination is a factor in arrests, such feedback loops could reinforce and perpetuate racial discrimination in policing.&lt;ref name="Chamma" /&gt; Another well known example of such an algorithm exhibiting such behavior is [[COMPAS (software)|COMPAS]], a software that determines an individual's likelihood of becoming a criminal offender. The software is often criticized for labeling Black individuals as criminals much more likely than others, and then feeds the data back into itself in the event indivuals become registered criminals, further enforcing the bias created by the dataset the algorithm is acting on.

Recommender systems such as those used to recommend online videos or news articles can create feedback loops.&lt;ref&gt;{{Cite journal|last1=Sun|first1=Wenlong|last2=Nasraoui|first2=Olfa|last3=Shafto|first3=Patrick|date=2018|title=Iterated Algorithmic Bias in the Interactive Machine Learning Process of Information Filtering|journal=Proceedings of the 10th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management|location=Seville, Spain|publisher=SCITEPRESS - Science and Technology Publications|pages=110–118|doi=10.5220/0006938301100118|isbn=9789897583308|doi-access=free}}&lt;/ref&gt; When users click on content that is suggested by algorithms, it influences the next set of suggestions.&lt;ref&gt;{{Cite journal|last1=Sinha|first1=Ayan|last2=Gleich|first2=David F.|last3=Ramani|first3=Karthik|date=2018-08-09|title=Gauss's law for networks directly reveals community boundaries|journal=Scientific Reports|volume=8|issue=1|pages=11909|doi=10.1038/s41598-018-30401-0|pmid=30093660|pmc=6085300|issn=2045-2322|bibcode=2018NatSR...811909S}}&lt;/ref&gt; Over time this may lead to users entering a [[Filter bubble|Filter Bubble]] and being unaware of important or useful content.&lt;ref&gt;{{Cite web|url=https://qz.com/1194566/google-is-finally-admitting-it-has-a-filter-bubble-problem/|title=Google is finally admitting it has a filter-bubble problem|last1=Hao|first1=Karen|website=Quartz|access-date=2019-02-26}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=http://fortune.com/2017/04/25/facebook-related-articles-filter-bubbles/|title=Facebook Is Testing This New Feature to Fight 'Filter Bubbles'|website=Fortune|access-date=2019-02-26}}&lt;/ref&gt;

== Impact ==

=== Commercial influences ===
Corporate algorithms could be skewed to invisibly favor financial arrangements or agreements between companies, without the knowledge of a user who may mistake the algorithm as being impartial. For example, [[American Airlines]] created a flight-finding algorithm in the 1980s. The software presented a range of flights from various airlines to customers, but weighed factors that boosted its own flights, regardless of price or convenience. In testimony to the [[United States Congress]], the president of the airline stated outright that the system was created with the intention of gaining competitive advantage through preferential treatment.&lt;ref name="Sandvig1" /&gt;{{rp|2}}&lt;ref name="FriedmanNissenbaum"&gt;{{cite journal|last1=Friedman|first1=Batya|last2=Nissenbaum|first2=Helen|title=Bias in Computer Systems|journal=ACM Transactions on Information Systems|date=July 1996|volume=14|issue=3|pages=330–347|url=https://nissenbaum.tech.cornell.edu/papers/biasincomputers.pdf|access-date=10 March 2019|doi=10.1145/230538.230561|s2cid=207195759}}&lt;/ref&gt;{{rp|331}}

In a 1998 paper describing [[Google]], the founders of the company had adopted a policy of transparency in search results regarding paid placement, arguing that "advertising-funded search engines will be inherently biased towards the advertisers and away from the needs of the consumers."&lt;ref name="BrinPage98"&gt;{{cite web|last1=Brin|first1=Sergey|last2=Page|first2=Lawrence|title=The Anatomy of a Search Engine|url=http://www7.scu.edu.au/1921/com1921.htm|website=www7.scu.edu.au|access-date=18 November 2017|archive-url=https://web.archive.org/web/20190702020902/http://www7.scu.edu.au/1921/com1921.htm|archive-date=2 July 2019|url-status=dead}}&lt;/ref&gt; This bias would be an "invisible" manipulation of the user.&lt;ref name="Sandvig1"&gt;{{cite journal|last1=Sandvig|first1=Christian|last2=Hamilton|first2=Kevin|author-link3=Karrie Karahalios|last3=Karahalios|first3=Karrie|last4=Langbort|first4=Cedric|title=Auditing Algorithms: Research Methods for Detecting Discrimination on Internet Platforms|journal=64th Annual Meeting of the International Communication Association|date=22 May 2014|url=http://www-personal.umich.edu/~csandvig/research/Auditing%20Algorithms%20--%20Sandvig%20--%20ICA%202014%20Data%20and%20Discrimination%20Preconference.pdf|access-date=18 November 2017}}&lt;/ref&gt;{{rp|3}}

=== Voting behavior ===
A series of studies about undecided voters in the US and in India found that search engine results were able to shift voting outcomes by about 20%. The researchers concluded that candidates have "no means of competing" if an algorithm, with or without intent, boosted page listings for a rival candidate.&lt;ref name="Epstein"&gt;{{cite journal|last1=Epstein|first1=Robert|last2=Robertson|first2=Ronald E.|title=The search engine manipulation effect (SEME) and its possible impact on the outcomes of elections|journal=Proceedings of the National Academy of Sciences|date=18 August 2015|volume=112|issue=33|pages=E4512–E4521|doi=10.1073/pnas.1419828112|pmid=26243876|bibcode=2015PNAS..112E4512E|pmc=4547273}}&lt;/ref&gt; Facebook users who saw messages related to voting were more likely to vote. A 2010 [[randomized trial]] of Facebook users showed a 20% increase (340,000 votes) among users who saw messages encouraging voting, as well as images of their friends who had voted.&lt;ref name="Bond-etal"&gt;{{cite journal|last1=Bond|first1=Robert M.|last2=Fariss|first2=Christopher J.|last3=Jones|first3=Jason J.|last4=Kramer|first4=Adam D. I.|last5=Marlow|first5=Cameron|last6=Settle|first6=Jaime E.|last7=Fowler|first7=James H.|title=A 61-million-person experiment in social influence and political mobilization|journal=Nature|date=13 September 2012|volume=489|issue=7415|pages=295–8|doi=10.1038/nature11421|pmid=22972300|pmc=3834737|issn=0028-0836|bibcode=2012Natur.489..295B}}&lt;/ref&gt; Legal scholar Jonathan Zittrain has warned that this could create a "digital gerrymandering" effect in elections, "the selective presentation of information by an intermediary to meet its agenda, rather than to serve its users", if intentionally manipulated.&lt;ref name="Zittrain"&gt;{{cite journal|last1=Zittrain|first1=Jonathan|title=Engineering an Election|journal=Harvard Law Review Forum|date=2014|volume=127|pages=335–341|url=http://cdn.harvardlawreview.org/wp-content/uploads/2014/06/vol127_Symposium_Zittrain.pdf|access-date=19 November 2017}}&lt;/ref&gt;{{rp|335}}

=== Gender discrimination ===
In 2016, the professional networking site [[LinkedIn]] was discovered to recommend male variations of women's names in response to search queries. The site did not make similar recommendations in searches for male names. For example, "Andrea" would bring up a prompt asking if users meant "Andrew", but queries for "Andrew" did not ask if users meant to find "Andrea". The company said this was the result of an analysis of users' interactions with the site.&lt;ref name="Day"&gt;{{cite web|last1=Day|first1=Matt|title=How LinkedIn's search engine may reflect a gender bias|url=https://www.seattletimes.com/business/microsoft/how-linkedins-search-engine-may-reflect-a-bias/|website=The Seattle Times|access-date=25 November 2017|date=31 August 2016}}&lt;/ref&gt;

In 2012, the department store franchise [[Target (company)|Target]] was cited for gathering data points to infer when women customers were pregnant, even if they had not announced it, and then sharing that information with marketing partners.&lt;ref name="CrawfordSchultz"&gt;{{cite journal|last1=Crawford|first1=Kate|last2=Schultz|first2=Jason|title=Big Data and Due Process: Toward a Framework to Redress Predictive Privacy Harms|journal=Boston College Law Review|date=2014|volume=55|issue=1|pages=93–128|url=http://lawdigitalcommons.bc.edu/bclr/vol55/iss1/4/|access-date=18 November 2017}}&lt;/ref&gt;{{rp|94}}&lt;ref name="Duhigg"&gt;{{Cite news|last1=Duhigg|first1=Charles|title=How Companies Learn Your Secrets|url=https://www.nytimes.com/2012/02/19/magazine/shopping-habits.html|newspaper=The New York Times|access-date=18 November 2017|date=16 February 2012}}&lt;/ref&gt; Because the data had been predicted, rather than directly observed or reported, the company had no legal obligation to protect the privacy of those customers.&lt;ref name="CrawfordSchultz" /&gt;{{rp|98}}

Web search algorithms have also been accused of bias. Google's results may prioritize pornographic content in search terms related to sexuality, for example, "lesbian". This bias extends to the search engine showing popular but sexualized content in neutral searches. For example, "Top 25 Sexiest Women Athletes" articles displayed as first-page results in searches for "women athletes".&lt;ref name="Noble"&gt;{{cite journal|last1=Noble|first1=Safiya|author-link=Safiya Noble|title=Missed Connections: What Search Engines Say about Women|journal=Bitch Magazine|date=2012|volume=12|issue=4|pages=37–41|url=https://safiyaunoble.files.wordpress.com/2012/03/54_search_engines.pdf}}&lt;/ref&gt;{{rp|31}} In 2017, Google adjusted these results along with others that surfaced [[hate groups]], racist views, child abuse and pornography, and other upsetting and offensive content.&lt;ref name="Guynn2"&gt;{{cite news|last1=Guynn|first1=Jessica|title=Google starts flagging offensive content in search results|url=https://www.usatoday.com/story/tech/news/2017/03/16/google-flags-offensive-content-search-results/99235548/|access-date=19 November 2017|work=USA TODAY|agency=USA Today|date=16 March 2017}}&lt;/ref&gt; Other examples include the display of higher-paying jobs to male applicants on job search websites.&lt;ref name="SimoniteMIT"&gt;{{cite web|url=https://www.technologyreview.com/s/539021/probing-the-dark-side-of-googles-ad-targeting-system/|title=Study Suggests Google's Ad-Targeting System May Discriminate|last1=Simonite|first1=Tom|website=MIT Technology Review|publisher=Massachusetts Institute of Technology|access-date=17 November 2017}}&lt;/ref&gt; Researchers have also identified that machine translation exhibits a strong tendency towards male defaults.&lt;ref&gt;{{Cite arXiv|url=https://arxiv.org/abs/1809.02208|eprint = 1809.02208|last1 = Prates|first1 = Marcelo O. R.|last2 = Avelar|first2 = Pedro H. C.|last3 = Lamb|first3 = Luis|title = Assessing Gender Bias in Machine Translation -- A Case Study with Google Translate|year = 2018|class = cs.CY}}&lt;/ref&gt; In particular, this is observed in fields linked to unbalanced gender distribution, including [[Science, technology, engineering, and mathematics|STEM]] occupations.&lt;ref&gt;{{Cite journal |doi = 10.1007/s00521-019-04144-6|title = Assessing gender bias in machine translation: A case study with Google Translate|journal = Neural Computing and Applications|year = 2019|last1 = Prates|first1 = Marcelo O. R.|last2 = Avelar|first2 = Pedro H.|last3 = Lamb|first3 = Luís C.|volume = 32|issue = 10|pages = 6363–6381|arxiv = 1809.02208|s2cid = 52179151}}&lt;/ref&gt; In fact, current [https://www.theregister.co.uk/2018/09/10/boffins_bash_google_translate_for_sexist_language/ machine translation systems fail to reproduce the real world distribution of female workers].

In 2015, [[Amazon.com]] turned off an AI system it developed to screen job applications when they realized it was biased against women.&lt;ref&gt;{{cite news |last1=Dastin |first1=Jeffrey |title=Amazon scraps secret AI recruiting tool that showed bias against women |url=https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G |work=Reuters |date=October 9, 2018}}&lt;/ref&gt; The recruitment tool excluded applicants who attended all-women's colleges and resumes that included the word "women's."&lt;ref&gt;{{Cite web|last=Vincent|first=James|date=10 October 2018|title=Amazon reportedly scraps internal AI recruiting tool that was biased against women|url=https://www.theverge.com/2018/10/10/17958784/ai-recruiting-tool-bias-amazon-report|website=The Verge}}&lt;/ref&gt; While in the music streaming services, the similar things happened. In 2019, Spotify was discovered that its recommender system algorithm was biased against women artists.&lt;ref&gt;{{Cite web|title=Reflecting on Spotify's Recommender System – SongData|url=https://songdata.ca/2019/10/01/reflecting-on-spotifys-recommender-system/|access-date=2020-08-07|language=en-US}}&lt;/ref&gt; Spotify's song recommendations suggested more male artists over women artists.

=== Racial and ethnic discrimination ===
Algorithms have been criticized as a method for obscuring racial prejudices in decision-making.&lt;ref name="Buolamwini-Gebru"&gt;{{cite journal |last1=Buolamwini |first1=Joy |last2=Gebru |first2=Timnit |title=Buolamwini, Joy and Timnit Gebru. "Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification." FAT (2018). |journal=Proceedings of Machine Learning Research |volume=81 |issue=2018 |pages=1–15 |url=http://proceedings.mlr.press/v81/buolamwini18a.html |access-date=27 September 2020}}&lt;/ref&gt;&lt;ref name="Noble2"&gt;{{cite book |last1=Noble |first1=Safiya Umoja |title=Algorithms of oppression : how search engines reinforce racism |date=20 February 2018 |publisher=NYU Press |location=New York |isbn=978-1479837243}}&lt;/ref&gt;&lt;ref name="Nakamura1"&gt;{{cite book|title=The new media of surveillance|last1=Nakamura|first1=Lisa|date=2009|publisher=Routledge|isbn=978-0-415-56812-8|editor1-last=Magnet|editor1-first=Shoshana|location=London|pages=149–162|editor2-last=Gates|editor2-first=Kelly}}&lt;/ref&gt;{{rp|158}} Because of how certain races and ethnic groups were treated in the past, data can often contain hidden biases. For example, black people are likely to receive longer sentences than white people who committed the same crime.&lt;ref&gt;{{Cite journal|last1=Alexander|first1=Rudolph|last2=Gyamerah|first2=Jacquelyn|date=September 1997|title=Differential Punishing of African Americans and Whites Who Possess Drugs: A Just Policy or a Continuation of the Past?|journal=Journal of Black Studies|volume=28|issue=1|pages=97–111|doi=10.1177/002193479702800106|s2cid=152043501|issn=0021-9347}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Petersilia|first=Joan|date=January 1985|title=Racial Disparities in the Criminal Justice System: A Summary|journal=Crime &amp; Delinquency|volume=31|issue=1|pages=15–34|doi=10.1177/0011128785031001002|s2cid=146588630|issn=0011-1287}}&lt;/ref&gt; This could potentially mean that a system amplifies the original biases in the data.

In 2015, Google apologized when black users complained that an image-identification algorithm in its Photos application identified them as [[Ethnic stereotype|gorillas]].&lt;ref name="Guynn"&gt;{{cite news|last1=Guynn|first1=Jessica|title=Google Photos labeled black people 'gorillas'|url=https://www.usatoday.com/story/tech/2015/07/01/google-apologizes-after-photos-identify-black-people-as-gorillas/29567465/|access-date=18 November 2017|work=USA TODAY|agency=USA Today|publisher=USA Today|date=1 July 2015}}&lt;/ref&gt; In 2010, [[Nikon]] cameras were criticized when image-recognition algorithms consistently asked Asian users if they were blinking.&lt;ref name="Rose"&gt;{{Cite journal|last1=Rose|first1=Adam|title=Are Face-Detection Cameras Racist?|url=http://content.time.com/time/business/article/0,8599,1954643,00.html|journal=Time|access-date=18 November 2017|date=22 January 2010}}&lt;/ref&gt; Such examples are the product of bias in [[biometric data]] sets.&lt;ref name="Guynn" /&gt; Biometric data is drawn from aspects of the body, including racial features either observed or inferred, which can then be transferred into data points.&lt;ref name="Nakamura1" /&gt;{{rp|154}} Speech recognition technology can have different accuracies depending on the user's accent. This may be caused by the a lack of training data for speakers of that accent.&lt;ref&gt;{{Cite web|url=https://www.washingtonpost.com/graphics/2018/business/alexa-does-not-understand-your-accent/|title=Alexa does not understand your accent|website=Washington Post}}&lt;/ref&gt;

Biometric data about race may also be inferred, rather than observed. For example, a 2012 study showed that names commonly associated with blacks were more likely to yield search results implying arrest records, regardless of whether there is any police record of that individual's name.&lt;ref name="Sweeney"&gt;{{cite journal|last1=Sweeney|first1=Latanya|title=Discrimination in Online Ad Delivery|journal=SSRI|date=28 January 2013|doi=10.2139/ssrn.2208240|arxiv=1301.6822|bibcode=2013arXiv1301.6822S}}&lt;/ref&gt;

In 2019, a research study revealed that a healthcare algorithm sold by [[Optum]] favored white patients over sicker black patients. The algorithm predicts how much patients would cost the health-care system in the future. However, cost is not race-neutral, as black patients incurred about $1,800 less in medical costs per year than white patients with the same number of chronic conditions, which led to the algorithm scoring white patients as equally at risk of future health problems as black patients who suffered from significantly more diseases.&lt;ref&gt;{{Cite web|url=https://www.washingtonpost.com/health/2019/10/24/racial-bias-medical-algorithm-favors-white-patients-over-sicker-black-patients/|title=Racial bias in a medical algorithm favors white patients over sicker black patients|first=Carolyn Y. |last=Johnson |date=24 October 2019|website=Washington Post|language=en|access-date=2019-10-28}}&lt;/ref&gt;

A study conducted by researchers at UC Berkeley in November 2019 revealed that mortgage algorithms have been discriminatory towards Latino and African Americans which discriminated against minorities based on "creditworthiness" which is rooted in the U.S. fair-lending law which allows lenders to use measures of identification to determine if an individual is worthy of receiving loans. These particular algorithms were present in FinTech companies and were shown to discriminate against minorities.&lt;ref&gt;{{Cite journal|last1=Bartlett|first1=Robert|last2=Morse|first2=Adair|last3=Stanton|first3=Richard|last4=Wallace|first4=Nancy|date=June 2019|title=Consumer-Lending Discrimination in the FinTech Era|url=http://www.nber.org/papers/w25943|journal=NBER Working Paper No. 25943|doi=10.3386/w25943}}&lt;/ref&gt;{{Primary source inline|date=December 2019}}

==== Law enforcement and legal proceedings ====
Algorithms already have numerous applications in legal systems. An example of this is [[COMPAS (software)|COMPAS]], a commercial program widely used by [[U.S. court]]s to assess the likelihood of a [[defendant]] becoming a [[recidivist]]. [[ProPublica]] claims that the average COMPAS-assigned recidivism risk level of black defendants is significantly higher than the average COMPAS-assigned risk level of white defendants, and that black defendants are twice as likely to be erroneously assigned the label "high-risk" as white defendants.&lt;ref&gt;{{Cite web|last=Jeff Larson|first=Julia Angwin|date=2016-05-23|title=How We Analyzed the COMPAS Recidivism Algorithm|url=https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm|url-status=live|archive-url=https://web.archive.org/web/20190429190950/https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm|archive-date=29 April 2019|access-date=2020-06-19|website=ProPublica|language=en}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|date=2019-01-12|title=Commentary: Bad news. Artificial intelligence is biased|url=https://www.channelnewsasia.com/news/commentary/artificial-intelligence-big-data-bias-hiring-loans-key-challenge-11097374|url-status=live|archive-url=https://web.archive.org/web/20190112104421/https://www.channelnewsasia.com/news/commentary/artificial-intelligence-big-data-bias-hiring-loans-key-challenge-11097374|archive-date=12 January 2019|access-date=2020-06-19|website=CNA|language=en}}&lt;/ref&gt;

One example is the use of [[risk assessment]]s in [[criminal sentencing in the United States]] and [[Parole board|parole hearings]], judges were presented with an algorithmically generated score intended to reflect the risk that a prisoner will repeat a crime.&lt;ref name="ProPublica"&gt;{{cite web|last1=Angwin|first1=Julia|last2=Larson|first2=Jeff|last3=Mattu|first3=Surya|last4=Kirchner|first4=Lauren|date=23 May 2016|title=Machine Bias — ProPublica|url=https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing|access-date=18 November 2017|website=ProPublica}}&lt;/ref&gt; For the time period starting in 1920 and ending in 1970, the nationality of a criminal's father was a consideration in those risk assessment scores.&lt;ref name="Harcourt"&gt;{{cite journal|last1=Harcourt|first1=Bernard|date=16 September 2010|title=Risk as a Proxy for Race|journal=Criminology and Public Policy, Forthcoming|ssrn=1677654}}&lt;/ref&gt;{{rp|4}} Today, these scores are shared with judges in Arizona, Colorado, Delaware, Kentucky, Louisiana, Oklahoma, Virginia, Washington, and Wisconsin. An independent investigation by [[ProPublica]] found that the scores were inaccurate 80% of the time, and disproportionately skewed to suggest blacks to be at risk of relapse, 77% more often than whites.&lt;ref name="ProPublica" /&gt;

One study that set out to examine “Risk, Race, &amp; Recidivism: Predictive Bias and Disparate Impact” alleges a two-fold (45 percent vs. 23 percent) adverse likelihood for black vs. Caucasian defendants to be misclassified as imposing a higher risk despite having objectively remained without any documented recidivism over a two-year period of observation.&lt;ref&gt;Skeem J, Lowenkamp C, Risk, Race, &amp; Recidivism: Predictive Bias and Disparate Impact, (June 14, 2016). Available at SSRN: https://ssrn.com/abstract=2687339 or https://doi.org/10.2139/ssrn.2687339&lt;/ref&gt;

==== Online hate speech ====
In 2017 a [[Facebook]] algorithm designed to remove online hate speech was found to advantage white men over black children when assessing objectionable content, according to internal Facebook documents.&lt;ref name="AngwinGrassegger"&gt;{{cite web|url=https://www.propublica.org/article/facebook-hate-speech-censorship-internal-documents-algorithms|title=Facebook's Secret Censorship Rules Protect White Men From Hate Speech But Not Black Children — ProPublica|last1=Angwin|first1=Julia|last2=Grassegger|first2=Hannes|date=28 June 2017|website=ProPublica|access-date=20 November 2017}}&lt;/ref&gt; The algorithm, which is a combination of computer programs and human content reviewers, was created to protect broad categories rather than specific subsets of categories. For example, posts denouncing "Muslims" would be blocked, while posts denouncing "Radical Muslims" would be allowed. An unanticipated outcome of the algorithm is to allow hate speech against black children, because they denounce the "children" subset of blacks, rather than "all blacks", whereas "all white men" would trigger a block, because whites and males are not considered subsets.&lt;ref name="AngwinGrassegger" /&gt; Facebook was also found to allow ad purchasers to target "Jew haters" as a category of users, which the company said was an inadvertent outcome of algorithms used in assessing and categorizing data. The company's design also allowed ad buyers to block African-Americans from seeing housing ads.&lt;ref name="AngwinVarnerTobin"&gt;{{cite news|url=https://www.propublica.org/article/facebook-enabled-advertisers-to-reach-jew-haters|title=Facebook Enabled Advertisers to Reach 'Jew Haters' — ProPublica|last1=Angwin|first1=Julia|date=14 September 2017|work=ProPublica|access-date=20 November 2017|last2=Varner|first2=Madeleine|last3=Tobin|first3=Ariana}}&lt;/ref&gt;

While algorithms are used to track and block hate speech, some were found to be 1.5 times more likely to flag information posted by Black users and 2.2 times likely to flag information as hate speech if written in Ebonics.&lt;ref&gt;{{Cite web|url=https://homes.cs.washington.edu/~msap/pdfs/sap2019risk.pdf|title=The Risk of Racial Bias in Hate Speech Detection|last=Sap|first=Maarten|url-status=live|archive-date=February 19, 2020}}&lt;/ref&gt; Without context for slurs and epithets, even when used by communities which have re-appropriated them, were flagged.&lt;ref&gt;{{Cite web|url=https://www.vox.com/recode/2019/8/15/20806384/social-media-hate-speech-bias-black-african-american-facebook-twitter|title=The algorithms that detect hate speech online are biased against black people|last=Ghaffary|first=Shirin|website=Vox|access-date=19 February 2020}}&lt;/ref&gt;

==== Surveillance ====
Surveillance camera software may be considered inherently political because it requires algorithms to distinguish normal from abnormal behaviors, and to determine who belongs in certain locations at certain times.&lt;ref name="Graham" /&gt;{{rp|572}} The ability of such algorithms to recognize faces across a racial spectrum has been shown to be limited by the racial diversity of images in its training database; if the majority of photos belong to one race or gender, the software is better at recognizing other members of that race or gender.&lt;ref name="Furl2002"&gt;{{cite journal|last1=Furl|first1=N|date=December 2002|title=Face recognition algorithms and the other-race effect: computational mechanisms for a developmental contact hypothesis|journal=Cognitive Science|volume=26|issue=6|pages=797–815|doi=10.1207/s15516709cog2606_4|doi-access=free}}&lt;/ref&gt; However, even audits of these image-recognition systems are ethically fraught, and some scholars have suggested the technology's context will always have a disproportionate impact on communities whose actions are over-surveilled.&lt;ref name="Raji-Gebru-Mitchell-2020"&gt;{{cite journal |last1=Raji |first1=Inioluwa Deborah |last2=Gebru |first2=Timnit |last3=Mitchell |first3=Margaret |last4=Buolamwini |first4=Joy |last5=Lee |first5=Joonseok |last6=Denton |first6=Emily |title=Saving Face: Investigating the Ethical Concerns of Facial Recognition Auditing |journal=Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society |date=7 February 2020 |pages=145–151 |doi=10.1145/3375627.3375820 |url=https://dl.acm.org/doi/10.1145/3375627.3375820 |publisher=Association for Computing Machinery|arxiv=2001.00964 |s2cid=209862419 }}&lt;/ref&gt; For example, a 2002 analysis of software used to identify individuals in [[CCTV]] images found several examples of bias when run against criminal databases. The software was assessed as identifying men more frequently than women, older people more frequently than the young, and identified Asians, African-Americans and other races more often than whites.&lt;ref name="IntronaWood" /&gt;{{rp|190}} Additional studies of facial recognition software have found the opposite to be true when trained on non-criminal databases, with the software being the least accurate in identifying darker-skinned females.&lt;ref&gt;{{Cite journal|last1=Buolamwini|first1=Joy|last2=Gebru|first2=Timnit|date=2018|title=Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification|url=http://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf|journal=Proceedings of Machine Learning Research|volume=81|page=1|via=MLR Press}}&lt;/ref&gt;

=== Sexual discrimination ===
In 2011, users of the gay hookup application [[Grindr]] reported that the [[Google Play|Android store]]'s recommendation algorithm was linking Grindr to applications designed to find sex offenders, which critics said inaccurately related homosexuality with pedophilia. Writer Mike Ananny criticized this association in ''[[The Atlantic]]'', arguing that such associations further stigmatized [[History of gay men in the United States|gay men]].&lt;ref name="Ananny"&gt;{{cite web|last1=Ananny|first1=Mike|title=The Curious Connection Between Apps for Gay Men and Sex Offenders|url=https://www.theatlantic.com/technology/archive/2011/04/the-curious-connection-between-apps-for-gay-men-and-sex-offenders/237340/|website=The Atlantic|access-date=18 November 2017|date=2011-04-14}}&lt;/ref&gt; In 2009, online retailer [[Amazon (company)|Amazon]] de-listed 57,000 books after an algorithmic change expanded its "adult content" blacklist to include any book addressing sexuality or gay themes, such as the critically acclaimed novel ''[[Brokeback Mountain]]''.&lt;ref name="Kafka2"&gt;{{cite web|last1=Kafka|first1=Peter|title=Did Amazon Really Fail This Weekend? The Twittersphere Says 'Yes,' Online Retailer Says 'Glitch.'|url=http://allthingsd.com/20090412/did-amazon-really-fail-this-weekend-the-twittersphere-says-yes/|website=AllThingsD|access-date=22 November 2017}}&lt;/ref&gt;&lt;ref name="Gillespie et al" /&gt;{{rp|5}}&lt;ref name="Kafka"&gt;{{cite web|last1=Kafka|first1=Peter|title=Amazon Apologizes for 'Ham-fisted Cataloging Error'|url=http://allthingsd.com/20090413/amazon-apologizes-for-ham-fisted-cataloging-error/|website=AllThingsD|publisher=AllThingsD|access-date=22 November 2017}}&lt;/ref&gt;

In 2019, it was found that on Facebook, searches for "photos of my female friends" yielded suggestions such as "in bikinis" or "at the beach". In contrast, searches for "photos of my male friends" yielded no results.&lt;ref&gt;{{Cite news|url=https://www.wired.com/story/facebook-female-friends-photo-search-bug/|title=A 'Sexist' Search Bug Says More About Us Than Facebook|last=Matsakis|first=Louise|date=2019-02-22|work=Wired|access-date=2019-02-26|issn=1059-1028}}&lt;/ref&gt;

Facial recognition technology has been seen to cause problems for transgender individuals. In 2018, there were reports of uber drivers who were transgender or transitioning experiencing difficulty with the facial recognition software that Uber implements as a built-in security measure. As a result of this, some of the accounts of trans uber drivers were suspended which cost them fares and potentially cost them a job, all due to the facial recognition software experiencing difficulties with recognizing the face of a trans driver who was transitioning.&lt;ref&gt;{{Cite web|url=https://www.vox.com/future-perfect/2019/4/19/18412674/ai-bias-facial-recognition-black-gay-transgender|title=Some AI just shouldn't exist|date=2019-04-19}}&lt;/ref&gt; Although the solution to this issue would appear to be including trans individuals in training sets for machine learning models, an instance of trans YouTube videos that were collected to be used in training data did not receive consent from the trans individuals that were included in the videos, which created an issue of violation of privacy.&lt;ref&gt;{{Cite web|url=https://www.vox.com/future-perfect/2019/4/19/18412674/ai-bias-facial-recognition-black-gay-transgender|title=Some AI just shouldn't exist|last=Samuel|first=Sigal|date=2019-04-19|website=Vox|language=en|access-date=2019-12-12}}&lt;/ref&gt;

There has also been a study that was conducted at Stanford University in 2017 that tested algorithms in a machine learning system that was said to be able to detect an individuals sexual orientation based on their facial images.&lt;ref&gt;{{Cite journal|last1=Wang|first1=Yilun|last2=Kosinski|first2=Michal|date=2017-02-15|title=Deep neural networks are more accurate than humans at detecting sexual orientation from facial images.|url=https://osf.io/zn79k/|journal=OSF|language=en}}&lt;/ref&gt; The model in the study predicted a correct distinction between gay and straight men 81% of the time, and a correct distinction between gay and straight women 74% of the time. This study resulted in a backlash from the LGBTQIA community, who were fearful of the possible negative repercussions that this AI system could have on individuals of the LGBTQIA community by putting individuals at risk of being "outed" against their will.&lt;ref&gt;{{Cite news|url=https://www.theguardian.com/world/2017/sep/08/ai-gay-gaydar-algorithm-facial-recognition-criticism-stanford|title=LGBT groups denounce 'dangerous' AI that uses your face to guess sexuality|last=Levin|first=Sam|date=2017-09-09|work=The Guardian|access-date=2019-12-12|language=en-GB|issn=0261-3077}}&lt;/ref&gt;

=== Google Search ===
While users generate results that are "completed" automatically, Google has failed to remove sexist and racist autocompletion text. For example, ''[[Algorithms of Oppression|Algorithms of Oppression: How Search Engines Reinforce Racism]]'' Safiya Noble notes an example of the search for "black girls", which was reported to result in pornographic images. Google claimed it was unable to erase those pages unless they were considered unlawful.&lt;ref&gt;{{Cite book|title=Algorithms of Oppression: how search engines reinforce racism|last=Noble, Safiya Umoja|isbn=9781479837243|location=New York|oclc=987591529|date = 2018-02-20}}&lt;/ref&gt;

== Obstacles to research ==

Several problems impede the study of large-scale algorithmic bias, hindering the application of academically rigorous studies and public understanding.&lt;ref name="Seaver" /&gt;{{rp|5}}

=== Defining fairness ===
Literature on algorithmic bias has focused on the remedy of fairness, but definitions of fairness are often incompatible with each other and the realities of machine learning optimization. For example, defining fairness as an "equality of outcomes" may simply refer to a system producing the same result for all people, while fairness defined as "equality of treatment" might explicitly consider differences between individuals.&lt;ref name="Friedler"&gt;{{cite journal |last1=Friedler |first1=Sorelle A. |last2=Scheidegger |first2=Carlos |last3=Venkatasubramanian |first3=Suresh |title=On the (im)possibility of fairness |year=2016 |arxiv=1609.07236}}&lt;/ref&gt;{{rp|2}} As a result, fairness is sometimes described as being in conflict with the accuracy of a model, suggesting innate tensions between the priorities of social welfare and the priorities of the vendors designing these systems.&lt;ref name="Hu"&gt;{{cite journal |last1=Hu |first1=Lily |last2=Chen |first2=Yiling |title=Welfare and Distributional Impacts of Fair Classification |year=2018 |arxiv=1807.01134 }}&lt;/ref&gt;{{rp|2}} In response to this tension, researchers have suggested more care to the design and use of systems that draw on potentially biased algorithms, with "fairness" defined for specific applications and contexts.&lt;ref name="Dwork"&gt;{{cite journal |last1=Dwork |first1=Cynthia |last2=Hardt |first2=Moritz |last3=Pitassi |first3=Toniann |last4=Reingold |first4=Omer |last5=Zemel |first5=Rich |title=Fairness Through Awareness |date=28 November 2011 |arxiv=1104.3913}}&lt;/ref&gt;

=== Complexity ===
Algorithmic processes are [[Complex system|complex]], often exceeding the understanding of the people who use them.&lt;ref name="Seaver" /&gt;{{rp|2}}&lt;ref name="Sandvig2"&gt;{{cite journal|last1=Sandvig|first1=Christian|last2=Hamilton|first2=Kevin|last3=Karahalios|first3=Karrie|last4=Langbort|first4=Cedric|date=2014|editor1-last=Gangadharan|editor1-first=Seeta Pena|editor2-last=Eubanks|editor2-first=Virginia|editor3-last=Barocas|editor3-first=Solon|title=An Algorithm Audit|url=http://www-personal.umich.edu/~csandvig/research/An%20Algorithm%20Audit.pdf|journal=Data and Discrimination: Collected Essays}}&lt;/ref&gt;{{rp|7}} Large-scale operations may not be understood even by those involved in creating them.&lt;ref name="LaFrance"&gt;{{cite web|last1=LaFrance|first1=Adrienne|title=The Algorithms That Power the Web Are Only Getting More Mysterious|url=https://www.theatlantic.com/technology/archive/2015/09/not-even-the-people-who-write-algorithms-really-know-how-they-work/406099/|website=The Atlantic|access-date=19 November 2017|date=2015-09-18}}&lt;/ref&gt; The methods and processes of contemporary programs are often obscured by the inability to know every permutation of a code's input or output.&lt;ref name="IntronaWood" /&gt;{{rp|183}} Social scientist [[Bruno Latour]] has identified this process as [[blackboxing]], a process in which "scientific and technical work is made invisible by its own success. When a machine runs efficiently, when a matter of fact is settled, one need focus only on its inputs and outputs and not on its internal complexity. Thus, paradoxically, the more science and technology succeed, the more opaque and obscure they become."&lt;ref&gt;{{Cite book|title=Pandora's hope: essays on the reality of science studies|author=Bruno Latour|publisher=[[Harvard University Press]]|year=1999|location=[[Cambridge, Massachusetts]]}}&lt;/ref&gt; Others have critiqued the black box metaphor, suggesting that current algorithms are not one black box, but a network of interconnected ones.&lt;ref name="KubitschkoKaun"&gt;{{cite book|url=https://books.google.com/books?id=ZdzMDQAAQBAJ|title=Innovative Methods in Media and Communication Research|last1=Kubitschko|first1=Sebastian|last2=Kaun|first2=Anne|date=2016|publisher=Springer|isbn=978-3-319-40700-5|access-date=19 November 2017}}&lt;/ref&gt;{{rp|92}}

An example of this complexity can be found in the range of inputs into customizing feedback. The social media site Facebook factored in at least 100,000 data points to determine the layout of a user's social media feed in 2013.&lt;ref name="McGee"&gt;{{cite web|last1=McGee|first1=Matt|title=EdgeRank Is Dead: Facebook's News Feed Algorithm Now Has Close To 100K Weight Factors|url=https://marketingland.com/edgerank-is-dead-facebooks-news-feed-algorithm-now-has-close-to-100k-weight-factors-55908|website=Marketing Land|access-date=18 November 2017|date=16 August 2013}}&lt;/ref&gt; Furthermore, large teams of programmers may operate in relative isolation from one another, and be unaware of the cumulative effects of small decisions within connected, elaborate algorithms.&lt;ref name="Introna1" /&gt;{{rp|118}} Not all code is original, and may be borrowed from other libraries, creating a complicated set of relationships between data processing and data input systems.&lt;ref name="Kitchin"&gt;{{cite journal|last1=Kitchin|first1=Rob|date=25 February 2016|title=Thinking critically about and researching algorithms|url=http://mural.maynoothuniversity.ie/11591/1/Kitchin_Thinking_2017.pdf|journal=Information, Communication &amp; Society|volume=20|issue=1|pages=14–29|doi=10.1080/1369118X.2016.1154087|s2cid=13798875}}&lt;/ref&gt;{{rp|22}}

Additional complexity occurs through [[machine learning]] and the personalization of algorithms based on user interactions such as clicks, time spent on site, and other metrics. These personal adjustments can confuse general attempts to understand algorithms.&lt;ref name="Granka"&gt;{{cite journal|last1=Granka|first1=Laura A.|date=27 September 2010|title=The Politics of Search: A Decade Retrospective|url=https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36914.pdf|journal=The Information Society|volume=26|issue=5|pages=364–374|doi=10.1080/01972243.2010.511560|s2cid=16306443|access-date=18 November 2017}}&lt;/ref&gt;{{rp|367}}&lt;ref name="Sandvig2" /&gt;{{rp|7}} One unidentified streaming radio service reported that it used five unique music-selection algorithms it selected for its users, based on their behavior. This creates different experiences of the same streaming services between different users, making it harder to understand what these algorithms do.&lt;ref name="Seaver" /&gt;{{rp|5}}
Companies also run frequent [[A/B tests]] to fine-tune algorithms based on user response. For example, the search engine [[Bing (search engine)|Bing]] can run up to ten million subtle variations of its service per day, creating different experiences of the service between each use and/or user.&lt;ref name="Seaver" /&gt;{{rp|5}}

=== Lack of transparency ===
Commercial algorithms are proprietary, and may be treated as [[trade secrets]].&lt;ref name="Seaver" /&gt;{{rp|2}}&lt;ref name="Sandvig2" /&gt;{{rp|7}}&lt;ref name="IntronaWood" /&gt;{{rp|183}} Treating algorithms as trade secrets protects companies, such as [[Web search engine|search engines]], where a transparent algorithm might reveal tactics to manipulate search rankings.&lt;ref name="Granka" /&gt;{{rp|366}} This makes it difficult for researchers to conduct interviews or analysis to discover how algorithms function.&lt;ref name="Kitchin" /&gt;{{rp|20}} Critics suggest that such secrecy can also obscure possible unethical methods used in producing or processing algorithmic output.&lt;ref name="Granka" /&gt;{{rp|369}} Other critics, such as lawyer and activist Katarzyna Szymielewicz, have suggested that the lack of transparency is often disguised as a result of algorithmic complexity, shielding companies from disclosing or investigating its own algorithmic processes.&lt;ref&gt;{{Cite web|url=https://medium.com/@szymielewicz/black-boxed-politics-cebc0d5a54ad|title=Black-Boxed Politics|last=Szymielewicz|first=Katarzyna|date=2020-01-20|website=Medium|language=en|access-date=2020-02-11}}&lt;/ref&gt;

=== Lack of data about sensitive categories ===
A significant barrier to understanding the tackling of bias in practice is that categories, such as demographics of individuals protected by [[anti-discrimination law]], are often not explicitly considered when collecting and processing data.&lt;ref&gt;{{Cite journal|last1=Veale|first1=Michael|last2=Binns|first2=Reuben|date=2017|title=Fairer machine learning in the real world: Mitigating discrimination without collecting sensitive data|journal=Big Data &amp; Society|volume=4|issue=2|pages=205395171774353|doi=10.1177/2053951717743530|ssrn=3060763|doi-access=free}}&lt;/ref&gt; In some cases, there is little opportunity to collect this data explicitly, such as in [[device fingerprint]]ing, [[ubiquitous computing]] and the [[Internet of things|Internet of Things]]. In other cases, the data controller may not wish to collect such data for reputational reasons, or because it represents a heightened liability and security risk. It may also be the case that, at least in relation to the European Union's [[General Data Protection Regulation]], such data falls under the 'special category' provisions (Article 9), and therefore comes with more restrictions on potential collection and processing.

Some practitioners have tried to estimate and impute these missing sensitive categorisations in order to allow bias mitigation, for example building systems to infer ethnicity from names,&lt;ref&gt;{{Cite journal|last1=Elliott|first1=Marc N.|last2=Morrison|first2=Peter A.|last3=Fremont|first3=Allen|last4=McCaffrey|first4=Daniel F.|last5=Pantoja|first5=Philip|last6=Lurie|first6=Nicole|date=June 2009|title=Using the Census Bureau's surname list to improve estimates of race/ethnicity and associated disparities|journal=Health Services and Outcomes Research Methodology|volume=9|issue=2|pages=69–83|doi=10.1007/s10742-009-0047-1|s2cid=43293144|issn=1387-3741}}&lt;/ref&gt; however this can introduce other forms of bias if not undertaken with care.&lt;ref&gt;{{Cite journal|last1=Chen|first1=Jiahao|last2=Kallus|first2=Nathan|last3=Mao|first3=Xiaojie|last4=Svacha|first4=Geoffry|last5=Udell|first5=Madeleine|date=2019|title=Fairness Under Unawareness: Assessing Disparity When Protected Class Is Unobserved|url=http://dl.acm.org/citation.cfm?doid=3287560.3287594|journal=Proceedings of the Conference on Fairness, Accountability, and Transparency - FAT* '19|location=Atlanta, GA, USA|publisher=ACM Press|pages=339–348|doi=10.1145/3287560.3287594|isbn=9781450361255|arxiv=1811.11154|s2cid=58006233}}&lt;/ref&gt; Machine learning researchers have drawn upon cryptographic [[privacy-enhancing technologies]] such as [[secure multi-party computation]] to propose methods whereby algorithmic bias can be assessed or mitigated without these data ever being available to modellers in [[cleartext]].&lt;ref&gt;{{Cite journal|last1=Kilbertus|first1=Niki|last2=Gascon|first2=Adria|last3=Kusner|first3=Matt|last4=Veale|first4=Michael|last5=Gummadi|first5=Krishna|last6=Weller|first6=Adrian|date=2018|title=Blind Justice: Fairness with Encrypted Sensitive Attributes|url=http://proceedings.mlr.press/v80/kilbertus18a.html|journal=International Conference on Machine Learning|pages=2630–2639|bibcode=2018arXiv180603281K|arxiv=1806.03281}}&lt;/ref&gt;

Algorithmic bias does not only include protected categories, but can also concerns characteristics less easily observable or codifiable, such as political viewpoints. In these cases, there is rarely an easily accessible or non-controversial [[ground truth]], and removing the bias from such a system is more difficult.&lt;ref&gt;{{Cite book|last1=Binns|first1=Reuben|last2=Veale|first2=Michael|last3=Kleek|first3=Max Van|last4=Shadbolt|first4=Nigel|date=13 September 2017|title=Like Trainer, Like Bot? Inheritance of Bias in Algorithmic Content Moderation|journal=Social Informatics|series=Lecture Notes in Computer Science|volume=10540|pages=405–415|arxiv=1707.01477|doi=10.1007/978-3-319-67256-4_32|isbn=978-3-319-67255-7|s2cid=2814848}}&lt;/ref&gt; Furthermore, false and accidental [[correlations]] can emerge from a lack of understanding of protected categories, for example, insurance rates based on historical data of car accidents which may overlap, strictly by coincidence, with residential clusters of ethnic minorities.&lt;ref name="Claburn"&gt;{{cite web|last1=Claburn|first1=Thomas|title=EU Data Protection Law May End The Unknowable Algorithm – InformationWeek|url=https://www.informationweek.com/government/big-data-analytics/eu-data-protection-law-may-end-the-unknowable-algorithm/d/d-id/1326294?|website=InformationWeek|access-date=25 November 2017}}&lt;/ref&gt;

==Solutions==
A study of 84 policy guidelines on ethical AI found that fairness and "mitigation of unwanted bias" was a common point of concern, and were addressed through a blend of technical solutions, transparency and monitoring, right to remedy and increased oversight, and diversity and inclusion efforts.&lt;ref name=":0"&gt;{{Cite journal|last1=Jobin|first1=Anna|last2=Ienca|first2=Marcello|last3=Vayena|first3=Effy|date=2 September 2019|title=The global landscape of AI ethics guidelines|journal=Nature Machine Intelligence|volume=1|issue=9|pages=389–399|doi=10.1038/s42256-019-0088-2|arxiv=1906.11668|s2cid=201827642}}&lt;/ref&gt;

=== Technical ===
There have been several attempts to create methods and tools that can detect and observe biases within an algorithm. These emergent fields focus on tools which are typically applied to the (training) data used by the program rather than the algorithm's internal processes. These methods may also analyze a program's output and its usefulness and therefore may involve the analysis of its [[confusion matrix]] (or table of confusion).&lt;ref&gt;https://research.google.com/bigpicture/attacking-discrimination-in-ml/ Attacking discrimination with smarter machine learning&lt;/ref&gt;&lt;ref&gt;{{cite arxiv |eprint=1610.02413|last1=Hardt|first1=Moritz|title=Equality of Opportunity in Supervised Learning|last2=Price|first2=Eric|last3=Srebro|first3=Nathan|class=cs.LG|year=2016}}&lt;/ref&gt;&lt;ref&gt;https://venturebeat.com/2018/05/25/microsoft-is-developing-a-tool-to-help-engineers-catch-bias-in-algorithms/ Microsoft is developing a tool to help engineers catch bias in algorithms&lt;/ref&gt;&lt;ref&gt;https://qz.com/1268520/facebook-says-it-has-a-tool-to-detect-bias-in-its-artificial-intelligence/ Facebook says it has a tool to detect bias in its artificial intelligence&lt;/ref&gt;&lt;ref&gt;[https://github.com/pymetrics/audit-ai open source] Pymetrics audit-ai&lt;/ref&gt;&lt;ref&gt;https://venturebeat-com.cdn.ampproject.org/c/s/venturebeat.com/2018/05/31/pymetrics-open-sources-audit-ai-an-algorithm-bias-detection-tool/amp/ Pymetrics open-sources Audit AI, an algorithm bias detection tool&lt;/ref&gt;&lt;ref&gt;https://github.com/dssg/aequitas open source Aequitas: Bias and Fairness Audit Toolkit&lt;/ref&gt;&lt;ref&gt;https://dsapp.uchicago.edu/aequitas/ open-sources Audit AI, Aequitas at University of Chicago&lt;/ref&gt;&lt;ref&gt;https://www.ibm.com/blogs/research/2018/02/mitigating-bias-ai-models/ Mitigating Bias in AI Models&lt;/ref&gt; Explainable AI to detect algorithm Bias is a suggested way to detect the existence of bias in an algorithm or learning model.&lt;ref&gt;S. Sen, D. Dasgupta and K. D. Gupta, "An Empirical Study on Algorithmic Bias," 2020 IEEE 44th Annual Computers, Software, and Applications Conference (COMPSAC), Madrid, Spain, 2020, pp. 1189-1194, {{doi|10.1109/COMPSAC48688.2020.00-95}}.&lt;/ref&gt; Using machine learning to detect bias is called, "conducting an AI audit", where the "auditor" is an algorithm that goes through the AI model and the training data to identify biases.&lt;ref&gt;{{Cite journal|last=Zou|first=James|last2=Schiebinger|first2=Londa|date=July 2018|title=AI can be sexist and racist — it’s time to make it fair|url=https://www.nature.com/articles/d41586-018-05707-8|journal=Nature|language=en|volume=559|issue=7714|pages=324–326|doi=10.1038/d41586-018-05707-8|doi-access=free}}&lt;/ref&gt;

Currently, a new [[IEEE Standards Association|IEEE standard]] is being drafted that aims to specify methodologies which help creators of algorithms eliminate issues of bias and articulate transparency (i.e. to authorities or [[end user]]s) about the function and possible effects of their algorithms. The project was approved February 2017 and is sponsored by the [https://www.computer.org/web/standards/s2esc Software &amp; Systems Engineering Standards Committee], a committee chartered by the [[IEEE Computer Society]]. A draft of the standard is expected to be submitted for balloting in June 2019.&lt;ref&gt;{{Cite journal|last=Koene|first=Ansgar|date=June 2017|title=Algorithmic Bias: Addressing Growing Concerns [Leading Edge]|journal=IEEE Technology and Society Magazine|volume=36|issue=2|pages=31–32|doi=10.1109/mts.2017.2697080|issn=0278-0097|url=http://eprints.nottingham.ac.uk/44207/8/IEEE_Tech_Sociery_Magazine_AlgoBias_2017_AKoene.pdf}}&lt;!--http://eprints.nottingham.ac.uk/44207/8/IEEE_Tech_Sociery_Magazine_AlgoBias_2017_AKoene.pdf--&gt;&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://standards.ieee.org/project/7003.html|title=P7003 - Algorithmic Bias Considerations|website=standards.ieee.org|access-date=2018-12-03}}&lt;/ref&gt;

=== Transparency and monitoring ===
Ethics guidelines on AI point to the need for accountability, recommending that steps be taken to improve the interpretability of results.&lt;ref&gt;{{Cite web|url=https://www.internetsociety.org/resources/doc/2017/artificial-intelligence-and-machine-learning-policy-paper/|title=Artificial Intelligence and Machine Learning: Policy Paper|last=The Internet Society|date=18 April 2017|website=Internet Society|access-date=11 February 2020}}&lt;/ref&gt; Such solutions include the consideration of the "right to understanding" in machine learning algorithms, and to resist deployment of machine learning in situations where the decisions could not be explained or reviewed.&lt;ref name=":2"&gt;{{Cite web|url=https://www.weforum.org/whitepapers/how-to-prevent-discriminatory-outcomes-in-machine-learning|title=White Paper: How to Prevent Discriminatory Outcomes in Machine Learning|date=12 March 2018|website=World Economic Forum|access-date=11 February 2020}}&lt;/ref&gt; Toward this end, a movement for "[[Explainable artificial intelligence|Explainable AI]]" is already underway within organizations such as [[DARPA]], for reasons that go beyond the remedy of bias.&lt;ref&gt;{{Cite web|url=https://www.darpa.mil/program/explainable-artificial-intelligence|title=Explainable Artificial Intelligence|website=www.darpa.mil|access-date=2020-02-11}}&lt;/ref&gt; [[PricewaterhouseCoopers|Price Waterhouse Coopers]], for example, also suggests that monitoring output means designing systems in such a way as to ensure that solitary components of the system can be isolated and shut down if they skew results.&lt;ref&gt;{{Cite web|url=https://www.pwc.co.uk/services/risk-assurance/insights/accelerating-innovation-through-responsible-ai/responsible-ai-framework.html|title=The responsible AI framework|last=PricewaterhouseCoopers|website=PwC|language=en-gb|access-date=2020-02-11}}&lt;/ref&gt;

An initial approach towards transparency included the [[Open-source software|open-sourcing of algorithms]].&lt;ref&gt;{{Cite book|last=Heald|first=David|title=Transparency: The Key to Better Governance?|date=2006-09-07|publisher=British Academy|isbn=978-0-19-726383-9|language=en|doi=10.5871/bacad/9780197263839.003.0002}}&lt;/ref&gt; Software code can be looked into and improvements can be proposed through [[Comparison of source-code-hosting facilities|source-code-hosting facilities]]. However, this approach doesn't necessarily produce the intended effects. Companies and organizations can share all possible documentation and code, but this does not establish transparency if the audience doesn't understand the information given. Therefore, the role of an interested critical audience is worth exploring in relation to transparency. Algorithms cannot be held accountable without a critical audience.&lt;ref&gt;{{Cite journal|last=Kemper|first=Jakko|last2=Kolkman|first2=Daan|date=2019-12-06|title=Transparent to whom? No algorithmic accountability without a critical audience|url=https://doi.org/10.1080/1369118X.2018.1477967|journal=Information, Communication &amp; Society|volume=22|issue=14|pages=2081–2096|doi=10.1080/1369118X.2018.1477967|issn=1369-118X|doi-access=free}}&lt;/ref&gt;

=== Right to remedy ===
From a regulatory perspective, the [[Toronto Declaration]] calls for applying a human rights framework to harms caused by algorithmic bias.&lt;ref&gt;{{Cite web|url=https://www.hrw.org/news/2018/07/03/toronto-declaration-protecting-rights-equality-and-non-discrimination-machine|title=The Toronto Declaration: Protecting the rights to equality and non-discrimination in machine learning systems|date=2018-07-03|website=Human Rights Watch|language=en|access-date=2020-02-11}}&lt;/ref&gt; This includes legislating expectations of due diligence on behalf of designers of these algorithms, and creating accountability when private actors fail to protect the public interest, noting that such rights may be obscured by the complexity of determining responsibility within a web of complex, intertwining processes.&lt;ref&gt;{{Cite book|last=Human Rights Watch|title=The Toronto Declaration: Protecting the right to equality and non-discrimination in machine learning systems|publisher=Human Rights Watch|year=2018|url=https://www.accessnow.org/cms/assets/uploads/2018/08/The-Toronto-Declaration_ENG_08-2018.pdf|pages=15}}&lt;/ref&gt; Others propose the need for clear liability insurance mechanisms.&lt;ref&gt;{{Cite journal|last1=Floridi|first1=Luciano|last2=Cowls|first2=Josh|last3=Beltrametti|first3=Monica|last4=Chatila|first4=Raja|last5=Chazerand|first5=Patrice|last6=Dignum|first6=Virginia|last7=Luetge|first7=Christoph|last8=Madelin|first8=Robert|last9=Pagallo|first9=Ugo|last10=Rossi|first10=Francesca|last11=Schafer|first11=Burkhard|date=2018-12-01|title=AI4People—An Ethical Framework for a Good AI Society: Opportunities, Risks, Principles, and Recommendations|journal=Minds and Machines|language=en|volume=28|issue=4|pages=703|doi=10.1007/s11023-018-9482-5|issn=1572-8641|pmc=6404626|pmid=30930541}}&lt;/ref&gt;

=== Diversity and inclusion ===
Amid concerns that the design of AI systems is primarily the domain of white, male engineers,&lt;ref&gt;{{Cite news|last=Crawford|first=Kate|url=https://www.nytimes.com/2016/06/26/opinion/sunday/artificial-intelligences-white-guy-problem.html|title=Opinion {{!}} Artificial Intelligence's White Guy Problem|date=2016-06-25|work=The New York Times|access-date=2020-02-11|language=en-US|issn=0362-4331}}&lt;/ref&gt; a number of scholars have suggested that algorithmic bias may be minimized by expanding inclusion in the ranks of those designing AI systems.&lt;ref name=":2" /&gt;&lt;ref name=":0" /&gt; For example, just 12% of machine learning engineers are women,&lt;ref&gt;{{Cite news|url=https://www.wired.com/story/artificial-intelligence-researchers-gender-imbalance/|title=AI Is the Future—But Where Are the Women?|work=Wired|access-date=2020-02-11|language=en|issn=1059-1028}}&lt;/ref&gt; with black AI leaders pointing to a "diversity crisis" in the field.&lt;ref&gt;{{Cite web|url=https://www.technologyreview.com/s/610192/were-in-a-diversity-crisis-black-in-ais-founder-on-whats-poisoning-the-algorithms-in-our/|title="We're in a diversity crisis": cofounder of Black in AI on what's poisoning algorithms in our lives|last=Snow|first=Jackie|website=MIT Technology Review|language=en-US|access-date=2020-02-11}}&lt;/ref&gt; Critiques of simple inclusivity efforts suggest that diversity programs can not address overlapping forms of inequality, and have called for applying a more deliberate lens of [[Intersectional feminism|intersectionality]] to the design of algorithms.&lt;ref&gt;{{Cite journal|last=Ciston|first=Sarah|date=2019-12-29|title=Intersectional AI Is Essential|journal=Journal of Science and Technology of the Arts|language=en|volume=11|issue=2|pages=3–8|doi=10.7559/citarj.v11i2.665|issn=2183-0088|doi-access=free}}&lt;/ref&gt;&lt;ref name="DataFeminism"&gt;{{cite book |last1=D'Ignazio |first1=Catherine |last2=Klein |first2=Lauren F. |title=Data feminism |date=2020 |publisher=MIT Press |isbn=978-0262044004}}&lt;/ref&gt;{{rp|4}} Researchers at the University of Cambridge have argued that addressing racial diversity is hampered by the 'whiteness' of the culture of AI.&lt;ref&gt;{{Cite journal|last1=Cave|first1=Stephen|last2=Dihal|first2=Kanta|date=2020-08-06|title=The Whiteness of AI|journal=Philosophy &amp; Technology|language=en|doi=10.1007/s13347-020-00415-6|issn=2210-5441|doi-access=free}}&lt;/ref&gt;

== Regulation ==

=== Europe ===
The [[General Data Protection Regulation]] (GDPR), the [[European Union]]'s revised data protection regime that was implemented in 2018, addresses "Automated individual decision-making, including profiling" in Article 22. These rules prohibit "solely" automated decisions which have a "significant" or "legal" effect on an individual, unless they are explicitly authorised by consent, contract, or [[Member state of the European Union|member state]] law. Where they are permitted, there must be safeguards in place, such as a right to a [[human-in-the-loop]], and a non-binding [[right to an explanation]] of decisions reached. While these regulations are commonly considered to be new, nearly identical provisions have existed across Europe since 1995, in Article 15 of the [[Data Protection Directive]]. The original automated decision rules and safeguards found in French law since the late 1970s.&lt;ref&gt;{{Cite journal|last=Bygrave|first=Lee A|journal=Computer Law &amp; Security Review|volume=17|issue=1|pages=17–24|doi=10.1016/s0267-3649(01)00104-2|year=2001|title=Automated Profiling}}&lt;/ref&gt;

The GDPR addresses algorithmic bias in profiling systems, as well as the statistical approaches possible to clean it, directly in [[Recital (law)|recital]] 71,&lt;ref name=":1"&gt;{{Cite journal|last1=Veale|first1=Michael|last2=Edwards|first2=Lilian|date=2018|title=Clarity, Surprises, and Further Questions in the Article 29 Working Party Draft Guidance on Automated Decision-Making and Profiling|journal=Computer Law &amp; Security Review|doi=10.2139/ssrn.3071679|ssrn=3071679|url=http://discovery.ucl.ac.uk/10046182/1/Veale%201-s2.0-S026736491730376X-main%281%29.pdf}}&lt;/ref&gt; noting that&lt;blockquote&gt; ... the controller should use appropriate mathematical or statistical procedures for the profiling, implement technical and organisational measures appropriate ... that prevents, inter alia, discriminatory effects on natural persons on the basis of racial or ethnic origin, political opinion, religion or beliefs, trade union membership, genetic or health status or sexual orientation, or that result in measures having such an effect.&lt;/blockquote&gt;Like the non-binding [[right to an explanation]] in recital 71, the problem is the non-binding nature of [[Recital (law)|recitals]].&lt;ref&gt;{{Cite journal|last1=Wachter|first1=Sandra|last2=Mittelstadt|first2=Brent|last3=Floridi|first3=Luciano|date=1 May 2017|title=Why a Right to Explanation of Automated Decision-Making Does Not Exist in the General Data Protection Regulation|journal=International Data Privacy Law|volume=7|issue=2|pages=76–99|doi=10.1093/idpl/ipx005|issn=2044-3994|doi-access=free}}&lt;/ref&gt; While it has been treated as a requirement by the [[Article 29 Working Party]] that advised on the implementation of data protection law,&lt;ref name=":1" /&gt; its practical dimensions are unclear. It has been argued that the Data Protection Impact Assessments for high risk data profiling (alongside other pre-emptive measures within data protection) may be a better way to tackle issues of algorithmic discrimination, as it restricts the actions of those deploying algorithms, rather than requiring consumers to file complaints or request changes.&lt;ref name="Edwards"&gt;{{Cite journal|last1=Edwards|first1=Lilian|last2=Veale|first2=Michael|date=23 May 2017|title=Slave to the Algorithm? Why a Right to an Explanation Is Probably Not the Remedy You Are Looking For|ssrn=2972855|journal=Duke Law &amp; Technology Review|volume=16|pages=18–84|doi=10.2139/ssrn.2972855}}&lt;/ref&gt;

=== United States ===
The United States has no general legislation controlling algorithmic bias, approaching the problem through various state and federal laws that might vary by industry, sector, and by how an algorithm is used.&lt;ref name="Singer"&gt;{{cite news|last1=Singer|first1=Natasha|title=Consumer Data Protection Laws, an Ocean Apart|url=https://www.nytimes.com/2013/02/03/technology/consumer-data-protection-laws-an-ocean-apart.html|access-date=26 November 2017|work=The New York Times|date=2 February 2013}}&lt;/ref&gt; Many policies are self-enforced or controlled by the [[Federal Trade Commission]].&lt;ref name="Singer" /&gt; In 2016, the Obama administration released the [[National Artificial Intelligence Research and Development Strategic Plan]],&lt;ref name="ObamaAdmin"&gt;{{cite web|last1=Obama|first1=Barack|title=The Administration's Report on the Future of Artificial Intelligence|url=https://obamawhitehouse.archives.gov/blog/2016/10/12/administrations-report-future-artificial-intelligence|website=whitehouse.gov|publisher=National Archives|access-date=26 November 2017|date=12 October 2016}}&lt;/ref&gt; which was intended to guide policymakers toward a critical assessment of algorithms. It recommended researchers to "design these systems so that their actions and decision-making are transparent and easily interpretable by humans, and thus can be examined for any bias they may contain, rather than just learning and repeating these biases". Intended only as guidance, the report did not create any legal precedent.&lt;ref name="NSTC"&gt;{{cite book|last1=and Technology Council|first1=National Science|title=National Artificial Intelligence Research and Development Strategic Plan|date=2016|publisher=US Government|url=https://obamawhitehouse.archives.gov/sites/default/files/whitehouse_files/microsites/ostp/NSTC/national_ai_rd_strategic_plan.pdf|access-date=26 November 2017}}&lt;/ref&gt;{{rp|26}}

In 2017, [[New York City]] passed the first algorithmic accountability bill in the United States.&lt;ref name="Kirchner"&gt;{{cite web |last1=Kirchner |first1=Lauren |title=New York City Moves to Create Accountability for Algorithms — ProPublica |url=https://www.propublica.org/article/new-york-city-moves-to-create-accountability-for-algorithms |website=ProPublica |publisher=ProPublica |access-date=28 July 2018 |date=18 December 2017}}&lt;/ref&gt; The bill, which went into effect on January 1, 2018, required "the creation of a task force that provides recommendations on how information on agency automated decision systems may be shared with the public, and how agencies may address instances where people are harmed by agency automated decision systems."&lt;ref name="NYC"&gt;{{cite web |title=The New York City Council - File #: Int 1696-2017 |url=http://legistar.council.nyc.gov/LegislationDetail.aspx?ID=3137815&amp;GUID=437A6A6D-62E1-47E2-9C42-461253F9C6D0 |website=legistar.council.nyc.gov |publisher=New York City Council |access-date=28 July 2018 }}&lt;/ref&gt; The task force is required to present findings and recommendations for further regulatory action in 2019.&lt;ref name="Powles"&gt;{{cite web |last1=Powles |first1=Julia |title=New York City's Bold, Flawed Attempt to Make Algorithms Accountable |url=https://www.newyorker.com/tech/elements/new-york-citys-bold-flawed-attempt-to-make-algorithms-accountable |website=The New Yorker |publisher=The New Yorker |access-date=28 July 2018}}&lt;/ref&gt;

=== India ===
On July 31, 2018, a draft of the Personal Data Bill was presented.&lt;ref&gt;{{Cite web|url=https://www.insurancejournal.com/news/international/2018/07/31/496489.htm|title=India Weighs Comprehensive Data Privacy Bill, Similar to EU's GDPR|date=2018-07-31|website=Insurance Journal|access-date=2019-02-26}}&lt;/ref&gt; The draft proposes standards for the storage, processing and transmission of data. While it does not use the term algorithm, it makes for provisions for "...harm resulting from any processing or any kind of processing undertaken by the fiduciary". It defines ''"any denial or withdrawal of a service, benefit or good resulting from an evaluative decision about the data principal"'' or ''"any discriminatory treatment"''  as a source of harm that could arise from improper use of data. It also makes special provisions for people of "Intersex status”.&lt;ref&gt;https://meity.gov.in/writereaddata/files/Personal_Data_Protection_Bill,2018.pdf&lt;/ref&gt;

== See also ==

* [[Ethics of artificial intelligence]]

== Further reading ==
* {{cite book |last1=Baer |first1=Tobias |date=2019 |title=Understand, Manage, and Prevent Algorithmic Bias: A Guide for Business Users and Data Scientists |isbn=9781484248843 |location=New York |publisher=Apress |url=https://www.springer.com/us/book/9781484248843}}
* {{cite book |last1=Noble |first1=Safiya Umoja |date=2018 |title=Algorithms of oppression: How search engines reinforce racism |isbn=9781479837243 |location=New York |publisher=New York University Press |url=https://en.wikipedia.org/wiki/Algorithms_of_Oppression}}
* [[Fairness (machine learning)]]

== References ==
{{Reflist}}

[[Category:Machine learning]]
[[Category:Information ethics]]
[[Category:Computing and society]]
[[Category:Philosophy of artificial intelligence]]
[[Category:Discrimination]]
[[Category:Bias]]</text>
      <sha1>schfk7ldv1sdwk01vc9mwjv520og8h3</sha1>
    </revision>
  </page>
  <page>
    <title>Automated machine learning</title>
    <ns>0</ns>
    <id>55843837</id>
    <revision>
      <id>1002595487</id>
      <parentid>1002594957</parentid>
      <timestamp>2021-01-25T04:44:42Z</timestamp>
      <contributor>
        <username>Fuzheado</username>
        <id>15130</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/45.115.91.54|45.115.91.54]] ([[User talk:45.115.91.54|talk]]): using Wikipedia for [[WP:NOTADVERTISING|advertising/promotion]] ([[WP:HG|HG]]) (3.4.10)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="5126" xml:space="preserve">{{short description|Automated machine learning or AutoML is the process of automating the end-to-end process of machine learning.}}
{{multiple issues|{{incomprehensible|date=November 2018}}
{{technical|date=November 2018}}
{{prose|date=March 2018}}}}

{{Machine learning bar}}

'''Automated machine learning''' ('''AutoML''') is the process of [[automation|automating]] the process of applying [[machine learning]] to real-world problems. AutoML covers the complete pipeline from the raw dataset to the deployable machine learning model. AutoML was proposed as an [[artificial intelligence]]-based solution to the ever-growing challenge of applying machine learning.&lt;ref name="autoweka1"&gt;{{cite conference|year=2013|title=Auto-WEKA: Combined Selection and Hyperparameter Optimization of Classification Algorithms|url=https://dl.acm.org/citation.cfm?id=2487629|conference=KDD '13 Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining|pages=847–855|vauthors=Thornton C, Hutter F, Hoos HH, Leyton-Brown K}}&lt;/ref&gt;&lt;ref name="AutoML2014ICML"/&gt; The high degree of automation in AutoML allows non-experts to make use of machine learning models and techniques without requiring becoming an expert in the field first. 

Automating the process of applying machine learning end-to-end additionally offers the advantages of producing simpler solutions, faster creation of those solutions, and models that often outperform hand-designed models. 

== Comparison to the standard approach ==
In a typical machine learning application, practitioners have a set of input data points to train on. The raw data may not be in a form that all algorithms can be applied to it. To make the data amenable for machine learning, an expert may have to apply appropriate [[data pre-processing]], [[feature engineering]], [[feature extraction]], and [[feature selection]] methods. After these steps, practitioners must then perform [[algorithm selection]] and [[hyperparameter optimization]] to maximize the predictive performance of their model. All of these steps induce challenges, accumulating to a significant hurdle to get started with machine learning.

AutoML dramatically simplifies these steps for non-experts.

==Targets of automation==
Automated machine learning can target various stages of the machine learning process.&lt;ref name="AutoML2014ICML"&gt;{{Cite web|title=AutoML 2014 @ ICML|vauthors=Hutter F, Caruana R, Bardenet R, Bilenko M, Guyon I, Kegl B, and Larochelle H|work=AutoML 2014 Workshop @ ICML|access-date=2018-03-28|url=http://icml2014.automl.org}}&lt;/ref&gt;  Steps to automate are:
*[[Data preparation]] and ingestion (from raw data and miscellaneous formats)
** Column [[Statistical data type|type]] detection; e.g., boolean, discrete numerical, continuous numerical, or text
** Column intent detection; e.g., target/label, [[Stratified sampling|stratification]] field, numerical feature, categorical text feature, or free text feature
** Task detection; e.g., [[binary classification]], [[regression analysis|regression]], [[Cluster analysis|clustering]], or [[learning to rank|ranking]]
*[[Feature engineering]]
**[[Feature selection]]
** [[Feature extraction]]
** [[Meta learning (computer science)|Meta learning]] and [[transfer learning]]
** Detection and handling of skewed data and/or missing values
*[[Model selection]]
* [[Hyperparameter optimization|Hyperparameter Optimization]] of the learning algorithm and featurization
* Pipeline selection under time, memory, and complexity constraints
* Selection of evaluation metrics and validation procedures
* Problem checking
** [[Leakage (machine learning)|Leakage]] detection
** Misconfiguration detection
* Analysis of results obtained
* User interfaces and visualizations for automated machine learning

==See also==
* [[Neural architecture search]]
* [[Neuroevolution]]
* [[Self-tuning]]
* [[Neural Network Intelligence]]
* [[AutoAI]]
* [[ModelOps]]

==References==
{{Reflist}}

==Further reading==
* {{Cite web|url=http://www.bizety.com/2020/06/16/open-source-automl-tools-autogluon-transmogrifai-auto-sklearn-and-nni/|title=Open Source AutoML Tools: AutoGluon, TransmogrifAI, Auto-sklearn, and NNI|website=Bizety|date=2020-06-16}}

==External links==
* [https://docs.microsoft.com/uk-UA/azure/machine-learning/concept-automated-ml Azure ML documentation – What is AutoML?] – [[Microsoft Azure]] cloud service documentation
* [https://cloud.google.com/automl Google Cloud AutoML], AutoML solution on [[Google Cloud Platform]]
* [https://www.ibm.com/cloud/watson-studio/autoai AutoAI with IBM Watson Studio]: automation of data preparation, model development, feature engineering, and hyper-parameter optimization in [[IBM Watson Studio]]
* [https://docs.cloud.oracle.com/en-us/iaas/tools/ads-sdk/latest/user_guide/automl/overview.html The Oracle AutoML Pipeline], documentation of Oracle Accelerated Data Science (ADS) SDK, a Python library included as part of the [[Oracle Cloud]] Infrastructure [https://www.oracle.com/data-science/ Data Science] service

[[Category:Machine learning]]
[[Category:Artificial intelligence]]</text>
      <sha1>7l56didv9znmv62bmssm7zayu0171z6</sha1>
    </revision>
  </page>
  <page>
    <title>Proaftn</title>
    <ns>0</ns>
    <id>30992863</id>
    <revision>
      <id>994776697</id>
      <parentid>980775032</parentid>
      <timestamp>2020-12-17T13:54:08Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 8 templates: del empty params (4×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="4598" xml:space="preserve">'''Proaftn''' is a [[fuzzy classification]] method that belongs to the class of [[supervised learning]] [[algorithms]]. The [[acronym]] Proaftn stands for: (PROcédure d'Affectation Floue pour la problématique du Tri Nominal), which means in English: [[Fuzzy logic|Fuzzy]] Assignment Procedure for Nominal [[Sorting]].
 
The method enables to determine the fuzzy indifference relations by generalizing the indices (concordance and discordance) used in the [[ELECTRE]] III method.&lt;ref&gt;{{cite book|last=Roy|first=B.|title= Multicriteria Methodology for Decision Aiding | publisher = Kluwer Academic|location = Dordrecht|year = 1996}}&lt;/ref&gt; To determine the fuzzy indifference relations, PROAFTN uses the general scheme of the [[Discretization of continuous features|discretization]] technique described in,&lt;ref&gt;{{cite journal|last=Ching |first = J.Y.| title = Class-dependent discretization for inductive learning from continuous and mixed-mode data|journal=IEEE Transactions on Pattern Analysis and Machine Intelligence|volume=17|issue = 7|pages=641–651|doi=10.1109/34.391407|year = 1995}}&lt;/ref&gt; that establishes a set of pre-classified cases called a training set.

To resolve the classification problems, Proaftn proceeds by the following stages:&lt;ref&gt;{{cite journal|title= Multicriteria assignment method PROAFTN: Methodology and medical application|journal=European Journal of Operational Research|year=2000|first=N.|last=Belacel |volume=125|issue=3|pages=175–83|doi=10.1016/s0377-2217(99)00192-7}}&lt;/ref&gt;

Stage 1. Modeling of classes: In this stage, the prototypes of the classes are conceived using the two following steps:

*Step 1. Structuring: The prototypes and their parameters (thresholds, weights, etc.) are established using the available knowledge given by the expert.
*Step 2. Validation: We use one of the two following techniques in order to validate or adjust the parameters obtained in the first step through the assignment  examples known as a training set.
 
Direct technique: It consists in adjusting the parameters through the training set and with the expert intervention.

Indirect technique: It consists in fitting the parameters without the expert intervention as used in [[machine learning]] approaches.&lt;ref&gt;{{cite journal|last=Doumpos|first=M.|author2=Zopounidis, C.|title=Preference disaggregation and statistical learning for multicriteria decision support: A review|journal=European Journal of Operational Research|year=2011|volume=209|issue=3|pages=203–214|doi=10.1016/j.ejor.2010.05.029}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|title=Learning multicriteria fuzzy classification method PROAFTN from data |journal=Computers &amp; Operations Research|year=2007|first=N.|last=Belacel |author2= Rava, H. B.l |author3= Punnen, A. P.|volume=34|issue=7| pages=1885–1898|doi=10.1016/j.cor.2005.07.019|url=https://nrc-publications.canada.ca/eng/view/accepted/?id=ce2dc2ef-277f-40ee-a2d5-13d4aa4211bc}}&lt;/ref&gt; 
   
In [[multicriteria classification]] problem, the indirect technique is known as ''preference disaggregation analysis''.&lt;ref&gt;{{cite journal|last=Jacquet-Lagrèze|first=E.|author2=Siskos, J.|title=Preference disaggregation: Twenty years of MCDA experience|journal=European Journal of Operational Research|year=2001|volume=130|issue=2|pages=233–245|doi=10.1016/s0377-2217(00)00035-7}}&lt;/ref&gt; This technique requires less cognitive effort than the former technique; it uses an automatic method to determine the optimal parameters, which minimize the classification errors.
  
Furthermore, several [[heuristics]] and [[metaheuristics]] were used to learn the multicriteria classification method Proaftn.&lt;ref&gt;{{cite journal|title=An evolutionary framework using particle swarm optimization for classification method PROAFTN|journal= Applied Soft Computing|year=2011|first=F.|last=Al-Obeidat|volume=11|issue=8|pages=4971–4980|doi=10.1016/j.asoc.2011.06.003|url= https://nrc-publications.canada.ca/eng/view/accepted/?id=ab0d4beb-dfd6-4ec8-97e3-2f052515ccdd|display-authors=etal}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|title=Differential Evolution for learning the classification method PROAFTN|journal= Knowledge Based System|year=2010|first=f.|last=Al-Obeidat|volume=23|issue=5|pages= 418–426 |doi=10.1016/j.knosys.2010.02.003|display-authors=etal}}&lt;/ref&gt;

Stage 2. Assignment: After conceiving the prototypes, Proaftn proceeds to assign the new objects to specific classes.

==References==
{{reflist}}

== External links ==
* [http://mcsc2.ist.utl.pt/index.html Site dedicated to the sorting problematic of MCDA]

[[Category: Machine learning]]
[[Category: Statistical classification]]</text>
      <sha1>mzcpbfj9do93gmjj4bgpapujgnk6ujc</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Signal processing conferences</title>
    <ns>14</ns>
    <id>55964407</id>
    <revision>
      <id>813614631</id>
      <timestamp>2017-12-04T09:56:25Z</timestamp>
      <contributor>
        <username>Ai-zahran</username>
        <id>32469043</id>
      </contributor>
      <comment>[[WP:AES|←]]Created page with '[[Academic conference]]s related to [[signal processing]], [[machine learning]] and [[pattern recognition]].  [[Category:Artificial intelligence|Conferences]] ...'</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="242" xml:space="preserve">[[Academic conference]]s related to [[signal processing]], [[machine learning]] and [[pattern recognition]].

[[Category:Artificial intelligence|Conferences]]
[[Category:Machine learning|Conferences]]
[[Category:Computer science conferences]]</text>
      <sha1>2eqmrbse2qro1a3oeix46zylyl3ns1r</sha1>
    </revision>
  </page>
  <page>
    <title>List of datasets for machine-learning research</title>
    <ns>0</ns>
    <id>49082762</id>
    <revision>
      <id>1004367328</id>
      <parentid>1004366740</parentid>
      <timestamp>2021-02-02T07:35:08Z</timestamp>
      <contributor>
        <ip>14.201.32.111</ip>
      </contributor>
      <comment>/* Transit */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="248432" xml:space="preserve">{{Use dmy dates|date=September 2017}}
{{machine learning bar}}

These [[data set|datasets]] are used for [[machine-learning]] research and have been cited in [[Peer review|peer-reviewed]] academic journals. Datasets are an integral part of the field of machine learning. Major advances in this field can result from advances in learning [[algorithm]]s (such as [[deep learning]]), computer hardware, and, less-intuitively, the availability of high-quality training datasets.&lt;ref&gt;{{cite web|url = https://edge.org/response-detail/26587|title = Datasets Over Algorithms|publisher = Edge.com|access-date = 8 January 2016|last = Wissner-Gross|first = A.}}&lt;/ref&gt; High-quality labeled training datasets for [[Supervised learning|supervised]] and [[Semi-supervised learning|semi-supervised]] machine learning algorithms are usually difficult and expensive to produce because of the large amount of time needed to label the data. Although they do not need to be labeled, high-quality datasets for [[Unsupervised learning|unsupervised]] learning can also be difficult and costly to produce.&lt;ref&gt;{{cite journal | last1=Weiss | first1=G. M. | last2=Provost | first2=F. | title=Learning When Training Data are Costly: The Effect of Class Distribution on Tree Induction | journal=Journal of Artificial Intelligence Research | publisher=AI Access Foundation | volume=19 | date=September 1, 2003 | issn=1076-9757 | doi=10.1613/jair.1199 | pages=315–354 | s2cid=2344521 |url=https://www.jair.org/index.php/jair/article/download/10346/24739}}&lt;/ref&gt;&lt;ref&gt;{{cite arXiv |last=Turney |first=Peter |title=Types of cost in inductive concept learning |year=2000 |eprint=cs/0212034}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last=Abney|first=Steven|title=Semisupervised Learning for Computational Linguistics|url=https://books.google.com/books?id=VCd67cGB_rAC&amp;pg=PP1|date=September 17, 2007|publisher=CRC Press|isbn=978-1-4200-1080-0}}&lt;/ref&gt;&lt;ref&gt;{{cite book | last1=Žliobaitė | first1=Indrė | last2=Bifet | first2=Albert | last3=Pfahringer | first3=Bernhard | last4=Holmes | first4=Geoff | title=Machine Learning and Knowledge Discovery in Databases | chapter=Active Learning with Evolving Streaming Data | publisher=Springer Berlin Heidelberg | location=Berlin, Heidelberg | year=2011 | isbn=978-3-642-23807-9 | issn=0302-9743 | doi=10.1007/978-3-642-23808-6_39 | pages=597–612}}&lt;/ref&gt;

== Image data ==
Datasets consisting primarily of images or videos for tasks such as [[object detection]], [[Facial recognition system|facial recognition]], and [[multi-label classification]].

=== Facial recognition ===
In [[computer vision]], face images have been used extensively to develop [[facial recognition system]]s, [[face detection]], and many other projects that use images of faces.
{| class="wikitable sortable" style="width: 100%"
! scope="col" style="width: 15%;" |Dataset name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" |Creator
|-
|Aff-Wild
|298 videos of 200 individuals, ~1,250,000 manually annotated images: annotated in terms of dimensional affect (valence-arousal); in-the-wild setting; color database; various resolutions (average = 640x360)
|the detected faces, facial landmarks and valence-arousal annotations
|~1,250,000 manually annotated images
|video (visual + audio modalities)
|affect recognition (valence-arousal estimation)
|2017
|CVPR&lt;ref&gt;{{Cite journal|last1=Zafeiriou|first1=S.|last2=Kollias|first2=D.|last3=Nicolaou|first3=M.A.|last4=Papaioannou|first4=A.|last5=Zhao|first5=G.|last6=Kotsia|first6=I.|date=2017|title=Aff-Wild: Valence and Arousal in-the-wild Challenge|url=http://openaccess.thecvf.com/content_cvpr_2017_workshops/w33/papers/Zafeiriou_Aff-Wild_Valence_and_CVPR_2017_paper.pdf|journal=Computer Vision and Pattern Recognition Workshops (CVPRW), 2017|pages=1980–1987|doi=10.1109/CVPRW.2017.248|isbn=978-1-5386-0733-6|s2cid=3107614}}&lt;/ref&gt; 
IJCV&lt;ref&gt;{{Cite journal|last1=Kollias|first1=D.|last2=Tzirakis|first2=P.|last3=Nicolaou|first3=M.A.|last4=Papaioannou|first4=A.|last5=Zhao|first5=G.|last6=Schuller|first6=B.|last7=Kotsia|first7=I.|last8=Zafeiriou|first8=S.|date=2019|title=Deep Affect Prediction in-the-wild: Aff-Wild Database and Challenge, Deep Architectures, and Beyond|url=https://rdcu.be/bmGm2|journal=International Journal of Computer Vision (IJCV), 2019|volume=127|issue=6–7|pages=907–929|doi=10.1007/s11263-019-01158-4|s2cid=13679040}}&lt;/ref&gt;
|D.Kollias et al.
|-
|Aff-Wild2
|558 videos of 458 individuals, ~2,800,000 manually annotated images: annotated in terms of i) categorical affect (7 basic expressions: neutral, happiness, sadness, surprise, fear, disgust, anger); ii) dimensional affect (valence-arousal); iii) action units (AUs 1,2,4,6,12,15,20,25); in-the-wild setting; color database; various resolutions (average = 1030x630)
|the detected faces, detected and aligned faces and annotations
|~2,800,000 manually annotated images
|video (visual + audio modalities)
|affect recognition (valence-arousal estimation, basic expression classification, action unit detection)
|2019
|BMVC&lt;ref&gt;{{Cite journal|last1=Kollias|first1=D.|last2=Zafeiriou|first2=S.|date=2019|title=Expression, affect, action unit recognition: Aff-wild2, multi-task learning and arcface|url=https://bmvc2019.org/wp-content/uploads/papers/0399-paper.pdf|journal=British Machine Vision Conference (BMVC), 2019|arxiv=1910.04855}}&lt;/ref&gt;
FG&lt;ref&gt;{{Cite journal|last1=Kollias|first1=D.|last2=Schulc|first2=A.|last3=Hajiyev|first3=E.|last4=Zafeiriou|first4=S.|date=2020|title=Analysing affective behavior in the first abaw 2020 competition|url=https://www.computer.org/csdl/proceedings-article/fg/2020/307900a794/1kecIYu9wL6|journal=IEEE International Conference on Automatic Face and Gesture Recognition (FG), 2020|arxiv=2001.11409}}&lt;/ref&gt;
|D.Kollias et al.
|-
|[[FERET (facial recognition technology)]]
|11338 images of 1199 individuals in different positions and at different times.
|None.
|11,338
|Images
|Classification, face recognition
|2003
|&lt;ref name=":4"&gt;{{cite journal | last1 = Phillips | first1 = P. Jonathon | display-authors = et al | year = 1998 | title = The FERET database and evaluation procedure for face-recognition algorithms | journal = Image and Vision Computing | volume = 16 | issue = 5| pages = 295–306 | doi=10.1016/s0262-8856(97)00070-x}}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Wiskott | first1 = Laurenz | display-authors = et al | year = 1997 | title = Face recognition by elastic bunch graph matching | journal = IEEE Transactions on Pattern Analysis and Machine Intelligence | volume = 19 | issue = 7| pages = 775–779 | doi=10.1109/34.598235| citeseerx = 10.1.1.44.2321 }}&lt;/ref&gt;
|[[United States Department of Defense]]
|-
|Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS)
|7,356 video and audio recordings of 24 professional actors. 8 emotions each at two intensities.
|Files labelled with expression. Perceptual validation ratings provided by 319 raters.
|7,356
|Video, sound files
|Classification, face recognition, voice recognition
|2018
|&lt;ref&gt;{{Cite journal | doi=10.1371/journal.pone.0196391| pmid=29768426| pmc=5955500| title=The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in North American English| journal=PLOS ONE| volume=13| issue=5| pages=e0196391| year=2018| last1=Livingstone| first1=Steven R.| last2=Russo| first2=Frank A.| bibcode=2018PLoSO..1396391L}}&lt;/ref&gt;&lt;ref&gt;{{Cite book | doi=10.5281/zenodo.1188976| year=2018| last1=Livingstone| first1=Steven R.| title=The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS)| last2=Russo| first2=Frank A.| chapter=Emotion}}&lt;/ref&gt;
|S.R. Livingstone and F.A. Russo
|-
|SCFace
|Color images of faces at various angles.
|Location of facial features extracted. Coordinates of features given.
|4,160
|Images, text
|[[Statistical classification|Classification]], face recognition
|2011
|&lt;ref name=":0"&gt;{{cite journal | last1 = Grgic | first1 = Mislav | last2 = Delac | first2 = Kresimir | last3 = Grgic | first3 = Sonja | year = 2011 | title = SCface–surveillance cameras face database | journal = Multimedia Tools and Applications | volume = 51 | issue = 3| pages = 863–879 | doi = 10.1007/s11042-009-0417-2 | s2cid = 207218990 }}&lt;/ref&gt;&lt;ref&gt;Wallace, Roy, et al. "[https://repository.ubn.ru.nl/bitstream/handle/2066/94489/94489.pdf Inter-session variability modelling and joint factor analysis for face authentication]." ''Biometrics (IJCB), 2011 International Joint Conference on''. IEEE, 2011.&lt;/ref&gt;
|M. Grgic et al.
|-
|Yale Face Database
|Faces of 15 individuals in 11 different expressions.
|Labels of expressions.
|165
|Images
|Face recognition
|1997
|&lt;ref&gt;{{cite journal | last1 = Georghiades | first1 = A | title = Yale face database | journal = Center For Computational Vision And Control At Yale University, http://CVC.yale.edu/Projects/Yalefaces/Yalefa | volume = 2 | page = 1997 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Nguyen | first1 = Duy | display-authors = et al | year = 2006 | title = Real-time face detection and lip feature extraction using field-programmable gate arrays | journal = IEEE Transactions on Systems, Man, and Cybernetics - Part B: Cybernetics| volume = 36 | issue = 4| pages = 902–912 | doi=10.1109/tsmcb.2005.862728| pmid = 16903373 | citeseerx = 10.1.1.156.9848 | s2cid = 7334355 }}&lt;/ref&gt;
|J. Yang et al.
|-
|Cohn-Kanade AU-Coded Expression Database
|Large database of images with labels for expressions.
|Tracking of certain facial features.
|500+ sequences
|Images, text
|Facial expression analysis
|2000
|&lt;ref&gt;Kanade, Takeo, Jeffrey F. Cohn, and Yingli Tian. "[http://www.ri.cmu.edu/pub_files/pub2/kanade_takeo_2000_1/kanade_takeo_2000_1.pdf Comprehensive database for facial expression analysis]." ''Automatic Face and Gesture Recognition, 2000. Proceedings. Fourth IEEE International Conference on''. IEEE, 2000.&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Zeng | first1 = Zhihong | display-authors = et al | year = 2009 | title = A survey of affect recognition methods: Audio, visual, and spontaneous expressions | journal = IEEE Transactions on Pattern Analysis and Machine Intelligence | volume = 31 | issue = 1| pages = 39–58 | doi=10.1109/tpami.2008.52| pmid = 19029545 | citeseerx = 10.1.1.144.217 }}&lt;/ref&gt;
|T. Kanade et al.
|-
|-
|JAFFE Facial Expression Database
|213 images of 7 facial expressions (6 basic facial expressions + 1 neutral) posed by 10 Japanese female models.
|Images are cropped to the facial region. Includes semantic ratings data on emotion labels.
|213
|Images, text
|Facial expression cognition
|1998
|&lt;ref&gt;{{Cite book | doi=10.5281/zenodo.3451524| year=1998| last1=Lyons| first1=Michael| title=The Japanese Female Facial Expression (JAFFE) Database| last2=Kamachi| first2=Miyuki| last3=Gyoba| first3=Jiro| chapter=Facial expression images}}&lt;/ref&gt;&lt;ref&gt;Lyons, Michael; Akamatsu, Shigeru; Kamachi, Miyuki; Gyoba, Jiro "[https://zenodo.org/record/3430156 Coding facial expressions with Gabor wavelets]." ''Automatic Face and Gesture Recognition, 1998. Proceedings. Third IEEE International Conference on''. IEEE, 1998.&lt;/ref&gt;
|Lyons, Kamachi, Gyoba
|-
|FaceScrub
|Images of public figures scrubbed from image searching.
|Name and m/f annotation.
|107,818
|Images, text
|Face recognition
|2014
|&lt;ref&gt;Ng, Hong-Wei, and Stefan Winkler. "[http://vintage.winklerbros.net/Publications/icip2014a.pdf A data-driven approach to cleaning large face datasets]." ''Image Processing (ICIP), 2014 IEEE International Conference on''. IEEE, 2014.&lt;/ref&gt;&lt;ref&gt;{{cite arXiv |eprint=1506.01342|last1=RoyChowdhury|first1=Aruni|title=One-to-many face recognition with bilinear CNNs|last2=Lin|first2=Tsung-Yu|last3=Maji|first3=Subhransu|last4=Learned-Miller|first4=Erik|class=cs.CV|year=2015}}&lt;/ref&gt;
|H. Ng et al.
|-
|BioID Face Database
|Images of faces with eye positions marked.
|Manually set eye positions.
|1521
|Images, text
|Face recognition
|2001
|&lt;ref&gt;Jesorsky, Oliver, Klaus J. Kirchberg, and Robert W. Frischholz. "Robust face detection using the hausdorff distance." ''Audio-and video-based biometric person authentication''. Springer Berlin Heidelberg, 2001.&lt;/ref&gt;&lt;ref&gt;Huang, Gary B., et al. ''[https://hal.inria.fr/docs/00/32/19/23/PDF/Huang_long_eccv2008-lfw.pdf Labeled faces in the wild: A database for studying face recognition in unconstrained environments]''. Vol. 1. No. 2. Technical Report 07-49, University of Massachusetts, Amherst, 2007.&lt;/ref&gt;
|BioID
|-
|Skin Segmentation Dataset
|Randomly sampled color values from face images.
|B, G, R, values extracted.
|245,057
|Text
|Segmentation, classification
|2012
|&lt;ref&gt;Bhatt, Rajen B., et al. "[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.708.9158&amp;rep=rep1&amp;type=pdf Efficient skin region segmentation using low complexity fuzzy decision tree model]." ''India Conference (INDICON), 2009 Annual IEEE''. IEEE, 2009.&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Lingala | first1 = Mounika | display-authors = et al | year = 2014 | title = Fuzzy logic color detection: Blue areas in melanoma dermoscopy images | journal = Computerized Medical Imaging and Graphics | volume = 38 | issue = 5| pages = 403–410 | doi=10.1016/j.compmedimag.2014.03.007| pmid = 24786720 | pmc = 4287461 }}&lt;/ref&gt;
|R. Bhatt.
|-
|Bosphorus
|3D Face image database.
|34 action units and 6 expressions labeled; 24 facial landmarks labeled.
|4652
|
Images, text

|Face recognition, classification
|2008
|&lt;ref&gt;Maes, Chris, et al. "[https://lirias.kuleuven.be/retrieve/135678 Feature detection on 3D face surfaces for pose normalisation and recognition]." ''Biometrics: Theory Applications and Systems (BTAS), 2010 Fourth IEEE International Conference on''. IEEE, 2010.&lt;/ref&gt;&lt;ref&gt;Savran, Arman, et al. "[https://pdfs.semanticscholar.org/4254/fbba3846008f50671edc9cf70b99d7304543.pdf Bosphorus database for 3D face analysis]." ''Biometrics and Identity Management''. Springer Berlin Heidelberg, 2008. 47–56.&lt;/ref&gt;
|A Savran et al.
|-
|UOY 3D-Face
|neutral face, 5 expressions: anger, happiness, sadness, eyes closed, eyebrows raised.
|labeling.
|5250
|
Images, text

|Face recognition, classification
|2004
|&lt;ref&gt;Heseltine, Thomas, Nick Pears, and Jim Austin. "[http://eprints.whiterose.ac.uk/1526/01/austinj4.pdf Three-dimensional face recognition: An eigensurface approach]." ''Image Processing, 2004. ICIP'04. 2004 International Conference on''. Vol. 2. IEEE, 2004.&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Ge | first1 = Yun | display-authors = et al | year = 2011 | title = 3D Novel Face Sample Modeling for Face Recognition | journal = Journal of Multimedia | volume = 6 | issue = 5| pages = 467–475 | doi=10.4304/jmm.6.5.467-475| citeseerx = 10.1.1.461.9710 }}&lt;/ref&gt;
|[[University of York]]
|-
|CASIA 3D Face Database
|Expressions: Anger, smile, laugh, surprise, closed eyes.
|None.
|4624
|
Images, text

|Face recognition, classification
|2007
|&lt;ref&gt;{{cite journal | last1 = Wang | first1 = Yueming | last2 = Liu | first2 = Jianzhuang | last3 = Tang | first3 = Xiaoou | year = 2010 | title = Robust 3D face recognition by local shape difference boosting | journal = IEEE Transactions on Pattern Analysis and Machine Intelligence | volume = 32 | issue = 10| pages = 1858–1870 | doi=10.1109/tpami.2009.200| pmid = 20724762 | citeseerx = 10.1.1.471.2424 | s2cid = 15263913 }}&lt;/ref&gt;&lt;ref&gt;Zhong, Cheng, Zhenan Sun, and Tieniu Tan. "[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.580.8534&amp;rep=rep1&amp;type=pdf Robust 3D face recognition using learned visual codebook]." ''Computer Vision and Pattern Recognition, 2007. CVPR'07. IEEE Conference on''. IEEE, 2007.&lt;/ref&gt;
|[[Institute of Automation, Chinese Academy of Sciences]]
|-
|CASIA NIR
|Expressions: Anger Disgust Fear Happiness Sadness Surprise
|None.
|480
|Annotated Visible Spectrum and Near Infrared Video captures at 25 frames per second
|Face recognition, classification
|2011
|&lt;ref&gt;{{cite journal | last1 = Zhao | first1 = G. | last2 = Huang | first2 = X. | last3 = Taini | first3 = M. | last4 = Li | first4 = S. Z. | last5 = Pietikäinen | first5 = M. | year = 2011 | title = Facial expression recognition from near-infrared videos | url = http://www.academia.edu/download/42229488/Image_and_Vision_Computing20160206-29020-1auzaon.pdf | journal = Image and Vision Computing | volume = 29 | issue = 9| pages = 607–619 | doi = 10.1016/j.imavis.2011.07.002 }}&lt;/ref&gt;
|Zhao, G. et al.
|-
|BU-3DFE
|neutral face, and 6 expressions: anger, happiness, sadness, surprise, disgust, fear (4 levels). 3D images extracted.
|None.
|2500
|Images, text
|Facial expression recognition, classification
|2006
|&lt;ref&gt;Soyel, Hamit, and Hasan Demirel. "[https://pdfs.semanticscholar.org/cf81/4b618fcbc9a556cdce225e74a8806867ba84.pdf Facial expression recognition using 3D facial feature distances]." ''Image Analysis and Recognition''. Springer Berlin Heidelberg, 2007. 831–838.&lt;/ref&gt;
|[[Binghamton University]]
|-
|[[Face Recognition Grand Challenge]] Dataset
|Up to 22 samples for each subject. Expressions: anger, happiness, sadness, surprise, disgust, puffy. 3D Data.
|None.
|4007
|Images, text
|Face recognition, classification
|2004
|&lt;ref&gt;{{cite journal | last1 = Bowyer | first1 = Kevin W. | last2 = Chang | first2 = Kyong | last3 = Flynn | first3 = Patrick | year = 2006 | title = A survey of approaches and challenges in 3D and multi-modal 3D+ 2D face recognition | journal = Computer Vision and Image Understanding | volume = 101 | issue = 1| pages = 1–15 | doi=10.1016/j.cviu.2005.05.005| citeseerx = 10.1.1.134.8784 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Tan | first1 = Xiaoyang | last2 = Triggs | first2 = Bill | year = 2010 | title = Enhanced local texture feature sets for face recognition under difficult lighting conditions | journal = IEEE Transactions on Image Processing| volume = 19 | issue = 6| pages = 1635–1650 | doi=10.1109/tip.2010.2042645| pmid = 20172829 | bibcode = 2010ITIP...19.1635T | citeseerx = 10.1.1.105.3355 | s2cid = 4943234 }}&lt;/ref&gt;
|[[National Institute of Standards and Technology]]
|-
|Gavabdb
|Up to 61 samples for each subject. Expressions neutral face, smile, frontal accentuated laugh, frontal random gesture. 3D images.
|None.
|549
|Images, text
|Face recognition, classification
|2008
|&lt;ref&gt;Mousavi, Mir Hashem, Karim Faez, and Amin Asghari. "[https://ieeexplore.ieee.org/abstract/document/4529822/ Three dimensional face recognition using SVM classifier]." ''Computer and Information Science, 2008. ICIS 08. Seventh IEEE/ACIS International Conference on''. IEEE, 2008.&lt;/ref&gt;&lt;ref&gt;Amberg, Brian, Reinhard Knothe, and Thomas Vetter. "[https://gravis.dmi.unibas.ch/publications/2008/FG08_Amberg.pdf Expression invariant 3D face recognition with a morphable model]." ''Automatic Face &amp; Gesture Recognition, 2008. FG'08. 8th IEEE International Conference on''. IEEE, 2008.&lt;/ref&gt;
|[[King Juan Carlos University]]
|-
|3D-RMA
|Up to 100 subjects, expressions mostly neutral. Several poses as well.
|None.
|9971
|Images, text
|Face recognition, classification
|2004
|&lt;ref&gt;İrfanoğlu, M. O., Berk Gökberk, and Lale Akarun. "[https://www.researchgate.net/profile/Berk_Gokberk/publication/4090704_3D_Shape-based_face_recognition_using_automatically_registered_facial_surfaces/links/0fcfd50ee9450e057a000000.pdf 3D shape-based face recognition using automatically registered facial surfaces]." ''Pattern Recognition, 2004. ICPR 2004. Proceedings of the 17th International Conference on''. Vol. 4. IEEE, 2004.&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Beumier | first1 = Charles | last2 = Acheroy | first2 = Marc | year = 2001 | title = Face verification from 3D and grey level clues | journal = Pattern Recognition Letters | volume = 22 | issue = 12| pages = 1321–1329 | doi=10.1016/s0167-8655(01)00077-0}}&lt;/ref&gt;
|[[Royal Military Academy (Belgium)]]
|-
|SoF
|112 persons (66 males and 46 females) wear glasses under different illumination conditions.
|A set of synthetic filters (blur, occlusions, noise, and posterization ) with different level of difficulty.
|42,592 (2,662 original image × 16 synthetic image)
|Images, Mat file
|Gender classification, face detection, face recognition, age estimation, and glasses detection
|2017
|&lt;ref&gt;{{cite arxiv|last1=Afifi|first1=Mahmoud|last2=Abdelhamed|first2=Abdelrahman|date=2017-06-13|title=AFIF4: Deep Gender Classification based on AdaBoost-based Fusion of Isolated Facial Features and Foggy Faces|eprint=1706.04277|class=cs.CV}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://sites.google.com/view/sof-dataset|title=SoF dataset|website=sites.google.com|language=en-US|access-date=2017-11-18}}&lt;/ref&gt;
|Afifi, M. et al.
|-
|IMDB-WIKI
|IMDB and Wikipedia face images with gender and age labels.
| None
| 523,051
|Images
|Gender classification, face detection, face recognition, age estimation
|2015
|&lt;ref&gt;{{Cite web|url=https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/|title=IMDB-WIKI|website=data.vision.ee.ethz.ch|language=en-US|access-date=2018-03-13}}&lt;/ref&gt;
|R. Rothe, R. Timofte, L. V. Gool 
|}

=== Action recognition ===
{| class="wikitable sortable" style="width: 100%"
! scope="col" style="width: 15%;" |Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" |Creator
|-
|TV Human Interaction Dataset
|Videos from 20 different TV shows for prediction social actions: handshake, high five, hug, kiss and none.
|None.
|6,766 video clips
|video clips
|Action prediction
|2013
|&lt;ref&gt;{{cite journal | last1 = Patron-Perez | first1 = A. | last2 = Marszalek | first2 = M. | last3 = Reid | first3 = I. | last4 = Zisserman | first4 = A. | year = 2012 | title = Structured learning of human interactions in TV shows | journal = IEEE Transactions on Pattern Analysis and Machine Intelligence | volume = 34 | issue = 12| pages = 2441–2453 | doi=10.1109/tpami.2012.24| pmid = 23079467 | s2cid = 6060568 }}&lt;/ref&gt;
|Patron-Perez, A. et al.
|-
|Berkeley Multimodal Human Action Database (MHAD)
|Recordings of a single person performing 12 actions
|MoCap pre-processing
|660 action samples
|8 PhaseSpace Motion Capture, 2 Stereo Cameras, 4 Quad Cameras, 6 accelerometers, 4 microphones
|Action classification
|2013
|&lt;ref&gt;Ofli, F., Chaudhry, R., Kurillo, G., Vidal, R., &amp; Bajcsy, R. (January 2013). [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.432.5113&amp;rep=rep1&amp;type=pdf Berkeley MHAD: A comprehensive multimodal human action database]. In Applications of Computer Vision (WACV), 2013 IEEE Workshop on (pp. 53–60). IEEE.&lt;/ref&gt;
|Ofli, F. et al.
|-
|THUMOS Dataset
|Large video dataset for action classification.
|Actions classified and labeled.
|45M frames of video
|Video, images, text
|Classification, action detection
|2013
|&lt;ref&gt;Jiang, Y. G., et al. "THUMOS challenge: Action recognition with a large number of classes." ''ICCV Workshop on Action Recognition with a Large Number of Classes'', http://crcv.ucf.edu/ICCV13-Action-Workshop. 2013.&lt;/ref&gt;&lt;ref&gt;Simonyan, Karen, and Andrew Zisserman. "[https://papers.nips.cc/paper/5353-two-stream-convolutional-networks-for-action-recognition-in-videos.pdf Two-stream convolutional networks for action recognition in videos]." ''Advances in Neural Information Processing Systems''. 2014.&lt;/ref&gt;
|Y. Jiang et al.
|-
|MEXAction2
|Video dataset for action localization and spotting 
|Actions classified and labeled.
|1000
|Video
|Action detection
|2014
|&lt;ref&gt;{{cite journal |doi=10.1109/TCSVT.2015.2475835|title=Fast Action Localization in Large-Scale Video Archives|journal=IEEE Transactions on Circuits and Systems for Video Technology|volume=26|issue=10|pages=1917–1930|year=2016|last1=Stoian|first1=Andrei|last2=Ferecatu|first2=Marin|last3=Benois-Pineau|first3=Jenny|last4=Crucianu|first4=Michel|s2cid=31537462}}&lt;/ref&gt;
|Stoian et al.
|}

=== Object detection and recognition ===
{| class="wikitable sortable" style="width: 100%"
! scope="col" style="width: 15%;" |Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" |Creator
|-
|Visual Genome
|Images and their description
|
|108,000
|images, text
|Image captioning
|2016
|&lt;ref&gt;{{Cite journal|doi=10.1007/s11263-016-0981-7|title=Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations|journal=International Journal of Computer Vision|volume=123|pages=32–73|year=2017|last1=Krishna|first1=Ranjay|last2=Zhu|first2=Yuke|last3=Groth|first3=Oliver|last4=Johnson|first4=Justin|last5=Hata|first5=Kenji|last6=Kravitz|first6=Joshua|last7=Chen|first7=Stephanie|last8=Kalantidis|first8=Yannis|last9=Li|first9=Li-Jia|last10=Shamma|first10=David A|last11=Bernstein|first11=Michael S|last12=Fei-Fei|first12=Li|arxiv=1602.07332|s2cid=4492210}}&lt;/ref&gt;
|R. Krishna et al.
|-
|Berkeley 3-D Object Dataset
|849 images taken in 75 different scenes. About 50 different object classes are labeled.
|Object bounding boxes and labeling.
|849
|labeled images, text
|Object recognition
|2014
|&lt;ref name=":6"&gt;Karayev, S., et al. "[http://alliejanoch.com/iccvw2011.pdf A category-level 3-D object dataset: putting the Kinect to work]." ''Proceedings of the IEEE International Conference on Computer Vision Workshops''. 2011.&lt;/ref&gt;&lt;ref&gt;Tighe, Joseph, and Svetlana Lazebnik. "[http://152.2.128.56/~jtighe/Papers/ECCV10/eccv10-jtighe.pdf Superparsing: scalable nonparametric image parsing with superpixels]." ''Computer Vision–ECCV 2010''. Springer Berlin Heidelberg, 2010. 352–365.&lt;/ref&gt;
|A. Janoch et al.
|-
|Berkeley Segmentation Data Set and Benchmarks 500 (BSDS500)
|500 natural images, explicitly separated into disjoint train, validation and test subsets + benchmarking code. Based on BSDS300.
|Each image segmented by five different subjects on average.
|500
|Segmented images
|Contour detection and hierarchical image segmentation
|2011
|&lt;ref&gt;{{cite journal|last1=Arbelaez|first1=P.|last2=Maire|first2=M|last3=Fowlkes|first3=C|last4=Malik|first4=J|title=Contour Detection and Hierarchical Image Segmentation|journal=IEEE Transactions on Pattern Analysis and Machine Intelligence |date=May 2011|volume=33|issue=5|pages=898–916|url=http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/papers/amfm_pami2010.pdf|access-date=27 February 2016|doi=10.1109/tpami.2010.161|pmid=20733228|s2cid=206764694}}&lt;/ref&gt;
|[[University of California, Berkeley]]
|-
|Microsoft Common Objects in Context (COCO)
|complex everyday scenes of common objects in their natural context.
|Object highlighting, labeling, and classification into 91 object types.
|2,500,000
|Labeled images, text
|Object recognition
|2015
|&lt;ref&gt;Lin, Tsung-Yi, et al. "[https://arxiv.org/abs/1405.0312 Microsoft coco: Common objects in context]." ''Computer Vision–ECCV 2014''. Springer International Publishing, 2014. 740–755.&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Russakovsky | first1 = Olga | display-authors = et al | year = 2015 | title = Imagenet large scale visual recognition challenge | journal = International Journal of Computer Vision | volume = 115 | issue = 3| pages = 211–252 | doi=10.1007/s11263-015-0816-y| arxiv = 1409.0575 | hdl = 1721.1/104944 | s2cid = 2930547 }}&lt;/ref&gt;
|T. Lin et al.
|-
|SUN Database
|Very large scene and object recognition database.
|Places and objects are labeled. Objects are segmented.
|131,067
|Images, text
|Object recognition, scene recognition
|2014
|&lt;ref&gt;Xiao, Jianxiong, et al. "Sun database: Large-scale scene recognition from abbey to zoo." ''Computer vision and pattern recognition (CVPR), 2010 IEEE conference on''. IEEE, 2010.&lt;/ref&gt;&lt;ref&gt;{{cite arXiv |eprint=1310.1531|last1=Donahue|first1=Jeff|title=DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition |last2=Jia|first2=Yangqing|last3=Vinyals|first3=Oriol|last4=Hoffman|first4=Judy|last5=Zhang|first5=Ning|last6=Tzeng|first6=Eric|last7=Darrell|first7=Trevor|class=cs.CV|year=2013}}&lt;/ref&gt;
|J. Xiao et al.
|-
|[[ImageNet]]
|Labeled object image database, used in the [[ImageNet Large Scale Visual Recognition Challenge]]
|Labeled objects, bounding boxes, descriptive words, SIFT features 
|14,197,122
|Images, text
|Object recognition, scene recognition
|2009 (2014)
|&lt;ref&gt;Deng, Jia, et al. "[https://www.researchgate.net/profile/Li_Jia_Li/publication/221361415_ImageNet_a_Large-Scale_Hierarchical_Image_Database/links/00b495388120dbc339000000/ImageNet-a-Large-Scale-Hierarchical-Image-Database.pdf Imagenet: A large-scale hierarchical image database]."''Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on''. IEEE, 2009.&lt;/ref&gt;&lt;ref name=":02"/&gt;&lt;ref&gt;{{cite journal|last1=Russakovsky|first1=Olga|last2=Deng|first2=Jia|last3=Su|first3=Hao|last4=Krause|first4=Jonathan|last5=Satheesh|first5=Sanjeev|last6=Ma|first6=Sean|last7=Huang|first7=Zhiheng|last8=Karpathy|first8=Andrej|last9=Khosla|first9=Aditya|last10=Bernstein|first10=Michael|last11=Berg|first11=Alexander C.|last12=Fei-Fei|first12=Li|display-authors=5|title=ImageNet Large Scale Visual Recognition Challenge|journal=International Journal of Computer Vision|date=11 April 2015|volume=115|issue=3|pages=211–252|doi=10.1007/s11263-015-0816-y|arxiv=1409.0575|hdl=1721.1/104944|s2cid=2930547}}&lt;/ref&gt;
|J. Deng et al.
|-
|Open Images
|A Large set of images listed as having CC BY 2.0 license with image-level labels and bounding boxes spanning thousands of classes.
|Image-level labels, Bounding boxes
|9,178,275
|Images, text
|Classification, Object recognition
|2017
|&lt;ref&gt;Ivan Krasin, Tom Duerig, Neil Alldrin, Andreas Veit, Sami Abu-El-Haija, Serge Belongie, David Cai, Zheyun Feng, Vittorio Ferrari, Victor Gomes, Abhinav Gupta, Dhyanesh Narayanan, Chen Sun, Gal Chechik, Kevin Murphy. "OpenImages: A public dataset for large-scale multi-label and multi-class image classification, 2017. Available from https://github.com/openimages."&lt;/ref&gt;
|
|-
|TV News Channel Commercial Detection Dataset
|TV commercials and news broadcasts.
|Audio and video features extracted from still images.
|129,685
|Text
|Clustering, classification
|2015
|&lt;ref&gt;Vyas, Apoorv, et al. "[https://dl.acm.org/citation.cfm?id=2683546 Commercial Block Detection in Broadcast News Videos]." ''Proceedings of the 2014 Indian Conference on Computer Vision Graphics and Image Processing''. ACM, 2014.&lt;/ref&gt;&lt;ref&gt;Hauptmann, Alexander G., and Michael J. Witbrock. "[https://pdfs.semanticscholar.org/5c21/6db7892fa3f515d816f84893bfab1137f0b2.pdf Story segmentation and detection of commercials in broadcast news video]." ''Research and Technology Advances in Digital Libraries, 1998. ADL 98. Proceedings. IEEE International Forum on''. IEEE, 1998.&lt;/ref&gt;
|P. Guha et al.
|-
|Statlog (Image Segmentation) Dataset
|The instances were drawn randomly from a database of 7 outdoor images and hand-segmented to create a classification for every pixel.
|Many features calculated.
|2310
|Text
|Classification
|1990
|&lt;ref&gt;Tung, Anthony KH, Xin Xu, and Beng Chin Ooi. "[https://www.researchgate.net/profile/Anthony_Tung/publication/221214229_CURLER_Finding_and_Visualizing_Nonlinear_Correlated_Clusters/links/55b8691a08aed621de05cd92.pdf Curler: finding and visualizing nonlinear correlation clusters]." ''Proceedings of the 2005 ACM SIGMOD international conference on Management of data''. ACM, 2005.&lt;/ref&gt;
|[[University of Massachusetts]]
|-
|[[Caltech 101]]
|Pictures of objects.
|Detailed object outlines marked.
|9146
|Images
|Classification, object recognition.
|2003
|&lt;ref&gt;Jarrett, Kevin, et al. "[https://ieeexplore.ieee.org/abstract/document/5459469/ What is the best multi-stage architecture for object recognition?]." ''Computer Vision, 2009 IEEE 12th International Conference on''. IEEE, 2009.&lt;/ref&gt;&lt;ref&gt;Lazebnik, Svetlana, Cordelia Schmid, and Jean Ponce. "[https://hal.inria.fr/inria-00548585/document Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories]."''Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on''. Vol. 2. IEEE, 2006.&lt;/ref&gt;
|F. Li et al.
|-
|Caltech-256
|Large dataset of images for object classification.
|Images categorized and hand-sorted.
|30,607
|Images, Text
|Classification, object detection
|2007
|&lt;ref&gt;Griffin, G., A. Holub, and P. Perona. ''Caltech-256 object category dataset California Inst''. Technol., Tech. Rep. 7694, 2007 [Online]. Available: http://authors.library.caltech.edu/7694, 2007.&lt;/ref&gt;&lt;ref&gt;Baeza-Yates, Ricardo, and Berthier Ribeiro-Neto. ''Modern information retrieval''. Vol. 463. New York: ACM press, 1999.&lt;/ref&gt;
|G. Griffin et al.
|-
|SIFT10M Dataset
|SIFT features of Caltech-256 dataset.
|Extensive SIFT feature extraction.
|11,164,866
|Text
|Classification, object detection
|2016
|&lt;ref&gt;Fu, Xiping, et al. "[https://pdfs.semanticscholar.org/9da2/abae3072fd9fcff0e13b8f00fc21f22d0085.pdf NOKMeans: Non-Orthogonal K-means Hashing]." ''Computer Vision—ACCV 2014''. Springer International Publishing, 2014. 162–177.&lt;/ref&gt;
|X. Fu et al.
|-
|LabelMe
|Annotated pictures of scenes.
|Objects outlined.
|187,240
|Images, text
|Classification, object detection
|2005
|&lt;ref&gt;{{cite journal | last1 = Heitz | first1 = Geremy | display-authors = et al | year = 2009 | title = Shape-based object localization for descriptive classification | journal = International Journal of Computer Vision | volume = 84 | issue = 1| pages = 40–62 | doi=10.1007/s11263-009-0228-y| citeseerx = 10.1.1.142.280 | s2cid = 646320 }}&lt;/ref&gt;
|[[MIT Computer Science and Artificial Intelligence Laboratory]]
|-
|Cityscapes Dataset
|Stereo video sequences recorded in street scenes, with pixel-level annotations. Metadata also included.
|Pixel-level segmentation and labeling
|25,000
|Images, text
|Classification, object detection

|2016
|&lt;ref&gt;M. Cordts, M. Omran, S. Ramos, T. Scharwächter, M. Enzweiler, R. Benenson, U. Franke, S. Roth, and B. Schiele, "[https://www.cityscapes-dataset.com/wordpress/wp-content/papercite-data/pdf/cordts2015cvprw.pdf The Cityscapes Dataset]." In CVPR Workshop on The Future of Datasets in Vision, 2015.&lt;/ref&gt;
|[[Daimler AG]] et al.
|-
|PASCAL VOC Dataset
|Large number of images for classification tasks.
|Labeling, bounding box included
|500,000
|Images, text
|Classification, object detection
|2010
|&lt;ref&gt;{{cite journal | last1 = Everingham | first1 = Mark | display-authors = et al | year = 2010 | title = The pascal visual object classes (voc) challenge | url = https://www.research.ed.ac.uk/portal/en/publications/the-pascal-visual-object-classes-voc-challenge(88a29de3-6220-442b-ab2d-284210cf72d6).html| journal = International Journal of Computer Vision | volume = 88 | issue = 2| pages = 303–338 | doi=10.1007/s11263-009-0275-4| s2cid = 4246903 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Felzenszwalb | first1 = Pedro F. | display-authors = et al | year = 2010 | title = Object detection with discriminatively trained part-based models | journal = IEEE Transactions on Pattern Analysis and Machine Intelligence | volume = 32 | issue = 9| pages = 1627–1645 | doi=10.1109/tpami.2009.167| pmid = 20634557 | citeseerx = 10.1.1.153.2745 | s2cid = 3198903 }}&lt;/ref&gt;
|M. Everingham et al.
|-
|[[CIFAR-10]] Dataset
|Many small, low-resolution, images of 10 classes of objects.
|Classes labelled, training set splits created.
|60,000
|Images
|Classification
|2009
|&lt;ref name=":02"&gt;Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. "[http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf Imagenet classification with deep convolutional neural networks]." ''Advances in neural information processing systems''. 2012.&lt;/ref&gt;&lt;ref name=":12"&gt;Gong, Yunchao, and Svetlana Lazebnik. "Iterative quantization: A procrustean approach to learning binary codes." ''Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on''. IEEE, 2011.&lt;/ref&gt;
|A. Krizhevsky et al.
|-
|CIFAR-100 Dataset
|Like CIFAR-10, above, but 100 classes of objects are given.
|Classes labelled, training set splits created.
|60,000
|Images
|Classification
|2009
|&lt;ref name=":02"/&gt;&lt;ref name=":12"/&gt;
|A. Krizhevsky et al.
|-
|CINIC-10 Dataset
|A unified contribution of CIFAR-10 and Imagenet with 10 classes, and 3 splits. Larger than CIFAR-10.
|Classes labelled, training, validation, test set splits created.
|270,000
|Images
|Classification
|2018
|&lt;ref&gt;{{cite web|title=CINIC-10 dataset|url=http://www.bayeswatch.com/2018/10/09/CINIC/|website=Luke N. Darlow, Elliot J. Crowley, Antreas Antoniou, Amos J. Storkey (2018) CINIC-10 is not ImageNet or CIFAR-10|access-date=2018-11-13|date=2018-10-09}}&lt;/ref&gt;
|Luke N. Darlow, Elliot J. Crowley, Antreas Antoniou, Amos J. Storkey
|-
|Fashion-MNIST
|A MNIST-like fashion product database
|Classes labelled, training set splits created.
|60,000
|Images
|Classification
|2017
|&lt;ref&gt;{{Citation|title=fashion-mnist: A MNIST-like fashion product database. Benchmark :point_right|date=2017-10-07|url=https://github.com/zalandoresearch/fashion-mnist|publisher=Zalando Research|access-date=2017-10-07}}&lt;/ref&gt;
|Zalando SE
|-
|notMNIST
|Some publicly available fonts and extracted glyphs from them to make a dataset similar to MNIST. There are 10 classes, with letters A-J taken from different fonts.
|Classes labelled, training set splits created.
|500,000
|Images
|Classification
|2011
|&lt;ref&gt;{{cite web|title=notMNIST dataset|url=http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html|website=Machine Learning, etc|access-date=2017-10-13|date=2011-09-08}}&lt;/ref&gt;
|Yaroslav Bulatov
|-
|German Traffic Sign Detection Benchmark Dataset
|Images from vehicles of traffic signs on German roads. These signs comply with UN standards and therefore are the same as in other countries.
|Signs manually labeled
|900
|Images
|Classification
|2013
|&lt;ref&gt;Houben, Sebastian, et al. "[https://www.researchgate.net/profile/Sebastian_Houben/publication/242346625_Detection_of_Traffic_Signs_in_Real-World_Images_The_German_Traffic_Sign_Detection_Benchmark/links/0046352a03ec384e97000000/Detection-of-Traffic-Signs-in-Real-World-Images-The-German-Traffic-Sign-Detection-Benchmark.pdf Detection of traffic signs in real-world images: The German Traffic Sign Detection Benchmark]." ''Neural Networks (IJCNN), The 2013 International Joint Conference on''. IEEE, 2013.&lt;/ref&gt;&lt;ref&gt;Mathias, Mayeul, et al. "[http://www.varcity.eu/paper/ijcnn2013_mathias_trafficsign.pdf Traffic sign recognition—How far are we from the solution?]." ''Neural Networks (IJCNN), The 2013 International Joint Conference on''. IEEE, 2013.&lt;/ref&gt;
|S Houben et al.
|-
|KITTI Vision Benchmark Dataset
|Autonomous vehicles driving through a mid-size city captured images of various areas using cameras and laser scanners.
|Many benchmarks extracted from data.
|&gt;100 GB of data
|Images, text
|Classification, object detection
|2012
|&lt;ref&gt;Geiger, Andreas, Philip Lenz, and Raquel Urtasun. "[http://www.webmail.cvlibs.net/publications/Geiger2012CVPR.pdf Are we ready for autonomous driving? the kitti vision benchmark suite]." ''Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on''. IEEE, 2012.&lt;/ref&gt;&lt;ref&gt;Sturm, Jürgen, et al. "[http://jsturm.de/publications/data/sturm12iros.pdf A benchmark for the evaluation of RGB-D SLAM systems]." ''Intelligent Robots and Systems (IROS), 2012 IEEE/RSJ International Conference on''. IEEE, 2012.&lt;/ref&gt;
|A Geiger et al.
|-
|Linnaeus 5 dataset
|Images of 5 classes of objects.
|Classes labelled, training set splits created.
|8000
|Images
|Classification
|2017
|&lt;ref&gt;Chaladze, G., Kalatozishvili, L. (2017).&amp;nbsp;''Linnaeus 5 dataset''.&amp;nbsp;''Chaladze.com''. Retrieved 13 November 2017, from http://chaladze.com/l5/&lt;/ref&gt;
|Chaladze &amp; Kalatozishvili
|-
|FieldSAFE
|Multi-modal dataset for obstacle detection in agriculture including stereo camera, thermal camera, web camera, 360-degree camera, lidar, radar, and precise localization.
|Classes labelled geographically.
|&gt;400 GB of data
|Images and 3D point clouds
|Classification, object detection, object localization
|2017
|&lt;ref&gt;{{cite journal | last1 = Kragh | first1 = Mikkel F. | display-authors = et al | year = 2017 | title = FieldSAFE – Dataset for Obstacle Detection in Agriculture | url = https://vision.eng.au.dk/fieldsafe | journal = Sensors | volume = 17 | issue = 11 | pages =  2579| doi = 10.3390/s17112579 | pmid = 29120383 | pmc = 5713196 | bibcode = 2017arXiv170903526F | arxiv = 1709.03526 }}&lt;/ref&gt;
| M. Kragh et al.
|-
|11K Hands
|11,076 hand images (1600 x 1200 pixels) of 190 subjects, of varying ages between 18 – 75 years old, for gender recognition and biometric identification.
|None
|11,076 hand images
|Images and (.mat, .txt, and .csv) label files
|Gender recognition and biometric identification
|2017
|&lt;ref&gt;{{cite arxiv|last=Afifi|first=Mahmoud|date=2017-11-12|title=Gender recognition and biometric identification using a large dataset of hand images|eprint=1711.04322|class=cs.CV}}&lt;/ref&gt;
|M Afifi
|-
|CORe50
|Specifically designed for Continuous/Lifelong Learning and Object Recognition, is a collection of more than 500 videos (30fps) of 50 domestic objects belonging to 10 different categories.
|Classes labelled, training set splits created based on a 3-way, multi-runs benchmark.
|164,866 RBG-D images 
|images (.png or .pkl)
and (.pkl, .txt, .tsv) label files
|Classification, Object recognition
|2017
|&lt;ref&gt;{{Cite arxiv|last1=Lomonaco|first1=Vincenzo|last2=Maltoni|first2=Davide|date=2017-10-18|title=CORe50: a New Dataset and Benchmark for Continuous Object Recognition|eprint=1705.03550|class=cs.CV}}&lt;/ref&gt;
|V. Lomonaco and D. Maltoni
|-
|OpenLORIS-Object
|Lifelong/Continual Robotic Vision dataset (OpenLORIS-Object) collected by real robots mounted with multiple high-resolution sensors, includes a collection of 121 object instances (1st version of dataset, 40 categories daily necessities objects under 20 scenes). The dataset has rigorously considered 4 environment factors under different scenes, including illumination, occlusion, object pixel size and clutter, and defines the difficulty levels of each factor explicitly. 
|Classes labelled, training/validation/testing set splits created by benchmark scripts. 
|1,106,424 RBG-D images 
|images (.png and .pkl)
and (.pkl) label files
|Classification, Lifelong object recognition, Robotic Vision
|2019
|&lt;ref&gt;{{Cite arxiv|last1=She|first1=Qi|last2=Feng|first2=Fan|last3=Hao|first3=Xinyue|last4=Yang|first4=Qihan|last5=Lan|first5=Chuanlin|last6=Lomonaco|first6=Vincenzo|last7=Shi|first7=Xuesong|last8=Wang|first8=Zhengwei|last9=Guo|first9=Yao|last10=Zhang|first10=Yimin|last11=Qiao|first11=Fei|last12=Chan|first12=Rosa H.M.|date=2019-11-15|title=OpenLORIS-Object: A Robotic Vision Dataset and Benchmark for Lifelong Deep Learning|eprint=1911.06487v2|class=cs.CV}}&lt;/ref&gt;
|Q. She et al.
|-
|THz and thermal video data set
|This multispectral data set includes terahertz, thermal, visual, near infrared, and three-dimensional videos of objects hidden under people's clothes.
|3D lookup tables are provided that allow you to project images onto 3D point clouds.
|More than 20 videos. The duration of each video is about 85 seconds (about 345 frames).
|AP2J
|Experiments with hidden object detection
|2019
|&lt;ref&gt;{{cite web|url=http://www.fullvision.ru/monitoring/description_eng.php|last1=Morozov|first1=Alexei|last2=Sushkova|first2=Olga|date=2019-06-13|title=THz and thermal video data set|publisher=IRE RAS|website=Development of the multi-agent logic programming approach to a human behaviour analysis in a multi-channel video surveillance|access-date=2019-07-19|location=Moscow}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last1=Morozov|first1=Alexei|last2=Sushkova|first2=Olga|last3=Kershner|first3=Ivan|last4=Polupanov|first4=Alexander|date=2019-07-09|title=Development of a method of terahertz intelligent video surveillance based on the semantic fusion of terahertz and 3D video images|url=http://ceur-ws.org/Vol-2391/paper19.pdf|journal=CEUR|volume=2391|pages=paper19|access-date=2019-07-19}}&lt;/ref&gt;
|Alexei A. Morozov and Olga S. Sushkova
|}

=== Handwriting and character recognition ===
{| class="wikitable sortable" style="width: 100%"
!Dataset Name
!Brief description
!Preprocessing
!Instances
!Format
!Default Task
!Created (updated)
!Reference
!Creator
|-
|Artificial Characters Dataset
|Artificially generated data describing the structure of 10 capital English letters.
|Coordinates of lines drawn given as integers. Various other features.
|6000
|Text
|Handwriting recognition, classification
|1992
|&lt;ref&gt;Botta, M., A. Giordana, and L. Saitta. "[https://pdfs.semanticscholar.org/9f0e/1349d1422f1b455b8ccc26ebf7b114b8db20.pdf Learning fuzzy concept definitions]." ''Fuzzy Systems, 1993., Second IEEE International Conference on''. IEEE, 1993.&lt;/ref&gt;
|H. Guvenir et al.
|-
|Letter Dataset
|Upper case printed letters.
|17 features are extracted from all images.
|20,000
|Text
|OCR, classification
|1991
|&lt;ref&gt;{{cite journal | last1 = Frey | first1 = Peter W. | last2 = Slate | first2 = David J. | year = 1991 | title = Letter recognition using Holland-style adaptive classifiers | journal = Machine Learning | volume = 6 | issue = 2| pages = 161–182 | doi=10.1007/bf00114162| doi-access = free }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Peltonen | first1 = Jaakko | last2 = Klami | first2 = Arto | last3 = Kaski | first3 = Samuel | year = 2004 | title = Improved learning of Riemannian metrics for exploratory analysis | journal = Neural Networks | volume = 17 | issue = 8| pages = 1087–1100 | doi=10.1016/j.neunet.2004.06.008| pmid = 15555853 | citeseerx = 10.1.1.59.4865 }}&lt;/ref&gt;
|D. Slate et al.
|-
| CASIA-HWDB
| Offline handwritten [[Chinese characters|Chinese character]] database. 3755 classes in the [[GB 2312]] character set.
| Gray-scaled images with background pixels labeled as 255. 
|1,172,907
|Images, Text
|Handwriting recognition, classification
|2009
|&lt;ref name="casia13"&gt;{{cite journal |title=Online and offline handwritten Chinese character recognition: Benchmarking on new databases |journal=Pattern Recognition |volume=46 |issue=1 |date=January 2013 |pages=155–162 |first1=Cheng-Lin |last1=Liu |first2=Fei |last2=Yin |first3=Da-Han |last3=Wang |first4=Qiu-Feng |last4=Wang |doi=10.1016/j.patcog.2012.06.021 }}&lt;/ref&gt;
|[[Institute of Automation, Chinese Academy of Sciences|CASIA]]
|-
| CASIA-OLHWDB
| Online handwritten Chinese character database, collected using Anoto pen on paper. 3755 classes in the [[GB 2312]] character set.
| Provides the sequences of coordinates of strokes.
|1,174,364
|Images, Text
|Handwriting recognition, classification
| 2009
| &lt;ref name="OLHWDB1"&gt;{{cite journal |last1=Wang |first1=D. |first2=C. |last2=Liu |first3=J. |last3=Yu |first4=X. |last4=Zhou |journal=2009 10th International Conference on Document Analysis and Recognition |title=CASIA-OLHWDB1: A Database of Online Handwritten Chinese Characters |year=2009 |pages=1206–1210|doi=10.1109/ICDAR.2009.163 |isbn=978-1-4244-4500-4 |s2cid=5705532 }}&lt;/ref&gt;&lt;ref name="casia13"/&gt;
|CASIA
|-
|Character Trajectories Dataset
|Labeled samples of pen tip trajectories for people writing simple characters.
|3-dimensional pen tip velocity trajectory matrix for each sample
|2858
|Text
|Handwriting recognition, classification
|2008
|&lt;ref&gt;Williams, Ben H., Marc Toussaint, and Amos J. Storkey. ''[https://www.era.lib.ed.ac.uk/bitstream/handle/1842/3221/BH%20Williams%20PhD%20thesis%2009.pdf?sequence=1 Extracting motion primitives from natural handwriting data]''. Springer Berlin Heidelberg, 2006.&lt;/ref&gt;&lt;ref&gt;Meier, Franziska, et al. "[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.395.8598&amp;rep=rep1&amp;type=pdf Movement segmentation using a primitive library]."''Intelligent Robots and Systems (IROS), 2011 IEEE/RSJ International Conference on''. IEEE, 2011.&lt;/ref&gt;
|B. Williams
|-
|Chars74K Dataset
|Character recognition in natural images of symbols used in both English and [[Kannada alphabet|Kannada]]
|
|74,107
|
|Character recognition, handwriting recognition, OCR, classification
|2009
|&lt;ref&gt;T. E. de Campos, B. R. Babu and M. Varma. [http://personal.ee.surrey.ac.uk/Personal/T.Decampos/papers/decampos_etal_visapp2009.pdf Character recognition in natural images]. In ''Proceedings of the International Conference on Computer Vision Theory and Applications (VISAPP), Lisbon, Portugal'', February 2009&lt;/ref&gt;
|T. de Campos
|-
|UJI Pen Characters Dataset
|Isolated handwritten characters
|Coordinates of pen position as characters were written given.
|11,640
|Text
|Handwriting recognition, classification
|2009
|&lt;ref&gt;Llorens, David, et al. "[https://pdfs.semanticscholar.org/24cf/ef15094c59322560377bbf8e4185245c654f.pdf The UJIpenchars Database: a Pen-Based Database of Isolated Handwritten Characters]." ''LREC''. 2008.&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Calderara | first1 = Simone | last2 = Prati | first2 = Andrea | last3 = Cucchiara | first3 = Rita | year = 2011 | title = Mixtures of von mises distributions for people trajectory shape analysis | journal = IEEE Transactions on Circuits and Systems for Video Technology| volume = 21 | issue = 4| pages = 457–471 | doi=10.1109/tcsvt.2011.2125550| s2cid = 1427766 }}&lt;/ref&gt;
|F. Prat et al.
|-
|Gisette Dataset
|Handwriting samples from the often-confused 4 and 9 characters.
|Features extracted from images, split into train/test, handwriting images size-normalized.
|13,500
|Images, text
|Handwriting recognition, classification
|2003
|&lt;ref&gt;Guyon, Isabelle, et al. "[http://papers.nips.cc/paper/2728-result-analysis-of-the-nips-2003-feature-selection-challenge.pdf Result analysis of the nips 2003 feature selection challenge]." ''Advances in neural information processing systems''. 2004.&lt;/ref&gt;
|Yann LeCun et al.
|-
|Omniglot dataset
|1623 different handwritten characters from 50 different alphabets.
|Hand-labeled.
|38,300
|Images, text, strokes
|Classification, one-shot learning
|2015
|&lt;ref&gt;{{Cite journal|last1=Lake|first1=B. M.|last2=Salakhutdinov|first2=R.|last3=Tenenbaum|first3=J. B.|date=2015-12-11|title=Human-level concept learning through probabilistic program induction|journal=Science|language=en|volume=350|issue=6266|pages=1332–1338|doi=10.1126/science.aab3050|issn=0036-8075|pmid=26659050|bibcode=2015Sci...350.1332L|doi-access=free}}&lt;/ref&gt;&lt;ref&gt;{{Citation|last=Lake|first=Brenden|title=Omniglot data set for one-shot learning|date=2019-11-09|url=https://github.com/brendenlake/omniglot|access-date=2019-11-10}}&lt;/ref&gt;
|[[American Association for the Advancement of Science]]
|-
|[[MNIST database]]
|Database of handwritten digits.
|Hand-labeled.
|60,000
|Images, text
|Classification
|1998
|&lt;ref&gt;{{cite journal | last1 = LeCun | first1 = Yann | display-authors = et al | year = 1998 | title = Gradient-based learning applied to document recognition | journal = Proceedings of the IEEE | volume = 86 | issue = 11| pages = 2278–2324 | doi=10.1109/5.726791| citeseerx = 10.1.1.32.9552 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Kussul | first1 = Ernst | last2 = Baidyk | first2 = Tatiana | year = 2004 | title = Improved method of handwritten digit recognition tested on MNIST database | journal = Image and Vision Computing | volume = 22 | issue = 12| pages = 971–981 | doi = 10.1016/j.imavis.2004.03.008 }}&lt;/ref&gt;
|[[National Institute of Standards and Technology]]
|-
|Optical Recognition of Handwritten Digits Dataset
|Normalized bitmaps of handwritten data.
|Size normalized and mapped to bitmaps.
|5620
|Images, text
|Handwriting recognition, classification
|1998
|&lt;ref&gt;{{cite journal | last1 = Xu | first1 = Lei | last2 = Krzyżak | first2 = Adam | last3 = Suen | first3 = Ching Y. | year = 1992 | title = Methods of combining multiple classifiers and their applications to handwriting recognition | journal = IEEE Transactions on Systems, Man and Cybernetics| volume = 22 | issue = 3| pages = 418–435 | doi=10.1109/21.155943| hdl = 10338.dmlcz/135217 }}&lt;/ref&gt;
|E. Alpaydin et al.
|-
|Pen-Based Recognition of Handwritten Digits Dataset
|Handwritten digits on electronic pen-tablet.
|Feature vectors extracted to be uniformly spaced.
|10,992
|Images, text
|Handwriting recognition, classification
|1998
|&lt;ref&gt;Alimoglu, Fevzi, et al. "[http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.25.6299 Combining multiple classifiers for pen-based handwritten digit recognition]." (1996).&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Tang | first1 = E. Ke | display-authors = et al | year = 2005 | title = Linear dimensionality reduction using relevance weighted LDA | journal = Pattern Recognition | volume = 38 | issue = 4| pages = 485–493 | doi=10.1016/j.patcog.2004.09.005}}&lt;/ref&gt;
|E. Alpaydin et al.
|-
|Semeion Handwritten Digit Dataset
|Handwritten digits from 80 people.
|All handwritten digits have been normalized for size and mapped to the same grid.
|1593
|Images, text
|Handwriting recognition, classification
|2008
|&lt;ref&gt;Hong, Yi, et al. "[https://pages.ucsd.edu/~ztu/publication/iccv11_sparsemetric.pdf Learning a mixture of sparse distance metrics for classification and dimensionality reduction]." ''Computer Vision (ICCV), 2011 IEEE International Conference on''. IEEE, 2011.&lt;/ref&gt;
|T. Srl
|-
|HASYv2
|Handwritten mathematical symbols
|All symbols are centered and of size 32px x 32px.
|168233
|Images, text
|Classification
|2017
|&lt;ref&gt;{{cite arXiv |eprint=1701.08380|last1=Thoma|first1=Martin|title=The HASYv2 dataset|class=cs.CV|year=2017}}&lt;/ref&gt;
|Martin Thoma
|-
|Noisy Handwritten Bangla Dataset
|Includes Handwritten Numeral Dataset (10 classes) and Basic Character Dataset (50 classes), each dataset has three types of noise: white gaussian, motion blur, and reduced contrast.
|All images are centered and of size 32x32.
|Numeral Dataset:

23330,

Character Dataset:

76000
|Images,
text
|Handwriting recognition,
classification
|2017
|&lt;ref&gt;{{cite arxiv|last1=Karki|first1=Manohar|last2=Liu|first2=Qun|last3=DiBiano|first3=Robert|last4=Basu|first4=Saikat|last5=Mukhopadhyay|first5=Supratik|date=2018-06-20|title=Pixel-level Reconstruction and Classification for Noisy Handwritten Bangla Characters|eprint=1806.08037|class=cs.CV}}&lt;/ref&gt;&lt;ref&gt;{{Citation|last1=Liu|first1=Qun|title=PCGAN-CHAR: Progressively Trained Classifier Generative Adversarial Networks for Classification of Noisy Handwritten Bangla Characters|date=2019|work=Digital Libraries at the Crossroads of Digital Information for the Future|pages=3–15|publisher=Springer International Publishing|isbn=978-3-030-34057-5|last2=Collier|first2=Edward|last3=Mukhopadhyay|first3=Supratik|doi=10.1007/978-3-030-34058-2_1|arxiv=1908.08987|s2cid=201665955}}&lt;/ref&gt;
|M. Karki et al.
|}

=== Aerial images ===
{| class="wikitable sortable" style="width: 100%"
! scope="col" style="width: 15%;" |Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" |Creator
|-
|Aerial Image Segmentation Dataset
|80 high-resolution aerial images with spatial resolution ranging from 0.3 to 1.0.
|Images manually segmented.
|80
|Images
|Aerial Classification, object detection
|2013
|&lt;ref&gt;{{cite journal | last1 = Yuan | first1 = Jiangye | last2 = Gleason | first2 = Shaun S. | last3 = Cheriyadat | first3 = Anil M. | year = 2013 | title = Systematic benchmarking of aerial image segmentation | journal = IEEE Geoscience and Remote Sensing Letters| volume = 10 | issue = 6| pages = 1527–1531 | doi=10.1109/lgrs.2013.2261453| bibcode = 2013IGRSL..10.1527Y | s2cid = 629629 }}&lt;/ref&gt;&lt;ref&gt;Vatsavai, Ranga Raju. "[https://dl.acm.org/citation.cfm?id=2534927 Object based image classification: state of the art and computational challenges]." ''Proceedings of the 2nd ACM SIGSPATIAL International Workshop on Analytics for Big Geospatial Data''. ACM, 2013.&lt;/ref&gt;
|J. Yuan et al.
|-
|KIT AIS Data Set
|Multiple labeled training and evaluation datasets of aerial images of crowds.
|Images manually labeled to show paths of individuals through crowds.
|~ 150
|Images with paths
|People tracking, aerial tracking
|2012
|&lt;ref&gt;Butenuth, Matthias, et al. "[http://www.hartmann-alberts.de/dirk/pub/proceedings2011e.pdf Integrating pedestrian simulation, tracking and event detection for crowd analysis]." ''Computer Vision Workshops (ICCV Workshops), 2011 IEEE International Conference on''. IEEE, 2011.&lt;/ref&gt;&lt;ref&gt;Fradi, Hajer, and Jean-Luc Dugelay. "[http://www.eurecom.fr/fr/publication/3841/download/mm-publi-3841.pdf Low level crowd analysis using frame-wise normalized feature for people counting]." ''Information Forensics and Security (WIFS), 2012 IEEE International Workshop on''. IEEE, 2012.&lt;/ref&gt;
|M. Butenuth et al.
|-
|Wilt Dataset
|Remote sensing data of diseased trees and other land cover.
|Various features extracted.
|4899
|Images
|Classification, aerial object detection
|2014
|&lt;ref&gt;Johnson, Brian Alan, Ryutaro Tateishi, and Nguyen Thanh Hoan. "[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.826.9200&amp;rep=rep1&amp;type=pdf A hybrid pansharpening approach and multiscale object-based image analysis for mapping diseased pine and oak trees]." ''International journal of remote sensing''34.20 (2013): 6969–6982.&lt;/ref&gt;&lt;ref&gt;{{Cite journal|url=https://www.tandfonline.com/doi/abs/10.1080/2150704X.2015.1062159|doi = 10.1080/2150704X.2015.1062159|title = A new classification model for a class imbalanced data set using genetic programming and support vector machines: Case study for wilt disease classification|year = 2015|last1 = Mohd Pozi|first1 = Muhammad Syafiq|last2 = Sulaiman|first2 = Md Nasir|last3 = Mustapha|first3 = Norwati|last4 = Perumal|first4 = Thinagaran|journal = Remote Sensing Letters|volume = 6|issue = 7|pages = 568–577|s2cid = 58788630}}&lt;/ref&gt;
|B. Johnson
|-
|MASATI dataset
|Maritime scenes of optical aerial images from the visible spectrum. It contains color images in dynamic marine environments, each image may contain one or multiple targets in different weather and illumination conditions. 
|Object bounding boxes and labeling. 
|7389
|Images
|Classification, aerial object detection
|2018
|&lt;ref&gt;Gallego, A.-J.; Pertusa, A.; Gil, P. "[https://www.mdpi.com/2072-4292/10/4/511 Automatic Ship Classification from Optical Aerial Images with Convolutional Neural Networks]." ''Remote Sensing''. 2018; 10(4):511.&lt;/ref&gt;&lt;ref&gt;Gallego, A.-J.; Pertusa, A.; Gil, P. "MAritime SATellite Imagery dataset" [Online]. Available: https://www.iuii.ua.es/datasets/masati/, 2018.&lt;/ref&gt;
|A.-J. Gallego et al.
|-
|Forest Type Mapping Dataset
|Satellite imagery of forests in Japan.
|Image wavelength bands extracted.
|326
|Text
|Classification
|2015
|&lt;ref&gt;{{cite journal | last1 = Johnson | first1 = Brian | last2 = Tateishi | first2 = Ryutaro | last3 = Xie | first3 = Zhixiao | year = 2012 | title = Using geographically weighted variables for image classification | journal = Remote Sensing Letters | volume = 3 | issue = 6| pages = 491–499 | doi=10.1080/01431161.2011.629637| s2cid = 122543681 }}&lt;/ref&gt;&lt;ref&gt;Chatterjee, Sankhadeep, et al. "[https://www.researchgate.net/profile/Sankhadeep_Chatterjee/publication/282605325_Forest_Type_Classification_A_Hybrid_NN-GA_Model_Based_Approach/links/57493cb308ae5c51e29e6f1b/Forest-Type-Classification-A-Hybrid-NN-GA-Model-Based-Approach.pdf Forest Type Classification: A Hybrid NN-GA Model Based Approach]." ''Information Systems Design and Intelligent Applications''. Springer India, 2016. 227-236.&lt;/ref&gt;
|B. Johnson
|-
|[[Overhead Imagery Research Data Set]]
|Annotated overhead imagery. Images with multiple objects.
|Over 30 annotations and over 60 statistics that describe the target within the context of the image.
|1000
|Images, text
|Classification
|2009
|&lt;ref&gt;Diegert, Carl. "[https://www.osti.gov/servlets/purl/1278837 A combinatorial method for tracing objects using semantics of their shape]." ''Applied Imagery Pattern Recognition Workshop (AIPR), 2010 IEEE 39th''. IEEE, 2010.&lt;/ref&gt;&lt;ref&gt;Razakarivony, Sebastien, and Frédéric Jurie. "[https://hal.archives-ouvertes.fr/hal-00943444/file/13_mva-detection.pdf Small target detection combining foreground and background manifolds]." ''IAPR International Conference on Machine Vision Applications''. 2013.&lt;/ref&gt;
|F. Tanner et al.
|-
|SpaceNet
|SpaceNet is a corpus of commercial satellite imagery and labeled training data.
|GeoTiff and GeoJSON files containing building footprints.
|&gt;17533
|Images
|Classification, Object Identification
|2017
|&lt;ref&gt;{{Cite web|url=http://explore.digitalglobe.com/spacenet|title=SpaceNet|website=explore.digitalglobe.com|access-date=2018-03-13}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://medium.com/the-downlinq/getting-started-with-spacenet-data-827fd2ec9f53|title=Getting Started With SpaceNet Data|last=Etten|first=Adam Van|date=2017-01-05|website=The DownLinQ|access-date=2018-03-13}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|last1=Vakalopoulou|first1=M.|last2=Bus|first2=N.|last3=Karantzalosa|first3=K.|last4=Paragios|first4=N.|date=July 2017|title=Integrating edge/boundary priors with classification scores for building detection in very high resolution data|journal=2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)|pages=3309–3312|doi=10.1109/IGARSS.2017.8127705|isbn=978-1-5090-4951-6|s2cid=8297433}}&lt;/ref&gt;
|[[DigitalGlobe|DigitalGlobe, Inc.]]
|-
|UC Merced Land Use Dataset
|These images were manually extracted from large images from the USGS National Map Urban Area Imagery collection for various urban areas around the US.
|This is a 21 class land use image dataset meant for research purposes. There are 100 images for each class.
|2,100
|Image chips of 256x256, 30&amp;nbsp;cm (1 foot) GSD
|Land cover classification
|2010
|&lt;ref&gt;{{Cite book|last1=Yang|first1=Yi|last2=Newsam|first2=Shawn|date=2010|title=Bag-of-visual-words and spatial extensions for land-use classification|journal=Proceedings of the 18th SIGSPATIAL International Conference on Advances in Geographic Information Systems - GIS '10|location=New York, New York, USA|publisher=ACM Press|doi=10.1145/1869790.1869829|isbn=9781450304283|s2cid=993769}}&lt;/ref&gt;
|Yi Yang and Shawn Newsam
|-
|SAT-4 Airborne Dataset
|Images were extracted from the National Agriculture Imagery Program (NAIP) dataset.
|SAT-4 has four broad land cover classes, includes barren land, trees, grassland and a class that consists of all land cover classes other than the above three. 
 
|500,000
|Images
|Classification
|2015
|&lt;ref name=":1"&gt;{{Cite book|last1=Basu|first1=Saikat|last2=Ganguly|first2=Sangram|last3=Mukhopadhyay|first3=Supratik|last4=DiBiano|first4=Robert|last5=Karki|first5=Manohar|last6=Nemani|first6=Ramakrishna|date=2015-11-03|title=DeepSat: a learning framework for satellite imagery|publisher=ACM|pages=37|doi=10.1145/2820783.2820816|isbn=9781450339674|s2cid=4387134}}&lt;/ref&gt;&lt;ref name=":11"&gt;{{Cite journal|last1=Liu|first1=Qun|last2=Basu|first2=Saikat|last3=Ganguly|first3=Sangram|last4=Mukhopadhyay|first4=Supratik|last5=DiBiano|first5=Robert|last6=Karki|first6=Manohar|last7=Nemani|first7=Ramakrishna|date=2019-11-21|title=DeepSat V2: feature augmented convolutional neural nets for satellite image classification|journal=Remote Sensing Letters|volume=11|issue=2|pages=156–165|doi=10.1080/2150704x.2019.1693071|arxiv=1911.07747|s2cid=208138097|issn=2150-704X}}&lt;/ref&gt;
|S. Basu et al.
|-
|SAT-6 Airborne Dataset
|Images were extracted from the National Agriculture Imagery Program (NAIP) dataset.
|SAT-6 has six broad land cover classes, includes barren land, trees, grassland, roads, buildings and water bodies.
|405,000
|Images
|Classification
|2015
|&lt;ref name=":1" /&gt;&lt;ref name=":11" /&gt;
|S. Basu et al.
|}

=== Other images ===
{| class="wikitable sortable" style="width: 100%"
! scope="col" style="width: 15%;" |Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" |Creator

|-
|Density functional theory quantum simulations of graphene
|Labelled images of raw input to a simulation of graphene
|Raw data (in HDF5 format) and output labels from density functional theory quantum simulation
| 60744 test and 501473 and training files
|Labeled images
|Regression
|2019
|&lt;ref&gt;{{Citation | doi=10.4224/c8sc04578j.data| title=Big graphene dataset| date=2018-05-16| last1=Mills| first1=Kyle| last2=Tamblyn| first2=Isaac| publisher=National Research Council of Canada}}&lt;/ref&gt;
|K. Mills &amp; I. Tamblyn

|-
|Quantum simulations of an electron in a two dimensional potential well
|Labelled images of raw input to a simulation of 2d Quantum mechanics
|Raw data (in HDF5 format) and output labels from quantum simulation
|1.3 million images
|Labeled images
|Regression
|2017
|&lt;ref&gt;{{Cite book | doi=10.4224/PhysRevA.96.042113.data| title=Quantum simulations of an electron in a two dimensional potential well| date=2018-05-16| last1=Mills| first1=Kyle| last2=Spanner| first2=Michael| last3=Tamblyn| first3=Isaac| chapter=Quantum simulation| publisher=National Research Council of Canada}}&lt;/ref&gt;
|K. Mills, M.A. Spanner, &amp; I. Tamblyn

|-
|MPII Cooking Activities Dataset
|Videos and images of various cooking activities.
|Activity paths and directions, labels, fine-grained motion labeling, activity class, still image extraction and labeling.
|881,755 frames
|Labeled video, images, text
|Classification
|2012
|&lt;ref&gt;{{cite conference | last1=Rohrbach | first1=M. | last2=Amin | first2=S. | last3=Andriluka | first3=M. | last4=Schiele | first4=B. | title=A database for fine grained activity detection of cooking activities | publisher=IEEE | year=2012 | isbn=978-1-4673-1228-8 | doi=10.1109/cvpr.2012.6247801 }}&lt;/ref&gt;&lt;ref&gt;Kuehne, Hilde, Ali Arslan, and Thomas Serre. "[https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Kuehne_The_Language_of_2014_CVPR_paper.pdf The language of actions: Recovering the syntax and semantics of goal-directed human activities]."''Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition''. 2014.&lt;/ref&gt;
|M. Rohrbach et al.
|-
|FAMOS Dataset
|5,000 unique microstructures, all samples have been acquired 3 times with two different cameras.
|Original PNG files, sorted per camera and then per acquisition. MATLAB datafiles with one 16384 times 5000 matrix per camera per acquisition.
|30,000
|Images and .mat files 
|Authentication
|2012
|&lt;ref&gt;Sviatoslav, Voloshynovskiy, et al. "[http://vision.unige.ch/publications/postscript/2012/2012.WIFS.database.pdf Towards Reproducible results in authentication based on physical non-cloneable functions: The Forensic Authentication Microstructure Optical Set (FAMOS).]"''Proc. Proceedings of IEEE International Workshop on Information Forensics and Security''. 2012.&lt;/ref&gt;
|S. Voloshynovskiy, et al.
|-
|PharmaPack Dataset
|1,000 unique classes with 54 images per class.
|Class labeling, many local descriptors, like SIFT and aKaZE, and local feature agreators, like Fisher Vector (FV).
|54,000
|Images and .mat files 
|Fine-grain classification
|2017
|&lt;ref&gt;Olga, Taran and Shideh, Rezaeifar, et al. "[https://archive-ouverte.unige.ch/unige:97444/ATTACHMENT01 PharmaPack: mobile fine-grained recognition of pharma packages]."''Proc. European Signal Processing Conference (EUSIPCO)''. 2017.&lt;/ref&gt;
|O. Taran and S. Rezaeifar, et al.
|-
|Stanford Dogs Dataset
|Images of 120 breeds of dogs from around the world.
|Train/test splits and ImageNet annotations provided.
|20,580
|Images, text
|Fine-grain classification
|2011
|&lt;ref&gt;Khosla, Aditya, et al. "[https://people.csail.mit.edu/khosla/papers/fgvc2011.pdf Novel dataset for fine-grained image categorization: Stanford dogs]."''Proc. CVPR Workshop on Fine-Grained Visual Categorization (FGVC)''. 2011.&lt;/ref&gt;&lt;ref name=":7"&gt;Parkhi, Omkar M., et al. "[http://www.robots.ox.ac.uk:5000/~vgg/publications/2012/parkhi12a/parkhi12a.pdf Cats and dogs]."''Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on''. IEEE, 2012.&lt;/ref&gt;
|A. Khosla et al.
|-
|StanfordExtra Dataset
|2D keypoints and segmentations for the Stanford Dogs Dataset.
|2D keypoints and segmentations provided.
|12,035
|Labelled images
|3D reconstruction/pose estimation
|2020
|&lt;ref&gt;Biggs, Benjamin, et al. "[https://arxiv.org/abs/2007.11110 Who Left the Dogs Out? 3D Animal Reconstruction with Expectation Maximization in the Loop.]."''Proc. ECCV''. 2020.&lt;/ref&gt;
|B. Biggs et al.
|-
|The Oxford-IIIT Pet Dataset
|37 categories of pets with roughly 200 images of each.
|Breed labeled, tight bounding box, foreground-background segmentation.
|~ 7,400
|Images, text
|Classification, object detection
|2012
|&lt;ref name=":7" /&gt;&lt;ref name="Razavian, Ali 2014"&gt;Razavian, Ali, et al. "[https://www.cv-foundation.org/openaccess/content_cvpr_workshops_2014/W15/papers/Razavian_CNN_Features_Off-the-Shelf_2014_CVPR_paper.pdf CNN features off-the-shelf: an astounding baseline for recognition]." ''Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops''. 2014.&lt;/ref&gt;
|O. Parkhi et al.
|-
|Corel Image Features Data Set
|Database of images with features extracted.
|Many features including color histogram, co-occurrence texture, and colormoments,
|68,040
|Text
|Classification, object detection
|1999
|&lt;ref&gt;{{cite journal | last1 = Ortega | first1 = Michael | display-authors = et al | year = 1998 | title = Supporting ranked boolean similarity queries in MARS | journal = IEEE Transactions on Knowledge and Data Engineering| volume = 10 | issue = 6| pages = 905–925 | doi=10.1109/69.738357| citeseerx = 10.1.1.36.6079 }}&lt;/ref&gt;&lt;ref&gt;He, Xuming, Richard S. Zemel, and Miguel Á. Carreira-Perpiñán. "[ftp://www-vhost.cs.toronto.edu/public_html/public_html/dist/zemel/Papers/cvpr04.pdf Multiscale conditional random fields for image labeling]." ''Computer vision and pattern recognition, 2004. CVPR 2004. Proceedings of the 2004 IEEE computer society conference on''. Vol. 2. IEEE, 2004.&lt;/ref&gt;
|M. Ortega-Bindenberger et al.
|-
|Online Video Characteristics and Transcoding Time Dataset.
|Transcoding times for various different videos and video properties.
|Video features given.
|168,286
|Text
|Regression
|2015
|&lt;ref&gt;Deneke, Tewodros, et al. "[https://ieeexplore.ieee.org/abstract/document/6890256/ Video transcoding time prediction for proactive load balancing]." Multimedia and Expo (ICME), 2014 IEEE International Conference on. IEEE, 2014.&lt;/ref&gt;
|T. Deneke et al.
|-
|Microsoft Sequential Image Narrative Dataset (SIND)
|Dataset for sequential vision-to-language
|Descriptive caption and storytelling given for each photo, and photos are arranged in sequences
|81,743
|Images, text
|Visual storytelling
|2016
|&lt;ref&gt;{{cite arXiv |author=Ting-Hao (Kenneth) Huang, Francis Ferraro, Nasrin Mostafazadeh, Ishan Misra, Aishwarya Agrawal, Jacob Devlin, Ross Girshick, Xiaodong He, Pushmeet Kohli, Dhruv Batra, C. Lawrence Zitnick, Devi Parikh, Lucy Vanderwende, Michel Galley, Margaret Mitchell |eprint=1604.03968  |title=Visual Storytelling |class=cs.CL |date=13 April 2016 }}&lt;/ref&gt;
|[[Microsoft Research]]
|-
|Caltech-UCSD Birds-200-2011 Dataset
|Large dataset of images of birds.
|Part locations for birds, bounding boxes, 312 binary attributes given
|11,788
|Images, text
|Classification
|2011
|&lt;ref&gt;Wah, Catherine, et al. "[https://authors.library.caltech.edu/27452/1/CUB_200_2011.pdf The caltech-ucsd birds-200-2011 dataset]." (2011).&lt;/ref&gt;&lt;ref&gt;Duan, Kun, et al. "[http://vision.soic.indiana.edu/papers/attributes2012cvpr.pdf Discovering localized attributes for fine-grained recognition]." ''Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on''. IEEE, 2012.&lt;/ref&gt;
|C. Wah et al.
|-
|YouTube-8M
|Large and diverse labeled video dataset
|YouTube video IDs and associated labels from a diverse vocabulary of 4800 visual entities
|8 million
|Video, text
|Video classification
|2016
|&lt;ref&gt;{{cite web|title=YouTube-8M Dataset|url=https://research.google.com/youtube8m/|website=research.google.com|access-date=1 October 2016}}&lt;/ref&gt;&lt;ref&gt;{{cite arxiv |author1=Abu-El-Haija, Sami |author2=Kothari, Nisarg |author3=Lee, Joonseok |author4=Natsev, Paul |author5=Toderici, George |author6=Varadarajan, Balakrishnan |author7=Vijayanarasimhan, Sudheendra |eprint=1609.08675 |title=YouTube-8M: A Large-Scale Video Classification Benchmark |class=cs.CV |date=27 September 2016 }}&lt;/ref&gt;
|S. Abu-El-Haija et al.

|-
|YFCC100M
|Large and diverse labeled image and video dataset
|Flickr Videos and Images and associated description, titles, tags, and other metadata (such as EXIF and geotags)
|100&amp;nbsp;million
|Video, Image, Text
|Video and Image classification
|2016
|&lt;ref&gt;{{cite web|title=YFCC100M Dataset|url=http://mmcommons.org|website=mmcommons.org|publisher=[[Yahoo-ICSI-LLNL]]|access-date=1 June 2017}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |author1=Bart Thomee |author2=David A Shamma |author3=Gerald Friedland |author4=Benjamin Elizalde |author5=Karl Ni |author6=Douglas Poland |author7=Damian Borth |author8=Li-Jia Li |arxiv=1503.01817 |title=Yfcc100m: The new data in multimedia research |date=25 April 2016 |doi=10.1145/2812802 |volume=59 |issue=2 |journal=Communications of the ACM |pages=64–73 |s2cid=207230134 }}&lt;/ref&gt;
|B. Thomee et al.
|-

|Discrete LIRIS-ACCEDE
|Short videos annotated for valence and arousal.
|Valence and arousal labels.
|9800
|Video
|Video emotion elicitation detection
|2015
|&lt;ref&gt;Y. Baveye, E. Dellandrea, C. Chamaret, and L. Chen, "[https://hal.archives-ouvertes.fr/hal-01375518/document LIRIS-ACCEDE: A Video Database for Affective Content Analysis]," in IEEE Transactions on Affective Computing, 2015.&lt;/ref&gt;
|Y. Baveye et al.
|-
|Continuous LIRIS-ACCEDE
|Long videos annotated for valence and arousal while also collecting Galvanic Skin Response.
|Valence and arousal labels.
|30
|Video
|Video emotion elicitation detection
|2015
|&lt;ref&gt;Y. Baveye, E. Dellandrea, C. Chamaret, and L. Chen, "[https://hal.archives-ouvertes.fr/hal-01193144/document Deep Learning vs. Kernel Methods: Performance for Emotion Prediction in Videos]," in 2015 Humaine Association Conference on Affective Computing and Intelligent Interaction (ACII), 2015.&lt;/ref&gt;
|Y. Baveye et al.
|-
|MediaEval LIRIS-ACCEDE
|Extension of Discrete LIRIS-ACCEDE including annotations for violence levels of the films.
|Violence, valence and arousal labels.
|10900
|Video
|Video emotion elicitation detection
|2015
|&lt;ref&gt;M. Sjöberg, Y. Baveye, H. Wang, V. L. Quang, B. Ionescu, E. Dellandréa, M. Schedl, C.-H. Demarty, and L. Chen, "[https://www.researchgate.net/profile/Hanli_Wang2/publication/309704559_The_MediaEval_2015_Affective_Impact_of_Movies_Task/links/581dada308ae12715af33bc8/The-MediaEval-2015-Affective-Impact-of-Movies-Task.pdf The mediaeval 2015 affective impact of movies task]," in MediaEval 2015 Workshop, 2015.&lt;/ref&gt;
|Y. Baveye et al.
|-
|Leeds Sports Pose
|Articulated human pose annotations in 2000 natural sports images from Flickr.
|Rough crop around single person of interest with 14 joint labels
|2000
|Images plus .mat file labels
|Human pose estimation
|2010
|&lt;ref&gt;S. Johnson and M. Everingham, "[http://sam.johnson.io/research/publications/johnson10bmvc.pdf Clustered Pose and Nonlinear Appearance Models for Human Pose Estimation]", in Proceedings of the 21st British Machine Vision Conference (BMVC2010)&lt;/ref&gt;
|S. Johnson and M. Everingham
|-
|Leeds Sports Pose Extended Training
|Articulated human pose annotations in 10,000 natural sports images from Flickr.
|14 joint labels via crowdsourcing
|10000
|Images plus .mat file labels
|Human pose estimation
|2011
|&lt;ref&gt;S. Johnson and M. Everingham, "[http://sam.johnson.io/research/publications/johnson11cvpr.pdf Learning Effective Human Pose Estimation from Inaccurate Annotation]", In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR2011)&lt;/ref&gt;
|S. Johnson and M. Everingham
|-
|MCQ Dataset
|6 different real multiple choice-based exams (735 answer sheets and 33,540 answer boxes) to evaluate computer vision techniques and systems developed for multiple choice test assessment systems.
|None
|735 answer sheets and 33,540 answer boxes
|Images and .mat file labels
|Development of multiple choice test assessment systems
|2017
|&lt;ref&gt;{{cite arxiv|last1=Afifi|first1=Mahmoud|last2=Hussain|first2=Khaled F.|date=2017-11-02|title=The Achievement of Higher Flexibility in Multiple Choice-based Tests Using Image Classification Techniques|eprint=1711.00972|class=cs.CV}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://sites.google.com/view/mcq-dataset/mcqe-dataset|title=MCQ Dataset|website=sites.google.com|language=en-US|access-date=2017-11-18}}&lt;/ref&gt;
|Afifi, M. et al.
|-
|Surveillance Videos
|Real surveillance videos cover a large surveillance time (7 days with 24 hours each).
|None
|19 surveillance videos (7 days with 24 hours each).
|Videos
|Data compression
|2016
|&lt;ref&gt;{{Cite book|last1=Taj-Eddin|first1=I. A. T. F.|last2=Afifi|first2=M.|last3=Korashy|first3=M.|last4=Hamdy|first4=D.|last5=Nasser|first5=M.|last6=Derbaz|first6=S.|date=July 2016|title=A new compression technique for surveillance videos: Evaluation using new dataset|journal=2016 Sixth International Conference on Digital Information and Communication Technology and Its Applications (DICTAP)|pages=159–164|doi=10.1109/DICTAP.2016.7544020|isbn=978-1-4673-9609-7|s2cid=8698850}}&lt;/ref&gt;
|Taj-Eddin, I. A. T. F. et al.
|-
|LILA BC
|Labeled Information Library of Alexandria: Biology and Conservation.  Labeled images that support machine learning research around ecology and environmental science.
|None
|~10M images
|Images
|Classification
|2019
|&lt;ref name="TabakNorouzzadeh2018"&gt;{{cite journal|last1=Tabak|first1=Michael A.|last2=Norouzzadeh|first2=Mohammad S.|last3=Wolfson|first3=David W.|last4=Sweeney|first4=Steven J.|last5=Vercauteren|first5=Kurt C.|last6=Snow|first6=Nathan P.|last7=Halseth|first7=Joseph M.|last8=Di Salvo|first8=Paul A.|last9=Lewis|first9=Jesse S.|last10=White|first10=Michael D.|last11=Teton|first11=Ben|last12=Beasley|first12=James C.|last13=Schlichting|first13=Peter E.|last14=Boughton|first14=Raoul K.|last15=Wight|first15=Bethany|last16=Newkirk|first16=Eric S.|last17=Ivan|first17=Jacob S.|last18=Odell|first18=Eric A.|last19=Brook|first19=Ryan K.|last20=Lukacs|first20=Paul M.|last21=Moeller|first21=Anna K.|last22=Mandeville|first22=Elizabeth G.|last23=Clune|first23=Jeff|last24=Miller|first24=Ryan S.|last25=Photopoulou|first25=Theoni|title=Machine learning to classify animal species in camera trap images: Applications in ecology|journal=Methods in Ecology and Evolution|volume=10|issue=4|pages=585–590|year=2018|issn=2041-210X|doi=10.1111/2041-210X.13120|doi-access=free}}&lt;/ref&gt;
|LILA working group
|-
|Can We See Photosynthesis?
|32 videos for eight live and eight dead leaves recorded under both DC and AC lighting conditions. 
|None
|32 videos
|Videos
|Liveness detection of plants
|2017
|&lt;ref&gt;{{Cite journal|last1=Taj-Eddin|first1=Islam A. T. F.|last2=Afifi|first2=Mahmoud|last3=Korashy|first3=Mostafa|last4=Ahmed|first4=Ali H.|last5=Ng|first5=Yoke Cheng|last6=Hernandez|first6=Evelyng|last7=Abdel-Latif|first7=Salma M.|date=November 2017|title=Can we see photosynthesis? Magnifying the tiny color changes of plant green leaves using Eulerian video magnification|journal=Journal of Electronic Imaging|volume=26|issue=6|pages=060501|doi=10.1117/1.jei.26.6.060501|issn=1017-9909|arxiv=1706.03867|bibcode=2017JEI....26f0501T|s2cid=12367169}}&lt;/ref&gt;
|Taj-Eddin, I. A. T. F. et al.
|}

== Text data ==
Datasets consisting primarily of text for tasks such as [[natural language processing]], [[sentiment analysis]], translation, and [[cluster analysis]].

=== Reviews ===
{| class="wikitable sortable" style="width: 100%"
! scope="col" style="width: 15%;" | Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" | Creator
|-
|Amazon reviews
| US product reviews from [[Amazon.com]].
|None.
| ~ 82M
|Text
|Classification, sentiment analysis
|2015
|&lt;ref&gt;McAuley, Julian, et al. "[https://arxiv.org/abs/1506.04757 Image-based recommendations on styles and substitutes]." ''Proceedings of the 38th international ACM SIGIR conference on Research and development in information retrieval''. ACM, 2015&lt;/ref&gt;
|McAuley et al.
|-

|OpinRank Review Dataset
|Reviews of cars and hotels from [[Edmunds.com]] and [[TripAdvisor]] respectively.
|None.
|42,230 / ~259,000 respectively
|Text
|Sentiment analysis, clustering
|2011
|&lt;ref&gt;{{cite journal | last1 = Ganesan | first1 = Kavita | last2 = Zhai | first2 = Chengxiang | year = 2012 | title = Opinion-based entity ranking | journal = Information Retrieval | volume = 15 | issue = 2| pages = 116–150 | doi=10.1007/s10791-011-9174-8| hdl = 2142/15252 | s2cid = 16258727 | hdl-access = free }}&lt;/ref&gt;&lt;ref&gt;Lv, Yuanhua, Dimitrios Lymberopoulos, and Qiang Wu. "[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.599.1442&amp;rep=rep1&amp;type=pdf An exploration of ranking heuristics in mobile local search]." ''Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval''. ACM, 2012.&lt;/ref&gt;
|K. Ganesan et al.
|-
|MovieLens
|22,000,000 ratings and 580,000 tags applied to 33,000 movies by 240,000 users.
|None.
|~ 22M
|Text
|Regression, clustering, classification
|2016
|&lt;ref&gt;{{cite journal | last1 = Harper | first1 = F. Maxwell | last2 = Konstan | first2 = Joseph A. | year = 2015 | title = The MovieLens Datasets: History and Context | journal = ACM Transactions on Interactive Intelligent Systems  | volume = 5 | issue = 4| page = 19 | doi = 10.1145/2827872 | s2cid = 16619709 }}&lt;/ref&gt;
|[[GroupLens Research]]
|-
|Yahoo! Music User Ratings of Musical Artists
|Over 10M ratings of artists by Yahoo users.
|None described.
|~ 10M
|Text
|Clustering, regression
|2004
|&lt;ref&gt;Koenigstein, Noam, Gideon Dror, and Yehuda Koren. "[https://www.researchgate.net/profile/Noam_Koenigstein/publication/221141054_Yahoo_music_recommendations_Modeling_music_ratings_with_temporal_dynamics_and_item_taxonomy/links/5404184a0cf2c48563b03c68/Yahoo-music-recommendations-Modeling-music-ratings-with-temporal-dynamics-and-item-taxonomy.pdf Yahoo! music recommendations: modeling music ratings with temporal dynamics and item taxonomy]." ''Proceedings of the fifth ACM conference on Recommender systems''. ACM, 2011.&lt;/ref&gt;&lt;ref&gt;McFee, Brian, et al. "[https://bmcfee.github.io/papers/msdchallenge.pdf The million song dataset challenge]." ''Proceedings of the 21st international conference companion on World Wide Web''. ACM, 2012.&lt;/ref&gt;
|[[Yahoo!]]
|-
|Car Evaluation Data Set
|Car properties and their overall acceptability.
|Six categorical features given.
|1728
|Text
|Classification
|1997
|&lt;ref&gt;Bohanec, Marko, and Vladislav Rajkovic. "[https://www.researchgate.net/profile/Marko_Bohanec/publication/246614940_KNOWLEDGE_ACQUISITION_AND_EXPLANATION_FOR_MULTI-ATTRIBUTE_DECISION_MAKING/links/02e7e532152f452d87000000.pdf Knowledge acquisition and explanation for multi-attribute decision making]." ''8th Intl Workshop on Expert Systems and their Applications''. 1988.&lt;/ref&gt;&lt;ref&gt;Tan, Peter J., and David L. Dowe. "[http://www.csse.monash.edu.au/~dld/Publications/2002/Tan+Dowe2002_MMLDecisionGraphs.ps MML inference of decision graphs with multi-way joins]." ''Australian Joint Conference on Artificial Intelligence''. 2002.&lt;/ref&gt;
|M. Bohanec
|-
|YouTube Comedy Slam Preference Dataset
|User vote data for pairs of videos shown on YouTube. Users voted on funnier videos.
|Video metadata given.
|1,138,562
|Text
|Classification
|2012
|&lt;ref&gt;{{Cite web
| url = https://metatext.io/datasets
| title = Quantifying comedy on YouTube: why the number of o's in your LOL matter
| website = Metatext NLP Database
| access-date = 2020-10-26
}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|chapter-url=https://link.springer.com/chapter/10.1007/978-3-642-32692-9_63|doi=10.1007/978-3-642-32692-9_63|chapter=A Classifier for Big Data|title=Convergence and Hybrid Information Technology|series=Communications in Computer and Information Science|year=2012|last1=Kim|first1=Byung Joo|volume=310|pages=505–512|isbn=978-3-642-32691-2}}&lt;/ref&gt;
|Google
|-
|Skytrax User Reviews Dataset
|User reviews of airlines, airports, seats, and lounges from Skytrax.
|Ratings are fine-grain and include many aspects of airport experience.
|41396
|Text
|Classification, regression
|2015
|&lt;ref&gt;{{cite journal | last1 = Pérezgonzález | first1 = Jose D. | last2 = Gilbey | first2 = Andrew | year = 2011 | title = Predicting Skytrax airport rankings from customer reviews | url = https://www.ingentaconnect.com/content/hsp/cam/2011/00000005/00000004/art00007| journal = Journal of Airport Management | volume = 5 | issue = 4| pages = 335–339 }}&lt;/ref&gt;
|Q. Nguyen
|-
|Teaching Assistant Evaluation Dataset
|Teaching assistant reviews.
|Features of each instance such as class, class size, and instructor are given.
|151
|Text
|Classification
|1997
|&lt;ref&gt;Loh, Wei-Yin, and Yu-Shan Shih. "[http://www3.stat.sinica.edu.tw/statistica/oldpdf/A7n41.pdf Split selection methods for classification trees]." ''Statistica sinica''(1997): 815–840.&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Lim | first1 = Tjen-Sien | last2 = Loh | first2 = Wei-Yin | last3 = Shih | first3 = Yu-Shan | year = 2000 | title = A comparison of prediction accuracy, complexity, and training time of thirty-three old and new classification algorithms | journal = Machine Learning | volume = 40 | issue = 3| pages = 203–228 | doi=10.1023/a:1007608224229| s2cid = 17030953 }}&lt;/ref&gt;
|W. Loh et al.
|-
|Vietnamese Students’ Feedback Corpus (UIT-VSFC)
|Students’ Feedback.
|Comments
|16,000
|Text
|Classification
|1997
|&lt;ref&gt;Kiet Van Nguyen, Vu Duc Nguyen, Phu X. V. Nguyen, Tham T. H. Truong, Ngan Luu-Thuy Nguyen. "[https://ieeexplore.ieee.org/document/8573337 UIT-VSFC: Vietnamese Students’ Feedback Corpus for Sentiment Analysis]}}&lt;/ref&gt;
|Nguyen et al.
|-
|Vietnamese Social Media Emotion Corpus (UIT-VSMEC)
|Users’ Facebook Comments.
|Comments
|6,927
|Text
|Classification
|1997
|&lt;ref&gt;Vong Anh Ho, Duong Huynh-Cong Nguyen, Danh Hoang Nguyen, Linh Thi-Van Pham, Duc-Vu Nguyen, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen. "[https://link.springer.com/chapter/10.1007/978-981-15-6168-9_27 Emotion Recognition for Vietnamese Social Media Text]}}&lt;/ref&gt;
|Nguyen et al.
|-
|}

=== News articles ===
{| class="wikitable sortable" style="width: 100%"
! scope="col" style="width: 15%;" | Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" | Creator
|-
|NYSK Dataset
|English news articles about the case relating to allegations of sexual assault against the former [[International Monetary Fund|IMF]] director [[Dominique Strauss-Kahn]].
|Filtered and presented in XML format.
|10,421
|XML, text
|Sentiment analysis, topic extraction
|2013
|&lt;ref&gt;{{cite conference | last1=Dermouche | first1=Mohamed | last2=Velcin | first2=Julien | last3=Khouas | first3=Leila | last4=Loudcher | first4=Sabine | title=A Joint Model for Topic-Sentiment Evolution over Time | publisher=IEEE | year=2014 | isbn=978-1-4799-4302-9 | doi=10.1109/icdm.2014.82 }}&lt;/ref&gt;
|Dermouche, M. et al.
|-
|The Reuters Corpus Volume 1
|Large corpus of [[Reuters]] news stories in English.
|Fine-grain categorization and topic codes.
|810,000
|Text
|Classification, clustering, [[Automatic summarization|summarization]]
|2002
|&lt;ref&gt;{{cite journal | last1 = Rose | first1 = Tony | last2 = Stevenson | first2 = Mark | last3 = Whitehead | first3 = Miles | title = The Reuters Corpus Volume 1-from Yesterday's News to Tomorrow's Language Resources | url =https://pdfs.semanticscholar.org/3e4b/dc7f8904c58f8fce199389299ec1ed8e1226.pdf | journal = LREC | volume = 2 | year = 2002 | s2cid = 9239414 }}&lt;/ref&gt;
|[[Reuters]]
|-
|The Reuters Corpus Volume 2
|Large corpus of [[Reuters]] news stories in multiple languages.
|Fine-grain categorization and topic codes.
|487,000
|Text
|Classification, clustering, summarization
|2005
|&lt;ref&gt;{{cite journal | last1=Amini | first1=Massih R. | last2=Usunier | first2=Nicolas | last3=Goutte | first3=Cyril | title=Learning from Multiple Partially Observed Views - an Application to Multilingual Text Categorization | url=http://papers.nips.cc/paper/3690-learning-from-multiple-partially-observed-views-an-application-to-multilingual-text-categorization | year=2009 | pages=28–36 |journal=Advances in Neural Information Processing Systems}}&lt;/ref&gt;
|[[Reuters]]
|-
|Thomson Reuters Text Research Collection
|Large corpus of news stories.
|Details not described.
|1,800,370
|Text
|Classification, clustering, summarization
|2009
|&lt;ref&gt;{{cite conference |last=Liu |first=Ming |display-authors=etal |url=https://www.aaai.org/ocs/index.php/IJCAI/IJCAI15/paper/download/10903/10990 |title=VRCA: a clustering algorithm for massive amount of texts |book-title=Proceedings of the 24th International Conference on Artificial Intelligence |publisher=AAAI Press |year=2015}}&lt;/ref&gt;
|T. Rose et al.
|-
|Saudi Newspapers Corpus
|31,030 Arabic newspaper articles.
|Metadata extracted.
|31,030
|JSON
|Summarization, clustering
|2015
|&lt;ref&gt;{{cite conference |last1=Al-Harbi |first1=S |last2=Almuhareb |first2=A |last3=Al-Thubaity |first3=A |last4=Khorsheed |first4=M. S. |last5=Al-Rajeh |first5=A |year=2008 |title=Automatic Arabic Text Classification |book-title=Proceedings of the 9th International Conference on the Statistical Analysis of Textual Data, Lyon, France}}&lt;/ref&gt;
|M. Alhagri
|-
|RE3D (Relationship and Entity Extraction Evaluation Dataset)
|Entity and Relation marked data from various news and government sources. Sponsored by Dstl
|Filtered, categorisation using Baleen types
|not known
|JSON
|Classification, Entity and Relation recognition
|2017
|&lt;ref&gt;{{Cite web | url=https://github.com/dstl/re3d | title=Relationship and Entity Extraction Evaluation Dataset: Dstl/re3d| date=2018-12-17}}&lt;/ref&gt;
|Dstl
|-
|[[Examiner.com|Examiner]] Spam Clickbait Catalogue
|Clickbait, spam, crowd-sourced headlines from 2010 to 2015
|Publish date and headlines
|3,089,781
|CSV
|Clustering, Events, Sentiment
|2016
|&lt;ref&gt;{{Cite web | url=https://www.kaggle.com/therohk/examine-the-examiner | title=The Examiner - SpamClickBait Catalogue}}&lt;/ref&gt;
|R. Kulkarni
|-
|[[Australian Broadcasting Corporation|ABC]] Australia News Corpus
|Entire news corpus of ABC Australia from 2003 to 2019
|Publish date and headlines
|1,186,018
|CSV
|Clustering, Events, Sentiment
|2020
|&lt;ref&gt;{{Cite web | url=https://www.kaggle.com/therohk/million-headlines | title=A Million News Headlines}}&lt;/ref&gt;
|R. Kulkarni
|-
|Worldwide News - Aggregate of 20K [[Web feed|Feeds]]
|One week snapshot of all online headlines in 20+ languages
|Publish time, URL and headlines
|1,398,431
|CSV
|Clustering, Events, Language Detection
|2018
|&lt;ref&gt;{{Cite web | url=https://www.kaggle.com/therohk/global-news-week | title=One Week of Global News Feeds}}&lt;/ref&gt;
|R. Kulkarni
|-
|[[Reuters]] News Wire Headline
|11 Years of timestamped events published on the news-wire
|Publish time, Headline Text
|16,121,310
|CSV
|NLP, Computational Linguistics, Events
|2018
|&lt;ref&gt;{{Citation | title=Reuters News-Wire Archive|doi = 10.7910/DVN/XDB74W|year = 2018|last1 = Kulkarni|first1 = Rohit|publisher = Harvard Dataverse}}&lt;/ref&gt;
|R. Kulkarni
|-
|[[The Irish Times]] Ireland News Corpus
|24 Years of Ireland News from 1996 to 2019
|Publish time, Headline Category and Text
|1,484,340
|CSV
|NLP, Computational Linguistics, Events
|2020
|&lt;ref&gt;{{Cite web | url=https://www.kaggle.com/therohk/ireland-historical-news | title=IrishTimes - the Waxy-Wany News}}&lt;/ref&gt;
|R. Kulkarni
|-
|News Headlines Dataset for Sarcasm Detection
|High quality dataset with Sarcastic and Non-sarcastic news headlines.
|Clean, normalized text
|26,709
|JSON
|NLP, Classification, Linguistics
|2018
|&lt;ref&gt;{{Cite web|url=https://kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection|title=News Headlines Dataset For Sarcasm Detection|website=kaggle.com|access-date=2019-04-27}}&lt;/ref&gt;
|Rishabh Misra
|}

=== Messages ===
{| style="width: 100%" class="wikitable sortable"
! scope="col" style="width: 15%;" | Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" | Creator
|-
|Enron Email Dataset
|Emails from employees at [[Enron]] organized into folders.
|Attachments removed, invalid email addresses converted to user@enron.com or no_address@enron.com.
|~ 500,000
|Text
|[[Social network analysis|Network analysis]], sentiment analysis
|2004 (2015)
|&lt;ref&gt;Klimt, Bryan, and Yiming Yang. "[https://bklimt.com/papers/2004_klimt_ceas.pdf Introducing the Enron Corpus]." ''CEAS''. 2004.&lt;/ref&gt;&lt;ref&gt;Kossinets, Gueorgi, Jon Kleinberg, and Duncan Watts. "[https://arxiv.org/abs/0806.3201 The structure of information pathways in a social communication network]." ''Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining''. ACM, 2008.&lt;/ref&gt;
|Klimt, B. and Y. Yang
|-
|Ling-Spam Dataset
|Corpus containing both legitimate and [[Email spam|spam]] emails.
|Four version of the corpus involving whether or not a [[Lemmatisation|lemmatiser]] or stop-list was enabled.
|2,412 Ham 481 Spam 
|Text
|Classification
|2000
|&lt;ref&gt;{{Cite conference |arxiv=cs/0006013 |last1=Androutsopoulos |first1=Ion |last2=Koutsias |first2=John |last3= Chandrinos |first3=Konstantinos V. |last4=Paliouras |first4=George |last5= Spyropoulos |first5=Constantine D. |year=2000 |title=An evaluation of Naive Bayesian anti-spam filtering |book-title=Proceedings of the Workshop on Machine Learning in the New Information Age |conference=11th European Conference on Machine Learning, Barcelona, Spain |editor1-first=G. |editor1-last=Potamias |editor2-first=V. |editor2-last=Moustakis |editor3-first=M. |editor3-last=van Someren |volume=11 |pages=9–17 |bibcode=2000cs........6013A}}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Bratko | first1 = Andrej | display-authors = et al | year = 2006 | title = Spam filtering using statistical data compression models | url =http://www.jmlr.org/papers/volume7/bratko06a/bratko06a.pdf | journal = The Journal of Machine Learning Research | volume = 7 | pages = 2673–2698 }}&lt;/ref&gt;
|Androutsopoulos, J. et al.
|-
|SMS Spam Collection Dataset
|Collected SMS spam messages.
|None.
|5,574
|Text
|Classification
|2011
|&lt;ref&gt;Almeida, Tiago A., José María G. Hidalgo, and Akebo Yamakami. "[http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/doceng11.pdf Contributions to the study of SMS spam filtering: new collection and results]."''Proceedings of the 11th ACM symposium on Document engineering''. ACM, 2011.&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Delany | last2 = Jane | first2 = Sarah | last3 = Buckley | first3 = Mark | last4 = Greene | first4 = Derek | year = 2012 | title = SMS spam filtering: methods and data | url = https://arrow.dit.ie/cgi/viewcontent.cgi?article=1022&amp;context=scschcomart| journal = Expert Systems with Applications | volume = 39 | issue = 10| pages = 9899–9908 | doi=10.1016/j.eswa.2012.02.053}}&lt;/ref&gt;
|T. Almeida et al.
|-
|Twenty Newsgroups Dataset
|Messages from 20 different newsgroups.
|None.
|20,000
|Text
|Natural language processing
|1999
|&lt;ref&gt;Joachims, Thorsten. ''[https://apps.dtic.mil/dtic/tr/fulltext/u2/a307731.pdf A Probabilistic Analysis of the Rocchio Algorithm with TFIDF for Text Categorization]''. No. CMU-CS-96-118. Carnegie-mellon univ pittsburgh pa dept of computer science, 1996.&lt;/ref&gt;
|T. Mitchell et al.
|-
|Spambase Dataset
|Spam emails.
|Many text features extracted.
|4,601
|Text
|Spam detection, classification
|1999
|&lt;ref&gt;Dimitrakakis, Christos, and Samy Bengio. ''[https://infoscience.epfl.ch/record/82788/files/rr02-28.pdf Online Policy Adaptation for Ensemble Algorithms]''. No. EPFL-REPORT-82788. IDIAP, 2002.&lt;/ref&gt;
|M. Hopkins et al.
|-
|ColBERT Dataset
|Short jokes.
|Outliers removed.
|200,000
|Text
|Humor detection, classification
|2020
|&lt;ref&gt;Annamoradnejad, Issa. ''[https://arxiv.org/pdf/2004.12765 	arXiv:2004.12765]''. 	arXiv:2004.12765, 2020.&lt;/ref&gt;
|I. Annamoradnejad.
|}

=== Twitter and tweets ===
{| style="width: 100%" class="wikitable sortable"
! scope="col" style="width: 15%;" |Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" |Creator
|-
|MovieTweetings
|Movie rating dataset based on public and well-structured tweets
|
|~710,000
|Text
|Classification, regression
|2018
|&lt;ref&gt;Dooms, S. et al. "Movietweetings: a movie rating dataset collected from twitter, 2013. Available from https://github.com/sidooms/MovieTweetings."&lt;/ref&gt;
|S. Dooms
|-
|Twitter100k
|Pairs of images and tweets
|
|100,000
|Text and Images
|Cross-media retrieval
|2017
|&lt;ref&gt;{{Cite arxiv|title=Twitter100k: A Real-world Dataset for Weakly Supervised Cross-Media Retrieval|eprint = 1703.06618|last1 = RoyChowdhury|first1 = Aruni|last2=Lin|first2=Tsung-Yu|last3=Maji|first3=Subhransu|last4=Learned-Miller|first4=Erik|class=cs.CV|year=2017}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://github.com/huyt16/Twitter100k|title=huyt16/Twitter100k|website=GitHub|language=en|access-date=2018-03-26}}&lt;/ref&gt;
|Y. Hu, et al.
|-
|Sentiment140
|Tweet data from 2009 including original text, time stamp, user and sentiment.
|Classified using distant supervision from presence of emoticon in tweet.
|1,578,627
|Tweets, comma, separated values
|Sentiment analysis
|2009
|&lt;ref&gt;{{cite journal | last1 = Go | first1 = Alec | last2 = Bhayani | first2 = Richa | last3 = Huang | first3 = Lei | year = 2009 | title = Twitter sentiment classification using distant supervision | journal = CS224N Project Report, Stanford | volume = 1 | page = 12 }}&lt;/ref&gt;&lt;ref&gt;Chikersal, Prerna, Soujanya Poria, and Erik Cambria. "[https://www.aclweb.org/anthology/S15-2108 SeNTU: sentiment analysis of tweets by combining a rule-based classifier with supervised learning]." ''Proceedings of the International Workshop on Semantic Evaluation, SemEval''. 2015.&lt;/ref&gt;
|A. Go et al.
|-
|ASU Twitter Dataset
|Twitter network data, not actual tweets. Shows connections between a large number of users.
|None.
|11,316,811 users, 85,331,846 connections
|Text
|Clustering, graph analysis
|2009
|&lt;ref&gt;Zafarani, Reza, and [[Huan Liu]]. "Social computing data repository at ASU." ''School of Computing, Informatics and Decision Systems Engineering, Arizona State University'' (2009).&lt;/ref&gt;&lt;ref&gt;Bisgin, Halil, Nitin Agarwal, and Xiaowei Xu. "[http://www.academia.edu/download/3746109/4191a533.pdf Investigating homophily in online social networks]." ''Web Intelligence and Intelligent Agent Technology (WI-IAT), 2010 IEEE/WIC/ACM International Conference on''. Vol. 1. IEEE, 2010.&lt;/ref&gt;
|R. Zafarani et al.
|-
|SNAP Social Circles: Twitter Database
|Large Twitter network data.
|Node features, circles, and ego networks.
|1,768,149
|Text
|Clustering, graph analysis
|2012
|&lt;ref&gt;{{cite journal | last1 = McAuley | first1 = Julian J. | last2 = Leskovec | first2 = Jure | title = Learning to Discover Social Circles in Ego Networks | journal = NIPS | volume = 2012 | page = 2012 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Šubelj | first1 = Lovro | last2 = Fiala | first2 = Dalibor | last3 = Bajec | first3 = Marko | title = Network-based statistical comparison of citation topology of bibliographic databases | journal = Scientific Reports | volume = 4 | issue = 6496| pages = 6496 | year = 2014 | doi=10.1038/srep06496| pmid = 25263231 | pmc = 4178292 | arxiv = 1502.05061 | bibcode = 2014NatSR...4E6496S }}&lt;/ref&gt;
|J. McAuley et al.
|-
|Twitter Dataset for Arabic Sentiment Analysis
|Arabic tweets.
|Samples hand-labeled as positive or negative.
|2000
|Text
|Classification
|2014
|&lt;ref&gt;Abdulla, N., et al. "Arabic sentiment analysis: Corpus-based and lexicon-based." ''Proceedings of the IEEE conference on Applied Electrical Engineering and Computing Technologies (AEECT)''. 2013.&lt;/ref&gt;&lt;ref&gt;Abooraig, Raddad, et al. "[https://www.researchgate.net/profile/Shadi_Alzubi/publication/324487844_Automatic_categorization_of_Arabic_articles_based_on_their_political_orientation/links/5c1201c9299bf139c7549e1a/Automatic-categorization-of-Arabic-articles-based-on-their-political-orientation.pdf On the automatic categorization of Arabic articles based on their political orientation]." ''Third International Conference on Informatics Engineering and Information Science (ICIEIS2014)''. 2014.&lt;/ref&gt;
|N. Abdulla
|-
|Buzz in Social Media Dataset
|Data from Twitter and Tom's Hardware. This dataset focuses on specific buzz topics being discussed on those sites.
|Data is windowed so that the user can attempt to predict the events leading up to social media buzz.
|140,000
|Text
|Regression, Classification
|2013
|&lt;ref&gt;Kawala, François, et al. "[https://hal.archives-ouvertes.fr/hal-00881395/document Prédictions d'activité dans les réseaux sociaux en ligne]." ''4ième conférence sur les modèles et l'analyse des réseaux: Approches mathématiques et informatiques''. 2013.&lt;/ref&gt;&lt;ref&gt;{{cite arXiv |eprint=1601.00024|last1=Sabharwal|first1=Ashish|title=Selecting Near-Optimal Learners via Incremental Data Allocation|last2=Samulowitz|first2=Horst|last3=Tesauro|first3=Gerald|class=cs.LG|year=2015}}&lt;/ref&gt;
|F. Kawala et al.
|-
|Paraphrase and Semantic Similarity in Twitter (PIT)
|This dataset focuses on whether tweets have (almost) same meaning/information or not. Manually labeled. 
|tokenization, part-of-speech and named entity tagging
|18,762
|Text
|Regression, Classification
|2015
|&lt;ref&gt;Xu et al. "[https://www.aclweb.org/anthology/S15-2001 SemEval-2015 Task 1: Paraphrase and Semantic Similarity in Twitter (PIT)]" ''Proceedings of the 9th International Workshop on Semantic Evaluation''. 2015.&lt;/ref&gt;&lt;ref&gt;Xu et al. "[https://transacl.org/ojs/index.php/tacl/article/viewFile/498/64 Extracting Lexically Divergent Paraphrases from Twitter]" ''Transactions of the Association for Computational (TACL)''. 2014.&lt;/ref&gt;
|Xu et al.
|-
|Geoparse Twitter benchmark dataset
|This dataset contains tweets during different news events in different countries. Manually labeled location mentions.
|location annotations added to JSON metadata
|6,386
|Tweets, JSON
|Classification, Information Extraction
|2014
|&lt;ref&gt;{{cite journal|doi=10.1109/MIS.2013.126|title=Real-Time Crisis Mapping of Natural Disasters Using Social Media|journal=IEEE Intelligent Systems|volume=29|issue=2|pages=9–17|year=2014|last1=Middleton|first1=Stuart E|last2=Middleton|first2=Lee|last3=Modafferi|first3=Stefano|s2cid=15139204|url=https://eprints.soton.ac.uk/370581/1/ieee-is2014.pdf}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://pypi.org/project/geoparsepy|title=geoparsepy|year = 2016}} Python PyPI library&lt;/ref&gt;
|S.E. Middleton et al.
|-
|Dutch Social media collection
|This dataset contains Covid-19 tweets made by Dutch speakers or users from Netherlands. The data has been machine-annotated
|classified for sentiment, tweet text &amp; user description translated to English. Industry mention are extracted
|271,342
|JSONL
|Sentiment, multi-label classification, machine translation
|2020
|&lt;ref&gt;{{Cite journal|last=Gupta|first=Aakash|date=2020-12-05|title=Dutch social media collection|url=http://localhost:8080/dataset.xhtml?persistentId=doi:10.5072/FK2/MTPTL7|language=en|doi=10.5072/FK2/MTPTL7}}&lt;/ref&gt; &lt;ref&gt;{{Cite web|title=Streamlit|url=https://huggingface.co/datasets/viewer/?dataset=dutch_social|access-date=2020-12-18|website=huggingface.co}}&lt;/ref&gt; &lt;ref&gt;{{Cite web|title=Dutch Social media collection|url=https://kaggle.com/skylord/dutch-tweets|access-date=2020-12-18|website=kaggle.com|language=en}}&lt;/ref&gt;
|Aaaksh Gupta, CoronaWhy
|}

=== Dialogues ===
{| style="width: 100%" class="wikitable sortable"
! scope="col" style="width: 15%;" | Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" | Creator
|-
|NPS Chat Corpus
|Posts from age-specific online chat rooms.
|Hand privacy masked, tagged for part of speech and dialogue-act.
|~ 500,000
|XML
|NLP, programming, linguistics
|2007
|&lt;ref&gt;Forsyth, E., Lin, J., &amp; Martell, C. (2008, June 25). The NPS Chat Corpus. Retrieved from http://faculty.nps.edu/cmartell/NPSChat.htm&lt;/ref&gt;
|Forsyth, E., Lin, J., &amp; Martell, C.
|-
|Twitter Triple Corpus
|A-B-A triples extracted from Twitter.
|
|4,232
|Text
|NLP
|2016
|&lt;ref&gt;Alessandro Sordoni, Michel Galley, Michael Auli, Chris Brockett, Yangfeng Ji, Meg Mitchell, Jian-Yun Nie, Jianfeng Gao, and Bill Dolan, [https://arxiv.org/abs/1506.06714 A Neural Network Approach to Context-Sensitive Generation of Conversational Responses], Conference of the North American Chapter of the Association for Computational Linguistics – Human Language Technologies (NAACL-HLT 2015), June 2015.&lt;/ref&gt;
|Sordini, A. et al.
|-
|UseNet Corpus
|UseNet forum postings.
|Anonymized e-mails and URLs. Omitted documents with lengths &lt;500 words or &gt;500,000 words, or that were &lt;90% English.
|7 billion
|Text
|
|2011
|&lt;ref&gt;Shaoul, C. &amp; Westbury C. (2013) A reduced redundancy USENET corpus (2005-2011)  Edmonton, AB: University of Alberta (downloaded from http://www.psych.ualberta.ca/~westburylab/downloads/usenetcorpus.download.html)&lt;/ref&gt;
|Shaoul, C., &amp; Westbury C.
|-
|NUS SMS Corpus
|SMS messages collected between two users, with timing analysis.
|
|~ 10,000
|XML
|NLP
|2011
|&lt;ref&gt;KAN, M. (2011, January). NUS Short Message Service (SMS) Corpus. Retrieved from http://www.comp.nus.edu.sg/entrepreneurship/innovation/osr/corpus/&lt;/ref&gt;
|KAN, M
|-
|Reddit All Comments Corpus
|All Reddit comments (as of 2015).
|
|~ 1.7 billion
|JSON
|NLP, research
|2015
|&lt;ref&gt;Stuck_In_the_Matrix. (2015, July 3). I have every publicly available Reddit comment for research. ~ 1.7 billion comments @ 250 GB compressed. Any interest in this? [Original post]. Message posted to https://www.reddit.com/r/datasets/comments/3bxlg7/i_have_every_publicly_available_reddit_comment/&lt;/ref&gt;
|Stuck_In_the_Matrix
|-
|Ubuntu Dialogue Corpus
|Dialogues extracted from Ubuntu chat stream on IRC.
|
|
|CSV
|Dialogue Systems Research
|2015
|&lt;ref&gt;Ryan Lowe, Nissan Pow, Iulian V. Serban and Joelle Pineau, "[https://arxiv.org/abs/1506.08909 The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructure Multi-Turn Dialogue Systems]", SIGDial 2015.&lt;/ref&gt;
|Lowe, R. et al.
|}

=== Other text ===
{| style="width: 100%" class="wikitable sortable"
! scope="col" style="width: 15%;" |Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" |Creator
|-
| Web of Science Dataset
| Hierarchical Datasets for Text Classification
|None.
|46,985
|Text
|Classification,
Categorization
|2017
| &lt;ref name="KOW2017"&gt;K. Kowsari, D. E. Brown, M. Heidarysafa, K. Jafari Meimandi, M. S. Gerber and L. E. Barnes, "HDLTex: Hierarchical Deep Learning for Text Classification", 2017 16th IEEE International Conference on Machine Learning and Applications (ICMLA), pp. 364-371. doi: [https://doi.org/10.1109/ICMLA.2017.0-134 10.1109/ICMLA.2017.0-134]&lt;/ref&gt;&lt;ref name="KOW2017WOS"&gt;K. Kowsari, D. E. Brown, M. Heidarysafa, K. Jafari Meimandi, M. S. Gerber and L. E. Barnes, "Web of Science Dataset",  {{doi|10.17632/9rw3vkcfy4.6}}&lt;/ref&gt;
|K. Kowsari et al.
|-
|Legal Case Reports
|[[Federal Court of Australia]] cases from 2006 to 2009.
|None.
|4,000
|Text
|Summarization,
citation analysis
|2012
|&lt;ref&gt;Galgani, Filippo, Paul Compton, and Achim Hoffmann. "[https://www.aclweb.org/anthology/W12-0515 Combining different summarization techniques for legal text]." ''Proceedings of the Workshop on Innovative Hybrid Approaches to the Processing of Textual Data''. Association for Computational Linguistics, 2012.&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Nagwani | first1 = N. K. | year = 2015 | title = Summarizing large text collection using topic modeling and clustering based on MapReduce framework | journal = Journal of Big Data | volume = 2 | issue = 1| pages = 1–18 | doi=10.1186/s40537-015-0020-5| doi-access = free }}&lt;/ref&gt;
|F. Galgani et al.
|-
|Blogger Authorship Corpus
|Blog entries of 19,320 people from blogger.com.
|Blogger self-provided gender, age, industry, and astrological sign.
|681,288
|Text
|Sentiment analysis, summarization, classification
|2006
|&lt;ref&gt;{{cite journal | last1 = Schler | first1 = Jonathan | display-authors = et al | title = Effects of Age and Gender on Blogging | url =https://www.aaai.org/Papers/Symposia/Spring/2006/SS-06-03/SS06-03-039.pdf | journal = AAAI Spring Symposium: Computational Approaches to Analyzing Weblogs | volume = 6 | year = 2006 }}&lt;/ref&gt;&lt;ref&gt;Anand, Pranav, et al. "Believe Me-We Can Do This! Annotating Persuasive Acts in Blog Text."''Computational Models of Natural Argument''. 2011.&lt;/ref&gt;
|J. Schler et al.
|-
|Social Structure of Facebook Networks
|Large dataset of the social structure of Facebook.
|None.
|100 colleges covered
|Text
|Network analysis, clustering
|2012
|&lt;ref&gt;Traud, Amanda L., Peter J. Mucha, and Mason A. Porter. "Social structure of Facebook networks." ''Physica A: Statistical Mechanics and its Applications''391.16 (2012): 4165–4180.&lt;/ref&gt;&lt;ref&gt;{{cite arXiv |eprint=1206.6474|last1=Richard|first1=Emile|title=Estimation of Simultaneously Sparse and Low Rank Matrices|last2=Savalle|first2=Pierre-Andre|last3=Vayatis|first3=Nicolas|class=cs.DS|year=2012}}&lt;/ref&gt;
|A. Traud et al.
|-
|Dataset for the Machine Comprehension of Text
|Stories and associated questions for testing comprehension of text.
|None.
|660
|Text
|Natural language processing, machine comprehension
|2013
|&lt;ref&gt;{{cite journal | last1 = Richardson | first1 = Matthew | last2 = Burges | first2 = Christopher JC | last3 = Renshaw | first3 = Erin | title = MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text | url = https://www.aclweb.org/anthology/D13-1020| journal = EMNLP | volume = 1 | year = 2013 }}&lt;/ref&gt;&lt;ref&gt;{{cite arXiv |eprint=1502.05698|last1=Weston|first1=Jason|title=Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks|last2=Bordes|first2=Antoine|last3=Chopra|first3=Sumit|last4= Rush|first4=Alexander M.|author5=Bart van Merriënboer|last6=Joulin|first6=Armand|last7=Mikolov|first7=Tomas|class=cs.AI|year=2015}}&lt;/ref&gt;
|M. Richardson et al.
|-
|The Penn Treebank Project
|Naturally occurring text annotated for linguistic structure.
|Text is parsed into semantic trees.
|~ 1M words
|Text
|Natural language processing, summarization
|1995
|&lt;ref&gt;{{cite journal | last1 = Marcus | first1 = Mitchell P. | last2 = Ann Marcinkiewicz | first2 = Mary | last3 = Santorini | first3 = Beatrice | year = 1993 | title = Building a large annotated corpus of English: The Penn Treebank | url = http://repository.upenn.edu/cgi/viewcontent.cgi?article=1246&amp;context=cis_reports | journal = Computational Linguistics | volume = 19 | issue = 2| pages = 313–330 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Collins | first1 = Michael | year = 2003 | title = Head-driven statistical models for natural language parsing | journal = Computational Linguistics | volume = 29 | issue = 4| pages = 589–637 | doi=10.1162/089120103322753356| doi-access = free }}&lt;/ref&gt;
|M. Marcus et al.
|-
|DEXTER Dataset
|Task given is to determine, from features given, which articles are about corporate acquisitions.
|Features extracted include word stems. Distractor features included.
|2600
|Text
|Classification
|2008
|&lt;ref&gt;Guyon, Isabelle, et al., eds. ''[https://books.google.com/books?id=FOTzBwAAQBAJ&amp;printsec=frontcover#v=onepage&amp;q=DEXTER&amp;f=false Feature extraction: foundations and applications]''. Vol. 207. Springer, 2008.&lt;/ref&gt;
|[[Reuters]]
|-
|Google Books N-grams
|[[N-gram]]s from a very large corpus of books
|None.
|2.2 TB of text
|Text
|Classification, clustering, regression
|2011
|&lt;ref&gt;Lin, Yuri, et al. "[https://www.aclweb.org/anthology/P/P12/P12-3029.pdf Syntactic annotations for the google books ngram corpus]." ''Proceedings of the ACL 2012 system demonstrations''. Association for Computational Linguistics, 2012.&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Krishnamoorthy | first1 = Niveda | display-authors = et al | title = Generating Natural-Language Video Descriptions Using Text-Mined Knowledge | url = https://www.aaai.org/ocs/index.php/AAAI/AAAI13/paper/download/6454/7204| journal = AAAI | volume = 1 | year = 2013 }}&lt;/ref&gt;
|Google
|-
|Personae Corpus
|Collected for experiments in Authorship Attribution and Personality Prediction. Consists of 145 Dutch-language essays.
|In addition to normal texts, syntactically annotated texts are given.
|145
|Text
|Classification, regression
|2008
|&lt;ref&gt;Luyckx, Kim, and Walter Daelemans. "[http://www.academia.edu/download/30766398/759.pdf Personae: a Corpus for Author and Personality Prediction from Text]." ''LREC''. 2008.&lt;/ref&gt;&lt;ref&gt;Solorio, Thamar, Ragib Hasan, and Mainul Mizan. "[https://www.aclweb.org/anthology/W13-1107 A case study of sockpuppet detection in wikipedia]." ''Workshop on Language Analysis in Social Media (LASM) at NAACL HLT''. 2013.&lt;/ref&gt;
|K. Luyckx et al.
|-
|CNAE-9 Dataset
|Categorization task for free text descriptions of Brazilian companies.
|Word frequency has been extracted.
|1080
|Text
|Classification
|2012
|&lt;ref&gt;Ciarelli, Patrick Marques, and Elias Oliveira. "[https://ieeexplore.ieee.org/abstract/document/5364970/ Agglomeration and elimination of terms for dimensionality reduction]." ''Intelligent Systems Design and Applications, 2009. ISDA'09. Ninth International Conference on''. IEEE, 2009.&lt;/ref&gt;&lt;ref&gt;Zhou, Mingyuan, Oscar Hernan Madrid Padilla, and James G. Scott. "Priors for random count matrices derived from a family of negative binomial processes." ''Journal of the American Statistical Association'' just-accepted (2015): 00–00.&lt;/ref&gt;
|P. Ciarelli et al.
|-
|Sentiment Labeled Sentences Dataset
|3000 sentiment labeled sentences.
|Sentiment of each sentence has been hand labeled as positive or negative.
|3000
|Text
|Classification, sentiment analysis
|2015
|&lt;ref&gt;Kotzias, Dimitrios, et al. "[http://datalab.ics.uci.edu/papers/kdd2015_dimitris.pdf From group to individual labels using deep features]." Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 2015.&lt;/ref&gt;&lt;ref&gt;{{cite arXiv |eprint=1602.08033|last1=Ning|first1=Yue|title=Modeling Precursors for Event Forecasting via Nested Multi-Instance Learning|last2=Muthiah|first2=Sathappan|last3=Rangwala|first3=Huzefa|last4=Ramakrishnan|first4=Naren|class=cs.SI|year=2016}}&lt;/ref&gt;
|D. Kotzias
|-
|BlogFeedback Dataset
|Dataset to predict the number of comments a post will receive based on features of that post.
|Many features of each post extracted.
|60,021
|Text
|Regression
|2014
|&lt;ref&gt;Buza, Krisztian. "[http://www.cs.bme.hu/~buza/pdfs/gfkl2012_blogs.pdf Feedback prediction for blogs]."''Data analysis, machine learning and knowledge discovery''. Springer International Publishing, 2014. 145–152.&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Soysal | first1 = Ömer M | year = 2015 | title = Association rule mining with mostly associated sequential patterns | journal = Expert Systems with Applications | volume = 42 | issue = 5| pages = 2582–2592 | doi=10.1016/j.eswa.2014.10.049}}&lt;/ref&gt;
|K. Buza
|-
|Stanford Natural Language Inference (SNLI) Corpus
|Image captions matched with newly constructed sentences to form entailment, contradiction, or neutral pairs.
|Entailment class labels, syntactic parsing by the Stanford PCFG parser
|570,000
|Text
|Natural language inference/recognizing textual entailment
|2015
|&lt;ref&gt;Bowman, Samuel, et al. "[https://arxiv.org/abs/1508.05326 A large annotated corpus for learning natural language inference]." Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP). ACL, 2015.&lt;/ref&gt;
|S. Bowman et al.
|-
|DSL Corpus Collection (DSLCC)
|A multilingual collection of short excerpts of journalistic texts in similar languages and dialects.
|None
|294,000 phrases
|Text
|Discriminating between similar languages
|2017
|&lt;ref&gt;{{Cite web|url=http://ttg.uni-saarland.de/resources/DSLCC/|title=DSL Corpus Collection|website=ttg.uni-saarland.de|access-date=2017-09-22}}&lt;/ref&gt;
|Tan, Liling et al.
|-
|[[Urban Dictionary]] Dataset
|Corpus of words, votes and definitions
|User names anonymised
|2,580,925
|CSV
|NLP, Machine comprehension
|2016 May
|&lt;ref&gt;{{Cite web | url=https://www.kaggle.com/therohk/urban-dictionary-words-dataset | title=Urban Dictionary Words and Definitions}}&lt;/ref&gt;
|Anonymous
|-
|T-REx
|[[Wikipedia]] abstracts aligned with [[Wikidata]] entities
|Alignment of Wikidata triples with Wikipedia abstracts
|11M aligned triples
|JSON and NIF [https://hadyelsahar.github.io/t-rex/]
|NLP, Relation Extraction
|2018
| &lt;ref&gt;H. Elsahar, P. Vougiouklis, A. Remaci, C. Gravier, J. Hare, F. Laforest, E. Simperl, "[https://www.aclweb.org/anthology/L18-1544 T-REx: A Large Scale Alignment of Natural Language with Knowledge Base Triples]", Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC-2018).&lt;/ref&gt;
| H. Elsahar et al.
|-
|General Language Understanding Evaluation (GLUE)
|Benchmark of nine tasks
|Various
|~1M sentences and sentence pairs
|
|NLU
|2018
| &lt;ref&gt;Wang, A., Singh, A., Michael, J., Hill, F., Levy, O., &amp; Bowman, S. R. (2018). Glue: A multi-task benchmark and analysis platform for natural language understanding. arXiv preprint arXiv:1804.07461.&lt;/ref&gt;&lt;ref&gt;{{cite news |title=Computers Are Learning to Read—But They're Still Not So Smart |url=https://www.wired.com/story/computers-are-learning-to-read-but-theyre-still-not-so-smart/ |access-date=29 December 2019 |work=Wired |language=en}}&lt;/ref&gt;
| Wang et al.
|-
|Atticus Open Contract Dataset (AOK) 
|Dataset of legal contracts with rich expert annotations
|
|~3,000 labels
|CSV and PDF
|Natural language processing, QnA
|2020
|
|[https://www.atticusprojectai.org The Atticus Project]
|-
|Vietnamese Image Captioning Dataset (UIT-ViIC) 
|Vietnamese Image Captioning Dataset
|
|19,250 captions for 3,850 images 
|CSV and PDF
|Natural language processing, Computer vision
|2020
|&lt;ref&gt;{{cite web| last1=Quan |first1=Hoang Lam |last2=Quang |first2=Duy Le |last3=Van Kiet |first3=Nguyen |last4=Ngan |first4=Luu-Thuy Nguyen. |url=https://www.springerprofessional.de/uit-viic-a-dataset-for-the-first-evaluation-on-vietnamese-image-/18612672 |title=UIT-ViIC: A Dataset for the First Evaluation on Vietnamese Image Captioning}}&lt;/ref&gt;
|Lam et al.
|-
|Vietnamese Names annotated with Genders (UIT-ViNames)
|Vietnamese Names annotated with Genders
|
|26,850 Vietnamese full names annotated with genders
|CSV 
|Natural language processing
|2020
|&lt;ref&gt;{{cite web| last1=To |first1=Quoc Huy |last2=Nguyen |first2=Van Kiet |last3=Nguyen |first3= Luu Thuy Ngan |last4=Nguyen |first4=Gia Tuan Anh. |url=https://arxiv.org/pdf/2010.10852.pdf |title=Gender Prediction Based on Vietnamese Names with Machine Learning Techniques}}&lt;/ref&gt;
|To et al.
|-
|}

== Sound data ==
Datasets of sounds and sound features.

=== Speech ===
{| class="wikitable sortable" style="width: 100%"
! scope="col" style="width: 15%;" | Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" | Creator
|-
|Zero Resource Speech Challenge 2015
|Spontaneous speech (English), Read speech (Xitsonga).
|raw wav 
| English: 5h, 12 speakers; Xitsonga: 2h30; 24 speakers
|sound
|Unsupervised discovery of speech features/subword units/word units
|2015
|&lt;ref&gt;M. Versteegh, R. Thiollière, T. Schatz, X.-N. Cao, X. Anguera, A. Jansen, and E. Dupoux (2015).  "The Zero Resource Speech Challenge 2015," in INTERSPEECH-2015.&lt;/ref&gt;&lt;ref&gt;M. Versteegh, X. Anguera, A. Jansen, and E. Dupoux, (2016). "[https://core.ac.uk/download/pdf/82574050.pdf The Zero Resource Speech Challenge 2015: Proposed Approaches and Results]," in SLTU-2016.&lt;/ref&gt;
|Versteegh et al.
|-
|Parkinson Speech Dataset
|Multiple recordings of people with and without Parkinson's Disease.
|Voice features extracted, disease scored by physician using [[unified Parkinson's disease rating scale]]
|1,040
|Text
|Classification, regression
|2013
|&lt;ref&gt;{{cite journal | last1 = Sakar | first1 = Betul Erdogdu | display-authors = et al | year = 2013 | title = Collection and analysis of a Parkinson speech dataset with multiple types of sound recordings | journal = IEEE Journal of Biomedical and Health Informatics| volume = 17 | issue = 4| pages = 828–834 | doi=10.1109/jbhi.2013.2245674| pmid = 25055311 | s2cid = 15491516 }}&lt;/ref&gt;&lt;ref&gt;Zhao, Shunan, et al. "[https://www.researchgate.net/profile/Steven_Livingstone2/publication/267623907_Automatic_detection_of_expressed_emotion_in_Parkinson%27s_Disease/links/5453af1d0cf26d5090a54cfe/Automatic-detection-of-expressed-emotion-in-Parkinsons-Disease.pdf Automatic detection of expressed emotion in Parkinson's disease]." ''Acoustics, Speech and Signal Processing (ICASSP), 2014 IEEE International Conference on''. IEEE, 2014.&lt;/ref&gt;
|B. E. Sakar et al.
|-
|Spoken Arabic Digits
|Spoken Arabic digits from 44 male and 44 female.
|Time-series of [[mel-frequency cepstrum]] coefficients.
|8,800
|Text
|Classification
|2010
|&lt;ref name=":2"&gt;Used in: Hammami, Nacereddine, and Mouldi Bedda. "Improved tree model for Arabic speech recognition." ''Computer Science and Information Technology (ICCSIT), 2010 3rd IEEE International Conference on''. Vol. 5. IEEE, 2010.&lt;/ref&gt;&lt;ref&gt;Maaten, Laurens. "[https://lvdmaaten.github.io/publications/papers/ICML_2011.pdf Learning discriminative fisher kernels]." ''Proceedings of the 28th International Conference on Machine Learning (ICML-11)''. 2011.&lt;/ref&gt;
|M. Bedda et al.
|-
|ISOLET Dataset
|Spoken letter names.
|Features extracted from sounds.
|7797
|Text
|Classification
|1994
|&lt;ref&gt;Cole, Ronald, and Mark Fanty. "[https://www.aclweb.org/anthology/H90-1075 Spoken letter recognition]." ''Proc. Third DARPA Speech and Natural Language Workshop''. 1990.&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Chapelle | first1 = Olivier | last2 = Sindhwani | first2 = Vikas | last3 = Keerthi | first3 = Sathiya S. | year = 2008 | title = Optimization techniques for semi-supervised support vector machines | url =http://www.jmlr.org/papers/volume9/chapelle08a/chapelle08a.pdf | journal = The Journal of Machine Learning Research | volume = 9 | pages = 203–233 }}&lt;/ref&gt;
|R. Cole et al.
|-
|Japanese Vowels Dataset
|Nine male speakers uttered two Japanese vowels successively.
|Applied 12-degree linear prediction analysis to it to obtain a discrete-time series with 12 cepstrum coefficients.
|640
|Text
|Classification
|1999
|&lt;ref&gt;{{cite journal | last1 = Kudo | first1 = Mineichi | last2 = Toyama | first2 = Jun | last3 = Shimbo | first3 = Masaru | year = 1999 | title = Multidimensional curve classification using passing-through regions | journal = Pattern Recognition Letters | volume = 20 | issue = 11| pages = 1103–1111 | doi=10.1016/s0167-8655(99)00077-x| citeseerx = 10.1.1.46.2515 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Jaeger | first1 = Herbert | display-authors = et al | year = 2007 | title = Optimization and applications of echo state networks with leaky-integrator neurons | journal = Neural Networks | volume = 20 | issue = 3| pages = 335–352 | doi=10.1016/j.neunet.2007.04.016| pmid = 17517495 }}&lt;/ref&gt;
|M. Kudo et al.
|-
|Parkinson's Telemonitoring Dataset
|Multiple recordings of people with and without Parkinson's Disease.
|Sound features extracted.
|5875
|Text
|Classification
|2009
|&lt;ref&gt;{{cite journal | last1 = Tsanas | first1 = Athanasios | display-authors = et al | year = 2010 | title = Accurate telemonitoring of Parkinson's disease progression by noninvasive speech tests | url = http://precedings.nature.com/documents/3920/version/1| journal = IEEE Transactions on Biomedical Engineering| volume = 57 | issue = 4| pages = 884–893 | doi=10.1109/tbme.2009.2036000| pmid = 19932995 | s2cid = 7382779 | type = Submitted manuscript }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Clifford | first1 = Gari D. | last2 = Clifton | first2 = David | year = 2012 | title = Wireless technology in disease management and medicine | journal = Annual Review of Medicine | volume = 63 | pages = 479–492 | doi=10.1146/annurev-med-051210-114650| pmid = 22053737 }}&lt;/ref&gt;
|A. Tsanas et al.
|-
|[[TIMIT]]
|Recordings of 630 speakers of eight major dialects of American English, each reading ten phonetically rich sentences.
|Speech is lexically and phonemically transcribed.
|6300
|Text
|Speech recognition, classification.
|1986
|&lt;ref&gt;{{cite journal | last1 = Zue | first1 = Victor | last2 = Seneff | first2 = Stephanie | last3 = Glass | first3 = James | year = 1990 | title = Speech database development at MIT: TIMIT and beyond | journal = Speech Communication | volume = 9 | issue = 4| pages = 351–356 | doi=10.1016/0167-6393(90)90010-7}}&lt;/ref&gt;&lt;ref&gt;Kapadia, Sadik, Valtcho Valtchev, and S. J. Young. "MMI training for continuous phoneme recognition on the TIMIT database." ''Acoustics, Speech, and Signal Processing, 1993. ICASSP-93., 1993 IEEE International Conference on''. Vol. 2. IEEE, 1993.&lt;/ref&gt;
|J. Garofolo et al.
|-
|[[Arabic Speech Corpus]]
|A single-speaker, [[Modern Standard Arabic]] (MSA) speech corpus with phonetic and orthographic transcripts aligned to phoneme level
|Speech is orthographically and phonetically transcribed with stress marks.
|~1900
|Text, WAV
|Speech Synthesis, Speech Recognition, Corpus Alignment, Speech Therapy, Education.
|2016
|&lt;ref name="HALABI2016"&gt;{{cite thesis |last=Halabi |first=Nawar |year=2016 |title=Modern Standard Arabic Phonetics for Speech Synthesis |url=http://en.arabicspeechcorpus.com/Nawar%20Halabi%20PhD%20Thesis%20Revised.pdf |type=PhD Thesis |publisher=[[University of Southampton]], School of Electronics and Computer Science}}&lt;/ref&gt;
|N. Halabi
|-
|[[Common Voice]]
|A public domain database of [[Crowdsourcing|crowdsourced]] data across a wide range of dialects. 
|Validation by other users 
|English: 1,118 hours
|MP3 with corresponding text files 
|Speech recognition
|June 2017 (December 2019)
|&lt;ref&gt;{{cite arXiv | last1=Ardila | first1=Rosana | last2=Branson | first2=Megan | last3=Davis | first3=Kelly | last4=Henretty | first4=Michael | last5=Kohler | first5=Michael | last6=Meyer | first6=Josh | last7=Morais | first7=Reuben | last8=Saunders | first8=Lindsay | last9=Tyers | first9=Francis M. | last10=Weber | first10=Gregor | title=Common Voice: A Massively-Multilingual Speech Corpus | date=Dec 13, 2019 | class=cs.CL | eprint=1912.06670v2 }}&lt;/ref&gt;
|[[Mozilla]]
|}

=== Music ===
{| class="wikitable sortable" style="width: 100%"
! scope="col" style="width: 15%;" | Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" | Creator
|-
|Geographic Origin of Music Data Set
|Audio features of music samples from different locations.
|Audio features extracted using MARSYAS software.
|1,059
|Text
|Geographic classification, clustering
|2014
|&lt;ref&gt;Zhou, Fang, Q. Claire, and Ross D. King. "[https://ieeexplore.ieee.org/abstract/document/7023456/ Predicting the geographical origin of music]." ''Data Mining (ICDM), 2014 IEEE International Conference on''. IEEE, 2014.&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Saccenti | first1 = Edoardo | last2 = Camacho | first2 = José | year = 2015 | title = On the use of the observation‐wise k‐fold operation in PCA cross‐validation | journal = Journal of Chemometrics | volume = 29 | issue = 8| pages = 467–478 | doi=10.1002/cem.2726| hdl = 10481/55302 | s2cid = 62248957 | hdl-access = free }}&lt;/ref&gt;
|F. Zhou et al.
|-
|Million Song Dataset
|Audio features from one million different songs.
|Audio features extracted.
|1M
|Text
|Classification, clustering
|2011
|&lt;ref&gt;Bertin-Mahieux, Thierry, et al. "The million song dataset." ''ISMIR 2011: Proceedings of the 12th International Society for Music Information Retrieval Conference, 24–28 October 2011, Miami, Florida''. University of Miami, 2011.&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Henaff | first1 = Mikael | display-authors = et al | title = Unsupervised learning of sparse features for scalable audio classification | url =https://archives.ismir.net/ismir2011/paper/000128.pdf | journal = ISMIR | volume = 11 | year = 2011 }}&lt;/ref&gt;
|T. Bertin-Mahieux et al.
|-
|MUSDB18
|Multi-track popular music recordings 
|Raw audio
|150
|MP4, WAV
|Source Separation
|2017
|&lt;ref&gt;{{Cite book | doi=10.5281/zenodo.1117372| title=MUSDB18 - a corpus for music separation | year=2017 | last1=Rafii | first1=Zafar | chapter=Music }}&lt;/ref&gt;
|Z. Rafii et al.
|-
|[[Free Music Archive]]
|Audio under [[Creative Commons license|Creative Commons]] from 100k songs (343 days, 1TiB) with a hierarchy of 161 genres, metadata, user data, free-form text.
|Raw audio and audio features.
|106,574
|Text, MP3
|Classification, recommendation
|2017
|&lt;ref&gt;{{cite arxiv|last1=Defferrard|first1=Michaël|last2=Benzi|first2=Kirell|last3=Vandergheynst|first3=Pierre|last4=Bresson|first4=Xavier|date=6 December 2016|title=FMA: A Dataset For Music Analysis|eprint=1612.01840|class=cs.SD}}&lt;/ref&gt;
|M. Defferrard et al.
|-
|Bach Choral Harmony Dataset
|Bach chorale chords.
|Audio features extracted.
|5665
|Text
|Classification
|2014
|&lt;ref&gt;{{cite journal | last1 = Esposito | first1 = Roberto | last2 = Radicioni | first2 = Daniele P. | year = 2009 | title = Carpediem: Optimizing the viterbi algorithm and applications to supervised sequential learning | url =http://www.jmlr.org/papers/volume10/esposito09a/esposito09a.pdf | journal = The Journal of Machine Learning Research | volume = 10 | pages = 1851–1880 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Sourati | first1 = Jamshid | display-authors = et al | year = 2016 | title = Classification Active Learning Based on Mutual Information | journal = Entropy | volume = 18 | issue = 2| page = 51 | doi=10.3390/e18020051| bibcode = 2016Entrp..18...51S | doi-access = free }}&lt;/ref&gt;
|D. Radicioni et al.
|}

=== Other sounds ===
{| style="width: 100%" class="wikitable sortable"
! scope="col" style="width: 15%;" | Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" | Creator
|-
|UrbanSound
|Labeled sound recordings of sounds like air conditioners, car horns and children playing.
|Sorted into folders by class of events as well as metadata in a JSON file and annotations in a CSV file.
|1,059
|Sound
([[WAV]])
|Classification
|2014
|&lt;ref&gt;Salamon, Justin; Jacoby, Christopher; Bello, Juan Pablo. "[https://www.researchgate.net/profile/Justin_Salamon/publication/267269056_A_Dataset_and_Taxonomy_for_Urban_Sound_Research/links/544936af0cf2f63880810a84/A-Dataset-and-Taxonomy-for-Urban-Sound-Research.pdf A dataset and taxonomy for urban sound research]." ''Proceedings of the ACM International Conference on Multimedia''. ACM, 2014.&lt;/ref&gt;&lt;ref&gt;{{cite arXiv |eprint=1502.00141|last1=Lagrange|first1=Mathieu|title=An evaluation framework for event detection using a morphological model of acoustic scenes| last2=Lafay|first2=Grégoire|last3=Rossignol|first3=Mathias|last4=Benetos|first4=Emmanouil|last5=Roebel|first5=Axel|class=stat.ML|year=2015}}&lt;/ref&gt;
|J. Salamon et al.
|-
|AudioSet
|10-second sound snippets from YouTube videos, and an ontology of over 500 labels. 
|128-d PCA'd VGG-ish features every 1 second.
|2,084,320
|Text (CSV) and TensorFlow Record files
|Classification
|2017
|&lt;ref&gt;Gemmeke, Jort F., et al. "Audio Set: An ontology and human-labeled dataset for audio events." [[IEEE]] [[International Conference on Acoustics, Speech, and Signal Processing]] (ICASSP). 2017.&lt;/ref&gt;
|J. Gemmeke et al., Google
|-
|Bird Audio Detection challenge
|Audio from environmental monitoring stations, plus crowdsourced recordings
|
|17,000+
|
|Classification
|2016 (2018)
|&lt;ref&gt;{{cite news |title=Watch out, birders: Artificial intelligence has learned to spot birds from their songs |url=http://www.sciencemag.org/news/2018/07/watch-out-birders-artificial-intelligence-has-learned-spot-birds-their-songs |access-date=22 July 2018 |work=Science {{!}} AAAS |date=18 July 2018 |language=en}}&lt;/ref&gt;&lt;ref&gt;{{cite web |title=Bird Audio Detection challenge |url=http://machine-listening.eecs.qmul.ac.uk/bird-audio-detection-challenge/ |website=Machine Listening Lab at [[Queen Mary University]] |access-date=22 July 2018 |date=3 May 2016}}&lt;/ref&gt;
|[[Queen Mary University]] and [[IEEE Signal Processing Society]]
|-
|WSJ0 Hipster Ambient Mixtures
|Audio from WSJ0 mixed with noise recorded in the [[San Francisco Bay Area]]
|Noise clips matched to WSJ0 clips
|28,000
|Sound ([[WAV]])
|Audio source separation
|2019
|&lt;ref&gt;Wichern, G., et al. "WHAM!: Extending Speech Separation to Noisy Environments", Interspeech, 2019, https://arxiv.org/abs/1907.01160&lt;/ref&gt;
|Wichern, G., et al., Whisper and MERL
|-
|Clotho
|4,981 audio samples of 15 to 30 seconds long, each audio sample having five different captions of eight to 20 words long.
|
|24,905
|Sound ([[WAV]]) and text ([[Comma-separated values|CSV]])
|Automated audio captioning
|2020
|&lt;ref&gt;Drossos, K., Lipping, S., and Virtanen, T. "Clotho: An Audio Captioning Dataset" [[IEEE]] [[International Conference on Acoustics, Speech, and Signal Processing]] (ICASSP). 2020.&lt;/ref&gt;&lt;ref&gt;Drossos, K., Lipping, S., and Virtanen, T. (2019). Clotho dataset (Version 1.0) [Data set]. [[Zenodo]]. [http://doi.org/10.5281/zenodo.3490684 http://doi.org/10.5281/zenodo.3490684]&lt;/ref&gt;
|K. Drossos, S. Lipping, and T. Virtanen
|}

== Signal data ==
Datasets containing electric signal information requiring some sort of [[Signal processing]] for further analysis.

=== Electrical ===
{| style="width: 100%" class="wikitable sortable"
! scope="col" style="width: 15%;" |Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" |Creator
|-
|Witty Worm Dataset
|Dataset detailing the spread of the [[Witty (computer worm)|Witty worm]] and the infected computers.
|Split into a publicly available set and a restricted set containing more sensitive information like IP and UDP headers.
|55,909 IP addresses
|Text
|Classification
|2004
|&lt;ref&gt;The CAIDA UCSD Dataset on the Witty Worm – 19–24 March 2004, http://www.caida.org/data/passive/witty_worm_dataset.xml&lt;/ref&gt;&lt;ref&gt;Chen, Zesheng, and Chuanyi Ji. "[https://pdfs.semanticscholar.org/672e/7be9499fef9a7ff6b131b650a4de7614aae8.pdf Optimal worm-scanning method using vulnerable-host distributions]." ''International Journal of Security and Networks'' 2.1–2 (2007): 71–80.&lt;/ref&gt;
|Center for Applied Internet Data Analysis
|-
|Cuff-Less Blood Pressure Estimation Dataset
|Cleaned vital signals from human patients which can be used to estimate blood pressure.
|125&amp;nbsp;Hz vital signs have been cleaned.
|12,000
|Text
|Classification, regression
|2015
|&lt;ref&gt;Kachuee, Mohamad, et al. "[http://download.xuebalib.com/533elteIDEwk.pdf Cuff-less high-accuracy calibration-free blood pressure estimation using pulse transit time]." ''Circuits and Systems (ISCAS), 2015 IEEE International Symposium on''. IEEE, 2015.&lt;/ref&gt;&lt;ref&gt;PhysioBank, PhysioToolkit. "PhysioNet: components of a new research resource for complex physiologic signals." ''Circulation. v101 i23. e215-e220''.&lt;/ref&gt;
|M. Kachuee et al.
|-
|Gas Sensor Array Drift Dataset
|Measurements from 16 chemical sensors utilized in simulations for drift compensation.
|Extensive number of features given.
|13,910
|Text
|Classification
|2012
|&lt;ref&gt;{{cite journal | last1 = Vergara | first1 = Alexander | display-authors = et al | year = 2012 | title = Chemical gas sensor drift compensation using classifier ensembles | journal = Sensors and Actuators B: Chemical | volume = 166 | pages = 320–329 | doi=10.1016/j.snb.2012.01.074}}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Korotcenkov | first1 = G. | last2 = Cho | first2 = B. K. | year = 2014 | title = Engineering approaches to improvement of conductometric gas sensor parameters. Part 2: Decrease of dissipated (consumable) power and improvement stability and reliability | journal = Sensors and Actuators B: Chemical | volume = 198 | pages = 316–341 | doi=10.1016/j.snb.2014.03.069}}&lt;/ref&gt;
|A. Vergara
|-
|Servo Dataset
|Data covering the nonlinear relationships observed in a servo-amplifier circuit.
|Levels of various components as a function of other components are given.
|167
|Text
|Regression
|1993
|&lt;ref&gt;{{cite journal | last1 = Quinlan | first1 = John R | title = Learning with continuous classes | url =https://sci2s.ugr.es/keel/pdf/algorithm/congreso/1992-Quinlan-AI.pdf | journal = 5th Australian Joint Conference on Artificial Intelligence | volume = 92 | year = 1992 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Merz | first1 = Christopher J. | last2 = Pazzani | first2 = Michael J. | year = 1999 | title = A principal components approach to combining regression estimates | journal = Machine Learning | volume = 36 | issue = 1–2| pages = 9–32 | doi=10.1023/a:1007507221352| doi-access = free }}&lt;/ref&gt;
|K. Ullrich
|-
|UJIIndoorLoc-Mag Dataset
|Indoor localization database to test indoor positioning systems. Data is magnetic field based.
|Train and test splits given.
|40,000
|Text
|Classification, regression, clustering
|2015
|&lt;ref&gt;Torres-Sospedra, Joaquin, et al. "UJIIndoorLoc-Mag: A new database for magnetic field-based localization problems." ''Indoor Positioning and Indoor Navigation (IPIN), 2015 International Conference on''. IEEE, 2015.&lt;/ref&gt;&lt;ref&gt;Berkvens, Rafael, Maarten Weyn, and Herbert Peremans. "[https://www.researchgate.net/profile/Raf_Berkvens/publication/284154212_Mean_Mutual_Information_of_Probabilistic_Wi-Fi_Localization/links/564c6b7508aeab8ed5e92fcb.pdf Mean Mutual Information of Probabilistic Wi-Fi Localization]." ''Indoor Positioning and Indoor Navigation (IPIN), 2015 International Conference on. Banff, Canada: IPIN''. 2015.&lt;/ref&gt;
|D. Rambla et al.
|-
|Sensorless Drive Diagnosis Dataset
|Electrical signals from motors with defective components.
|Statistical features extracted.
|58,508
|Text
|Classification
|2015
|&lt;ref&gt;Paschke, Fabian, et al. "Sensorlose Zustandsüberwachung an Synchronmotoren."''Proceedings. 23. Workshop Computational Intelligence, Dortmund, 5.-6. Dezember 2013''. KIT Scientific Publishing, 2013.&lt;/ref&gt;&lt;ref&gt;Lessmeier, Christian, et al. "[https://www.researchgate.net/profile/Olaf_Enge-Rosenblatt/publication/264441239_Data_Acquisition_and_Signal_Analysis_from_Measured_Motor_Currents_for_Defect_Detection_in_Electromechanical_Drive_Systems/links/53df97e90cf2a768e49bb3b9.pdf Data Acquisition and Signal Analysis from Measured Motor Currents for Defect Detection in Electromechanical Drive Systems]."&lt;/ref&gt;
|M. Bator
|}

=== Motion-tracking ===
{| class="wikitable sortable" style="width: 100%"
! scope="col" style="width: 15%;" |Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" |Creator
|-
|Wearable Computing: Classification of Body Postures and Movements (PUC-Rio)
|People performing five standard actions while wearing motion trackers.
|None.
|165,632
|Text
|Classification
|2013
|&lt;ref&gt;Ugulino, Wallace, et al. "[http://groupware.secondlab.inf.puc-rio.br/public/papers/2012.Ugulino.WearableComputing.HAR.Classifier.RIBBON.pdf Wearable computing: Accelerometers’ data classification of body postures and movements]." ''Advances in Artificial Intelligence-SBIA 2012''. Springer Berlin Heidelberg, 2012. 52–61.&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Schneider | first1 = Jan | display-authors = et al | year = 2015 | title = Augmenting the senses: a review on sensor-based learning support | journal = Sensors | volume = 15 | issue = 2| pages = 4097–4133 | doi=10.3390/s150204097| pmid = 25679313 | pmc = 4367401 }}&lt;/ref&gt;
|[[Pontifical Catholic University of Rio de Janeiro]]
|-
|Gesture Phase Segmentation Dataset
|Features extracted from video of people doing various gestures.
|Features extracted aim at studying gesture phase segmentation.
|9900
|Text
|Classification, clustering
|2014
|&lt;ref&gt;Madeo, Renata CB, Clodoaldo AM Lima, and Sarajane M. Peres. "[https://tarjomefa.com/wp-content/uploads/2016/11/5781-English.pdf Gesture unit segmentation using support vector machines: segmenting gestures from rest positions]." ''Proceedings of the 28th Annual ACM Symposium on Applied Computing''. ACM, 2013.&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Lun | first1 = Roanna | last2 = Zhao | first2 = Wenbing | year = 2015 | title = A survey of applications and human motion recognition with Microsoft Kinect | url = https://engagedscholarship.csuohio.edu/cgi/viewcontent.cgi?article=1417&amp;context=enece_facpub| journal = International Journal of Pattern Recognition and Artificial Intelligence | volume = 29 | issue = 5| page = 1555008 | doi=10.1142/s0218001415550083}}&lt;/ref&gt;
|R. Madeo et a
|-
|Vicon Physical Action Data Set Dataset
|10 normal and 10 aggressive physical actions that measure the human activity tracked by a 3D tracker.
|Many parameters recorded by 3D tracker.
|3000
|Text
|Classification
|2011
|&lt;ref&gt;Theodoridis, Theodoros, and Huosheng Hu. "[https://cswww.sx.ac.uk/staff/hhu/Papers/ROBIO07-66.pdf Action classification of 3d human models using dynamic ANNs for mobile robot surveillance]."''Robotics and Biomimetics, 2007. ROBIO 2007. IEEE International Conference on''. IEEE, 2007.&lt;/ref&gt;&lt;ref&gt;Etemad, Seyed Ali, and Ali Arya. "[https://ieeexplore.ieee.org/abstract/document/5357690/ 3D human action recognition and style transformation using resilient backpropagation neural networks." ''Intelligent Computing and Intelligent Systems, 2009. ICIS 2009. IEEE International Conference on''. Vol. 4. IEEE, 2009.]&lt;/ref&gt;
|T. Theodoridis
|-
|Daily and Sports Activities Dataset
|Motor sensor data for 19 daily and sports activities.
|Many sensors given, no preprocessing done on signals.
|9120
|Text
|Classification
|2013
|&lt;ref&gt;{{cite journal | last1 = Altun | first1 = Kerem | last2 = Barshan | first2 = Billur | last3 = Tunçel | first3 = Orkun | year = 2010 | title = Comparative study on classifying human activities with miniature inertial and magnetic sensors | journal = Pattern Recognition | volume = 43 | issue = 10| pages = 3605–3620 | doi=10.1016/j.patcog.2010.04.019| hdl = 11693/11947 | hdl-access = free }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Nathan | first1 = Ran  |author-link1=Ran Nathan | display-authors = et al | year = 2012 | title = Using tri-axial acceleration data to identify behavioral modes of free-ranging animals: general concepts and tools illustrated for griffon vultures | journal = The Journal of Experimental Biology | volume = 215 | issue = 6| pages = 986–996 | doi=10.1242/jeb.058602| pmid = 22357592 | pmc = 3284320 }}&lt;/ref&gt;
|B. Barshan et al.
|-
|Human Activity Recognition Using Smartphones Dataset
|Gyroscope and accelerometer data from people wearing smartphones and performing normal actions.
|Actions performed are labeled, all signals preprocessed for noise.
|10,299
|Text
|Classification
|2012
|&lt;ref&gt;Anguita, Davide, et al. "[https://upcommons.upc.edu/bitstream/handle/2117/101769/IWAAL2012.pdf Human activity recognition on smartphones using a multiclass hardware-friendly support vector machine]." ''Ambient assisted living and home care''. Springer Berlin Heidelberg, 2012. 216–223.&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Su | first1 = Xing | last2 = Tong | first2 = Hanghang | last3 = Ji | first3 = Ping | year = 2014 | title = Activity recognition with smartphone sensors | journal = Tsinghua Science and Technology | volume = 19 | issue = 3| pages = 235–249 | doi=10.1109/tst.2014.6838194}}&lt;/ref&gt;
|J. Reyes-Ortiz et al.
|-
|Australian Sign Language Signs
|Australian sign language signs captured by motion-tracking gloves.
|None.
|2565
|Text
|Classification
|2002
|&lt;ref&gt;Kadous, Mohammed Waleed. ''[https://pdfs.semanticscholar.org/4bad/c3f0ad169ed9ec7d073375e9b168fa9f6c8f.pdf Temporal classification: Extending the classification paradigm to multivariate time series]''. Diss. The University of New South Wales, 2002.&lt;/ref&gt;&lt;ref&gt;Graves, Alex, et al. "[https://mediatum.ub.tum.de/doc/1292048/file.pdf Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks]." ''Proceedings of the 23rd international conference on Machine learning''. ACM, 2006.&lt;/ref&gt;
|M. Kadous
|-
|Weight Lifting Exercises monitored with Inertial Measurement Units
|Five variations of the biceps curl exercise monitored with IMUs.
|Some statistics calculated from raw data.
|39,242
|Text
|Classification
|2013
|&lt;ref&gt;Velloso, Eduardo, et al. "[https://www.perceptualui.org/publications/velloso13_ah.pdf Qualitative activity recognition of weight lifting exercises]."''Proceedings of the 4th Augmented Human International Conference''. ACM, 2013.&lt;/ref&gt;&lt;ref&gt;Mortazavi, Bobak Jack, et al. "[http://www.thehabitslab.com/assets/papers/28.pdf Determining the single best axis for exercise repetition recognition and counting on smartwatches]." ''Wearable and Implantable Body Sensor Networks (BSN), 2014 11th International Conference on''. IEEE, 2014.&lt;/ref&gt;
|W. Ugulino et al.
|-
|sEMG for Basic Hand movements Dataset
|Two databases of surface electromyographic signals of 6 hand movements.
|None.
|3000
|Text
|Classification
|2014
|&lt;ref&gt;Sapsanis, Christos, et al. "[https://www.researchgate.net/profile/Christos_Sapsanis/publication/257602303_Improving_EMG_based_classification_of_basic_hand_movements_using_EMD/links/56dfb7fd08ae979addef64a2/Improving-EMG-based-classification-of-basic-hand-movements-using-EMD.pdf Improving EMG based Classification of basic hand movements using EMD]." ''Engineering in Medicine and Biology Society (EMBC), 2013 35th Annual International Conference of the IEEE''. IEEE, 2013.&lt;/ref&gt;&lt;ref name="Andrianesis, Konstantinos 2015"&gt;{{cite journal | last1 = Andrianesis | first1 = Konstantinos | last2 = Tzes | first2 = Anthony | year = 2015 | title = Development and control of a multifunctional prosthetic hand with shape memory alloy actuators | journal = Journal of Intelligent &amp; Robotic Systems | volume = 78 | issue = 2| pages = 257–289 | doi=10.1007/s10846-014-0061-6| s2cid = 207174078 }}&lt;/ref&gt;
|C. Sapsanis et al.
|-
|REALDISP Activity Recognition Dataset
|Evaluate techniques dealing with the effects of sensor displacement in wearable activity recognition.
|None.
|1419
|Text
|Classification
|2014
|&lt;ref name="Andrianesis, Konstantinos 2015" /&gt;&lt;ref&gt;{{cite journal | last1 = Banos | first1 = Oresti | display-authors = et al | year = 2014 | title = Dealing with the effects of sensor displacement in wearable activity recognition | journal = Sensors | volume = 14 | issue = 6| pages = 9995–10023 | doi=10.3390/s140609995| pmid = 24915181 | pmc=4118358}}&lt;/ref&gt;
|O. Banos et al.
|-
|Heterogeneity Activity Recognition Dataset
|Data from multiple different smart devices for humans performing various activities.
|None.
|43,930,257
|Text
|Classification, clustering
|2015
|&lt;ref&gt;Stisen, Allan, et al. "[https://www.researchgate.net/profile/Henrik_Blunck/publication/301464144_Smart_Devices_are_Different_Assessing_and_MitigatingMobile_Sensing_Heterogeneities_for_Activity_Recognition/links/585a4c4908ae3852d256f186.pdf Smart Devices are Different: Assessing and MitigatingMobile Sensing Heterogeneities for Activity Recognition]."''Proceedings of the 13th ACM Conference on Embedded Networked Sensor Systems''. ACM, 2015.&lt;/ref&gt;&lt;ref&gt;Bhattacharya, Sourav, and Nicholas D. Lane. "[http://discovery.ucl.ac.uk/1503672/1/deepwatch_wristsense.pdf From Smart to Deep: Robust Activity Recognition on Smartwatches using Deep Learning]."&lt;/ref&gt;
|A. Stisen et al.
|-
|Indoor User Movement Prediction from RSS Data
|Temporal wireless network data that can be used to track the movement of people in an office.
|None.
|13,197
|Text
|Classification
|2016
|&lt;ref&gt;{{cite journal | last1 = Bacciu | first1 = Davide | display-authors = et al | year = 2014 | title = An experimental characterization of reservoir computing in ambient assisted living applications | journal = Neural Computing and Applications | volume = 24 | issue = 6| pages = 1451–1464 | doi=10.1007/s00521-013-1364-4| hdl = 11568/237959 | s2cid = 14124013 | hdl-access = free }}&lt;/ref&gt;&lt;ref&gt;{{Cite book|chapter-url=https://link.springer.com/chapter/10.1007/978-3-642-41043-7_3|doi = 10.1007/978-3-642-41043-7_3|chapter = Multisensor Data Fusion for Activity Recognition Based on Reservoir Computing|title = Evaluating AAL Systems Through Competitive Benchmarking|series = Communications in Computer and Information Science|year = 2013|last1 = Palumbo|first1 = Filippo|last2 = Barsocchi|first2 = Paolo|last3 = Gallicchio|first3 = Claudio|last4 = Chessa|first4 = Stefano|last5 = Micheli|first5 = Alessio|volume = 386|pages = 24–35|isbn = 978-3-642-41042-0}}&lt;/ref&gt;
|D. Bacciu
|-
|PAMAP2 Physical Activity Monitoring Dataset
|18 different types of physical activities performed by 9 subjects wearing 3 IMUs.
|None.
|3,850,505
|Text
|Classification
|2012
|&lt;ref&gt;Reiss, Attila, and Didier Stricker. "[https://www.researchgate.net/profile/Attila_Reiss/publication/235348485_Introducing_a_New_Benchmarked_Dataset_for_Activity_Monitoring/links/00b7d5309d19ca4346000000/Introducing-a-New-Benchmarked-Dataset-for-Activity-Monitoring.pdf Introducing a new benchmarked dataset for activity monitoring]."''Wearable Computers (ISWC), 2012 16th International Symposium on''. IEEE, 2012.&lt;/ref&gt;
|A. Reiss
|-
|OPPORTUNITY Activity Recognition Dataset
|Human Activity Recognition from wearable, object, and ambient sensors is a dataset devised to benchmark human activity recognition algorithms.
|None.
|2551
|Text
|Classification
|2012
|&lt;ref&gt;Roggen, Daniel, et al. "[https://infoscience.epfl.ch/record/138648/files/RoggenFoCaHoFaTrLuPiBaKuFeHoRiChMi09.pdf OPPORTUNITY: Towards opportunistic activity and context recognition systems]." ''World of Wireless, Mobile and Multimedia Networks &amp; Workshops, 2009. WoWMoM 2009. IEEE International Symposium on a''. IEEE, 2009.&lt;/ref&gt;&lt;ref&gt;Kurz, Marc, et al. "[https://www.researchgate.net/profile/Marc_Kurz/publication/220271166_Dynamic_Quantification_of_Activity_Recognition_Capabilities_in_Opportunistic_Systems/links/09e4150f66b480c97a000000/Dynamic-Quantification-of-Activity-Recognition-Capabilities-in-Opportunistic-Systems.pdf Dynamic quantification of activity recognition capabilities in opportunistic systems]." ''Vehicular Technology Conference (VTC Spring), 2011 IEEE 73rd''. IEEE, 2011.&lt;/ref&gt;
|D. Roggen et al.
|-
|Real World Activity Recognition Dataset
|Human Activity Recognition from wearable devices. Distinguishes between seven on-body device positions and comprises six different kinds of sensors.
|None.
|3,150,000 (per sensor)
|Text
|Classification
|2016
|&lt;ref&gt;Sztyler, Timo, and Heiner Stuckenschmidt. "[https://sensor.informatik.uni-mannheim.de/publications/presentation/percom2016.pdf On-body localization of wearable devices: an investigation of position-aware activity recognition]." ''Pervasive Computing and Communications (PerCom), 2016 IEEE International Conference on''. IEEE, 2016.&lt;/ref&gt;
|T. Sztyler et al.
|-
|Toronto Rehab Stroke Pose Dataset
|3D human pose estimates (Kinect) of stroke patients and healthy participants performing a set of tasks using a stroke rehabilitation robot.
|None.
|10 healthy person and 9 stroke survivors (3500-6000 frames per person)
|CSV
|Classification
|2017
|&lt;ref&gt;{{Cite journal|last1=Zhi|first1=Ying Xuan|last2=Lukasik|first2=Michelle|last3=Li|first3=Michael H.|last4=Dolatabadi|first4=Elham|last5=Wang|first5=Rosalie H.|last6=Taati|first6=Babak|date=2018|title=Automatic Detection of Compensation During Robotic Stroke Rehabilitation Therapy|journal=IEEE Journal of Translational Engineering in Health and Medicine|volume=6|pages=2100107|doi=10.1109/JTEHM.2017.2780836|issn=2168-2372|pmc=5788403|pmid=29404226}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|last1=Dolatabadi|first1=Elham|last2=Zhi|first2=Ying Xuan|last3=Ye|first3=Bing|last4=Coahran|first4=Marge|last5=Lupinacci|first5=Giorgia|last6=Mihailidis|first6=Alex|last7=Wang|first7=Rosalie|last8=Taati|first8=Babak|date=2017-05-23|title=The toronto rehab stroke pose dataset to detect compensation during stroke rehabilitation therapy|publisher=ACM|pages=375–381|doi=10.1145/3154862.3154925|isbn=9781450363631|s2cid=24581930}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.kaggle.com/derekdb/toronto-robot-stroke-posture-dataset|title=Toronto Rehab Stroke Pose Dataset}}&lt;/ref&gt;
|E. Dolatabadi et al.
|-
|Corpus of Social Touch (CoST)
|7805 gesture captures of 14 different social touch gestures performed by 31 subjects. The gestures were performed in three variations: gentle, normal and rough, on a pressure sensor grid wrapped around a mannequin arm.
|Touch gestures performed are segmented and labeled.
|7805 gesture captures 
|CSV
|Classification
|2016
|&lt;ref&gt;{{Cite journal|last1=Jung|first1=Merel M.|last2=Poel|first2=Mannes|last3=Poppe|first3=Ronald|last4=Heylen|first4=Dirk K. J.|date=2017-03-01|title=Automatic recognition of touch gestures in the corpus of social touch|journal=Journal on Multimodal User Interfaces|language=en|volume=11|issue=1|pages=81–96|doi=10.1007/s12193-016-0232-9|s2cid=1802116|issn=1783-8738}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|date=2016-06-01|title=Corpus of Social Touch (CoST)|url=https://data.4tu.nl/articles/dataset/Corpus_of_Social_Touch_CoST_/12696869|language=en|doi=10.4121/uuid:5ef62345-3b3e-479c-8e1d-c922748c9b29|last1=Jung|first1=M.M. (Merel)|publisher=University of Twente}}&lt;/ref&gt;
|M. Jung et al.
|}

=== Other signals ===
{| class="wikitable sortable" style="width: 100%"
! scope="col" style="width: 15%;" |Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" |Creator
|-
|Wine Dataset
|Chemical analysis of wines grown in the same region in Italy but derived from three different cultivars.
|13 properties of each wine are given
|178
|Text
|Classification, regression
|1991
|&lt;ref&gt;Aeberhard, S., D. Coomans, and O. De Vel. "Comparison of classifiers in high dimensional settings." ''Dept. Math. Statist., James Cook Univ., North Queensland, Australia, Tech. Rep'' 92-02 (1992).&lt;/ref&gt;&lt;ref&gt;Basu, Sugato. "[http://www.aaai.org/Papers/AAAI/2004/AAAI04-138.pdf Semi-supervised clustering with limited background knowledge]." ''AAAI''. 2004.&lt;/ref&gt;
|M. Forina et al.
|-
|Combined Cycle Power Plant Data Set
|Data from various sensors within a power plant running for 6 years.
|None
|9568
|Text
|Regression
|2014
|&lt;ref&gt;{{cite journal | last1 = Tüfekci | first1 = Pınar | year = 2014 | title = Prediction of full load electrical power output of a base load operated combined cycle power plant using machine learning methods | journal = International Journal of Electrical Power &amp; Energy Systems | volume = 60 | pages = 126–140 | doi=10.1016/j.ijepes.2014.02.027}}&lt;/ref&gt;&lt;ref&gt;Kaya, Heysem, Pınar Tüfekci, and Fikret S. Gürgen. "Local and global learning methods for predicting power of a combined gas &amp; steam turbine." ''International conference on emerging trends in computer and electronics engineering (ICETCEE'2012), Dubai''. 2012.&lt;/ref&gt;
|P. Tufekci et al.
|}

== Physical data ==
Datasets from physical systems.

=== High-energy physics ===
{| class="wikitable sortable" style="width: 100%"
! scope="col" style="width: 15%;" |Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" |Creator
|-
|HIGGS Dataset
|Monte Carlo simulations of particle accelerator collisions.
|28 features of each collision are given.
|11M
|Text
|Classification
|2014
|&lt;ref&gt;{{cite journal | last1 = Baldi | first1 = Pierre | last2 = Sadowski | first2 = Peter | last3 = Whiteson | first3 = Daniel | year = 2014| title = Searching for exotic particles in high-energy physics with deep learning | journal = Nature Communications | volume = 5 | page = 2014 | bibcode = 2014NatCo...5.4308B | doi = 10.1038/ncomms5308 | pmid = 24986233 | arxiv = 1402.4735 | s2cid = 195953 }}&lt;/ref&gt;&lt;ref name=":8"&gt;{{cite journal | last1 = Baldi | first1 = Pierre | last2 = Sadowski | first2 = Peter | last3 = Whiteson | first3 = Daniel | year = 2015 | title = Enhanced Higgs Boson to τ+ τ− Search with Deep Learning | journal = Physical Review Letters | volume = 114 | issue = 11| page = 111801 | doi=10.1103/physrevlett.114.111801| pmid = 25839260 | bibcode = 2015PhRvL.114k1801B | arxiv = 1410.3469 | s2cid = 2339142 }}&lt;/ref&gt;&lt;ref name=":9"&gt;{{Cite journal|url=https://higgsml.lal.in2p3.fr/|title=The Higgs Machine Learning Challenge|journal=Journal of Physics Conference Series|volume=664|issue=7|pages=072015|bibcode=2015JPhCS.664g2015A|last1=Adam-Bourdarios|first1=C.|last2=Cowan|first2=G.|last3=Germain-Renaud|first3=C.|last4=Guyon|first4=I.|last5=Kégl|first5=B.|last6=Rousseau|first6=D.|year=2015|doi=10.1088/1742-6596/664/7/072015|doi-access=free}}&lt;/ref&gt;
|D. Whiteson
|-
|HEPMASS Dataset
|Monte Carlo simulations of particle accelerator collisions. Goal is to separate the signal from noise.
|28 features of each collision are given.
|10,500,000
|Text
|Classification
|2016
|&lt;ref name=":8" /&gt;&lt;ref name=":9" /&gt;&lt;ref&gt;Pierre Baldi, Kyle Cranmer, Taylor Faucett, Peter Sadowski, and Daniel Whiteson. '[https://arxiv.org/abs/1601.07913 Parameterized Machine Learning for High-Energy Physics].' In submission.&lt;/ref&gt;
|D. Whiteson
|}

=== Systems ===
{| class="wikitable sortable" style="width: 100%"
! scope="col" style="width: 15%;" |Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" |Creator
|-
|Yacht Hydrodynamics Dataset
|Yacht performance based on dimensions.
|Six features are given for each yacht.
|308
|Text
|Regression
|2013
|&lt;ref&gt;{{cite journal | last1 = Ortigosa | first1 = I. | last2 = Lopez | first2 = R. | last3 = Garcia | first3 = J. | title = A neural networks approach to residuary resistance of sailing yachts prediction | journal = Proceedings of the International Conference on Marine Engineering MARINE | volume = 2007 }}&lt;/ref&gt;&lt;ref&gt;Gerritsma, J., R. Onnink, and A. Versluis.''Geometry, resistance and stability of the delft systematic yacht hull series''. Delft University of Technology, 1981.&lt;/ref&gt;
|R. Lopez
|-
|Robot Execution Failures Dataset
|5 data sets that center around robotic failure to execute common tasks.
|Integer valued features such as torque and other sensor measurements.
|463
|Text
|Classification
|1999
|&lt;ref&gt;Liu, Huan, and Hiroshi Motoda. ''[https://books.google.com/books?id=zi_0EdWW5fYC&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false Feature extraction, construction and selection: A data mining perspective]''. Springer Science &amp; Business Media, 1998.&lt;/ref&gt;
|L. Seabra et al.
|-
|Pittsburgh Bridges Dataset
|Design description is given in terms of several properties of various bridges.
|Various bridge features are given.
|108
|Text
|Classification
|1990
|&lt;ref&gt;Reich, Yoram. ''Converging to Ideal Design Knowledge by Learning''. [Carnegie Mellon University], Engineering Design Research Center, 1989.&lt;/ref&gt;&lt;ref&gt;{{Cite book|chapter-url=https://link.springer.com/chapter/10.1007/978-3-540-48247-5_11|doi = 10.1007/978-3-540-48247-5_11|chapter = Experiments in Meta-level Learning with ILP|title = Principles of Data Mining and Knowledge Discovery|series = Lecture Notes in Computer Science|year = 1999|last1 = Todorovski|first1 = Ljupčo|last2 = Džeroski|first2 = Sašo|volume = 1704|pages = 98–106|isbn = 978-3-540-66490-1}}&lt;/ref&gt;
|Y. Reich et al.
|-
|Automobile Dataset
|Data about automobiles, their insurance risk, and their normalized losses.
|Car features extracted.
|205
|Text
|Regression
|1987
|&lt;ref&gt;Wang, Yong. ''[http://www.cs.waikato.ac.nz/~ml/publications/2000/thesis.pdf A new approach to fitting linear models in high dimensional spaces]''. Diss. The University of Waikato, 2000.&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Kibler | first1 = Dennis | last2 = Aha | first2 = David W. | last3 = Albert | first3 = Marc K. | year = 1989 | title = Instance‐based prediction of real‐valued attributes | url = https://escholarship.org/uc/item/68f860zb| journal = Computational Intelligence | volume = 5 | issue = 2| pages = 51–57 | doi=10.1111/j.1467-8640.1989.tb00315.x| s2cid = 40800413 }}&lt;/ref&gt;
|J. Schimmer et al.
|-
|Auto MPG Dataset
|MPG data for cars.
|Eight features of each car given.
|398
|Text
|Regression
|1993
|&lt;ref&gt;Palmer, Christopher R., and Christos Faloutsos. "[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.469.989&amp;rep=rep1&amp;type=pdf Electricity based external similarity of categorical attributes]." ''Advances in Knowledge Discovery and Data Mining''. Springer Berlin Heidelberg, 2003. 486–500.&lt;/ref&gt;
|[[Carnegie Mellon University]]
|-
|Energy Efficiency Dataset
|Heating and cooling requirements given as a function of building parameters.
|Building parameters given.
|768
|Text
|Classification, regression
|2012
|&lt;ref&gt;{{cite journal | last1 = Tsanas | first1 = Athanasios | last2 = Xifara | first2 = Angeliki | year = 2012 | title = Accurate quantitative estimation of energy performance of residential buildings using statistical machine learning tools | journal = Energy and Buildings | volume = 49 | pages = 560–567 | doi=10.1016/j.enbuild.2012.03.003}}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = De Wilde | first1 = Pieter | year = 2014 | title = The gap between predicted and measured energy performance of buildings: A framework for investigation | journal = Automation in Construction | volume = 41 | pages = 40–49 | doi=10.1016/j.autcon.2014.02.009}}&lt;/ref&gt;
|A. Xifara et al.
|-
|Airfoil Self-Noise Dataset
|A series of aerodynamic and acoustic tests of two and three-dimensional airfoil blade sections.
|Data about frequency, angle of attack, etc., are given.
|1503
|Text
|Regression
|2014
|&lt;ref&gt;Brooks, Thomas F., D. Stuart Pope, and Michael A. Marcolini. ''[https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/19890016302.pdf Airfoil self-noise and prediction]''. Vol. 1218. National Aeronautics and Space Administration, Office of Management, Scientific and Technical Information Division, 1989.&lt;/ref&gt;
|R. Lopez
|-
|Challenger USA Space Shuttle O-Ring Dataset
|Attempt to predict O-ring problems given past Challenger data.
|Several features of each flight, such as launch temperature, are given.
|23
|Text
|Regression
|1993
|&lt;ref&gt;Draper, David. "[http://www2.denizyuret.com/ref/draper/assessment-and-propagation.pdf Assessment and propagation of model uncertainty]." ''Journal of the Royal Statistical Society, Series B (Methodological)'' (1995): 45–97.&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Lavine | first1 = Michael | year = 1991 | title = Problems in extrapolation illustrated with space shuttle O-ring data | journal = Journal of the American Statistical Association | volume = 86 | issue = 416| pages = 919–921 | doi=10.1080/01621459.1991.10475132}}&lt;/ref&gt;
|D. Draper et al.
|-
|Statlog (Shuttle) Dataset
|NASA space shuttle datasets.
|Nine features given.
|58,000
|Text
|Classification
|2002
|&lt;ref&gt;Wang, Jun, Bei Yu, and Les Gasser. "[https://www.researchgate.net/profile/Bei_Yu2/publication/228407462_Concept_Tree_Based_Ordering_for_Shaded_Similarity_Matrix/links/00b7d5175607b61d2e000000.pdf Concept tree based clustering visualization with shaded similarity matrices]." ''Data Mining, 2002. ICDM 2003. Proceedings. 2002 IEEE International Conference on''. IEEE, 2002.&lt;/ref&gt;
|[[NASA]]
|}

=== Astronomy ===
{| class="wikitable sortable" style="width: 100%"
! scope="col" style="width: 15%;" |Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" |Creator
|-
|Volcanoes on Venus – JARtool experiment Dataset
|Venus images returned by the Magellan spacecraft.
|Images are labeled by humans.
|not given
|Images
|Classification
|1991
|&lt;ref&gt;Pettengill, Gordon H., et al. "[https://science.sciencemag.org/content/252/5003/260.short Magellan: Radar performance and data products]." ''Science''252.5003 (1991): 260–265.&lt;/ref&gt;&lt;ref name=":10"&gt;{{cite journal | last1 = Aharonian | first1 = F. | display-authors = et al | year = 2008 | title = Energy spectrum of cosmic-ray electrons at TeV energies | journal = Physical Review Letters | volume = 101 | issue = 26| page = 261104 | bibcode = 2008PhRvL.101z1104A | doi = 10.1103/PhysRevLett.101.261104 | pmid = 19437632 | arxiv = 0811.3894 | hdl = 2440/51450 | s2cid = 41850528 }}&lt;/ref&gt;
|M. Burl
|-
|MAGIC Gamma Telescope Dataset
|Monte Carlo generated high-energy gamma particle events.
|Numerous features extracted from the simulations.
|19,020
|Text
|Classification
|2007
|&lt;ref name=":10" /&gt;&lt;ref&gt;{{cite journal | last1 = Bock | first1 = R. K. | display-authors = et al | year = 2004 | title = Methods for multidimensional event classification: a case study using images from a Cherenkov gamma-ray telescope | journal = Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment | volume = 516 | issue = 2| pages = 511–528 | doi=10.1016/j.nima.2003.08.157| bibcode = 2004NIMPA.516..511B }}&lt;/ref&gt;
|R. Bock
|-
|Solar Flare Dataset
|Measurements of the number of certain types of solar flare events occurring in a 24-hour period.
|Many solar flare-specific features are given.
|1389
|Text
|Regression, classification
|1989
|&lt;ref&gt;{{cite journal | last1 = Li | first1 = Jinyan | display-authors = et al | year = 2004 | title = Deeps: A new instance-based lazy discovery and classification system | journal = Machine Learning | volume = 54 | issue = 2| pages = 99–124 | doi=10.1023/b:mach.0000011804.08528.7d| doi-access = free }}&lt;/ref&gt;
|G. Bradshaw
|}

=== Earth science ===
{| class="wikitable sortable" style="width: 100%"
! scope="col" style="width: 15%;" |Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" |Creator
|-
|Volcanoes of the World
|Volcanic eruption data for all known volcanic events on earth.
|Details such as region, subregion, tectonic setting, dominant rock type are given.
|1535
|Text
|Regression, classification
|2013
|&lt;ref&gt;Siebert, Lee, and Tom Simkin. "Volcanoes of the world: an illustrated catalog of Holocene volcanoes and their eruptions." (2014).&lt;/ref&gt;
|E. Venzke et al.
|-
|Seismic-bumps Dataset
|Seismic activities from a coal mine.
|Seismic activity was classified as hazardous or not.
|2584
|Text
|Classification
|2013
|&lt;ref&gt;{{cite journal | last1 = Sikora | first1 = Marek | last2 = Wróbel | first2 = Łukasz | year = 2010 | title = Application of rule induction algorithms for analysis of data collected by seismic hazard monitoring systems in coal mines | url = https://www.infona.pl/resource/bwmeta1.element.baztech-article-BPZ5-0008-0008| journal = Archives of Mining Sciences | volume = 55 | issue = 1| pages = 91–114 }}&lt;/ref&gt;&lt;ref&gt;Sikora, Marek, and Beata Sikora. "Rough natural hazards monitoring." ''Rough Sets: Selected Methods and Applications in Management and Engineering''. Springer London, 2012. 163–179.&lt;/ref&gt;
|M. Sikora et al.
|}

=== Other physical ===
{| class="wikitable sortable" style="width: 100%"
! scope="col" style="width: 15%;" |Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" |Creator
|-
|Concrete Compressive Strength Dataset
|Dataset of concrete properties and compressive strength.
|Nine features are given for each sample.
|1030
|Text
|Regression
|2007
|&lt;ref&gt;{{cite journal | last1 = Yeh | first1 = I–C | year = 1998 | title = Modeling of strength of high-performance concrete using artificial neural networks | journal = Cement and Concrete Research | volume = 28 | issue = 12| pages = 1797–1808 | doi=10.1016/s0008-8846(98)00165-3}}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Zarandi | first1 = MH Fazel | display-authors = et al | year = 2008 | title = Fuzzy polynomial neural networks for approximation of the compressive strength of concrete | journal = Applied Soft Computing | volume = 8 | issue = 1| pages = 488–498 | doi=10.1016/j.asoc.2007.02.010| bibcode = 2008ApSoC...8...79S }}&lt;/ref&gt;
|I. Yeh
|-
|Concrete Slump Test Dataset
|Concrete slump flow given in terms of properties.
|Features of concrete given such as fly ash, water, etc.
|103
|Text
|Regression
|2009
|&lt;ref&gt;Yeh, I. "Modeling slump of concrete with fly ash and superplasticizer." ''Computers and Concrete''5.6 (2008): 559–572.&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Gencel | first1 = Osman | display-authors = et al | year = 2011 | title = Comparison of artificial neural networks and general linear model approaches for the analysis of abrasive wear of concrete | journal = Construction and Building Materials | volume = 25 | issue = 8| pages = 3486–3494 | doi=10.1016/j.conbuildmat.2011.03.040}}&lt;/ref&gt;
|I. Yeh
|-
|Musk Dataset
|Predict if a molecule, given the features, will be a musk or a non-musk.
|168 features given for each molecule.
|6598
|Text
|Classification
|1994
|&lt;ref&gt;Dietterich, Thomas G., et al. "[http://papers.nips.cc/paper/781-a-comparison-of-dynamic-reposing-and-tangent-distance-for-drug-activity-prediction.pdf A comparison of dynamic reposing and tangent distance for drug activity prediction]." ''Advances in Neural Information Processing Systems'' (1994): 216–216.&lt;/ref&gt;
|Arris Pharmaceutical Corp.
|-
|Steel Plates Faults Dataset
|Steel plates of 7 different types.
|27 features given for each sample.
|1941
|Text
|Classification
|2010
|&lt;ref&gt;Buscema, Massimo, William J. Tastle, and Stefano Terzi. "[https://www.researchgate.net/profile/Massimo_Buscema/publication/13731626_MetaNet_The_Theory_of_Independent_Judges/links/0deec52baf2937fc8e000000.pdf Meta net: A new meta-classifier family]."''Data Mining Applications Using Artificial Adaptive Systems''. Springer New York, 2013. 141–182.&lt;/ref&gt;
|Semeion Research Center
|}

== Biological data ==
Datasets from biological systems.

=== Human ===
{| class="wikitable sortable" style="width: 100%"
! scope="col" style="width: 15%;" |Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" |Creator
|-
|EEG Database
|Study to examine EEG correlates of genetic predisposition to alcoholism.
|Measurements from 64 electrodes placed on the scalp sampled at 256&amp;nbsp;Hz (3.9&amp;nbsp;ms epoch) for 1 second.
|122
|Text
|Classification
|1999
|&lt;ref name=":3"&gt;{{cite journal | last = Ingber | first = Lester | year = 1997 | title = Statistical mechanics of neocortical interactions: Canonical momenta indicatorsof electroencephalography | journal = Physical Review E | volume = 55 | issue = 4| pages =  4578–4593| bibcode =  1997PhRvE..55.4578I| doi =  10.1103/PhysRevE.55.4578| arxiv = physics/0001052| s2cid = 6390999 }}&lt;/ref&gt;
|H. Begleiter
|-
|P300 Interface Dataset
|Data from nine subjects collected using P300-based brain-computer interface for disabled subjects.
|Split into four sessions for each subject. [[MATLAB]] code given.
|1,224
|Text
|Classification
|2008
|&lt;ref&gt;{{cite journal | last1 = Hoffmann | first1 = Ulrich | last2 = Vesin | first2 = Jean-Marc | last3 = Ebrahimi | first3 = Touradj | last4 = Diserens | first4 = Karin | year = 2008 | title = An efficient P300-based brain–computer interface for disabled subjects | journal = Journal of Neuroscience Methods | volume = 167 | issue = 1| pages = 115–125 | doi=10.1016/j.jneumeth.2007.03.005| pmid = 17445904 | citeseerx = 10.1.1.352.4630 | s2cid = 9648828 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last1=Donchin |first1=Emanuel |first2=Kevin M. |last2=Spencer |first3=Ranjith |last3=Wijesinghe |title=The mental prosthesis: assessing the speed of a P300-based brain-computer interface |journal=IEEE Transactions on Rehabilitation Engineering |volume=8 |issue=2 |year=2000 |pages=174–179 |pmid=10896179 |doi=10.1109/86.847808}}&lt;/ref&gt;
|U. Hoffman et al.
|-
|Heart Disease Data Set
|Attributed of patients with and without heart disease.
|75 attributes given for each patient with some missing values.
|303
|Text
|Classification
|1988
|&lt;ref&gt;{{cite journal | last1 = Detrano | first1 = Robert | display-authors = et al | year = 1989 | title = International application of a new probability algorithm for the diagnosis of coronary artery disease | journal = The American Journal of Cardiology | volume = 64 | issue = 5| pages = 304–310 | doi=10.1016/0002-9149(89)90524-9| pmid = 2756873 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Bradley | first1 = Andrew P | year = 1997 | title = The use of the area under the ROC curve in the evaluation of machine learning algorithms | url = http://espace.library.uq.edu.au/view/UQ:8925/pr-t.pdf| journal = Pattern Recognition | volume = 30 | issue = 7| pages = 1145–1159 | doi=10.1016/s0031-3203(96)00142-2}}&lt;/ref&gt;
|A. Janosi et al.
|-
|Breast Cancer Wisconsin (Diagnostic) Dataset
|Dataset of features of breast masses. Diagnoses by physician is given.
|10 features for each sample are given.
|569
|Text
|Classification
|1995
|&lt;ref&gt;{{Cite book|chapter-url=https://www.spiedigitallibrary.org/conference-proceedings-of-spie/1905/0000/Nuclear-feature-extraction-for-breast-tumor-diagnosis/10.1117/12.148698.short|doi = 10.1117/12.148698|chapter = Nuclear feature extraction for breast tumor diagnosis|title = Biomedical Image Processing and Biomedical Visualization|year = 1993|editor1-last = Acharya|editor1-first = Raj S|last1 = Street|first1 = W. N.|last2 = Wolberg|first2 = W. H.|last3 = Mangasarian|first3 = O. L.|volume = 1905|pages = 861–870|s2cid = 14922543|url = http://digital.library.wisc.edu/1793/59692|editor2-first = Dmitry B|editor2-last = Goldgof}}&lt;/ref&gt;&lt;ref&gt;Demir, Cigdem, and Bülent Yener. "[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.61.1199&amp;rep=rep1&amp;type=pdf Automated cancer diagnosis based on histopathological images: a systematic survey]." ''Rensselaer Polytechnic Institute, Tech. Rep'' (2005).&lt;/ref&gt;
|W. Wolberg et al.
|-
|National Survey on Drug Use and Health
|Large scale survey on health and drug use in the United States.
|None.
|55,268
|Text
|Classification, regression
|2012
|&lt;ref&gt;Abuse, Substance. "Mental Health Services Administration, Results from the 2010 National Survey on Drug Use and Health: Summary of National Findings, NSDUH Series H-41, HHS Publication No.(SMA) 11-4658." ''Rockville, MD: Substance Abuse and Mental Health Services Administration'' 201 (2011).&lt;/ref&gt;
|[[United States Department of Health and Human Services]]
|-
|Lung Cancer Dataset
|Lung cancer dataset without attribute definitions
|56 features are given for each case
|32
|Text
|Classification
|1992
|&lt;ref&gt;{{cite journal | last1 = Hong | first1 = Zi-Quan | last2 = Yang | first2 = Jing-Yu | year = 1991 | title = Optimal discriminant plane for a small number of samples and design method of classifier on the plane | journal = Pattern Recognition | volume = 24 | issue = 4| pages = 317–324 | doi=10.1016/0031-3203(91)90074-f}}&lt;/ref&gt;&lt;ref name="Jinyan 2003"&gt;Li, Jinyan, and Limsoon Wong. "Using rules to analyse bio-medical data: a comparison between C4. 5 and PCL." ''Advances in Web-Age Information Management''. Springer Berlin Heidelberg, 2003. 254-265.&lt;/ref&gt;
|Z. Hong et al.
|-
|Arrhythmia Dataset
|Data for a group of patients, of which some have cardiac arrhythmia.
|276 features for each instance.
|452
|Text
|Classification
|1998
|&lt;ref&gt;Güvenir, H. Altay, et al. "[http://repository.bilkent.edu.tr/bitstream/handle/11693/27699/bilkent-research-paper.pdf?sequence=1 A supervised machine learning algorithm for arrhythmia analysis]."''Computers in Cardiology 1997''. IEEE, 1997.&lt;/ref&gt;&lt;ref&gt;Lagus, Krista, et al. "[http://users.ics.aalto.fi/ahonkela/papers/Lagus05akrr.pdf Independent variable group analysis in learning compact representations for data]." ''Proceedings of the International and Interdisciplinary Conference on Adaptive Knowledge Representation and Reasoning (AKRR'05), T. Honkela, V. Könönen, M. Pöllä, and O. Simula, Eds., Espoo, Finland''. 2005.&lt;/ref&gt;
|H. Altay et al.
|-
|Diabetes 130-US hospitals for years 1999–2008 Dataset
|9 years of readmission data across 130 US hospitals for patients with diabetes.
|Many features of each readmission are given.
|100,000
|Text
|Classification, clustering
|2014
|&lt;ref&gt;Strack, Beata, et al. "[http://downloads.hindawi.com/journals/bmri/2014/781670.pdf Impact of HbA1c measurement on hospital readmission rates: analysis of 70,000 clinical database patient records]." ''BioMed Research International'' 2014; 2014&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Rubin | first1 = Daniel J | year = 2015 | title = Hospital readmission of patients with diabetes | journal = Current Diabetes Reports | volume = 15 | issue = 4| pages = 1–9 | doi=10.1007/s11892-015-0584-7| pmid = 25712258 | s2cid = 3908599 }}&lt;/ref&gt;
|J. Clore et al.
|-
|Diabetic Retinopathy Debrecen Dataset
|Features extracted from images of eyes with and without diabetic retinopathy.
|Features extracted and conditions diagnosed.
|1151
|Text
|Classification
|2014
|&lt;ref&gt;{{cite journal | last1 = Antal | first1 = Bálint | last2 = Hajdu | first2 = András | year = 2014 | title = An ensemble-based system for automatic screening of diabetic retinopathy | journal = Knowledge-Based Systems | volume = 60 | issue = 2014| pages = 20–27 | doi=10.1016/j.knosys.2013.12.023| arxiv = 1410.8576 | bibcode = 2014arXiv1410.8576A | s2cid = 13984326 }}&lt;/ref&gt;&lt;ref&gt;{{cite arXiv |eprint=1505.04424|last1=Haloi|first1=Mrinal|title=Improved Microaneurysm Detection using Deep Neural Networks|class=cs.CV|year=2015}}&lt;/ref&gt;
|B. Antal et al.
|-
|Diabetic Retinopathy Messidor Dataset
|Methods to evaluate segmentation and indexing techniques in the field of retinal ophthalmology (MESSIDOR)
|Features retinopathy grade and risk of macular edema
|1200
|Images, Text
|Classification, Segmentation
|2008
|&lt;ref&gt;{{Cite web|url=http://www.adcis.net/en/Download-Third-Party/Messidor.htmldownload.php|title=ADCIS Download Third Party: Messidor Database|last=ELIE|first=Guillaume PATRY, Gervais GAUTHIER, Bruno LAY, Julien ROGER, Damien|website=adcis.net|language=en|access-date=2018-02-25}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last1=Decencière|first1=Etienne|last2=Zhang|first2=Xiwei|last3=Cazuguel|first3=Guy|last4=Lay|first4=Bruno|last5=Cochener|first5=Béatrice|last6=Trone|first6=Caroline|last7=Gain|first7=Philippe|last8=Ordonez|first8=Richard|last9=Massin|first9=Pascale|date=2014-08-26|journal=Image Analysis &amp; Stereology|language=en|volume=33|issue=3|pages=231–234|doi=10.5566/ias.1155|issn=1854-5165|title=Feedback on a Publicly Distributed Image Database: The Messidor Database|doi-access=free}}&lt;/ref&gt;
|Messidor Project
|-
|Liver Disorders Dataset
|Data for people with liver disorders.
|Seven biological features given for each patient.
|345
|Text
|Classification
|1990
|&lt;ref&gt;{{cite journal | last1 = Bagirov | first1 = A. M. | display-authors = et al | year = 2003 | title = Unsupervised and supervised data classification via nonsmooth and global optimization | journal = Top | volume = 11 | issue = 1| pages = 1–75 | doi=10.1007/bf02578945| citeseerx = 10.1.1.1.6429 | s2cid = 14165678 }}&lt;/ref&gt;&lt;ref&gt;Fung, Glenn, et al. "[https://jinbo-bi.uconn.edu/wp-content/uploads/sites/2638/2018/12/icml04_kernel.pdf A fast iterative algorithm for fisher discriminant using heterogeneous kernels]."''Proceedings of the twenty-first international conference on Machine learning''. ACM, 2004.&lt;/ref&gt;
|Bupa Medical Research Ltd.
|-
|Thyroid Disease Dataset
|10 databases of thyroid disease patient data.
|None.
|7200
|Text
|Classification
|1987
|&lt;ref&gt;Quinlan, John Ross, et al. "Inductive knowledge acquisition: a case study." ''Proceedings of the Second Australian Conference on Applications of expert systems''. Addison-Wesley Longman Publishing Co., Inc., 1987.&lt;/ref&gt;&lt;ref name="Zhou, Zhi-Hua 2004"&gt;{{cite journal | last1 = Zhou | first1 = Zhi-Hua | last2 = Jiang | first2 = Yuan | year = 2004 | title = NeC4. 5: neural ensemble based C4. 5 | journal = IEEE Transactions on Knowledge and Data Engineering| volume = 16 | issue = 6| pages = 770–773 | doi=10.1109/tkde.2004.11| citeseerx = 10.1.1.1.8430 | s2cid = 1024861 }}&lt;/ref&gt;
|R. Quinlan
|-
|Mesothelioma Dataset
|Mesothelioma patient data.
|Large number of features, including asbestos exposure, are given.
|324
|Text
|Classification
|2016
|&lt;ref&gt;{{cite journal | last1 = Er | first1 = Orhan | display-authors = et al | year = 2012 | title = An approach based on probabilistic neural network for diagnosis of Mesothelioma's disease | journal = Computers &amp; Electrical Engineering | volume = 38 | issue = 1| pages = 75–81 | doi=10.1016/j.compeleceng.2011.09.001}}&lt;/ref&gt;&lt;ref&gt;Er, Orhan, A. Çetin Tanrikulu, and Abdurrahman Abakay. "[https://dergipark.org.tr/download/article-file/54521 Use of artificial intelligence techniques for diagnosis of malignant pleural mesothelioma]."''Dicle Tıp Dergisi'' 42.1 (2015).&lt;/ref&gt;
|A. Tanrikulu et al.
|-
|Parkinson's Vision-Based Pose Estimation Dataset
|2D human pose estimates of Parkinson's patients performing a variety of tasks. 
|Camera shake has been removed from trajectories.
|134
|Text
|Classification, regression
|2017
|&lt;ref&gt;{{cite journal|last1=Li|first1=Michael H.|last2=Mestre|first2=Tiago A.|last3=Fox|first3=Susan H.|last4=Taati|first4=Babak|date=2017-07-25|title=Vision-Based Assessment of Parkinsonism and Levodopa-Induced Dyskinesia with Deep Learning Pose Estimation|journal=Journal of Neuroengineering and Rehabilitation|volume=15|issue=1|pages=97|arxiv=1707.09416|doi=10.1186/s12984-018-0446-z|pmid=30400914|pmc=6219082|bibcode=2017arXiv170709416L}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last1=Li|first1=Michael H.|last2=Mestre|first2=Tiago A.|last3=Fox|first3=Susan H.|last4=Taati|first4=Babak|date=May 2018|title=Automated assessment of levodopa-induced dyskinesia: Evaluating the responsiveness of video-based features|journal=Parkinsonism &amp; Related Disorders|volume=53|pages=42–45|doi=10.1016/j.parkreldis.2018.04.036|pmid=29748112|issn=1353-8020}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.kaggle.com/limi44/parkinsons-visionbased-pose-estimation-dataset/home|title=Parkinson's Vision-Based Pose Estimation Dataset {{!}} Kaggle|website=kaggle.com|access-date=2018-08-22}}&lt;/ref&gt;
|M. Li et al.
|-
|KEGG Metabolic Reaction Network (Undirected) Dataset
|Network of metabolic pathways. A reaction network and a [[relation network]] are given.
|Detailed features for each network node and pathway are given.
|65,554
|Text
|Classification, clustering, regression
|2011
|&lt;ref&gt;{{cite journal|last1=Shannon|first1=Paul|display-authors=etal|year=2003|title=Cytoscape: a software environment for integrated models of biomolecular interaction networks|journal=Genome Research |volume=13 |issue=11 |pages=2498–2504 |doi=10.1101/gr.1239303 |pmid=14597658 |pmc=403769}}&lt;/ref&gt;
|M. Naeem et al.
|-
|Modified Human Sperm Morphology Analysis Dataset (MHSMA)
|Human sperm images from 235 patients with male factor infertility, labeled for normal or abnormal sperm acrosome, head, vacuole, and tail.
|Cropped around single sperm head. Magnification normalized. Training, validation, and test set splits created.
|1,540
|.npy files
|Classification
|2019
|&lt;ref&gt;{{cite journal|last1=Javadi|first1=Soroush|last2=Mirroshandel|first2=Seyed Abolghasem|year=2019|title=A novel deep learning method for automatic assessment of human sperm images|journal=Computers in Biology and Medicine|volume=109|pages=182–194|issn=0010-4825|doi=10.1016/j.compbiomed.2019.04.030|pmid=31059902}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=https://github.com/soroushj/mhsma-dataset|title=soroushj/mhsma-dataset: MHSMA: The Modified Human Sperm Morphology Analysis Dataset|website=github.com|access-date=2019-05-03}}&lt;/ref&gt;
|S. Javadi and S.A. Mirroshandel
|}

=== Animal ===
{| class="wikitable sortable" style="width: 100%"
! scope="col" style="width: 15%;" |Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" |Creator
|-
|Abalone Dataset
|Physical measurements of Abalone. Weather patterns and location are also given.
|None.
|4177
|Text
|Regression
|1995
|&lt;ref&gt;Clark, David, Zoltan Schreter, and Anthony Adams. "A quantitative comparison of dystal and backpropagation." ''Proceedings of 1996 Australian Conference on Neural Networks''. 1996.&lt;/ref&gt;
|Marine Research Laboratories – Taroona
|-
|Zoo Dataset
|Artificial dataset covering 7 classes of animals.
|Animals are classed into 7 categories and features are given for each.
|101
|Text
|Classification
|1990
|&lt;ref&gt;Jiang, Yuan, and Zhi-Hua Zhou. "[https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/isnn04a.pdf Editing training data for kNN classifiers with neural network ensemble]." ''Advances in Neural Networks–ISNN 2004''. Springer Berlin Heidelberg, 2004. 356–361.&lt;/ref&gt;
|R. Forsyth
|-
|Demospongiae Dataset
|Data about marine sponges.
|503 sponges in the [[Demosponge]] class are described by various features.
|503
|Text
|Classification
|2010
|&lt;ref&gt;Ontañón, Santiago, and Enric Plaza. "On similarity measures based on a refinement lattice." ''Case-Based Reasoning Research and Development''. Springer Berlin Heidelberg, 2009. 240–255.&lt;/ref&gt;
|E. Armengol et al.
|-
|Splice-junction Gene Sequences Dataset
|Primate splice-junction gene sequences (DNA) with associated imperfect domain theory.
|None.
|3190
|Text
|Classification
|1992
|&lt;ref name="Jinyan 2003" /&gt;
|G. Towell et al.
|-
|Mice Protein Expression Dataset
|Expression levels of 77 proteins measured in the cerebral cortex of mice.
|None.
|1080
|Text
|Classification, Clustering
|2015
|&lt;ref&gt;{{cite journal | last1 = Higuera | first1 = Clara | last2 = Gardiner | first2 = Katheleen J. | last3 = Cios | first3 = Krzysztof J. | year = 2015 | title = Self-organizing feature maps identify proteins critical to learning in a mouse model of down syndrome | journal = PLOS ONE | volume = 10 | issue = 6| page = e0129126 | doi=10.1371/journal.pone.0129126| pmid = 26111164 | pmc = 4482027 | bibcode = 2015PLoSO..1029126H }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Ahmed | first1 = Md Mahiuddin | display-authors = et al | year = 2015 | title = Protein dynamics associated with failed and rescued learning in the Ts65Dn mouse model of Down syndrome | journal = PLOS ONE | volume = 10 | issue = 3| page = e0119491 | doi=10.1371/journal.pone.0119491| pmid = 25793384 | pmc = 4368539 | bibcode = 2015PLoSO..1019491A }}&lt;/ref&gt;
|C. Higuera et al.
|}

=== Plant ===
{| class="wikitable sortable" style="width: 100%"
! scope="col" style="width: 15%;" |Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" |Creator
|-
|Forest Fires Dataset
|Forest fires and their properties.
|13 features of each fire are extracted.
|517
|Text
|Regression
|2008
|&lt;ref&gt;Cortez, Paulo, and Aníbal de Jesus Raimundo Morais. "A data mining approach to predict forest fires using meteorological data." (2007).&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Farquad | first1 = M. A. H. | last2 = Ravi | first2 = V. | last3 = Raju | first3 = S. Bapi | year = 2010 | title = Support vector regression based hybrid rule extraction methods for forecasting | journal = Expert Systems with Applications | volume = 37 | issue = 8| pages = 5577–5589 | doi=10.1016/j.eswa.2010.02.055}}&lt;/ref&gt;
|P. Cortez et al.
|-
|[[Iris flower data set|Iris Dataset]]
|Three types of iris plants are described by 4 different attributes.
|None.
|150
|Text
|Classification
|1936
|&lt;ref&gt;{{cite journal | last1 = Fisher | first1 = Ronald A | year = 1936 | title = The use of multiple measurements in taxonomic problems | journal = Annals of Eugenics | volume = 7 | issue = 2| pages = 179–188 | doi=10.1111/j.1469-1809.1936.tb02137.x| hdl = 2440/15227 | hdl-access = free }}&lt;/ref&gt;&lt;ref&gt;Ghahramani, Zoubin, and Michael I. Jordan. "[http://papers.nips.cc/paper/767-supervised-learning-from-incomplete-data-via-an-em-approach.pdf Supervised learning from incomplete data via an EM approach]." ''Advances in neural information processing systems 6''. 1994.&lt;/ref&gt;
|R. Fisher
|-
|Plant Species Leaves Dataset
|Sixteen samples of leaf each of one-hundred plant species.
|Shape descriptor, fine-scale margin, and texture histograms are given.
|1600
|Text
|Classification
|2012
|&lt;ref&gt;{{cite journal | last1 = Mallah | first1 = Charles | last2 = Cope | first2 = James | last3 = Orwell | first3 = James | year = 2013 | title = Plant leaf classification using probabilistic integration of shape, texture and margin features | url =https://www.researchgate.net/publication/266632357 | journal = Signal Processing, Pattern Recognition and Applications | volume = 5 | page = 1 }}&lt;/ref&gt;&lt;ref&gt;Yahiaoui, Itheri, Olfa Mzoughi, and Nozha Boujemaa. "[http://www.cmlab.csie.ntu.edu.tw/~zenic/Data/Download/ICME2012/Conference/data/4711a254.pdf Leaf shape descriptor for tree species identification]." ''Multimedia and Expo (ICME), 2012 IEEE International Conference on''. IEEE, 2012.&lt;/ref&gt;
|J. Cope et al.
|-
|Mushroom Dataset
|Mushroom attributes and classification.
|Many properties of each mushroom are given.
|8124
|Text
|Classification
|1987
|&lt;ref&gt;{{cite journal | last1 = Langley | first1 = PAT | year = 2014 | title = Trading off simplicity and coverage in incremental concept learning | url =https://www.westmont.edu/~iba/pubs/hillary-paper.pdf | journal = Machine Learning Proceedings | volume = 1988 | page = 73 }}&lt;/ref&gt;
|J. Schlimmer
|-
|Soybean Dataset
|Database of diseased soybean plants.
|35 features for each plant are given. Plants are classified into 19 categories.
|307
|Text
|Classification
|1988
|&lt;ref&gt;Tan, Ming, and Larry Eshelman. "[https://www.sciencedirect.com/science/article/pii/B9780934613644500189 Using weighted networks to represent classification knowledge in noisy domains]." ''Proceedings of the Fifth International Conference on Machine Learning''. 2014.&lt;/ref&gt;
|R. Michalski et al.
|-
|Seeds Dataset
|Measurements of geometrical properties of kernels belonging to three different varieties of wheat.
|None.
|210
|Text
|Classification, clustering
|2012
|&lt;ref&gt;Charytanowicz, Małgorzata, et al. "[http://home.agh.edu.pl/~kulpi/publ/Charytanowicz_Niewczas_Kulczycki_Kowalski_Lukasik_Zak_-_Information_Technologies_in_Biomedicine_-_2010.pdf Complete gradient clustering algorithm for features analysis of x-ray images]." ''Information technologies in biomedicine''. Springer Berlin Heidelberg, 2010. 15–24.&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Sanchez | first1 = Mauricio A. | display-authors = et al | year = 2014 | title = Fuzzy granular gravitational clustering algorithm for multivariate data | journal = Information Sciences | volume = 279 | pages = 498–511 | doi=10.1016/j.ins.2014.04.005}}&lt;/ref&gt;
|Charytanowicz et al.
|-
|Covertype Dataset
|Data for predicting forest cover type strictly from cartographic variables.
|Many geographical features given.
|581,012
|Text
|Classification
|1998
|&lt;ref&gt;{{cite journal | last1 = Blackard | first1 = Jock A. | last2 = Dean | first2 = Denis J. | year = 1999 | title = Comparative accuracies of artificial neural networks and discriminant analysis in predicting forest cover types from cartographic variables | journal = Computers and Electronics in Agriculture | volume = 24 | issue = 3| pages = 131–151 | doi=10.1016/s0168-1699(99)00046-0| citeseerx = 10.1.1.128.2475 }}&lt;/ref&gt;&lt;ref&gt;Fürnkranz, Johannes. "[http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.20.9520 Round robin rule learning]."''Proceedings of the 18th International Conference on Machine Learning (ICML-01): 146--153''. 2001.&lt;/ref&gt;
|J. Blackard et al.
|-
|Abscisic Acid Signaling Network Dataset
|Data for a plant signaling network. Goal is to determine set of rules that governs the network.
|None.
|300
|Text
|Causal-discovery
|2008
|&lt;ref&gt;{{cite journal | last1 = Li | first1 = Song | last2 = Assmann | first2 = Sarah M. | last3 = Albert | first3 = Réka | year = 2006 | title = Predicting essential components of signal transduction networks: a dynamic model of guard cell abscisic acid signaling | journal = PLOS Biol | volume = 4 | issue = 10| page = e312 | doi=10.1371/journal.pbio.0040312| pmid = 16968132 | pmc = 1564158 | bibcode = 2006q.bio....10012L | arxiv = q-bio/0610012 }}&lt;/ref&gt;
|J. Jenkens et al.
|-
|Folio Dataset
|20 photos of leaves for each of 32 species.
|None.
|637
|Images, text
|Classification, clustering
|2015
|&lt;ref&gt;{{cite journal | last1 = Munisami | first1 = Trishen | display-authors = et al | year = 2015 | title = Plant Leaf Recognition Using Shape Features and Colour Histogram with K-nearest Neighbour Classifiers | journal = Procedia Computer Science | volume = 58 | pages = 740–747 | doi=10.1016/j.procs.2015.08.095| doi-access = free }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Li | first1 = Bai | year = 2016 | title = Atomic potential matching: An evolutionary target recognition approach based on edge features | journal = Optik-International Journal for Light and Electron Optics | volume = 127 | issue = 5| pages = 3162–3168 | doi=10.1016/j.ijleo.2015.11.186| bibcode = 2016Optik.127.3162L }}&lt;/ref&gt;
|T. Munisami et al.
|-
|Oxford Flower Dataset
|17 category dataset of flowers.
|Train/test splits, labeled images,
|1360
|Images, text
|Classification
|2006
|&lt;ref name="Razavian, Ali 2014"/&gt;&lt;ref&gt;Nilsback, Maria-Elena, and Andrew Zisserman. "[http://www.robots.ox.ac.uk/~men/papers/nilsback_cvpr06.pdf A visual vocabulary for flower classification]."''Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on''. Vol. 2. IEEE, 2006.&lt;/ref&gt;
|M-E Nilsback et al.
|-
|Plant Seedlings Dataset
|12 category dataset of plant seedlings.
|Labelled images, segmented images,
|5544
|Images
|Classification, detection
|2017
|&lt;ref&gt;{{cite arxiv | last1 = Giselsson | first1 = Thomas M. | display-authors = et al | year = 2017 | title = A Public Image Database for Benchmark of Plant Seedling Classification Algorithms | eprint= 1711.05458 | class = cs.CV }}&lt;/ref&gt;
|Giselsson et al.
|-
|Fruits 360 dataset
|Database with images of 120 fruits and vegetables.
|100x100 pixels, White background.
|82213
|Images (jpg)
|Classification
|2017-2019
|&lt;ref&gt;{{cite journal | last1 = Muresan| first1 = Horea |last2 = Oltean| first2 = Mihai | year = 2018 | title = Fruit recognition from images using deep learning | url = https://www.researchgate.net/publication/321475443| journal = Acta Univ. Sapientiae, Informatica | volume = 10 | issue = 1| pages = 26–42| doi=10.2478/ausi-2018-0002| doi-access = free}}&lt;/ref&gt;&lt;ref&gt;{{cite web|last1 = Oltean| first1 = Mihai |last2 = Muresan| first2 = Horea| year = 2017 | title = A dataset with fruit images on Kaggle| url = https://www.kaggle.com/moltean/fruits}}&lt;/ref&gt;
|Mihai Oltean, Horea Muresan
|}

=== Microbe ===
{| class="wikitable sortable" style="width: 100%"
! scope="col" style="width: 15%;" |Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" |Creator
|-
|Ecoli Dataset
|Protein localization sites.
|Various features of the protein localizations sites are given.
|336
|Text
|Classification
|1996
|&lt;ref&gt;{{cite journal | last1 = Nakai | first1 = Kenta | last2 = Kanehisa | first2 = Minoru | year = 1991 | title = Expert system for predicting protein localization sites in gram‐negative bacteria | journal = Proteins: Structure, Function, and Bioinformatics | volume = 11 | issue = 2| pages = 95–110 | doi=10.1002/prot.340110203| pmid = 1946347 | s2cid = 27606447 }}&lt;/ref&gt;&lt;ref&gt;Ling, Charles X., et al. "[https://cling.csd.uwo.ca/cs860/ICML04-Ling.pdf Decision trees with minimal costs]." ''Proceedings of the twenty-first international conference on Machine learning''. ACM, 2004.&lt;/ref&gt;
|K. Nakai et al.
|-
|MicroMass Dataset
|Identification of microorganisms from mass-spectrometry data.
|Various mass spectrometer features.
|931
|Text
|Classification
|2013
|&lt;ref&gt;Mahé, Pierre, et al. "[https://academic.oup.com/bioinformatics/article/30/9/1280/237488 Automatic identification of mixed bacterial species fingerprints in a MALDI-TOF mass-spectrum]." ''Bioinformatics'' (2014): btu022.&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Barbano | first1 = Duane | display-authors = et al | year = 2015 | title = Rapid characterization of microalgae and microalgae mixtures using matrix-assisted laser desorption ionization time-of-flight mass spectrometry (MALDI-TOF MS) | journal = PLOS ONE | volume = 10 | issue = 8| page = e0135337 | doi=10.1371/journal.pone.0135337| pmid = 26271045 | pmc = 4536233 | bibcode = 2015PLoSO..1035337B }}&lt;/ref&gt;
|P. Mahe et al.
|-
|Yeast Dataset
|Predictions of Cellular localization sites of proteins.
|Eight features given per instance.
|1484
|Text
|Classification
|1996
|&lt;ref&gt;{{cite journal | last1 = Horton | first1 = Paul | last2 = Nakai | first2 = Kenta | year = 1996| title = A probabilistic classification system for predicting the cellular localization sites of proteins | url =https://www.aaai.org/Papers/ISMB/1996/ISMB96-012.pdf | journal = ISMB-96 Proceedings | volume = 4 | pages = 109–15 | pmid = 8877510 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Allwein | first1 = Erin L. | last2 = Schapire | first2 = Robert E. | last3 = Singer | first3 = Yoram | year = 2001 | title = Reducing multiclass to binary: A unifying approach for margin classifiers | url = http://www.jmlr.org/papers/volume1/allwein00a/allwein00a.pdf| journal = The Journal of Machine Learning Research | volume = 1 | pages = 113–141 }}&lt;/ref&gt;
|K. Nakai et al.
|}

=== Drug Discovery ===
{| class="wikitable sortable" style="width: 100%"
! scope="col" style="width: 15%;" |Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" |Creator
|-
|Tox21 Dataset
|Prediction of outcome of biological assays.
|Chemical descriptors of molecules are given.
|12707
|Text
|Classification
|2016
|&lt;ref&gt;{{cite journal | last1 = Mayr | first1 = Andreas | last2 = Klambauer | first2 = Guenter | last3 = Unterthiner | first3 = Thomas | last4 = Hochreiter | first4 = Sepp | year = 2016 | title = DeepTox: Toxicity Prediction Using Deep Learning | url = http://bioinf.jku.at/research/DeepTox/tox21.html | journal = Frontiers in Environmental Science | volume = 3 | page = 80 | doi=10.3389/fenvs.2015.00080| doi-access = free }}&lt;/ref&gt;
|A. Mayr et al.
|-
|}

== Anomaly data ==

{| style="width: 100%" class="wikitable sortable"
! scope="col" style="width: 15%;" |Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" |Creator
|-
|Numenta Anomaly Benchmark (NAB)
|Data are ordered, timestamped, single-valued metrics. All data files contain anomalies, unless otherwise noted.
|None
|50+ files
|Comma separated values
|[[Anomaly detection]]
|2016 (continually updated)
|&lt;ref&gt;{{cite book |last1=Lavin |first1=Alexander |last2=Ahmad |first2=Subutai |arxiv=1510.03336 |title=Evaluating Real-time Anomaly Detection Algorithms – the Numenta Anomaly Benchmark |pages=38 |date=12 October 2015 |doi=10.1109/ICMLA.2015.141 |isbn=978-1-5090-0287-0 |s2cid=6842305 }}&lt;/ref&gt;
|[[Numenta]]
|-
|Skoltech Anomaly Benchmark (SKAB)
|Each file represents a single experiment and contains a single anomaly. The dataset represents a multivariate time series collected from the sensors installed on the testbed.
|There are two markups for Outlier detection (point anomalies) and Changepoint detection (collective anomalies) problems
|30+ files (v0.9)
|Comma separated values
|[[Anomaly detection]]
|2020 (continually updated)
|
&lt;ref&gt;{{cite web |author1=Iurii D. Katser |author2=Vyacheslav O. Kozitsin |title=SKAB GitHub repository |url=https://github.com/waico/skab |access-date=12 January 2021}}&lt;/ref&gt;
&lt;ref&gt;{{cite web |author1=Iurii D. Katser |author2=Vyacheslav O. Kozitsin |title=Skoltech Anomaly Benchmark (SKAB) |publisher=Kaggle |year=2020 |doi=10.34740/KAGGLE/DSV/1693952 |url=https://www.kaggle.com/yuriykatser/skoltech-anomaly-benchmark-skab |access-date=12 January 2021}}&lt;/ref&gt;
|Iurii D. Katser and Vyacheslav O. Kozitsin
|-
|On the Evaluation of Unsupervised Outlier Detection: Measures, Datasets, and an Empirical Study
|Most data files are adapted from UCI Machine Learning Repository data, some are collected from the literature.
|treated for missing values, numerical attributes only, different percentages of anomalies, labels
|1000+ files
|[[Attribute-Relation File Format|ARFF]]
|[[Anomaly detection]]
|2016 (possibly updated with new datasets and/or results)
|
&lt;ref name="CamposZimek2016"&gt;{{cite journal|last1=Campos|first1=Guilherme O.|last2=Zimek|first2=Arthur|author-link2=Arthur Zimek|last3=Sander|first3=Jörg|last4=Campello|first4=Ricardo J. G. B.|last5=Micenková|first5=Barbora|last6=Schubert|first6=Erich|last7=Assent|first7=Ira|last8=Houle|first8=Michael E.|title=On the evaluation of unsupervised outlier detection: measures, datasets, and an empirical study|journal=Data Mining and Knowledge Discovery|volume=30|issue=4|pages=891|year=2016|issn=1384-5810|doi=10.1007/s10618-015-0444-8|s2cid=1952214}}&lt;/ref&gt;
|Campos et al.
|}

== Question Answering data ==
This section includes datasets that deals with structured data.

{| style="width: 100%" class="wikitable sortable"
! scope="col" style="width: 15%;" |Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" |Creator
|-
|DBpedia Neural Question Answering (DBNQA) Dataset
|A large collection of Question to SPARQL specially design for Open Domain Neural Question Answering over DBpedia Knowledgebase.
|This dataset contains a large collection of Open Neural SPARQL Templates and instances for training Neural SPARQL Machines; it was pre-processed by semi-automatic annotation tools as well as by three SPARQL experts.
|894,499
|Question-query pairs
|Question Answering
|2018
|&lt;ref&gt;Ann-Kathrin Hartmann, Tommaso Soru, Edgard Marx. [https://www.researchgate.net/publication/324482598_Generating_a_Large_Dataset_for_Neural_Question_Answering_over_the_DBpedia_Knowledge_Base ''Generating a Large Dataset for Neural Question Answering over the DBpedia Knowledge Base'']. 2018.&lt;/ref&gt;&lt;ref&gt;Tommaso Soru, Edgard Marx. Diego Moussallem, Andre Valdestilhas, Diego Esteves, Ciro Baron. [https://arxiv.org/abs/1708.07624 ''SPARQL as a Foreign Language'']. 2018.&lt;/ref&gt;
|Hartmann, Soru, and Marx et al.
|-
|Vietnamese Question Answering Dataset (UIT-ViQuAD)
|A large collection of Vietnamese questions for evaluating MRC models.
|This dataset comprises over 23,000 human-generated question-answer pairs based on 5,109 passages of 174 Vietnamese articles from Wikipedia.
|23,074
|Question-answer pairs
|Question Answering
|2020
|&lt;ref&gt;Kiet Van Nguyen, Duc-Vu Nguyen, Anh Gia-Tuan Nguyen, Ngan Luu-Thuy Nguyen. [https://www.aclweb.org/anthology/2020.coling-main.233.pdf ''A Vietnamese Dataset for Evaluating Machine Reading Comprehension'']. COLING 2020.&lt;/ref&gt;
|Nguyen et al.
|-
|Vietnamese Multiple-Choice Machine Reading Comprehension Corpus(ViMMRC)
|A collection of Vietnamese multiple-choice questions for evaluating MRC models.
|This corpus includes 2,783 Vietnamese multiple-choice questions.
|2,783
|Question-answer pairs
|Question Answering/Machine Reading Comprehension
|2020
|&lt;ref&gt;Kiet Van Nguyen, Khiem Vinh Tran, Son T. Luu, Anh Gia-Tuan Nguyen, Ngan Luu-Thuy Nguyen. [https://ieeexplore.ieee.org/document/9247161 ''Enhancing Lexical-Based Approach With External Knowledge for Vietnamese Multiple-Choice Machine Reading Comprehension'']. IEEE Access. 2020.&lt;/ref&gt;
|Nguyen et al.
|}

== Multivariate data ==
Datasets consisting of rows of observations and columns of attributes characterizing those observations. Typically used for [[regression analysis]] or classification but other types of algorithms can also be used. This section includes datasets that do not fit in the above categories.

=== Financial ===
{| style="width: 100%" class="wikitable sortable"
! scope="col" style="width: 15%;" |Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" |Creator
|-
|Dow Jones Index
|Weekly data of stocks from the first and second quarters of 2011.
|Calculated values included such as percentage change and a lags.
|750
|Comma separated values
|Classification, regression, [[Time series]]
|2014
|&lt;ref&gt;Brown, Michael Scott, Michael J. Pelosi, and Henry Dirska. "[http://www.academia.edu/download/46729605/BrownPelosiDirska79880027.pdf Dynamic-radius species-conserving genetic algorithm for the financial forecasting of Dow Jones index stocks]." ''Machine Learning and Data Mining in Pattern Recognition''. Springer Berlin Heidelberg, 2013. 27–41.&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Shen | first1 = Kao-Yi | last2 = Tzeng | first2 = Gwo-Hshiung | year = 2015 | title = Fuzzy Inference-Enhanced VC-DRSA Model for Technical Analysis: Investment Decision Aid | journal = International Journal of Fuzzy Systems | volume = 17 | issue = 3| pages = 375–389 | doi=10.1007/s40815-015-0058-8| s2cid = 68241024 }}&lt;/ref&gt;
|M. Brown et al.
|-
|Statlog (Australian Credit Approval)
|Credit card applications either accepted or rejected and attributes about the application.
|Attribute names are removed as well as identifying information. Factors have been relabeled.
|690
|Comma separated values
|Classification
|1987
|&lt;ref&gt;{{cite journal | last1 = Quinlan | first1 = J. Ross | year = 1987 | title = Simplifying decision trees | journal = International Journal of Man-machine Studies | volume = 27 | issue = 3| pages = 221–234 | doi=10.1016/s0020-7373(87)80053-6| citeseerx = 10.1.1.18.4267 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Hamers | first1 = Bart | last2 = Suykens | first2 = Johan AK | last3 = De Moor | first3 = Bart | year = 2003 | title = Coupled transductive ensemble learning of kernel models | url =ftp://ftp.esat.kuleuven.be/pub/SISTA/hamers/BH_clm.pdf | journal = Journal of Machine Learning Research | volume = 1 | pages = 1–48 }}&lt;/ref&gt;
|R. Quinlan
|-
|eBay auction data
|Auction data from various eBay.com objects over various length auctions
|Contains all bids, bidderID, bid times, and opening prices.
|~ 550
|Text
|Regression, classification
|2012
|&lt;ref&gt;[[Galit Shmueli|Shmueli, Galit]], Ralph P. Russo, and Wolfgang Jank. "[https://projecteuclid.org/download/pdfview_1/euclid.aoas/1196438025 The BARISTA: a model for bid arrivals in online auctions]." ''The Annals of Applied Statistics''(2007): 412–441.&lt;/ref&gt;&lt;ref&gt;Peng, Jie, and Hans-Georg Müller. "[https://projecteuclid.org/download/pdfview_1/euclid.aoas/1223908052 Distance-based clustering of sparsely observed stochastic processes, with applications to online auctions]." ''The Annals of Applied Statistics'' (2008): 1056–1077.&lt;/ref&gt;
|[[Galit Shmueli|G. Shmueli]] et al.
|-
|Statlog (German Credit Data)
|Binary credit classification into "good" or "bad" with many features
|Various financial features of each person are given.
|690
|Text
|Classification
|1994
|&lt;ref&gt;Eggermont, Jeroen, Joost N. Kok, and Walter A. Kosters. "[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.9.8725&amp;rep=rep1&amp;type=pdf Genetic programming for data classification: Partitioning the search space]."''Proceedings of the 2004 ACM symposium on Applied computing''. ACM, 2004.&lt;/ref&gt;
|H. Hofmann
|-
|Bank Marketing Dataset
|Data from a large marketing campaign carried out by a large bank .
|Many attributes of the clients contacted are given. If the client subscribed to the bank is also given.
|45,211
|Text
|Classification
|2012
|&lt;ref&gt;{{cite journal | last1 = Moro | first1 = Sérgio | last2 = Cortez | first2 = Paulo | last3 = Rita | first3 = Paulo | year = 2014 | title = A data-driven approach to predict the success of bank telemarketing | journal = Decision Support Systems | volume = 62 | pages = 22–31 | doi=10.1016/j.dss.2014.03.001| hdl = 10071/9499 | hdl-access = free }}&lt;/ref&gt;&lt;ref&gt;{{cite arXiv |eprint=1411.5653|last1= Payne|first1= Richard D.|title= Bayesian Big Data Classification: A Review with Complements|last2=  Mallick|first2= Bani K.|class= stat.ME|year= 2014}}&lt;/ref&gt;
|S. Moro et al.
|-
|Istanbul Stock Exchange Dataset
|Several stock indexes tracked for almost two years.
|None.
|536
|Text
|Classification, regression
|2013
|&lt;ref&gt;{{cite journal | last1 = Akbilgic | first1 = Oguz | last2 = Bozdogan | first2 = Hamparsum | last3 = Balaban | first3 = M. Erdal | year = 2014 | title = A novel Hybrid RBF Neural Networks model as a forecaster | journal = Statistics and Computing | volume = 24 | issue = 3| pages = 365–375 | doi=10.1007/s11222-013-9375-7| s2cid = 17764829 }}&lt;/ref&gt;&lt;ref&gt;Jabin, Suraiya. "[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.677.8985&amp;rep=rep1&amp;type=pdf Stock market prediction using feed-forward artificial neural network]." ''Int. J. Comput. Appl. (IJCA)'' 99.9 (2014).&lt;/ref&gt;
|O. Akbilgic
|-
|Default of Credit Card Clients
|Credit default data for Taiwanese creditors.
|Various features about each account are given.
|30,000
|Text
|Classification
|2016
|&lt;ref&gt;{{cite journal | last1 = Yeh | first1 = I-Cheng | last2 = Che-hui | first2 = Lien | year = 2009 | title = The comparisons of data mining techniques for the predictive accuracy of probability of default of credit card clients | journal = Expert Systems with Applications | volume = 36 | issue = 2| pages = 2473–2480 | doi=10.1016/j.eswa.2007.12.020}}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Lin | first1 = Shu Ling | year = 2009 | title = A new two-stage hybrid approach of credit risk in banking industry | journal = Expert Systems with Applications | volume = 36 | issue = 4| pages = 8333–8341 | doi=10.1016/j.eswa.2008.10.015}}&lt;/ref&gt;
|I. Yeh
|}

=== Weather ===
{| class="wikitable sortable" style="width: 100%"
! scope="col" style="width: 15%;" |Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" |Creator
|-
|Cloud DataSet
|Data about 1024 different clouds.
|Image features extracted.
|1024
|Text
|Classification, clustering
|1989
|&lt;ref&gt;{{cite journal | last1 = Pelckmans | first1 = Kristiaan | display-authors = et al | year = 2005 | title = The differogram: Non-parametric noise variance estimation and its use for model selection | journal = Neurocomputing | volume = 69 | issue = 1| pages = 100–122 | doi=10.1016/j.neucom.2005.02.015}}&lt;/ref&gt;
|P. Collard
|-
|El Nino Dataset
|Oceanographic and surface meteorological readings taken from a series of buoys positioned throughout the equatorial Pacific.
|12 weather attributes are measured at each buoy.
|178080
|Text
|Regression
|1999
|&lt;ref&gt;{{cite journal | last1 = Bay | first1 = Stephen D. | display-authors = et al | year = 2000 | title = The UCI KDD archive of large data sets for data mining research and experimentation | journal = ACM SIGKDD Explorations Newsletter | volume = 2 | issue = 2| pages = 81–85 | doi=10.1145/380995.381030| citeseerx = 10.1.1.15.9776 | s2cid = 534881 }}&lt;/ref&gt;
|[[Pacific Marine Environmental Laboratory]]
|-
|Greenhouse Gas Observing Network Dataset
|Time-series of greenhouse gas concentrations at 2921 grid cells in California created using simulations of the weather.
|None.
|2921
|Text
|Regression
|2015
|&lt;ref&gt;{{cite journal | last1 = Lucas | first1 = D. D. | display-authors = et al | year = 2015 | title = Designing optimal greenhouse gas observing networks that consider performance and cost | journal = Geoscientific Instrumentation, Methods and Data Systems | volume = 4 | issue = 1| page = 121 | doi=10.5194/gi-4-121-2015| bibcode = 2015GI......4..121L | doi-access = free }}&lt;/ref&gt;
|D. Lucas
|-
|Atmospheric CO2 from Continuous Air Samples at Mauna Loa Observatory
|Continuous air samples in Hawaii, USA. 44 years of records.
|None.
|44 years
|Text
|Regression
|2001
|&lt;ref&gt;{{cite journal | last1 = Pales | first1 = Jack C. | last2 = Keeling | first2 = Charles D. | year = 1965 | title = The concentration of atmospheric carbon dioxide in Hawaii | journal = Journal of Geophysical Research | volume = 70 | issue = 24| pages = 6053–6076 | doi=10.1029/jz070i024p06053 | bibcode=1965JGR....70.6053P}}&lt;/ref&gt;
|[[Mauna Loa Observatory]]
|-
|Ionosphere Dataset
|Radar data from the ionosphere. Task is to classify into good and bad radar returns.
|Many radar features given.
|351
|Text
|Classification
|1989
|&lt;ref name="Zhou, Zhi-Hua 2004" /&gt;&lt;ref&gt;Sigillito, Vincent G., et al. "Classification of radar returns from the ionosphere using neural networks." ''Johns Hopkins APL Technical Digest''10.3 (1989): 262–266.&lt;/ref&gt;
|[[Johns Hopkins University]]
|-
|Ozone Level Detection Dataset
|Two ground ozone level datasets.
|Many features given, including weather conditions at time of measurement.
|2536
|Text
|Classification
|2008
|&lt;ref&gt;Zhang, Kun, and Wei Fan. "[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.218.9860&amp;rep=rep1&amp;type=pdf Forecasting skewed biased stochastic ozone days: analyses, solutions and beyond]." ''Knowledge and Information Systems''14.3 (2008): 299–326.&lt;/ref&gt;&lt;ref&gt;Reich, Brian J., Montserrat Fuentes, and David B. Dunson. "[https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3583387/ Bayesian spatial quantile regression]." ''Journal of the American Statistical Association'' (2012).&lt;/ref&gt;
|K. Zhang et al.
|}

=== Census ===
{| style="width: 100%" class="wikitable sortable"
! scope="col" style="width: 15%;" |Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" |Creator
|-
|Adult Dataset
|Census data from 1994 containing demographic features of adults and their income.
|Cleaned and anonymized.
|48,842
|Comma separated values
|Classification
|1996
|&lt;ref&gt;{{cite journal | last1 = Kohavi | first1 = Ron | title = Scaling Up the Accuracy of Naive-Bayes Classifiers: A Decision-Tree Hybrid | journal = KDD | volume = 96 | year = 1996 }}&lt;/ref&gt;
|United States Census Bureau
|-
|Census-Income (KDD)
|Weighted census data from the 1994 and 1995 [[Current population survey (US)|Current Population Surveys]].
|Split into training and test sets.
|299,285
|Comma separated values
|Classification
|2000
|&lt;ref&gt;Oza, Nikunj C., and Stuart Russell. "Experimental comparisons of online and batch versions of bagging and boosting." ''Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining''. ACM, 2001.&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Bay | first1 = Stephen D | year = 2001 | title = Multivariate discretization for set mining | journal = Knowledge and Information Systems | volume = 3 | issue = 4| pages = 491–512 | doi=10.1007/pl00011680| citeseerx = 10.1.1.217.921 | s2cid = 10945544 }}&lt;/ref&gt;
|[[United States Census Bureau]]
|-
|IPUMS Census Database
|Census data from the Los Angeles and Long Beach areas.
|None
|256,932
|Text
|Classification, regression
|1999
|&lt;ref&gt;{{cite journal | last1 = Ruggles | first1 = Steven | year = 1995 | title = Sample designs and sampling errors | journal = Historical Methods: A Journal of Quantitative and Interdisciplinary History | volume = 28 | issue = 1| pages = 40–46 | doi=10.1080/01615440.1995.9955312}}&lt;/ref&gt;
|[[IPUMS]]
|-
|US Census Data 1990
|Partial data from 1990 US census.
|Results randomized and useful attributes selected.
|2,458,285
|Text
|Classification, regression
|1990
|&lt;ref&gt;Meek, Christopher, Bo Thiesson, and David Heckerman. "[https://www.microsoft.com/en-us/research/wp-content/uploads/2001/01/lc-aistats.pdf The Learning Curve Method Applied to Clustering]." ''AISTATS''. 2001.&lt;/ref&gt;
|[[United States Census Bureau]]
|}

=== Transit ===
{| class="wikitable sortable" style="width: 100%"
! scope="col" style="width: 15%;" |Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" |Creator
|-
|Bike Sharing Dataset
|Hourly and daily count of rental bikes in a large city.
|Many features, including weather, length of trip, etc., are given.
|17,389
|Text
|Regression
|2013
|&lt;ref&gt;{{cite journal | last1 = Fanaee-T | first1 = Hadi | last2 = Gama | first2 = Joao | year = 2013| title = Event labeling combining ensemble detectors and background knowledge | url = http://repositorio.inesctec.pt/handle/123456789/3506| journal = Progress in Artificial Intelligence | volume = 2 | issue = 2–3| pages = 113–127 | doi = 10.1007/s13748-013-0040-3 | s2cid = 3345087 }}&lt;/ref&gt;&lt;ref&gt;Giot, Romain, and Raphaël Cherrier. "[https://hal.archives-ouvertes.fr/docs/01/06/59/83/PDF/paper_final.pdf Predicting bikeshare system usage up to one day ahead]." ''Computational intelligence in vehicles and transportation systems (CIVTS), 2014 IEEE symposium on''. IEEE, 2014.&lt;/ref&gt;
|H. Fanaee-T
|-
|New York City Taxi Trip Data
|Trip data for yellow and green taxis in New York City.
|Gives pick up and drop off locations, fares, and other details of trips.
|6 years
|Text
|Classification, clustering
|2015
|&lt;ref&gt;{{cite journal | last1 = Zhan | first1 = Xianyuan | display-authors = et al | year = 2013 | title = Urban link travel time estimation using large-scale taxi data with partial information | journal = Transportation Research Part C: Emerging Technologies | volume = 33 | pages = 37–49 | doi=10.1016/j.trc.2013.04.001}}&lt;/ref&gt;
|[[New York City Taxi and Limousine Commission]]
|-
|Taxi Service Trajectory ECML PKDD
|Trajectories of all taxis in a large city.
|Many features given, including start and stop points.
|1,710,671
|Text
|Clustering, causal-discovery
|2015
|&lt;ref&gt;{{cite journal | last1 = Moreira-Matias | first1 = Luis | display-authors = et al | year = 2013 | title = Predicting taxi–passenger demand using streaming data | url = http://repositorio.inesctec.pt/handle/123456789/5356| journal = IEEE Transactions on Intelligent Transportation Systems| volume = 14 | issue = 3| pages = 1393–1402 | doi=10.1109/tits.2013.2262376| s2cid = 14764358 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Hwang | first1 = Ren-Hung | last2 = Hsueh | first2 = Yu-Ling | last3 = Chen | first3 = Yu-Ting | year = 2015 | title = An effective taxi recommender system based on a spatio-temporal factor analysis model | journal = Information Sciences | volume = 314 | pages = 28–40 | doi=10.1016/j.ins.2015.03.068}}&lt;/ref&gt;
|M. Ferreira et al.
|-
|METR-LA
|Speed from loop detectors in the highway of Los Angles County.
|Average speed in 5 minutes timesteps.
|7,094,304 from 207 sensors and 34,272 timesteps
|Comma separated values
|Regression, Forecasting
|2014
| &lt;ref&gt;H. V. Jagadish, Johannes Gehrke, Alexandros Labrinidis, Yannis Papakonstantinou, Jignesh M. Patel,
Raghu Ramakrishnan, and Cyrus Shahabi. Big data and its technical challenges. Commun. ACM,
57(7):86–94, July 2014.&lt;/ref&gt;
|Jagadish et. al.
|-
|PeMS
|Speed, flow, occupancy and other metrics from loop detectors and other sensors in the freeway of the State of California, U.S.A..
|Metric usually aggregated via Average into 5 minutes timesteps.
|39,000 individual detectors, each containing years of timeseries
|Comma separated values
|Regression, Forecasting, Nowcasting, Interpolation
|(updated realtime)
|&lt;ref&gt;http://pems.dot.ca.gov/&lt;/ref&gt;
|California Department of Transportation
|}

=== Internet ===
{| class="wikitable sortable" style="width: 100%"
! scope="col" style="width: 15%;" |Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" |Creator
|-
|Webpages from Common Crawl 2012
|Large collection of webpages and how they are connected via hyperlinks
|None.
|3.5B
|Text
|clustering, classification
|2013
|&lt;ref&gt;Meusel, Robert, et al. "[https://www.nowpublishers.com/article/OpenAccessDownload/JWS-0003 The Graph Structure in the Web—Analyzed on Different Aggregation Levels]."''The Journal of Web Science'' 1.1 (2015).&lt;/ref&gt;
|V. Granville
|-
|Internet Advertisements Dataset
|Dataset for predicting if a given image is an advertisement or not.
|Features encode geometry of ads and phrases occurring in the URL.
|3279
|Text
|Classification
|1998
|&lt;ref&gt;Kushmerick, Nicholas. "[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.35.5686&amp;rep=rep1&amp;type=pdf Learning to remove internet advertisements]." ''Proceedings of the third annual conference on Autonomous Agents''. ACM, 1999.&lt;/ref&gt;&lt;ref&gt;Fradkin, Dmitriy, and David Madigan. "[https://www.researchgate.net/profile/Dmitriy_Fradkin/publication/2573186_Experiments_with_Random_Projections_for_Machine_Learning/links/0fcfd50b6230aaf309000000.pdf Experiments with random projections for machine learning]."''Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining''. ACM, 2003.&lt;/ref&gt;
|N. Kushmerick
|-
|Internet Usage Dataset
|General demographics of internet users.
|None.
|10,104
|Text
|Classification, clustering
|1999
|&lt;ref&gt;This data was used in the American Statistical Association Statistical Graphics and Computing Sections 1999 Data Exposition.&lt;/ref&gt;
|D. Cook
|-
|URL Dataset
|120 days of URL data from a large conference.
|Many features of each URL are given.
|2,396,130
|Text
|Classification
|2009
|&lt;ref&gt;Ma, Justin, et al. "[https://cseweb.ucsd.edu/~voelker/pubs/mal-url-icml09.pdf Identifying suspicious URLs: an application of large-scale online learning]."''Proceedings of the 26th annual international conference on machine learning''. ACM, 2009.&lt;/ref&gt;&lt;ref&gt;Levchenko, Kirill, et al. "[http://www.icir.org/christian/publications/2011-oakland-trajectory.pdf Click trajectories: End-to-end analysis of the spam value chain]." ''Security and Privacy (SP), 2011 IEEE Symposium on''. IEEE, 2011.&lt;/ref&gt;
|J. Ma
|-
|Phishing Websites Dataset
|Dataset of phishing websites.
|Many features of each site are given.
|2456
|Text
|Classification
|2015
|&lt;ref&gt;Mohammad, Rami M., Fadi Thabtah, and Lee McCluskey. "[http://eprints.hud.ac.uk/16229/1/The_7th_ICITST_2012_Conference_-An_Assessment_of_Features_Related_to_Phishing_Websites_using_an_Automated_Technique.pdf An assessment of features related to phishing websites using an automated technique]."''Internet Technology And Secured Transactions, 2012 International Conference for''. IEEE, 2012.&lt;/ref&gt;
|R. Mustafa et al.
|-
|Online Retail Dataset
|Online transactions for a UK online retailer.
|Details of each transaction given.
|541,909
|Text
|Classification, clustering
|2015
|&lt;ref&gt;Singh, Ashishkumar, et al. "[https://dl.acm.org/citation.cfm?id=2644161 Clustering Experiments on Big Transaction Data for Market Segmentation]." ''Proceedings of the 2014 International Conference on Big Data Science and Computing''. ACM, 2014.&lt;/ref&gt;
|D. Chen
|-
|Freebase Simple Topic Dump
|Freebase is an online effort to structure all human knowledge.
|Topics from Freebase have been extracted.
|large
|Text
|Classification, clustering
|2011
|&lt;ref&gt;Bollacker, Kurt, et al. "[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.538.7139&amp;rep=rep1&amp;type=pdf Freebase: a collaboratively created graph database for structuring human knowledge]." ''Proceedings of the 2008 ACM SIGMOD international conference on Management of data''. ACM, 2008.&lt;/ref&gt;&lt;ref&gt;Mintz, Mike, et al. "[https://www.aclweb.org/anthology/P09-1113 Distant supervision for relation extraction without labeled data]." ''Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2-Volume 2''. Association for Computational Linguistics, 2009.&lt;/ref&gt;
|[[Freebase (database)|Freebase]]
|-
|Farm Ads Dataset
|The text of farm ads from websites. Binary approval or disapproval by content owners is given.
|SVMlight sparse vectors of text words in ads calculated.
|4143
|Text
|Classification
|2011
|&lt;ref&gt;Mesterharm, Chris, and Michael J. Pazzani. "[http://research.cs.rutgers.edu/~mesterha/active-online.pdf Active learning using on-line algorithms]."''Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining''. ACM, 2011.&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Wang | first1 = Shusen | last2 = Zhang | first2 = Zhihua | year = 2013 | title = Improving CUR matrix decomposition and the Nyström approximation via adaptive sampling | url = http://www.jmlr.org/papers/volume14/wang13c/wang13c.pdf| journal = The Journal of Machine Learning Research | volume = 14 | issue = 1| pages = 2729–2769 | arxiv = 1303.4207 | bibcode = 2013arXiv1303.4207W }}&lt;/ref&gt;
|C. Masterharm et al.
|}

=== Games ===
{| style="width: 100%" class="wikitable sortable"
! scope="col" style="width: 15%;" |Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" |Creator
|-
|Poker Hand Dataset
|5 card hands from a standard 52 card deck.
|Attributes of each hand are given, including the Poker hands formed by the cards it contains.
|1,025,010
|Text
|Regression, classification
|2007
|&lt;ref&gt;{{cite journal |last1=Cattral |first1=Robert |first2=Franz |last2=Oppacher |first3=Dwight |last3=Deugo |url=https://pdfs.semanticscholar.org/c068/ea7807367573f4b5f98c0681fca665e9ef74.pdf |title=Evolutionary data mining with automatic rule generalization |journal=Recent Advances in Computers, Computing and Communications |year=2002 |pages=296–300|s2cid=18625415 }}&lt;/ref&gt;
|R. Cattral
|-
|Connect-4 Dataset
|Contains all legal 8-ply positions in the game of connect-4 in which neither player has won yet, and in which the next move is not forced.
|None.
|67,557
|Text
|Classification
|1995
|&lt;ref&gt;{{cite journal | last1=Burton | first1=Ariel N. | last2=Kelly | first2=Paul H.J. | title=Performance prediction of paging workloads using lightweight tracing | journal=Future Generation Computer Systems | publisher=Elsevier BV | volume=22 | issue=7 | year=2006 | issn=0167-739X | doi=10.1016/j.future.2006.02.003 | pages=784–793}}&lt;/ref&gt;
|J. Tromp
|-
|Chess (King-Rook vs. King) Dataset
|Endgame Database for White King and Rook against Black King.
|None.
|28,056
|Text
|Classification
|1994
|&lt;ref&gt;{{cite journal |last1=Bain |first1=Michael |first2=Stephen |last2=Muggleton |title=Learning optimal chess strategies |journal=Machine Intelligence |volume=13 |publisher=Oxford University Press, Inc. |year=1994}}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Quilan | first1 = J. R. | title = Learning efficient classification procedures and their application to chess end games | journal = Machine Learning: An Artificial Intelligence Approach | volume = 1 | pages = 463–482 | year= 1983 | doi = 10.1007/978-3-662-12405-5_15 | isbn = 978-3-662-12407-9 }}&lt;/ref&gt;
|M. Bain et al.
|-
|Chess (King-Rook vs. King-Pawn) Dataset
|King+Rook versus King+Pawn on a7.
|None.
|3196
|Text
|Classification
|1989
|&lt;ref&gt;{{cite book |last=Shapiro |first=Alen D. |title=Structured induction in expert systems |publisher=Addison-Wesley Longman Publishing Co., Inc. |year=1987}}&lt;/ref&gt;
|R. Holte
|-
|Tic-Tac-Toe Endgame Dataset
|Binary classification for win conditions in tic-tac-toe.
|None.
|958
|Text
|Classification
|1991
|&lt;ref&gt;{{cite journal | last1 = Matheus | first1 = Christopher J. | last2 = Rendell | first2 = Larry A. | title = Constructive Induction on Decision Trees | url =http://www.academia.edu/download/40413240/Constructive_Induction_On_Decision_Trees20151126-4470-tjt71n.pdf | journal = IJCAI | volume = 89 | year = 1989 }}&lt;/ref&gt;
|D. Aha
|}

=== Other multivariate ===
{| style="width: 100%" class="wikitable sortable"
! scope="col" style="width: 15%;" |Dataset Name
! scope="col" style="width: 18%;" | Brief description
! scope="col" style="width: 18%;" | Preprocessing
! scope="col" style="width: 6%;" | Instances
! scope="col" style="width: 7%;" | Format
! scope="col" style="width: 7%;" | Default Task
! scope="col" style="width: 6%;" | Created (updated)
! scope="col" style="width: 6%;" | Reference
! scope="col" style="width: 11%;" |Creator
|-
|Housing Data Set
|Median home values of Boston with associated home and neighborhood attributes.
|None.
|506
|Text
|Regression
|1993
|&lt;ref name=":5"&gt;Belsley, David A., Edwin Kuh, and Roy E. Welsch. ''Regression diagnostics: Identifying influential data and sources of collinearity''. Vol. 571. John Wiley &amp; Sons, 2005.&lt;/ref&gt;
|D. Harrison et al.
|-
|The Getty Vocabularies
|structured terminology for art and other material culture, archival materials, visual surrogates, and bibliographic materials.
|None.
|large
|Text
|Classification
|2015
|&lt;ref&gt;{{cite journal | last1 = Ruotsalo | first1 = Tuukka | last2 = Aroyo | first2 = Lora | last3 = Schreiber | first3 = Guus | year = 2009 | title = Knowledge-based linguistic annotation of digital cultural heritage collections | url =http://dare.ubvu.vu.nl/bitstream/handle/1871/24407/243319.pdf?sequence=3 | journal = IEEE Intelligent Systems | volume = 24 | issue = 2| pages = 64–75 | doi = 10.1109/MIS.2009.32 | s2cid = 6667472 }}&lt;/ref&gt;
|[[Getty Center]]
|-
|Yahoo! Front Page Today Module User Click Log
|User click log for news articles displayed in the Featured Tab of the Today Module on Yahoo! Front Page.
|Conjoint analysis with a bilinear model.
|45,811,883 user visits
|Text
|Regression, clustering
|2009
|&lt;ref&gt;Li, Lihong, et al. "[https://arxiv.org/abs/1003.5956 Unbiased offline evaluation of contextual-bandit-based news article recommendation algorithms]." ''Proceedings of the fourth ACM international conference on Web search and data mining''. ACM, 2011.&lt;/ref&gt;&lt;ref&gt;Yeung, Kam Fung, and Yanyan Yang. "[https://ieeexplore.ieee.org/abstract/document/5633837/ A proactive personalized mobile news recommendation system]." ''Developments in E-systems Engineering (DESE), 2010''. IEEE, 2010.&lt;/ref&gt;
|Chu et al.
|-
|British Oceanographic Data Centre
|Biological, chemical, physical and geophysical data for oceans. 22K variables tracked.
|Various.
|22K variables, many instances
|Text
|Regression, clustering
|2015
|&lt;ref&gt;{{cite journal | last1 = Gass | first1 = Susan E. | last2 = Roberts | first2 = J. Murray | year = 2006 | title = The occurrence of the cold-water coral Lophelia pertusa (Scleractinia) on oil and gas platforms in the North Sea: colony growth, recruitment and environmental controls on distribution | journal = Marine Pollution Bulletin | volume = 52 | issue = 5| pages = 549–559 | doi=10.1016/j.marpolbul.2005.10.002| pmid = 16300800 }}&lt;/ref&gt;
|[[British Oceanographic Data Centre]]
|-
|Congressional Voting Records Dataset
|Voting data for all USA representatives on 16 issues.
|Beyond the raw voting data, various other features are provided.
|435
|Text
|Classification
|1987
|&lt;ref&gt;{{cite journal | last1 = Gionis | first1 = Aristides | last2 = Mannila | first2 = Heikki | last3 = Tsaparas | first3 = Panayiotis | year = 2007 | title = Clustering aggregation | journal = ACM Transactions on Knowledge Discovery from Data  | volume = 1 | issue = 1| page = 4 | doi=10.1145/1217299.1217303| citeseerx = 10.1.1.709.528 | s2cid = 433708 }}&lt;/ref&gt;
|J. Schlimmer
|-
|Entree Chicago Recommendation Dataset
|Record of user interactions with Entree Chicago recommendation system.
|Details of each users usage of the app are recorded in detail.
|50,672
|Text
|Regression, recommendation
|2000
|&lt;ref&gt;Obradovic, Zoran, and Slobodan Vucetic.''Challenges in Scientific Data Mining: Heterogeneous, Biased, and Large Samples''. Technical Report, Center for Information Science and Technology Temple University, 2004.&lt;/ref&gt;
|R. Burke
|-
|Insurance Company Benchmark (COIL 2000)
|Information on customers of an insurance company.
|Many features of each customer and the services they use.
|9,000
|Text
|Regression, classification
|2000
|&lt;ref&gt;{{cite journal | last1 = Van Der Putten | first1 = Peter | last2 = van Someren | first2 = Maarten | year = 2000 | title = CoIL challenge 2000: The insurance company case | journal = Published by Sentient Machine Research, Amsterdam. Also a Leiden Institute of Advanced Computer Science Technical Report | volume = 9 | pages = 1–43 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Mao | first1 = K. Z. | year = 2002 | title = RBF neural network center selection based on Fisher ratio class separability measure | journal = IEEE Transactions on Neural Networks| volume = 13 | issue = 5| pages = 1211–1217 | doi=10.1109/tnn.2002.1031953| pmid = 18244518 }}&lt;/ref&gt;
|P. van der Putten
|-
|Nursery Dataset
|Data from applicants to nursery schools.
|Data about applicant's family and various other factors included.
|12,960
|Text
|Classification
|1997
|&lt;ref&gt;{{cite journal | last1 = Olave | first1 = Manuel | last2 = Rajkovic | first2 = Vladislav | last3 = Bohanec | first3 = Marko | year = 1989 | title = An application for admission in public school systems | url = http://kt.ijs.si/MarkoBohanec/pub/Nursery89.pdf | journal = Expert Systems in Public Administration | volume = 1 | pages = 145–160 }}&lt;/ref&gt;&lt;ref&gt;Lizotte, Daniel J., Omid Madani, and Russell Greiner. "[https://arxiv.org/abs/1212.2472 Budgeted learning of nailve-bayes classifiers]." ''Proceedings of the Nineteenth conference on Uncertainty in Artificial Intelligence''. Morgan Kaufmann Publishers Inc., 2002.&lt;/ref&gt;
|V. Rajkovic et al.
|-
|University Dataset
|Data describing attributed of a large number of universities.
|None.
|285
|Text
|Clustering, classification
|1988
|&lt;ref&gt;{{cite book | last1 = Lebowitz | first1 = Michael | year = 1986 | title = Concept learning in a rich input domain: Generalization-based memory | url = https://books.google.com/books?id=f9RylgKpHZsC&amp;q=%22Concept+learning+in+a+rich+input+domain:+Generalization-based+memory%22&amp;pg=PA193| journal = Machine Learning: An Artificial Intelligence Approach | volume = 2 | pages = 193–214 | isbn = 9780934613002 }}&lt;/ref&gt;
|S. Sounders et al.
|-
|Blood Transfusion Service Center Dataset
|Data from blood transfusion service center. Gives data on donors return rate, frequency, etc.
|None.
|748
|Text
|Classification
|2008
|&lt;ref&gt;{{cite journal | last1 = Yeh | first1 = I-Cheng | last2 = Yang | first2 = King-Jang | last3 = Ting | first3 = Tao-Ming | year = 2009 | title = Knowledge discovery on RFM model using Bernoulli sequence | journal = Expert Systems with Applications | volume = 36 | issue = 3| pages = 5866–5871 | doi=10.1016/j.eswa.2008.07.018}}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Lee | first1 = Wen-Chen | last2 = Cheng | first2 = Bor-Wen | year = 2011 | title = An intelligent system for improving performance of blood donation | url = http://www.airitilibrary.com/Publication/alDetailedMesh?docid=10220690-201104-201105050019-201105050019-173-185| journal = Journal of Quality Vol | volume = 18 | issue = 2| page = 173 }}&lt;/ref&gt;
|I. Yeh
|-
|Record Linkage Comparison Patterns Dataset
|Large dataset of records. Task is to link relevant records together.
|Blocking procedure applied to select only certain record pairs.
|5,749,132
|Text
|Classification
|2011
|&lt;ref&gt;Schmidtmann, Irene, et al. "[http://www.krebsregister-nrw.de/fileadmin/user_upload/dokumente/Evaluation/EKR_NRW_Evaluation_Abschlussbericht_2009-06-11.pdf Evaluation des Krebsregisters NRW Schwerpunkt Record Linkage]." ''Abschlußbericht vom'' 11 (2009).&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Sariyar | first1 = Murat | last2 = Borg | first2 = Andreas | last3 = Pommerening | first3 = Klaus | year = 2011 | title = Controlling false match rates in record linkage using extreme value theory | journal = Journal of Biomedical Informatics | volume = 44 | issue = 4| pages = 648–654 | doi=10.1016/j.jbi.2011.02.008| pmid = 21352952 }}&lt;/ref&gt;
|[[University of Mainz]]
|-
|Nomao Dataset
|Nomao collects data about places from many different sources. Task is to detect items that describe the same place.
|Duplicates labeled.
|34,465
|Text
|Classification
|2012
|&lt;ref&gt;Candillier, Laurent, and Vincent Lemaire. "[https://pdfs.semanticscholar.org/1647/fc91cfe3e68ef3c41d727b7292ce20482b11.pdf Design and Analysis of the Nomao challenge Active Learning in the Real-World]." ''Proceedings of the ALRA: Active Learning in Real-world Applications, Workshop ECML-PKDD''. 2012.&lt;/ref&gt;&lt;ref&gt;Marquez, Ivan Garrido. "[http://ccc.inaoep.mx/~mmontesg/tesis%20estudiantes/TesisMaestria-IvanGarrido.pdf A Domain Adaptation Method for Text Classification based on Self-adjusted Training Approach]." (2013).&lt;/ref&gt;
|Nomao Labs
|-
|Movie Dataset
|Data for 10,000 movies.
|Several features for each movie are given.
|10,000
|Text
|Clustering, classification
|1999
|&lt;ref&gt;Nagesh, Harsha S., Sanjay Goil, and Alok N. Choudhary. "Adaptive Grids for Clustering Massive Data Sets." SDM. 2001.&lt;/ref&gt;
|G. Wiederhold
|-
|Open University Learning Analytics Dataset
|Information about students and their interactions with a virtual learning environment.
|None.
|~ 30,000
|Text
|Classification, clustering, regression
|2015
|&lt;ref&gt;Kuzilek, Jakub, et al. "[http://oro.open.ac.uk/42529/1/__userdata_documents4_ctb44_Desktop_analysing-at-risk-students-at-open-university.pdf OU Analyse: analysing at-risk students at The Open University]." ''Learning Analytics Review'' (2015): 1–16.&lt;/ref&gt;&lt;ref&gt;Siemens, George, et al. ''[http://search.ror.unisa.edu.au/record/UNISA_ALMA11143300720001831/media/digital/open/9915909179101831/12143300710001831/13143328550001831/pdf Open Learning Analytics: an integrated &amp; modularized platform]''. Diss. Open University Press, 2011.&lt;/ref&gt;
|J. Kuzilek et al.
|-
|Mobile phone records
|Telecommunications activity and interactions
|Aggregation per geographical grid cells and every 15 minutes.
|large
|Text
|Classification, Clustering, Regression
|2015
|&lt;ref name="BarlacchiDe Nadai2015"&gt;{{cite journal|last1=Barlacchi|first1=Gianni|last2=De Nadai|first2=Marco|last3=Larcher|first3=Roberto|last4=Casella|first4=Antonio|last5=Chitic|first5=Cristiana|last6=Torrisi|first6=Giovanni|last7=Antonelli|first7=Fabrizio|last8=Vespignani|first8=Alessandro|last9=Pentland|first9=Alex|last10=Lepri|first10=Bruno|title=A multi-source dataset of urban life in the city of Milan and the Province of Trentino|journal=Scientific Data|volume=2|year=2015|pages=150055|issn=2052-4463|doi=10.1038/sdata.2015.55|pmid=26528394|pmc=4622222|bibcode=2015NatSD...250055B}}&lt;/ref&gt;
|G. Barlacchi et al.
|}

== Curated repositories of datasets ==

As datasets come in myriad formats and can sometimes be difficult to use, there has been considerable work put into curating and standardizing the format of datasets to make them easier to use for machine learning research.

* OpenML:&lt;ref&gt;{{cite journal | vauthors = Vanschoren J, van Rijn JN, Bischl B, Torgo L | year = 2013 | title = OpenML: networked science in machine learning | journal = SIGKDD Explorations | volume = 15 | issue = 2  | pages = 49–60 | doi = 10.1145/2641190.2641198 | arxiv = 1407.7722 | s2cid = 4977460 }}&lt;/ref&gt; Web platform with Python, R, Java, and other APIs for downloading hundreds of machine learning datasets, evaluating algorithms on datasets, and benchmarking algorithm performance against dozens of other algorithms.
* PMLB:&lt;ref&gt;{{cite journal | vauthors = Olson RS, La Cava W, Orzechowski P, Urbanowicz RJ, Moore JH | year = 2017 | title = PMLB: a large benchmark suite for machine learning evaluation and comparison | journal = BioData Mining | volume = 10  | pages = 36 | doi = 10.1186/s13040-017-0154-4 | pmid = 29238404 | pmc = 5725843 | bibcode = 2017arXiv170300512O | arxiv = 1703.00512 }}&lt;/ref&gt; A large, curated repository of benchmark datasets for evaluating supervised machine learning algorithms. Provides classification and regression datasets in a standardized format that are accessible through a Python API.
*Metatext NLP: https://metatext.io/datasets web repository maintained by community, containing nearly 1000 benchmark datasets, and counting. Provides many tasks from classification to QA, and various languages from English, Portuguese to Arabic.
*[[Appen (company)|Appen]]: Off The Shelf and Open Source Datasets hosted and maintained by the company. These biological, image, physical, question answering, signal, sound, text, and video resources number over 250 and can be applied to over 25 different use cases.&lt;ref&gt;{{cite web |title=Off The Shelf Datasets |url=https://appen.com/off-the-shelf-datasets/ |website=appen.com |publisher=[[Appen (company)|Appen]] |access-date=30 December 2020}}&lt;/ref&gt;&lt;ref&gt;{{cite web |title=Open Source Datasets |url=https://appen.com/resources/datasets/ |website=appen.com |publisher=[[Appen (company)|Appen]] |access-date=30 December 2020}}&lt;/ref&gt;

== See also ==
* [[Comparison of deep learning software]]
* [[List of manual image annotation tools]]
* [[List of biological databases]]

== References ==
{{reflist}}

[[Category:Datasets in machine learning| ]]
[[Category:Machine learning|*]]
[[Category:Artificial intelligence]]</text>
      <sha1>lia6swvjk5yypo9mp7ufba00akkc0w6</sha1>
    </revision>
  </page>
  <page>
    <title>Outline of machine learning</title>
    <ns>0</ns>
    <id>53587467</id>
    <revision>
      <id>999847448</id>
      <parentid>996735268</parentid>
      <timestamp>2021-01-12T07:04:09Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 5 templates: hyphenate params (1×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="41896" xml:space="preserve">{{Short description|1=Overview of and topical guide to machine learning}}
&lt;!--... Attention:  THIS IS AN OUTLINE

        part of the set of 720+ outlines listed at
             [[Portal:Contents/Outlines]].

                 Wikipedia outlines are
              a special type of list article.
              They make up one of Wikipedia's
                content navigation systems

                See [[Wikipedia:Outlines]]
                      for more details.
                   Further improvements
              to this outline are on the way
...--&gt;
&lt;!--{{see also|Index of machine learning articles}}
--&gt;
{{machine learning bar}}
The following [[Outline (list)|outline]] is provided as an overview of and topical guide to '''machine learning'''. [[Machine learning]] is a subfield of [[soft computing]] within [[computer science]] that evolved from the study of [[pattern recognition]] and [[computational learning theory]] in [[artificial intelligence]].&lt;ref name=Britannica&gt;http://www.britannica.com/EBchecked/topic/1116194/machine-learning {{tertiary}}&lt;/ref&gt; In 1959, [[Arthur Samuel]] defined machine learning as a "field of study that gives computers the ability to learn without being explicitly programmed".&lt;ref name="arthur_samuel_machine_learning_def"&gt;{{cite book | title=Too Big to Ignore: The Business Case for Big Data | publisher=Wiley | author=Phil Simon | date=March 18, 2013 | pages=89 | isbn=978-1-118-63817-0 | url=https://books.google.com/books?id=Dn-Gdoh66sgC&amp;pg=PA89}}&lt;/ref&gt; Machine learning explores the study and construction of [[algorithm]]s that can [[learning|learn]] from and make predictions on [[data]].&lt;ref&gt;{{cite journal |title=Glossary of terms |author1=Ron Kohavi |author2=Foster Provost |journal=[[Machine Learning (journal)|Machine Learning]] |volume=30 |pages=271–274 |year=1998 |doi=10.1023/A:1007411609915 |url=https://ai.stanford.edu/~ronnyk/glossary.html|doi-access=free }}&lt;/ref&gt; Such algorithms operate by building a [[Mathematical model|model]] from an example [[training set]] of input observations in order to make data-driven predictions or decisions expressed as outputs, rather than following strictly static program instructions.

{{TOC limit|limit=3}}

== What ''type'' of thing is machine learning? ==

* An [[academic discipline]]
* A branch of [[science]]
** An [[applied science]]
*** A subfield of [[computer science]]
**** A branch of [[artificial intelligence]]
**** A subfield of [[soft computing]]
*** Application of [[statistics]]

== Branches of machine learning ==

=== Subfields of machine learning ===

Subfields of machine learning
* [[Computational learning theory]] &amp;ndash; studying the design and analysis of [[machine learning]] algorithms.&lt;ref name="ACL"&gt;{{Cite web | url=http://www.learningtheory.org/ | title=ACL - Association for Computational Learning}}&lt;/ref&gt;
* [[Grammar induction]]
* [[Meta learning (computer science)|Meta learning]]

=== Cross-disciplinary fields involving machine learning ===

Cross-disciplinary fields involving machine learning
* [[Adversarial machine learning]]
* [[Predictive analytics]]
* [[Quantum machine learning]]
* [[Robot learning]]
** [[Developmental robotics]]

== Applications of machine learning ==

[[Applications of machine learning]]
* [[Bioinformatics]]
* [[Biomedical informatics]]
* [[Computer vision]]
* [[Customer relationship management]] &amp;ndash;
* [[Data mining]]
* [[Email filtering]]
* [[Inverted pendulum]] &amp;ndash; balance and equilibrium system.
* [[Natural language processing]] (NLP)
** [[Automatic summarization]]
** [[Automatic taxonomy construction]]
** [[Dialog system]]
** [[Grammar checker]]
** Language recognition
*** [[Handwriting recognition]]
*** [[Optical character recognition]]
*** [[Speech recognition]]
** [[Machine translation]]
** [[Question answering]]
** [[Speech synthesis]]
** [[Text mining]]
***[[Term frequency–inverse document frequency]] (tf–idf)
** [[Text simplification]]
* [[Pattern recognition]]
** [[Facial recognition system]]
** [[Handwriting recognition]]
** [[Image recognition]] 
** [[Optical character recognition]]
** [[Speech recognition]]
* [[Recommendation system]]
**[[Collaborative filtering]]
**[[Content-based filtering]]
**[[Recommender system#Hybrid recommender systems|Hybrid recommender systems]] (Collaborative and content-based filtering)
* [[Search engine]]
**[[Search engine optimization]]
* [[Social engineering (security)|Social Engineering]]

== Machine learning hardware ==

Machine learning hardware
* [[Graphics processing unit]]
* [[Tensor processing unit]]
* [[Vision processing unit]]

== Machine learning tools ==

[[Machine learning tools]] &amp;nbsp; ([[List of machine learning tools|list]])
* [[Comparison of deep learning software]]
** Comparison of deep learning software/Resources

=== Machine learning frameworks ===

Machine learning framework

==== Proprietary machine learning frameworks ====

Proprietary machine learning frameworks
* [[Amazon Machine Learning]]
* [[Microsoft Azure#Machine Learning|Microsoft Azure Machine Learning Studio]]
* [[DistBelief]] &amp;ndash; replaced by TensorFlow

==== Open source machine learning frameworks ====

Open source machine learning frameworks
* [[Apache Singa]]
* [[Apache MXNet]]
* [[Caffe (software)|Caffe]]
* [[PyTorch]] 
* [[mlpack]]
* [[TensorFlow]]
* [[Torch (machine learning)|Torch]]
* [[Microsoft Cognitive Toolkit|CNTK]]
* [[Accord.NET|Accord.Net]]

=== Machine learning libraries ===

Machine learning library &amp;nbsp; 
* [[Deeplearning4j]]
* [[Theano (software)|Theano]]
* [[Scikit-learn]]
* [[Keras]]

=== Machine learning algorithms ===

[[Machine learning algorithm]]

==== Types of machine learning algorithms ====
* [[Almeida–Pineda recurrent backpropagation]]
* [[ALOPEX]]
* [[Backpropagation]]
* [[Bootstrap aggregating]]
* [[CN2 algorithm]]
* [[Constructing skill trees]]
* [[Dehaene–Changeux model]]
* [[Diffusion map]]
* [[Dominance-based rough set approach]]
* [[Dynamic time warping]]
* [[Error-driven learning]]
* [[Evolutionary multimodal optimization]]
* [[Expectation–maximization algorithm]]
* [[FastICA]]
* [[Forward–backward algorithm]]
* [[GeneRec]]
* [[Genetic Algorithm for Rule Set Production]]
* [[Growing self-organizing map]]
* [[Hyper basis function network]]
* [[IDistance]]
* [[K-nearest neighbors algorithm]]
* [[Kernel methods for vector output]]
* [[Kernel principal component analysis]]
* [[Leabra]]
* [[Linde–Buzo–Gray algorithm]]
* [[Local outlier factor]]
* [[Logic learning machine]]
* [[LogitBoost]]
* [[Manifold alignment]]
*[[Markov chain Monte Carlo|Markov chain Monte Carlo (MCMC)]]
* [[Minimum redundancy feature selection]]
* [[Mixture of experts]]
* [[Multiple kernel learning]]
* [[Non-negative matrix factorization]]
* [[Online machine learning]]
* [[Out-of-bag error]]
* [[Prefrontal cortex basal ganglia working memory]]
* [[PVLV]]
* [[Q-learning]]
* [[Quadratic unconstrained binary optimization]]
* [[Query-level feature]]
* [[Quickprop]]
* [[Radial basis function network]]
* [[Randomized weighted majority algorithm]]
* [[Reinforcement learning]]
* [[Repeated incremental pruning to produce error reduction (RIPPER)]]
* [[Rprop]]
* [[Rule-based machine learning]]
* [[Skill chaining]]
* [[Sparse PCA]]
* [[State–action–reward–state–action]]
* [[Stochastic gradient descent]]
* [[Structured kNN]]
* [[T-distributed stochastic neighbor embedding]]
* [[Temporal difference learning]]
* [[Wake-sleep algorithm]]
* [[Weighted majority algorithm (machine learning)]]

== Machine learning methods ==

[[Machine learning method]] &amp;nbsp; ([[List of machine learning methods|list]])

=== '''Instance-based algorithm''' ===
* [[K-nearest neighbors algorithm]] (KNN)
* [[Learning vector quantization]] (LVQ)
* [[Self-organizing map]] (SOM)

=== [[Regression analysis]] ===
* [[Logistic regression]]
* [[Ordinary least squares regression]] (OLSR)
* [[Linear regression]]
* [[Stepwise regression]]
* [[Multivariate adaptive regression splines]] (MARS)

* Regularization algorithm
** [[Ridge regression]]
** [[Least Absolute Shrinkage and Selection Operator]] (LASSO)
** [[Elastic net]]
** [[Least-angle regression]] (LARS)
* [[Statistical classification|Classifiers]]
** [[Probabilistic classifier]]
*** [[Naive Bayes classifier]]
** [[Binary classifier]]
** [[Linear classifier]]
** [[Hierarchical classifier]]

=== Dimensionality reduction ===

[[Dimensionality reduction]]
* [[Canonical correlation analysis]] (CCA)
* [[Factor analysis]]
* [[Feature extraction]]
* [[Feature selection]]
* [[Independent component analysis]] (ICA)
* [[Linear discriminant analysis]] (LDA)
* [[Multidimensional scaling]] (MDS)
* [[Non-negative matrix factorization]] (NMF)
* [[Partial least squares regression]] (PLSR)
* [[Principal component analysis]] (PCA)
* [[Principal component regression]] (PCR)
* [[Projection pursuit]]
* [[Sammon mapping]]
* [[t-distributed stochastic neighbor embedding]] (t-SNE)

=== Ensemble learning ===

[[Ensemble learning]]
* [[AdaBoost]]
* [[Boosting (machine learning)|Boosting]]
* [[Bootstrap aggregating]] (Bagging)
* [[Ensemble averaging (machine learning)|Ensemble averaging]] &amp;ndash; process of creating multiple models and combining them to produce a desired output, as opposed to creating just one model. Frequently an ensemble of models performs better than any individual model, because the various errors of the models "average out."
* [[Gradient boosted decision tree]] (GBDT)
* [[Gradient boosting]] machine (GBM)
* [[Random Forest]]
* [[Stacked Generalization]] (blending)

=== Meta learning ===

[[Meta learning (computer science)|Meta learning]]
* [[Inductive bias]]
* [[Metadata]]

=== Reinforcement learning ===

[[Reinforcement learning]]
* [[Q-learning]]
* [[State–action–reward–state–action]] (SARSA)
* [[Temporal difference learning]] (TD)
* [[Learning Automata]]

=== Supervised learning ===

[[Supervised learning]]
* [[AODE]]
* [[Artificial neural network]]
* [[Association rule learning]] algorithms
** [[Apriori algorithm]]
** [[Eclat algorithm]]
* [[Case-based reasoning]]
* [[Gaussian process regression]]
* [[Gene expression programming]]
* [[Group method of data handling]] (GMDH)
* [[Inductive logic programming]]
* [[Instance-based learning]]
* [[Lazy learning]]
* [[Learning Automata]]
* [[Learning Vector Quantization]]
* [[Logistic Model Tree]]
* [[Minimum message length]] (decision trees, decision graphs, etc.)
** [[Nearest neighbor (pattern recognition)|Nearest Neighbor Algorithm]]
** [[Analogical modeling]]
* [[Probably approximately correct learning]] (PAC) learning
* [[Ripple down rules]], a knowledge acquisition methodology
* Symbolic machine learning algorithms
* [[Support vector machine]]s
* [[Random forest|Random Forests]]
* [[Ensembles of classifiers]]
** [[Bootstrap aggregating]] (bagging)
** [[Boosting (meta-algorithm)]]
* [[Ordinal classification]]
* [[Information Fuzzy Networks|Information fuzzy networks]] (IFN)
* [[Conditional Random Field]]
* [[ANOVA]]
* [[Quadratic classifier]]s
* [[Nearest neighbor (pattern recognition)|k-nearest neighbor]]
* [[Boosting (machine learning)|Boosting]]
** SPRINT
* [[Bayesian network]]s
** [[Naive Bayes]]
* [[Hidden Markov model]]s
**[[Hierarchical hidden Markov model]]

==== Bayesian ====

[[Bayesian statistics]]
* Bayesian knowledge base
* [[Naive Bayes]]
* [[Gaussian Naive Bayes]]
* [[Multinomial Naive Bayes]]
* [[Averaged One-Dependence Estimators]] (AODE)
* [[Bayesian Belief Network]] (BBN)
* [[Bayesian Network]] (BN)

==== Decision tree algorithms ====

Decision tree algorithm
* [[Decision tree]]
* [[Classification and regression tree]] (CART)
* [[Iterative Dichotomiser 3]] (ID3)
* [[C4.5 algorithm]]
* [[C5.0 algorithm]]
* [[Chi-squared Automatic Interaction Detection]] (CHAID)
* [[Decision stump]]
* Conditional decision tree
* [[ID3 algorithm]]
* [[Random forest]]
* SLIQ

==== Linear classifier ====

[[Linear classifier]]
* [[Fisher's linear discriminant]]
* [[Linear regression]]
* [[Logistic regression]]
* [[Multinomial logistic regression]]
* [[Naive Bayes classifier]]
* [[Perceptron]]
* [[Support vector machine]]

=== Unsupervised learning ===

[[Unsupervised learning]]
* [[Expectation-maximization algorithm]]
* [[Vector Quantization]]
* [[Generative topographic map]]
* [[Information bottleneck method]]

==== Artificial neural networks ====

[[Artificial neural network]]
* [[Feedforward neural network]]
** [[Extreme learning machine]]
** [[Convolutional neural network]]
* [[Recurrent neural network]]
** [[Long short-term memory|Long short-term memory (LSTM)]]
* [[Logic learning machine]]
* [[Self-organizing map]]

==== Association rule learning ====

[[Association rule learning]]
* [[Apriori algorithm]]
* [[Eclat algorithm]]
* [[Association rule learning#FP-growth algorithm|FP-growth algorithm]]

==== Hierarchical clustering ====

[[Hierarchical clustering]]
* [[Single-linkage clustering]]
* [[Conceptual clustering]]

==== Cluster analysis ====

[[Cluster analysis]]
* [[BIRCH]]
* [[DBSCAN]]
* [[Expectation-maximization algorithm|Expectation-maximization (EM)]]
* [[Fuzzy clustering]]
* [[Hierarchical Clustering]]
* [[K-means clustering]]
* [[K-medians]]
* [[Mean-shift]]
* [[OPTICS algorithm]]

==== Anomaly detection ====

[[Anomaly detection]]
* [[k-nearest neighbors classification]] (''k''-NN)
* [[Local outlier factor]]

=== Semi-supervised learning ===

[[Semi-supervised learning]]
* [[Active learning (machine learning)|Active learning]] &amp;ndash; special case of semi-supervised learning in which a learning algorithm is able to interactively query the user (or some other information source) to obtain the desired outputs at new data points.&lt;ref name="settles"&gt;{{Citation
 | title = Active Learning Literature Survey
 | url = http://pages.cs.wisc.edu/~bsettles/pub/settles.activelearning.pdf
 | author = Settles, Burr
 | journal = Computer Sciences Technical Report 1648. University of Wisconsin–Madison
 | year = 2010
 | access-date = 2014-11-18
}}&lt;/ref&gt;&lt;ref name="rubens2016"&gt;{{cite book
|last1=Rubens |first1=Neil
|last2= [https://www.linkedin.com/in/mehdielahi Elahi]|first2=Mehdi
 |last3=Sugiyama|first3=Masashi|last4=Kaplan|first4=Dain|editor1-last=Ricci
 |editor1-first=Francesco
 |editor2-last=Rokach|editor2-first=Lior
 |editor3-last=Shapira |editor3-first=Bracha
 |title=Recommender Systems Handbook
 |date=2016
 |publisher=Springer US
 |isbn=978-1-4899-7637-6
 |edition=2
 |chapter=Active Learning in Recommender Systems
 |doi=10.1007/978-1-4899-7637-6
|hdl=11311/1006123
|s2cid=11569603
}}&lt;/ref&gt;
* [[Semi-supervised learning#Generative models|Generative models]]
* [[Semi-supervised learning#Low-density separation|Low-density separation]]
* [[Semi-supervised learning#Graph-based methods|Graph-based methods]]
* [[Co-training]]
* [[Transduction (machine learning)|Transduction]]

=== Deep learning ===

[[Deep learning]]
* [[Deep belief network]]s
* Deep [[Boltzmann machine]]s
* Deep [[Convolutional neural network]]s
* Deep [[Recurrent neural network]]s
* [[Hierarchical temporal memory]]
* [[Generative adversarial network|Generative Adversarial Networks]]
* [[Deep Boltzmann Machine]] (DBM)
* [[Stacked Auto-Encoders]]

=== Other machine learning methods and problems ===

* [[Anomaly detection]]
* [[Association rule learning|Association rules]]
* [[Bias-variance dilemma]]
* [[Statistical classification|Classification]]
** [[Multi-label classification]]
* [[Cluster analysis|Clustering]]
* [[Data Pre-processing]]
* [[Empirical risk minimization]]
* [[Feature engineering]]
* [[Feature learning]]
* [[Learning to rank]]
* [[Occam learning]]
* [[Online machine learning]]
* [[PAC learning]]
* [[Regression analysis|Regression]]
* [[Reinforcement Learning]]
* [[Semi-supervised learning]]
* [[Statistical learning]]
* [[Structured prediction]]
** [[Graphical model]]s
*** [[Bayesian network]]
*** [[Conditional random field]] (CRF)
*** [[Hidden Markov model]] (HMM)
* [[Unsupervised learning]]
* [[VC theory]]

== Machine learning research ==
* [[List of artificial intelligence projects]]
* [[List of datasets for machine learning research]]

== History of machine learning ==

[[History of machine learning]]
* [[Timeline of machine learning]]

== Machine learning projects ==

Machine learning projects
* [[DeepMind]]
* [[Google Brain]]

== Machine learning organizations ==

Machine learning organizations
* [[Knowledge Engineering and Machine Learning Group]]

=== Machine learning conferences and workshops ===

* Artificial Intelligence and Security (AISec) (co-located workshop with CCS)
* [[Conference on Neural Information Processing Systems]] (NIPS)
* [[ECML PKDD]]
* [[International Conference on Machine Learning]] (ICML)
* [http://ml4all.org ML4ALL] (Machine Learning For All)

== Machine learning publications ==

=== Books on machine learning ===
{{expand section|content|date=November 2018}}
Books about machine learning

=== Machine learning journals ===

* ''[[Machine Learning (journal)|Machine Learning]]''
* ''[[Journal of Machine Learning Research]]'' (JMLR)
* ''[[Neural Computation (journal)|Neural Computation]]''

== Persons influential in machine learning ==

* [[Alberto Broggi]]
* [[Andrei Knyazev (mathematician)|Andrei Knyazev]]
* [[Andrew McCallum]]
* [[Andrew Ng]]
* [[Anuraag Jain]]
* [[Armin B. Cremers]]
* [[Ayanna Howard]]
* [[Barney Pell]]
* [[Ben Goertzel]]
* [[Ben Taskar]]
* [[Bernhard Schölkopf]]
* [[Brian D. Ripley]]
* [[Christopher G. Atkeson]]
* [[Corinna Cortes]]
* [[Demis Hassabis]]
* [[Douglas Lenat]]
* [[Eric Xing]]
* [[Ernst Dickmanns]]
* [[Geoffrey Hinton]] &amp;ndash; co-inventor of the backpropagation and contrastive divergence training algorithms
* [[Hans-Peter Kriegel]]
* [[Hartmut Neven]]
* [[Heikki Mannila]]
* [[Ian Goodfellow]] &amp;ndash; Father of Generative &amp; adversarial networks
* [[Jacek M. Zurada]]
* [[Jaime Carbonell]]
* [[Jeremy Slovak]]
* [[Jerome H. Friedman]]
* [[John D. Lafferty]]
* [[John Platt (computer scientist)|John Platt]] &amp;ndash; invented SMO and Platt scaling
* [[Julie Beth Lovins]]
* [[Jürgen Schmidhuber]]
* [[Karl Steinbuch]]
* [[Katia Sycara]]
* [[Leo Breiman]] &amp;ndash; invented bagging and random forests
* [[Lise Getoor]]
* [[Luca Maria Gambardella]]
* [[Léon Bottou]]
* [[Marcus Hutter]]
* [[Mehryar Mohri]]
* [[Michael Collins (computational linguist)|Michael Collins]]
* [[Michael I. Jordan]]
* [[Michael L. Littman]]
* [[Nando de Freitas]]
* [[Ofer Dekel (researcher)|Ofer Dekel]]
* [[Oren Etzioni]]
* [[Pedro Domingos]]
* [[Peter Flach]]
* [[Pierre Baldi]]
* [[Pushmeet Kohli]]
* [[Ray Kurzweil]]
* [[Rayid Ghani]]
* [[Ross Quinlan]]
* [[Salvatore J. Stolfo]]
* [[Sebastian Thrun]]
* [[Selmer Bringsjord]]
* [[Sepp Hochreiter]]
* [[Shane Legg]]
* [[Stephen Muggleton]]
* [[Steve Omohundro]]
* [[Tom M. Mitchell]]
* [[Trevor Hastie]]
* [[Vasant Honavar]]
* [[Vladimir Vapnik]] &amp;ndash; co-inventor of the SVM and VC theory
* [[Yann LeCun]] &amp;ndash; invented convolutional neural networks
* [[Yasuo Matsuyama]]
* [[Yoshua Bengio]]
* [[Zoubin Ghahramani]]

== See also ==

* [[Outline of artificial intelligence]]
** [[Outline of computer vision]]
* [[Outline of robotics]]
&lt;!-- Place these in the body of the outline above --&gt;
* [[Accuracy paradox]]
* [[Action model learning]]
* [[Activation function]]
* [[Activity recognition]]
* [[ADALINE]]
* [[Adaptive neuro fuzzy inference system]]
* [[Adaptive resonance theory]]
* [[Additive smoothing]]
* [[Adjusted mutual information]]
* [[AIVA]]
* [[AIXI]]
* [[AlchemyAPI]]
* [[AlexNet]]
* [[Algorithm selection]]
* [[Algorithmic inference]]
* [[Algorithmic learning theory]]
* [[AlphaGo]]
* [[AlphaGo Zero]]
* [[Alternating decision tree]]
* [[Apprenticeship learning]]
* [[Causal Markov condition]] &lt;!--this is an ML concept; subtopic of Markov blanket--&gt;
* [[Competitive learning]]
* [[Concept learning]]
* [[Decision tree learning]]
* [[Distribution learning theory]]
* [[Eager learning]]
* [[End-to-end reinforcement learning]]
* [[Error tolerance (PAC learning)]]
* [[Explanation-based learning]]
* [[Feature (machine learning)|Feature]]
* [[GloVe (machine learning)|GloVe]]
* [[Hyperparameter (machine learning)|Hyperparameter]]
* [[IBM Machine Learning Hub]]
* [[Inferential theory of learning]]
* [[Learning automata]]
* [[Learning classifier system]]
* [[Learning rule]]
* [[Learning with errors]]
* [[M-Theory (learning framework)]]
* [[Machine learning control]]
* [[Machine learning in bioinformatics]]
* [[Margin (machine learning)|Margin]]
* [[Markov chain geostatistics]] &lt;!--stub article; this topic is probably an application of ML--&gt;
* [[Markov chain Monte Carlo]] (MCMC) &lt;!--this is an ML topic; applications to Markov logic networks, among others--&gt;
* [[Markov information source]] &lt;!--topic with direct applications to ML in NLP--&gt;
* [[Markov logic network]] &lt;!--Topic with applications to ML through MCMC models (https://homes.cs.washington.edu/~pedrod/papers/mlj05.pdf) --&gt;
* [[Markov model]]&lt;!--this is an ML topic--&gt;
* [[Markov random field]]&lt;!--this seems to be an ML topic--&gt;
* [[Markovian discrimination]] &lt;!--seems to be an ML-related with applications to NLP; the article lacks context, so it's difficult to tell--&gt;
* [[Maximum-entropy Markov model]] &lt;!--this is definitely an ML topic--&gt;
* [[Multi-armed bandit]] &lt;!--Definitely an ML concept--&gt;
* [[Multi-task learning]]
* [[Multilinear subspace learning]]
* [[Multimodal learning]]
* [[Multiple instance learning]]
* [[Multiple-instance learning]]
* [[Never-Ending Language Learning]]
* [[Offline learning]]
* [[Parity learning]]
* [[Population-based incremental learning]]
* [[Predictive learning]]
* [[Preference learning]]
* [[Proactive learning]]
* [[Proximal gradient methods for learning]]
* [[Semantic analysis (machine learning)|Semantic analysis]]
* [[Similarity learning]]
* [[Sparse dictionary learning]]
* [[Stability (learning theory)]]
* [[Statistical learning theory]]
* [[Statistical relational learning]]
* [[Tanagra (machine learning)|Tanagra]]
* [[Transfer learning]]
* [[Variable-order Markov model]] &lt;!--a Markov model with applications to ML--&gt;
* [[Version space learning]]
* [[Waffles (machine learning)|Waffles]]
* [[Weka (machine learning)|Weka]]
* [[Loss function]]
** [[Loss functions for classification]]
** [[Mean squared error]] (MSE)
** [[Mean squared prediction error]] (MSPE)
** [[Taguchi loss function]]
* [[Low-energy adaptive clustering hierarchy]]

=== Other ===

&lt;!-- Filter out those that are not subtopics of machine learning. There's a section on the talk page for links you are not sure about. --&gt;

* [[Anne O'Tate]]
* [[Ant colony optimization algorithms]]
* [[Anthony Levandowski]]
* [[Anti-unification (computer science)]]
* [[Apache Flume]]
* [[Apache Giraph]]
* [[Apache Mahout]]
* [[Apache SINGA]]
* [[Apache Spark]]
* [[Apache SystemML]]
* [[Aphelion (software)]]
* [[Arabic Speech Corpus]]
* [[Archetypal analysis]]
* [[Arthur Zimek]]
* [[Artificial ants]]
* [[Artificial bee colony algorithm]]
* [[Artificial development]]
* [[Artificial immune system]]
* [[Astrostatistics]]
* [[Averaged one-dependence estimators]]
* [[Bag-of-words model]]
* [[Balanced clustering]]
* [[Ball tree]]
* [[Base rate]]
* [[Bat algorithm]]
* [[Baum–Welch algorithm]]
* [[Bayesian hierarchical modeling]]
* [[Bayesian interpretation of kernel regularization]]
* [[Bayesian optimization]]
* [[Bayesian structural time series]]
* [[Bees algorithm]]
* [[Behavioral clustering]]
* [[Bernoulli scheme]]
* [[Bias–variance tradeoff]]
* [[Biclustering]]
* [[BigML]]
* [[Binary classification]]
* [[Bing Predicts]]
* [[Bio-inspired computing]]
* [[Biogeography-based optimization]]
* [[Biplot]]
* [[Bondy's theorem]]
* [[Bongard problem]]
* [[Bradley–Terry model]]
* [[BrownBoost]]
* [[Brown clustering]]
* [[Burst error]]
* [[CBCL (MIT)]]
* [[CIML community portal]]
* [[CMA-ES]]
* [[CURE data clustering algorithm]]
* [[Cache language model]]
* [[Calibration (statistics)]]
* [[Canonical correspondence analysis]]
* [[Canopy clustering algorithm]]
* [[Cascading classifiers]]
* [[Category utility]]
* [[CellCognition]]
* [[Cellular evolutionary algorithm]]
* [[Chi-square automatic interaction detection]]
* [[Chromosome (genetic algorithm)]]
* [[Classifier chains]]
* [[Cleverbot]]
* [[Clonal selection algorithm]]
* [[Cluster-weighted modeling]]
* [[Clustering high-dimensional data]]
* [[Clustering illusion]]
* [[CoBoosting]]
* [[Cobweb (clustering)]]
* [[Cognitive computer]]
* [[Cognitive robotics]]
* [[Collostructional analysis]]
* [[Common-method variance]]
* [[Complete-linkage clustering]]
* [[Computer-automated design]]
* [[Concept class]]
* [[Concept drift]]
* [[Conference on Artificial General Intelligence]]
* [[Conference on Knowledge Discovery and Data Mining]]
* [[Confirmatory factor analysis]]
* [[Confusion matrix]]
* [[Congruence coefficient]]
* [[Connect (computer system)]]
* [[Consensus clustering]]
* [[Constrained clustering]]
* [[Constrained conditional model]]
* [[Constructive cooperative coevolution]]
* [[Correlation clustering]]
* [[Correspondence analysis]]
* [[Cortica]]
* [[Coupled pattern learner]]
* [[Cross-entropy method]]
* [[Cross-validation (statistics)]]
* [[Crossover (genetic algorithm)]]
* [[Cuckoo search]]
* [[Cultural algorithm]]
* [[Cultural consensus theory]]
* [[Curse of dimensionality]]
* [[DADiSP]]
* [[DARPA LAGR Program]]
* [[Darkforest]]
* [[Dartmouth workshop]]
* [[DarwinTunes]]
* [[Data Mining Extensions]]
* [[Data exploration]]
* [[Data pre-processing]]
* [[Data stream clustering]]
* [[Dataiku]]
* [[Davies–Bouldin index]]
* [[Decision boundary]]
* [[Decision list]]
* [[Decision tree model]]
* [[Deductive classifier]]
* [[DeepArt]]
* [[DeepDream]]
* [[Deep Web Technologies]]
* [[Defining length]]
* [[Dendrogram]]
* [[Dependability state model]]
* [[Detailed balance]]
* [[Determining the number of clusters in a data set]]
* [[Detrended correspondence analysis]]
* [[Developmental robotics]]
* [[Diffbot]]
* [[Differential evolution]]
* [[Discrete phase-type distribution]]
* [[Discriminative model]]
* [[Dissociated press]]
* [[Distributed R]]
* [[Dlib]]
* [[Document classification]]
* [[Documenting Hate]]
* [[Domain adaptation]]
* [[Doubly stochastic model]]
* [[Dual-phase evolution]]
* [[Dunn index]]
* [[Dynamic Bayesian network]]
* [[Dynamic Markov compression]]
* [[Dynamic topic model]]
* [[Dynamic unobserved effects model]]
* [[EDLUT]]
* [[ELKI]]
* [[Edge recombination operator]]
* [[Effective fitness]]
* [[Elastic map]]
* [[Elastic matching]]
* [[Elbow method (clustering)]]
* [[Emergent (software)]]
* [[Encog]]
* [[Entropy rate]]
* [[Erkki Oja]]
* [[Eurisko]]
* [[European Conference on Artificial Intelligence]]
* [[Evaluation of binary classifiers]]
* [[Evolution strategy]]
* [[Evolution window]]
* [[Evolutionary Algorithm for Landmark Detection]]
* [[Evolutionary algorithm]]
* [[Evolutionary art]]
* [[Evolutionary music]]
* [[Evolutionary programming]]
* [[Evolvability (computer science)]]
* [[Evolved antenna]]
* [[Evolver (software)]]
* [[Evolving classification function]]
* [[Expectation propagation]]
* [[Exploratory factor analysis]]
* [[F1 score]]
* [[FLAME clustering]]
* [[Factor analysis of mixed data]]
* [[Factor graph]]
* [[Factor regression model]]
* [[Factored language model]]
* [[Farthest-first traversal]]
* [[Fast-and-frugal trees]]
* [[Feature Selection Toolbox]]
* [[Feature hashing]]
* [[Feature scaling]]
* [[Feature vector]]
* [[Firefly algorithm]]
* [[First-difference estimator]]
* [[First-order inductive learner]]
* [[Fish School Search]]
* [[Fisher kernel]]
* [[Fitness approximation]]
* [[Fitness function]]
* [[Fitness proportionate selection]]
* [[Fluentd]]
* [[Folding@home]]
* [[Formal concept analysis]]
* [[Forward algorithm]]
* [[Fowlkes–Mallows index]]
* [[Frederick Jelinek]]
* [[Frrole]]
* [[Functional principal component analysis]]
* [[GATTO]]
* [[GLIMMER]]
* [[Gary Bryce Fogel]]
* [[Gaussian adaptation]]
* [[Gaussian process]]
* [[Gaussian process emulator]]
* [[Gene prediction]]
* [[General Architecture for Text Engineering]]
* [[Generalization error]]
* [[Generalized canonical correlation]]
* [[Generalized filtering]]
* [[Generalized iterative scaling]]
* [[Generalized multidimensional scaling]]
* [[Generative adversarial network]]
* [[Generative model]]
* [[Genetic algorithm]]
* [[Genetic algorithm scheduling]]
* [[Genetic algorithms in economics]]
* [[Genetic fuzzy systems]]
* [[Genetic memory (computer science)]]
* [[Genetic operator]]
* [[Genetic programming]]
* [[Genetic representation]]
* [[Geographical cluster]]
* [[Gesture Description Language]]
* [[Geworkbench]]
* [[Glossary of artificial intelligence]]
* [[Glottochronology]]
* [[Golem (ILP)]]
* [[Google matrix]]
* [[Grafting (decision trees)]]
* [[Gramian matrix]]
* [[Grammatical evolution]]
* [[Granular computing]]
* [[GraphLab]]
* [[Graph kernel]]
* [[Gremlin (programming language)]]
* [[Growth function]]
* [[HUMANT (HUManoid ANT) algorithm]]
* [[Hammersley–Clifford theorem]]
* [[Harmony search]]
* [[Hebbian theory]]
* [[Hidden Markov random field]]
* [[Hidden semi-Markov model]]
* [[Hierarchical hidden Markov model]]
* [[Higher-order factor analysis]]
* [[Highway network]]
* [[Hinge loss]]
* [[Holland's schema theorem]]
* [[Hopkins statistic]]
* [[Hoshen–Kopelman algorithm]]
* [[Huber loss]]
* [[IRCF360]]
* [[Ian Goodfellow]]
* [[Ilastik]]
* [[Ilya Sutskever]]
* [[Immunocomputing]]
* [[Imperialist competitive algorithm]]
* [[Inauthentic text]]
* [[Incremental decision tree]]
* [[Induction of regular languages]]
* [[Inductive bias]]
* [[Inductive probability]]
* [[Inductive programming]]
* [[Influence diagram]]
* [[Information Harvesting]]
* [[Information fuzzy networks]]
* [[Information gain in decision trees]]
* [[Information gain ratio]]
* [[Inheritance (genetic algorithm)]]
* [[Instance selection]]
* [[Intel RealSense]]
* [[Interacting particle system]]
* [[Interactive machine translation]]
* [[International Joint Conference on Artificial Intelligence]]
* [[International Meeting on Computational Intelligence Methods for Bioinformatics and Biostatistics]]
* [[International Semantic Web Conference]]
* [[Iris flower data set]]
* [[Island algorithm]]
* [[Isotropic position]]
* [[Item response theory]]
* [[Iterative Viterbi decoding]]
* [[JOONE]]
* [[Jabberwacky]]
* [[Jaccard index]]
* [[Jackknife variance estimates for random forest]]
* [[Java Grammatical Evolution]]
* [[Joseph Nechvatal]]
* [[Jubatus]]
* [[Julia (programming language)]]
* [[Junction tree algorithm]]
* [[K-SVD]]
* [[K-means++]]
* [[K-medians clustering]]
* [[K-medoids]]
* [[KNIME]]
* [[KXEN Inc.]]
* [[K q-flats]]
* [[Kaggle]]
* [[Kalman filter]]
* [[Katz's back-off model]]
* [[Kernel adaptive filter]]
* [[Kernel density estimation]]
* [[Kernel eigenvoice]]
* [[Kernel embedding of distributions]]
* [[Kernel method]]
* [[Kernel perceptron]]
* [[Kernel random forest]]
* [[Kinect]]
* [[Klaus-Robert Müller]]
* [[Kneser–Ney smoothing]]
* [[Knowledge Vault]]
* [[Knowledge integration]]
* [[LIBSVM]]
* [[LPBoost]]
* [[Labeled data]]
* [[LanguageWare]]
* [[Language Acquisition Device (computer)]]
* [[Language identification in the limit]]
* [[Language model]]
* [[Large margin nearest neighbor]]
* [[Latent Dirichlet allocation]]
* [[Latent class model]]
* [[Latent semantic analysis]]
* [[Latent variable]]
* [[Latent variable model]]
* [[Lattice Miner]]
* [[Layered hidden Markov model]]
* [[Learnable function class]]
* [[Least squares support vector machine]]
* [[Leave-one-out error]]
* [[Leslie P. Kaelbling]]
* [[Linear genetic programming]]
* [[Linear predictor function]]
* [[Linear separability]]
* [[Lingyun Gu]]
* [[Linkurious]]
* [[Lior Ron (business executive)]]
* [[List of genetic algorithm applications]]
* [[List of metaphor-based metaheuristics]]
* [[List of text mining software]]
* [[Local case-control sampling]]
* [[Local independence]]
* [[Local tangent space alignment]]
* [[Locality-sensitive hashing]]
* [[Log-linear model]]
* [[Logistic model tree]]
* [[Low-rank approximation]]
* [[Low-rank matrix approximations]]
* [[MATLAB]]
* [[MIMIC (immunology)]]
* [[MXNet]]
* [[Mallet (software project)]]
* [[Manifold regularization]]
* [[Margin-infused relaxed algorithm]]
* [[Margin classifier]]
* [[Mark V. Shaney]]
* [[Massive Online Analysis]]
* [[Matrix regularization]]
* [[Matthews correlation coefficient]]
* [[Mean shift]]
* [[Mean squared error]]
* [[Mean squared prediction error]]
* [[Measurement invariance]]
* [[Medoid]]
* [[MeeMix]]
* [[Melomics]]
* [[Memetic algorithm]]
* [[Meta-optimization]]
* [[Mexican International Conference on Artificial Intelligence]]
* [[Michael Kearns (computer scientist)]]
* [[MinHash]]
* [[Mixture model]]
* [[Mlpy]]
* [[Models of DNA evolution]]
* [[Moral graph]]
* [[Mountain car problem]]
* [[Movidius]]
* [[Multi-armed bandit]]
* [[Multi-label classification]]
* [[Multi expression programming]]
* [[Multiclass classification]]
* [[Multidimensional analysis]]
* [[Multifactor dimensionality reduction]]
* [[Multilinear principal component analysis]]
* [[Multiple correspondence analysis]]
* [[Multiple discriminant analysis]]
* [[Multiple factor analysis]]
* [[Multiple sequence alignment]]
* [[Multiplicative weight update method]]
* [[Multispectral pattern recognition]]
* [[Mutation (genetic algorithm)]]
* [[MysteryVibe]]
* [[N-gram]]
* [[NOMINATE (scaling method)]]
* [[Native-language identification]]
* [[Natural Language Toolkit]]
* [[Natural evolution strategy]]
* [[Nearest-neighbor chain algorithm]]
* [[Nearest centroid classifier]]
* [[Nearest neighbor search]]
* [[Neighbor joining]]
* [[Nest Labs]]
* [[NetMiner]]
* [[NetOwl]]
* [[Neural Designer]]
* [[Neural Engineering Object]]
* [[Neural Lab]]
* [[Neural modeling fields]]
* [[Neural network software]]
* [[NeuroSolutions]]
* [[Neuro Laboratory]]
* [[Neuroevolution]]
* [[Neuroph]]
* [[Niki.ai]]
* [[Noisy channel model]]
* [[Noisy text analytics]]
* [[Nonlinear dimensionality reduction]]
* [[Novelty detection]]
* [[Nuisance variable]]
* [[Numenta]]
* [[One-class classification]]
* [[Onnx]]
* [[OpenNLP]]
* [[Optimal discriminant analysis]]
* [[Oracle Data Mining]]
* [[Orange (software)]]
* [[Ordination (statistics)]]
* [[Overfitting]]
* [[PROGOL]]
* [[PSIPRED]]
* [[Pachinko allocation]]
* [[PageRank]]
* [[Parallel metaheuristic]]
* [[Parity benchmark]]
* [[Part-of-speech tagging]]
* [[Particle swarm optimization]]
* [[Path dependence]]
* [[Pattern language (formal languages)]]
* [[Peltarion Synapse]]
* [[Perplexity]]
* [[Persian Speech Corpus]]
* [[Picas (app)]]
* [[Pietro Perona]]
* [[Pipeline Pilot]]
* [[Piranha (software)]]
* [[Pitman–Yor process]]
* [[Plate notation]]
* [[Polynomial kernel]]
* [[Pop music automation]]
* [[Population process]]
* [[Portable Format for Analytics]]
* [[Predictive Model Markup Language]]
* [[Predictive state representation]]
* [[Preference regression]]
* [[Premature convergence]]
* [[Principal geodesic analysis]]
* [[Prior knowledge for pattern recognition]]
* [[Prisma (app)]]
* [[Probabilistic Action Cores]]
* [[Probabilistic context-free grammar]]
* [[Probabilistic latent semantic analysis]]
* [[Probabilistic soft logic]]
* [[Probability matching]]
* [[Probit model]]
* [[Product of experts]]
* [[Programming with Big Data in R]]
* [[Proper generalized decomposition]]
* [[Pruning (decision trees)]]
* [[Pushpak Bhattacharyya]]
* [[Q methodology]]
* [[Qloo]]
* [[Quality control and genetic algorithms]]
* [[Quantum Artificial Intelligence Lab]]
* [[Queueing theory]]
* [[Quick, Draw!]]
* [[R (programming language)]]
* [[Rada Mihalcea]]
* [[Rademacher complexity]]
* [[Radial basis function kernel]]
* [[Rand index]]
* [[Random indexing]]
* [[Random projection]]
* [[Random subspace method]]
* [[Ranking SVM]]
* [[RapidMiner]]
* [[Rattle GUI]]
* [[Raymond Cattell]]
* [[Reasoning system]]
* [[Regularization perspectives on support vector machines]]
* [[Relational data mining]]
* [[Relationship square]]
* [[Relevance vector machine]]
* [[Relief (feature selection)]]
* [[Renjin]]
* [[Repertory grid]]
* [[Representer theorem]]
* [[Reward-based selection]]
* [[Richard Zemel]]
* [[Right to explanation]]
* [[RoboEarth]]
* [[Robust principal component analysis]]
* [[RuleML Symposium]]
* [[Rule induction]]
* [[Rules extraction system family]]
* [[SAS (software)]]
* [[SNNS]]
* [[SPSS Modeler]]
* [[SUBCLU]]
* [[Sample complexity]]
* [[Sample exclusion dimension]]
* [[Santa Fe Trail problem]]
* [[Savi Technology]]
* [[Schema (genetic algorithms)]]
* [[Search-based software engineering]]
* [[Selection (genetic algorithm)]]
* [[Self-Service Semantic Suite]]
* [[Semantic folding]]
* [[Semantic mapping (statistics)]]
* [[Semidefinite embedding]]
* [[Sense Networks]]
* [[Sensorium Project]]
* [[Sequence labeling]]
* [[Sequential minimal optimization]]
* [[Shattered set]]
* [[Shogun (toolbox)]]
* [[Silhouette (clustering)]]
* [[SimHash]]
* [[SimRank]]
* [[Similarity measure]]
* [[Simple matching coefficient]]
* [[Simultaneous localization and mapping]]
* [[Sinkov statistic]]
* [[Sliced inverse regression]]
* [[Snakes and Ladders]]
* [[Soft independent modelling of class analogies]]
* [[Soft output Viterbi algorithm]]
* [[Solomonoff's theory of inductive inference]]
* [[SolveIT Software]]
* [[Spectral clustering]]
* [[Spike-and-slab variable selection]]
* [[Statistical machine translation]]
* [[Statistical parsing]]
* [[Statistical semantics]]
* [[Stefano Soatto]]
* [[Stephen Wolfram]]
* [[Stochastic block model]]
* [[Stochastic cellular automaton]]
* [[Stochastic diffusion search]]
* [[Stochastic grammar]]
* [[Stochastic matrix]]
* [[Stochastic universal sampling]]
* [[Stress majorization]]
* [[String kernel]]
* [[Structural equation modeling]]
* [[Structural risk minimization]]
* [[Structured sparsity regularization]]
* [[Structured support vector machine]]
* [[Subclass reachability]]
* [[Sufficient dimension reduction]]
* [[Sukhotin's algorithm]]
* [[Sum of absolute differences]]
* [[Sum of absolute transformed differences]]
* [[Swarm intelligence]]
* [[Switching Kalman filter]]
* [[Symbolic regression]]
* [[Synchronous context-free grammar]]
* [[Syntactic pattern recognition]]
* [[TD-Gammon]]
* [[TIMIT]]
* [[Teaching dimension]]
* [[Teuvo Kohonen]]
* [[Textual case-based reasoning]]
* [[Theory of conjoint measurement]]
* [[Thomas G. Dietterich]]
* [[Thurstonian model]]
* [[Topic model]]
* [[Tournament selection]]
* [[Training, test, and validation sets]]
* [[Transiogram]]
* [[Trax Image Recognition]]
* [[Trigram tagger]]
* [[Truncation selection]]
* [[Tucker decomposition]]
* [[UIMA]]
* [[UPGMA]]
* [[Ugly duckling theorem]]
* [[Uncertain data]]
* [[Uniform convergence in probability]]
* [[Unique negative dimension]]
* [[Universal portfolio algorithm]]
* [[User behavior analytics]]
* [[VC dimension]]
* [[VIGRA]]
* [[Validation set]]
* [[Vapnik–Chervonenkis theory]]
* [[Variable-order Bayesian network]]
* [[Variable kernel density estimation]]
* [[Variable rules analysis]]
* [[Variational message passing]]
* [[Varimax rotation]]
* [[Vector quantization]]
* [[Vicarious (company)]]
* [[Viterbi algorithm]]
* [[Vowpal Wabbit]]
* [[WACA clustering algorithm]]
* [[WPGMA]]
* [[Ward's method]]
* [[Weasel program]]
* [[Whitening transformation]]
* [[Winnow (algorithm)]]
* [[Win–stay, lose–switch]]
* [[Witness set]]
* [[Wolfram Language]]
* [[Wolfram Mathematica]]
* [[Writer invariant]]
* [[Xgboost]]
* [[Yooreeka]]
* [[Zeroth (software)]]

== Further reading ==

* [[Trevor Hastie]], [[Robert Tibshirani]] and [[Jerome H. Friedman]] (2001). ''[https://web.archive.org/web/20091110212529/http://www-stat.stanford.edu/~tibs/ElemStatLearn/ The Elements of Statistical Learning]'', Springer. {{ISBN|0-387-95284-5}}.
* [[Pedro Domingos]] (September 2015), [[The Master Algorithm]], Basic Books, {{ISBN|978-0-465-06570-7}}
* [[Mehryar Mohri]], Afshin Rostamizadeh, Ameet Talwalkar (2012). ''[http://www.cs.nyu.edu/~mohri/mlbook/ Foundations of Machine Learning]'', The MIT Press. {{ISBN|978-0-262-01825-8}}.
* Ian H. Witten and Eibe Frank (2011). ''Data Mining: Practical machine learning tools and techniques'' Morgan Kaufmann, 664pp., {{ISBN|978-0-12-374856-0}}.
* [[David J. C. MacKay]]. ''[http://www.inference.phy.cam.ac.uk/mackay/itila/book.html Information Theory, Inference, and Learning Algorithms]'' Cambridge: Cambridge University Press, 2003. {{ISBN|0-521-64298-1}}
* [[Richard O. Duda]], [[Peter E. Hart]], David G. Stork (2001) ''Pattern classification'' (2nd edition), Wiley, New York, {{ISBN|0-471-05669-3}}.
* [[Christopher Bishop]] (1995). ''Neural Networks for Pattern Recognition'', Oxford University Press. {{ISBN|0-19-853864-2}}.
* [[Vladimir Vapnik]] (1998). ''Statistical Learning Theory''. Wiley-Interscience, {{ISBN|0-471-03003-1}}.
* [[Ray Solomonoff]], ''An Inductive Inference Machine'', IRE Convention Record, Section on Information Theory, Part 2, pp., 56–62, 1957.
* [[Ray Solomonoff]], "[http://world.std.com/~rjs/indinf56.pdf An Inductive Inference Machine]" A privately circulated report from the 1956 [[Dartmouth Conferences|Dartmouth Summer Research Conference on AI]].

== References ==
{{Reflist}}

== External links ==
{{Sister project links|Machine learning}}

* [https://web.archive.org/web/20170118041300/https://mitprofessionalx.mit.edu/courses/course-v1:MITProfessionalX+DSx+2016_T1/about Data Science: Data to Insights from MIT (machine learning)]
* Popular online course by [[Andrew Ng]], at [https://www.coursera.org/course/ml Coursera]. It uses [[GNU Octave]]. The course is a free version of [[Stanford University]]'s actual course taught by Ng, see.stanford.edu/Course/CS229 available for free].
* [https://mloss.org/ mloss] is an academic database of open-source machine learning software.

{{Outline footer}}

[[Category:Outlines of applied sciences|Machine learning]]
[[Category:Wikipedia outlines|Machine learning]]
[[Category:Computing-related lists]]
[[Category:Machine learning|*]]
[[Category:Artificial intelligence|Machine learning]]
[[Category:Data mining|Machine learning]]</text>
      <sha1>1rwcb2z4qgecsse2ofl3i3iqnmmhr0u</sha1>
    </revision>
  </page>
  <page>
    <title>Hyperparameter optimization</title>
    <ns>0</ns>
    <id>54361643</id>
    <revision>
      <id>1002995616</id>
      <parentid>1002045800</parentid>
      <timestamp>2021-01-27T00:21:12Z</timestamp>
      <contributor>
        <username>Jka02</username>
        <id>3021789</id>
      </contributor>
      <minor/>
      <comment>/* Random search */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="30248" xml:space="preserve">In [[machine learning]], '''hyperparameter optimization''' or tuning is the problem of choosing a set of optimal [[Hyperparameter (machine learning)|hyperparameters]] for a learning algorithm. A hyperparameter is a [[parameter]] whose value is used to control the learning process. By contrast, the values of other parameters (typically node weights) are learned.

The same kind of machine learning model can require different constraints, weights or learning rates to generalize different data patterns. These measures are called hyperparameters, and have to be tuned so that the model can optimally solve the machine learning problem. Hyperparameter optimization finds a tuple of hyperparameters that yields an optimal model which minimizes a predefined [[loss function]] on given independent data.&lt;ref name=abs1502.02127&gt;{{cite arxiv |eprint=1502.02127|last1=Claesen|first1=Marc|title=Hyperparameter Search in Machine Learning|author2=Bart De Moor|class=cs.LG|year=2015}}&lt;/ref&gt;  The objective function takes a tuple of hyperparameters and returns the associated loss.&lt;ref name=abs1502.02127/&gt; [[Cross-validation (statistics)|Cross-validation]] is often used to estimate this generalization performance.&lt;ref name="bergstra"&gt;{{cite journal|last1=Bergstra|first1=James|last2=Bengio|first2=Yoshua|year=2012|title=Random Search for Hyper-Parameter Optimization|url=http://jmlr.csail.mit.edu/papers/volume13/bergstra12a/bergstra12a.pdf|journal=Journal of Machine Learning Research|volume=13|pages=281–305}}&lt;/ref&gt;

== Approaches ==

[[File:Hyperparameter Optimization using Grid Search.svg|thumb|Grid search across different values of two hyperparameters. For each hyperparameter, 10 different values are considered, so a total of 100 different combinations are evaluated and compared. Blue contours indicate regions with strong results, whereas red ones show regions with poor results.]]

=== Grid search ===
The traditional way of performing hyperparameter optimization has been ''grid search'', or a ''parameter sweep'', which is simply an [[Brute-force search|exhaustive searching]] through a manually specified subset of the hyperparameter space of a learning algorithm. A grid search algorithm must be guided by some performance metric, typically measured by [[Cross-validation (statistics)|cross-validation]] on the training set&lt;ref&gt;Chin-Wei Hsu, Chih-Chung Chang and Chih-Jen Lin (2010). [http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf A practical guide to support vector classification]. Technical Report, [[National Taiwan University]].&lt;/ref&gt;
or evaluation on a held-out validation set.&lt;ref&gt;{{cite journal 
| vauthors = Chicco D
| title = Ten quick tips for machine learning in computational biology 
| journal = BioData Mining
| volume = 10
| issue =  35
| pages = 35 
| date = December 2017 
| pmid = 29234465
| doi = 10.1186/s13040-017-0155-3
| pmc= 5721660}}&lt;/ref&gt;

Since the parameter space of a machine learner may include real-valued or unbounded value spaces for certain parameters, manually set bounds and discretization may be necessary before applying grid search.

For example, a typical soft-margin [[support vector machine|SVM]] [[statistical classification|classifier]] equipped with an [[radial basis function kernel|RBF kernel]] has at least two hyperparameters that need to be tuned for good performance on unseen data: a regularization constant ''C'' and a kernel hyperparameter γ. Both parameters are continuous, so to perform grid search, one selects a finite set of "reasonable" values for each, say

:&lt;math&gt;C \in \{10, 100, 1000\}&lt;/math&gt;
:&lt;math&gt;\gamma \in \{0.1, 0.2, 0.5, 1.0\}&lt;/math&gt;

Grid search then trains an SVM with each pair (''C'', γ) in the [[Cartesian product]] of these two sets and evaluates their performance on a held-out validation set (or by internal cross-validation on the training set, in which case multiple SVMs are trained per pair). Finally, the grid search algorithm outputs the settings that achieved the highest score in the validation procedure.

Grid search suffers from the [[curse of dimensionality]], but is often [[embarrassingly parallel]] because the hyperparameter settings it evaluates are typically independent of each other.&lt;ref name="bergstra"/&gt;

[[File:Hyperparameter Optimization using Random Search.svg|thumb|Random search across different combinations of values for two hyperparameters. In this example, 100 different random choices are evaluated. The green bars show that more individual values for each hyperparameter are considered compared to a grid search.]]

=== Random search ===
Random Search replaces the exhaustive enumeration of all combinations by selecting them randomly. This can be simply applied to the discrete setting described above, but also generalizes to continuous and mixed spaces. It can outperform Grid search, especially when only a small number of hyperparameters affects the final performance of the machine learning algorithm.&lt;ref name="bergstra" /&gt; In this case, the optimization problem is said to have a low intrinsic dimensionality.&lt;ref&gt;{{Cite journal|last=Ziyu|first=Wang|last2=Frank|first2=Hutter|last3=Masrour|first3=Zoghi|last4=David|first4=Matheson|last5=Nando|first5=de Feitas|date=2016|title=Bayesian Optimization in a Billion Dimensions via Random Embeddings|journal=Journal of Artificial Intelligence Research|language=en|volume=55|pages=361–387|doi=10.1613/jair.4806|arxiv=1301.1942}}&lt;/ref&gt; Random Search is also [[embarrassingly parallel]], and additionally allows the inclusion of prior knowledge by specifying the distribution from which to sample.

[[File:Hyperparameter Optimization using Tree-Structured Parzen Estimators.svg|thumb|Methods such as Bayesian optimization smartly explore the space of potential choices of hyperparameters by deciding which combination to explore next based on previous observations.]]

=== Bayesian optimization ===
{{main|Bayesian optimization}}

Bayesian optimization is a global optimization method for noisy black-box functions.  Applied to hyperparameter optimization, Bayesian optimization builds a probabilistic model of the function mapping from hyperparameter values to the objective evaluated on a validation set. By iteratively evaluating a promising hyperparameter configuration based on the current model, and then updating it, Bayesian optimization, aims to gather observations revealing as much information as possible about this function and, in particular, the location of the optimum. It tries to balance exploration (hyperparameters for which the outcome is most uncertain) and exploitation (hyperparameters expected close to the optimum). In practice, Bayesian optimization has been shown&lt;ref name="hutter"&gt;{{Citation
 | last = Hutter
 | first = Frank
 | last2 = Hoos
 | first2 = Holger
 | last3 = Leyton-Brown
 | first3 = Kevin
 | title = Sequential model-based optimization for general algorithm configuration
 | journal = Learning and Intelligent Optimization
 | volume = 6683
 | pages = 507–523
 | year = 2011
 | url = http://www.cs.ubc.ca/labs/beta/Projects/SMAC/papers/11-LION5-SMAC.pdf | doi = 10.1007/978-3-642-25566-3_40
 | citeseerx = 10.1.1.307.8813
 | series = Lecture Notes in Computer Science
 | isbn = 978-3-642-25565-6
 }}&lt;/ref&gt;&lt;ref name="bergstra11"&gt;{{Citation
 | last = Bergstra
 | first = James
 | last2 = Bardenet
 | first2 = Remi
 | last3 = Bengio
 | first3 = Yoshua
 | last4 = Kegl
 | first4 = Balazs
 | title = Algorithms for hyper-parameter optimization
 | journal = Advances in Neural Information Processing Systems
 | year = 2011
 | url = http://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf }}&lt;/ref&gt;&lt;ref name="snoek"&gt;{{cite journal
 | last = Snoek
 | first = Jasper
 | last2 = Larochelle
 | first2 = Hugo
 | last3 = Adams
 | first3 = Ryan
 | title = Practical Bayesian Optimization of Machine Learning Algorithms
 | journal = Advances in Neural Information Processing Systems
 | volume =&lt;!-- --&gt;
 | pages =&lt;!-- --&gt;
 | year = 2012
 | url = http://papers.nips.cc/paper/4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf
 | bibcode = 2012arXiv1206.2944S
 | arxiv = 1206.2944
 }}&lt;/ref&gt;&lt;ref name="thornton"&gt;{{cite journal
 | last = Thornton
 | first = Chris
 | last2 = Hutter
 | first2 = Frank
 | last3 = Hoos
 | first3 = Holger
 | last4 = Leyton-Brown
 | first4 = Kevin
 | title = Auto-WEKA: Combined selection and hyperparameter optimization of classification algorithms
 | journal = Knowledge Discovery and Data Mining
 | volume = &lt;!-- --&gt;
 | pages = &lt;!-- --&gt;
 | year = 2013
 | url = http://www.cs.ubc.ca/labs/beta/Projects/autoweka/papers/autoweka.pdf
 | bibcode = 2012arXiv1208.3719T
 | arxiv = 1208.3719
 }}&lt;/ref&gt; to obtain better results in fewer evaluations compared to grid search and random search, due to the ability to reason about the quality of experiments before they are run.

=== Gradient-based optimization ===
For specific learning algorithms, it is possible to compute the gradient with respect to hyperparameters and then optimize the hyperparameters using gradient descent. The first usage of these techniques was focused on neural networks.&lt;ref&gt;{{cite journal |last1=Larsen|first1=Jan|last2= Hansen |first2=Lars Kai|last3=Svarer|first3=Claus|last4=Ohlsson|first4=M|title=Design and regularization of neural networks: the optimal use of a validation set|journal=Proceedings of the 1996 IEEE Signal Processing Society Workshop|date=1996|pages=62–71|doi=10.1109/NNSP.1996.548336|isbn=0-7803-3550-3|citeseerx=10.1.1.415.3266|url=http://orbit.dtu.dk/files/4545571/Svarer.pdf}}&lt;/ref&gt; Since then, these methods have been extended to other models such as [[support vector machine]]s&lt;ref&gt;{{cite journal |author1=Olivier Chapelle |author2=Vladimir Vapnik |author3=Olivier Bousquet |author4=Sayan Mukherjee |title=Choosing multiple parameters for support vector machines |journal=Machine Learning |year=2002 |volume=46 |pages=131–159 |url=http://www.chapelle.cc/olivier/pub/mlj02.pdf | doi = 10.1023/a:1012450327387 }}&lt;/ref&gt; or logistic regression.&lt;ref&gt;{{cite journal |author1 =Chuong B|author2= Chuan-Sheng Foo|author3=Andrew Y Ng|journal = Advances in Neural Information Processing Systems 20|title = Efficient multiple hyperparameter learning for log-linear models|year =2008|url=http://papers.nips.cc/paper/3286-efficient-multiple-hyperparameter-learning-for-log-linear-models.pdf}}&lt;/ref&gt;

A different approach in order to obtain a gradient with respect to hyperparameters consists in differentiating the steps of an iterative optimization algorithm using  [[automatic differentiation]].&lt;ref&gt;{{cite journal|last1=Domke|first1=Justin|title=Generic Methods for Optimization-Based Modeling|journal=Aistats |date=2012|volume=22|url=http://www.jmlr.org/proceedings/papers/v22/domke12/domke12.pdf}}&lt;/ref&gt;&lt;ref name=abs1502.03492&gt;{{cite arXiv |last1=Maclaurin|first1=Douglas|last2=Duvenaud|first2=David|last3=Adams|first3=Ryan P.|eprint=1502.03492|title=Gradient-based Hyperparameter Optimization through Reversible Learning|class=stat.ML|date=2015}}&lt;/ref&gt; &lt;ref&gt;{{cite journal |last1=Franceschi |first1=Luca |last2=Donini |first2=Michele |last3=Frasconi |first3=Paolo |last4=Pontil |first4=Massimiliano |title=Forward and Reverse Gradient-Based Hyperparameter Optimization |journal=Proceedings of the 34th International Conference on Machine Learning |date=2017 |arxiv=1703.01785 |bibcode=2017arXiv170301785F |url=http://proceedings.mlr.press/v70/franceschi17a/franceschi17a-supp.pdf}}&lt;/ref&gt;

=== Evolutionary optimization ===
{{main|Evolutionary algorithm}}

Evolutionary optimization is a methodology for the global optimization of noisy black-box functions. In hyperparameter optimization, evolutionary optimization uses [[evolutionary algorithms]] to search the space of hyperparameters for a given algorithm.&lt;ref name="bergstra11" /&gt; Evolutionary hyperparameter optimization follows a [[Evolutionary algorithm#Implementation|process]] inspired by the biological concept of [[evolution]]:

# Create an initial population of random solutions (i.e., randomly generate tuples of hyperparameters, typically 100+)
# Evaluate the hyperparameters tuples and acquire their [[fitness function]] (e.g., 10-fold [[Cross-validation (statistics)|cross-validation]] accuracy of the machine learning algorithm with those hyperparameters)
# Rank the hyperparameter tuples by their relative fitness
# Replace the worst-performing hyperparameter tuples with new hyperparameter tuples generated through [[crossover (genetic algorithm)|crossover]] and [[mutation (genetic algorithm)|mutation]]
# Repeat steps 2-4 until satisfactory algorithm performance is reached or algorithm performance is no longer improving

Evolutionary optimization has been used in hyperparameter optimization for statistical machine learning algorithms,&lt;ref name="bergstra11" /&gt; [[automated machine learning]], [[Deep learning#Deep neural networks|deep neural network]] architecture search,&lt;ref name="miikkulainen1"&gt;{{cite arxiv | vauthors = Miikkulainen R, Liang J, Meyerson E, Rawal A, Fink D, Francon O, Raju B, Shahrzad H, Navruzyan A, Duffy N, Hodjat B | year = 2017 | title = Evolving Deep Neural Networks |eprint=1703.00548| class = cs.NE }}&lt;/ref&gt;&lt;ref name="jaderberg1"&gt;{{cite arxiv | vauthors = Jaderberg M, Dalibard V, Osindero S, Czarnecki WM, Donahue J, Razavi A, Vinyals O, Green T, Dunning I, Simonyan K, Fernando C, Kavukcuoglu K | year = 2017 | title = Population Based Training of Neural Networks |eprint=1711.09846| class = cs.LG }}&lt;/ref&gt; as well as training of the weights in deep neural networks.&lt;ref name="such1"&gt;{{cite arxiv | vauthors = Such FP, Madhavan V, Conti E, Lehman J, Stanley KO, Clune J | year = 2017 | title = Deep Neuroevolution: Genetic Algorithms Are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning |eprint=1712.06567| class = cs.NE }}&lt;/ref&gt;

=== Population-based ===
Population Based Training (PBT) learns both hyperparameter values and network weights. Multiple learning processes operate independently, using different hyperparameters. As with evolutionary methods, poorly performing models are iteratively replaced with models that adopt modified hyperparameter values and weights based on the better performers. This replacement model warm starting is the primary differentiator between PBT and other evolutionary methods. PBT thus allows the hyperparameters to evolve and eliminates the need for manual hypertuning. The process makes no assumptions regarding model architecture, loss functions or training procedures.&lt;ref&gt;{{cite arxiv|last=Li|first=Ang|last2=Spyra|first2=Ola|last3=Perel|first3=Sagi|last4=Dalibard|first4=Valentin|last5=Jaderberg|first5=Max|last6=Gu|first6=Chenjie|last7=Budden|first7=David|last8=Harley|first8=Tim|last9=Gupta|first9=Pramod|date=2019-02-05|title=A Generalized Framework for Population Based Training|eprint=1902.01894|class=cs.AI}}&lt;/ref&gt;

=== Early stopping-based ===
A class of early stopping-based hyperparameter optimization algorithms is purpose built for large search spaces of continuous and discrete hyperparameters, particularly when the computational cost to evaluate the performance of a set of hyperparameters is high. Irace implements the iterated racing algorithm, that focuses the search around the most promising configurations, using statistical tests to discard the ones that perform poorly.&lt;ref name="irace"&gt;{{cite journal |last1=López-Ibáñez |first1=Manuel |last2=Dubois-Lacoste |first2=Jérémie |last3=Pérez Cáceres |first3=Leslie |last4=Stützle |first4=Thomas |last5=Birattari |first5=Mauro |date=2016 |title=The irace package: Iterated Racing for Automatic Algorithm Configuration |journal=Operations Research Perspective |issue=3 |pages=43-58 |doi=10.1016/j.orp.2016.09.002|doi-access=free }}&lt;/ref&gt;&lt;ref name="race"&gt;{{cite journal |last1=Birattari |first1=Mauro |last2=Stützle |first2=Thomas |last3=Paquete |first3=Luis |last4=Varrentrapp |first4=Klaus |date=2002 |title=A Racing Algorithm for Configuring Metaheuristics |journal=GECCO 2002 |pages=11-18}}&lt;/ref&gt;
Another early stopping hyperparameter optimization algorithm is successive halving (SHA),&lt;ref&gt;{{cite arxiv|last=Jamieson|first=Kevin|last2=Talwalkar|first2=Ameet|date=2015-02-27|title=Non-stochastic Best Arm Identification and Hyperparameter Optimization|eprint=1502.07943|class=cs.LG}}&lt;/ref&gt; which begins as a random search but periodically prunes low-performing models, thereby focusing computational resources on more promising models.  Asynchronous successive halving (ASHA)&lt;ref&gt;{{cite arxiv|last=Li|first=Liam|last2=Jamieson|first2=Kevin|last3=Rostamizadeh|first3=Afshin|last4=Gonina|first4=Ekaterina|last5=Hardt|first5=Moritz|last6=Recht|first6=Benjamin|last7=Talwalkar|first7=Ameet|date=2020-03-16|title=A System for Massively Parallel Hyperparameter Tuning|eprint=1810.05934v5}}&lt;/ref&gt; further improves upon SHA's resource utilization profile by removing the need to synchronously evaluate and prune low-performing models. Hyperband&lt;ref&gt;{{cite arxiv|last=Li|first=Lisha|last2=Jamieson|first2=Kevin|last3=DeSalvo|first3=Giulia|last4=Rostamizadeh|first4=Afshin|last5=Talwalkar|first5=Ameet|date=2020-03-16|title=Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization|eprint=1603.06560v4}}&lt;/ref&gt; is a higher level early stopping-based algorithm that invokes SHA or ASHA multiple times with varying levels of pruning aggressiveness, in order to be more widely applicable and with fewer required inputs.

=== Others ===
[[Radial basis function|RBF]]&lt;ref name=abs1705.08520&gt;{{cite arxiv |eprint=1705.08520|last1=Diaz|first1=Gonzalo|title=An effective algorithm for hyperparameter optimization of neural networks|last2=Fokoue|first2=Achille|last3=Nannicini|first3=Giacomo|last4=Samulowitz|first4=Horst|class=cs.AI|year=2017}}&lt;/ref&gt; and [[spectral method|spectral]]&lt;ref name=abs1706.00764&gt;{{cite arxiv |eprint=1706.00764|last1=Hazan|first1=Elad|title=Hyperparameter Optimization: A Spectral Approach|last2=Klivans|first2=Adam|last3=Yuan|first3=Yang|class=cs.LG|year=2017}}&lt;/ref&gt; approaches have also been developed.

== Open-source software ==

===Grid search===
*[https://github.com/determined-ai/determined Determined], a DL Training Platform includes grid search for PyTorch and TensorFlow (Keras and Estimator) models.
*[http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html H2O AutoML] provides grid search over algorithms in the H2O open source machine learning library.
*[https://github.com/kubeflow/katib Katib] is a Kubernetes-native system that includes grid search.
*[[scikit-learn]] is a Python package that includes [http://scikit-learn.sourceforge.net/modules/grid_search.html grid] search.
*[https://github.com/autonomio/talos Talos] includes grid search for [[Keras]].
*[https://ray.readthedocs.io/en/latest/tune.html Tune] is a Python library for distributed hyperparameter tuning and supports grid search.

===Random search===
*[https://github.com/determined-ai/determined Determined] is a DL Training Platform that supports random search for PyTorch and TensorFlow (Keras and Estimator) models.
* [https://github.com/hyperopt/hyperopt hyperopt], also via [https://github.com/maxpumperla/hyperas hyperas] and [https://github.com/hyperopt/hyperopt-sklearn hyperopt-sklearn], are Python packages which include random search.
*[https://github.com/kubeflow/katib Katib] is a Kubernetes-native system that includes random search.
* [[scikit-learn]] is a Python package which includes [https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html random] search.
* [[caret]] is a R package which includes [http://topepo.github.io/caret/random-hyperparameter-search.html grid &amp; random] search.
*[https://github.com/autonomio/talos Talos] includes a customizable random search for [[Keras]].
*[https://ray.readthedocs.io/en/latest/tune.html Tune] is a Python library for distributed hyperparameter tuning and supports random search over arbitrary parameter distributions.

===Bayesian===
* [https://github.com/automl/auto-sklearn Auto-sklearn]&lt;ref name="autosklearn"&gt;{{cite journal | vauthors = Feurer M, Klein A, Eggensperger K, Springenberg J, Blum M, Hutter F | year = 2015 | title = Efficient and Robust Automated Machine Learning | url = https://papers.nips.cc/paper/5872-efficient-and-robust-automated-machine-learning | journal = Advances in Neural Information Processing Systems 28 (NIPS 2015) | pages = 2962–2970 }}&lt;/ref&gt; is a Bayesian hyperparameter optimization layer on top of [[scikit-learn]].
* [https://github.com/facebook/Ax Ax]&lt;ref name=AxBoTorch&gt;{{cite web |url=https://ai.facebook.com/blog/open-sourcing-ax-and-botorch-new-ai-tools-for-adaptive-experimentation/ |title=Open-sourcing Ax and BoTorch: New AI tools for adaptive experimentation |year=2019}}&lt;/ref&gt; is a Python-based experimentation platform that supports Bayesian optimization and bandit optimization as exploration strategies.
* [https://github.com/baptistar/BOCS BOCS] is a Matlab package which uses [[semidefinite programming]] for minimizing a black-box function over discrete inputs.&lt;ref name="arXiv:1806.08838"&gt;{{cite arXiv |year=2018 |title=Bayesian Optimization of Combinatorial Structures |eprint=1806.08838|last1=Baptista |first1=Ricardo |last2=Poloczek |first2=Matthias |class=stat.ML }}&lt;/ref&gt; A Python 3 implementation is also included.
* [https://github.com/automl/HpBandSter HpBandSter] is a Python package which combines Bayesian optimization with bandit-based methods.&lt;ref name="arXiv:1807.01774"&gt;{{cite arXiv |year=2018 |title=BOHB: Robust and Efficient Hyperparameter Optimization at Scale |eprint=1807.01774|last1=Falkner |first1=Stefan |last2=Klein |first2=Aaron |last3=Hutter |first3=Frank |class=stat.ML }}&lt;/ref&gt;
*[https://github.com/kubeflow/katib Katib] is a Kubernetes-native system which includes bayesian optimization.
*[https://github.com/mlr-org/mlrMBO mlrMBO], also with [https://github.com/mlr-org/mlr mlr], is an [[R (programming language)|R]] package for model-based/Bayesian optimization of black-box functions.
*[https://optuna.readthedocs.io/en/latest/ optuna] is a Python package for black box optimization, compatible with arbitrary functions that need to be optimized.
* [https://github.com/scikit-optimize/scikit-optimize scikit-optimize] is a Python package or sequential model-based optimization with a scipy.optimize interface.&lt;ref name=skopt&gt;{{Cite web|url=https://scikit-optimize.github.io/|title=skopt API documentation|website=scikit-optimize.github.io}}&lt;/ref&gt;
* [https://github.com/automl/SMAC3 SMAC] SMAC is a Python/Java library implementing Bayesian optimization.&lt;ref name="SMAC"&gt;{{cite journal | vauthors = Hutter F, Hoos HH, Leyton-Brown K | title = Sequential Model-Based Optimization for General Algorithm Configuration | url = https://www.cs.ubc.ca/~hutter/papers/10-TR-SMAC.pdf | journal = Proceedings of the Conference on Learning and Intelligent OptimizatioN (LION 5)}}&lt;/ref&gt;
* [https://github.com/PhilippPro/tuneRanger tuneRanger] is an R package for tuning random forests using model-based optimization.

===Gradient-based optimization===
* [https://github.com/lucfra/FAR-HO FAR-HO] is a Python package containing Tensorflow implementations and wrappers for gradient-based hyperparamteter optimization with forward and reverse mode algorithmic differentiation.
* [https://github.com/dmlc/xgboost XGBoost] is an open-source software library that provides a gradient boosting framework for C++, Java, Python, R, and Julia.

===Evolutionary===
* [https://github.com/DEAP/deap deap] is a Python framework for general evolutionary computation which is flexible and integrates with parallelization packages like [https://github.com/soravux/scoop scoop] and [[PySpark|pyspark]], and other Python frameworks like [[Scikit-learn|sklearn]] via [https://github.com/rsteca/sklearn-deap sklearn-deap].
*[https://github.com/determined-ai/determined Determined] is a DL Training Platform that supports PBT for optimizing PyTorch and TensorFlow (Keras and Estimator) models.
* [https://github.com/joeddav/devol devol] is a Python package that performs Deep Neural Network architecture search using [[genetic programming]].
* [https://github.com/facebookresearch/nevergrad nevergrad]&lt;ref name=nevergrad_issue1/&gt; is a Python package which includes [[Differential_evolution]], [[Evolution_strategy]], [[Bayesian_optimization]], population control methods for the noisy case and [[Particle_swarm_optimization]].&lt;ref name=nevergrad/&gt;
*[https://ray.readthedocs.io/en/latest/tune.html Tune] is a Python library for distributed hyperparameter tuning and leverages [https://github.com/facebookresearch/nevergrad nevergrad] for evolutionary algorithm support.

===Early Stopping===
*[https://github.com/determined-ai/determined Determined] is a DL Training Platform that supports Hyperband for PyTorch and TensorFlow (Keras and Estimator) models.
* [https://iridia.ulb.ac.be/irace/ irace] is an R package that implements the iterated racing algorithm.&lt;ref name="irace"&gt;{{cite journal |last1=López-Ibáñez |first1=Manuel |last2=Dubois-Lacoste |first2=Jérémie |last3=Pérez Cáceres |first3=Leslie |last4=Stützle |first4=Thomas |last5=Birattari |first5=Mauro |date=2016 |title=The irace package: Iterated Racing for Automatic Algorithm Configuration |journal=Operations Research Perspective |issue=3 |pages=43-58 |doi=10.1016/j.orp.2016.09.002|doi-access=free }}&lt;/ref&gt;&lt;ref name="race"&gt;{{cite journal |last1=Birattari |first1=Mauro |last2=Stützle |first2=Thomas |last3=Paquete |first3=Luis |last4=Varrentrapp |first4=Klaus |date=2002 |title=A Racing Algorithm for Configuring Metaheuristics |journal=GECCO 2002 |pages=11-18}}&lt;/ref&gt;
*[https://github.com/kubeflow/katib Katib] is a Kubernetes-native system that includes hyperband.

===Other===
*[https://github.com/determined-ai/determined Determined] is a DL Training Platform that supports random, grid, PBT, Hyperband and NAS approaches to hyperparameter optimization for PyTorch and TensorFlow (Keras and Estimator) models.
* [[dlib]]&lt;ref name=dlib_github&gt;{{Cite web|url=https://github.com/davisking/dlib|title=A toolkit for making real world machine learning and data analysis applications in C++: davisking/dlib|date=February 25, 2019|via=GitHub}}&lt;/ref&gt; is a C++ package with a Python API which has a parameter-free optimizer based on [https://arxiv.org/abs/1703.02628 LIPO] and [[trust region]] optimizers working in tandem.&lt;ref name=dlib_blog&gt;{{cite web |last1=King |first1=Davis |title=A Global Optimization Algorithm Worth Using |url=http://blog.dlib.net/2017/12/a-global-optimization-algorithm-worth.html}}&lt;/ref&gt;
* [https://github.com/callowbird/Harmonica Harmonica] is a Python package for spectral hyperparameter optimization.&lt;ref name=abs1706.00764/&gt;
* [https://github.com/hyperopt/hyperopt hyperopt], also via [https://github.com/maxpumperla/hyperas hyperas] and [https://github.com/hyperopt/hyperopt-sklearn hyperopt-sklearn], are Python packages which include [[kernel density estimation|Tree of Parzen Estimators]] based distributed hyperparameter optimization.
*[https://github.com/kubeflow/katib/ Katib] is a Kubernetes-native system which includes grid, random search, bayesian optimization, hyperband, and NAS based on reinforcement learning.
* [https://github.com/facebookresearch/nevergrad nevergrad]&lt;ref name=nevergrad_issue1&gt;{{Cite web|url=https://github.com/facebookresearch/nevergrad/issues/1|title=[QUESTION] How to use to optimize NN hyperparameters · Issue #1 · facebookresearch/nevergrad|website=GitHub}}&lt;/ref&gt; is a Python package for gradient-free optimization using techniques such as differential evolution, sequential quadratic programming, fastGA, covariance matrix adaptation, population control methods, and particle swarm optimization.&lt;ref name=nevergrad&gt;{{Cite web|url=https://code.fb.com/ai-research/nevergrad/|title=Nevergrad: An open source tool for derivative-free optimization|date=December 20, 2018}}&lt;/ref&gt;
* [[Neural Network Intelligence]] (NNI) is a Python package which includes hyperparameter tuning for neural networks in local and distributed environments. Its techniques include TPE, random, anneal, evolution, SMAC, batch, grid, and hyperband.
* [https://github.com/sherpa-ai/sherpa parameter-sherpa] is a similar Python package which includes several techniques grid search, Bayesian and genetic Optimization
* [https://github.com/wwu-mmll/photonai photonai] is a high level Python API for designing and optimizing machine learning pipelines based on grid, random search and bayesian optimization.
* [https://github.com/CMA-ES/pycma pycma] is a Python implementation of [[CMA-ES|Covariance Matrix Adaptation Evolution Strategy]].
* [https://github.com/coin-or/rbfopt rbfopt] is a Python package that uses a [[radial basis function]] model&lt;ref name=abs1705.08520/&gt;
*[https://ray.readthedocs.io/en/latest/tune.html Tune] is a Python library for hyperparameter tuning execution and integrates with/scales many existing hyperparameter optimization libraries such as [https://github.com/hyperopt/hyperopt hyperopt], [https://github.com/facebookresearch/nevergrad nevergrad], and [https://github.com/scikit-optimize/scikit-optimize scikit-optimize].

== Commercial services ==
* [https://aws.amazon.com/sagemaker/ Amazon Sagemaker] uses Gaussian processes to tune hyperparameters. 
* [https://bigml.com/api/optimls BigML OptiML] supports mixed search domains
* [https://cloud.google.com/ml-engine/docs/tensorflow/using-hyperparameter-tuning Google HyperTune] supports mixed search domains
* [https://indiesolver.com Indie Solver] supports multiobjective, multifidelity and constraint optimization
* [https://mindfoundry.ai/OPTaaS Mind Foundry OPTaaS] supports mixed search domains, multiobjective, constraints, parallel optimization and surrogate models.
* [https://sigopt.com SigOpt] supports mixed search domains, multiobjective, multisolution, multifidelity, constraint (linear and black-box), and parallel optimization.

== See also ==
* [[Automated machine learning]]
* [[Neural architecture search]]
* [[Meta-optimization]]
* [[Model selection]]
* [[Self-tuning]]
* [[XGBoost]]

== References ==
{{Reflist|30em}}

[[Category:Machine learning]]
[[Category:Mathematical optimization]]
[[Category:Model selection]]</text>
      <sha1>l5ahyvaq3kwtn68jhyfa4xgcwxc9as5</sha1>
    </revision>
  </page>
  <page>
    <title>Paraphrasing (computational linguistics)</title>
    <ns>0</ns>
    <id>56142183</id>
    <revision>
      <id>1000177215</id>
      <parentid>990832167</parentid>
      <timestamp>2021-01-13T23:49:40Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 9 templates: hyphenate params (5×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="15126" xml:space="preserve">{{about|automated generation and recognition of paraphrases||Paraphrase (disambiguation)}}
'''Paraphrase''' or '''Paraphrasing''' in [[computational linguistics]] is the [[natural language processing]] task of detecting and generating [[paraphrase]]s. Applications of paraphrasing are varied including information retrieval, [[question answering]], [[Automatic summarization|text summarization]], and [[plagiarism detection]].&lt;ref name=Socher /&gt; Paraphrasing is also useful in the [[evaluation of machine translation]],&lt;ref name=Callison&gt;{{cite conference|last=Callison-Burch|first=Chris|title=Syntactic Constraints on Paraphrases Extracted from Parallel Corpora|book-title=EMNLP '08 Proceedings of the Conference on Empirical Methods in Natural Language Processing|date=October 25–27, 2008|place=Honolulu, Hawaii|pages=196–205|url=https://dl.acm.org/citation.cfm?id=1613743}}&lt;/ref&gt; as well as [[semantic parsing]]&lt;ref&gt;Berant, Jonathan, and Percy Liang. "[http://www.aclweb.org/anthology/P14-1133 Semantic parsing via paraphrasing]." Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Vol. 1. 2014.&lt;/ref&gt; and [[natural language generation|generation]] of new samples to expand existing [[Text corpus|corpora]].&lt;ref name=Barzilay /&gt;

== Paraphrase generation ==

=== Multiple sequence alignment ===
Barzilay and Lee&lt;ref name=Barzilay&gt;{{cite conference|last1=Barzilay|first1=Regina|last2=Lee|first2=Lillian|title=Learning to Paraphrase: An Unsupervised Approach Using Multiple-Sequence Alignment|book-title=Proceedings of HLT-NAACL 2003|date=May–June 2003|url=http://www.cs.cornell.edu/home/llee/papers/statpar.home.html}}&lt;/ref&gt; proposed a method to generate paraphrases through the usage of monolingual [[parallel text|parallel corpora]], namely news articles covering the same event on the same day. Training consists of using [[multiple sequence alignment|multi-sequence alignment]] to generate sentence-level paraphrases from an unannotated corpus. This is done by

* finding recurring patterns in each individual corpus, i.e. "{{mvar|X}} (injured/wounded) {{mvar|Y}} people, {{mvar|Z}} seriously" where {{mvar|X, Y, Z}} are variables
* finding pairings between such patterns the represent paraphrases, i.e. "{{mvar|X}} (injured/wounded) {{mvar|Y}} people, {{mvar|Z}} seriously" and "{{mvar|Y}} were (wounded/hurt) by {{mvar|X}}, among them {{mvar|Z}} were in serious condition"

This is achieved by first clustering similar sentences together using [[n-gram]] overlap. Recurring patterns are found within clusters by using multi-sequence alignment. Then the position of argument words are determined by finding areas of high variability within each clusters, aka between words shared by more than 50% of a cluster's sentences. Pairings between patterns are then found by comparing similar variable words between different corpora. Finally new paraphrases can be generated by choosing a matching cluster for a source sentence, then substituting the source sentence's argument into any number of patterns in the cluster.

=== Phrase-based Machine Translation ===
Paraphrase can also be generated through the use of [[statistical machine translation#Phrase-based translation|phrase-based translation]] as proposed by Bannard and Callison-Burch.&lt;ref name=Bannard&gt;{{cite conference|last1=Bannard|first1=Colin|last2=Callison-Burch|first2=Chris|title=Paraphrasing Bilingual Parallel Corpora|book-title=Proceedings of the 43rd Annual Meeting of the ACL|place=Ann Arbor, Michigan|pages=597–604|year=2005|url=https://dl.acm.org/citation.cfm?id=1219914}}&lt;/ref&gt; The chief concept consists of aligning phrases in a [[pivot language]] to produce potential paraphrases in the original language. For example, the phrase "under control" in an English sentence is aligned with the phrase "unter kontrolle" in its German counterpart. The phrase "unter kontrolle" is then found in another German sentence with the aligned English phrase being "in check", a paraphrase of "under control".

The probability distribution can be modeled as &lt;math&gt;\Pr(e_2 | e_1)&lt;/math&gt;, the probability phrase &lt;math&gt;e_2&lt;/math&gt; is a paraphrase of &lt;math&gt;e_1&lt;/math&gt;, which is equivalent to &lt;math&gt;\Pr(e_2|f) \Pr(f|e_1)&lt;/math&gt; summed over all &lt;math&gt;f&lt;/math&gt;, a potential phrase translation in the pivot language. Additionally, the sentence &lt;math&gt;e_1&lt;/math&gt; is added as a prior to add context to the paraphrase. Thus the optimal paraphrase, &lt;math&gt;\hat{e_2}&lt;/math&gt; can be modeled as:

: &lt;math&gt;\hat{e_2} = \text{arg} \max_{e_2 \neq e_1} \Pr(e_2 | e_1, S) = \text{arg} \max_{e_2 \neq e_1} \sum_f \Pr(e_2 | f, S) \Pr(f | e_1, S)&lt;/math&gt;

&lt;math&gt;\Pr(e_2|f)&lt;/math&gt; and &lt;math&gt;\Pr(f|e_1)&lt;/math&gt; can be approximated by simply taking their frequencies. Adding &lt;math&gt;S&lt;/math&gt; as a prior is modeled by calculating the probability of forming the &lt;math&gt;S&lt;/math&gt; when &lt;math&gt;e_1&lt;/math&gt; is substituted with {{nowrap|&lt;math&gt;e_2&lt;/math&gt;.}}

=== Long short-term memory ===
There has been success in using [[long short-term memory]] (LSTM) models to generate paraphrases.&lt;ref name=Prakash&gt;{{Citation|last1=Prakash|first1=Aaditya|last2=Hasan|first2=Sadid A.|last3=Lee|first3=Kathy|last4=Datla|first4=Vivek|last5=Qadir|first5=Ashequl|last6=Liu|first6=Joey|last7=Farri|first7=Oladimeji|title=Neural Paraphrase Generation with Staked Residual LSTM Networks|year=2016|arxiv=1610.03098|bibcode=2016arXiv161003098P}}&lt;/ref&gt; In short, the model consists of an encoder and decoder component, both implemented using variations of a stacked [[Vanishing gradient problem#Residual networks|residual]] LSTM. First, the encoding LSTM takes a [[one-hot]] encoding of all the words in a sentence as input and produces a final hidden vector, which can be viewed as a representation of the input sentence. The decoding LSTM then takes the hidden vector as input and generates new sentence, terminating in an end-of-sentence token. The encoder and decoder are trained to take a phrase and reproduce the one-hot distribution of a corresponding paraphrase by minimizing [[perplexity]] using simple [[stochastic gradient descent]]. New paraphrases are generated by inputting a new phrase to the encoder and passing the output to the decoder.

== Paraphrase recognition ==

=== Recursive Autoencoders ===
Paraphrase recognition has been attempted by Socher et al&lt;ref name=Socher&gt;{{Citation|last1=Socher|first1=Richard|last2=Huang|first2=Eric|last3=Pennington|first3=Jeffrey|last4=Ng|first4=Andrew|last5=Manning|first5=Christopher|title=Dynamic Pooling and Unfolding Recursive Autoencoders for Paraphrase Detection|book-title=Advances in Neural Information Processing Systems 24|year=2011|url=http://www.socher.org/index.php/Main/DynamicPoolingAndUnfoldingRecursiveAutoencodersForParaphraseDetection}}&lt;/ref&gt; through the use of recursive [[autoencoder]]s. The main concept is to produce a vector representation of a sentence along with its components through recursively using an autoencoder. The vector representations of paraphrases should have similar vector representations; they are processed, then fed as input into a [[artificial neural network|neural network]] for classification.

Given a sentence &lt;math&gt;W&lt;/math&gt; with &lt;math&gt;m&lt;/math&gt; words, the autoencoder is designed to take 2 &lt;math&gt;n&lt;/math&gt;-dimensional [[word embedding]]s as input and produce an &lt;math&gt;n&lt;/math&gt;-dimensional vector as output. The same autoencoder is applied to every pair of words in &lt;math&gt;S&lt;/math&gt; to produce &lt;math&gt;\lfloor m/2 \rfloor&lt;/math&gt; vectors. The autoencoder is then applied recursively with the new vectors as inputs until a single vector is produced. Given an odd number of inputs, the first vector is forwarded as is to the next level of recursion. The autoencoder is then trained to reproduce every vector in the full recursion tree including the initial word embeddings.

Given two sentences &lt;math&gt;W_1&lt;/math&gt; and &lt;math&gt;W_2&lt;/math&gt; of length 4 and 3 respectively, the autoencoders would produce 7 and 5 vector representations including the initial word embeddings. The [[euclidean distance]] is then taken between every combination of vectors in &lt;math&gt;W_1&lt;/math&gt; and &lt;math&gt;W_2&lt;/math&gt; to produce a similarity matrix &lt;math&gt;S \in \mathbb{R}^{7 \times 5}&lt;/math&gt;. &lt;math&gt;S&lt;/math&gt; is then subject to a dynamic min-[[convolutional neural network#Pooling layer|pooling layer]] to produce a fixed size &lt;math&gt;n_p \times n_p&lt;/math&gt; matrix. Since &lt;math&gt;S&lt;/math&gt; are not uniform in size among all potential sentences, &lt;math&gt;S&lt;/math&gt; is split into &lt;math&gt;n_p&lt;/math&gt; roughly even sections. The output is then normalized to have mean 0 and standard deviation 1 and is fed into a fully connected layer with a [[softmax function|softmax]] output. The dynamic pooling to softmax model is trained using pairs of known paraphrases.

=== Skip-thought vectors ===
Skip-thought vectors are an attempt to create a vector representation of the semantic meaning of a sentence in a similar fashion as the [[word2vec|skip gram model]].&lt;ref name=Kiros&gt;{{Citation|last1=Kiros|first1=Ryan|last2=Zhu|first2=Yukun|last3=Salakhutdinov|first3=Ruslan|last4=Zemel|first4=Richard|last5=Torralba|first5=Antonio|last6=Urtasun|first6=Raquel|last7=Fidler|first7=Sanja|title=Skip-Thought Vectors|year=2015|arxiv=1506.06726|bibcode=2015arXiv150606726K}}&lt;/ref&gt; Skip-thought vectors are produced through the use of a skip-thought model which consists of three key components, an encoder and two decoders. Given a corpus of documents, the skip-thought model is trained to take a sentence as input and encode it into a skip-thought vector. The skip-thought vector is used as input for both decoders, one of which attempts to reproduce the previous sentence and the other the following sentence in its entirety. The encoder and decoder can be implemented through the use of a [[recursive neural network]] (RNN) or an [[long short-term memory|LSTM]].

Since paraphrases carry the same semantic meaning between one another, they should have similar skip-thought vectors. Thus a simple [[logistic regression]] can be trained to a good performance with the absolute difference and component-wise product of two skip-thought vectors as input.

== Evaluation ==
There are multiple methods that can be used to evaluate paraphrases. Since paraphrase recognition can be posed as a classification problem, most standard evaluations metrics such as [[accuracy]], [[f1 score]], or an [[receiver operating characteristic|ROC curve]] do relatively well. However, there is difficulty calculating f1-scores due to trouble produce a complete list of paraphrases for a given phrase along with the fact that good paraphrases are dependent upon context. A metric designed to counter these problems is ParaMetric.&lt;ref name=Burch2&gt;{{cite conference|last1=Callison-Burch|first1=Chris|last2=Cohn|first2=Trevor|last3=Lapata|first3=Mirella|title=ParaMetric: An Automatic Evaluation Metric for Paraphrasing|book-title=Proceedings of the 22nd International Conference on Computational Linguistics|place=Manchester|year=2008|pages=97–104|doi=10.3115/1599081.1599094|s2cid=837398|url=https://pdfs.semanticscholar.org/be0d/0df960833c1bea2a39ba9a17e5ca958018cd.pdf}}&lt;/ref&gt; ParaMetric aims to calculate the precision and recall of an automatic paraphrase system by comparing the automatic alignment of paraphrases to a manual alignment of similar phrases. Since ParaMetric is simply rating the quality of phrase alignment, it can be used to rate paraphrase generation systems as well assuming it uses phrase alignment as part of its generation process. A noted drawback to ParaMetric is the large and exhaustive set of manual alignments that must be initially created before a rating can be produced.

The evaluation of paraphrase generation has similar difficulties as the evaluation of [[machine translation]]. Often the quality of a paraphrase is dependent upon its context, whether it is being used as a summary, and how it is generated among other factors. Additionally, a good paraphrase usually is lexically dissimilar from its source phrase. The simplest method used to evaluate paraphrase generation would be through the use of human judges. Unfortunately, evaluation through human judges tends to be time consuming. Automated approaches to evaluation prove to be challenging as it is essentially a problem as difficult as paraphrase recognition. While originally used to evaluate machine translations, bilingual evaluation understudy ([[BLEU]]) has been used successfully to evaluate paraphrase generation models as well. However, paraphrases often have several lexically different but equally valid solutions which hurts BLEU and other similar evaluation metrics.&lt;ref name=Chen&gt;{{cite conference|last1=Chen|first1=David|last2=Dolan|first2=William|title=Collecting Highly Parallel Data for Paraphrase Evaluation|book-title=Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies|place=Portland, Oregon|year=2008|pages=190–200|url=https://dl.acm.org/citation.cfm?id=2002497}}&lt;/ref&gt;

Metrics specifically designed to evaluate paraphrase generation include paraphrase in n-gram change (PINC)&lt;ref name=Chen /&gt; and paraphrase evaluation metric (PEM)&lt;ref name=Liu&gt;{{cite conference|last1=Liu|first1=Chang|last2=Dahlmeier|first2=Daniel|last3=Ng|first3=Hwee Tou|title=PEM: A Paraphrase Evaluation Metric Exploiting Parallel Texts|book-title=Proceedings of the 2010 Conference on Empricial Methods in Natural Language Processing|place=MIT, Massachusetts|year=2010|pages=923–932|url=http://www.aclweb.org/anthology/D10-1090}}&lt;/ref&gt; along with the aforementioned ParaMetric. PINC is designed to be used in conjunction with BLEU and help cover its inadequacies. Since BLEU has difficulty measuring lexical dissimilarity, PINC is a measurement of the lack of n-gram overlap between a source sentence and a candidate paraphrase. It is essentially the [[Jaccard index|Jaccard distance]] between the sentence excluding n-grams that appear in the source sentence to maintain some semantic equivalence. PEM, on the other hand, attempts to evaluate the "adequacy, fluency, and lexical dissimilarity" of paraphrases by returning a single value heuristic calculated using [[N-gram]]s overlap in a pivot language. However, a large drawback to PEM is that must be trained using a large, in-domain parallel corpora as well as human judges.&lt;ref name=Chen /&gt; In other words, it is tantamount to training a paraphrase recognition system in order to evaluate a paraphrase generation system.

== See also ==
* [[Round-trip translation]]
* [[Text simplification]]
* [[Text normalization]]

== References ==
{{Reflist|30em}}

== External links ==
* [https://www.microsoft.com/en-us/download/details.aspx?id=52398 Microsoft Research Paraphrase Corpus] - a dataset consisting of 5800 pairs of sentences extracted from news articles annotated to note whether a pair captures semantic equivalence
* [http://paraphrase.org/#/ Paraphrase Database (PPDB)] - A searchable database containing millions of paraphrases in 16 different languages

[[Category:Computational linguistics]]
[[Category:Machine learning]]</text>
      <sha1>1vio8zsijhw855wd8e6sa8diwqn6wo1</sha1>
    </revision>
  </page>
  <page>
    <title>Life-time of correlation</title>
    <ns>0</ns>
    <id>31978226</id>
    <revision>
      <id>841008351</id>
      <parentid>840349133</parentid>
      <timestamp>2018-05-13T13:56:32Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>[[WP:GenFixes]] on, 3+ incoming mainspace links, removed orphan tag using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1637" xml:space="preserve">{{Multiple issues|
{{notability|date=September 2011}}
{{context|date=June 2011}}
{{cleanup|date=June 2011}}
}}

The '''life-time of correlation''' measures the timespan over which there is appreciable [[autocorrelation]] or [[cross correlation]] in [[stochastic process]]es.

==Definition==
{| class="wikitable" style="float:right;"
|-
! Correlation !! Negative !! Positive
|-
| Weak || −0.5 to 0.0 || 0.0 to 0.5
|-
| Strong || −1.0 to −0.5|| 0.5 to 1.0
|}

The [[Pearson product-moment correlation coefficient|correlation coefficient]] ''ρ'', expressed as an [[autocorrelation function]] or [[cross-correlation function]], depends on the lag-time between the times being considered. Typically such functions, ''ρ''(''t''), decay to zero with increasing lag-time, but they can assume values across all levels of correlations: strong and weak, and positive and negative as in the table.

The life-time of a correlation is defined as the length of time when the correlation coefficient is at the strong level.&lt;ref name="Buda"&gt;Buda, Andrzej; Jarynowski, Andrzej (2010) ''Life-time of correlations and its applications vol.1'', p.9, [Głogów] : Wydawnictwo Niezależne&lt;/ref&gt; The durability of correlation is determined by signal (the strong level of correlation is separated from weak and negative levels). The mean life-time of correlation could measure how the durability of correlation depends on the window width size (the window is the length of time series used to calculate correlation).

==References==
&lt;References/&gt;

[[Category:Stochastic processes]]
[[Category:Machine learning]]


{{probability-stub}}
{{statistics-stub}}</text>
      <sha1>ebs0xrvf9b00fet3wztxcxzaubzrmrl</sha1>
    </revision>
  </page>
  <page>
    <title>RAMnets</title>
    <ns>0</ns>
    <id>57261507</id>
    <revision>
      <id>965472600</id>
      <parentid>938380269</parentid>
      <timestamp>2020-07-01T14:35:46Z</timestamp>
      <contributor>
        <ip>2606:A000:7A0C:8700:8DA7:F9AC:AF97:5965</ip>
      </contributor>
      <comment>remove 'is still one of the best' because it is a) poor grammar and b) unsubstantiated with references</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="7658" xml:space="preserve">{{no footnotes|date=June 2018}}
'''RAMnets''' is one of the oldest practical neurally inspired classification [[algorithms]]. The RAMnets  is also known as a type of "''n''-tuple recognition method" or "weightless neural network".

==Algorithm==
[http://www.haralick.org/ML/NCRG_95_013.pdf Consider (let us say ''N'') sets of n distinct bit locations are selected randomly.] These are the ''n''-tuples. The restriction of a pattern to an n-tuple can be regarded as an ''n''-bit number which, together with the identity of the ''n''-tuple, constitutes a `feature' of the pattern. The standard ''n''-tuple recognizer operates simply as follows:

''A pattern is classified as belonging to the class for which it has the most features in common with at least one training pattern of that class.
''
This is the &lt;math&gt;\Theta&lt;/math&gt;= 0 case of a more general rule whereby the class assigned to unclassified pattern u is

   &lt;math&gt;\begin{align} \underset{c}argmax(\sum_{i=1}^N\Theta(\sum_{v\in D_{c}}\delta(\alpha_{i}(u),\alpha_{i}(v))))\end{align}&lt;/math&gt;

where D&lt;sub&gt;c&lt;/sub&gt; is the set of training patterns in class c, &lt;math&gt;\Theta(x)&lt;/math&gt;= x for &lt;math&gt;0\leq x\leq \theta&lt;/math&gt; ,&lt;math&gt;\Theta(x)=\theta&lt;/math&gt; for &lt;math&gt;x\geq\theta&lt;/math&gt;,&lt;math&gt;\delta_{i,j}&lt;/math&gt; is the [[Kronecker delta]](&lt;math&gt;\delta_{i,j}&lt;/math&gt;=1 if i=j and 0 otherwise.)and &lt;math&gt;(\alpha_{i}(u))&lt;/math&gt;is the i&lt;sup&gt;th&lt;/sup&gt; feature of the pattern u:

   &lt;math&gt;\sum_{j=0}^{n-1}u_\eta i(j)2^{j}&lt;/math&gt;

Here u&lt;sub&gt;k&lt;/sub&gt; is the k&lt;sup&gt;th&lt;/sup&gt; bit of u and &lt;math&gt;u_\eta i (j)&lt;/math&gt;is the j&lt;sup&gt;th&lt;/sup&gt; bit location of the i&lt;sup&gt;th&lt;/sup&gt; n-tuple.

With C classes to distinguish, the system can be implemented as a network of NC nodes, each of which is a random access memory (RAM); hence the term ''RAMnet.'' The memory content &lt;math&gt;m_{ci\alpha}&lt;/math&gt; at address &lt;math&gt;\alpha&lt;/math&gt;  of the i&lt;sup&gt;th&lt;/sup&gt; node allocated to class c is set to

    &lt;math&gt;m_{ci\alpha}&lt;/math&gt; = &lt;math&gt;\Theta(\sum_{v\in D_{c}}\delta(\alpha,\alpha_{i}(v)))&lt;/math&gt;

In the usual &lt;math&gt;\theta&lt;/math&gt; = 1 case, the 1-bit content of &lt;math&gt;m_{ci\alpha}&lt;/math&gt; is set if any pattern of D&lt;sub&gt;c&lt;/sub&gt; has feature &lt;math&gt;\alpha &lt;/math&gt; and unset otherwise. Recognition is  accomplished by summing the contents of the nodes of each class at the addresses given by the features of the unclassified pattern. That is, pattern '''u''' is assigned to class

    &lt;math&gt;\begin{align} \underset{c}argmax(\sum_{i=1}^N m_{ci\alpha}(u)) \end{align}&lt;/math&gt;

==RAM-discriminators and WiSARD ==
The RAMnets formed the basis of a commercial product known as WiSARD (Wilkie, Stonham and Aleksander Recognition Device) was the first artificial neural network machine to be patented.

A RAM-discriminator consists of a set of {{var|X}} one-bit word RAMs with {{var|n}} inputs and a summing device (Σ). Any such RAM-discriminator can receive a binary pattern of X⋅n bits as input. The RAM input lines are connected to the input pattern by means of a biunivocal pseudo-random mapping. The summing device enables this network of RAMs to exhibit – just like other ANN models based on synaptic weights – generalization and noise tolerance.

In order to train the discriminator one has to set all RAM memory locations to 0 and choose a training set formed by binary patterns of X⋅n bits. For each training pattern, a 1 is stored in the memory location of each RAM addressed by this input pattern. Once the training of patterns is completed, RAM memory contents will be set to a certain number of 0’s and 1’s.

The information stored by the RAM during the training phase is used to deal with previous unseen patterns. When one of these is given as input, the RAM memory contents addressed by the input pattern are read and summed by Σ. The number {{var|r}} thus obtained, which is called the discriminator response, is equal to the number of RAMs that output 1. r reaches the maximum {{var|X}} if the input belongs to the training set. {{var|r}} is equal to 0 if no ''n''-bit component of the input pattern appears in the training set (not a single RAM outputs 1). Intermediate values of r express a kind of “similarity measure” of the input pattern with respect to the patterns in the training set.

A system formed by various RAM-discriminators is called WiSARD. Each RAM-discriminator is trained on a particular class of patterns, and classification by the multi-discriminator system is performed in the following way. When a pattern is given as input, each RAM-discriminator gives a response to that input. The various responses are evaluated by an algorithm which compares them and computes the relative confidence {{var|c}} of the highest response (e.g., the difference d between the highest response and the second highest response, divided by the highest response). A schematic representation of a RAM-discriminator and a 10 RAM-discriminator WiSARD is shown in Figure 1.&lt;ref&gt;{{Cite book|title=Advances in computational intelligence and learning : 17th European Symposium on Artificial Neural Networks ; ESANN 2009 ; Bruges, Belgium, April 22-23-24, 2009 ; proceedings|date=2009|publisher=d-side|others=Verleysen, Michel, Université catholique de Louvain, ESANN (17 2009.04.22-24 Bruges), European Symposium on Artificial Neural Networks (17 2009.04.22-24 Bruges)|isbn=978-2930307091|location=Evere|oclc=553956424}}&lt;/ref&gt;

== See also ==
* [[Artificial Neural Network]]
* [[Kronecker delta]]
* [[Pattern Recognition]]
* [[Unsupervised learning]]
* [[Erlang distribution]]
* [[Machine learning]]
* [[Erlang (unit)]]

== References ==
{{reflist}}
* Michal Morciniec and Richard Rohwer(1995) "[http://www.haralick.org/ML/NCRG_95_013.pdf The n-tuple Classifier: Too Good to Ignore]"
* {{cite book |first1=Trevor |last1=Hastie |first2=Robert |last2=Tibshirani |title=The Elements of Statistical Learning: Data mining, Inference, and Prediction |year=2009 |publisher=Springer| location=New York |isbn=978-0-387-84857-0 |pages=485–586 |doi=10.1007/978-0-387-84858-7_14}}
* {{cite book |editor1=[[Geoffrey Hinton|Hinton, Geoffrey]] |editor2=[[Terrence J. Sejnowski|Sejnowski, Terrence J.]] |year=1999 |title=Unsupervised Learning: Foundations of Neural Computation |publisher=[[MIT Press]] |isbn=0-262-58168-X}} (This book focuses on unsupervised learning  in [[neural network]]s)
*{{cite journal|title=Generalization in probabilistic RAM nets|first=.G. Clarkson|last1= Y. Guan,J.G. Taylor,D. Gorse|journal=IEEE Transactions on Neural Networks|volume=4|issue=2|year=1993|doi=10.1109/72.207603|pmid=18267737|pages=360–363}}
*[https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2009-6.pdf A brief introduction to Weightless NeuralSystems] (2009)  

==Further reading==
# {{Cite book|title=N-Tuple Neural Networks|last=N. M. Allinson|first=A. R. Kolcz|publisher=Springer, Boston, MA|year=1997|isbn=978-1-4615-6099-9|location=Springer Science+Business Media New York}}
# {{cite book|last=Fukunaga|first=Keinosuke|title=Introduction to Statistical Pattern Recognition|edition=2nd|year=1990|publisher=Academic Press|location=Boston|isbn=0-12-269851-7|url-access=registration|url=https://archive.org/details/introductiontost1990fuku}}
# {{cite book|last1=Hornegger|first1=Joachim|last2=Paulus|first2=Dietrich W. R.|title=Applied Pattern Recognition: A Practical Introduction to Image and Speech Processing in C++|edition=2nd|year=1999|publisher=Morgan Kaufmann Publishers|location=San Francisco|isbn=3-528-15558-2}}
# [http://www.egmont-petersen.nl/classifiers.htm An introductory tutorial to classifiers (introducing the basic terms, with numeric example)]

[[Category:Machine learning]]
[[Category:Unsupervised learning]]</text>
      <sha1>19kvgdk477l0z5wggenmedclceu3bkn</sha1>
    </revision>
  </page>
  <page>
    <title>Multimodal sentiment analysis</title>
    <ns>0</ns>
    <id>57687371</id>
    <revision>
      <id>994703791</id>
      <parentid>980599147</parentid>
      <timestamp>2020-12-17T03:08:17Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 23 templates: del empty params (2×); hyphenate params (2×); cvt lang vals (1×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="15184" xml:space="preserve">'''Multimodal sentiment analysis''' is a new dimension{{peacock term|date=June 2018}} of the traditional text-based [[sentiment analysis]], which goes beyond the analysis of texts, and includes other [[Modality (human–computer interaction)|modalities]] such as audio and visual data.&lt;ref&gt;{{cite journal |last1=Soleymani |first1=Mohammad |last2=Garcia |first2=David |last3=Jou |first3=Brendan |last4=Schuller |first4=Björn |last5=Chang |first5=Shih-Fu |last6=Pantic |first6=Maja |title=A survey of multimodal sentiment analysis |journal=Image and Vision Computing |date=September 2017 |volume=65 |pages=3–14 |doi=10.1016/j.imavis.2017.08.003|url=https://zenodo.org/record/3449163 }}&lt;/ref&gt; It can be bimodal, which includes different combinations of two modalities, or trimodal, which incorporates three modalities.&lt;ref&gt;{{cite journal |last1=Karray |first1=Fakhreddine |last2=Milad |first2=Alemzadeh |last3=Saleh |first3=Jamil Abou |last4=Mo Nours |first4=Arab |title=Human-Computer Interaction: Overview on State of the Art |journal=International Journal on Smart Sensing and Intelligent Systems |volume=1 |pages=137–159 |date=2008 |url=http://s2is.org/Issues/v1/n1/papers/paper9.pdf|doi=10.21307/ijssis-2017-283 }}&lt;/ref&gt; With the extensive amount of [[social media]] data available online in different forms such as videos and images, the conventional text-based [[sentiment analysis]] has evolved into more complex models of multimodal sentiment analysis,&lt;ref name="s1"&gt;{{cite journal |last1=Poria |first1=Soujanya |last2=Cambria |first2=Erik |last3=Bajpai |first3=Rajiv |last4=Hussain |first4=Amir |title=A review of affective computing: From unimodal analysis to multimodal fusion |journal=Information Fusion |date=September 2017 |volume=37 |pages=98–125 |doi=10.1016/j.inffus.2017.02.003|hdl=1893/25490 |hdl-access=free }}&lt;/ref&gt; which can be applied in the development of  [[virtual assistant]]s,&lt;ref name ="s5"&gt;{{cite web |title=Google AI to make phone calls for you |url=https://www.bbc.com/news/technology-44045424 |website=BBC News |access-date=12 June 2018 |date=8 May 2018}}&lt;/ref&gt; [[Social media analytics|analysis]] of YouTube movie reviews,&lt;ref name="s4"&gt;{{cite journal |last1=Wollmer |first1=Martin |last2=Weninger |first2=Felix |last3=Knaup |first3=Tobias |last4=Schuller |first4=Bjorn |last5=Sun |first5=Congkai |last6=Sagae |first6=Kenji |last7=Morency |first7=Louis-Philippe |title=YouTube Movie Reviews: Sentiment Analysis in an Audio-Visual Context |journal=IEEE Intelligent Systems |date=May 2013 |volume=28 |issue=3 |pages=46–53 |doi=10.1109/MIS.2013.34|s2cid=12789201 }}&lt;/ref&gt; [[Social media analytics|analysis]] of news videos,&lt;ref&gt;{{cite arxiv|last1=Pereira |first1=Moisés H. R. |last2=Pádua |first2=Flávio L. C. |last3=Pereira |first3=Adriano C. M. |last4=Benevenuto |first4=Fabrício |last5=Dalip |first5=Daniel H. |title=Fusing Audio, Textual and Visual Features for Sentiment Analysis of News Videos|date=9 April 2016 |eprint=1604.02612|class=cs.CL }}&lt;/ref&gt; and [[emotion recognition]] (sometimes known as [[emotion]] detection) such as [[depression (mood)|depression]] monitoring,&lt;ref name = "s6"&gt;{{cite book |last1=Zucco |first1=Chiara |last2=Calabrese |first2=Barbara |last3=Cannataro |first3=Mario |title=Sentiment analysis and affective computing for depression monitoring |journal=2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM) |date=November 2017 |pages=1988–1995 |doi=10.1109/bibm.2017.8217966 |publisher=IEEE |language=en|isbn=978-1-5090-3050-7 |s2cid=24408937 }}&lt;/ref&gt; among others.

Similar to the traditional [[sentiment analysis]], one of the most basic task in multimodal sentiment analysis is [[Feeling|sentiment]] classification, which classifies different sentiments into categories such as positive, negative, or neutral.&lt;ref&gt;{{cite book |last1=Pang |first1=Bo |last2=Lee |first2=Lillian |title=Opinion mining and sentiment analysis |date=2008 |publisher=Now Publishers |location=Hanover, MA |isbn=978-1601981509}}&lt;/ref&gt; The complexity of [[Social media analytics|analyzing]] text, audio, and visual features to perform such a task requires the application of different fusion techniques, such as feature-level, decision-level, and hybrid fusion.&lt;ref name="s1" /&gt; The performance of these fusion techniques and the [[classification]] [[algorithm]]s applied, are influenced by the type of textual, audio, and visual features employed in the analysis.&lt;ref name = "s7" /&gt;

== Features ==
[[Feature engineering]], which involves the selection of features that are fed into [[machine learning]] algorithms, plays a key role in the sentiment classification performance.&lt;ref name = "s7"&gt;{{cite journal |last1=Sun |first1=Shiliang |last2=Luo |first2=Chen |last3=Chen |first3=Junyu |title=A review of natural language processing techniques for opinion mining systems |journal=Information Fusion |date=July 2017 |volume=36 |pages=10–25 |doi=10.1016/j.inffus.2016.10.004}}&lt;/ref&gt; In multimodal sentiment analysis, a combination of different textual, audio, and visual features are employed.&lt;ref name = "s1" /&gt;

=== Textual features ===
Similar to the conventional text-based [[sentiment analysis]], some of the most commonly used textual features in multimodal sentiment analysis are [[n-grams|unigrams]] and [[n-gram]]s, which are basically a sequence of words in a given textual document.&lt;ref&gt;{{cite journal |last1=Yadollahi |first1=Ali |last2=Shahraki |first2=Ameneh Gholipour |last3=Zaiane |first3=Osmar R. |title=Current State of Text Sentiment Analysis from Opinion to Emotion Mining |journal=ACM Computing Surveys |date=25 May 2017 |volume=50 |issue=2 |pages=1–33 |doi=10.1145/3057270|s2cid=5275807 }}&lt;/ref&gt; These features are applied using [[bag-of-words]] or bag-of-concepts feature representations, in which words or concepts are represented as vectors in a suitable space.&lt;ref name="s2"&gt;{{cite journal |last1=Perez Rosas |first1=Veronica |last2=Mihalcea |first2=Rada |last3=Morency |first3=Louis-Philippe |title=Multimodal Sentiment Analysis of Spanish Online Videos |journal=IEEE Intelligent Systems |date=May 2013 |volume=28 |issue=3 |pages=38–45 |doi=10.1109/MIS.2013.9|s2cid=1132247 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last1=Poria |first1=Soujanya |last2=Cambria |first2=Erik |last3=Hussain |first3=Amir |last4=Huang |first4=Guang-Bin |title=Towards an intelligent framework for multimodal affective data analysis |journal=Neural Networks |date=March 2015 |volume=63 |pages=104–116 |doi=10.1016/j.neunet.2014.10.005|pmid=25523041 |hdl=1893/21310 |hdl-access=free }}&lt;/ref&gt;

=== Audio features ===
[[Feeling|Sentiment]] and [[emotion]] characteristics are prominent in different [[phonetic]] and [[prosodic]] properties contained in audio features.&lt;ref&gt;{{cite journal |last1=Chung-Hsien Wu |last2=Wei-Bin Liang |title=Emotion Recognition of Affective Speech Based on Multiple Classifiers Using Acoustic-Prosodic Information and Semantic Labels |journal=IEEE Transactions on Affective Computing |date=January 2011 |volume=2 |issue=1 |pages=10–21 |doi=10.1109/T-AFFC.2010.16|s2cid=52853112 }}&lt;/ref&gt; Some of the most important audio features employed in multimodal sentiment analysis are [[mel-frequency cepstrum| mel-frequency cepstrum (MFCC)]], [[spectral centroid]], [[spectral flux]], beat histogram, beat sum, strongest beat, pause duration, and [[pitch accent|pitch]].&lt;ref name="s1" /&gt; [[OpenSMILE]]&lt;ref&gt;{{cite book |last1=Eyben |first1=Florian |last2=Wöllmer |first2=Martin |last3=Schuller |first3=Björn |title=OpenEAR — Introducing the munich open-source emotion and affect recognition toolkit - IEEE Conference Publication |pages=1 |date=2009 |doi=10.1109/ACII.2009.5349350 |isbn=978-1-4244-4800-5 |chapter=OpenEAR — Introducing the munich open-source emotion and affect recognition toolkit |s2cid=2081569 }}&lt;/ref&gt; and [[Praat]] are popular open-source toolkits for extracting such audio features.&lt;ref&gt;{{cite book|last1=Morency |first1=Louis-Philippe |last2=Mihalcea |first2=Rada |last3=Doshi |first3=Payal |title=Towards multimodal sentiment analysis: harvesting opinions from the web |date=14 November 2011 |pages=169–176 |doi=10.1145/2070481.2070509 |publisher=ACM|chapter=Towards multimodal sentiment analysis |isbn=9781450306416 |s2cid=1257599 }}&lt;/ref&gt;

=== Visual features ===
One of the main advantages of analyzing videos with respect to texts alone, is the presence of rich sentiment cues in visual data.&lt;ref&gt;{{cite journal |last1=Poria |first1=Soujanya |last2=Cambria |first2=Erik |last3=Hazarika |first3=Devamanyu |last4=Majumder |first4=Navonil |last5=Zadeh |first5=Amir |last6=Morency |first6=Louis-Philippe |title=Context-Dependent Sentiment Analysis in User-Generated Videos |journal=Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) |pages=873–883 |date=2017 |doi=10.18653/v1/p17-1081 |doi-access=free }}&lt;/ref&gt; Visual features include [[facial expression]]s, which are of paramount importance in capturing sentiments and [[emotion]]s, as they are a main channel of forming a person's present state of mind.&lt;ref name="s1" /&gt; Specifically, [[smile]], is considered to be one of the most predictive visual cues in multimodal sentiment analysis.&lt;ref name="s2" /&gt; OpenFace is an open-source facial analysis toolkit available for extracting and understanding such visual features.&lt;ref&gt;{{cite journal |title=OpenFace: An open source facial behavior analysis toolkit - IEEE Conference Publication |doi= 10.1109/WACV.2016.7477553|s2cid= 1919851|url= https://www.repository.cam.ac.uk/handle/1810/280724}}&lt;/ref&gt;

== Fusion techniques ==
Unlike the traditional text-based [[sentiment analysis]], multimodal sentiment analysis undergo a fusion process in which data from different modalities (text, audio, or visual) are fused and analyzed together.&lt;ref name ="s1" /&gt; The existing approaches in multimodal sentiment analysis [[data fusion]] can be grouped into three main categories: feature-level, decision-level, and hybrid fusion, and the performance of the sentiment classification depends on which type of fusion technique is employed.&lt;ref name ="s1" /&gt;

=== Feature-level fusion ===
Feature-level fusion (sometimes known as early fusion) gathers all the features from each [[modality (human–computer interaction)|modality]] (text, audio, or visual) and joins them together into a single feature vector, which is eventually fed into a classification algorithm.&lt;ref name="s3"&gt;{{cite journal |last1=Poria |first1=Soujanya |last2=Cambria |first2=Erik |last3=Howard |first3=Newton |last4=Huang |first4=Guang-Bin |last5=Hussain |first5=Amir |title=Fusing audio, visual and textual clues for sentiment analysis from multimodal content |journal=Neurocomputing |date=January 2016 |volume=174 |pages=50–59 |doi=10.1016/j.neucom.2015.01.095}}&lt;/ref&gt; One of the difficulties in implementing this technique is the integration of the heterogeneous features.&lt;ref name="s1" /&gt;

=== Decision-level fusion ===
Decision-level fusion (sometimes known as late fusion), feeds data from each modality (text, audio, or visual) independently into its own classification algorithm, and obtains the final sentiment classification results by fusing each result into a single decision vector.&lt;ref name="s3" /&gt; One of the advantages of this fusion technique is that it eliminates the need to fuse heterogeneous data, and each [[modality (human–computer interaction)|modality]] can utilize its most appropriate [[classification]] [[algorithm]].&lt;ref name="s1" /&gt;

=== Hybrid fusion ===
Hybrid fusion is a combination of feature-level and decision-level fusion techniques, which exploits complementary information from both methods during the classification process.&lt;ref name="s4" /&gt; It usually involves a two-step procedure wherein feature-level fusion is initially performed between two modalities, and decision-level fusion is then applied as a second step, to fuse the initial results from the feature-level fusion, with the remaining [[Modality (human–computer interaction)|modality]].&lt;ref&gt;{{cite journal |last1=Shahla |first1=Shahla |last2=Naghsh-Nilchi |first2=Ahmad Reza |title=Exploiting evidential theory in the fusion of textual, audio, and visual modalities for affective music video retrieval - IEEE Conference Publication |date=2017 |doi=10.1109/PRIA.2017.7983051 |s2cid=24466718 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last1=Poria |first1=Soujanya |last2=Peng |first2=Haiyun |last3=Hussain |first3=Amir |last4=Howard |first4=Newton |last5=Cambria |first5=Erik |title=Ensemble application of convolutional neural networks and multiple kernel learning for multimodal sentiment analysis |journal=Neurocomputing |date=October 2017 |volume=261 |pages=217–230 |doi=10.1016/j.neucom.2016.09.117}}&lt;/ref&gt;

== Applications ==
Similar to text-based sentiment analysis, multimodal sentiment analysis can be applied in the development of different forms of [[recommender system]]s such as in the analysis of user-generated videos of movie reviews&lt;ref name="s4" /&gt; and general product reviews,&lt;ref&gt;{{cite journal |last1=Pérez-Rosas |first1=Verónica |last2=Mihalcea |first2=Rada |last3=Morency |first3=Louis Philippe |title=Utterance-level multimodal sentiment analysis |journal=Long Papers |date=1 January 2013 |url=https://experts.umich.edu/en/publications/utterance-level-multimodal-sentiment-analysis |publisher=Association for Computational Linguistics (ACL)}}&lt;/ref&gt; to predict the sentiments of customers, and subsequently create product or service recommendations.&lt;ref&gt;{{cite web |last1=Chui |first1=Michael |last2=Manyika |first2=James |last3=Miremadi |first3=Mehdi |last4=Henke |first4=Nicolaus |last5=Chung |first5=Rita |last6=Nel |first6=Pieter |last7=Malhotra |first7=Sankalp |title=Notes from the AI frontier. Insights from hundreds of use cases |url=https://www.mckinsey.com/mgi/ |website=McKinsey &amp; Company |publisher=McKinsey &amp; Company |access-date=13 June 2018 |language=en}}&lt;/ref&gt; Multimodal sentiment analysis also plays an important role in the advancement of [[virtual assistant]]s through the application of [[natural language processing]] (NLP) and [[machine learning]] techniques.&lt;ref name ="s5" /&gt; In the healthcare domain, multimodal sentiment analysis can be utilized to detect certain medical conditions such as [[Psychological stress|stress]], [[anxiety]], or [[Depression (mood)|depression]].&lt;ref name = "s6" /&gt; Multimodal sentiment analysis can also be applied in understanding the sentiments contained in video news programs, which is considered as a complicated and challenging domain, as sentiments expressed by reporters tend to be less obvious or neutral.&lt;ref&gt;{{cite book|last1=Ellis |first1=Joseph G. |last2=Jou |first2=Brendan |last3=Chang |first3=Shih-Fu |title=Why We Watch the News: A Dataset for Exploring Sentiment in Broadcast Video News |date=12 November 2014 |pages=104–111 |doi=10.1145/2663204.2663237 |publisher=ACM|chapter=Why We Watch the News |isbn=9781450328852 |s2cid=14112246 }}&lt;/ref&gt;

==References==
{{Reflist}}

[[Category:Natural language processing]]
[[Category:Affective computing]]
[[Category:Social media]]
[[Category:Machine learning]]
[[Category:Multimodal interaction]]</text>
      <sha1>f0x2ssut1c4pjp38ea8y1jecxo6atqx</sha1>
    </revision>
  </page>
  <page>
    <title>Anomaly detection</title>
    <ns>0</ns>
    <id>8190902</id>
    <revision>
      <id>1000256053</id>
      <parentid>996877039</parentid>
      <timestamp>2021-01-14T10:19:18Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>FIx REFPUNCT + other minor fixes</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="21156" xml:space="preserve">{{broader|Outlier}}
In [[data analysis]], '''anomaly detection''' (also '''outlier detection''')&lt;ref name=":0"&gt;{{Citation|last1=Zimek|first1=Arthur|title=Outlier Detection|date=2017|encyclopedia=Encyclopedia of Database Systems|pages=1–5|publisher=Springer New York|doi=10.1007/978-1-4899-7993-3_80719-1|isbn=9781489979933|last2=Schubert|first2=Erich}}&lt;/ref&gt; is the identification of rare items, events or observations which raise suspicions by differing significantly from the majority of the data.&lt;ref name=":0" /&gt; Typically the anomalous items will translate to some kind of problem such as [[bank fraud]], a structural defect, medical problems or errors in a text. Anomalies are also referred to as [[outlier]]s, novelties, noise, deviations and exceptions.&lt;ref&gt;{{cite journal | last1 = Hodge | first1 = V. J. | last2 = Austin | first2 = J. | doi = 10.1007/s10462-004-4304-y | title = A Survey of Outlier Detection Methodologies | journal = Artificial Intelligence Review| volume = 22 | issue = 2 | pages = 85–126 | year = 2004 | url = http://eprints.whiterose.ac.uk/767/1/hodgevj4.pdf| citeseerx = 10.1.1.318.4023 | s2cid = 3330313 }}&lt;/ref&gt;

In particular, in the context of abuse and network intrusion detection, the interesting objects are often not ''rare'' objects, but unexpected ''bursts'' in activity. This pattern does not adhere to the common statistical definition of an outlier as a rare object, and many outlier detection methods (in particular unsupervised methods) will fail on such data, unless it has been aggregated appropriately. Instead, a [[cluster analysis]] algorithm may be able to detect the micro clusters formed by these patterns.&lt;ref&gt;{{cite journal| first1=Paul | last1=Dokas | first2=Levent |last2=Ertoz |first3=Vipin |last3=Kumar |first4=Aleksandar |last4=Lazarevic |first5=Jaideep |last5=Srivastava |first6=Pang-Ning |last6=Tan | title=Data mining for network intrusion detection | year=2002 | journal=Proceedings NSF Workshop on Next Generation Data Mining | url=http://www.csee.umbc.edu/~kolari1/Mining/ngdm/dokas.pdf}}&lt;/ref&gt;

Three broad categories of anomaly detection techniques exist.&lt;ref name="ChandolaSurvey"&gt;{{cite journal|last1=Chandola|first1=V.|last2=Banerjee|first2=A.|last3=Kumar|first3=V.|s2cid=207172599|year=2009|title=Anomaly detection: A survey|journal=[[ACM Computing Surveys]]|volume=41|issue=3|pages=1–58|doi=10.1145/1541880.1541882}}&lt;/ref&gt; '''Unsupervised anomaly detection''' techniques detect anomalies in an unlabeled test data set under the assumption that the majority of the instances in the data set are normal by looking for instances that seem to fit least to the remainder of the data set. '''Supervised anomaly detection''' techniques require a data set that has been labeled as "normal" and "abnormal" and involves training a classifier (the key difference to many other [[statistical classification]] problems is the inherent unbalanced nature of outlier detection). '''Semi-supervised anomaly detection''' techniques construct a model representing normal behavior from a given ''normal'' training data set, and then test the likelihood of a test instance to be generated by the learnt model.

== Applications ==
Anomaly detection is applicable in a variety of domains, such as [[intrusion detection]], [[fraud detection]], fault detection, system health monitoring, event detection in sensor networks, and detecting ecosystem disturbances. It is often used in [[Data pre-processing|preprocessing]] to remove anomalous data from the dataset. In [[supervised learning]], removing the anomalous data from the dataset often results in a statistically significant increase in accuracy.&lt;ref&gt;{{cite journal | doi = 10.1109/TSMC.1976.4309523 | first = Ivan | last = Tomek| title = An Experiment with the Edited Nearest-Neighbor Rule | journal = [[IEEE Systems, Man, and Cybernetics Society|IEEE Transactions on Systems, Man, and Cybernetics]]| volume = 6 | issue = 6 | pages = 448–452 | year = 1976 }}&lt;/ref&gt;&lt;ref&gt;{{cite book | last1 = Smith | first1 = M. R. | last2 = Martinez | first2 = T. | doi = 10.1109/IJCNN.2011.6033571 | chapter = Improving classification accuracy by identifying and removing instances that should be misclassified | title = The 2011 International Joint Conference on Neural Networks | pages = 2690 | year = 2011 | isbn = 978-1-4244-9635-8 | chapter-url = http://axon.cs.byu.edu/papers/smith.ijcnn2011.pdf| citeseerx = 10.1.1.221.1371 | s2cid = 5809822 }}&lt;/ref&gt;

== Popular techniques ==
Several anomaly detection techniques have been proposed in literature.&lt;ref name="ZimekFilzmoser2018"&gt;{{cite journal|last1=Zimek|first1=Arthur|last2=Filzmoser|first2=Peter|title=There and back again: Outlier detection between statistical reasoning and data mining algorithms|journal=Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery|volume=8|issue=6|year=2018|pages=e1280|issn=1942-4787|doi=10.1002/widm.1280|url=https://findresearcher.sdu.dk:8443/ws/files/153197807/There_and_Back_Again.pdf}}&lt;/ref&gt; Some of the popular techniques are:

* Density-based techniques ([[K-nearest neighbor algorithm|k-nearest neighbor]],&lt;ref&gt;{{cite journal | doi = 10.1007/s007780050006| title = Distance-based outliers: Algorithms and applications| journal = The VLDB Journal the International Journal on Very Large Data Bases| volume = 8| issue = 3–4| pages = 237–253| year = 2000| last1 = Knorr | first1 = E. M. | last2 = Ng | first2 = R. T. | last3 = Tucakov | first3 = V. | citeseerx = 10.1.1.43.1842| s2cid = 11707259}}&lt;/ref&gt;&lt;ref&gt;{{cite conference | doi = 10.1145/342009.335437| title = Efficient algorithms for mining outliers from large data sets| conference = Proceedings of the 2000 ACM SIGMOD international conference on Management of data – SIGMOD '00| pages = 427| year = 2000| last1 = Ramaswamy | first1 = S. | last2 = Rastogi | first2 = R. | last3 = Shim | first3 = K. | isbn = 1-58113-217-4}}&lt;/ref&gt;&lt;ref&gt;{{cite conference | doi = 10.1007/3-540-45681-3_2| title = Fast Outlier Detection in High Dimensional Spaces| conference = Principles of Data Mining and Knowledge Discovery| volume = 2431| pages = 15| series = Lecture Notes in Computer Science| year = 2002| last1 = Angiulli | first1 = F. | last2 = Pizzuti | first2 = C. | isbn = 978-3-540-44037-6| doi-access = free}}&lt;/ref&gt; [[local outlier factor]],&lt;ref&gt;{{cite conference| doi = 10.1145/335191.335388| title = LOF: Identifying Density-based Local Outliers| year = 2000| last1 = Breunig | first1 = M. M.| last2 = Kriegel | first2 = H.-P. | author-link2 = Hans-Peter Kriegel| last3 = Ng | first3 = R. T.| last4 = Sander | first4 = J.| work = Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data| series = [[SIGMOD]]| isbn = 1-58113-217-4| pages = 93–104| url = http://www.dbs.ifi.lmu.de/Publikationen/Papers/LOF.pdf}}&lt;/ref&gt; [[isolation forest]]s,&lt;ref&gt;{{Cite book|last1=Liu|first1=Fei Tony|last2=Ting|first2=Kai Ming|last3=Zhou|first3=Zhi-Hua|date=December 2008|title=Isolation Forest|url=https://www.computer.org/csdl/proceedings/icdm/2008/3502/00/3502a413-abs.html|journal=2008 Eighth IEEE International Conference on Data Mining|language=en|pages=413–422|doi=10.1109/ICDM.2008.17|isbn=9780769535029|s2cid=6505449}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last1=Liu|first1=Fei Tony|last2=Ting|first2=Kai Ming|last3=Zhou|first3=Zhi-Hua|date=March 2012|title=Isolation-Based Anomaly Detection|url=https://www.researchgate.net/publication/239761771|journal=ACM Transactions on Knowledge Discovery from Data |language=en|volume=6|issue=1|pages=1–39|doi=10.1145/2133360.2133363|s2cid=207193045}}&lt;/ref&gt; and many more variations of this concept&lt;ref&gt;{{cite journal | last1 = Schubert | first1 = E. | last2 = Zimek | first2 = A. | author-link2 = Arthur Zimek | last3 = Kriegel | first3 = H. -P. | s2cid = 19036098 | author-link3 = Hans-Peter Kriegel| doi = 10.1007/s10618-012-0300-z | title = Local outlier detection reconsidered: A generalized view on locality with applications to spatial, video, and network outlier detection | journal = Data Mining and Knowledge Discovery | volume = 28 | pages = 190–237 | year = 2012 }}&lt;/ref&gt;).
* Subspace-,&lt;ref&gt;{{cite conference | doi = 10.1007/978-3-642-01307-2_86| title = Outlier Detection in Axis-Parallel Subspaces of High Dimensional Data| conference = Advances in Knowledge Discovery and Data Mining| volume = 5476| pages = 831| series = Lecture Notes in Computer Science| year = 2009| last1 = Kriegel | first1 = H. P. | author-link1 = Hans-Peter Kriegel| last2 = Kröger | first2 = P. | last3 = Schubert | first3 = E. | last4 = Zimek | first4 = A. | author-link4 = Arthur Zimek | isbn = 978-3-642-01306-5}}&lt;/ref&gt; correlation-based&lt;ref&gt;{{cite conference | doi = 10.1109/ICDM.2012.21| title = Outlier Detection in Arbitrarily Oriented Subspaces| conference = 2012 IEEE 12th International Conference on Data Mining| pages = 379| year = 2012| last1 = Kriegel | first1 = H. P. | author-link1 = Hans-Peter Kriegel| last2 = Kroger | first2 = P. | last3 = Schubert | first3 = E. | last4 = Zimek | first4 = A. | author-link4 = Arthur Zimek | isbn = 978-1-4673-4649-8}}&lt;/ref&gt; and tensor-based &lt;ref&gt;{{cite journal | last1 = Fanaee-T| first1 = H. | last2 = Gama | first2 = J.| title = Tensor-based anomaly detection: An interdisciplinary survey | doi = 10.1016/j.knosys.2016.01.027 | journal = Knowledge-Based Systems | volume = 98 | pages = 130–147| year = 2016| url = http://repositorio.inesctec.pt/handle/123456789/5381 }}&lt;/ref&gt; outlier detection for high-dimensional data.&lt;ref&gt;{{cite journal | last1 = Zimek | first1 = A. | author-link1 = Arthur Zimek | last2 = Schubert | first2 = E.| last3 = Kriegel | first3 = H.-P. | author-link3=Hans-Peter Kriegel| title = A survey on unsupervised outlier detection in high-dimensional numerical data | doi = 10.1002/sam.11161 | journal = Statistical Analysis and Data Mining | volume = 5 | issue = 5 | pages = 363–387| year = 2012 }}&lt;/ref&gt;
* One-class [[support vector machines]].&lt;ref&gt;{{cite journal | doi = 10.1162/089976601750264965| pmid = 11440593| title = Estimating the Support of a High-Dimensional Distribution| journal = Neural Computation| volume = 13| issue = 7| pages = 1443–71| year = 2001| last1 = Schölkopf | first1 = B. | last2 = Platt | first2 = J. C. | last3 = Shawe-Taylor | first3 = J. | last4 = Smola | first4 = A. J. | last5 = Williamson | first5 = R. C. | citeseerx = 10.1.1.4.4106| s2cid = 2110475}}&lt;/ref&gt;
* Replicator [[neural network]]s.,&lt;ref name="replicator"&gt;{{cite book |doi=10.1007/3-540-46145-0_17 |chapter=Outlier Detection Using Replicator Neural Networks |title=Data Warehousing and Knowledge Discovery |volume=2454 |pages=170–180 |year=2002 |last1=Hawkins |first1=Simon |last2=He |first2=Hongxing |last3=Williams |first3=Graham |last4=Baxter |first4=Rohan |isbn=978-3-540-44123-6 |series=Lecture Notes in Computer Science |citeseerx=10.1.1.12.3366 }}&lt;/ref&gt; [[Autoencoder#Anomaly Detection|autoencoder]]s, variational autoencoders,&lt;ref&gt;J. An and S. Cho, "Variational autoencoder based anomaly detection using reconstruction probability", 2015.&lt;/ref&gt; [[long short-term memory]] neural networks&lt;ref&gt;{{Cite conference|last1=Malhotra|first1=Pankaj|last2=Vig|first2=Lovekesh|last3=Shroff|first3=Gautman|last4=Agarwal|first4=Puneet|title=Long Short Term Memory Networks for Anomaly Detection in Time Series|url=https://www.researchgate.net/publication/304782562|conference=European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning|language=en|date=22–24 April 2015|location=Bruges (Belgium)}}&lt;/ref&gt;
* [[Bayesian network]]s.&lt;ref name="replicator"/&gt;
* [[Hidden Markov model]]s (HMMs).&lt;ref name="replicator"/&gt;
* [[Cluster analysis]]-based outlier detection.&lt;ref&gt;{{cite journal | doi = 10.1016/S0167-8655(03)00003-5| title = Discovering cluster-based local outliers| journal = Pattern Recognition Letters| volume = 24| issue = 9–10| pages = 1641–1650| year = 2003| last1 = He | first1 = Z. | last2 = Xu | first2 = X. | last3 = Deng | first3 = S. | citeseerx = 10.1.1.20.4242}}&lt;/ref&gt;&lt;ref&gt;{{cite journal
| first1 = R. J. G. B. | last1 = Campello
| first2 = D. | last2 = Moulavi
| first3 = A. | last3 = Zimek | author-link3 = Arthur Zimek 
| first4 = J. | last4 = Sander
| s2cid = 2887636
| title = Hierarchical Density Estimates for Data Clustering, Visualization, and Outlier Detection
| journal = ACM Transactions on Knowledge Discovery from Data
| volume = 10 | issue = 1 | pages = 5:1–51 | year = 2015 | doi = 10.1145/2733381}}&lt;/ref&gt;
* Deviations from [[association rule learning|association rules]] and frequent itemsets.
* Fuzzy logic-based outlier detection.
* [[Ensemble learning|Ensemble techniques]], using [[random subspace method|feature bagging]],&lt;ref&gt;{{cite book| doi = 10.1145/1081870.1081891| title = Feature bagging for outlier detection| year = 2005| last1 = Lazarevic | first1 = A.| last2 = Kumar | first2 = V.| pages = 157–166| journal = Proc. 11th ACM SIGKDD International Conference on Knowledge Discovery in Data Mining| isbn = 978-1-59593-135-1| citeseerx = 10.1.1.399.425| s2cid = 2054204}}&lt;/ref&gt;&lt;ref&gt;{{cite conference | doi = 10.1007/978-3-642-12026-8_29| title = Mining Outliers with Ensemble of Heterogeneous Detectors on Random Subspaces| conference = Database Systems for Advanced Applications| volume = 5981| pages = 368| series = Lecture Notes in Computer Science| year = 2010| last1 = Nguyen | first1 = H. V. | last2 = Ang | first2 = H. H. | last3 = Gopalkrishnan | first3 = V. | isbn = 978-3-642-12025-1}}&lt;/ref&gt; score normalization&lt;ref&gt;{{cite conference | doi = 10.1137/1.9781611972818.2| title = Interpreting and Unifying Outlier Scores| conference = Proceedings of the 2011 SIAM International Conference on Data Mining| pages = 13–24| year = 2011| last1 = Kriegel | first1 = H. P. | author-link1 = Hans-Peter Kriegel| last2 = Kröger | first2 = P. | last3 = Schubert | first3 = E. | last4 = Zimek | first4 = A. | author-link4 = Arthur Zimek | isbn = 978-0-89871-992-5| citeseerx = 10.1.1.232.2719}}&lt;/ref&gt;&lt;ref&gt;{{cite conference | doi = 10.1137/1.9781611972825.90| title = On Evaluation of Outlier Rankings and Outlier Scores| conference = Proceedings of the 2012 SIAM International Conference on Data Mining| pages = 1047–1058| year = 2012| last1 = Schubert | first1 = E. | last2 = Wojdanowski | first2 = R. | last3 = Zimek | first3 = A. | author-link3 = Arthur Zimek | last4 = Kriegel | first4 = H. P. | author-link4 = Hans-Peter Kriegel| isbn = 978-1-61197-232-0}}&lt;/ref&gt; and different sources of diversity.&lt;ref&gt;{{cite journal | doi = 10.1145/2594473.2594476| title = Ensembles for unsupervised outlier detection| journal = ACM SIGKDD Explorations Newsletter| volume = 15| pages = 11–22| year = 2014| last1 = Zimek | first1 = A. | author-link1 = Arthur Zimek | last2 = Campello | first2 = R. J. G. B. | last3 = Sander | first3 = J. R. | s2cid = 8065347}}&lt;/ref&gt;&lt;ref&gt;{{cite conference | doi = 10.1145/2618243.2618257| title = Data perturbation for outlier detection ensembles| conference = Proceedings of the 26th International Conference on Scientific and Statistical Database Management – SSDBM '14| pages = 1| year = 2014| last1 = Zimek | first1 = A. | author-link1 = Arthur Zimek | last2 = Campello | first2 = R. J. G. B. | last3 = Sander | first3 = J. R. | isbn = 978-1-4503-2722-0}}&lt;/ref&gt;

The performance of different methods depends a lot on the data set and parameters, and methods have little systematic advantages over another when compared across many data sets and parameters.&lt;ref name="CamposZimek2016"&gt;{{cite journal|last1=Campos|first1=Guilherme O.|last2=Zimek|first2=Arthur|author-link2=Arthur Zimek|last3=Sander|first3=Jörg|last4=Campello|first4=Ricardo J. G. B.|last5=Micenková|first5=Barbora|last6=Schubert|first6=Erich|last7=Assent|first7=Ira|last8=Houle|first8=Michael E.|s2cid=1952214|title=On the evaluation of unsupervised outlier detection: measures, datasets, and an empirical study|journal=Data Mining and Knowledge Discovery|volume=30|issue=4|pages=891|year=2016|issn=1384-5810|doi=10.1007/s10618-015-0444-8}}&lt;/ref&gt;&lt;ref&gt;[http://www.dbs.ifi.lmu.de/research/outlier-evaluation/ Anomaly detection benchmark data repository] of the [[Ludwig-Maximilians-Universität München]]; [http://lapad-web.icmc.usp.br/repositories/outlier-evaluation/ Mirror] at [[University of São Paulo]].&lt;/ref&gt;

== Application to data security ==
Anomaly detection was proposed for [[intrusion detection systems]] (IDS) by [[Dorothy E. Denning|Dorothy Denning]] in 1986.&lt;ref&gt;{{cite journal | last1 = Denning | first1 = D. E. | author-link1 = Dorothy E. Denning| doi = 10.1109/TSE.1987.232894 | title = An Intrusion-Detection Model | journal = [[IEEE Transactions on Software Engineering]]| issue = 2 | pages = 222–232 | year = 1987 | url = http://www.dtic.mil/dtic/tr/fulltext/u2/a484998.pdf| citeseerx=10.1.1.102.5127 | volume=SE-13| s2cid = 10028835 }}&lt;/ref&gt; Anomaly detection for IDS is normally accomplished with thresholds and statistics, but can also be done with [[soft computing]], and inductive learning.&lt;ref&gt;{{cite book | last1 = Teng | first1 = H. S. | last2 = Chen | first2 = K. | last3 = Lu | first3 = S. C. | doi = 10.1109/RISP.1990.63857 | title = Adaptive real-time anomaly detection using inductively generated sequential patterns | journal =Proceedings of the IEEE Computer Society Symposium on Research in Security and Privacy| pages = 278–284| year = 1990 | isbn = 978-0-8186-2060-7 | s2cid = 35632142 | url = http://www.cs.unc.edu/~jeffay/courses/nidsS05/ai/Teng-AdaptiveRTAnomaly-SnP90.pdf}}&lt;/ref&gt; Types of statistics proposed by 1999 included profiles of users, workstations, networks, remote hosts, groups of users, and programs based on frequencies, means, variances, covariances, and standard deviations.&lt;ref&gt;{{cite journal | last1 = Jones | first1 = Anita K. | last2 = Sielken | first2 = Robert S. | title = Computer System Intrusion Detection: A Survey | journal= Technical Report, Department of Computer Science, University of Virginia, Charlottesville, VA | year= 1999 | citeseerx=10.1.1.24.7802 }}&lt;/ref&gt;  The counterpart of anomaly detection in [[intrusion detection]] is [[misuse detection]].

== In data pre-processing ==
In supervised learning, anomaly detection is often an important step in data pre-processing to provide the learning algorithm a proper dataset to learn on. This is also known as [[Data cleansing]].  After detecting anomalous samples classifiers remove them, however, at times corrupted data can still provide useful samples for learning. A common method for finding appropriate samples to use is identifying [[Noisy data]]. One approach to find noisy values is to create a probabilistic model from data using models of uncorrupted data and corrupted data.&lt;ref&gt;{{Cite journal|last=Kubica|first=J.|last2=Moore|first2=A.|title=Probabilistic noise identification and data cleaning|url=http://dx.doi.org/10.1109/icdm.2003.1250912|journal=Third IEEE International Conference on Data Mining|publisher=IEEE Comput. Soc|doi=10.1109/icdm.2003.1250912|isbn=0-7695-1978-4}}&lt;/ref&gt;

Below is an example of the [[Iris flower data set]] with an anomaly added. With an anomaly included, classification algorithm may have difficulties properly finding patterns, or run into errors. 
{| class="wikitable mw-collapsible"
|+Fischer's Iris Data with an Anomaly
!Dataset order
!Sepal length
!Sepal width
!Petal length
!Petal width
!Species
|-
|1
|5.1
|3.5
|1.4
|0.2
|I. setosa
|-
|2
|4.9
|3.0
|1.4
|0.2
|I. setosa
|-
|3
|4.7
|3.2
|1.3
|0.2
|I. setosa
|-
|4
|4.6
|3.1
|1.5
|0.2
|I. setosa
|-
|5
|5.0
|NULL
|1.4
|NULL
|I. setosa
|}
By removing the anomaly, training will be enabled to find patterns in classifications more easily.

In data mining, high-dimensional data will also propose high computing challenges with intensely large sets of data. By removing numerous samples that can find itself irrelevant to a classifier or detection algorithm, runtime can be significantly reduced on even the largest sets of data.

== Software ==
* [[ELKI]] is an open-source Java data mining toolkit that contains several anomaly detection algorithms, as well as index acceleration for them.
*[[Scikit-learn|Scikit-Learn]] is an open-source Python library that has built functionality to provide unsupervised anomaly detection.

== Datasets ==
* [http://www.dbs.ifi.lmu.de/research/outlier-evaluation/ Anomaly detection benchmark data repository] of the [[Ludwig-Maximilians-Universität München]]; [http://lapad-web.icmc.usp.br/repositories/outlier-evaluation/ Mirror] at [[University of São Paulo]].
* [http://odds.cs.stonybrook.edu/ ODDS] – ODDS: A large collection of publicly available outlier detection datasets with ground truth in different domains.
* [https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/OPQMVF Unsupervised Anomaly Detection Benchmark] at Harvard Dataverse: Datasets for Unsupervised Anomaly Detection with ground truth.

== See also ==
* [[Change detection]]
* [[Statistical process control]]
* [[Novelty detection]]
* [[Hierarchical temporal memory]]

== References ==
{{Reflist|30em}}

[[Category:Data mining]]
[[Category:Machine learning]]
[[Category:Data security]]
[[Category:Statistical outliers]]</text>
      <sha1>gclh5fz8dhhz9v5lks5a7j3t6zuoaey</sha1>
    </revision>
  </page>
  <page>
    <title>Novelty detection</title>
    <ns>0</ns>
    <id>12656117</id>
    <revision>
      <id>918885551</id>
      <parentid>914179387</parentid>
      <timestamp>2019-09-30T18:49:48Z</timestamp>
      <contributor>
        <username>Me, Myself, and I are Here</username>
        <id>17619453</id>
      </contributor>
      <minor/>
      <comment>/* See also */ alpha</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2834" xml:space="preserve">'''Novelty detection''' is the mechanism by which an intelligent organism is able to identify an incoming sensory pattern as being hitherto unknown. If the pattern is sufficiently salient or associated with a high positive or strong negative utility, it will be given computational resources for effective future processing. The principle is long known in neurophysiology, with roots in the [[orienting response]] research by E. N. Sokholov&lt;ref name="Sokolov, E.N 1960, pp. 187"&gt;Sokolov, E. N., (1960). Neuronal models and the orienting reflex, In ''The Central Nervous System and Behavior'', Mary A.B. Brazier, ed. NY: JosiahMacy, Jr. Foundation, pp. 187–276&lt;/ref&gt; in the 1950s. The reverse phenomenon is [[habituation]], i.e., the phenomenon that known patterns yield a less marked response. Early neural modeling attempts were by Yehuda Salu.&lt;ref name="Yehuda Salu, 1988"&gt;Salu, Y. (1988). [https://www.sciencedirect.com/science/article/pii/0303264788900032 Models of neural novelty detectors, with similarities to cerebral cortex]. BioSystems, 21, pp. 99-113, Elsevier.&lt;/ref&gt; An increasing body of knowledge has been collected concerning the corresponding mechanisms in the brain.&lt;ref&gt;Tiitinen, H., May, P., Reinikainen K. &amp;  Näätänen, R. (1994). ''[https://www.nature.com/articles/372090a0 Attentive novelty detection in humans is governed by pre-attentive sensory memory]'', Nature, 372, pp. 90–92.&lt;/ref&gt;&lt;ref&gt;Duncan, K., Ketz, N., Inati, S.J., Davachi, L. (2012). ''[https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3529001/ Evidence for area CA1 as a match/mismatch detector: A high-resolution fMRI study of the human hippocampus]'', Hippocampus, 22(3), pp. 389-398&lt;/ref&gt; In technology, the principle became important for radar detection methods during the Cold War, where unusual aircraft-reflection patterns could indicate an attack by a new type of aircraft. Today, the phenomenon plays an important role in machine learning and data science, where the corresponding methods are known as [[anomaly detection |anomaly detection or outlier detection]]. An extensive methodological overview is given by Markou and Singh.&lt;ref&gt;[https://doi.org/10.1016/j.sigpro.2003.07.018 Markou, M. &amp; Singh, S. (2003). ''Novelty detection: a review — Part 1: statistical approaches'', Signal Processing, Volume 83, Issue 12, pp. 2481-2497, ISSN 0165-1684]&lt;/ref&gt;&lt;ref&gt;[https://doi.org/10.1016/j.sigpro.2003.07.019 Markou, M. &amp; Singh, S. (2003). ''Novelty detection: a review — Part 2: neural network based approaches'', Signal Processing, Volume 83, Issue 12, pp. 2499-2521, ISSN 0165-1684]&lt;/ref&gt;

== See also ==
* [[Change detection]]
* [[Outlier]]

== References ==
{{Reflist|30em}}

[[Category:Neurophysiology]]
[[Category:Experimental psychology]]
[[Category:Machine learning]]
[[Category:Data mining]]
[[Category:Statistical outliers]]</text>
      <sha1>e8fzqkq7kcy8ky58m38tkv9ibxxeu4j</sha1>
    </revision>
  </page>
  <page>
    <title>Programming by example</title>
    <ns>0</ns>
    <id>8880387</id>
    <revision>
      <id>906227110</id>
      <parentid>906225790</parentid>
      <timestamp>2019-07-14T13:41:45Z</timestamp>
      <contributor>
        <username>Krauss</username>
        <id>1222358</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3034" xml:space="preserve">In [[computer science]], '''programming by example''' ('''PbE'''), also termed '''programming by demonstration''' or more generally as '''demonstrational programming''', is an [[end-user development]] technique for [[machine learning|teaching a computer new behavior]] by demonstrating actions on concrete examples.&lt;ref&gt;[https://www.microsoft.com/en-us/research/publication/machine-learning-framework-programming-example/ A Machine Learning Framework for Programming by Example - Microsoft]&lt;/ref&gt; The system records user actions and infers a generalized [[Computer program|program]] that can be used on new examples.

PbE is intended to be easier to do than traditional [[computer programming]], which generally requires learning and using a [[programming language]].  Many PbE systems have been developed as research prototypes, but few have found widespread real-world application.  More recently, PbE has proved to be a useful paradigm for creating scientific work-flows. PbE is used in two independent clients for the [[BioMOBY]] protocol: [http://www.biomedcentral.com/1471-2105/8/208/abstract Seahawk] and [http://www.scfbm.org/content/1/1/4 Gbrowse moby]. 

Also the [[programming by demonstration]] (PbD) term has been mostly adopted by robotics researchers for teaching new behaviors to the robot through a physical demonstration of the task. The usual distinction in literature between these terms is that in PbE the user gives a prototypical product of the computer execution, such as [[Query by Example|a row in the desired results of a query]]; while in PbD the user performs a sequence of actions that the computer must repeat, generalizing it to be used in different data sets. For final users, to automate a workflow in a complex tool (e.g. [[Adobe Photoshop|Photoshop]]), the most simple case of PbD is the  [[macro recorder]]. 

==See also==
* [[Query by Example]]
* [[Automated machine learning]]
* [[Example-based machine translation]]
* [[Inductive programming]]
* [[Lapis (text editor)]], which allows [[simultaneous editing]] of similar items in [[multiple selection]]s created by example
* [[Programming by demonstration]]
* [[Test-driven development]]&lt;!-- example-driven software development --&gt;

==References==
&lt;references /&gt;

==External links==
* [http://web.media.mit.edu/~lieber/PBE/ Henry Lieberman's page on Programming by Example]
* [http://www.acypher.com/wwid/ Online copy of &lt;u&gt;Watch What I Do&lt;/u&gt;, Allen Cypher's book on Programming by Demonstration]
* [http://web.media.mit.edu/~lieber/Your-Wish/ Online copy of &lt;u&gt;Your Wish is My Command&lt;/u&gt;, Henry Lieberman's sequel to &lt;u&gt;Watch What I Do&lt;/u&gt;]
* [http://www.dsmforum.org/events/DSVL01/carlson.pdf &lt;u&gt;A Visual Language for Data Mapping&lt;/u&gt;, John Carlson's description of an Integrated Development Environment (IDE) that used Programming by Example (desktop objects) for data mapping, and an iconic language for recording operations]

[[Category:User interfaces]]
[[Category:Programming paradigms]]
[[Category:Machine learning]]

{{comp-sci-stub}}</text>
      <sha1>ryk961ccsom20qxcn8sq4p4u35nkfjc</sha1>
    </revision>
  </page>
  <page>
    <title>Bayesian regret</title>
    <ns>0</ns>
    <id>8529968</id>
    <revision>
      <id>982887928</id>
      <parentid>982887799</parentid>
      <timestamp>2020-10-11T00:08:14Z</timestamp>
      <contributor>
        <username>Homunq</username>
        <id>1978054</id>
      </contributor>
      <comment>re-add category</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2031" xml:space="preserve">In [[stochastic game|stochastic]] [[game theory]], '''Bayesian regret''' is the expected difference ("*[[Regret (decision theory)|regret]]") between the [[utility]] of a Bayesian strategy and that of the optimal strategy (the one with the highest expected payoff). 

The term ''Bayesian'' refers to [[Thomas Bayes]] (1702–1761), who proved a special case of what is now called [[Bayes' theorem]], who provided the first mathematical treatment of a non-trivial problem of statistical data analysis using what is now known as [[Bayesian inference]]. 

==Economics==
This term has been used to compare a random buy-and-hold strategy to professional traders' records. This same concept has  received numerous different names, as the New York Times notes: 

"In 1957, for example, a statistician named James Hanna called his theorem Bayesian Regret. He had been preceded by David Blackwell, also a statistician, who called his theorem Controlled Random Walks. Other, later papers had titles like 'On Pseudo Games', 'How to Play an Unknown Game', 'Universal Coding' and 'Universal Portfolios'".&lt;ref&gt;{{Cite news|url=https://www.nytimes.com/2006/02/05/weekinreview/pity-the-scientist-who-discovers-the-discovered.html|title=Pity the Scientist Who Discovers the Discovered|last=Kolata|first=Gina|date=2006-02-05|work=The New York Times|access-date=2017-02-27|issn=0362-4331}}&lt;/ref&gt;

==Social Choice (voting methods)==

"Bayesian Regret" has also been used as an alternate term for [[social utility efficiency]], that is, a measure of the expected utility of different [[electoral system|voting methods]] under a given probabilistic model of voter utilities and strategies. In this case, the relation to Bayes is unclear, as there is no conditioning or posterior distribution involved.

==References==
{{Citation style|date=September 2018}}
{{Reflist}}

[[Category:Game theory]]
[[Category:Bayesian estimation]]
[[Category:Economic theories]]
[[Category:Machine learning]]
[[Category:Bayesian statistics]]
[[Category:Social choice theory]]</text>
      <sha1>9tn3kd6f1oha308xh5gh3hpf22ron0y</sha1>
    </revision>
  </page>
  <page>
    <title>Training, validation, and test sets</title>
    <ns>0</ns>
    <id>1514392</id>
    <revision>
      <id>998052768</id>
      <parentid>997888359</parentid>
      <timestamp>2021-01-03T15:59:11Z</timestamp>
      <contributor>
        <username>Generalartificialintelligence</username>
        <id>40847943</id>
      </contributor>
      <comment>/* Validation dataset */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="17961" xml:space="preserve">{{refimprove|date=December 2012}}
{{use dmy dates|date=June 2020|cs1-dates=y}}
{{anchor|Parameter}}&lt;!-- Parked anchor for redirects --&gt;
In [[machine learning]], a common task is the study and construction of [[Algorithm|algorithms]] that can learn from and make predictions on [[data]].&lt;ref&gt;{{cite journal |title=Glossary of terms |author1=Ron Kohavi |author2=Foster Provost |journal=[[Machine Learning (journal)|Machine Learning]] |volume=30 |pages=271–274 |year=1998 |url=https://ai.stanford.edu/~ronnyk/glossary.html|doi=10.1023/A:1007411609915 |doi-access=free }}&lt;/ref&gt; Such algorithms function by making data-driven predictions or decisions,&lt;ref name="bishop"&gt;{{cite book |first=Christopher M. |last=Bishop |title=Pattern Recognition and Machine Learning |location=New York |publisher=Springer |year=2006 |isbn=0-387-31073-8 |page=vii |quote=Pattern recognition has its origins in engineering, whereas machine learning grew out of computer science. However, these activities can be viewed as two facets of the same field, and together they have undergone substantial development over the past ten years. }}&lt;/ref&gt; through building a [[mathematical model]] from input data.

[[File:ML dataset training validation test sets.png|thumb|Examples of ways to partition a dataset. Dataset A only uses a training set and a test set. The test set would be used to test the trained model. For Dataset B, the validation set would be used to test the trained model, and the test set would evaluate the final model.]]

The data used to build the final model usually comes from multiple [[dataset]]s. In particular, three datasets are commonly used in different stages of the creation of the model.

The model is initially fit on a '''training dataset''',&lt;ref name="James 2013 176"&gt;{{cite book|last=James|first=Gareth|title=An Introduction to Statistical Learning: with Applications in R|date=2013|publisher=Springer|isbn=978-1461471370|page=176|url=http://www-bcf.usc.edu/~gareth/ISL/}}&lt;/ref&gt; which is a set of examples used to fit the parameters (e.g. weights of connections between neurons in [[artificial neural networks]]) of the model.&lt;ref name="Ripley 1996 354"&gt;{{cite book|last=Ripley|first=Brian|title=Pattern Recognition and Neural Networks|url=https://archive.org/details/patternrecogniti00ripl|url-access=limited|date=1996|publisher=Cambridge University Press|isbn=978-0521717700|page=[https://archive.org/details/patternrecogniti00ripl/page/n365 354]}}&lt;/ref&gt; The model (e.g. a [[neural net]] or a [[naive Bayes classifier]]) is trained on the training dataset using a [[supervised learning]] method, for example using optimization methods such as [[gradient descent]] or [[stochastic gradient descent]]. In practice, the training dataset often consists of pairs of an input [[Array data structure|vector]] (or scalar) and the corresponding output vector (or scalar), where the answer key is commonly denoted as the ''target'' (or ''label''). The current model is run with the training dataset and produces a result, which is then compared with the ''target'', for each input vector in the training dataset. Based on the result of the comparison and the specific learning algorithm being used, the parameters of the model are adjusted. The model fitting can include both [[feature selection|variable selection]] and parameter [[estimation theory|estimation]].

Successively, the fitted model is used to predict the responses for the observations in a second dataset called the '''validation dataset'''.&lt;ref name="James 2013 176"/&gt; The validation dataset provides an unbiased evaluation of a model fit on the training dataset while tuning the model's [[Hyperparameter (machine learning)|hyperparameters]]&lt;ref name="Brownlee"&gt;{{cite web |url=https://machinelearningmastery.com/difference-test-validation-datasets/|title=What is the Difference Between Test and Validation Datasets?|last=Brownlee|first=Jason|access-date=12 October 2017|date=2017-07-13}}&lt;/ref&gt; (e.g. the number of hidden units (layers and layer widths) in a neural network&lt;ref name="Ripley 1996 354"/&gt;). Validation datasets can be used for [[Regularization (mathematics)|regularization]] by [[early stopping]] (stopping training when the error on the validation dataset increases, as this is a sign of [[overfitting]] to the training dataset).&lt;ref name="prechelt_early_2012"&gt;{{Cite book
| publisher = Springer Berlin Heidelberg
| isbn = 978-3-642-35289-8
| pages = [https://archive.org/details/neuralnetworkstr00mlle/page/n60 53]–67
| editor = Grégoire Montavon
| editor2 = Klaus-Robert Müller
| editor2-link = Klaus-Robert Müller
| last = Prechelt
| first = Lutz
|author2=Geneviève B. Orr
| title = Neural Networks: Tricks of the Trade
| url = https://archive.org/details/neuralnetworkstr00mlle
| url-access = limited
| chapter = Early Stopping — But When?
| series = Lecture Notes in Computer Science
| date = 2012-01-01
| doi = 10.1007/978-3-642-35289-8_5
}}&lt;/ref&gt;
This simple procedure is complicated in practice by the fact that the validation dataset's error may fluctuate during training, producing multiple local minima. This complication has led to the creation of many ad-hoc rules for deciding when overfitting has truly begun.&lt;ref name="prechelt_early_2012"/&gt;

Finally, the '''test dataset''' is a dataset used to provide an unbiased evaluation of a ''final'' model fit on the training dataset.&lt;ref name="Brownlee"/&gt; If the data in the test dataset has never been used in training (for example in [[Cross-validation (statistics)|cross-validation]]), the test dataset is also called a '''holdout dataset'''. The term "validation set" is sometimes used instead of "test set" in some literature (e.g., if the original dataset was partitioned into only two subsets, the test set might be referred to as the validation set).&lt;ref name="Brownlee"/&gt;

== Training dataset ==
A training dataset is a [[dataset]] of examples used during the learning process and is used to fit the parameters (e.g., weights) of, for example, a [[Classifier (machine learning)|classifier]].&lt;ref name="Ripley, B.D. 1996 p. 354"&gt;Ripley, B.D. (1996) ''Pattern Recognition and Neural Networks'', Cambridge: Cambridge University Press, p. 354&lt;/ref&gt;&lt;ref name="cann-faq"&gt;"[ftp://ftp.sas.com/pub/neural/FAQ.html#A_data Subject: What are the population, sample, training set, design set, validation set, and test set?]", [ftp://ftp.sas.com/pub/neural/FAQ.html Neural Network FAQ, part 1 of 7: Introduction] ([ftp://ftp.sas.com/pub/neural/FAQ1.txt txt]), comp.ai.neural-nets, Sarle, W.S., ed. (1997, last modified 2002-05-17)&lt;/ref&gt; 

For classification tasks, a supervised learning algorithm looks at the training dataset to determine, or learn, the optimal combinations of variables that will generate a good [[Predictive modelling|predictive model]].&lt;ref name="Larose2014"&gt;{{cite book | last=Larose | first=D. T. | last2=Larose | first2=C. D. | title=Discovering knowledge in data : an introduction to data mining | publisher=Wiley | publication-place=Hoboken | year=2014 | isbn=978-0-470-90874-7 | oclc=869460667 | doi=10.1002/9781118874059}}&lt;/ref&gt; The goal is to produce a trained (fitted) model that generalizes well to new, unknown data.&lt;ref name="Xu Goodacre 2018"&gt;{{cite journal | last=Xu | first=Yun | last2=Goodacre | first2=Royston | title=On Splitting Training and Validation Set: A Comparative Study of Cross-Validation, Bootstrap and Systematic Sampling for Estimating the Generalization Performance of Supervised Learning | journal=Journal of Analysis and Testing | publisher=Springer Science and Business Media LLC | volume=2 | issue=3 | year=2018 | issn=2096-241X | doi=10.1007/s41664-018-0068-2 | pages=249–262| doi-access=free }}&lt;/ref&gt; The fitted model is evaluated using “new” examples from the held-out datasets (validation and test datasets) to estimate the model’s accuracy in classifying new data.&lt;ref name="Brownlee"/&gt; To reduce the risk of issues such as overfitting, the examples in the validation and test datasets should not be used to train the model.&lt;ref name="Brownlee"/&gt;

Most approaches that search through training data for empirical relationships tend to [[overfit]] the data, meaning that they can identify and exploit apparent relationships in the training data that do not hold in general.

== Validation dataset ==
A validation dataset is a [[dataset]] of examples used to tune the [[Hyperparameter (machine learning)|hyperparameter]]s (i.e. the architecture) of a classifier. It is sometimes also called the development set or the "dev set". An example of a hyperparameter for [[artificial neural networks]] includes the number of hidden units in each layer.&lt;ref name="Ripley, B.D. 1996 p. 354" /&gt;&lt;ref name="cann-faq" /&gt; It, as well as the testing set (as mentioned above), should follow the same probability distribution as the training dataset.

In order to avoid overfitting, when any [[Statistical classification|classification]] parameter needs to be adjusted, it is necessary to have a validation dataset in addition to the training and test datasets. For example, if the most suitable classifier for the problem is sought, the training dataset is used to train the different candidate classifiers, the validation dataset is used to compare their performances and decide which one to take and, finally, the test dataset is used to obtain the performance characteristics such as [[accuracy]], [[sensitivity and specificity|sensitivity]], [[Sensitivity and specificity|specificity]], [[Precision and recall#F-measure|F-measure]], and so on. The validation dataset functions as a hybrid: it is training data used for testing, but neither as part of the low-level training nor as part of the final testing.

The basic process of using a validation dataset for [[model selection]] (as part of training dataset, validation dataset, and test dataset) is:&lt;ref name="cann-faq" /&gt;&lt;ref&gt;Bishop, C.M. (1995), ''[https://books.google.com/books?id=T0S0BgAAQBAJ&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false Neural Networks for Pattern Recognition]'', Oxford: Oxford University Press, p. 372&lt;/ref&gt;

{{quote|
Since our goal is to find the network having the best performance on new data, the simplest approach to the comparison of different networks is to evaluate the error function using data which is independent of that used for training. Various networks are trained by minimization of an appropriate error function defined with respect to a training data set. The performance of the networks is then compared by evaluating the error function using an independent validation set, and the network having the smallest error with respect to the validation set is selected. This approach is called the ''hold out'' method. Since this procedure can itself lead to some overfitting to the validation set, the performance of the selected network should be confirmed by measuring its performance on a third independent set of data called a test set.}}

An application of this process is in [[early stopping]], where the candidate models are successive iterations of the same network, and training stops when the error on the validation set grows, choosing the previous model (the one with minimum error).

== Test dataset ==
A test dataset is a [[dataset]] that is [[independence (probability theory)|independent]] of the training dataset, but that follows the same [[probability distribution]] as the training dataset. If a model fit to the training dataset also fits the test dataset well, minimal [[overfitting]] has taken place (see figure below). A better fitting of the training dataset as opposed to the test dataset usually points to overfitting.

A test set is therefore a set of examples used only to assess the performance (i.e. generalization) of a fully specified classifier.&lt;ref name="Ripley, B.D. 1996 p. 354"/&gt;&lt;ref name="cann-faq"/&gt; To do this, the final model is used to predict classifications of examples in the test set. Those predictions are compared to the examples' true classifications to assess the model's accuracy.&lt;ref name="Larose2014" /&gt;

In a scenario where both validation and test datasets are used, the test dataset is typically used to assess the final model that is selected during the validation process. In the case where the original dataset is partitioned into two subsets (training and test datasets), the test dataset might assess the model only once (e.g., in the [[Holdout method|holdout method]]).&lt;ref name="Kohavi2001"&gt;{{Cite journal | url=https://www.researchgate.net/publication/2352264 | title=A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection| volume=14| date=2001-03-03| last1=Kohavi| first1=Ron}}&lt;/ref&gt; Note that some sources advise against such a method.&lt;ref name="Xu Goodacre 2018" /&gt; However, when using a method such as [[Cross-validation (statistics)|cross-validation]], two partitions can be sufficient and effective since results are averaged after repeated rounds of model training and testing to help reduce bias and variability.&lt;ref name="Brownlee"/&gt;&lt;ref name="Xu Goodacre 2018" /&gt;


[[File:traintest.svg|center|700px|thumb|A training set (left) and a test set (right) from the same statistical population are shown as blue points.  Two predictive models are fit to the training data.  Both fitted models are plotted with both the training and test sets.  In the training set, the [[mean squared error|MSE]] of the fit shown in orange is 4 whereas the MSE for the fit shown in green is 9.  In the test set, the MSE for the fit shown in orange is 15 and the MSE for the fit shown in green is 13.  The orange curve severely overfits the training data, since its MSE increases by almost a factor of four when comparing the test set to the training set.  The green curve overfits the training data much less, as its MSE increases by less than a factor of 2.]]

== Confusion in terminology ==

The terms '''test set''' and '''validation set''' are sometimes used in a way that flips their meaning in both industry and academia. In the erroneous usage, "test set" becomes the development set, and "validation set" is the independent set used to evaluate the performance of a fully specified classifier. &lt;blockquote&gt;The literature on machine learning often reverses the meaning of “validation” and “test” sets. This is the most blatant example of the terminological confusion that pervades artificial intelligence research.&lt;ref&gt;{{Cite book|title=Pattern recognition and neural networks|last=Ripley, Brian D.|date=2009|publisher=Cambridge Univ. Press|isbn=9780521717700|pages=Glossary|oclc=601063414}}&lt;/ref&gt;&lt;/blockquote&gt;

== Cross-validation ==
A dataset can be repeatedly split into a training dataset and a validation dataset: this is known as [[cross-validation (statistics)|cross-validation]]. These repeated partitions can be done in various ways, such as dividing into 2 equal datasets and using them as training/validation, and then validation/training, or repeatedly selecting a random subset as a validation dataset{{Citation needed|date=October 2017}}. To validate the model performance, sometimes an additional test dataset that was held out from cross-validation is used.{{fact|date=July 2020}}

== Hierarchical classification ==
Another example of parameter adjustment is '''hierarchical classification''' (sometimes referred to as '''instance space decomposition'''&lt;ref&gt;{{cite journal |last=Cohen |first=S. |last2=Rokach |first2=L. |last3=Maimon |first3=O. |title=Decision-tree instance-space decomposition with grouped gain-ratio |journal=Information Sciences |volume=177 |issue=17 |pages=3592–3612 |publisher=Elsevier |year=2007 |doi=10.1016/j.ins.2007.01.016 }}&lt;/ref&gt;), which splits a complete [[multi-class classification|multi-class]] problem into a set of smaller classification problems. It serves for learning more accurate concepts due to simpler classification boundaries in subtasks and individual feature selection procedures for subtasks. When doing classification decomposition, the central choice is the order of combination of smaller classification steps, called the classification path. Depending on the application, it can be derived from the [[confusion matrix]] and, uncovering the reasons for typical errors and finding ways to prevent the system make those in the future. For example,&lt;ref&gt;Sidorova, J., Badia, T. "[http://rua.ua.es/dspace/bitstream/10045/8621/1/PLN_41_43.pdf ESEDA: tool for enhanced speech emotion detection and analysis]". The 4th International Conference on Automated Solutions for Cross Media Content and Multi-Channel Distribution (AXMEDIS 2008). Florence, November, 17-19, pp. 257–260. IEEE press.&lt;/ref&gt; on the validation set one can see which classes are most frequently mutually confused by the system and then the instance space decomposition is done as follows: firstly, the classification is done among well recognizable classes, and the difficult to separate classes are treated as a single joint class, and finally, as a second classification step the joint class is classified into the two initially mutually confused classes.{{fact|date=July 2020}}

== See also ==
* [[Statistical classification]]
* [[List of datasets for machine learning research]]

== References ==
{{Reflist}}

== External links ==
* [ftp://ftp.sas.com/pub/neural/FAQ.html#A_data FAQ: What are the population, sample, training set, design set, validation set, and test set?]
* [https://machinelearningmastery.com/difference-test-validation-datasets/ What is the Difference Between Test and Validation Datasets? ]
* [https://www.quora.com/What-is-training-validation-and-testing-data-sets-scenario-in-machine-learning What is training, validation, and testing data-sets scenario in machine learning?]
* [https://stackoverflow.com/q/13610074/3924118 Is there a rule-of-thumb for how to divide a dataset into training and validation sets?]

[[Category:Datasets in machine learning]]
[[Category:Machine learning]]
[[Category:Validity (statistics)]]</text>
      <sha1>tlyod49784oj81fvdoyiza9ai6h5jzh</sha1>
    </revision>
  </page>
  <page>
    <title>Multitask optimization</title>
    <ns>0</ns>
    <id>58175832</id>
    <revision>
      <id>908624903</id>
      <parentid>908624647</parentid>
      <timestamp>2019-07-30T22:21:50Z</timestamp>
      <contributor>
        <username>Jarble</username>
        <id>7226930</id>
      </contributor>
      <comment>/* See also */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="7508" xml:space="preserve">{{context|date=October 2018}}

{{short description|Optimizing the solving of multiple self-contained tasks simultaneously}}
'''Multi-task optimization''' is a paradigm in the optimization literature that focuses on solving multiple self-contained tasks simultaneously.&lt;ref name=TO&gt;Gupta, A., Ong, Y. S., &amp; Feng, L. (2018). [https://www.researchgate.net/publication/321143620_Insights_on_Transfer_Optimization_Because_Experience_is_the_Best_Teacher Insights on transfer optimization: Because experience is the best teacher]. IEEE Transactions on Emerging Topics in Computational Intelligence, 2(1), 51-64.&lt;/ref&gt;&lt;ref name=mfo&gt;Gupta, A., Ong, Y. S., &amp; Feng, L. (2016). [http://www.cil.ntu.edu.sg/mfo/downloads/Multifactorial_Evolution.pdf Multifactorial evolution: toward evolutionary multitasking.] IEEE Transactions on Evolutionary Computation, 20(3), 343-357.&lt;/ref&gt;  The paradigm has been inspired by the well-established concepts of [[transfer learning]]&lt;ref&gt;Pan, S. J., &amp; Yang, Q. (2010). [https://www.cse.ust.hk/~qyang/Docs/2009/tkde_transfer_learning.pdf A survey on transfer learning]. IEEE Transactions on knowledge and data engineering, 22(10), 1345-1359.}&lt;/ref&gt; and [[multi-task learning]]&lt;ref&gt;Caruana, R., "Multitask Learning", pp. 95-134 in {{Harvnb|Pratt|Thrun|1998}}&lt;/ref&gt; in [[predictive analytics]]. 

The key motivation behind multi-task optimization is that if optimization tasks are related to each other in terms of their optimal solutions or the general characteristics of their function landscapes,&lt;ref&gt;Cheng, M. Y., Gupta, A., Ong, Y. S., &amp; Ni, Z. W. (2017). [https://www.sciencedirect.com/science/article/pii/S095219761730101X Coevolutionary multitasking for concurrent global optimization: With case studies in complex engineering design]. Engineering Applications of Artificial Intelligence, 64, 13-24.}&lt;/ref&gt; the search progress can be transferred to substantially accelerate the search on the other. 

The success of the paradigm is not necessarily limited to one-way knowledge transfers from simpler to more complex tasks. In practice an attempt is to intentionally solve a more difficult task that may unintentionally solve several smaller problems.&lt;ref name="DeFreitas"&gt; Cabi, S., Colmenarejo, S. G., Hoffman, M. W., Denil, M., Wang, Z., &amp; De Freitas, N. (2017). [https://arxiv.org/abs/1707.03300 The intentional unintentional agent: Learning to solve many continuous control tasks simultaneously]. arXiv preprint arXiv:1707.03300.&lt;/ref&gt;

==Methods== 

There are two common approaches for multi-task optimization: [[Bayesian optimization]] and [[evolutionary computation]].&lt;ref name=TO/&gt;

=== Multi-task Bayesian optimization ===
'''Multi-task Bayesian optimization''' is a modern model-based approach that leverages the concept of knowledge transfer to speed up the automatic [[hyperparameter optimization]] process of machine learning algorithms.&lt;ref name=mtbo&gt;Swersky, K., Snoek, J., &amp; Adams, R. P. (2013). [http://papers.nips.cc/paper/5086-multi-task-bayesian-optimization.pdf Multi-task bayesian optimization]. Advances in neural information processing systems (pp. 2004-2012).&lt;/ref&gt; The method builds a multi-task Gaussian
process model on the data originating from different searches progressing in tandem.&lt;ref&gt;Bonilla, E. V., Chai, K. M., &amp; Williams, C. (2008). [http://papers.nips.cc/paper/3189-multi-task-gaussian-process-prediction.pdf Multi-task Gaussian process prediction]. Advances in neural information processing systems (pp. 153-160).&lt;/ref&gt; The captured inter-task dependencies are thereafter utilized to better inform the subsequent sampling of candidate solutions in respective search spaces.

=== Evolutionary multi-tasking ===
'''Evolutionary multi-tasking''' has been explored as a means of exploiting the implicit parallelism of population-based search algorithms to simultaneously progress multiple distinct optimization tasks. By mapping all tasks to a unified search space, the evolving population of candidate solutions can harness the hidden relationships between them through continuous genetic transfer. This is induced when solutions associated with different tasks crossover.&lt;ref name=mfo/&gt;&lt;ref name=cognitive&gt;Ong, Y. S., &amp; Gupta, A. (2016). [http://www.cil.ntu.edu.sg/mfo/downloads/MultitaskOptimization_manuscript.pdf Evolutionary multitasking: a computer science view of cognitive multitasking]. Cognitive Computation, 8(2), 125-142.&lt;/ref&gt; Recently, modes of knowledge transfer that are different from direct solution [[Crossover (genetic algorithm)|crossover]] have been explored.&lt;ref&gt;Feng, L., Zhou, L., Zhong, J., Gupta, A., Ong, Y. S., Tan, K. C., &amp; Qin, A. K. (2018). [https://ieeexplore.ieee.org/abstract/document/8401802/ Evolutionary Multitasking via Explicit Autoencoding]. IEEE transactions on cybernetics, (99).&lt;/ref&gt;

== Applications ==

Algorithms for multi-task optimization span a wide array of real-world applications. Recent studies highlight the potential for speed-ups in the optimization of engineering design parameters by conducting related designs jointly in a multi-task manner.&lt;ref name=cognitive/&gt; In [[machine learning]], the transfer of optimized features across related data sets can enhance the efficiency of the training process as well as improve the generalization capability of learned models.&lt;ref&gt;Chandra, R., Gupta, A., Ong, Y. S., &amp; Goh, C. K. (2016, October). [http://www.cil.ntu.edu.sg/mfo/downloads/cvmultask.pdf Evolutionary multi-task learning for modular training of feedforward neural networks]. In International Conference on Neural Information Processing (pp. 37-46). Springer, Cham.&lt;/ref&gt;&lt;ref&gt;Yosinski, J., Clune, J., Bengio, Y., &amp; Lipson, H. (2014). [http://papers.nips.cc/paper/5347-how-transferable-are-features-in-deep-n%E2%80%A6 How transferable are features in deep neural networks?] In Advances in neural information processing systems (pp. 3320-3328).&lt;/ref&gt; In addition, the concept of multi-tasking has led to advances in automatic [[hyperparameter optimization]] of machine learning models and [[ensemble learning]].&lt;ref&gt;Wen, Y. W., &amp; Ting, C. K. (2016, July). [https://ieeexplore.ieee.org/abstract/document/7748363/ Learning ensemble of decision trees through multifactorial genetic programming]. In Evolutionary Computation (CEC), 2016 IEEE Congress on (pp. 5293-5300). IEEE.&lt;/ref&gt;&lt;ref&gt;Zhang, B., Qin, A. K., &amp; Sellis, T. (2018, July). [https://dl.acm.org/citation.cfm?id=3205638 Evolutionary feature subspaces generation for ensemble classification]. In Proceedings of the Genetic and Evolutionary Computation Conference (pp. 577-584). ACM.&lt;/ref&gt;

Applications have also been reported in cloud computing,&lt;ref&gt;Bao, L., Qi, Y., Shen, M., Bu, X., Yu, J., Li, Q., &amp; Chen, P. (2018, June). [https://link.springer.com/chapter/10.1007/978-3-319-94472-2_10 An Evolutionary Multitasking Algorithm for Cloud Computing Service Composition]. In World Congress on Services (pp. 130-144). Springer, Cham.&lt;/ref&gt; with future developments geared towards cloud-based on-demand optimization services that can cater to multiple customers simultaneously.&lt;ref name=mfo/&gt;&lt;ref&gt;Tang, J., Chen, Y., Deng, Z., Xiang, Y., &amp; Joy, C. P. (2018). [https://www.ijcai.org/proceedings/2018/0538.pdf A Group-based Approach to Improve Multifactorial Evolutionary Algorithm]. In IJCAI (pp. 3870-3876).&lt;/ref&gt;

==See also==
* [[Multi-objective optimization]]
* [[Multi-task learning]]
* [[Multicriteria classification]]
* [[Multiple-criteria decision analysis]]

==References==
&lt;references /&gt;

[[Category:Machine learning]]</text>
      <sha1>5skzihsb5sr9vn87dtls7mlvfhfgoq2</sha1>
    </revision>
  </page>
  <page>
    <title>Associative classifier</title>
    <ns>0</ns>
    <id>58655546</id>
    <revision>
      <id>1001858271</id>
      <parentid>1001680416</parentid>
      <timestamp>2021-01-21T18:33:44Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <comment>Add: pages, volume, journal, s2cid, arxiv. Removed parameters. Formatted [[WP:ENDASH|dashes]]. | You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | Suggested by AManWithNoPlan | via #UCB_toolbar</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="8569" xml:space="preserve">{{short description|machine learning model type}}An '''associative classifier''' (AC) is a kind of [[supervised learning]] model that uses [[association rules]] to assign a target value. The term associative classification was coined by [[Bing Liu (computer scientist)|Bing Liu]] et al.,&lt;ref name=":0"&gt;{{Cite journal|last1=Liu|first1=Bing|last2=Hsu|first2=Wynne|last3=Ma|first3=Yiming|date=1998|title=Integrating Classification and Association Rule Mining|pages=80––86|citeseerx=10.1.1.48.8380}}&lt;/ref&gt; in which the authors defined a model made of rules "whose right-hand side are restricted to the classification class attribute".

== Model ==
The model generated by an AC and used to label new records consists of [[association rules]], where the consequent corresponds to the class label. As such, they can also be seen as a list of "if-then" clauses: if the record matches some criteria (expressed in the left side of the rule, also called antecedent), it is then labeled accordingly to the class on the right side of the rule (or consequent).

Most ACs read the list of rules in order, and apply the first matching rule to label the new record.&lt;ref&gt;{{Cite journal|last=Thabtah|first=Fadi|date=2007|title=A review of associative classification mining|journal=The Knowledge Engineering Review|volume=22|issue=1|pages=37–65|doi=10.1017/s0269888907001026|issn=0269-8889|url=http://eprints.hud.ac.uk/id/eprint/269/1/ThabtahReview.pdf}}&lt;/ref&gt;

More recent approaches have formulated the problem of combining pre-mined association rules in a [[decision list]] or rule list optimally. These methods use different forms of [[Occam's razor]] (the rule of parsimony) and can divided in three main types based on the theory used:  
*Regularized loss (accuracy with &lt;math&gt;{L_{1}}&lt;/math&gt;  norm) &lt;ref&gt;{{cite journal |last1=Angelino |first1=Elaine |last2=Larus-Stone |first2=Nicholas |last3=Alabi |first3=Daniel |last4=Seltzer |first4=Margo |last5=Rudin |first5=Cynthia |title=Learning certifiably optimal rule lists for categorical data |journal=The Journal of Machine Learning Research |date=1 January 2017 |volume=18 |issue=1 |pages=8753–8830 |arxiv=1704.01701 |url=https://dl.acm.org/doi/abs/10.5555/3122009.3290419 |issn=1532-4435}}&lt;/ref&gt;
*[[Bayesian statistics]] &lt;ref&gt;{{cite journal |last1=Letham |first1=Benjamin |last2=Rudin |first2=Cynthia |last3=McCormick |first3=Tyler H. |last4=Madigan |first4=David |title=Interpretable classifiers using rules and Bayesian analysis: Building a better stroke prediction model |journal=Annals of Applied Statistics |date=September 2015 |volume=9 |issue=3 |pages=1350–1371 |doi=10.1214/15-AOAS848 |arxiv=1511.01644 |s2cid=17699665 |url=https://projecteuclid.org/euclid.aoas/1446488742 |language=EN |issn=1932-6157}}&lt;/ref&gt; &lt;ref&gt;{{cite journal |last1=Yang |first1=Hongyu |last2=Rudin |first2=Cynthia |last3=Seltzer |first3=Margo |title=Scalable Bayesian Rule Lists |journal=International Conference on Machine Learning |date=17 July 2017 |pages=3921–3930 |url=http://proceedings.mlr.press/v70/yang17h.html |publisher=PMLR |arxiv=1602.08610 |language=en}}&lt;/ref&gt;
*[[Minimum description length]] (MDL) principle &lt;ref&gt;{{cite journal |last1=Proença |first1=Hugo |last2=van Leeuwen |first2=Matthijs |title=Interpretable multiclass classification by MDL-based rule lists |journal=Information Sciences |date=May 2019 |volume=512 |pages=1372–1393 |arxiv=1905.00328 |doi=10.1016/j.ins.2019.10.050 |s2cid=141461238 }}&lt;/ref&gt;
\end{enumerate}
The first approach finds decision lists and solves the problem optimally through a branch-and-bound algorithm. The second finds a probabilistic rule list for binary classification and resorts to a Markov Chain Monte Carlo (MCMC) that approximately solves the problem, as it only accepts small amounts of pre-mined rules. The third, also finds a probabilistic rule list although for multiclass classification, and uses a greedy algorithm to scale for large datasets.

== Metrics ==
The rules of an AC inherit some of the metrics of association rules, like the support or the confidence.&lt;ref&gt;{{Cite book|title=Recent Advances in Data Mining of Enterprise Data: Algorithms and Applications|last1=Liao|first1=T Warren|last2=Triantaphyllou|first2=Evangelos|s2cid=34599426|date=2008|publisher=WORLD SCIENTIFIC|isbn=9789812779854|series=Series on Computers and Operations Research|doi=10.1142/6689}}&lt;/ref&gt; Metrics can be used to order or filter the rules in the model&lt;ref&gt;{{Cite web|url=http://cgi.csc.liv.ac.uk/~frans/KDD/Software/CBA/cba.html|title=CBA homepage|access-date=2018-10-04}}&lt;/ref&gt; and to evaluate their quality.

== Implementations ==
The first proposal of a classification model made of association rules was CBA,&lt;ref name=":0" /&gt; although other authors had previously proposed the mining of association rules for classification.&lt;ref&gt;{{Cite journal|last1=Ali|first1=Kamal|last2=Manganaris|first2=Stefanos|last3=Srikant|first3=Ramakrishnan|date=1997-08-14|title=Partial classification using association rules|url=http://dl.acm.org/citation.cfm?id=3001392.3001412|publisher=AAAI Press|pages=115–118|series=KDD'97}}&lt;/ref&gt; Other authors have since then proposed multiple changes to the initial model, like the addition of a redundant rule pruning phase&lt;ref name=":2"&gt;{{Cite book|last1=Wenmin Li|last2=Jiawei Han|last3=Jian Pei|title=CMAR: accurate and efficient classification based on multiple class-association rules|journal=Proceedings 2001 IEEE International Conference on Data Mining|pages=369–376|publisher=IEEE Comput. Soc|doi=10.1109/icdm.2001.989541|isbn=978-0769511191|year=2001|citeseerx=10.1.1.13.219|s2cid=2243455}}&lt;/ref&gt; or the exploitation of Emerging Patterns.&lt;ref name=":3"&gt;{{Citation|last1=Dong|first1=Guozhu|title=CAEP: Classification by Aggregating Emerging Patterns|date=1999|work=Discovery Science|pages=[https://archive.org/details/discoveryscience0000unse/page/30 30–42]|publisher=Springer Berlin Heidelberg|isbn=9783540667131|last2=Zhang|first2=Xiuzhen|last3=Wong|first3=Limsoon|last4=Li|first4=Jinyan|doi=10.1007/3-540-46846-3_4|citeseerx=10.1.1.37.3226|url-access=registration|url=https://archive.org/details/discoveryscience0000unse/page/30}}&lt;/ref&gt;

Notable implementations include:

* CMAR&lt;ref name=":2" /&gt;&lt;ref&gt;{{Cite web|url=https://cgi.csc.liv.ac.uk/~frans/KDD/Software/CMAR/cmar.html|title=CMAR Implementation|website=cgi.csc.liv.ac.uk|access-date=2018-10-04}}&lt;/ref&gt;
* CPAR&lt;ref&gt;{{Citation|last1=Yin|first1=Xiaoxin|title=CPAR: Classification based on Predictive Association Rules|date=2003|work=Proceedings of the 2003 SIAM International Conference on Data Mining|pages=331–335|publisher=Society for Industrial and Applied Mathematics|isbn=9780898715453|last2=Han|first2=Jiawei|doi=10.1137/1.9781611972733.40|citeseerx=10.1.1.12.7268}}&lt;/ref&gt;&lt;ref name=":1"&gt;{{Cite web|url=https://cgi.csc.liv.ac.uk/~frans/KDD/Software/FOIL_PRM_CPAR/foilPrmCpar.html|title=THE LUCS-KDD IMPLEMENTATIONS OF THE FOIL, PRM AND CPAR ALGORITHMS|website=cgi.csc.liv.ac.uk|access-date=2018-10-04}}&lt;/ref&gt;
*L³&lt;ref&gt;{{Cite journal|last1=Baralis|first1=E.|last2=Chiusano|first2=S.|last3=Garza|first3=P.|date=2008|title=A Lazy Approach to Associative Classification|journal=IEEE Transactions on Knowledge and Data Engineering|volume=20|issue=2|pages=156–171|doi=10.1109/tkde.2007.190677|s2cid=14829459|issn=1041-4347}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=http://dbdmg.polito.it/wordpress/research/associative-classification/|title=L3 implementation|website=dbdmg.polito.it|access-date=2018-10-08}}&lt;/ref&gt;
*CAEP&lt;ref name=":3" /&gt;
*GARC&lt;ref&gt;{{Cite journal|last1=Chen|first1=Guoqing|last2=Liu|first2=Hongyan|last3=Yu|first3=Lan|last4=Wei|first4=Qiang|last5=Zhang|first5=Xing|date=2006|title=A new approach to classification based on association rule mining|journal=Decision Support Systems|volume=42|issue=2|pages=674–689|doi=10.1016/j.dss.2005.03.005|issn=0167-9236}}&lt;/ref&gt;
*ADT.&lt;ref&gt;{{Cite book|last1=Wang|first1=Ke|last2=Zhou|first2=Senqiang|last3=He|first3=Yu|date=2000|title=Growing decision trees on support-less association rules|journal=Proceedings of the Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD '00|location=New York, New York, USA|publisher=ACM Press|doi=10.1145/347090.347147|isbn=978-1581132335|citeseerx=10.1.1.36.9265|s2cid=8296096}}&lt;/ref&gt;

== References ==
&lt;!-- Inline citations added to your article will automatically display here. See https://en.wikipedia.org/wiki/WP:REFB for instructions on how to add citations. --&gt;
{{reflist}}

[[Category:Supervised learning]]
[[Category:Machine learning]]
[[Category:Artificial intelligence]]</text>
      <sha1>39950d54u26qe371p4u5gc8ajn4gcas</sha1>
    </revision>
  </page>
  <page>
    <title>Time series</title>
    <ns>0</ns>
    <id>406624</id>
    <revision>
      <id>1002585593</id>
      <parentid>999862037</parentid>
      <timestamp>2021-01-25T03:32:36Z</timestamp>
      <contributor>
        <username>Otto von bisbarck</username>
        <id>40925413</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="36348" xml:space="preserve">{{Use American English|date = March 2019}}
{{short description|Sequence of data points over time}}
[[File:Random-data-plus-trend-r2.png|thumb|250px|Time series: random data plus trend, with best-fit line and different applied filters|alt=|right]]
A '''time series''' is a series of [[data point]]s indexed (or listed or graphed) in time order.  Most commonly, a time series is a [[sequence]] taken at successive equally spaced points in time. Thus it is a sequence of [[discrete-time]] data. Examples of time series are heights of ocean [[tides]], counts of [[sunspots]], and the daily closing value of the [[Dow Jones Industrial Average]].

Time series are very frequently plotted via [[run chart]]s (a temporal [[line chart]]). Time series are used in [[statistics]], [[signal processing]], [[pattern recognition]], [[econometrics]], [[mathematical finance]], [[weather forecasting]], [[earthquake prediction]], [[electroencephalography]], [[control engineering]], [[astronomy]], [[communications engineering]], and largely in any domain of applied [[Applied science|science]] and [[engineering]] which involves [[Time|temporal]] measurements.

'''Time series ''analysis''''' comprises methods for analyzing time series data in order to extract meaningful statistics and other characteristics of the data. '''Time series ''forecasting''''' is the use of a [[model (abstract)|model]] to predict future values based on previously observed values. While [[regression analysis]] is often employed in such a way as to test relationships between one more different time series, this type of analysis is not usually called "time series analysis," which refers in particular to relationships between different points in time within a single series. [[Interrupted time series]] analysis is used to detect changes in the evolution of a time series from before to after some intervention which may affect the underlying variable.

Time series data have a natural temporal ordering.  This makes time series analysis distinct from [[cross-sectional study|cross-sectional studies]], in which there is no natural ordering of the observations (e.g. explaining people's wages by reference to their respective education levels, where the individuals' data could be entered in any order).  Time series analysis is also distinct from [[spatial data analysis]] where the observations typically relate to geographical locations (e.g. accounting for house prices by the location as well as the intrinsic characteristics of the houses). A [[stochastic]] model for a time series will generally reflect the fact that observations close together in time will be more closely related than observations further apart. In addition, time series models will often make use of the natural one-way ordering of time so that values for a given period will be expressed as deriving in some way from past values, rather than from future values (see [[time reversibility]].)

Time series analysis can be applied to [[real number|real-valued]], continuous data, [[:wikt:discrete|discrete]] [[Data type#Numeric types|numeric]] data, or discrete symbolic data (i.e. sequences of characters, such as letters and words in the [[English language]]&lt;ref&gt;{{cite book |last1=Lin |first1=Jessica |last2=Keogh |first2=Eamonn |last3=Lonardi |first3=Stefano |last4=Chiu |first4=Bill |chapter=A symbolic representation of time series, with implications for streaming algorithms |title=Proceedings of the 8th ACM SIGMOD workshop on Research issues in data mining and knowledge discovery |pages=2–11 |year=2003 |location=New York |publisher=ACM Press |doi=10.1145/882082.882086|citeseerx=10.1.1.14.5597 |s2cid=6084733 }}&lt;/ref&gt;).

==Methods for analysis==

Methods for time series analysis may be divided into two classes: [[frequency-domain]] methods and [[time-domain]] methods. The former include [[frequency spectrum#Spectrum analysis|spectral analysis]] and [[wavelet analysis]]; the latter include [[auto-correlation]] and [[cross-correlation]] analysis. In the time domain, correlation and analysis can be made in a filter-like manner using [[scaled correlation]], thereby mitigating the need to operate in the frequency domain.

Additionally, time series analysis techniques may be divided into [[Parametric estimation|parametric]] and [[Non-parametric statistics|non-parametric]] methods. The [[Parametric estimation|parametric approaches]] assume that the underlying [[stationary process|stationary stochastic process]] has a certain structure which can be described using a small number of parameters (for example, using an [[autoregressive]] or [[moving average model]]). In these approaches, the task is to estimate the parameters of the model that describes the stochastic process. By contrast, [[Non-parametric statistics|non-parametric approaches]] explicitly estimate the [[covariance]] or the [[spectrum]] of the process without assuming that the process has any particular structure.

Methods of time series analysis may also be divided into [[Linear regression|linear]] and [[Nonlinear regression|non-linear]], and [[Univariate analysis|univariate]] and [[Multivariate analysis|multivariate]].

==Panel data==

A time series is one type of [[panel data]]. Panel data is the general class, a multidimensional data set, whereas a time series data set is a one-dimensional panel (as is a [[cross-sectional data]]set).  A data set may exhibit characteristics of both panel data and time series data.  One way to tell is to ask what makes one data record unique from the other records.  If the answer is the time data field, then this is a time series data set candidate.  If determining a unique record requires a time data field and an additional identifier which is unrelated to time (student ID, stock symbol, country code), then it is panel data candidate.  If the differentiation lies on the non-time identifier, then the data set is a cross-sectional data set candidate.

==Analysis==

There are several types of motivation and data analysis available for time series which are appropriate for different purposes.

===Motivation===

In the context of [[statistics]], [[econometrics]], [[quantitative finance]], [[seismology]], [[meteorology]], and [[geophysics]] the primary goal of time series analysis is [[forecasting]]. In the context of [[signal processing]], [[control engineering]] and [[communication engineering]] it is used for signal detection. Other application are in [[data mining]], [[pattern recognition]] and [[machine learning]], where time series analysis can be used for [[cluster analysis|clustering]],&lt;ref&gt;{{cite journal | last1 = Liao | first1 = T. Warren | title = Clustering of time series data - a survey | journal = Pattern Recognition | volume = 38 | issue = 11 | pages = 1857–1874 | publisher = Elsevier | date = 2005 | language = en | doi = 10.1016/j.patcog.2005.01.025}}{{subscription required|via=ScienceDirect }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Aghabozorgi | first1 = Saeed | last2 = Shirkhorshidi | first2 = Ali S. | last3 = Wah | first3 = Teh Y. | title = Time-series clustering – A decade review | journal = Information Systems | volume = 53 | pages = 16–38 | publisher = Elsevier | date = 2015 | language = en | doi = 10.1016/j.is.2015.04.007}}{{subscription required|via=ScienceDirect }}&lt;/ref&gt; [[Statistical classification|classification]],&lt;ref&gt;{{cite journal | last1 = Keogh | first1 = Eamonn J. | title = On the need for time series data mining benchmarks | journal = Data Mining and Knowledge Discovery | volume = 7 | pages = 349–371 | publisher = Kluwer | date = 2003 | language = en | doi = 10.1145/775047.775062| isbn = 158113567X }}{{subscription required|via=ACM Digital Library }}&lt;/ref&gt; query by content,&lt;ref&gt;{{cite conference|last1=Agrawal|first1=Rakesh|last2=Faloutsos|first2=Christos|last3=Swami|first3=Arun|date=October 1993|title=Efficient Similarity Search In Sequence Databases|conference=International Conference on Foundations of Data Organization and Algorithms|volume=730|pages=69–84|book-title=Proceedings of the 4th International Conference on Foundations of Data Organization and Algorithms|doi=10.1007/3-540-57301-1_5}}{{Subscription required|via=SpringerLink}}&lt;/ref&gt; [[anomaly detection]] as well as [[forecasting]].{{citation needed|date=October 2017}}

===Exploratory analysis===
[[File:Tuberculosis incidence US 1953-2009.png|thumb|Tuberculosis incidence US 1953-2009]]
{{further|Exploratory analysis}}
A straightforward way to examine a regular time series is manually with a [[line chart]]. An example chart is shown on the right for tuberculosis incidence in the United States, made with a spreadsheet program. The number of cases was standardized to a rate per 100,000 and the percent change per year in this rate was calculated. The nearly steadily dropping line shows that the TB incidence was decreasing in most years, but the percent change in this rate varied by as much as +/- 10%, with 'surges' in 1975 and around the early 1990s. The use of both vertical axes allows the comparison of two time series in one graphic.

Other techniques include:

* [[Autocorrelation]] analysis to examine [[serial dependence]]
* [[frequency spectrum#Spectrum analysis|Spectral analysis]] to examine cyclic behavior which need not be related to [[seasonality]]. For example, sun spot activity varies over 11 year cycles.&lt;ref&gt;{{cite book |last=Bloomfield |first=P. |year=1976 |title=Fourier analysis of time series: An introduction |location=New York |publisher=Wiley |isbn=978-0471082569 }}&lt;/ref&gt;&lt;ref&gt;{{cite book |last=Shumway |first=R. H. |year=1988 |title=Applied statistical time series analysis |location=Englewood Cliffs, NJ |publisher=Prentice Hall |isbn=978-0130415004 }}&lt;/ref&gt; Other common examples include celestial phenomena, weather patterns, neural activity, commodity prices, and economic activity.
* Separation into components representing trend, seasonality, slow and fast variation, and cyclical irregularity: see [[trend estimation]] and [[decomposition of time series]]

===Curve fitting===
{{main|Curve fitting}}

Curve fitting&lt;ref&gt;Sandra Lach Arlinghaus, PHB Practical Handbook of Curve Fitting. CRC Press, 1994.&lt;/ref&gt;&lt;ref&gt;William M. Kolb. Curve Fitting for Programmable Calculators. Syntec, Incorporated, 1984.&lt;/ref&gt; is the process of constructing a [[curve]], or [[function (mathematics)|mathematical function]], that has the best fit to a series of [[data]] points,&lt;ref&gt;S.S. Halli, K.V. Rao. 1992. Advanced Techniques of Population Analysis. {{isbn|0306439972}} Page 165 (''cf''. ... functions are fulfilled if we have a good to moderate fit for the observed data.)&lt;/ref&gt; possibly subject to constraints.&lt;ref&gt;[https://archive.org/details/signalnoisewhymo00silv ''[[The Signal and the Noise]]]: Why So Many Predictions Fail-but Some Don't.'' By Nate Silver&lt;/ref&gt;&lt;ref&gt;[https://books.google.com/books?id=hhdVr9F-JfAC Data Preparation for Data Mining]: Text. By Dorian Pyle.&lt;/ref&gt; Curve fitting can involve either [[interpolation]],&lt;ref&gt;Numerical Methods in Engineering with MATLAB®. By [[Jaan Kiusalaas]]. Page 24.&lt;/ref&gt;&lt;ref&gt;[https://books.google.com/books?id=YlkgAwAAQBAJ&amp;printsec=frontcover#v=onepage&amp;q=%22curve%20fitting%22&amp;f=false Numerical Methods in Engineering with Python 3]. By Jaan Kiusalaas. Page 21.&lt;/ref&gt; where an exact fit to the data is required, or [[smoothing]],&lt;ref&gt;[https://books.google.com/books?id=UjnB0FIWv_AC&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false Numerical Methods of Curve Fitting]. By P. G. Guest, Philip George Guest. Page 349.&lt;/ref&gt;&lt;ref&gt;See also: [[Mollifier]]&lt;/ref&gt; in which a "smooth" function is constructed that approximately fits the data.  A related topic is [[regression analysis]],&lt;ref&gt;[http://www.facm.ucl.ac.be/intranet/books/statistics/Prism-Regression-Book.unlocked.pdf Fitting Models to Biological Data Using Linear and Nonlinear Regression]. By Harvey Motulsky, Arthur Christopoulos.&lt;/ref&gt;&lt;ref&gt;Regression Analysis By Rudolf J. Freund, William J. Wilson, Ping Sa. Page 269.&lt;/ref&gt; which focuses more on questions of [[statistical inference]] such as how much uncertainty is present in a curve that is fit to data observed with random errors. Fitted curves can be used as an aid for data visualization,&lt;ref&gt;Visual Informatics. Edited by Halimah Badioze Zaman, Peter Robinson, Maria Petrou, Patrick Olivier, Heiko Schröder. Page 689.&lt;/ref&gt;&lt;ref&gt;[https://books.google.com/books?id=rdJvXG1k3HsC&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false Numerical Methods for Nonlinear Engineering Models]. By John R. Hauser. Page 227.&lt;/ref&gt; to infer values of a function where no data are available,&lt;ref&gt;Methods of Experimental Physics: Spectroscopy, Volume 13, Part 1. By Claire Marton. Page 150.&lt;/ref&gt; and to summarize the relationships among two or more variables.&lt;ref&gt;Encyclopedia of Research Design, Volume 1. Edited by Neil J. Salkind. Page 266.&lt;/ref&gt; [[Extrapolation]] refers to the use of a fitted curve beyond the [[range (statistics)|range]] of the observed data,&lt;ref&gt;[https://books.google.com/books?id=ba0hAQAAQBAJ&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false Community Analysis and Planning Techniques]. By Richard E. Klosterman. Page 1.&lt;/ref&gt; and is subject to a [[Uncertainty|degree of uncertainty]]&lt;ref&gt;An Introduction to Risk and Uncertainty in the Evaluation of Environmental Investments. DIANE Publishing. [https://books.google.com/books?id=rJ23LWaZAqsC&amp;pg=PA69 Pg 69]&lt;/ref&gt; since it may reflect the method used to construct the curve as much as it reflects the observed data.

The construction of economic time series involves the estimation of some components for some dates by [[interpolation]] between values ("benchmarks") for earlier and later dates. Interpolation is estimation of an unknown quantity between two known quantities (historical data), or drawing conclusions about missing information from the available information ("reading between the lines").&lt;ref&gt;Hamming, Richard. Numerical methods for scientists and engineers. Courier Corporation, 2012.&lt;/ref&gt; Interpolation is useful where the data surrounding the missing data is available and its trend, seasonality, and longer-term cycles are known. This is often done by using a related series known for all relevant dates.&lt;ref&gt;Friedman, Milton. "[http://www.nber.org/chapters/c2062.pdf The interpolation of time series by related series]." Journal of the American Statistical Association 57.300 (1962): 729–757.&lt;/ref&gt; Alternatively [[polynomial interpolation]] or [[spline interpolation]] is used where piecewise [[polynomial]] functions are fit into time intervals such that they fit smoothly together. A different problem which is closely related to interpolation is the approximation of a complicated function by a simple function (also called [[Polynomial regression|regression]]).The main difference between regression and interpolation is that polynomial regression gives a single polynomial that models the entire data set.  Spline interpolation, however, yield a piecewise continuous function composed of many polynomials to model the data set.

[[Extrapolation]] is the process of estimating, beyond the original observation range, the value of a variable on the basis of its relationship with another variable. It is similar to [[interpolation]], which produces estimates between known observations, but extrapolation is subject to greater [[uncertainty]] and a higher risk of producing meaningless results.

===Function approximation===
{{main|Function approximation}}
In general, a function approximation problem asks us to select a [[function (mathematics)|function]] among a well-defined class that closely matches ("approximates") a target function in a task-specific way.
One can distinguish two major classes of function approximation problems: First, for known target functions [[approximation theory]]  is the branch of [[numerical analysis]] that investigates how certain known functions (for example, [[special function]]s) can be approximated by a specific class of functions (for example, [[polynomial]]s or [[rational function]]s) that often have desirable properties (inexpensive computation, continuity, integral and limit values, etc.).

Second, the target function, call it ''g'', may be unknown; instead of an explicit formula, only a set of points (a time series) of the form (''x'', ''g''(''x'')) is provided.  Depending on the structure of the [[domain of a function|domain]] and [[codomain]] of ''g'', several techniques for approximating ''g'' may be applicable.  For example, if ''g'' is an operation on the [[real number]]s, techniques of [[interpolation]], [[extrapolation]], [[regression analysis]], and [[curve fitting]] can be used.  If the [[codomain]] (range or target set) of ''g'' is a finite set, one is dealing with a [[statistical classification|classification]] problem instead. A related problem of ''online'' time series approximation&lt;ref&gt;Gandhi, Sorabh, Luca Foschini, and Subhash Suri. "[https://ieeexplore.ieee.org/abstract/document/5447930/ Space-efficient online approximation of time series data: Streams, amnesia, and out-of-order]." Data Engineering (ICDE), 2010 IEEE 26th International Conference on. IEEE, 2010.&lt;/ref&gt; is to summarize the data in one-pass and construct an approximate representation that can support a variety of time series queries with bounds on worst-case error.

To some extent the different problems ([[regression analysis|regression]], [[Statistical classification|classification]], [[fitness approximation]]) have received a unified treatment in [[statistical learning theory]], where they are viewed as [[supervised learning]] problems.

===Prediction and forecasting===
In [[statistics]], [[prediction]] is a part of [[statistical inference]]. One particular approach to such inference is known as [[predictive inference]], but the prediction can be undertaken within any of the several approaches to statistical inference. Indeed, one description of statistics is that it provides a means of transferring knowledge about a sample of a population to the whole population, and to other related populations, which is not necessarily the same as prediction over time. When information is transferred across time, often to specific points in time, the process is known as [[forecasting]].
* Fully formed statistical models for [[stochastic simulation]] purposes, so as to generate alternative versions of the time series, representing what might happen over non-specific time-periods in the future
* Simple or fully formed statistical models to describe the likely outcome of the time series in the immediate future, given knowledge of the most recent outcomes (forecasting).
* Forecasting on time series is usually done using automated statistical software packages and programming languages, such as [[Julia (programming language)|Julia]], [[Python (programming language)|Python]], [[R (programming language)|R]], [[SAS (software)|SAS]], [[SPSS]] and many others.
* Forecasting on large scale data can be done with [[Apache Spark]] using the Spark-TS library, a third-party package.&lt;ref&gt;{{cite web |title=Time Series Analysis with Spark |author=Sandy Ryza |date=2020-03-18 |access-date=2021-01-12 |url=https://databricks.com/session/time-series-analysis-with-spark |format=slides of a talk at Spark Summit East 2016 |publisher=[[Databricks]]}}&lt;/ref&gt;

===Classification===
{{main|Statistical classification}}
Assigning time series pattern to a specific category, for example identify a word based on series of hand movements in [[sign language]].

===Signal estimation===
{{see also|Signal processing|Estimation theory}}
This approach is based on [[harmonic analysis]] and filtering of signals in the [[frequency domain]] using the [[Fourier transform]], and [[spectral density estimation]], the development of which was significantly accelerated during [[World War II]] by mathematician [[Norbert Wiener]], electrical engineers [[Rudolf E. Kálmán]], [[Dennis Gabor]] and others for filtering signals from noise and predicting signal values at a certain point in time. See [[Kalman filter]], [[Estimation theory]], and [[Digital signal processing]]

===Segmentation===
{{main|Time-series segmentation}}
Splitting a time-series into a sequence of segments. It is often the case that a time-series can be represented as a sequence of individual segments, each with its own characteristic properties. For example, the audio signal from a conference call can be partitioned into pieces corresponding to the times during which each person was speaking. In time-series segmentation, the goal is to identify the segment boundary points in the time-series, and to characterize the dynamical properties associated with each segment. One can approach this problem using [[Change detection|change-point detection]], or by modeling the time-series as a more sophisticated system, such as a Markov jump linear system.

==Models==

Models for time series data can have many forms and represent different [[stochastic processes]]. When modeling variations in the level of a process, three broad classes of practical importance are the ''[[autoregressive]]'' (AR) models, the ''integrated'' (I) models, and the ''[[moving average model|moving average]]'' (MA) models. These three classes depend linearly on previous data points.&lt;ref name="linear time series"&gt;{{cite book |author-link=Neil Gershenfeld |last=Gershenfeld |first=N. |year=1999 |title=The Nature of Mathematical Modeling |url=https://archive.org/details/naturemathematic00gers_334 |url-access=limited |location=New York |publisher=Cambridge University Press |pages=[https://archive.org/details/naturemathematic00gers_334/page/n206 205]–208 |isbn=978-0521570954 }}&lt;/ref&gt; Combinations of these ideas produce [[autoregressive moving average]] (ARMA) and [[autoregressive integrated moving average]] (ARIMA) models. The [[autoregressive fractionally integrated moving average]] (ARFIMA) model generalizes the former three. Extensions of these classes to deal with vector-valued data are available under the heading of multivariate time-series models and sometimes the preceding acronyms are extended by including an initial "V" for "vector", as in VAR for [[vector autoregression]]. An additional set of extensions of these models is available for use where the observed time-series is driven by some "forcing" time-series (which may not have a causal effect on the observed series): the distinction from the multivariate case is that the forcing series may be deterministic or under the experimenter's control. For these models, the acronyms are extended with a final "X" for "exogenous".

Non-linear dependence of the level of a series on previous data points is of interest, partly because of the possibility of producing a [[chaos theory|chaotic]] time series. However, more importantly, empirical investigations can indicate the advantage of using predictions derived from non-linear models, over those from linear models, as for example in [[nonlinear autoregressive exogenous model]]s. Further references on nonlinear time series analysis: (Kantz and Schreiber),&lt;ref&gt;{{cite book|last1=Kantz|first1=Holger|last2=Thomas|first2=Schreiber|title=Nonlinear Time Series Analysis|date=2004|publisher=Cambridge University Press|location=London|isbn=978-0521529020}}&lt;/ref&gt; and (Abarbanel)&lt;ref&gt;{{cite book|last1=Abarbanel|first1=Henry|title=Analysis of Observed Chaotic Data|date=Nov 25, 1997|publisher=Springer|location=New York|isbn=978-0387983721}}&lt;/ref&gt;

Among other types of non-linear time series models, there are models to represent the changes of variance over time ([[heteroskedasticity]]). These models represent [[autoregressive conditional heteroskedasticity]] (ARCH) and the collection comprises a wide variety of representation ([[GARCH]], TARCH, EGARCH, FIGARCH, CGARCH, etc.). Here changes in variability are related to, or predicted by, recent past values of the observed series. This is in contrast to other possible representations of locally varying variability, where the variability might be modelled as being driven by a separate time-varying process, as in a [[doubly stochastic model]].

In recent work on model-free analyses, wavelet transform based methods (for example locally stationary wavelets and wavelet decomposed neural networks) have gained favor. Multiscale (often referred to as multiresolution) techniques decompose a given time series, attempting to illustrate time dependence at multiple scales. See also [[Markov switching multifractal]] (MSMF) techniques for modeling volatility evolution.

A [[Hidden Markov model]] (HMM) is a statistical Markov model in which the system being modeled is assumed to be a Markov process with unobserved (hidden) states. An HMM can be considered as the simplest [[dynamic Bayesian network]]. HMM models are widely used in [[speech recognition]], for translating a time series of spoken words into text.

===Notation===
A number of different notations are in use for time-series analysis. A common notation specifying a time series ''X'' that is indexed by the [[natural number]]s is written
:''X'' = (''X''&lt;sub&gt;1&lt;/sub&gt;, ''X''&lt;sub&gt;2&lt;/sub&gt;, ...).

Another common notation is
:''Y'' = (''Y&lt;sub&gt;t&lt;/sub&gt;'': ''t'' ∈ ''T''),
where ''T'' is the [[index set]].

===Conditions===
There are two sets of conditions under which much of the theory is built:
* [[Stationary process]]
* [[Ergodic process]]

However, ideas of stationarity must be expanded to consider two important ideas: [[strict stationarity]] and [[Stationary process#Weaker forms of stationarity|second-order stationarity]]. Both models and applications can be developed under each of these conditions, although the models in the latter case might be considered as only partly specified.

In addition, time-series analysis can be applied where the series are [[Cyclostationary process|seasonally stationary]] or non-stationary. Situations where the amplitudes of frequency components change with time can be dealt with in [[time-frequency analysis]] which makes use of a [[time–frequency representation]] of a time-series or signal.&lt;ref&gt;Boashash, B. (ed.), (2003) ''Time-Frequency Signal Analysis and Processing: A Comprehensive Reference'', Elsevier Science, Oxford, 2003 {{isbn|0-08-044335-4}}&lt;/ref&gt;

===Tools===
Tools for investigating time-series data include:

* Consideration of the [[autocorrelation|autocorrelation function]] and the [[Spectral density|spectral density function]] (also [[cross-correlation function]]s and cross-spectral density functions)
* [[Scaled correlation|Scaled]] cross- and auto-correlation functions to remove contributions of slow components&lt;ref name="Nikolicetal"&gt;{{cite journal |last1=Nikolić |first1=D. |last2=Muresan |first2=R. C. |last3=Feng |first3=W. |last4=Singer |first4=W. |year=2012 |title=Scaled correlation analysis: a better way to compute a cross-correlogram |journal=European Journal of Neuroscience |volume=35 |issue=5 |pages=742–762 |doi=10.1111/j.1460-9568.2011.07987.x |pmid=22324876 |s2cid=4694570 |url=https://semanticscholar.org/paper/caa784fc3c22656413143559c402b54d0567f4d1 }}&lt;/ref&gt;
* Performing a [[Fourier transform]] to investigate the series in the [[frequency domain]]
* Use of a [[digital filter|filter]] to remove unwanted [[noise (physics)|noise]]
* [[Principal component analysis]] (or [[empirical orthogonal function]] analysis)
* [[Singular spectrum analysis]]
* "Structural" models:
** General [[State Space Model]]s
** Unobserved Components Models
* [[Machine Learning]]
** [[Artificial neural network]]s
** [[Support vector machine]]
** [[Fuzzy logic]]
** [[Gaussian process]]
** [[Hidden Markov model]]
* [[Queueing theory]] analysis
* [[Control chart]]
** [[Shewhart individuals control chart]]
** [[CUSUM]] chart
** [[EWMA chart]]
* [[Detrended fluctuation analysis]]
* [[Nonlinear mixed-effects model|Nonlinear mixed-effects modeling]]
* [[Dynamic time warping]]&lt;ref name="Sakoe 1978"&gt;{{cite book |last1=Sakoe |first1=Hiroaki |last2=Chiba |first2=Seibi |year=1978 |chapter=Dynamic programming algorithm optimization for spoken word recognition |volume=26 |pages=43–49 |doi=10.1109/TASSP.1978.1163055 |journal=IEEE Transactions on Acoustics, Speech, and Signal Processing |s2cid=17900407 |chapter-url=https://semanticscholar.org/paper/18f355d7ef4aa9f82bf5c00f84e46714efa5fd77 }}&lt;/ref&gt;
* [[Cross-correlation]]&lt;ref&gt;{{cite book |last1=Goutte |first1=Cyril |last2=Toft |first2=Peter |last3=Rostrup |first3=Egill |last4=Nielsen |first4=Finn Å. |last5=Hansen |first5=Lars Kai |year=1999 |chapter=On Clustering fMRI Time Series |volume=9 |issue=3 |pages=298–310 |doi=10.1006/nimg.1998.0391 |pmid=10075900 |journal=NeuroImage |s2cid=14147564 |chapter-url=https://semanticscholar.org/paper/2d5c663fb53d8348bdf3c4df0f881b5db2dcf5e3 }}&lt;/ref&gt;
* [[Dynamic Bayesian network]]
* [[Time-frequency representation|Time-frequency analysis techniques:]]
** [[Fast Fourier transform]]
** [[Continuous wavelet transform]]
** [[Short-time Fourier transform]]
** [[Chirplet transform]]
** [[Fractional Fourier transform]]
* [[Chaos theory|Chaotic analysis]]
** [[Correlation dimension]]
** [[Recurrence plot]]s
** [[Recurrence quantification analysis]]
** [[Lyapunov exponent]]s
** [[Entropy encoding]]

===Measures===
Time series metrics or [[Features (pattern recognition)|features]] that can be used for time series [[Classification (machine learning)|classification]] or [[regression analysis]]:&lt;ref&gt;{{cite journal |last1=Mormann |first1=Florian |last2=Andrzejak |first2=Ralph G. |last3=Elger |first3=Christian E. |last4=Lehnertz |first4=Klaus |title=Seizure prediction: the long and winding road |journal=[[Brain (journal)|Brain]] |year=2007 |volume=130 |issue=2 |pages=314–333 |doi=10.1093/brain/awl241 |pmid=17008335|doi-access=free }}&lt;/ref&gt;

* '''Univariate linear measures'''
** [[Moment (mathematics)]]
** [[Spectral band power]]
** [[Spectral edge frequency]]
** Accumulated [[Energy (signal processing)]]
** Characteristics of the [[autocorrelation]] function
** [[Hjorth parameters]]
** [[Fast Fourier transform|FFT]] parameters
** [[Autoregressive model]] parameters
** [[Mann–Kendall test]]
* '''Univariate non-linear measures'''
** Measures based on the [[correlation]] sum
** [[Correlation dimension]]
** [[Correlation integral]]
** [[Correlation density]]
** [[Correlation entropy]]
** [[Approximate entropy]]&lt;ref&gt;{{cite web |last1=Land |first1=Bruce |last2=Elias |first2=Damian |title=Measuring the 'Complexity' of a time series |url=http://www.nbb.cornell.edu/neurobio/land/PROJECTS/Complexity/ }}&lt;/ref&gt;
** [[Sample entropy]]
** {{iw2|Fourier entropy||uk|Ентропія Фур'є}}
** Wavelet entropy
** [[Rényi entropy]]
** Higher-order methods
** [[Marginal predictability]]
** [[Dynamical similarity]] index
** [[State space]] dissimilarity measures
** [[Lyapunov exponent]]
** Permutation methods
** [[Local flow]]
* '''Other univariate measures'''
** [[Algorithmic information theory|Algorithmic complexity]]
** [[Kolmogorov complexity]] estimates
** [[Hidden Markov Model]] states
** [[Rough path#Signature|Rough path signature]]&lt;ref&gt;[1] Chevyrev, I., Kormilitzin, A. (2016) "[https://arxiv.org/abs/1603.03788 A Primer on the Signature Method in Machine Learning], arXiv:1603.03788v1"&lt;/ref&gt;
** Surrogate time series and surrogate correction
** Loss of recurrence (degree of non-stationarity)
* '''Bivariate linear measures'''
** Maximum linear [[cross-correlation]]
** Linear [[Coherence (signal processing)]]
* '''Bivariate non-linear measures'''
** Non-linear interdependence
** Dynamical Entrainment (physics)
** Measures for [[Phase synchronization]]
** Measures for [[Phase locking]]
* '''Similarity measures''':&lt;ref&gt;{{cite journal |last1=Ropella |first1=G. E. P. |last2=Nag |first2=D. A. |last3=Hunt |first3=C. A. |title=Similarity measures for automated comparison of in silico and in vitro experimental results |journal=Engineering in Medicine and Biology Society |year=2003 |volume=3 |pages=2933–2936 |doi=10.1109/IEMBS.2003.1280532 |isbn=978-0-7803-7789-9 |s2cid=17798157 }}&lt;/ref&gt;
** [[Cross-correlation]]
** [[Dynamic Time Warping]]&lt;ref name="Sakoe 1978"/&gt;
** [[Hidden Markov Models]]
** [[Edit distance]]
** [[Total correlation]]
** [[Newey–West estimator]]
** [[Prais–Winsten estimation|Prais–Winsten transformation]]
** Data as Vectors in a Metrizable Space
*** [[Minkowski distance]]
*** [[Mahalanobis distance]]
** Data as time series with envelopes
*** Global [[standard deviation]]
*** Local [[standard deviation]]
*** Windowed [[standard deviation]]
** Data interpreted as stochastic series
*** [[Pearson product-moment correlation coefficient]]
*** [[Spearman's rank correlation coefficient]]
** Data interpreted as a [[probability distribution]] function
*** [[Kolmogorov–Smirnov test]]
*** [[Cramér–von Mises criterion]]

==Visualization==
Time series can be visualized with two categories of chart: Overlapping Charts and Separated Charts. Overlapping Charts display all-time series on the same layout while Separated Charts presents them on different layouts (but aligned for comparison purpose)&lt;ref&gt;{{cite web|last1=Tominski|first1=Christian|last2= Aigner|first2=Wolfgang|title=The TimeViz Browser:A Visual Survey of Visualization Techniques for Time-Oriented Data|url=http://survey.timeviz.net/|access-date=1 June 2014}}&lt;/ref&gt;

===Overlapping charts===
* [[Braided graphs]]
* Line charts
* Slope graphs
* {{iw2|GapChart||fr}}

===Separated charts===
* [[Horizon graphs]]
* Reduced line chart (small multiples)
* Silhouette graph
* Circular silhouette graph

==See also==
{{Columns-list|colwidth=30em|
* [[Anomaly time series]]
* [[Chirp]]
* [[Decomposition of time series]]
* [[Detrended fluctuation analysis]]
* [[Digital signal processing]]
* [[Distributed lag]]
* [[Estimation theory]]
* [[Forecasting]]
* [[Hurst exponent]]
* [[Monte Carlo method]]
* [[Panel analysis]]
* [[Random walk]]
* [[Scaled correlation]]
* [[Seasonal adjustment]]
* [[Sequence analysis]]
* [[Signal processing]]
* [[Time series database]] (TSDB)
* [[Trend estimation]]
* [[Unevenly spaced time series]]
}}

==References==
{{Reflist|2}}

==Further reading==
* {{Citation
 | author-link = George E. P. Box
 | last1 = Box | first1 = George
 | last2 = Jenkins   | first2 = Gwilym
 | title = Time Series Analysis: forecasting and control, rev. ed.
 | publisher = Holden-Day
 | location = Oakland, California
 | year = 1976
}}
* [[James Durbin|Durbin J.]], Koopman S.J. (2001), ''Time Series Analysis by State Space Methods'', [[Oxford University Press]].
* {{Citation
 | last = Gershenfeld | first =  Neil
 | year = 2000
 | title = The Nature of Mathematical Modeling
 | isbn = 978-0-521-57095-4
 | publisher = [[Cambridge University Press]]
 | oclc = 174825352
}}
* {{Citation
 | author-link = James D. Hamilton
 | last = Hamilton | first =  James
 | year = 1994
 | title = Time Series Analysis
 | isbn = 978-0-691-04289-3
 | publisher = [[Princeton University Press]]
}}
* [[Maurice Priestley|Priestley, M. B.]] (1981), ''Spectral Analysis and Time Series'', [[Academic Press]]. {{ISBN|978-0-12-564901-8}}
* {{Citation | last = Shasha | first = D. | title = High Performance Discovery in Time Series | publisher = [[Springer Science+Business Media|Springer]] | year = 2004 | isbn = 978-0-387-00857-8 }}
* Shumway R. H., Stoffer D. S. (2017), ''Time Series Analysis and its Applications: With R Examples (ed. 4)'', Springer, {{ISBN|978-3-319-52451-1}}
* Weigend A. S., Gershenfeld N. A. (Eds.) (1994), ''Time Series Prediction: Forecasting the Future and Understanding the Past''. Proceedings of the NATO Advanced Research Workshop on Comparative Time Series Analysis (Santa Fe, May 1992), [[Addison-Wesley]].
* [[Norbert Wiener|Wiener, N.]] (1949), ''Extrapolation, Interpolation, and Smoothing of Stationary Time Series'', [[MIT Press]].
* Woodward, W. A., Gray, H. L. &amp; Elliott, A. C. (2012), ''Applied Time Series Analysis'', [[CRC Press]].

==External links==
{{Commons category}}
*[http://www.itl.nist.gov/div898/handbook/pmc/section4/pmc4.htm Introduction to Time series Analysis (Engineering Statistics Handbook)] — A practical guide to Time series analysis.

{{Statistics}}
{{Portal bar|Mathematics}}
{{Authority control}}

{{DEFAULTSORT:Time Series}}
[[Category:Time series| ]]
[[Category:Statistical data types]]
[[Category:Mathematical and quantitative methods (economics)]]
[[Category:Machine learning]]</text>
      <sha1>tuv10leo3hvxvyz2fc8g3lzbkauknr1</sha1>
    </revision>
  </page>
  <page>
    <title>Convolutional neural network</title>
    <ns>0</ns>
    <id>40409788</id>
    <revision>
      <id>1005469928</id>
      <parentid>1005469891</parentid>
      <timestamp>2021-02-07T20:42:52Z</timestamp>
      <contributor>
        <username>ClueBot NG</username>
        <id>13286072</id>
      </contributor>
      <minor/>
      <comment>Reverting possible vandalism by [[Special:Contribs/156.193.25.225|156.193.25.225]] to version by EditorHunter. [[WP:CBFP|Report False Positive?]] Thanks, [[WP:CBNG|ClueBot NG]]. (3892212) (Bot)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="103431" xml:space="preserve">{{Other uses|CNN (disambiguation)}}
{{short description|Artificial neural network}}
{{More citations needed|date=June 2019}}
{{machine learning bar}}
In [[deep learning]], a '''convolutional neural network''' ('''CNN''', or '''ConvNet''') is a class of [[deep neural network]]s, most commonly applied to analyzing visual imagery.&lt;ref name="Valueva Nagornov Lyakhov Valuev 2020 pp. 232–243"&gt;{{cite journal | last1=Valueva | first1=M.V. | last2=Nagornov | first2=N.N. | last3=Lyakhov | first3=P.A. | last4=Valuev | first4=G.V. | last5=Chervyakov | first5=N.I. | title=Application of the residue number system to reduce hardware costs of the convolutional neural network implementation | journal=Mathematics and Computers in Simulation | publisher=Elsevier BV | volume=177 | year=2020 | issn=0378-4754 | doi=10.1016/j.matcom.2020.04.031 | pages=232–243 | quote=Convolutional neural networks are a promising tool for solving the problem of pattern recognition. }}&lt;/ref&gt; They are also known as '''shift invariant''' or '''space invariant artificial neural networks''' ('''SIANN'''), based on their shared-weights architecture and [[translation invariance]] characteristics.&lt;ref name=":0"&gt;{{Cite journal|last=Zhang|first=Wei|date=1988|title=Shift-invariant pattern recognition neural network and its optical architecture|url=https://drive.google.com/file/d/1nN_5odSG_QVae54EsQN_qSz-0ZsX6wA0/view?usp=sharing|journal=Proceedings of Annual Conference of the Japan Society of Applied Physics}}&lt;/ref&gt;&lt;ref name=":1"&gt;{{Cite journal|last=Zhang|first=Wei|date=1990|title=Parallel distributed processing model with local space-invariant interconnections and its optical architecture|url=https://drive.google.com/file/d/0B65v6Wo67Tk5ODRzZmhSR29VeDg/view?usp=sharing|journal=Applied Optics|volume=29|issue=32|pages=4790–7|doi=10.1364/AO.29.004790|pmid=20577468|bibcode=1990ApOpt..29.4790Z}}&lt;/ref&gt; They have applications in [[Computer vision|image and video recognition]], [[recommender system]]s,&lt;ref&gt;{{Cite book|url=http://papers.nips.cc/paper/5004-deep-content-based-music-recommendation.pdf|title=Deep content-based music recommendation|last1=van den Oord|first1=Aaron|last2=Dieleman|first2=Sander|last3=Schrauwen|first3=Benjamin|date=2013-01-01|publisher=Curran Associates, Inc.|editor-last=Burges|editor-first=C. J. C.|pages=2643–2651|editor-last2=Bottou|editor-first2=L.|editor-last3=Welling|editor-first3=M.|editor-last4=Ghahramani|editor-first4=Z.|editor-last5=Weinberger|editor-first5=K. Q.}}&lt;/ref&gt; [[image classification]], [[Image segmentation]], [[Medical image computing|medical image analysis]], [[natural language processing]],&lt;ref&gt;{{Cite book|last1=Collobert|first1=Ronan|last2=Weston|first2=Jason|date=2008-01-01|title=A Unified Architecture for Natural Language Processing: Deep Neural Networks with Multitask Learning|journal=Proceedings of the 25th International Conference on Machine Learning|series=ICML '08|location=New York, NY, USA|publisher=ACM|pages=160–167|doi=10.1145/1390156.1390177|isbn=978-1-60558-205-4|s2cid=2617020}}&lt;/ref&gt; [[Brain–computer interface|brain-computer interfaces]],&lt;ref&gt;{{Cite journal|last1=Avilov|first1=Oleksii|last2=Rimbert|first2=Sebastien|last3=Popov|first3=Anton|last4=Bougrain|first4=Laurent|date=July 2020|title=Deep Learning Techniques to Improve Intraoperative Awareness Detection from Electroencephalographic Signals|url=https://ieeexplore.ieee.org/document/9176228|journal=2020 42nd Annual International Conference of the IEEE Engineering in Medicine &amp; Biology Society (EMBC)|volume=2020|location=Montreal, QC, Canada|publisher=IEEE|pages=142–145|doi=10.1109/EMBC44109.2020.9176228|pmid=33017950|isbn=978-1-7281-1990-8|s2cid=221386616}}&lt;/ref&gt; and financial [[time series]].&lt;ref name="Tsantekidis 7–12"&gt;{{Cite journal|last1=Tsantekidis|first1=Avraam|last2=Passalis|first2=Nikolaos|last3=Tefas|first3=Anastasios|last4=Kanniainen|first4=Juho|last5=Gabbouj|first5=Moncef|last6=Iosifidis|first6=Alexandros|date=July 2017|title=Forecasting Stock Prices from the Limit Order Book Using Convolutional Neural Networks|journal=2017 IEEE 19th Conference on Business Informatics (CBI)|location=Thessaloniki, Greece|publisher=IEEE|pages=7–12|doi=10.1109/CBI.2017.23|isbn=978-1-5386-3035-8|s2cid=4950757}}&lt;/ref&gt;

CNNs are [[Regularization (mathematics)|regularized]] versions of [[multilayer perceptron]]s. Multilayer perceptrons usually mean fully connected networks, that is, each neuron in one layer is connected to all neurons in the next layer. The "fully-connectedness" of these networks makes them prone to [[overfitting]] data. Typical ways of regularization include adding some form of magnitude measurement of weights to the loss function. CNNs take a different approach towards regularization: they take advantage of the hierarchical pattern in data and assemble more complex patterns using smaller and simpler patterns. Therefore, on the scale of connectedness and complexity, CNNs are on the lower extreme.

Convolutional networks were [[mathematical biology|inspired]] by [[biological]] processes&lt;ref name=fukuneoscholar /&gt;&lt;ref name="hubelwiesel1968" /&gt;&lt;ref name="intro" /&gt;&lt;ref name="robust face detection"&gt;{{cite journal|last=Matusugu|first=Masakazu|year=2003|title=Subject independent facial expression recognition with robust face detection using a convolutional neural network|url=http://www.iro.umontreal.ca/~pift6080/H09/documents/papers/sparse/matsugo_etal_face_expression_conv_nnet.pdf|journal=Neural Networks|volume=16|issue=5|pages=555–559|doi=10.1016/S0893-6080(03)00115-1|pmid=12850007|author2=Katsuhiko Mori|author3=Yusuke Mitari|author4=Yuji Kaneda|access-date=17 November 2013}}&lt;/ref&gt; in that the connectivity pattern between [[Artificial neuron|neurons]] resembles the organization of the animal [[visual cortex]]. Individual [[cortical neuron]]s respond to stimuli only in a restricted region of the [[visual field]] known as the [[receptive field]]. The receptive fields of different neurons partially overlap such that they cover the entire visual field.

CNNs use relatively little pre-processing compared to other [[Image classification|image classification algorithms]]. This means that the network learns the [[Filter (signal processing)|filters]] that in traditional algorithms were [[Feature engineering|hand-engineered]]. This independence from prior knowledge and human effort in feature design is a major advantage.

{{toclimit|3}}

== Definition ==
The name “convolutional neural network” indicates that the network employs a mathematical operation called [[convolution]].
Convolutional networks are a specialized type of neural networks that use convolution in place of general matrix multiplication in at least one of their layers.&lt;ref&gt;{{cite book |last1=Ian Goodfellow and Yoshua Bengio and Aaron Courville |title=Deep Learning |date=2016 |publisher=MIT Press |page=326 |url=http://www.deeplearningbook.org}}&lt;/ref&gt;

== Architecture ==
A convolutional neural network consists of an input layer, [[Multilayer perceptron#Layers|hidden layers]] and an output layer. In any feed-forward neural network, any middle layers are called hidden because their inputs and outputs are masked by the activation function and final [[convolution]]. In a convolutional neural network, the hidden layers include layers that perform convolutions. Typically this includes a layer that does multiplication or other [[dot product]], and its activation function is commonly [[Rectifier (neural networks)|ReLU]]. This is followed by other convolution layers such as pooling layers, fully connected layers and normalization layers.

=== Convolutional layers ===
In a CNN, the input is a [[tensor]] with shape (number of images) x (image height) x (image width) x (input [[Channel (digital image)|channels]]). After passing through a convolutional layer, the image becomes abstracted to a feature map, with shape (number of images) x (feature map height) x (feature map width) x (feature map [[Channel (digital image)|channels]]). A convolutional layer within a neural network should have the following attributes:

* Convolutional filters/kernels defined by a width and height (hyper-parameters).
* The number of input channels and output channels (hyper-parameter).
* The depth of the convolution kernel/filter (the input channels) must equal the number channels (depth) of the input feature map.
* Convolution operation specific hyperparameters like padding size and stride.

Convolutional layers convolve the input and pass its result to the next layer. This is similar to the response of a neuron in the visual cortex to a specific stimulus.&lt;ref name="deeplearning"&gt;{{cite web|title=Convolutional Neural Networks (LeNet) – DeepLearning 0.1 documentation|url=http://deeplearning.net/tutorial/lenet.html|work=DeepLearning 0.1|publisher=LISA Lab|access-date=31 August 2013}}&lt;/ref&gt; Each convolutional neuron processes data only for its [[receptive field]]. Although [[Multilayer perceptron|fully connected feedforward neural networks]] can be used to learn features and classify data, this architecture is impractical for images. It would require a very high number of neurons, even in a shallow architecture, due to the very large input sizes associated with images, where each pixel is a relevant variable. For instance, a fully connected layer for a (small) image of size 100 x 100 has 10,000 weights for ''each'' neuron in the second layer. Instead, convolution reduces the number of free parameters, allowing the network to be deeper.&lt;ref&gt;{{Cite book|title=Guide to convolutional neural networks : a practical application to traffic-sign detection and classification|last=Habibi|first=Aghdam, Hamed|others=Heravi, Elnaz Jahani|isbn=9783319575490|location=Cham, Switzerland|oclc=987790957|date = 2017-05-30}}&lt;/ref&gt; For example, regardless of image size, tiling 5 x 5 region, each with the same shared weights, requires only 25 learnable parameters. Using regularized weights over fewer parameters avoids the vanishing gradient and exploding gradient problems seen during [[backpropagation]] in traditional neural networks.&lt;ref&gt;{{Cite book|last1=Venkatesan|first1=Ragav|url=https://books.google.com/books?id=bAM7DwAAQBAJ&amp;q=vanishing+gradient|title=Convolutional Neural Networks in Visual Computing: A Concise Guide|last2=Li|first2=Baoxin|date=2017-10-23|publisher=CRC Press|isbn=978-1-351-65032-8|language=en}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|last1=Balas|first1=Valentina E.|url=https://books.google.com/books?id=XRS_DwAAQBAJ&amp;q=exploding+gradient|title=Recent Trends and Advances in Artificial Intelligence and Internet of Things|last2=Kumar|first2=Raghvendra|last3=Srivastava|first3=Rajshree|date=2019-11-19|publisher=Springer Nature|isbn=978-3-030-32644-9|language=en}}&lt;/ref&gt;

=== Pooling layers ===
Convolutional networks may include local or global pooling layers to streamline the underlying computation. Pooling layers reduce the dimensions of the data by combining the outputs of neuron clusters at one layer into a single neuron in the next layer. Local pooling combines small clusters, typically 2 x 2. Global pooling acts on all the neurons of the convolutional layer.&lt;ref name="flexible" /&gt;&lt;ref&gt;{{cite web|last=[[Alex Krizhevsky|Krizhevsky]]|first=Alex|title=ImageNet Classification with Deep Convolutional Neural Networks|url=http://www.image-net.org/challenges/LSVRC/2012/supervision.pdf|access-date=17 November 2013}}&lt;/ref&gt; There are two common types of pooling:  max and average. ''Max pooling'' uses the maximum value of each cluster of neurons at the prior layer,&lt;ref name=Yamaguchi111990&gt;{{cite conference |title=A Neural Network for Speaker-Independent Isolated Word Recognition |last1=Yamaguchi |first1=Kouichi |last2=Sakamoto |first2=Kenji |last3=Akabane |first3=Toshio |last4=Fujimoto |first4=Yoshiji |date=November 1990 |location=Kobe, Japan |conference=First International Conference on Spoken Language Processing (ICSLP 90)|url=https://www.isca-speech.org/archive/icslp_1990/i90_1077.html}}&lt;/ref&gt;&lt;ref name="mcdns"&gt;{{cite book |last1=Ciresan |first1=Dan |first2=Ueli |last2=Meier |first3=Jürgen |last3=Schmidhuber |title=Multi-column deep neural networks for image classification |journal=2012 IEEE Conference on Computer Vision and Pattern Recognition |date=June 2012 |pages=3642–3649 |doi=10.1109/CVPR.2012.6248110 |arxiv=1202.2745 |isbn=978-1-4673-1226-4 |oclc=812295155 |publisher=[[Institute of Electrical and Electronics Engineers]] (IEEE) |location=New York, NY|citeseerx=10.1.1.300.3283 |s2cid=2161592 }}&lt;/ref&gt; while ''average pooling'' instead uses the average value.&lt;ref name="cnnbackground"&gt;"[https://www.academia.edu/37491583/A_Survey_of_FPGA-based_Accelerators_for_Convolutional_Neural_Networks A Survey of FPGA-based Accelerators for Convolutional Neural Networks]", NCAA, 2018&lt;/ref&gt;

=== Fully connected layers ===
Fully connected layers connect every neuron in one layer to every neuron in another layer. It is the same as a traditional [[multi-layer perceptron]] neural network (MLP). The flattened matrix goes through a fully connected layer to classify the images.

=== Receptive field ===
In neural networks, each neuron receives input from some number of locations in the previous layer. In a fully connected layer, each neuron receives input from ''every'' neuron of the previous layer. In a convolutional layer, each neuron receives input from only a restricted area of the previous layer called the neuron's ''receptive field''. Typically the area is a square (e.g., 5 by 5 neurons). (So, in a fully connected layer, the receptive field is the entire previous layer.) Thus in each convolutional layer, each neuron takes input from a larger area of pixels in the input image than previous layers. This is due to applying the convolution over and over, which takes into account the value of a pixel and its surrounding pixels.

=== Weights ===
Each neuron in a neural network computes an output value by applying a specific function to the input values coming from the receptive field in the previous layer. The function that is applied to the input values is determined by a vector of weights and a bias (typically real numbers). Learning consists of iteratively adjusting these biases and weights.

The vector of weights and the bias are called ''filters'' and represent particular [[Feature (machine learning)|feature]]s of the input (e.g., a particular shape). A distinguishing feature of CNNs is that many neurons can share the same filter. This reduces [[memory footprint]] because a single bias and a single vector of weights are used across all receptive fields sharing that filter, as opposed to each receptive field having its own bias and vector weighting.&lt;ref name="LeCun"&gt;{{cite web|url=http://yann.lecun.com/exdb/lenet/|title=LeNet-5, convolutional neural networks|last=LeCun|first=Yann|access-date=16 November 2013}}&lt;/ref&gt;

== History ==

CNN design follows vision processing in [[living organisms]].{{citation needed|date=October 2017}}

=== Receptive fields in the visual cortex ===
Work by [[David H. Hubel|Hubel]] and [[Torsten Wiesel|Wiesel]] in the 1950s and 1960s showed that cat and monkey visual [[Cortex (anatomy)|cortex]]es contain neurons that individually respond to small regions of the [[visual field]]. Provided the eyes are not moving, the region of visual space within which visual stimuli affect the firing of a single neuron is known as its [[receptive field]].&lt;ref name=":4" /&gt; Neighboring cells have similar and overlapping receptive fields.{{citation needed|date=October 2017}} Receptive field size and location varies systematically across the cortex to form a complete map of visual space.{{citation needed|date=October 2017}} The cortex in each hemisphere represents the contralateral [[visual field]].{{citation needed|date=October 2017}}

Their 1968 paper identified two basic visual cell types in the brain:&lt;ref name="hubelwiesel1968"&gt;{{Cite journal|title = Receptive fields and functional architecture of monkey striate cortex|journal = The Journal of Physiology|date = 1968-03-01|issn = 0022-3751|pmc = 1557912|pmid = 4966457|pages = 215–243|volume = 195|issue = 1|first1 = D. H.|last1 = Hubel|first2 = T. N.|last2 = Wiesel|doi=10.1113/jphysiol.1968.sp008455}}&lt;/ref&gt;

*[[simple cells (visual cortex)|simple cell]]s, whose output is maximized by straight edges having particular orientations within their receptive field
*[[complex cells (visual cortex)|complex cell]]s, which have larger [[receptive field]]s, whose output is insensitive to the exact position of the edges in the field.

Hubel and Wiesel also proposed a cascading model of these two types of cells for use in pattern recognition tasks.&lt;ref&gt;
{{cite book
|title = Brain and visual perception: the story of a 25-year collaboration
|author = David H. Hubel and Torsten N. Wiesel
|publisher = Oxford University Press US
|year = 2005
|isbn = 978-0-19-517618-6
|page = 106
|url = https://books.google.com/books?id=8YrxWojxUA4C&amp;pg=PA106 }}&lt;/ref&gt;&lt;ref name=":4"&gt;{{cite journal | pmc = 1363130 | pmid=14403679 | volume=148 | issue=3 | title=Receptive fields of single neurones in the cat's striate cortex | date=October 1959 | journal=J. Physiol. | pages=574–91 | last1 = Hubel | first1 = DH | last2 = Wiesel | first2 = TN | doi=10.1113/jphysiol.1959.sp006308}}&lt;/ref&gt;

=== Neocognitron, origin of the CNN architecture ===

The "[[neocognitron]]"&lt;ref name=fukuneoscholar&gt;{{cite journal | last1 = Fukushima | first1 = K. | year = 2007 | title = Neocognitron | journal = Scholarpedia | volume = 2 | issue = 1| page = 1717 | doi=10.4249/scholarpedia.1717| bibcode = 2007SchpJ...2.1717F | doi-access = free }}&lt;/ref&gt; was introduced by [[Kunihiko Fukushima]] in 1980.&lt;ref name="intro"&gt;{{cite journal|last=Fukushima|first=Kunihiko|title=Neocognitron: A Self-organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position|journal=Biological Cybernetics|year=1980|volume=36|issue=4|pages=193–202|url=http://www.cs.princeton.edu/courses/archive/spr08/cos598B/Readings/Fukushima1980.pdf|access-date=16 November 2013|doi=10.1007/BF00344251|pmid=7370364|s2cid=206775608}}&lt;/ref&gt;&lt;ref name=mcdns /&gt;&lt;ref&gt;{{cite journal |first1=Yann |last1=LeCun |first2=Yoshua |last2=Bengio |first3=Geoffrey |last3=Hinton |title=Deep learning |journal=Nature |volume=521 |issue=7553 |year=2015 |pages=436–444 |doi=10.1038/nature14539|pmid=26017442 |bibcode=2015Natur.521..436L |s2cid=3074096 }}&lt;/ref&gt;
It was inspired by the above-mentioned work of Hubel and Wiesel. The neocognitron introduced the two basic types of layers in CNNs: convolutional layers, and downsampling layers. A convolutional layer contains units whose receptive fields cover a patch of the previous layer. The weight vector (the set of adaptive parameters) of such a unit is often called a filter. Units can share filters. Downsampling layers contain units whose receptive fields cover patches of previous convolutional layers. Such a unit typically computes the average of the activations of the units in its patch. This downsampling helps to correctly classify objects in visual scenes even when the objects are shifted.

In a variant of the neocognitron called the cresceptron, instead of using Fukushima's spatial averaging, J. Weng et al. introduced a method called max-pooling where a downsampling unit computes the maximum of the activations of the units in its patch.&lt;ref name="weng1993"&gt;{{cite journal |first1=J |last1=Weng |first2=N |last2=Ahuja |first3=TS |last3=Huang |s2cid=8619176 |title=Learning recognition and segmentation of 3-D objects from 2-D images |journal=Proc. 4th International Conf. Computer Vision |year=1993 |pages=121–128 |doi=10.1109/ICCV.1993.378228 |isbn=0-8186-3870-2 }}&lt;/ref&gt; Max-pooling is often used in modern CNNs.&lt;ref name="schdeepscholar" /&gt;

Several supervised and unsupervised learning algorithms have been proposed over the decades to train the weights of a neocognitron.&lt;ref name=fukuneoscholar /&gt; Today, however, the CNN architecture is usually trained through [[backpropagation]].

The [[neocognitron]] is the first CNN which requires units located at multiple network positions to have shared weights. Neocognitrons were adapted in 1988 to analyze time-varying signals.&lt;ref&gt;{{cite journal|last=Homma|first=Toshiteru|author2=Les Atlas|author3=Robert Marks II|year=1988|title=An Artificial Neural Network for Spatio-Temporal Bipolar Patters: Application to Phoneme Classification|url=http://papers.nips.cc/paper/20-an-artificial-neural-network-for-spatio-temporal-bipolar-patterns-application-to-phoneme-classification.pdf|journal=Advances in Neural Information Processing Systems|volume=1|pages=31–40}}&lt;/ref&gt;

=== Time delay neural networks ===
The [[time delay neural network]] (TDNN) was introduced in 1987 by [[Alex Waibel]] et al. and was the first convolutional network, as it achieved shift invariance.&lt;ref name=Waibel1987&gt;{{cite conference |title=Phoneme Recognition Using Time-Delay Neural Networks |last1=Waibel |first1=Alex |date=December 1987 |location=Tokyo, Japan |conference=Meeting of the Institute of Electrical, Information and Communication Engineers (IEICE)}}&lt;/ref&gt; It did so by utilizing weight sharing in combination with [[Backpropagation]] training.&lt;ref name="speechsignal"&gt;[[Alex Waibel|Alexander Waibel]] et al., ''[http://www.inf.ufrgs.br/~engel/data/media/file/cmp121/waibel89_TDNN.pdf Phoneme Recognition Using Time-Delay Neural Networks]'' IEEE Transactions on Acoustics, Speech, and Signal Processing, Volume 37, No. 3, pp. 328. - 339 March 1989.&lt;/ref&gt; Thus, while also using a pyramidal structure as in the neocognitron, it performed a global optimization of the weights instead of a local one.&lt;ref name=Waibel1987 /&gt;

TDNNs are convolutional networks that share weights along the temporal dimension.&lt;ref&gt;{{cite encyclopedia |last1=LeCun |first1=Yann |last2=Bengio |first2=Yoshua | editor-last=Arbib |editor-first=Michael A. |title=Convolutional networks for images, speech, and time series |encyclopedia=The handbook of brain theory and neural networks |edition=Second |year=1995 |publisher=The MIT press|pages=276–278 |url=https://www.researchgate.net/publication/2453996}}&lt;/ref&gt; They allow speech signals to be processed time-invariantly. In 1990 Hampshire and Waibel introduced a variant which performs a two dimensional convolution.&lt;ref name="Hampshire1990"&gt;John B. Hampshire and Alexander Waibel, ''[http://papers.nips.cc/paper/213-connectionist-architectures-for-multi-speaker-phoneme-recognition.pdf Connectionist Architectures for Multi-Speaker Phoneme Recognition]'',  Advances in Neural Information Processing Systems, 1990, Morgan Kaufmann.&lt;/ref&gt; Since these TDNNs operated on spectrograms, the resulting phoneme recognition system was invariant to both shifts in time and in frequency. This inspired translation invariance in image processing with CNNs.&lt;ref name="speechsignal"/&gt; The tiling of neuron outputs can cover timed stages.&lt;ref name="video quality" /&gt;

TDNNs now achieve the best performance in far distance speech recognition.&lt;ref name=Ko2017&gt;{{cite conference |title=A Study on Data Augmentation of Reverberant Speech for Robust Speech Recognition |last1=Ko |first1=Tom |last2=Peddinti |first2=Vijayaditya |last3=Povey |first3=Daniel |last4=Seltzer |first4=Michael L. |last5=Khudanpur |first5=Sanjeev |date=March 2018 |location=New Orleans, LA, USA |conference=The 42nd IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2017)|url=https://www.danielpovey.com/files/2017_icassp_reverberation.pdf}}&lt;/ref&gt;

==== Max pooling ====
In 1990 Yamaguchi et al. introduced the concept of max pooling. They did so by combining TDNNs with max pooling in order to realize a speaker independent isolated word recognition system.&lt;ref name="Yamaguchi111990" /&gt; In their system they used several TDNNs per word, one for each [[syllable]]. The results of each TDNN over the input signal were combined using max pooling and the outputs of the pooling layers were then passed on to networks performing the actual word classification.

=== Image recognition with CNNs trained by gradient descent ===
A system to recognize hand-written [[ZIP Code]] numbers&lt;ref&gt;Denker, J S , Gardner, W R., Graf, H. P, Henderson, D, Howard, R E, Hubbard, W, Jackel, L D , BaIrd, H S, and Guyon (1989) [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.852.5499&amp;rep=rep1&amp;type=pdf Neural network recognizer for hand-written zip code digits], AT&amp;T Bell Laboratories&lt;/ref&gt; involved convolutions in which the kernel coefficients had been laboriously hand designed.&lt;ref name=":2"&gt;Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard, L. D. Jackel, [http://yann.lecun.com/exdb/publis/pdf/lecun-89e.pdf Backpropagation Applied to Handwritten Zip Code Recognition]; AT&amp;T Bell Laboratories&lt;/ref&gt;

[[Yann LeCun]] et al. (1989)&lt;ref name=":2" /&gt; used back-propagation to learn the convolution kernel coefficients directly from images of hand-written numbers. Learning was thus fully automatic, performed better than manual coefficient design, and was suited to a broader range of image recognition problems and image types.

This approach became a foundation of modern [[computer vision]].

==== LeNet-5 ====
{{main|LeNet}}
LeNet-5, a pioneering 7-level convolutional network by [[Yann LeCun|LeCun]] et al. in 1998,&lt;ref name="lecun98"&gt;{{cite journal|last=LeCun|first=Yann|author2=Léon Bottou |author3=Yoshua Bengio |author4=Patrick Haffner |title=Gradient-based learning applied to document recognition|journal=Proceedings of the IEEE|year=1998|volume=86|issue=11|pages=2278–2324|url=http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf|access-date=October 7, 2016|doi=10.1109/5.726791|citeseerx=10.1.1.32.9552}}&lt;/ref&gt; that classifies digits, was applied by several banks to recognize hand-written numbers on checks ({{Lang-en-GB|cheques}}) digitized in 32x32 pixel images. The ability to process higher resolution images requires larger and more layers of convolutional neural networks, so this technique is constrained by the availability of computing resources.

=== Shift-invariant neural network ===

Similarly, a shift invariant neural network was proposed by W. Zhang et al. for image character recognition in 1988.&lt;ref name=":0" /&gt;&lt;ref name=":1" /&gt; The architecture and training algorithm were modified in 1991&lt;ref&gt;{{Cite journal|last=Zhang|first=Wei|date=1991|title=Error Back Propagation with Minimum-Entropy Weights: A Technique for Better Generalization of 2-D Shift-Invariant NNs|url=https://drive.google.com/file/d/0B65v6Wo67Tk5dkJTcEMtU2c5Znc/view?usp=sharing|journal=Proceedings of the International Joint Conference on Neural Networks}}&lt;/ref&gt; and applied for medical image processing&lt;ref&gt;{{Cite journal|last=Zhang|first=Wei|date=1991|title=Image processing of human corneal endothelium based on a learning network|url=https://drive.google.com/file/d/0B65v6Wo67Tk5cm5DTlNGd0NPUmM/view?usp=sharing|journal=Applied Optics|volume=30|issue=29|pages=4211–7|doi=10.1364/AO.30.004211|pmid=20706526|bibcode=1991ApOpt..30.4211Z}}&lt;/ref&gt; and automatic detection of breast cancer in [[Mammography|mammograms]].&lt;ref&gt;{{Cite journal|last=Zhang|first=Wei|date=1994|title=Computerized detection of clustered microcalcifications in digital mammograms using a shift-invariant artificial neural network|url=https://drive.google.com/file/d/0B65v6Wo67Tk5Ml9qeW5nQ3poVTQ/view?usp=sharing|journal=Medical Physics|volume=21|issue=4|pages=517–24|doi=10.1118/1.597177|pmid=8058017|bibcode=1994MedPh..21..517Z}}&lt;/ref&gt;

A different convolution-based design was proposed in 1988&lt;ref&gt;Daniel Graupe, Ruey Wen Liu, George S Moschytz."[https://www.researchgate.net/profile/Daniel_Graupe2/publication/241130197_Applications_of_signal_and_image_processing_to_medicine/links/575eef7e08aec91374b42bd2.pdf Applications of neural networks to medical signal processing]". In Proc. 27th IEEE Decision and Control Conf.,  pp. 343–347, 1988.&lt;/ref&gt; for application to decomposition of one-dimensional [[electromyography]] convolved signals via de-convolution. This design was modified in 1989 to other de-convolution-based designs.&lt;ref&gt;Daniel Graupe, Boris Vern, G. Gruener, Aaron Field, and Qiu Huang. "[https://ieeexplore.ieee.org/abstract/document/100522/ Decomposition of surface EMG signals into single fiber action potentials by means of neural network]". Proc. IEEE International Symp. on Circuits and Systems, pp. 1008–1011, 1989.&lt;/ref&gt;&lt;ref&gt;Qiu Huang, Daniel Graupe, Yi Fang Huang, Ruey Wen Liu."[http://www.academia.edu/download/42092095/graupe_huang_q_huang_yf_liu_rw_1989.pdf Identification of firing patterns of neuronal signals]." In Proc. 28th IEEE Decision and Control Conf., pp. 266–271, 1989.&lt;/ref&gt;

=== Neural abstraction pyramid ===
[[File:Neural Abstraction Pyramid.jpg|alt=Neural Abstraction Pyramid|thumb|Neural abstraction pyramid]]
The feed-forward architecture of convolutional neural networks was extended in the neural abstraction pyramid&lt;ref&gt;{{cite book
|last1=Behnke
|first1=Sven
|year=2003
|title=Hierarchical Neural Networks for Image Interpretation
|url=https://www.ais.uni-bonn.de/books/LNCS2766.pdf
|series=Lecture Notes in Computer Science
|volume=2766
|publisher=Springer
|doi=10.1007/b11963
|isbn=978-3-540-40722-5
|s2cid=1304548
}}&lt;/ref&gt; by lateral and feedback connections. The resulting recurrent convolutional network allows for the flexible incorporation of contextual information to iteratively resolve local ambiguities. In contrast to previous models, image-like outputs at the highest resolution were generated, e.g., for semantic segmentation, image reconstruction, and object localization tasks.

=== GPU implementations ===

Although CNNs were invented in the 1980s, their breakthrough in the 2000s required fast implementations on [[graphics processing unit]]s (GPUs).

In 2004, it was shown by K. S. Oh and K. Jung that standard neural networks can be greatly accelerated on GPUs. Their implementation was 20 times faster than an equivalent implementation on [[CPU]].&lt;ref&gt;{{cite journal|last1=Oh|first1=KS|last2=Jung|first2=K|title=GPU implementation of neural networks.|journal=Pattern Recognition|date=2004|volume=37|issue=6|pages=1311–1314|doi=10.1016/j.patcog.2004.01.013}}&lt;/ref&gt;&lt;ref name="schdeepscholar"&gt;{{cite journal|last1=Schmidhuber|first1=Jürgen|title=Deep Learning|journal=Scholarpedia|url=http://www.scholarpedia.org/article/Deep_Learning|date=2015|volume=10|issue=11|pages=1527–54|pmid=16764513|doi=10.1162/neco.2006.18.7.1527|citeseerx=10.1.1.76.1541|s2cid=2309950}}&lt;/ref&gt; In 2005, another paper also emphasised the value of [[GPGPU]] for [[machine learning]].&lt;ref&gt;{{cite book|author1=Dave Steinkraus|author2=Patrice Simard|author3=Ian Buck|title=12th International Conference on Document Analysis and Recognition (ICDAR 2005)|date=2005|pages=1115–1119|chapter-url=http://www.computer.org/csdl/proceedings/icdar/2005/2420/00/24201115-abs.html|archive-date=2016-03-14|chapter=Using GPUs for Machine Learning Algorithms}}&lt;/ref&gt;

The first GPU-implementation of a CNN was described in 2006 by K. Chellapilla et al. Their implementation was 4 times faster than an equivalent implementation on CPU.&lt;ref&gt;{{cite book|author1=Kumar Chellapilla|author2=Sid Puri|author3=Patrice Simard|editor1-last=Lorette|editor1-first=Guy|title=Tenth International Workshop on Frontiers in Handwriting Recognition|date=2006|publisher=Suvisoft|chapter-url=https://hal.inria.fr/inria-00112631/document|archive-date=2016-03-14|chapter=High Performance Convolutional Neural Networks for Document Processing}}&lt;/ref&gt; Subsequent work also used GPUs, initially for other types of neural networks (different from CNNs), especially unsupervised neural networks.&lt;ref&gt;{{cite journal|last1=Hinton|first1=GE|last2=Osindero|first2=S|last3=Teh|first3=YW|title=A fast learning algorithm for deep belief nets.|journal=Neural Computation|date=Jul 2006|volume=18|issue=7|pages=1527–54|pmid=16764513|doi=10.1162/neco.2006.18.7.1527|citeseerx=10.1.1.76.1541|s2cid=2309950}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Bengio|first1=Yoshua|last2=Lamblin|first2=Pascal|last3=Popovici|first3=Dan|last4=Larochelle|first4=Hugo|title=Greedy Layer-Wise Training of Deep Networks|journal=Advances in Neural Information Processing Systems|date=2007|pages=153–160|url=http://papers.nips.cc/paper/3048-greedy-layer-wise-training-of-deep-networks.pdf}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Ranzato|first1=MarcAurelio|last2=Poultney|first2=Christopher|last3=Chopra|first3=Sumit|last4=LeCun|first4=Yann|title=Efficient Learning of Sparse Representations with an Energy-Based Model|journal=Advances in Neural Information Processing Systems|date=2007|url=http://yann.lecun.com/exdb/publis/pdf/ranzato-06.pdf}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Raina|first1=R|last2=Madhavan|first2=A|last3=Ng|first3=Andrew|title=Large-scale deep unsupervised learning using graphics processors.|journal=ICML|date=2009|pages=873–880|url=http://robotics.stanford.edu/~ang/papers/icml09-LargeScaleUnsupervisedDeepLearningGPU.pdf}}&lt;/ref&gt;

In 2010, Dan Ciresan et al. at [[IDSIA]] showed that even deep standard neural networks with many layers can be quickly trained on GPU by supervised learning through the old method known as [[backpropagation]]. Their network outperformed previous machine learning methods on the [[MNIST]] handwritten digits benchmark.&lt;ref&gt;{{cite journal|last1=Ciresan|first1=Dan|last2=Meier|first2=Ueli|last3=Gambardella|first3=Luca|last4=Schmidhuber|first4=Jürgen|title=Deep big simple neural nets for handwritten digit recognition.|journal=Neural Computation|date=2010|volume=22|issue=12|pages=3207–3220|doi=10.1162/NECO_a_00052|pmid=20858131|arxiv=1003.0358|s2cid=1918673}}&lt;/ref&gt; In 2011, they extended this GPU approach to CNNs, achieving an acceleration factor of 60, with impressive results.&lt;ref name="flexible"&gt;{{cite journal|last=Ciresan|first=Dan|author2=Ueli Meier |author3=Jonathan Masci |author4=Luca M. Gambardella |author5=Jurgen Schmidhuber |title=Flexible, High Performance Convolutional Neural Networks for Image Classification|journal=Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence-Volume Volume Two|year=2011|volume=2|pages=1237–1242|url=http://www.idsia.ch/~juergen/ijcai2011.pdf|access-date=17 November 2013}}&lt;/ref&gt; In 2011, they used such CNNs on GPU to win an image recognition contest where they achieved superhuman performance for the first time.&lt;ref&gt;{{Cite web|url=http://benchmark.ini.rub.de/?section=gtsrb&amp;subsection=results|title=IJCNN 2011 Competition result table|website=OFFICIAL IJCNN2011 COMPETITION|language=en-US|access-date=2019-01-14|date=2010}}&lt;/ref&gt; Between May 15, 2011 and September 30, 2012, their CNNs won no less than four image competitions.&lt;ref&gt;{{Cite web|url=http://people.idsia.ch/~juergen/computer-vision-contests-won-by-gpu-cnns.html|last1=Schmidhuber|first1=Jürgen|title=History of computer vision contests won by deep CNNs on GPU|language=en-US|access-date=14 January 2019|date=17 March 2017}}&lt;/ref&gt;&lt;ref name="schdeepscholar" /&gt; In 2012, they also significantly improved on the best performance in the literature for multiple image [[database]]s, including the [[MNIST database]], the NORB database, the HWDB1.0 dataset (Chinese characters) and the [[CIFAR-10|CIFAR10 dataset]] (dataset of 60000 32x32 labeled [[RGB images]]).&lt;ref name="mcdns" /&gt;

Subsequently, a similar GPU-based CNN by Alex Krizhevsky et al. won the [[ImageNet Large Scale Visual Recognition Challenge]] 2012.&lt;ref name=":02" /&gt; A very deep CNN with over 100 layers by Microsoft won the ImageNet 2015 contest.&lt;ref&gt;{{cite journal|last1=He|first1=Kaiming|last2=Zhang|first2=Xiangyu|last3=Ren|first3=Shaoqing|last4=Sun|first4=Jian|title=Deep Residual Learning for Image Recognition.|journal= 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)|pages=770–778|date=2016|url=http://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf|doi=10.1109/CVPR.2016.90|arxiv=1512.03385|isbn=978-1-4673-8851-1|s2cid=206594692}}&lt;/ref&gt;

=== Intel Xeon Phi implementations ===

Compared to the training of CNNs using [[GPU]]s, not much attention was given to the [[Intel Xeon Phi]] [[coprocessor]].&lt;ref&gt;
{{cite book
 | last1= Viebke
 | first1= Andre
 | last2= Pllana
 | first2= Sabri
 | title= 2015 IEEE 17th International Conference on High Performance Computing and Communications, 2015 IEEE 7th International Symposium on Cyberspace Safety and Security, and 2015 IEEE 12th International Conference on Embedded Software and Systems
 | chapter= The Potential of the Intel (R) Xeon Phi for Supervised Deep Learning
 | pages= 758–765
 | website= IEEE Xplore
 | publisher= IEEE 2015
 | doi= 10.1109/HPCC-CSS-ICESS.2015.45
 | isbn= 978-1-4799-8937-9
 | year= 2015
 | s2cid= 15411954
 | chapter-url= http://urn.kb.se/resolve?urn=urn:nbn:se:lnu:diva-47951
 }}
&lt;/ref&gt;
A notable development is a parallelization method for training convolutional neural networks on the Intel Xeon Phi, named Controlled Hogwild with Arbitrary Order of Synchronization (CHAOS).&lt;ref&gt;
{{cite journal
 | last1= Viebke
 | first1= Andre
 | last2= Memeti
 | first2= Suejb
 | last3= Pllana
 | first3= Sabri
 | last4= Abraham
 | first4= Ajith
 | title= CHAOS: a parallelization scheme for training convolutional neural networks on Intel Xeon Phi
 | journal= The Journal of Supercomputing
 | date= 2019
 | volume= 75
 | issue= 1
 | pages= 197–227
 | doi= 10.1007/s11227-017-1994-x
 | arxiv= 1702.07908
| s2cid= 14135321
 }}
&lt;/ref&gt;
CHAOS exploits both the thread- and [[SIMD]]-level parallelism that is available on the Intel Xeon Phi.

== Distinguishing features ==
In the past, traditional [[multilayer perceptron]] (MLP) models were used for image recognition.{{examples|date=October 2017}} However, the full connectivity between nodes, caused the [[curse of dimensionality]], and was computationally intractable with higher resolution images. A 1000×1000-pixel image with [[RGB color model|RGB color]] channels has 3 million weights, which is too high to feasibly process efficiently at scale with full connectivity.
[[File:Conv layers.png|left|thumb|237x237px|CNN layers arranged in 3 dimensions]]
For example, in [[CIFAR-10]], images are only of size 32×32×3 (32 wide, 32 high, 3 color channels), so a single fully connected neuron in a first hidden layer of a regular neural network would have 32*32*3 = 3,072 weights. A 200×200 image, however, would lead to neurons that have 200*200*3 = 120,000 weights.

Also, such network architecture does not take into account the spatial structure of data, treating input pixels which are far apart in the same way as pixels that are close together. This ignores [[locality of reference]] in image data, both computationally and semantically. Thus, full connectivity of neurons is wasteful for purposes such as image recognition that are dominated by [[Spatial locality|spatially local]] input patterns.

Convolutional neural networks are variants of multilayer perceptrons, designed to emulate the behavior of a [[visual cortex]]. These models mitigate the challenges posed by the MLP architecture by exploiting the strong spatially local correlation present in natural images. As opposed to MLPs, CNNs have the following distinguishing features:
* 3D volumes of neurons. The layers of a CNN have neurons arranged in [[Three-dimensional space|3 dimensions]]: width, height and depth.{{citation needed|date=March 2019}} where each neuron inside a convolutional layer is connected to only a small region of the layer before it, called a receptive field. Distinct types of layers, both locally and completely connected, are stacked to form a CNN architecture.
* Local connectivity: following the concept of receptive fields, CNNs exploit spatial locality by enforcing a local connectivity pattern between neurons of adjacent layers. The architecture thus ensures that the learned "[[Filter (signal processing)|filters]]" produce the strongest response to a spatially local input pattern. Stacking many such layers leads to [[Nonlinear filter|non-linear filters]] that become increasingly global (i.e. responsive to a larger region of pixel space) so that the network first creates representations of small parts of the input, then from them assembles representations of larger areas.
* Shared weights: In CNNs, each filter is replicated across the entire visual field. These replicated units share the same parameterization (weight vector and bias) and form a feature map. This means that all the neurons in a given convolutional layer respond to the same feature within their specific response field. Replicating units in this way allows for the resulting feature map to be [[Equivariant map|equivariant]] under changes in the locations of input features in the visual field, i.e. they grant translational equivariance.
* Pooling: In a CNN's pooling layers, feature maps are divided into rectangular sub-regions, and the features in each rectangle are independently down-sampled to a single value, commonly by taking their average or maximum value. In addition to reducing the sizes of feature maps, the pooling operation grants a degree of [[Translational symmetry|translational invariance]] to the features contained therein, allowing the CNN to be more robust to variations in their positions.

Together, these properties allow CNNs to achieve better generalization on [[Computer vision|vision problems]]. Weight sharing dramatically reduces the number of [[free parameter]]s learned, thus lowering the memory requirements for running the network and allowing the training of larger, more powerful networks.

== Building blocks ==
{{More citations needed section|date=June 2017}}

A CNN architecture is formed by a stack of distinct layers that transform the input volume into an output volume (e.g. holding the class scores) through a differentiable function. A few distinct types of layers are commonly used. These are further discussed below.[[File:Conv layer.png|left|thumb|Neurons of a convolutional layer (blue), connected to their receptive field (red)|229x229px]]

=== Convolutional layer ===
The convolutional layer is the core building block of a CNN. The layer's parameters consist of a set of learnable [[Filter (signal processing)|filters]] (or [[Kernel (image processing)|kernels]]), which have a small receptive field, but extend through the full depth of the input volume. During the forward pass, each filter is [[Convolution|convolved]] across the width and height of the input volume, computing the [[dot product]] between the filter entries and the input, producing a 2-dimensional [[Activation function|activation map]] of that filter. As a result, the network learns filters that activate when it detects some specific type of [[Feature (machine learning)|feature]] at some spatial position in the input.&lt;ref name="Géron Hands-on ML 2019"&gt;{{cite book
|last1=Géron
|first1=Aurélien
|title=Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow
|date=2019
|publisher=O'Reilly Media
|location=Sebastopol, CA
|isbn=978-1-492-03264-9
}}, pp. 448&lt;/ref&gt;&lt;ref group="nb"&gt;When applied to other types of data than image data, such as sound data, "spatial position" may variously correspond to different points in the [[time domain]], [[frequency domain]] or other [[Space (mathematics)|mathematical spaces]].&lt;/ref&gt;

Stacking the activation maps for all filters along the depth dimension forms the full output volume of the convolution layer. Every entry in the output volume can thus also be interpreted as an output of a neuron that looks at a small region in the input and shares parameters with neurons in the same activation map.

==== Local connectivity ====

[[File:Typical cnn.png|thumb|395x395px|Typical CNN architecture]]

When dealing with high-dimensional inputs such as images, it is impractical to connect neurons to all neurons in the previous volume because such a network architecture does not take the spatial structure of the data into account. Convolutional networks exploit spatially local correlation by enforcing a [[Sparse network|sparse local connectivity]] pattern between neurons of adjacent layers: each neuron is connected to only a small region of the input volume.

The extent of this connectivity is a [[Hyperparameter optimization|hyperparameter]] called the [[receptive field]] of the neuron. The connections are [[Spatial Locality|local in space]] (along width and height), but always extend along the entire depth of the input volume. Such an architecture ensures that the learnt filters produce the strongest response to a spatially local input pattern.

==== Spatial arrangement ====

Three [[Hyperparameter (machine learning)|hyperparameters]] control the size of the output volume of the convolutional layer: the depth, [[Stride of an array|stride]] and zero-padding.

* The ''&lt;u&gt;depth&lt;/u&gt;'' of the output volume controls the number of neurons in a layer that connect to the same region of the input volume. These neurons learn to activate for different features in the input. For example, if the first convolutional layer takes the raw image as input, then different neurons along the depth dimension may activate in the presence of various oriented edges, or blobs of color.
*&lt;u&gt;''Stride''&lt;/u&gt; controls how depth columns around the width and height are allocated. If the stride is 1, then we move the filters one pixel at a time. This leads to heavily [[Intersection (set theory)|overlapping]] receptive fields between the columns, and to large output volumes. For any integer &lt;math display="inline"&gt;S &gt; 0,&lt;/math&gt; a stride ''S'' means that the filter is translated ''S'' units at a time per output. In practice, &lt;math display="inline"&gt;S \geq 3&lt;/math&gt; is rare. A greater stride means smaller overlap of receptive fields and smaller spacial dimensions of the output volume.&lt;ref&gt;{{Cite web|url=https://cs231n.github.io/convolutional-networks/|title=CS231n Convolutional Neural Networks for Visual Recognition|website=cs231n.github.io|access-date=2017-04-25}}&lt;/ref&gt;
* Sometimes, it is convenient to pad the input with zeros on the border of the input volume. The size of this padding is a third hyperparameter. Padding provides control of the output volume spatial size. In particular, sometimes it is desirable to exactly preserve the spatial size of the input volume.

The spatial size of the output volume is a function of the input volume size &lt;math&gt;W&lt;/math&gt;, the kernel field size &lt;math&gt;K&lt;/math&gt; of the convolutional layer neurons, the stride &lt;math&gt;S&lt;/math&gt;, and the amount of zero padding &lt;math&gt;P&lt;/math&gt; on the border. The number of neurons that "fit" in a given volume is then:

&lt;math display="block"&gt;\frac{W-K+2P}{S} + 1.&lt;/math&gt;

If this number is not an [[integer]], then the strides are incorrect and the neurons cannot be tiled to fit across the input volume in a [[Symmetry|symmetric]] way. In general, setting zero padding to be &lt;math display="inline"&gt;P = (K-1)/2&lt;/math&gt; when the stride is &lt;math&gt;S=1&lt;/math&gt; ensures that the input volume and output volume will have the same size spatially. However, it is not always completely necessary to use all of the neurons of the previous layer. For example, a neural network designer may decide to use just a portion of padding.

==== Parameter sharing ====

A parameter sharing scheme is used in convolutional layers to control the number of free parameters. It relies on the assumption that if a patch feature is useful to compute at some spatial position, then it should also be useful to compute at other positions. Denoting a single 2-dimensional slice of depth as a ''depth slice'', the neurons in each depth slice are constrained to use the same weights and bias.

Since all neurons in a single depth slice share the same parameters, the forward pass in each depth slice of the convolutional layer can be computed as a [[convolution]] of the neuron's weights with the input volume.&lt;ref group="nb"&gt;hence the name "convolutional layer"&lt;/ref&gt; Therefore, it is common to refer to the sets of weights as a filter (or a [[Kernel (image processing)|kernel]]), which is convolved with the input. The result of this convolution is an [[Activation function|activation map]], and the set of activation maps for each different filter are stacked together along the depth dimension to produce the output volume. Parameter sharing contributes to the [[Translational symmetry|translation invariance]] of the CNN architecture.

Sometimes, the parameter sharing assumption may not make sense. This is especially the case when the input images to a CNN have some specific centered structure; for which we expect completely different features to be learned on different spatial locations. One practical example is when the inputs are faces that have been centered in the image: we might expect different eye-specific or hair-specific features to be learned in different parts of the image. In that case it is common to relax the parameter sharing scheme, and instead simply call the layer a "locally connected layer".

=== Pooling layer ===
[[File:Max pooling.png|thumb|314x314px|Max pooling with a 2x2 filter and stride = 2]]
Another important concept of CNNs is pooling, which is a form of non-linear [[Downsampling (signal processing)|down-sampling]]. There are several non-linear functions to implement pooling among which ''max pooling'' is the most common. It [[Partition of a set|partitions]] the input image into a set of non-overlapping rectangles and, for each such sub-region, outputs the maximum.

Intuitively, the exact location of a feature is less important than its rough location relative to other features. This is the idea behind the use of pooling in convolutional neural networks. The pooling layer serves to progressively reduce the spatial size of the representation, to reduce the number of parameters, [[memory footprint]] and amount of computation in the network, and hence to also control [[overfitting]]. It is common to periodically insert a pooling layer between successive convolutional layers (each one typically followed by a [[#ReLU layer|ReLU layer]]) in a CNN architecture.&lt;ref name="Géron Hands-on ML 2019"/&gt;{{rp|460–461}} The pooling operation can be used as another form of translation invariance.&lt;ref name="Géron Hands-on ML 2019"/&gt;{{rp|458}}

The pooling layer operates independently on every depth slice of the input and resizes it spatially. The most common form is a pooling layer with filters of size 2×2 applied with a stride of 2 downsamples at every depth slice in the input by 2 along both width and height, discarding 75% of the activations:
&lt;math display="block"&gt;f_{X,Y}(S)=\max_{a,b=0}^1S_{2X+a,2Y+b}.&lt;/math&gt;
In this case, every [[Maximum|max operation]] is over 4 numbers. The depth dimension remains unchanged.

In addition to max pooling, pooling units can use other functions, such as [[average]] pooling or [[Euclidean norm|ℓ&lt;sub&gt;2&lt;/sub&gt;-norm]] pooling. Average pooling was often used historically but has recently fallen out of favor compared to max pooling, which performs better in practice.&lt;ref name="Scherer-ICANN-2010"&gt;{{cite conference 
| url =http://ais.uni-bonn.de/papers/icann2010_maxpool.pdf 
| title =Evaluation of Pooling Operations in Convolutional Architectures for Object Recognition 
| last1 =Scherer 
| first1 =Dominik 
| last2 =Müller 
| first2 =Andreas C. 
| last3 =Behnke 
| first3 =Sven 
| year =2010 
| publisher =Springer 
| book-title =Artificial Neural Networks (ICANN), 20th International Conference on 
| pages =92–101 
| location =Thessaloniki, Greece 
}}&lt;/ref&gt;

Due to the aggressive reduction in the size of the representation,{{Which|date=December 2018}} there is a recent trend towards using smaller filters&lt;ref&gt;{{cite arXiv|title = Fractional Max-Pooling|eprint= 1412.6071|date = 2014-12-18|first = Benjamin|last = Graham|class= cs.CV}}&lt;/ref&gt; or discarding pooling layers altogether.&lt;ref&gt;{{cite arXiv|title = Striving for Simplicity: The All Convolutional Net|eprint= 1412.6806|date = 2014-12-21|first1 = Jost Tobias|last1 = Springenberg|first2 = Alexey|last2 = Dosovitskiy|first3 = Thomas|last3 = Brox|first4 = Martin|last4 = Riedmiller|class= cs.LG}}&lt;/ref&gt;

[[File:RoI pooling animated.gif|thumb|400x300px|RoI pooling to size 2x2. In this example region proposal (an input parameter) has size 7x5.]]
"[[Region of interest|Region of Interest]]" pooling (also known as RoI pooling) is a variant of max pooling, in which output size is fixed and input rectangle is a parameter.&lt;ref&gt;{{Cite web
  | last = Grel
  | first = Tomasz
  | title = Region of interest pooling explained
  | website = deepsense.io
  | date = 2017-02-28
  | url = https://deepsense.io/region-of-interest-pooling-explained/
  | access-date = &lt;!-----5 April 2017-----&gt;|language=en}}&lt;/ref&gt;

Pooling is an important component of convolutional neural networks for [[object detection]] based on Fast R-CNN&lt;ref name="rcnn"&gt;{{cite arXiv
|title = Fast R-CNN
|eprint= 1504.08083
|date = 2015-09-27
|first = Ross
|last = Girshick
|class= cs.CV}}&lt;/ref&gt; architecture.

=== ReLU layer ===
ReLU is the abbreviation of [[Rectifier (neural networks)|rectified linear unit]], which applies the non-saturating [[activation function]] &lt;math alt="function of x equals maximum between zero and x" display="inline"&gt;f(x)=\max(0,x)&lt;/math&gt;.&lt;ref name=":02"&gt;{{Cite journal|last1=Krizhevsky|first1=Alex|last2=Sutskever|first2=Ilya|last3=Hinton|first3=Geoffrey E.|date=2017-05-24|title=ImageNet classification with deep convolutional neural networks|url=https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf|journal=Communications of the ACM|volume=60|issue=6|pages=84–90|doi=10.1145/3065386|s2cid=195908774|issn=0001-0782}}&lt;/ref&gt; It effectively removes negative values from an activation map by setting them to zero.&lt;ref name="Romanuke4"&gt;{{cite journal |last1=Romanuke |first1=Vadim |title=Appropriate number and allocation of ReLUs in convolutional neural networks |journal=Research Bulletin of NTUU "Kyiv Polytechnic Institute" |date=2017 |volume=1 |pages=69–78|doi=10.20535/1810-0546.2017.1.88156|doi-access=free }}&lt;/ref&gt; It increases the [[Nonlinearity|nonlinear properties]] of the [[Decision boundary|decision function]] and of the overall network without affecting the receptive fields of the convolution layer.

Other functions are also used to increase nonlinearity, for example the saturating [[hyperbolic tangent]] &lt;math alt="function of x equals hyperbolic tangent of x"&gt;f(x)=\tanh(x)&lt;/math&gt;, &lt;math alt="function of x equals absolute value of the hyperbolic tangent of x"&gt;f(x)=|\tanh(x)|&lt;/math&gt;, and the [[sigmoid function]] &lt;math alt="function of x equals the inverse of one plus e to the power of minus x" display="inline"&gt;\sigma(x)=(1+e^{-x} )^{-1}&lt;/math&gt;. ReLU is often preferred to other functions because it trains the neural network several times faster without a significant penalty to [[Generalization (learning)|generalization]] accuracy.&lt;ref&gt;{{cite journal|last=Krizhevsky|first=A.|author2=Sutskever, I. |author3=Hinton, G. E. |title=Imagenet classification with deep convolutional neural networks|journal=Advances in Neural Information Processing Systems |volume=1|year=2012|pages=1097–1105|url=http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf}}&lt;/ref&gt;

=== Fully connected layer ===
After several convolutional and max pooling layers, the high-level reasoning in the neural network is done via fully connected layers. Neurons in a fully connected layer have connections to all activations in the previous layer, as seen in regular (non-convolutional) [[artificial neural network]]s. Their activations can thus be computed as an [[affine transformation]], with [[matrix multiplication]] followed by a bias offset ([[vector addition]] of a learned or fixed bias term).{{citation needed|date=November 2020}}

=== Loss layer ===
{{Main|Loss function|Loss functions for classification}}
The "loss layer" specifies how [[training]] penalizes the deviation between the predicted (output) and [[Ground truth|true]] labels and is normally the final layer of a neural network. Various [[loss function]]s appropriate for different tasks may be used.

[[Softmax function|Softmax]] loss is used for predicting a single class of ''K'' mutually exclusive classes.&lt;ref group="nb"&gt;So-called [[categorical data]].&lt;/ref&gt; [[Sigmoid function|Sigmoid]] [[Cross entropy|cross-entropy]] loss is used for predicting ''K'' independent probability values in &lt;math&gt;[0,1]&lt;/math&gt;. [[Euclidean distance|Euclidean]] loss is used for [[Regression (machine learning)|regressing]] to [[Real number|real-valued]] labels &lt;math&gt;(-\infty,\infty)&lt;/math&gt;.

== Choosing hyperparameters ==
{{More citations needed section|date=June 2017}}
CNNs use more [[Hyperparameter (machine learning)|hyperparameters]] than a standard multilayer perceptron (MLP). While the usual rules for [[learning rate]]s and [[Regularization (mathematics)|regularization]] constants still apply, the following should be kept in mind when optimizing.

=== Number of filters ===

Since feature map size decreases with depth, layers near the input layer tend to have fewer filters while higher layers can have more. To equalize computation at each layer, the product of feature values ''v&lt;sub&gt;a&lt;/sub&gt;'' with pixel position is kept roughly constant across layers. Preserving more information about the input would require keeping the total number of activations (number of feature maps times number of pixel positions) non-decreasing from one layer to the next.

The number of feature maps directly controls the capacity and depends on the number of available examples and task complexity.

=== Filter shape ===

Common filter shapes found in the literature vary greatly, and are usually chosen based on the data set.

The challenge is to find the right level of granularity so as to create abstractions at the proper scale, given a particular data set, and without [[overfitting]].

=== Max pooling shape ===

Typical values are 2×2. Very large input volumes may warrant 4×4 pooling in the lower layers.&lt;ref&gt;{{Cite web|url=https://adeshpande3.github.io/adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html|title=The 9 Deep Learning Papers You Need To Know About (Understanding CNNs Part 3)|last=Deshpande|first=Adit|website=adeshpande3.github.io|access-date=2018-12-04}}&lt;/ref&gt; However, choosing larger shapes will dramatically [[Dimensionality reduction|reduce the dimension]] of the signal, and may result in excess [[Data loss|information loss]]. Often, non-overlapping pooling windows perform best.&lt;ref name="Scherer-ICANN-2010" /&gt;

== Regularization methods ==
{{main|Regularization (mathematics)}}{{More citations needed section|date=June 2017}}
[[Regularization (mathematics)|Regularization]] is a process of introducing additional information to solve an [[ill-posed problem]] &lt;nowiki/&gt;or to prevent [[overfitting]]. CNNs use various types of regularization.

=== Empirical ===

==== Dropout ====
Because a fully connected layer occupies most of the parameters, it is prone to overfitting. One method to reduce overfitting is [[Dropout (neural networks)|dropout]].&lt;ref&gt;{{cite journal|last=Srivastava|first=Nitish|author2=C. Geoffrey Hinton|author3=Alex Krizhevsky |author4=Ilya Sutskever |author5=Ruslan Salakhutdinov|title=Dropout: A Simple Way to Prevent Neural Networks from overfitting|journal=Journal of Machine Learning Research |year=2014|volume=15|issue=1|pages=1929–1958|url=http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf}}&lt;/ref&gt;&lt;ref name="DLPATTERNS"&gt;{{Cite web | title=A Pattern Language for Deep Learning| author=Carlos E. Perez| url=http://www.deeplearningpatterns.com}}&lt;/ref&gt; At each training stage, individual nodes are either "dropped out" of the net (ignored) with probability &lt;math&gt;1-p&lt;/math&gt; or kept with probability &lt;math&gt;p&lt;/math&gt;, so that a reduced network is left; incoming and outgoing edges to a dropped-out node are also removed. Only the reduced network is trained on the data in that stage. The removed nodes are then reinserted into the network with their original weights.

In the training stages, &lt;math&gt;p&lt;/math&gt; is usually 0.5; for input nodes, it is typically much higher because information is directly lost when input nodes are ignored.

At testing time after training has finished, we would ideally like to find a sample average of all possible &lt;math&gt;2^n&lt;/math&gt; dropped-out networks; unfortunately this is unfeasible for large values of &lt;math&gt;n&lt;/math&gt;. However, we can find an approximation by using the full network with each node's output weighted by a factor of &lt;math&gt;p&lt;/math&gt;, so the [[expected value]] of the output of any node is the same as in the training stages. This is the biggest contribution of the dropout method: although it effectively generates &lt;math&gt;2^n&lt;/math&gt; neural nets, and as such allows for model combination, at test time only a single network needs to be tested.

By avoiding training all nodes on all training data, dropout decreases overfitting. The method also significantly improves training speed. This makes the model combination practical, even for [[deep neural network]]s. The technique seems to reduce node interactions, leading them to learn more robust features{{Clarify|reason=|date=December 2018}} that better generalize to new data.

==== DropConnect ====

DropConnect is the generalization of dropout in which each connection, rather than each output unit, can be dropped with probability &lt;math&gt;1-p&lt;/math&gt;. Each unit thus receives input from a random subset of units in the previous layer.&lt;ref&gt;{{Cite journal|title = Regularization of Neural Networks using DropConnect {{!}} ICML 2013 {{!}} JMLR W&amp;CP|pages = 1058–1066|url = http://jmlr.org/proceedings/papers/v28/wan13.html|website = jmlr.org|access-date = 2015-12-17|date = 2013-02-13}}&lt;/ref&gt;

DropConnect is similar to dropout as it introduces dynamic sparsity within the model, but differs in that the sparsity is on the weights, rather than the output vectors of a layer. In other words, the fully connected layer with DropConnect becomes a sparsely connected layer in which the connections are chosen at random during the training stage.

==== Stochastic pooling ====

A major drawback to Dropout is that it does not have the same benefits for convolutional layers, where the neurons are not fully connected.

In stochastic pooling,&lt;ref&gt;{{cite arXiv|title = Stochastic Pooling for Regularization of Deep Convolutional Neural Networks|eprint= 1301.3557|date = 2013-01-15|first1 = Matthew D.|last1 = Zeiler|first2 = Rob|last2 = Fergus|class= cs.LG}}&lt;/ref&gt; the conventional [[Deterministic algorithm|deterministic]] pooling operations are replaced with a stochastic procedure, where the activation within each pooling region is picked randomly according to a [[multinomial distribution]], given by the activities within the pooling region. This approach is free of hyperparameters and can be combined with other regularization approaches, such as dropout and [[data augmentation]].

An alternate view of stochastic pooling is that it is equivalent to standard max pooling but with many copies of an input image, each having small local [[Deformation theory|deformations]]. This is similar to explicit [[elastic deformation]]s of the input images,&lt;ref name=":3" /&gt; which delivers excellent performance on the [[MNIST database|MNIST data set]].&lt;ref name=":3"&gt;{{Cite journal|title = Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis – Microsoft Research|url = http://research.microsoft.com/apps/pubs/?id=68920|journal = Microsoft Research|access-date = 2015-12-17|date = August 2003|last1 = Platt|first1 = John|last2 = Steinkraus|first2 = Dave|last3 = Simard|first3 = Patrice Y.}}&lt;/ref&gt; Using stochastic pooling in a multilayer model gives an exponential number of deformations since the selections in higher layers are independent of those below.

==== Artificial data ====
{{Main|Data augmentation}}
Because the degree of model overfitting is determined by both its power and the amount of training it receives, providing a convolutional network with more training examples can reduce overfitting. Because these networks are usually trained with all available data, one approach is to either generate new data from scratch (if possible) or perturb existing data to create new ones. For example, input images could be asymmetrically cropped by a few percent to create new examples with the same label as the original.&lt;ref&gt;{{Cite arXiv|title = Improving neural networks by preventing co-adaptation of feature detectors|eprint=1207.0580|last1= Hinton|first1=Geoffrey E.|last2=Srivastava|first2=Nitish|last3=Krizhevsky|first3=Alex|last4=Sutskever|first4=Ilya|last5= Salakhutdinov|first5=Ruslan R.|class=cs.NE|year=2012}}&lt;/ref&gt;

=== Explicit ===

==== Early stopping ====
{{main|Early stopping}}
One of the simplest methods to prevent overfitting of a network is to simply stop the training before overfitting has had a chance to occur. It comes with the disadvantage that the learning process is halted.

==== Number of parameters ====
Another simple way to prevent overfitting is to limit the number of parameters, typically by limiting the number of hidden units in each layer or limiting network depth. For convolutional networks, the filter size also affects the number of parameters. Limiting the number of parameters restricts the predictive power of the network directly, reducing the complexity of the function that it can perform on the data, and thus limits the amount of overfitting. This is equivalent to a "[[zero norm]]".

==== Weight decay ====
A simple form of added regularizer is weight decay, which simply adds an additional error, proportional to the sum of weights ([[L1-norm|L1 norm]]) or squared magnitude ([[L2 norm]]) of the weight vector, to the error at each node. The level of acceptable model complexity can be reduced by increasing the proportionality constant('alpha' hyperparameter), thus increasing the penalty for large weight vectors.

L2 regularization is the most common form of regularization. It can be implemented by penalizing the squared magnitude of all parameters directly in the objective. The L2 regularization has the intuitive interpretation of heavily penalizing peaky weight vectors and preferring diffuse weight vectors. Due to multiplicative interactions between weights and inputs this has the useful property of encouraging the network to use all of its inputs a little rather than some of its inputs a lot.

L1 regularization is also common. It makes the weight vectors sparse during optimization. In other words, neurons with L1 regularization end up using only a sparse subset of their most important inputs and become nearly invariant to the noisy inputs. L1 with L2 regularizations can be combined; this is called [[Elastic net regularization]].

==== Max norm constraints ====
Another form of regularization is to enforce an absolute upper bound on the magnitude of the weight vector for every neuron and use [[Sparse approximation#Projected Gradient Descent|projected gradient descent]] to enforce the constraint. In practice, this corresponds to performing the parameter update as normal, and then enforcing the constraint by clamping the weight vector &lt;math&gt;\vec{w}&lt;/math&gt; of every neuron to satisfy &lt;math&gt;\|\vec{w}\|_{2}&lt;c&lt;/math&gt;. Typical values of &lt;math&gt;c&lt;/math&gt; are order of 3–4. Some papers report improvements&lt;ref&gt;{{Cite web|title = Dropout: A Simple Way to Prevent Neural Networks from Overfitting|url = http://jmlr.org/papers/v15/srivastava14a.html|website = jmlr.org|access-date = 2015-12-17}}&lt;/ref&gt; when using this form of regularization.

== Hierarchical coordinate frames ==
Pooling loses the precise spatial relationships between high-level parts (such as nose and mouth in a face image). These relationships are needed for identity recognition. Overlapping the pools so that each feature occurs in multiple pools, helps retain the information. Translation alone cannot extrapolate the understanding of geometric relationships to a radically new viewpoint, such as a different orientation or scale. On the other hand, people are very good at extrapolating; after seeing a new shape once they can recognize it from a different viewpoint.&lt;ref&gt;{{cite journal | last1 = Hinton | first1 = Geoffrey | year = 1979 | title = Some demonstrations of the effects of structural descriptions in mental imagery | journal = Cognitive Science | volume = 3 | issue = 3| pages = 231–250 | doi=10.1016/s0364-0213(79)80008-7}}&lt;/ref&gt;

An earlier common way to deal with this problem is to train the network on transformed data in different orientations, scales, lighting, etc. so that the network can cope with these variations. This is computationally intensive for large data-sets. The alternative is to use a hierarchy of coordinate frames and use a group of neurons to represent a conjunction of the shape of the feature and its pose relative to the [[retina]]. The pose relative to the retina is the relationship between the coordinate frame of the retina and the intrinsic features' coordinate frame.&lt;ref&gt;Rock, Irvin. "The frame of reference." The legacy of Solomon Asch: Essays in cognition and social psychology (1990): 243–268.&lt;/ref&gt;

Thus, one way to represent something is to embed the coordinate frame within it. This allows large features to be recognized by using the consistency of the poses of their parts (e.g. nose and mouth poses make a consistent prediction of the pose of the whole face). This approach ensures that the higher-level entity (e.g. face) is present when the lower-level (e.g. nose and mouth) agree on its prediction of the pose. The vectors of neuronal activity that represent pose ("pose vectors") allow spatial transformations modeled as linear operations that make it easier for the network to learn the hierarchy of visual entities and generalize across viewpoints. This is similar to the way the human [[visual system]] imposes coordinate frames in order to represent shapes.&lt;ref&gt;J. Hinton, Coursera lectures on Neural Networks, 2012, Url: https://www.coursera.org/learn/neural-networks {{Webarchive|url=https://web.archive.org/web/20161231174321/https://www.coursera.org/learn/neural-networks |date=2016-12-31 }}&lt;/ref&gt;

== Applications ==

=== Image recognition ===
CNNs are often used in [[image recognition]] systems. In 2012 an [[Per-comparison error rate|error rate]] of 0.23% on the [[MNIST database]] was reported.&lt;ref name="mcdns" /&gt; Another paper on using CNN for image classification reported that the learning process was "surprisingly fast"; in the same paper, the best published results as of 2011 were achieved in the MNIST database and the NORB database.&lt;ref name="flexible" /&gt; Subsequently, a similar CNN called 
[[AlexNet]]&lt;ref name=quartz&gt;{{cite web
|website=[[Quartz (website)|Quartz]]
|author=Dave Gershgorn
|title=The inside story of how AI got good enough to dominate Silicon Valley
|url=https://qz.com/1307091/the-inside-story-of-how-ai-got-good-enough-to-dominate-silicon-valley/
|date=18 June 2018
|access-date=5 October 2018
}}&lt;/ref&gt; won the [[ImageNet Large Scale Visual Recognition Challenge]] 2012.

When applied to [[facial recognition system|facial recognition]], CNNs achieved a large decrease in error rate.&lt;ref&gt;{{cite journal|last=Lawrence|first=Steve|author2=C. Lee Giles |author3=Ah Chung Tsoi |author4=Andrew D. Back |title=Face Recognition: A Convolutional Neural Network Approach|journal=IEEE Transactions on Neural Networks|year=1997|volume=8|issue=1|pages=98–113|citeseerx = 10.1.1.92.5813|doi=10.1109/72.554195|pmid=18255614}}&lt;/ref&gt; Another paper reported a 97.6% recognition rate on "5,600 still images of more than 10 subjects".&lt;ref name="robust face detection" /&gt; CNNs were used to assess [[video quality]] in an objective way after manual training; the resulting system had a very low [[root mean square error]].&lt;ref name="video quality"&gt;{{cite journal|last=Le Callet|first=Patrick|author2=Christian Viard-Gaudin|author3=Dominique Barba|year=2006|title=A Convolutional Neural Network Approach for Objective Video Quality Assessment|url=http://hal.univ-nantes.fr/docs/00/28/74/26/PDF/A_convolutional_neural_network_approach_for_objective_video_quality_assessment_completefinal_manuscript.pdf|journal=IEEE Transactions on Neural Networks|volume=17|issue=5|pages=1316–1327|doi=10.1109/TNN.2006.879766|pmid=17001990|s2cid=221185563|access-date=17 November 2013}}&lt;/ref&gt;

The [[ImageNet Large Scale Visual Recognition Challenge]] is a benchmark in object classification and detection, with millions of images and hundreds of object classes. In the ILSVRC 2014,&lt;ref name="ILSVRC2014"&gt;{{cite web|url=http://www.image-net.org/challenges/LSVRC/2014/results|title=ImageNet Large Scale Visual Recognition Competition 2014 (ILSVRC2014)|access-date=30 January 2016}}&lt;/ref&gt; a large-scale visual recognition challenge, almost every highly ranked team used CNN as their basic framework. The winner [[GoogLeNet]]&lt;ref name=googlenet&gt;{{cite journal|first1=Christian |last1=Szegedy  |first2=Wei |last2=Liu |first3=Yangqing |last3=Jia|first4=Pierre |last4=Sermanet|first5=Scott |last5=Reed|first6=Dragomir |last6=Anguelov|first7=Dumitru |last7=Erhan|first8=Vincent |last8=Vanhoucke|first9=Andrew |last9=Rabinovich|title = Going Deeper with Convolutions|url=https://archive.org/details/arxiv-1409.4842 |journal= Computing Research Repository|year=2014 |arxiv= 1409.4842|bibcode=2014arXiv1409.4842S}}&lt;/ref&gt; (the foundation of [[DeepDream]]) increased the mean average [[Precision and recall|precision]] of object detection to 0.439329, and reduced classification error to 0.06656, the best result to date. Its network applied more than 30 layers. That performance of convolutional neural networks on the ImageNet tests was close to that of humans.&lt;ref&gt;{{cite arXiv|eprint=1409.0575|last1=Russakovsky|first1=Olga|title=Image ''Net'' Large Scale Visual Recognition Challenge|last2=Deng|first2=Jia|last3=Su|first3=Hao|last4=Krause|first4=Jonathan|last5=Satheesh|first5=Sanjeev|last6=Ma|first6=Sean|last7=Huang|first7=Zhiheng|last8=Karpathy|first8=Andrej|author-link8=Andrej Karpathy|last9=Khosla|first9=Aditya|last10=Bernstein|first10=Michael|last11= Berg|first11=Alexander C.|last12=Fei-Fei|first12=Li|class=cs.CV|year=2014|author1-link=Olga Russakovsky}}&lt;/ref&gt; The best algorithms still struggle with objects that are small or thin, such as a small ant on a stem of a flower or a person holding a quill in their hand. They also have trouble with images that have been distorted with filters, an increasingly common phenomenon with modern digital cameras. By contrast, those kinds of images rarely trouble humans. Humans, however, tend to have trouble with other issues. For example, they are not good at classifying objects into fine-grained categories such as the particular breed of dog or species of bird, whereas convolutional neural networks handle this.{{citation needed|date=June 2019}}

In 2015 a many-layered CNN demonstrated the ability to spot faces from a wide range of angles, including upside down, even when partially occluded, with competitive performance. The network was trained on a database of 200,000 images that included faces at various angles and orientations and a further 20 million images without faces. They used batches of 128 images over 50,000 iterations.&lt;ref&gt;{{Cite news|url = http://www.technologyreview.com/view/535201/the-face-detection-algorithm-set-to-revolutionize-image-search|title = The Face Detection Algorithm Set To Revolutionize Image Search|date = February 16, 2015|work = Technology Review|access-date = 27 October 2017}}&lt;/ref&gt;

=== Video analysis ===
Compared to image data domains, there is relatively little work on applying CNNs to video classification. Video is more complex than images since it has another (temporal) dimension. However, some extensions of CNNs into the video domain have been explored. One approach is to treat space and time as equivalent dimensions of the input and perform convolutions in both time and space.&lt;ref&gt;{{Cite book|publisher = Springer Berlin Heidelberg|date = 2011-11-16|isbn = 978-3-642-25445-1|pages = 29–39|series = Lecture Notes in Computer Science|first1 = Moez|last1 = Baccouche|first2 = Franck|last2 = Mamalet|first3 = Christian|last3 = Wolf|first4 = Christophe|last4 = Garcia|first5 = Atilla|last5 = Baskurt|editor-first = Albert Ali|editor-last = Salah|editor-first2 = Bruno|editor-last2 = Lepri|doi = 10.1007/978-3-642-25446-8_4|chapter = Sequential Deep Learning for Human Action Recognition|title = Human Behavior Unterstanding|volume = 7065|citeseerx = 10.1.1.385.4740}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|title = 3D Convolutional Neural Networks for Human Action Recognition|journal = IEEE Transactions on Pattern Analysis and Machine Intelligence|date = 2013-01-01|issn = 0162-8828|pages = 221–231|volume = 35|issue = 1|doi = 10.1109/TPAMI.2012.59|pmid = 22392705|first1 = Shuiwang|last1 = Ji|first2 = Wei|last2 = Xu|first3 = Ming|last3 = Yang|first4 = Kai|last4 = Yu|citeseerx = 10.1.1.169.4046|s2cid = 1923924}}&lt;/ref&gt; Another way is to fuse the features of two convolutional neural networks, one for the spatial and one for the temporal stream.&lt;ref&gt;{{cite arxiv | last1=Huang | first1=Jie | last2=Zhou | first2=Wengang | last3=Zhang | first3=Qilin | last4=Li | first4=Houqiang | last5=Li | first5=Weiping | title=Video-based Sign Language Recognition without Temporal Segmentation |eprint=1801.10111| class=cs.CV | year=2018 }}&lt;/ref&gt;&lt;ref&gt;Karpathy, Andrej, et al. "[https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Karpathy_Large-scale_Video_Classification_2014_CVPR_paper.pdf Large-scale video classification with convolutional neural networks]." IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2014.&lt;/ref&gt;&lt;ref&gt;{{cite arXiv|eprint=1406.2199|last1=Simonyan|first1=Karen|title=Two-Stream Convolutional Networks for Action Recognition in Videos|last2=Zisserman|first2=Andrew|class=cs.CV|year=2014}} (2014).&lt;/ref&gt; [[Long short-term memory]] (LSTM) [[Recurrent neural network|recurrent]] units are typically incorporated after the CNN to account for inter-frame or inter-clip dependencies.&lt;ref name="Wang Duan Zhang Niu p=1657"&gt;{{cite journal | last1=Wang | first1=Le | last2=Duan | first2=Xuhuan | last3=Zhang | first3=Qilin | last4=Niu | first4=Zhenxing | last5=Hua | first5=Gang | last6=Zheng | first6=Nanning | title=Segment-Tube: Spatio-Temporal Action Localization in Untrimmed Videos with Per-Frame Segmentation | journal=Sensors | volume=18 | issue=5 | date=2018-05-22 | issn=1424-8220 | doi=10.3390/s18051657 | pmid=29789447 | pmc=5982167 | page=1657 | url=https://qilin-zhang.github.io/_pages/pdfs/Segment-Tube_Spatio-Temporal_Action_Localization_in_Untrimmed_Videos_with_Per-Frame_Segmentation.pdf}}&lt;/ref&gt;&lt;ref name="Duan Wang Zhai Zheng 2018 p. "&gt;{{cite conference | last1=Duan | first1=Xuhuan | last2=Wang | first2=Le | last3=Zhai | first3=Changbo | last4=Zheng | first4=Nanning | last5=Zhang | first5=Qilin | last6=Niu | first6=Zhenxing | last7=Hua | first7=Gang | title=Joint Spatio-Temporal Action Localization in Untrimmed Videos with Per-Frame Segmentation | publisher=25th IEEE International Conference on Image Processing (ICIP)
| year=2018 | isbn=978-1-4799-7061-2 | doi=10.1109/icip.2018.8451692 }}&lt;/ref&gt; [[Unsupervised learning]] schemes for training spatio-temporal features have been introduced, based on Convolutional Gated Restricted [[Boltzmann machine|Boltzmann Machines]]&lt;ref&gt;{{Cite book|title = Convolutional Learning of Spatio-temporal Features|url = http://dl.acm.org/citation.cfm?id=1888212.1888225|publisher = Springer-Verlag|journal = Proceedings of the 11th European Conference on Computer Vision: Part VI|date = 2010-01-01|location = Berlin, Heidelberg|isbn = 978-3-642-15566-6|pages = 140–153|series = ECCV'10|first1 = Graham W.|last1 = Taylor|first2 = Rob|last2 = Fergus|first3 = Yann|last3 = LeCun|first4 = Christoph|last4 = Bregler}}&lt;/ref&gt; and Independent Subspace Analysis.&lt;ref&gt;{{Cite book|title = Learning Hierarchical Invariant Spatio-temporal Features for Action Recognition with Independent Subspace Analysis|publisher = IEEE Computer Society|journal = Proceedings of the 2011 IEEE Conference on Computer Vision and Pattern Recognition|date = 2011-01-01|location = Washington, DC, USA|isbn = 978-1-4577-0394-2|pages = 3361–3368|series = CVPR '11|doi = 10.1109/CVPR.2011.5995496|first1 = Q. V.|last1 = Le|first2 = W. Y.|last2 = Zou|first3 = S. Y.|last3 = Yeung|first4 = A. Y.|last4 = Ng|citeseerx = 10.1.1.294.5948|s2cid = 6006618}}&lt;/ref&gt;

=== Natural language processing ===
CNNs have also been explored for [[natural language processing]]. CNN models are effective for various NLP problems and achieved excellent results in [[semantic parsing]],&lt;ref&gt;{{cite arXiv|title = A Deep Architecture for Semantic Parsing|eprint= 1404.7296|date = 2014-04-29|first1 = Edward|last1 = Grefenstette|first2 = Phil|last2 = Blunsom|first3 = Nando|last3 = de Freitas|first4 = Karl Moritz|last4 = Hermann|class= cs.CL}}&lt;/ref&gt; search query retrieval,&lt;ref&gt;{{Cite journal|title = Learning Semantic Representations Using Convolutional Neural Networks for Web Search – Microsoft Research|url = http://research.microsoft.com/apps/pubs/default.aspx?id=214617|journal = Microsoft Research|access-date = 2015-12-17|date = April 2014|last1 = Mesnil|first1 = Gregoire|last2 = Deng|first2 = Li|last3 = Gao|first3 = Jianfeng|last4 = He|first4 = Xiaodong|last5 = Shen|first5 = Yelong}}&lt;/ref&gt; sentence modeling,&lt;ref&gt;{{cite arXiv|title = A Convolutional Neural Network for Modelling Sentences|eprint= 1404.2188|date = 2014-04-08|first1 = Nal|last1 = Kalchbrenner|first2 = Edward|last2 = Grefenstette|first3 = Phil|last3 = Blunsom|class= cs.CL}}&lt;/ref&gt; classification,&lt;ref&gt;{{cite arXiv|title = Convolutional Neural Networks for Sentence Classification|eprint= 1408.5882|date = 2014-08-25|first = Yoon|last = Kim|class= cs.CL}}&lt;/ref&gt; prediction&lt;ref&gt;Collobert, Ronan, and Jason Weston. "[https://thetalkingmachines.com/sites/default/files/2018-12/unified_nlp.pdf A unified architecture for natural language processing: Deep neural networks with multitask learning]."Proceedings of the 25th international conference on Machine learning. ACM, 2008.&lt;/ref&gt; and other traditional NLP tasks.&lt;ref&gt;{{cite arXiv|title = Natural Language Processing (almost) from Scratch|eprint= 1103.0398|date = 2011-03-02|first1 = Ronan|last1 = Collobert|first2 = Jason|last2 = Weston|first3 = Leon|last3 = Bottou|first4 = Michael|last4 = Karlen|first5 = Koray|last5 = Kavukcuoglu|first6 = Pavel|last6 = Kuksa|class= cs.LG}}&lt;/ref&gt;

=== Anomaly Detection ===
A CNN with 1-D convolutions was used on time series in the frequency domain (spectral residual) by an unsupervised model to detect anomalies in the time domain.&lt;ref&gt;{{Cite journal|title=Time-Series Anomaly Detection Service at Microsoft {{!}} Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining|language=EN|arxiv = 1906.03821|last1=Ren|first1=Hansheng|last2=Xu|first2=Bixiong|last3=Wang|first3=Yujing|last4=Yi|first4=Chao|last5=Huang|first5=Congrui|last6=Kou|first6=Xiaoyu|last7=Xing|first7=Tony|last8=Yang|first8=Mao|last9=Tong|first9=Jie|last10=Zhang|first10=Qi|year=2019|doi=10.1145/3292500.3330680|s2cid=182952311}}&lt;/ref&gt;

=== Drug discovery ===
CNNs have been used in [[drug discovery]]. Predicting the interaction between molecules and biological [[proteins]] can identify potential treatments. In 2015, Atomwise introduced AtomNet, the first deep learning neural network for structure-based [[Drug design|rational drug design]].&lt;ref&gt;{{cite arXiv|title = AtomNet: A Deep Convolutional Neural Network for Bioactivity Prediction in Structure-based Drug Discovery|eprint= 1510.02855|date = 2015-10-09|first1 = Izhar|last1 = Wallach|first2 = Michael|last2 = Dzamba|first3 = Abraham|last3 = Heifets|class= cs.LG}}&lt;/ref&gt; The system trains directly on 3-dimensional representations of chemical interactions. Similar to how image recognition networks learn to compose smaller, spatially proximate features into larger, complex structures,&lt;ref&gt;{{cite arXiv|title = Understanding Neural Networks Through Deep Visualization|eprint= 1506.06579|date = 2015-06-22|first1 = Jason|last1 = Yosinski|first2 = Jeff|last2 = Clune|first3 = Anh|last3 = Nguyen|first4 = Thomas|last4 = Fuchs|first5 = Hod|last5 = Lipson|class= cs.CV}}&lt;/ref&gt; AtomNet discovers chemical features, such as [[aromaticity]], [[orbital hybridisation|sp&lt;sup&gt;3&lt;/sup&gt; carbons]] and [[hydrogen bond]]ing. Subsequently, AtomNet was used to predict novel candidate [[biomolecule]]s for multiple disease targets, most notably treatments for the [[Ebola virus]]&lt;ref&gt;{{Cite news|title = Toronto startup has a faster way to discover effective medicines|url = https://www.theglobeandmail.com/report-on-business/small-business/starting-out/toronto-startup-has-a-faster-way-to-discover-effective-medicines/article25660419/|website = The Globe and Mail|access-date = 2015-11-09}}&lt;/ref&gt; and [[multiple sclerosis]].&lt;ref&gt;{{Cite web|title = Startup Harnesses Supercomputers to Seek Cures|url = http://ww2.kqed.org/futureofyou/2015/05/27/startup-harnesses-supercomputers-to-seek-cures/|website = KQED Future of You|access-date = 2015-11-09|language = en-us|date = 2015-05-27}}&lt;/ref&gt;

=== Health risk assessment and biomarkers of aging discovery ===

CNNs can be naturally tailored to analyze a sufficiently large collection of [[time series]] data representing one-week-long human physical activity streams augmented by the rich clinical data (including the death register, as provided by, e.g., the [[National Health and Nutrition Examination Survey|NHANES]] study). A simple CNN was combined with Cox-Gompertz [[proportional hazards model]] and used to produce a proof-of-concept example of digital [[biomarkers of aging]] in the form of all-causes-mortality predictor.&lt;ref name="pmid 29581467"&gt;{{cite journal | author1=Tim Pyrkov | author2=Konstantin Slipensky | author3=Mikhail Barg | author4=Alexey Kondrashin | author5=Boris Zhurov | author6=Alexander Zenin | author7=Mikhail Pyatnitskiy | author8=Leonid Menshikov | author9=Sergei Markov | author10=Peter O. Fedichev | title=Extracting biological age from biomedical data via deep learning: too much of a good thing? | journal=Scientific Reports | volume=8 | issue=1 | year=2018 | pages=5210 | doi=10.1038/s41598-018-23534-9 | pmid= 29581467 | pmc=5980076 | bibcode=2018NatSR...8.5210P }}&lt;/ref&gt;

=== Checkers game ===
CNNs have been used in the game of [[Draughts|checkers]]. From 1999 to 2001, [[David B. Fogel|Fogel]] and Chellapilla published papers showing how a convolutional neural network could learn to play '''checker''' using co-evolution. The learning process did not use prior human professional games, but rather focused on a minimal set of information contained in the checkerboard: the location and type of pieces, and the difference in number of pieces between the two sides. Ultimately, the program ([[Blondie24]]) was tested on 165 games against players and ranked in the highest 0.4%.&lt;ref&gt;{{cite journal | pmid = 18252639 | doi=10.1109/72.809083 | volume=10 | issue=6 | title=Evolving neural networks to play checkers without relying on expert knowledge | journal=IEEE Trans Neural Netw | pages=1382–91 | last1 = Chellapilla | first1 = K | last2 = Fogel | first2 = DB| year=1999 }}&lt;/ref&gt;&lt;ref&gt;{{Cite journal | doi=10.1109/4235.942536| title=Evolving an expert checkers playing program without using human expertise| journal=IEEE Transactions on Evolutionary Computation| volume=5| issue=4| pages=422–428| year=2001| last1=Chellapilla| first1=K.| last2=Fogel| first2=D.B.}}&lt;/ref&gt; It also earned a win against the program [[Chinook (draughts player)|Chinook]] at its "expert" level of play.&lt;ref&gt;{{cite book |last= Fogel |first= David |date= 2001 |title= Blondie24: Playing at the Edge of AI |location= San Francisco, CA|publisher= Morgan Kaufmann|isbn= 978-1558607835|author-link= David B. Fogel }}&lt;/ref&gt;

=== Go ===
CNNs have been used in [[computer Go]]. In December 2014, Clark and Storkey published a paper showing that a CNN trained by supervised learning from a database of human professional games could outperform [[GNU Go]] and win some games against [[Monte Carlo tree search]] Fuego 1.1 in a fraction of the time it took Fuego to play.&lt;ref&gt;{{Cite arXiv|eprint=1412.3409|last1=Clark|first1=Christopher|title=Teaching Deep Convolutional Neural Networks to Play Go|last2=Storkey|first2=Amos|class=cs.AI|year=2014}}&lt;/ref&gt; Later it was announced that a large 12-layer convolutional neural network had correctly predicted the professional move in 55% of positions, equalling the accuracy of a [[Go ranks and ratings|6 dan]] human player. When the trained convolutional network was used directly to play games of Go, without any search, it beat the traditional search program [[GNU Go]] in 97% of games, and matched the performance of the [[Monte Carlo tree search]] program Fuego simulating ten thousand playouts (about a million positions) per move.&lt;ref&gt;{{Cite arXiv|eprint=1412.6564|last1= Maddison|first1= Chris J.|title= Move Evaluation in Go Using Deep Convolutional Neural Networks|last2= Huang|first2= Aja|last3= Sutskever|first3= Ilya|last4= Silver|first4= David|class= cs.LG|year= 2014}}&lt;/ref&gt;

A couple of CNNs for choosing moves to try ("policy network") and evaluating positions ("value network") driving MCTS were used by [[AlphaGo]], the first to beat the best human player at the time.&lt;ref&gt;{{cite web|url=https://www.deepmind.com/alpha-go.html|title=AlphaGo – Google DeepMind|access-date=30 January 2016|archive-url=https://web.archive.org/web/20160130230207/http://www.deepmind.com/alpha-go.html|archive-date=30 January 2016|url-status=dead}}&lt;/ref&gt;

=== Time series forecasting ===
Recurrent neural networks are generally considered the best neural network architectures for time series forecasting (and sequence modeling in general), but recent studies show that convolutional networks can perform comparably or even better.&lt;ref&gt;{{cite arXiv | last1=Bai | first1=Shaojie | last2=Kolter | first2=J. Zico | last3=Koltun | first3=Vladlen | title=An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling | date=2018-04-19 | eprint=1803.01271 | class=cs.LG }}&lt;/ref&gt;&lt;ref name="Tsantekidis 7–12"/&gt; Dilated convolutions&lt;ref&gt;{{cite arXiv | last1=Yu | first1=Fisher | last2=Koltun | first2=Vladlen| title=Multi-Scale Context Aggregation by Dilated Convolutions | date=2016-04-30 | eprint=1511.07122 | class=cs.CV }}&lt;/ref&gt; might enable one-dimensional convolutional neural networks to effectively learn time series dependences.&lt;ref&gt;{{cite arXiv | last1=Borovykh | first1=Anastasia | last2=Bohte | first2=Sander | last3=Oosterlee | first3=Cornelis W. | title=Conditional Time Series Forecasting with Convolutional Neural Networks | date=2018-09-17 | eprint=1703.04691 | class=stat.ML }}&lt;/ref&gt; Convolutions can be implemented more efficiently than RNN-based solutions, and they do not suffer from vanishing (or exploding) gradients.&lt;ref&gt;{{cite arXiv | last=Mittelman | first=Roni | title=Time-series modeling with undecimated fully convolutional neural networks | date=2015-08-03 | eprint=1508.00317 | class=stat.ML }}&lt;/ref&gt; Convolutional networks can provide an improved forecasting performance when there are multiple similar time series to learn from.&lt;ref&gt;{{cite arXiv | last1=Chen | first1=Yitian | last2=Kang | first2=Yanfei | last3=Chen | first3=Yixiong | last4=Wang | first4=Zizhuo | title=Probabilistic Forecasting with Temporal Convolutional Neural Network | date=2019-06-11 | eprint=1906.04397 | class=stat.ML }}&lt;/ref&gt; CNNs can also be applied to further tasks in time series analysis (e.g., time series classification&lt;ref&gt;{{cite journal | last1=Zhao | first1=Bendong | last2=Lu | first2=Huanzhang | last3=Chen | first3=Shangfeng | last4=Liu | first4=Junliang | last5=Wu | first5=Dongya | date=2017-02-01 | title=Convolutional neural networks for time series classi | journal=Journal of Systems Engineering and Electronics | volume=28 | issue=1 | pages=162–169 | doi=10.21629/JSEE.2017.01.18 }}&lt;/ref&gt; or quantile forecasting&lt;ref&gt;{{cite arXiv | last=Petneházi | first=Gábor | title=QCNN: Quantile Convolutional Neural Network | date=2019-08-21 | eprint=1908.07978 | class=cs.LG }}&lt;/ref&gt;).

=== Cultural Heritage and 3D-datasets ===
As archaeological findings like [[clay tablet]]s with [[Cuneiform|cuneiform writing]] are increasingly acquired using [[3D scanners]] first benchmark datasets are becoming available like ''HeiCuBeDa''&lt;ref name="HeiCuBeDa_Hilprecht" /&gt; providing almost 2.000 normalized 2D- and 3D-datasets prepared with the [[GigaMesh Software Framework]].&lt;ref name="ICDAR19" /&gt; So [[curvature]] based measures are used in conjunction with Geometric Neural Networks (GNNs) e.g. for period classification of those clay tablets being among the oldest documents of human history.&lt;ref name="ICFHR20" /&gt;&lt;ref name="ICFHR20_Presentation" /&gt;

== Fine-tuning ==
For many applications, the training data is less available. Convolutional neural networks usually require a large amount of training data in order to avoid [[overfitting]]. A common technique is to train the network on a larger data set from a related domain. Once the network parameters have converged an additional training step is performed using the in-domain data to fine-tune the network weights. This allows convolutional networks to be successfully applied to problems with small training sets.&lt;ref&gt;Durjoy Sen Maitra; Ujjwal Bhattacharya; S.K. Parui, [http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7333916&amp;tag=1 "CNN based common approach to handwritten character recognition of multiple scripts,"] in Document Analysis and Recognition (ICDAR), 2015 13th International Conference on, vol., no., pp.1021–1025, 23–26 Aug. 2015&lt;/ref&gt;

== Human interpretable explanations ==
End-to-end training and prediction are common practice in [[computer vision]]. However, human interpretable explanations are required for [[Safety-critical system|critical systems]] such as a [[self-driving car]]s.&lt;ref name="Interpretable ML Symposium 2017"&gt;{{cite web | title=NIPS 2017 | website=Interpretable ML Symposium | date=2017-10-20 | url=http://interpretable.ml/ | access-date=2018-09-12}}&lt;/ref&gt; With recent advances in [[Salience (neuroscience)|visual salience]], [[Visual spatial attention|spatial]] and [[Visual temporal attention|temporal attention]], the most critical spatial regions/temporal instants could be visualized to justify the CNN predictions.&lt;ref name="Zang Wang Liu Zhang 2018 pp. 97–108"&gt;{{cite book | last1=Zang | first1=Jinliang | last2=Wang | first2=Le | last3=Liu | first3=Ziyi | last4=Zhang | first4=Qilin | last5=Hua | first5=Gang | last6=Zheng | first6=Nanning | title=IFIP Advances in Information and Communication Technology | chapter=Attention-Based Temporal Weighted Convolutional Neural Network for Action Recognition | publisher=Springer International Publishing | location=Cham | year=2018 | isbn=978-3-319-92006-1 | issn=1868-4238 | doi=10.1007/978-3-319-92007-8_9 | pages=97–108 | arxiv=1803.07179 | s2cid=4058889 }}&lt;/ref&gt;&lt;ref name="Wang Zang Zhang Niu p=1979"&gt;{{cite journal | last1=Wang | first1=Le | last2=Zang | first2=Jinliang | last3=Zhang | first3=Qilin | last4=Niu | first4=Zhenxing | last5=Hua | first5=Gang | last6=Zheng | first6=Nanning | title=Action Recognition by an Attention-Aware Temporal Weighted Convolutional Neural Network | journal=Sensors | volume=18 | issue=7 | date=2018-06-21 | issn=1424-8220 | doi=10.3390/s18071979 | pmid=29933555 | pmc=6069475 | page=1979 | url=https://qilin-zhang.github.io/_pages/pdfs/sensors-18-01979-Action_Recognition_by_an_Attention-Aware_Temporal_Weighted_Convolutional_Neural_Network.pdf }}&lt;/ref&gt;

== Related architectures ==

=== Deep Q-networks ===
A deep Q-network (DQN) is a type of deep learning model that combines a deep neural network with [[Q-learning]], a form of [[reinforcement learning]]. Unlike earlier reinforcement learning agents, DQNs that utilize CNNs can learn directly from high-dimensional sensory inputs via reinforcement learning.&lt;ref name="Ong Chavez Hong 2015"&gt;{{cite arXiv |last1=Ong |first1=Hao Yi |last2=Chavez |first2=Kevin |last3=Hong |first3=Augustus |title=Distributed Deep Q-Learning  |date=2015-08-18 |class=cs.LG |eprint=1508.04186v2}}&lt;/ref&gt;

Preliminary results were presented in 2014, with an accompanying paper in February 2015.&lt;ref name="DQN"&gt;{{cite journal|last1=Mnih|first1=Volodymyr|display-authors=etal|date=2015|title=Human-level control through deep reinforcement learning|journal=Nature|volume=518|issue=7540|pages=529–533|doi=10.1038/nature14236|pmid=25719670|bibcode=2015Natur.518..529M|s2cid=205242740}}&lt;/ref&gt; The research described an application to [[Atari 2600]] gaming. Other deep reinforcement learning models preceded it.&lt;ref&gt;{{Cite journal|last1=Sun|first1=R.|last2=Sessions|first2=C.|date=June 2000|title=Self-segmentation of sequences: automatic formation of hierarchies of sequential behaviors|journal=IEEE Transactions on Systems, Man, and Cybernetics - Part B: Cybernetics|volume=30|issue=3|pages=403–418|doi=10.1109/3477.846230|pmid=18252373|issn=1083-4419|citeseerx=10.1.1.11.226}}&lt;/ref&gt;

=== Deep belief networks ===
{{Main|Deep belief network}}
Convolutional deep belief networks (CDBN) have structure very similar to convolutional neural networks and are trained similarly to deep belief networks. Therefore, they exploit the 2D structure of images, like CNNs do, and make use of pre-training like [[deep belief network]]s. They provide a generic structure that can be used in many image and signal processing tasks. Benchmark results on standard image datasets like CIFAR&lt;ref name="CDBN-CIFAR"&gt;{{cite web|url=http://www.cs.toronto.edu/~kriz/conv-cifar10-aug2010.pdf|title=Convolutional Deep Belief Networks on CIFAR-10}}&lt;/ref&gt; have been obtained using CDBNs.&lt;ref name="CDBN"&gt;{{cite book|last1=Lee|first1=Honglak|last2=Grosse|first2=Roger|last3=Ranganath|first3=Rajesh|last4=Ng|first4=Andrew Y.|date=1 January 2009|title=Convolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations|journal=Proceedings of the 26th Annual International Conference on Machine Learning – ICML '09|publisher=ACM|pages=609–616|doi=10.1145/1553374.1553453|isbn=9781605585161|citeseerx=10.1.1.149.6800|s2cid=12008458}}&lt;/ref&gt;

== Notable libraries ==
* [[Caffe (software)|Caffe]]: A library for convolutional neural networks. Created by the Berkeley Vision and Learning Center (BVLC). It supports both CPU and GPU. Developed in [[C++]], and has [[Python (programming language)|Python]] and [[MATLAB]] wrappers.
* [[Deeplearning4j]]: Deep learning in [[Java (programming language)|Java]] and [[Scala (programming language)|Scala]] on multi-GPU-enabled [[Apache Spark|Spark]]. A general-purpose deep learning library for the JVM production stack running on a C++ scientific computing engine. Allows the creation of custom layers. Integrates with Hadoop and Kafka.
*[[Dlib]]: A toolkit for making real world machine learning and data analysis applications in C++.
* [[Microsoft Cognitive Toolkit]]: A deep learning toolkit written by Microsoft with several unique features enhancing scalability over multiple nodes. It supports full-fledged interfaces for training in C++ and Python and with additional support for model inference in [[C Sharp (programming language)|C#]] and Java.
*[[TensorFlow]]: [[Apache License#Version 2.0|Apache 2.0]]-licensed Theano-like library with support for CPU, GPU, Google's proprietary [[tensor processing unit]] (TPU),&lt;ref&gt;{{cite news|url=https://www.wired.com/2016/05/google-tpu-custom-chips/|title=Google Built Its Very Own Chips to Power Its AI Bots|author=Cade Metz|date=May 18, 2016|newspaper=Wired}}&lt;/ref&gt; and mobile devices.
*[[Theano (software)|Theano]]: The reference deep-learning library for Python with an API largely compatible with the popular [[NumPy]] library. Allows user to write symbolic mathematical expressions, then automatically generates their derivatives, saving the user from having to code gradients or backpropagation. These symbolic expressions are automatically compiled to [[CUDA]] code for a fast, [[Compute kernel|on-the-GPU]] implementation.
*[[Torch (machine learning)|Torch]]: A [[scientific computing]] framework with wide support for machine learning algorithms, written in [[C (programming language)|C]] and [[Lua (programming language)|Lua]]. The main author is Ronan Collobert, and it is now used at Facebook AI Research and Twitter.

== Notable APIs ==
*[[Keras]]: A high level API written in [[Python (programming language)|Python]] for [[TensorFlow]] and [[Theano (software)|Theano]] convolutional neural networks.&lt;ref&gt;{{cite web|title=Keras Documentation|url=https://keras.io/#you-have-just-found-keras|website=keras.io|language=en}}&lt;/ref&gt;

== See also ==
* [[Attention (machine learning)]]
* [[Convolution]]
* [[Deep learning]]
* [[Natural-language processing]]
* [[Neocognitron]]
* [[Scale-invariant feature transform]]
* [[Time delay neural network]]
* [[Vision processing unit]]

== Notes ==
{{Reflist|group=nb}}

== References ==
{{reflist|30em|refs=
&lt;ref name="ICDAR19"&gt;
{{citation|surname1=Hubert Mara and Bartosz Bogacz|periodical=Proceedings of the 15th International Conference on Document Analysis and Recognition (ICDAR)|title=Breaking the Code on Broken Tablets: The Learning Challenge for Annotated Cuneiform Script in Normalized 2D and 3D Datasets|location=Sydney, Australien|date=2019|pages=148–153|language=de|doi=10.1109/ICDAR.2019.00032
|isbn=978-1-7281-3014-9|s2cid=211026941}}
&lt;/ref&gt;
&lt;ref name="HeiCuBeDa_Hilprecht"&gt;
{{citation|surname1=Hubert Mara|title=HeiCuBeDa Hilprecht – Heidelberg Cuneiform Benchmark Dataset for the Hilprecht Collection|publisher=heiDATA – institutional repository for research data of Heidelberg University|date=2019-06-07|language=de|doi=10.11588/data/IE8CCN
}}
&lt;/ref&gt;&lt;ref name="ICFHR20"&gt;
{{citation
   |last1=Bogacz|first1=Bartosz
   |last2=Mara|first2=Hubert
   |periodical=Proceedings of the 17th International Conference on Frontiers of Handwriting Recognition (ICFHR)
   |title=Period Classification of 3D Cuneiform Tablets with Geometric Neural Networks
   |location=Dortmund, Germany
   |date=2020
}}&lt;/ref&gt;
&lt;ref name="ICFHR20_Presentation"&gt;{{YouTube
   |id=-iFntE51HRw
   |title=Presentation of the ICFHR paper on Period Classification of 3D Cuneiform Tablets with Geometric Neural Networks
}}&lt;/ref&gt;
}}

== External links ==
* [https://cs231n.github.io/ CS231n: Convolutional Neural Networks for Visual Recognition] — [[Andrej Karpathy]]'s [[Stanford University|Stanford]] computer science course on CNNs in computer vision
* [https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/ An Intuitive Explanation of Convolutional Neural Networks] — A beginner level introduction to what Convolutional Neural Networks are and how they work
* [https://www.completegate.com/2017022864/blog/deep-machine-learning-images-lenet-alexnet-cnn/all-pages Convolutional Neural Networks for Image Classification] — Literature Survey

[[Category:Artificial neural networks]]
[[Category:Computer vision]]
[[Category:Computational neuroscience]]
[[Category:Machine learning]]</text>
      <sha1>ol5yucesmhppc2m13509o2lu4yz91jv</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Deep learning</title>
    <ns>14</ns>
    <id>49119651</id>
    <revision>
      <id>873351034</id>
      <parentid>814116104</parentid>
      <timestamp>2018-12-12T17:27:42Z</timestamp>
      <contributor>
        <username>Sm8900</username>
        <id>2274507</id>
      </contributor>
      <comment>added [[Category:Machine learning]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="96" xml:space="preserve">{{catmain|Deep learning}}

[[Category:Artificial neural networks]]
[[Category:Machine learning]]</text>
      <sha1>s88nlse1wyqo1jn3hfvaadziidsise9</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Ontology learning (computer science)</title>
    <ns>14</ns>
    <id>6905288</id>
    <revision>
      <id>877223593</id>
      <parentid>345028598</parentid>
      <timestamp>2019-01-07T09:47:34Z</timestamp>
      <contributor>
        <username>Jarble</username>
        <id>7226930</id>
      </contributor>
      <comment>added [[Category:Machine learning]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="73" xml:space="preserve">[[Category:Ontology (information science)]]
[[Category:Machine learning]]</text>
      <sha1>49se4iyhejoe4rlv58q0wo5ntib6zds</sha1>
    </revision>
  </page>
  <page>
    <title>Data exploration</title>
    <ns>0</ns>
    <id>43385931</id>
    <revision>
      <id>977269294</id>
      <parentid>922801552</parentid>
      <timestamp>2020-09-07T22:11:45Z</timestamp>
      <contributor>
        <username>Certes</username>
        <id>5984052</id>
      </contributor>
      <minor/>
      <comment>Disambiguating links to [[Classification]] (link changed to [[Statistical classification]]) using [[User:Qwertyytrewqqwerty/DisamAssist|DisamAssist]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="5163" xml:space="preserve">'''Data exploration''' is an approach similar to initial [[data analysis]], whereby a [[data analyst]] uses visual exploration to understand what is in a dataset and the characteristics of the data, rather than through traditional data management systems.&lt;ref name="Foster"&gt;[https://www.fosteropenscience.eu/sites/default/files/pdf/2933.pdf FOSTER Open Science], Overview of Data Exploration Techniques: Stratos Idreos, Olga Papaemmonouil, Surajit Chaudhuri.&lt;/ref&gt; These characteristics can include size or amount of data, completeness of the data, correctness of the data, possible relationships amongst data elements or files/tables in the data.

Data exploration is typically conducted using a combination of automated and manual activities.&lt;ref name="Foster" /&gt;&lt;ref name="Stanford2011"&gt;[http://vis.stanford.edu/files/2011-Wrangler-CHI.pdf Stanford.edu], 2011 Wrangler: Interactive Visual Specification of Data Transformation Scripts, Kandel, Paepcke, Hellerstein Heer.&lt;/ref&gt;&lt;ref&gt;{{cite book|title=Guided Interaction: Rethinking the Query-Result Paradigm|publisher=International Conference on Very Large Data Bases (VLDB) 2011|author=Arnab Nandi|author2= H. V. Jagadish|url=http://www.vldb.org/pvldb/vol4/p1466-nandi.pdf}}&lt;/ref&gt; Automated activities can include [[data profiling]] or [[data visualization]] or [[tabular report]]s to give the analyst an initial view into the data and an understanding of key characteristics.&lt;ref name="Foster"/&gt;

This is often followed by manual [[drill-down]] or filtering of the data to identify anomalies or patterns identified through the automated actions.  Data exploration can also require manual scripting and queries into the data (e.g. using languages such as [[SQL]] or [[R (language)|R]]) or using [[spreadsheet]]s or similar tools to view the [[raw data]].&lt;ref name="Stanford2012"&gt;[http://vis.stanford.edu/files/2012-EnterpriseAnalysisInterviews-VAST.pdf Stanford.edu], IEEE Visual Analytics Science &amp; Technology (VAST), Oct 2012 Enterprise Data Analysis and Visualization: An Interview Study., Sean Kandel, Andreas Paepcke, Joseph Hellerstein, Jeffrey Heer Proc.&lt;/ref&gt;

All of these activities are aimed at creating a mental model and understanding of the data in the mind of the analyst, and defining basic [[metadata]] (statistics, structure, relationships) for the data set that can be used in further analysis.&lt;ref name="Foster"/&gt;

Once this initial understanding of the data is had, the data can be pruned or refined by removing unusable parts of the data ([[data cleansing]]), correcting poorly formatted elements and defining relevant relationships across datasets.&lt;ref name="Stanford2011" /&gt; This process is also known as determining [[data quality]].&lt;ref name="Stanford2012" /&gt;

Data exploration can also refer to the ad hoc querying and visualization of data to identify potential relationships or insights that may be hidden in the data.&lt;ref name="Foster" /&gt;

Traditionally, this had been a key area of focus for statisticians, with [[John Tukey]] being a key evangelist in the field.&lt;ref name="Tukey, John W."&gt;[https://www.stat.berkeley.edu/~brill/Papers/EDASage.pdf Exploratory Data Analysis], Pearson. {{ISBN|978-0201076165}}&lt;/ref&gt; Today, data exploration is more widespread and is the focus of data analysts and [[data scientists]]; the latter being a relatively new role within enterprises and larger organizations.

== Interactive Data Exploration ==
This area of data exploration has become an area of interest in the field of [[machine learning]]. This is a relatively new field and is still evolving.&lt;ref name="Stanford2012" /&gt;  As its most basic level, a machine-learning algorithm can be fed a data set and can be used to identify whether a hypothesis is true based on the dataset. Common machine learning algorithms can focus on identifying specific patterns in the data.&lt;ref name="Stanford2011" /&gt; Many common patterns include [[Regression analysis|regression]] and [[Statistical classification|classification]] or [[Cluster analysis|clustering]], but there are many possible patterns and algorithms that can be applied to data via machine learning.

By employing machine learning, it is possible to find patterns or relationships in the data that would be difficult or impossible to find via manual inspection, trial and error or traditional exploration techniques.&lt;ref&gt;[http://homepages.inf.ed.ac.uk/csutton/talks/glasgow2017/ Machine Learning for Data Exploration]&lt;/ref&gt;

==Software==
* [[Trifacta]] – a data preparation and analysis platform
* [[Paxata]] – self-service data preparation software
* [[Alteryx]] – data blending and advanced data analytics software
* Microsoft [[Power BI]] -  interactive visualization and data analysis tool
* [[OpenRefine]] -  a standalone open source desktop application for data clean-up and data transformation 
* [[Tableau software]] – interactive data visualization software

==See also==

* [[Exploratory data analysis]]
* [[Machine learning]]
* [[Data profiling]]
* [[Data visualization]]
{{-}}

== References ==
{{reflist}}

[[Category:Machine learning]]
[[Category:Data analysis]]
[[Category:Data management]]
[[Category:Data quality]]</text>
      <sha1>4wpbu4mz95hq9d0c7sowe1v9ujsnxob</sha1>
    </revision>
  </page>
  <page>
    <title>Waifu2x</title>
    <ns>0</ns>
    <id>59729969</id>
    <revision>
      <id>966822509</id>
      <parentid>962661090</parentid>
      <timestamp>2020-07-09T11:33:40Z</timestamp>
      <contributor>
        <ip>42.60.185.133</ip>
      </contributor>
      <comment>/* Etymology */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3575" xml:space="preserve">{{lowercase title}}
{{Infobox software
| name = waifu2x
| logo = &lt;!-- Image name is enough. --&gt;
| logo alt = 
| logo caption = 
| screenshot = &lt;!-- Image name is enough. --&gt;
| screenshot alt = 
| caption = 
| collapsible = &lt;!-- Any text here will collapse the screenshot. --&gt;
| author = nagadomi
| developer = 
| released = {{Start date and age|2015|10|11}}
| discontinued = &lt;!-- Set to yes if software is discontinued, otherwise omit. --&gt;
| ver layout = &lt;!-- simple (default) or stacked --&gt;
| latest release version = v0.13.2
| latest release date = {{Start date and age|2018|11|18}}
| latest preview version = 
| latest preview date = &lt;!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} --&gt;
| repo = &lt;!-- {{URL|example.org}} --&gt;
| programming language = [[Lua (programming language)|Lua]]
| operating system = [[Linux]] with [[CUDA]] support
| platform = 
| size = 
| language = 
| language count = &lt;!-- Number only --&gt;
| language footnote = 
| genre = 
| license = [[MIT License]]
| alexa = 
| website = {{URL|http://waifu2x.udp.jp/}}
| standard = 
| AsOf = 
}}
'''waifu2x''' is an [[image scaling]] and [[noise reduction]] program for anime-style art and other types of photos.&lt;ref&gt;{{cite web |title=Amplía la resolución de tus imágenes con este portal web |url=https://www.tekcrispy.com/2019/01/17/waifu2x-ampliar-resolucion-imagen/ |website=TekCrispy |date=2019-01-17 |accessdate=2019-01-21 |language=es }}&lt;/ref&gt;

waifu2x was inspired by [[Super-resolution imaging|Super-Resolution]] [[Convolutional Neural Network]] (SRCNN).&lt;ref&gt;{{Cite web | url=https://github.com/nagadomi/waifu2x |title = GitHub - nagadomi/Waifu2x: Image Super-Resolution for Anime-Style Art |date = April 2020}}&lt;/ref&gt;&lt;ref&gt;Dong C, Loy C C, He K, et al. {{URL|1=http://mmlab.ie.cuhk.edu.hk/projects/SRCNN.html|2=Image super-resolution using deep convolutional networks}}[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2016, 38(2): 295-307.&lt;/ref&gt; It uses [[Nvidia]] [[CUDA]] for computing,&lt;ref&gt;{{cite web |title=Even better image upscaling with Waifu2x |url=https://fedoramagazine.org/better-image-upscaling-waifu2x/ |website=Fedora Magazine |date=2018-10-02 |accessdate=2019-01-21 }}&lt;/ref&gt; although alternative implementations that allow for [[OpenCL]]&lt;ref&gt;{{Cite web | url=https://github.com/marcan/cl-waifu2x | title=GitHub - marcan/Cl-waifu2x: OpenCL implementation of waifu2x image upscaling | date=25 March 2020}}&lt;/ref&gt; and [[Vulkan (API)|Vulkan]]&lt;ref&gt;{{Cite web | url=https://github.com/nihui/waifu2x-ncnn-vulkan |title = Waifu2x converter NCNN version, runs fast on intel / Amd / Nvidia GPU with vulkan: Nihui/Waifu2x-NCNN-vulkan|date = April 2020}}&lt;/ref&gt; have been created.
==Etymology==
''[[Waifu]]'' (from the Japanese pronunciation of "wife") is [[anime]] slang for a female character to whom one is attracted.
''2x'' means two-times [[magnification]].

== Example ==
{{wide image|Wikipe-tan face (waifu2x).png|512px|&lt;small&gt;&lt;small&gt;&lt;small&gt;&lt;small&gt;　&lt;/small&gt;&lt;/small&gt;&lt;/small&gt;&lt;/small&gt;
*Left: 512×512px, PNG lossless, original source [[:File:Wikipe-tan face.svg|Wikipe-tan face.svg]]
*Middle: 256×256px, JPG quality 30%, then [[nearest-neighbor interpolation]]
*Right: 512×512px, waifu2x upscaling &amp; noise reduction}}

== See also ==
*[[Comparison gallery of image scaling algorithms]]

== References ==
{{reflist}}

== External links ==
* {{Official website|http://waifu2x.udp.jp/}}
* {{GitHub|nagadomi/waifu2x}}

[[Category:Image processing]]
[[Category:Artificial neural networks]]
[[Category:Machine learning]]
[[Category:Free software]]


{{Graphics-software-stub}}</text>
      <sha1>lno1banc7rxcp9sr9768eprao17cgtl</sha1>
    </revision>
  </page>
  <page>
    <title>Learning curve (machine learning)</title>
    <ns>0</ns>
    <id>59968610</id>
    <revision>
      <id>1002133246</id>
      <parentid>999504005</parentid>
      <timestamp>2021-01-23T00:56:02Z</timestamp>
      <contributor>
        <username>GoingBatty</username>
        <id>11555324</id>
      </contributor>
      <comment>[[WP:AWB/GF|General fixes]], removed stub, underlinked tags</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="5857" xml:space="preserve">{{context|date=March 2019}}

[[File:Learning Curves (Naive Bayes).png|thumb|Learning curve showing training score and cross validation score]]
{{Machine learning bar}}

In [[machine learning]], a '''learning curve''' (or '''training curve''') [[Plot (graphics)|plots]] the [[Mathematical optimization|optimal]] value of a model's [[loss function]] for a training set against this loss function evaluated on a [[Cross-validation (statistics)#Holdout method|validation]] data set with same parameters as produced the optimal function. It is a tool to find out how much a machine model benefits from adding more training data and whether the estimator suffers more from a variance error or a bias error. If both the validation score and the training score converge to a value that is too low with increasing size of the training set, it will not benefit much from more training data.&lt;ref name="scikit-learn_learning-curve"&gt;{{cite web |url=https://scikit-learn.org/stable/modules/learning_curve.html#learning-curve |title=Validation curves: plotting scores to evaluate models — scikit-learn 0.20.2 documentation |author=scikit-learn developers |access-date= February 15, 2019}}&lt;/ref&gt;

The machine learning curve is useful for many purposes including comparing different algorithms,&lt;ref&gt;{{cite web|last=Madhavan|first=P.G.|title=A New Recurrent Neural Network Learning Algorithm for Time Series Prediction|url=http://www.jininnovation.com/RecurrentNN_JIntlSys_PG.pdf|work=Journal of Intelligent Systems|page=113 Fig. 3|volume=7|issue=1–2|date=1997}}&lt;/ref&gt;  choosing model parameters during design,&lt;ref&gt;{{cite web|title=Machine Learning 102: Practical Advice|url=https://astroml.github.com/sklearn_tutorial/practical.html#learning-curves|work=Tutorial: Machine Learning for Astronomy with Scikit-learn}}&lt;/ref&gt; adjusting optimization to improve convergence, and determining the amount of data used for training.&lt;ref&gt;{{cite journal|last=Meek|first=Christopher|author2=Thiesson, Bo |author3=Heckerman, David |title=The Learning-Curve Sampling Method Applied to Model-Based Clustering|journal=Journal of Machine Learning Research|date=Summer 2002|volume=2|issue=3|page=397|url=http://connection.ebscohost.com/c/articles/7188676/learning-curve-sampling-method-applied-model-based-clustering|archive-url=https://web.archive.org/web/20130715142652/http://connection.ebscohost.com/c/articles/7188676/learning-curve-sampling-method-applied-model-based-clustering|url-status=dead|archive-date=2013-07-15}}&lt;/ref&gt;

In the machine learning domain, there are two implications of learning curves differing in the x-axis of the curves, with experience of the model graphed either as the number of training examples used for learning or the number of iterations used in training the model.&lt;ref&gt;{{cite book|last1=Sammut|first1=Claude|title=Encyclopedia of Machine Learning|publisher=Springer|isbn=978-0-387-30768-8|page=578|url=https://books.google.com/books?id=i8hQhp1a62UC&amp;q=neural+network+learning+curve&amp;pg=PT604|edition=1st|last2=Webb |first2 = Geoffrey I. (Eds.)|date=28 March 2011}}&lt;/ref&gt;

== Formal definition ==
One model of a machine learning is producing a [[Function (mathematics)|function]], {{Math|f(x)}}, which given some information, {{Math|x}}, predicts some variable, {{Math|y}}, from training data &lt;math&gt;X_\text{train} &lt;/math&gt; and &lt;math&gt;Y_\text{train} &lt;/math&gt;. It is distinct from [[mathematical optimization]] because &lt;math&gt;f &lt;/math&gt; should predict well for &lt;math&gt;x&lt;/math&gt;outside of &lt;math&gt;X_\text{train}&lt;/math&gt;.

We often constrain the possible functions to a family &lt;math&gt;\{f_\theta(x): \theta \in \Theta \} &lt;/math&gt; so that the function is [[Generalization (learning)|generalizable]]&lt;ref name=":0"&gt;{{Cite book|last1=Goodfellow|first1=Ian|url=https://books.google.com/books?id=Np9SDQAAQBAJ&amp;q=deep%20learning%20goodfellow&amp;pg=PA108|title=Deep Learning|last2=Bengio|first2=Yoshua|last3=Courville|first3=Aaron|date=2016-11-18|publisher=MIT Press|isbn=978-0-262-03561-3|pages=108|language=en}}&lt;/ref&gt; and so that certain properties are true,  either to make finding a good &lt;math&gt;f &lt;/math&gt; easier, or because we have some a priori reason to think they are true.&lt;ref name=":0" /&gt;{{Rp|172}}

Given that it is not possible to produce a function that perfectly fits out data, it is then necessary to produce a loss function &lt;math&gt;L(f_\theta(X), Y') &lt;/math&gt; to measure how good our prediction is.  We then define an optimization process which finds a &lt;math&gt;\theta &lt;/math&gt; which minimizes &lt;math&gt;L(f_\theta(X_\text{train}), Y_\text{train}) &lt;/math&gt; referred to as &lt;math&gt;\theta^*(X, Y) &lt;/math&gt; .

=== Training curve for amount of data ===
Then if our training data is &lt;math&gt;\{x_1, x_2, \dots, x_n \}, \{ y_1, y_2, \dots y_n \} &lt;/math&gt; and our validation data is &lt;math&gt;\{ x_1', x_2', \dots x_m' \},  \{ y_1', y_2', \dots y_m' \} &lt;/math&gt; a learning curve is the plot of the two curves

# &lt;math&gt;i \mapsto L(f_{\theta^*(X_i, Y_i)}(X_i), Y_i ) &lt;/math&gt;
# &lt;math&gt;i \mapsto L(f_{\theta^*(X_i, Y_i)}(X_i'), Y_i' ) &lt;/math&gt;

where &lt;math&gt;X_i = \{ x_1, x_2, \dots x_i \} &lt;/math&gt;

=== Training curve for number of iterations ===
Many optimization processes are iterative, repeating the same step until the process [[Convergence (mathematics)|converges]] to an optimal value. [[Gradient descent]] is one such algorithm. If you define &lt;math&gt;\theta_i^*&lt;/math&gt; as the approximation of the optimal &lt;math&gt;\theta&lt;/math&gt; after &lt;math&gt;i&lt;/math&gt; steps, a learning curve is the plot of

# &lt;math&gt;i \mapsto L(f_{\theta_i^*(X, Y)}(X), Y) &lt;/math&gt;
# &lt;math&gt;i \mapsto L(f_{\theta_i^*(X, Y)}(X'), Y') &lt;/math&gt;

==See also==
*[[Overfitting]]
*[[Bias–variance tradeoff]]
*[[Model selection]]
*[[Cross-validation (statistics)]]
*[[Validity (statistics)]]
*[[Verification and validation]]

==References==
{{Reflist}}

[[Category:Model selection]]
[[Category:Machine learning]]
[[Category:Artificial intelligence]]</text>
      <sha1>htdnbvrjo228r8k74h2ume3x7ao88pr</sha1>
    </revision>
  </page>
  <page>
    <title>Learning rate</title>
    <ns>0</ns>
    <id>59969558</id>
    <revision>
      <id>999801007</id>
      <parentid>999795948</parentid>
      <timestamp>2021-01-12T01:13:19Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <comment>Alter: template type. Add: eprint, class, citeseerx, journal, author pars. 1-1. Removed accessdate with no specified URL. Removed parameters. Some additions/deletions were actually parameter name changes. | You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | Suggested by Headbomb | All pages linked from cached copy of Wikipedia:WikiProject_Academic_Journals/Journals_cited_by_Wikipedia/Sandbox | via #UCB_webform_linked 27/54</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="8914" xml:space="preserve">{{short description|Tuning parameter (hyperparameter) in optimization}}
{{Machine learning bar}}
In [[machine learning]] and [[statistics]], the '''learning rate''' is a [[Hyperparameter (machine learning)|tuning parameter]] in an [[Mathematical optimization|optimization algorithm]] that determines the step size at each iteration while moving toward a minimum of a [[loss function]].&lt;ref&gt;{{cite book |first=Kevin P. |last=Murphy |title=Machine Learning: A Probabilistic Perspective |location=Cambridge |publisher=MIT Press |year=2012 |isbn=978-0-262-01802-9 |page=247 |url=https://www.google.com/books/edition/Machine_Learning/NZP6AQAAQBAJ?hl=en&amp;gbpv=1&amp;kptab=sideways&amp;pg=PA247 }}&lt;/ref&gt; Since it influences to what extent newly acquired information overrides old information, it metaphorically represents the speed at which a machine learning model "learns". In the [[adaptive control]] literature, the learning rate is commonly referred to as '''gain'''.&lt;ref&gt;{{cite paper |first=Bernard |last=Delyon |title=Stochastic Approximation with Decreasing Gain: Convergence and Asymptotic Theory |journal=Unpublished Lecture Notes |url=http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.29.4428&amp;rep=rep1&amp;type=pdf#page=5 |date=2000 |publisher=Université de Rennes |citeseerx=10.1.1.29.4428 }}&lt;/ref&gt;

In setting a learning rate, there is a trade-off between the rate of convergence and overshooting. While the [[descent direction]] is usually determined from the [[Gradient descent|gradient]] of the loss function, the learning rate determines how big a step is taken in that direction. A too high learning rate will make the learning jump over minima but a too low learning rate will either take too long to converge or get stuck in an undesirable local minimum.&lt;ref&gt;{{cite book |first1=Nikhil |last1=Buduma |first2=Nicholas |last2=Locascio |year=2017 |title=Fundamentals of Deep Learning : Designing Next-Generation Machine Intelligence Algorithms |publisher=O'Reilly |isbn=978-1-4919-2558-4 |page=21 }}&lt;/ref&gt;

In order to achieve faster convergence, prevent oscillations and getting stuck in undesirable local minima the learning rate is often varied during training either in accordance to a learning rate schedule or by using an adaptive learning rate.&lt;ref name="variablelearningrate"&gt;{{cite book |title=Deep Learning : A Practitioner's Approach |first1=Josh |last1=Patterson |first2=Adam |last2=Gibson |publisher=O'Reilly |year=2017 |chapter=Understanding Learning Rates |pages=258–263 |isbn=978-1-4919-1425-0 }}&lt;/ref&gt; The learning rate and its adjustments may also differ per parameter, in which case it is a [[diagonal matrix]] that can be interpreted as an approximation to the [[Invertible matrix|inverse]] of the [[Hessian matrix]] in [[Newton's method in optimization|Newton's method]].&lt;ref&gt;{{cite arXiv |first=Sebastian |last=Ruder |title=An Overview of Gradient Descent Optimization Algorithms |date=2017 |arxiv=1609.04747 }}&lt;/ref&gt; The learning rate is related to the step length determined by inexact [[line search]] in [[quasi-Newton method]]s and related optimization algorithms.&lt;ref&gt;{{cite book |first=Y. |last=Nesterov |title=Introductory Lectures on Convex Optimization: A Basic Course |location=Boston |publisher=Kluwer |year=2004 |isbn=1-4020-7553-7 |page=25 |url=https://www.google.com/books/edition/Introductory_Lectures_on_Convex_Optimiza/2-ElBQAAQBAJ?hl=en&amp;gbpv=1&amp;pg=PA25 }}&lt;/ref&gt;&lt;ref&gt;{{cite book |first=L. C. W. |last=Dixon |chapter=The Choice of Step Length, a Crucial Factor in the Performance of Variable Metric Algorithms |title=Numerical Methods for Non-linear Optimization |location=London |publisher=Academic Press |year=1972 |isbn=0-12-455650-7 |pages=149–170 }}&lt;/ref&gt;

== Learning rate schedule ==
Initial rate can be left as system default or can be selected using a range of techniques.&lt;ref&gt;{{cite arxiv |last1=Smith |first1=Leslie N. |title=Cyclical Learning Rates for Training Neural Networks |date=4 April 2017 |class=cs.CV |eprint=1506.01186 }}&lt;/ref&gt; A learning rate schedule changes the learning rate during learning and is most often changed between epochs/iterations. This is mainly done with two parameters: '''decay''' and '''momentum''' . There are many different learning rate schedules but the most common are '''time-based, step-based''' and '''exponential'''.&lt;ref name="variablelearningrate" /&gt;

'''Decay''' serves to settle the learning in a nice place and avoid oscillations, a situation that may arise when a too high constant learning rate makes the learning jump back and forth over a minima, and is controlled by a hyperparameter.

'''Momentum''' is analogous to a ball rolling down a hill; we want the ball to settle at the lowest point of the hill (corresponding to the lowest error). Momentum both speeds up the learning (increasing the learning rate) when the error cost gradient is heading in the same direction for a long time and also avoids local minima by 'rolling over' small bumps. Momentum is controlled by a hyper parameter analogous to a ball's mass which must be chosen manually—too high and the ball will roll over minima which we wish to find, too low and it will not fulfil its purpose. [[Stochastic gradient descent#Momentum|The formula for factoring in the momentum]] is more complex than for decay but is most often built in with deep learning libraries such as [[Keras]].

'''Time-based''' learning schedules alter the learning rate depending on the learning rate of the previous time iteration. Factoring in the decay the mathematical formula for the learning rate is:

&lt;math&gt;\eta_{n+1} = \frac{\eta_n }{1+dn}&lt;/math&gt;

where &lt;math&gt;\eta&lt;/math&gt; is the learning rate, &lt;math&gt;d&lt;/math&gt; is a decay parameter and &lt;math&gt;n&lt;/math&gt; is the iteration step.

'''Step-based''' learning schedules changes the learning rate according to some pre defined steps. The decay application formula is here defined as:

&lt;math&gt;\eta_{n} = \eta_0d^{floor(\frac{1+n}{r})}&lt;/math&gt;

where &lt;math&gt;\eta_{n}&lt;/math&gt; is the learning rate at iteration &lt;math&gt;n&lt;/math&gt;, &lt;math&gt;\eta_0&lt;/math&gt; is the initial learning rate, &lt;math&gt;d&lt;/math&gt; is how much the learning rate should change at each drop (0.5 corresponds to a halving) and &lt;math&gt;r&lt;/math&gt; corresponds to the droprate, or how often the rate should be dropped (10 corresponds to a drop every 10 iterations). The ''floor'' function here drops the value of its input to 0 for all values smaller than 1.

'''Exponential''' learning schedules are similar to step-based but instead of steps a decreasing exponential function is used. The mathematical formula for factoring in the decay is:

&lt;math&gt;\eta_{n} = \eta_0e^{-dn}&lt;/math&gt;

where &lt;math&gt;d&lt;/math&gt; is a decay parameter.

==Adaptive learning rate==
The issue with learning rate schedules is that they all depend on hyperparameters that must be manually chosen for each given learning session and may vary greatly depending on the problem at hand or the model used. To combat this there are many different types of adaptive gradient descent algorithms such as [[Stochastic gradient descent#AdaGrad|Adagrad]]''',''' Adadelta, [[Stochastic gradient descent#RMSProp|RMSprop]]''',''' [[Stochastic gradient descent#Adam|Adam]] which are generally built into deep learning libraries such as [[Keras]].&lt;ref&gt;{{cite web |last1=Brownlee |first1=Jason |title=How to Configure the Learning Rate When Training Deep Learning Neural Networks |url=https://machinelearningmastery.com/learning-rate-for-deep-learning-neural-networks/ |website=Machine Learning Mastery |access-date=4 January 2021 |date=22 January 2019}}&lt;/ref&gt;

==See also==
{{Div col|colwidth=20em}}
*[[Hyperparameter (machine learning)]]
*[[Hyperparameter optimization]]
*[[Stochastic gradient descent]]
*[[Variable metric methods]]
*[[Overfitting]]
*[[Backpropagation]]
*[[AutoML]]
*[[Model selection]]
*[[Self-tuning]]
{{Div col end}}

==References==
{{Reflist}}

==Further reading==
*{{cite book |first=Aurélien |last=Géron |title=Hands-On Machine Learning with Scikit-Learn and TensorFlow |publisher=O'Reilly |year=2017 |isbn=978-1-4919-6229-9 |pages=113–124 |chapter=Gradient Descent |chapter-url=https://books.google.com/books?id=khpYDgAAQBAJ&amp;pg=PA113 }}
*{{cite book |first1=V. P. |last1=Plagianakos |first2=G. D. |last2=Magoulas |first3=M. N. |last3=Vrahatis |chapter=Learning Rate Adaptation in Stochastic Gradient Descent |title=Advances in Convex Analysis and Global Optimization |publisher=Kluwer |year=2001 |isbn=0-7923-6942-4 |pages=433–444 |chapter-url=https://books.google.com/books?id=YW4KBwAAQBAJ&amp;pg=PA433 }}

==External links==
*{{cite web |first=Nando |last=de Freitas |title=Optimization |work=Deep Learning Lecture 6 |location=University of Oxford |date=February 12, 2015 |url=https://www.youtube.com/watch?v=0qUAb94CpOw&amp;list=PLE6Wd9FR--EfW8dtjAuPoTuPcqmOV53Fu&amp;index=9 |via=[[YouTube]] }}

[[Category:Machine learning]]
[[Category:Model selection]]
[[Category:Optimization algorithms and methods]]</text>
      <sha1>f2tj3p833yrrmi95uqr3mrhcv7pnawy</sha1>
    </revision>
  </page>
  <page>
    <title>Nature Machine Intelligence</title>
    <ns>0</ns>
    <id>59973182</id>
    <revision>
      <id>1002845180</id>
      <parentid>955353714</parentid>
      <timestamp>2021-01-26T08:32:32Z</timestamp>
      <contributor>
        <ip>2600:1700:142D:40:147A:9738:2F05:2C84</ip>
      </contributor>
      <comment>Nature Machine Intelligence is not Closed-access any longer. It is a transformative journal (offering open access) https://www.nature.com/natmachintell/</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1070" xml:space="preserve">{{italic title}}
{{Sources exist|date=April 2019}}
'''''Nature Machine Intelligence''''' is a transformative (offering optional open access) [[scientific journal]] dedicated to covering [[Machine learning|machine learning]] and [[Artificial intelligence|artificial intelligence]]. It was created by [[Nature Research]] in response to the machine learning explosion of the 2010s. It launched in January 2019, and its opening was met with controversy and boycotts within the machine learning research community due to opposition to Nature publishing the journal as closed access.&lt;ref&gt;{{Cite web|url=https://www.forbes.com/sites/samshead/2018/04/30/tech-giant-ai-researchers-boycott-nature-machine-intelligence-journal/#4eba55b45e01|title=Tech Giant AI Researchers Boycott Nature 'Machine Intelligence' Journal}}&lt;/ref&gt;

== References ==
{{reflist}}

== External links ==
* [https://www.nature.com/natmachintell/ Official website]

{{Academic-journal-stub}}

[[Category:Nature Research academic journals]]
[[Category:Computer science journals]]
[[Category:Machine learning]]</text>
      <sha1>egwe54ajc5h5crt5n8bu9c1vq80rbfb</sha1>
    </revision>
  </page>
  <page>
    <title>Connectionist temporal classification</title>
    <ns>0</ns>
    <id>54550729</id>
    <revision>
      <id>978557467</id>
      <parentid>971195317</parentid>
      <timestamp>2020-09-15T16:42:58Z</timestamp>
      <contributor>
        <username>Comp.arch</username>
        <id>18779361</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2833" xml:space="preserve">{{Short description|Type of neural network output and associated scoring function}}
{{Use dmy dates|date=September 2017}}

'''Connectionist temporal classification''' ('''CTC''') is a type of neural network output and associated scoring function, for training [[recurrent neural network]]s (RNNs) such as [[Long short-term memory|LSTM]] networks to tackle sequence problems where the timing is variable. It can be used for tasks like on-line [[handwriting recognition]]&lt;ref&gt;{{Cite journal|last=Liwicki|first=Marcus|last2=Graves|first2=Alex|last3=Bunke|first3=Horst|last4=Schmidhuber|first4=Jürgen|date=2007|title=A novel approach to on-line handwriting recognition based on bidirectional long short-term memory networks|journal=In Proceedings of the 9th International Conference on Document Analysis and Recognition, ICDAR 2007|citeseerx=10.1.1.139.5852}}&lt;/ref&gt; or recognizing phonemes in speech audio. CTC refers to the outputs and scoring, and is independent of the underlying neural network structure. It was introduced in 2006.&lt;ref name="graves2006"&gt;{{Cite journal |last=Graves |first=Alex |last2=Fernández |first2=Santiago |last3=Gomez |first3=Faustino |date=2006 |title=Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks |citeseerx=10.1.1.75.6306 |journal=In Proceedings of the International Conference on Machine Learning, ICML 2006 |pages=369–376}}&lt;/ref&gt;

The input is a sequence of observations, and the outputs are a sequence of labels, which can include blank outputs. The difficulty of training comes from there being many more observations than there are labels. For example in speech audio there can be multiple time slices which correspond to a single phoneme. Since we don't know the alignment of the observed sequence with the target labels we predict a probability distribution at each time step.&lt;ref&gt;{{Cite journal|last=Hannun|first=Awni|date=2017-11-27|title=Sequence Modeling with CTC|journal=Distill|language=en-US|volume=2|issue=11|doi=10.23915/distill.00008|issn=2476-0757|arxiv=1508.01211}}&lt;/ref&gt; A CTC network has a continuous output (e.g. [[Softmax function|softmax]]), which is fitted through training to model the probability of a label. CTC does not attempt to learn boundaries and timings: Label sequences are considered equivalent if they differ only in alignment, ignoring blanks. Equivalent label sequences can occur in many ways – which makes scoring a non-trivial task, but there is an efficient [[forward–backward algorithm]] for that.

CTC scores can then be used with the back-propagation algorithm to update the neural network weights.

Alternative approaches to a CTC-fitted neural network include a [[hidden Markov model]] (HMM).

==References==
{{reflist}}

[[Category:Machine learning]]
[[Category:Artificial neural networks]]</text>
      <sha1>qfo4jtmz03797p0ma8ojcvrixqv6jwp</sha1>
    </revision>
  </page>
  <page>
    <title>Astrostatistics</title>
    <ns>0</ns>
    <id>37815827</id>
    <revision>
      <id>996707911</id>
      <parentid>996707760</parentid>
      <timestamp>2020-12-28T05:21:13Z</timestamp>
      <contributor>
        <username>Ashleyyoursmile</username>
        <id>38062138</id>
      </contributor>
      <minor/>
      <comment>Reverted 1 edit by [[Special:Contributions/67.11.244.75|67.11.244.75]] ([[User talk:67.11.244.75|talk]]) to last revision by 2601:98B:8000:37A0:15C3:9797:CC03:5324</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1417" xml:space="preserve">'''Astrostatistics''' is a discipline which spans [[astrophysics]], [[statistical analysis]] and [[data mining]].&lt;ref&gt;[https://asaip.psu.edu  Astrostatistics and Astroinformatics Portal]&lt;/ref&gt; It is used to process the vast amount of data produced by [[automated scanning]] of the cosmos, to characterize complex datasets, and to link [[astronomical data]] to [[astrophysical theory]].  Many branches of statistics are involved in astronomical analysis including [[nonparametrics]], [[multivariate regression]] and [[multivariate classification]], [[time series analysis]], and especially [[Bayesian inference]].

==Professional association==
Practitioners are represented by the [[International Astrostatistics Association]] affiliated with the [[International Statistical Institute]], the [[International Astronomical Union]] Working Group in Astrostatistics and Astroinformatics, the [[American Astronomical Society]] Working Group in Astroinformatics and Astrostatistics, the [[American Statistical Association]] Interest Group in Astrostatistics, and the [https://cosmostatistics-initiative.org/ Cosmostatistics Initiative].  All of these organizations participate in the [http://asaip.psu.edu Astrostatistics and Astroinformatics Portal] Web site.

==References==
{{reflist}}

[[Category:Astrophysics]]
[[Category:Applied statistics]]
[[Category:Data mining]]
[[Category:Machine learning]]


{{Statistics-stub}}</text>
      <sha1>3a77tchr6d1juxzd5tneuz3ofy20eo8</sha1>
    </revision>
  </page>
  <page>
    <title>Weak supervision</title>
    <ns>0</ns>
    <id>60968880</id>
    <revision>
      <id>1000364529</id>
      <parentid>998415546</parentid>
      <timestamp>2021-01-14T20:25:29Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>References after punctuation per [[WP:REFPUNCT]], [[WP:CITEFOOT]], [[WP:PAIC]] + other fixes</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="13970" xml:space="preserve">'''Weak supervision''' is a branch of [[machine learning]] where noisy, limited, or imprecise sources are used to provide supervision signal for labeling large amounts of [[Training, validation, and test sets|training data]] in a [[supervised learning]] setting.&lt;ref name=":0"&gt;{{Cite web|url=https://hazyresearch.github.io/snorkel/blog/ws_blog_post.html|title=Weak Supervision: The New Programming Paradigm for Machine Learning|last=Alex Ratner, Stephen Bach, Paroma Varma, Chris Ré And referencing work by many other members of Hazy Research|website=hazyresearch.github.io|access-date=2019-06-05}}&lt;/ref&gt; This approach alleviates the burden of obtaining hand-labeled data sets, which can be costly or impractical. Instead, inexpensive weak labels are employed with the understanding that they are imperfect, but can nonetheless be used to create a strong predictive model.&lt;ref name=":2"&gt;{{Cite journal|url=https://pdfs.semanticscholar.org/3adc/fd254b271bcc2fb7e2a62d750db17e6c2c08.pdf|title=A Brief Introduction to Weakly Supervised Learning|last=Zhou|first=Zhi-Hua|journal=National Science Review|year=2018|volume=5|pages=44–53|doi=10.1093/NSR/NWX106|s2cid=44192968|access-date=4 June 2019}}&lt;/ref&gt;&lt;ref&gt;{{cite arXiv |last1=Nodet |first1=Pierre |last2=Lemaire |first2=Vincent |last3=Bondu |first3=Alexis |last4=Cornuéjols |first4=Antoine |last5=Ouorou |first5=Adam |title=From Weakly Supervised Learning to Biquality Learning, a brief introduction  |date=2020-12-20 |eprint=2012.09632|class = cs.LG}}&lt;/ref&gt;

== Problem of labeled training data ==
Machine learning models and techniques are increasingly accessible to researchers and developers; the real-world usefulness of these models, however, depends on access to high-quality labeled training data.&lt;ref&gt;{{Cite web|url=http://www.spacemachine.net/views/2016/3/datasets-over-algorithms|title=Datasets Over Algorithms|website=Space Machine|access-date=2019-06-05}}&lt;/ref&gt; This need for labeled training data often proves to be a significant obstacle to the application of machine learning models within an organization or industry.&lt;ref name=":0" /&gt; This bottleneck effect manifests itself in various ways, including the following examples:

'''Insufficient quantity of labeled data'''

When machine learning techniques are initially used in new applications or industries, there is often not enough training data available to apply traditional processes.&lt;ref name=":1"&gt;{{Cite arXiv|title=A Survey on Data Collection for Machine Learning: A Big Data - AI Integration Perspective|last=Roh|first=Yuji|date=8 Nov 2018 |eprint = 1811.03402|class = cs.LG}}&lt;/ref&gt; Some industries have the benefit of decades' worth of training data readily available; those that do not are at a significant disadvantage. In such cases, obtaining training data may be impractical, expensive, or impossible without waiting years for its accumulation.

'''Insufficient subject-matter expertise to label data'''

When labeling training data requires specific relevant expertise, creation of a usable training data set can quickly become prohibitively expensive.&lt;ref name=":1" /&gt; This issue is likely to occur, for example, in [[Biomedicine|biomedical]] or [[National security|security-related]] applications of machine learning.

'''Insufficient time to label and prepare data'''

Most of the time required to implement machine learning is spent in preparing data sets.&lt;ref name=":1" /&gt; When an industry or research field deals with problems that are, by nature, rapidly evolving, it can be impossible to collect and prepare data quickly enough for results to be useful in real-world applications. This issue could occur, for example, in [[fraud detection]] or [[Computer security|cybersecurity]] applications.

Other areas of machine learning exist that are likewise motivated by the demand for increased quantity and quality of labeled training data but employ different high-level techniques to approach this demand. These other approaches include [[Active learning (machine learning)|active learning]], [[semi-supervised learning]], and [[transfer learning]].&lt;ref name=":0" /&gt;

== Types of weak labels ==
Weak labels are intended to decrease the cost and increase the efficiency of human efforts expended in hand-labeling data. They can take many forms, including the following:

* '''Imprecise or inexact labels:''' developers may use higher-level, less precise input from subject-matter experts to create [[Heuristic (computer science)|heuristic rules]], define expected distributions, or impose other constraints on the training data.&lt;ref name="Data Programming 1605"&gt;{{Cite arxiv|last1=Ré|first1=Christopher|last2=Selsam|first2=Daniel|last3=Wu|first3=Sen|last4=De Sa|first4=Christopher|last5=Ratner|first5=Alexander|date=2016-05-25|title=Data Programming: Creating Large Training Sets, Quickly|eprint=1605.07723v3|class=stat.ML}}&lt;/ref&gt;&lt;ref name=":2" /&gt;
* '''Inaccurate labels:''' developers may use inexpensive, lower-quality input through means such as crowdsourcing to obtain labels that are numerous, but not expected to be perfectly correct.&lt;ref name=":2" /&gt;
* '''Existing resources''': developers may take advantage of existing resources (such as knowledge bases, alternative data sets, or pre-trained models&lt;ref name=":0" /&gt;) to create labels that are helpful, though not perfectly suited for the given task.&lt;ref name=":2" /&gt;&lt;ref&gt;{{Cite journal|last1=Cabannes|first1=Vivien|last2=Rudi|first2=Alessandro|last3=Bach|first3=Francis|date=2020|title=Structured Prediction with Partial Labelling through the Infimum Loss|journal=ICML|volume=37|arxiv=2003.00920}}&lt;/ref&gt;

== Applications of weak supervision ==
Applications of weak supervision are numerous and varied within the machine learning research community.

In 2014, researchers from [[UC Berkeley]] made use of the principles of weak supervision to propose an iterative learning algorithm that solely depends on labels generated by heuristics and alleviates the need of collecting any ground-truth labels.&lt;ref&gt;{{Cite journal|last1=Jin|first1=Ming|last2=Jia|first2=Ruoxi|last3=Kang|first3=Zhaoyi|last4=Konstantakopoulos|first4=Ioannis|last5=Spanos|first5=Costas|date=2014|title=PresenceSense: zero-training algorithm for individual presence detection based on power monitoring|journal=Proceedings of the 1st ACM Conference on Embedded Systems for Energy-Efficient Buildings|pages=1–10|doi= 10.1145/2674061.2674073}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last1=Jin|first1=Ming|last2=Jia|first2=Ruoxi|last3=Spanos|first3=Costas|date=2017|title=Virtual occupancy sensing: using smart meters to indicate your presence|journal=IEEE Transactions on Mobile Computing|volume=16|number=11|pages=3264–3277|doi= 10.1109/TMC.2017.2684806|arxiv=1407.4395}}&lt;/ref&gt; The algorithm was applied to smart meter data to learn about the household's occupancy without ever asking for the occupancy data, which has raised issues of privacy and security as covered by an article in IEEE Spectrum.&lt;ref&gt;{{Cite web|url=https://spectrum.ieee.org/view-from-the-valley/energy/the-smarter-grid/what-does-your-smart-meter-know-about-you|title=What does smart meter know about you?|website=IEEE Spectrum}}&lt;/ref&gt;

In 2018, researchers from [[UC Riverside]] proposed a method to localize actions/events in videos using only weak supervision, i.e., video-level labels, without any information about the start and end time of the events while training. Their work &lt;ref&gt;{{Cite journal|last1=Paul|first1=Sujoy|last2=Roy|first2=Sourya|last3=Roy-Chowdhury|first3=Amit K.|date=2018|title=W-TALC: Weakly-supervised Temporal Activity Localization and Classification|journal=European Conference on Computer Vision (ECCV)|arxiv=1807.10418}}&lt;/ref&gt; introduced an attention-based similarity between two videos, which acts as a regularizer for learning with weak labels. Thereafter in 2019, they introduced a new problem &lt;ref&gt;{{Cite journal|last1=Mithun|first1=Niluthpol Chowdhury|last2=Paul|first2=Sujoy|last3=Roy-Chowdhury|first3=Amit K.|date=2019|title=Weakly Supervised Video Moment Retrieval From Text Queries|journal=Computer Vision and Pattern Recognition (CVPR)|arxiv=1904.03282}}&lt;/ref&gt; of event localization in videos using text queries from users, but with weak annotations while training. Later in a collaboration with [[NEC Laboratories America]] a similar attention-based alignment mechanism with weak labels was introduced for adapting a source semantic segmentation model to a target domain.&lt;ref&gt;{{Cite journal|last1=Paul|first1=Sujoy|last2=Tsai|first2=Yi-Hsuan|last3=Schulter|first3=Samuel|last4=Roy-Chowdhury|first4=Amit K.|last5=Chandraker|first5=Manmohan|date=2020|title=Domain Adaptive Semantic Segmentation Using Weak Labels|journal=European Conference on Computer Vision (ECCV)|arxiv=2007.15176}}&lt;/ref&gt; When the weak labels of the target images are estimated using the source model, it is unsupervised domain adaptation, requiring no target annotation cost, and when the weak labels are acquired from an annotator, it incurs a very small amount of annotation cost and falls under the category of weakly-supervised domain adaptation, which is first introduced in this work for semantic segmentation.

[[Stanford University]] researchers created Snorkel, an open-source system for quickly assembling training data through weak supervision.&lt;ref&gt;{{Cite web|url=https://dawn.cs.stanford.edu/2017/05/08/snorkel/|title=Snorkel and The Dawn of Weakly Supervised Machine Learning · Stanford DAWN|website=dawn.cs.stanford.edu|access-date=2019-06-05}}&lt;/ref&gt; Snorkel employs the central principles of the data programming paradigm,&lt;ref name="Data Programming 1605"/&gt;  in which developers create labeling functions, which are then used to programmatically label data, and employs supervised learning techniques to assess the accuracy of those labeling functions.&lt;ref&gt;{{Cite web|url=https://hazyresearch.github.io/snorkel/|title=Snorkel by HazyResearch|website=hazyresearch.github.io|access-date=2019-06-05}}&lt;/ref&gt; In this way, potentially low-quality inputs can be used to create high-quality models.

In a joint work with [[Google]], Stanford researchers showed that existing organizational knowledge resources could be converted into weak supervision sources and used to significantly decrease development costs and time.&lt;ref&gt;{{Cite journal|last1=Malkin|first1=Rob|last2=Ré|first2=Christopher|last3=Kuchhal|first3=Rahul|last4=Alborzi|first4=Houman|last5=Hancock|first5=Braden|last6=Ratner|first6=Alexander|last7=Sen|first7=Souvik|last8=Xia|first8=Cassandra|last9=Shao|first9=Haidong|date=2018-12-02|title=Snorkel DryBell: A Case Study in Deploying Weak Supervision at Industrial Scale|journal=Proceedings. Acm-Sigmod International Conference on Management of Data|volume=2019|pages=362–375|arxiv=1812.00417|pmid=31777414|doi=10.1145/3299869.3314036|pmc=6879379|bibcode=2018arXiv181200417B}}&lt;/ref&gt;

In 2019, [[Massachusetts Institute of Technology]] and [[Google]] researchers released cleanlab, the first standardized [[Python (programming language)|Python]] package for machine learning and [[deep learning]] with noisy labels.&lt;ref&gt;{{Cite web|url=https://l7.curtisnorthcutt.com/cleanlab-python-package|title=Announcing cleanlab: a Python Package for ML and Deep Learning on Datasets with Label Errors|website=l7.curtisnorthcutt.com|language=en|access-date=2020-02-04}}&lt;/ref&gt; Cleanlab implements [[confident learning]],&lt;ref&gt;{{Cite web|url=https://l7.curtisnorthcutt.com/confident-learning|title=An Introduction to Confident Learning: Finding and Learning with Label Errors in Datasets|website=l7.curtisnorthcutt.com|access-date=2020-02-04}}&lt;/ref&gt;&lt;ref&gt;{{cite arxiv|last1=Northcutt|first1=Curtis G.|last2=Jiang|first2=Lu|last3=Chuang|first3=Isaac L.|date=2019-10-31|title=Confident Learning: Estimating Uncertainty in Dataset Labels|eprint=1911.00068|class=stat.ML}}&lt;/ref&gt; a framework of theory and algorithms for dealing with uncertainty in dataset labels, to (1) find label errors in datasets, (2) characterize label noise, and (3) standardize and simplify research in weak supervision and learning with noisy labels.&lt;ref&gt;{{Cite web|url=https://github.com/cgnorthcutt/cleanlab|title=CleanLab for Finding and Learning with Noisy Labels|last=Northcutt|first=Curtis|access-date=9 October 2019}}&lt;/ref&gt;

Researchers at [[University of Massachusetts Amherst]] propose augmenting traditional [[Active learning (machine learning)|active learning]] approaches by soliciting labels on features rather than instances within a data set.&lt;ref&gt;{{Cite web|url=http://gregorydruck.name/pubs/druck09active.pdf|title=Active Learning by Labeling Features|last=Druck|first=Gregory|access-date=4 June 2019}}&lt;/ref&gt;

Researchers at [[Johns Hopkins University]] propose reducing the cost of labeling data sets by having annotators provide rationales supporting each of their data annotations, then using those rationales to train both discriminative and generative models for labeling additional data.&lt;ref&gt;{{Cite web|url=http://www.cs.jhu.edu/~ozaidan/rationales/Zaidan_etal_rationales-nips2008.pdf|title=Machine Learning with Annotator Rationales to Reduce Annotation Cost|last=Zaidan|first=Omar|access-date=4 June 2019}}&lt;/ref&gt;

Researchers at [[University of Alberta Faculty of Engineering|University of Alberta]] propose a method that applies traditional active learning approaches to enhance the quality of the imperfect labels provided by weak supervision.&lt;ref&gt;{{Cite journal|last1=Nashaat|first1=Mona|last2=Ghosh|first2=Aindrila|last3=Miller|first3=James|last4=Quader|first4=Shaikh|last5=Marston|first5=Chad|last6=Puget|first6=Jean-Francois|date=December 2018|title=Hybridization of Active Learning and Data Programming for Labeling Large Industrial Datasets|journal=2018 IEEE International Conference on Big Data (Big Data)|location=Seattle, WA, USA|publisher=IEEE|pages=46–55|doi=10.1109/BigData.2018.8622459|isbn=9781538650356|s2cid=59233854}}&lt;/ref&gt;
&lt;references /&gt;

[[Category:Machine learning]]
[[Category:Machine learning researchers]]</text>
      <sha1>jn111tsnwr1okhxciub5yi4aryq53vt</sha1>
    </revision>
  </page>
  <page>
    <title>Federated learning</title>
    <ns>0</ns>
    <id>60992857</id>
    <revision>
      <id>1004438358</id>
      <parentid>1004438306</parentid>
      <timestamp>2021-02-02T16:15:45Z</timestamp>
      <contributor>
        <username>Dicklyon</username>
        <id>869314</id>
      </contributor>
      <comment>/* Transportation: self-driving cars */ number agreement</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="32637" xml:space="preserve">'''Federated learning''' (also known as '''collaborative learning''') is a [[machine learning]] technique that trains an algorithm across multiple decentralized edge devices or [[Server (computing)|servers]] holding local [[Data|data samples]], without exchanging them. This approach stands in contrast to traditional centralized machine learning techniques where all the local datasets are uploaded to one [[Server (computing)|server]], as well as to more classical decentralized approaches which often assume that local data samples are [[Independent and identically distributed random variables|identically distributed]].

Federated learning enables multiple actors to build a common, robust machine learning model without sharing data, thus allowing to address critical issues such as data privacy, data security, data access rights and access to heterogeneous data. Its applications are spread over a number of industries including defense, telecommunications, [[Internet of things|IoT]], and pharmaceutics.

== Definition ==
Federated learning aims at training a machine learning algorithm, for instance deep [[neural network]]s, on multiple local datasets contained in local nodes without explicitly exchanging data samples. The general principle consists in training local models on local data samples and exchanging [[Parameters (computer science)|parameters]] (e.g. the weights and biases of a deep neural network) between these local nodes at some frequency to generate a global model shared by all nodes.

The main difference between federated learning and distributed learning lies in the assumptions made on the properties of the local datasets,&lt;ref name=":1"&gt;{{Cite arXiv|eprint = 1511.03575|last1 = Konečný|first1 = Jakub|last2 = McMahan|first2 = Brendan|last3 = Ramage|first3 = Daniel|title = Federated Optimization: Distributed Optimization Beyond the Datacenter|year = 2015|class = cs.LG}}&lt;/ref&gt; as [[distributed learning]] originally aims at [[Computing power|parallelizing computing power]] where federated learning originally aims at training on [[Homogeneity and heterogeneity|heterogeneous datasets]]. While distributed learning also aims at training a single model on multiple servers, a common underlying assumption is that the local datasets are identically distributed (i.i.d.) and roughly have the same size. None of these hypotheses are made for federated learning; instead, the datasets are typically heterogeneous and their sizes may span several orders of magnitude. Moreover, the clients involved in federated learning may be unreliable as they are subject to more failures or drop out since they commonly rely on less powerful communication media (i.e. [[Wi-fi]]) and battery-powered systems (i.e. [[smartphone]]s and IoT devices) compared to distributed learning where nodes are typically [[data center|datacenters]] that have powerful computational capabilities and are connected to one another with fast networks.&lt;ref name="Survey-2019"&gt;{{cite arXiv |title=Advances and Open Problems in Federated Learning |date=10 December 2019 |eprint=1912.04977 |last1=Kairouz |first1=Peter |last2=Brendan McMahan |first2=H. |last3=Avent |first3=Brendan |last4=Bellet |first4=Aurélien |last5=Bennis |first5=Mehdi |author6=Arjun Nitin Bhagoji |last7=Bonawitz |first7=Keith |last8=Charles |first8=Zachary |last9=Cormode |first9=Graham |last10=Cummings |first10=Rachel |last11=D'Oliveira |first11=Rafael G. L. |author12=Salim El Rouayheb |last13=Evans |first13=David |last14=Gardner |first14=Josh |last15=Garrett |first15=Zachary |last16=Gascón |first16=Adrià |last17=Ghazi |first17=Badih |last18=Gibbons |first18=Phillip B. |last19=Gruteser |first19=Marco |last20=Harchaoui |first20=Zaid |last21=He |first21=Chaoyang |last22=He |first22=Lie |last23=Huo |first23=Zhouyuan |last24=Hutchinson |first24=Ben |last25=Hsu |first25=Justin |last26=Jaggi |first26=Martin |last27=Javidi |first27=Tara |last28=Joshi |first28=Gauri |last29=Khodak |first29=Mikhail |last30=Konečný |first30=Jakub |class=cs.LG |display-authors=29 }}&lt;/ref&gt;

=== Centralized federated learning ===
In the centralized federated learning setting, a central server is used to orchestrate the different steps of the algorithms and coordinate all the participating nodes during the learning process. The server is responsible for the nodes selection at the beginning of the training process and for the aggregation of the received model updates. Since all the selected nodes have to send updates to a single entity, the server may become a bottleneck of the system.&lt;ref name="Survey-2019" /&gt;

=== Decentralized federated learning ===
In the decentralized federated learning setting, the nodes are able to coordinate themselves to obtain the global model. This setup prevents single point failures as the model updates are exchanged only between interconnected nodes without the orchestration of the central server. Nevertheless, the specific [[network topology]] may affect the performances of the learning process.&lt;ref name="Survey-2019" /&gt; See blockchain-based federated learning&lt;ref&gt;{{cite journal|title=Federated Learning with Blockchain for Autonomous Vehicles: Analysis and Design Challenges |journal=IEEE Transactions on Communications |year=2020|doi=10.1109/TCOMM.2020.2990686|last1=Pokhrel |first1=Shiva Raj |last2=Choi |first2=Jinho |volume=68 |issue=8 |pages=4734–4746 |s2cid=219006840 }}&lt;/ref&gt; and the references therein.

=== Heterogeneous federated learning ===
An increasing number of application domains involve a large set of heterogeneous clients, e.g., mobile phones and IoT devices. Most of the existing Federated learning strategies assume that local models share the same global model architecture. Recently, a new federated learning framework named HeteroFL was developed to address heterogeneous clients equipped with very different computation and communication capabilities.&lt;ref name=":3"&gt;{{cite arxiv|last1=Diao|first1=Enmao|last2=Ding|first2=Jie|last3=Tarokh|first3=Vahid|date=2020-10-02|title=HeteroFL: Computation and Communication Efficient Federated Learning for Heterogeneous Clients|class=cs.LG|eprint=2010.01264}}&lt;/ref&gt; The HeteroFL technique can enable the training of heterogeneous local models with dynamically-varying computation complexities while still producing a single global inference model.&lt;ref name=":3"/&gt;

[[File:Federated learning process central case.png|alt=Federated learning general process in central orchestrator setup|thumb|upright=2|Federated learning general process in central orchestrator setup]]

== Main features ==

=== Iterative learning ===
To ensure good task performance of a final, central machine learning model, federated learning relies on an iterative process broken up into an atomic set of client-server interactions known as a federated learning round. Each round of this process consists in transmitting the current global model state to participating nodes, training local models on these local nodes to produce a set of potential model updates at each node, and then aggregating and processing these local updates into a single global update and applying it to the global model.&lt;ref name="Survey-2019" /&gt;

In the methodology below, a central server is used for aggregation, while local nodes perform local training depending on the central server's orders. However, other strategies lead to the same results without central servers, in a [[peer-to-peer]] approach, using [[Gossip protocol|gossip]]&lt;ref&gt;Decentralized Collaborative Learning of Personalized Models over Networks Paul Vanhaesebrouck, Aurélien Bellet, Marc Tommasi, 2017&lt;/ref&gt; or [[Consensus (computer science)|consensus]] methodologies.&lt;ref&gt;{{cite journal |last1=Savazzi |first1=Stefano |last2=Nicoli |first2=Monica |last3=Rampa |first3=Vittorio |title=Federated Learning With Cooperating Devices: A Consensus Approach for Massive IoT Networks |journal=IEEE Internet of Things Journal |date=May 2020 |volume=7 |issue=5 |pages=4641–4654 |doi=10.1109/JIOT.2020.2964162|arxiv=1912.13163 |s2cid=209515403 }}&lt;/ref&gt;

Assuming a federated round composed by one iteration of the learning process, the learning procedure can be summarized as follows:&lt;ref name=":0"&gt;Towards federated learning at scale: system design, Keith Bonawitz Hubert Eichner and al., 2019&lt;/ref&gt;
# '''Initialization''': according to the server inputs, a machine learning model (e.g., [[linear regression]], neural network, [[Boosting (machine learning)|boosting]]) is chosen to be trained on local nodes and initialized. Then, nodes are activated and wait for the central server to give the calculation tasks.
# '''Client selection''': a fraction of local nodes is selected to start training on local data. The selected nodes acquire the current statistical model while the others wait for the next federated round.
# '''Configuration''': the central server orders selected nodes to undergo training of the model on their local data in a pre-specified fashion (e.g., for some mini-batch updates of [[gradient descent]]).
# '''Reporting''': each selected node sends its local model to the server for aggregation. The central server aggregates the received models and sends back the model updates to the nodes. It also handles failures for disconnected nodes or lost model updates. The next federated round is started returning to the client selection phase.
# '''Termination''': once a pre-defined termination criterion is met (e.g., a maximum number of iterations is reached or the model accuracy is greater than a threshold) the central server aggregates the updates and finalizes the global model.

The procedure considered before assumes synchronized model updates. Recent federated learning developments introduced novel techniques to tackle asynchronicity during the training process, or training with dynamically varying models.&lt;ref name=":3"/&gt; Compared to synchronous approaches where local models are exchanged once the computations have been performed for all layers of the neural network, asynchronous ones leverage the properties of neural networks to exchange model updates as soon as the computations of a certain layer are available. These techniques are also commonly referred to as split learning&lt;ref name="Gupta-2018"&gt;{{cite arXiv |last1=Gupta |first1=Otkrist |last2=Raskar |first2=Ramesh |title=Distributed learning of deep neural network over multiple agents  |date=14 October 2018 |class=cs.LG |eprint=1810.06060 }}&lt;/ref&gt;&lt;ref name="Vepakomma-2018"&gt;{{cite arXiv |last1=Vepakomma |first1=Praneeth |last2=Gupta |first2=Otkrist |last3=Swedish |first3=Tristan |last4=Raskar |first4=Ramesh |title=Split learning for health: Distributed deep learning without sharing raw patient data |date=3 December 2018 |class=cs.LG |eprint=1812.00564 }}&lt;/ref&gt; and they can be applied both at training and inference time regardless of centralized or decentralized federated learning settings.&lt;ref name="Survey-2019" /&gt;&lt;ref name=":3"/&gt;

=== Non-iid data ===
In most cases, the assumption of independent and identically distributed samples across local nodes does not hold for federated learning setups. Under this setting, the performances of the training process may vary significantly according to the unbalancedness of local data samples as well as the particular probability distribution of the training examples (i.e., [[Feature (machine learning)|features]] and [[Labeled data|labels]]) stored at the local nodes. To further investigate the effects of non-iid data, the following description considers the main categories presented in the by Peter Kiarouz and al. in 2019.&lt;ref name="Survey-2019" /&gt;

The description of non-iid data relies on the analysis of the [[Joint probability distribution|joint probability]] between features and labels for each node.
This allows to decouple each contribution according to the specific distribution available at the local nodes.
The main categories for non-iid data can be summarized as follows:&lt;ref name ="Survey-2019" /&gt;

* '''Covariate shift''': local nodes may store examples that have different statistical distributions compared to other nodes. An example occurs in [[natural language processing]] datasets where people typically write the same digits/letters with different stroke widths or slants.&lt;ref name ="Survey-2019" /&gt;
* '''Prior probability shift''': local nodes may store labels that have different statistical distributions compared to other nodes. This can happen if datasets are regional and/or demographically partitioned. For example, datasets containing images of animals vary significantly from country to country.&lt;ref name ="Survey-2019" /&gt;
* '''Concept shift''' (''same label, different features''): local nodes may share the same labels but some of them correspond to different features at different local nodes. For example, images that depict a particular object can vary according to the weather condition in which they were captured.&lt;ref name ="Survey-2019" /&gt;
* '''Concept shift''' (''same features, different labels''): local nodes may share the same features but some of them correspond to different labels at different local nodes. For example, in natural language processing, the sentiment analysis may yield different sentiments even if the same text is observed.&lt;ref name ="Survey-2019" /&gt;
* '''Unbalancedness''': the data available at the local nodes may vary significantly in size.&lt;ref name ="Survey-2019" /&gt;&lt;ref name=":3"/&gt;

Other non-iid data descriptors take into account the dynamic variation of the network topology,&lt;ref name="SGD-2019"&gt;{{cite arXiv |last1=Eichner |first1=Hubert |last2=Koren |first2=Tomer |last3=McMahan |first3=H. Brendan |last4=Srebro |first4=Nathan |last5=Talwar |first5=Kunal |title=Semi-Cyclic Stochastic Gradient Descent |date=22 April 2019 |class=cs.LG |eprint=1904.10120 }}&lt;/ref&gt; due to failures or ineligibility of local nodes during the federated learning process, or dataset shifts, where the nodes participating in the training phase for learning the global model may not be eligible during inference due to insufficient computational capabilities. This results in a difference between the statistics of training and testing data samples.&lt;ref name="Survey-2019" /&gt;

== Algorithmic hyper-parameters ==

=== Network topology ===
The way the statistical local outputs are pooled and the way the nodes communicate with each other can change from the centralized model explained in the previous section. This leads to a variety of federated learning approaches: for instance no central orchestrating server, or stochastic communication.&lt;ref&gt;''Collaborative Deep Learning in Fixed Topology Networks,'' Zhanhong Jiang, Aditya Balu, Chinmay Hegde, Soumik Sarkar, 2017&lt;/ref&gt;

In particular, orchestrator-less distributed networks are one important variation. In this case, there is no central server dispatching queries to local nodes and aggregating local models. Each local node sends its outputs to several randomly-selected others, which aggregate their results locally. This restrains the number of transactions, thereby sometimes reducing training time and computing cost.&lt;ref name="Gossip-2018"&gt;GossipGraD: Scalable Deep Learning using Gossip Communication based Asynchronous Gradient Descent, Jeff Daily, Abhinav Vishnu, Charles Siegel, Thomas Warfel, Vinay Amatya, 2018&lt;/ref&gt;

=== Federated learning parameters ===
Once the topology of the node network is chosen, one can control different parameters of the federated learning process (in opposition to the machine learning model's own hyperparameters) to optimize learning:

* Number of federated learning rounds: &lt;math&gt;T&lt;/math&gt;
* Total number of nodes used in the process: &lt;math&gt;K&lt;/math&gt;
* Fraction of nodes used at each iteration for each node: &lt;math&gt;C&lt;/math&gt;
* Local [[Batch normalization|batch size]] used at each learning iteration: &lt;math&gt;B&lt;/math&gt;

Other model-dependent parameters can also be tinkered with, such as:

* Number of iterations for local training before pooling: &lt;math&gt;N&lt;/math&gt;
* Local learning rate: &lt;math&gt;\eta&lt;/math&gt;

Those parameters have to be optimized depending on the constraints of the machine learning application (e.g., available computing power, available memory, [[Bandwidth (computing)|bandwidth]]). For instance, stochastically choosing a limited fraction &lt;math&gt;C&lt;/math&gt; of nodes for each iteration diminishes computing cost and may prevent [[overfitting]], in the same way that stochastic gradient descent can reduce overfitting.

== Federated learning variations ==
In this section, the exposition of the paper published by H. Brendan McMahan and al. in 2017 is followed.&lt;ref name="ReferenceA"&gt;Communication-Efficient Learning of Deep Networks from Decentralized Data, H. Brendan McMahan and al. 2017&lt;/ref&gt;

To describe the federated strategies, let us introduce some notations:

* &lt;math&gt;K&lt;/math&gt; : total number of clients;
* &lt;math&gt;k&lt;/math&gt; : index of clients;
* &lt;math&gt;n_k&lt;/math&gt;: number of data samples available during training for client &lt;math&gt;k&lt;/math&gt;;
* &lt;math&gt;k_t&lt;/math&gt;: model's weight vector on client &lt;math&gt;k&lt;/math&gt;, at the federated round &lt;math&gt;t&lt;/math&gt;;
* &lt;math&gt;l(w, b)&lt;/math&gt; : loss function for weights &lt;math&gt;w&lt;/math&gt; and batch &lt;math&gt;b&lt;/math&gt;;
* &lt;math&gt;E&lt;/math&gt; : number of local epochs;

=== Federated stochastic gradient descent (FedSGD) ===
[[Deep learning]] training mainly relies on variants of [[stochastic gradient descent]], where gradients are computed on a random subset of the total dataset and then used to make one step of the gradient descent.

Federated stochastic gradient descent&lt;ref name="ReferencePPDL"&gt;Privacy Preserving Deep Learning, R. Shokri and V. Shmatikov, 2015&lt;/ref&gt; is the direct transposition of this algorithm to the federated setting, but by using a random fraction &lt;math&gt;C&lt;/math&gt; of the nodes and using all the data on this node. The gradients are averaged by the server proportionally to the number of training samples on each node, and used to make a gradient descent step.

=== Federated averaging ===
Federated averaging (FedAvg) is a generalization of FedSGD, which allows local nodes to perform more than one batch update on local data and exchanges the updated weights rather than the gradients. The rationale behind this generalization is that in FedSGD, if all local nodes start from the same initialization, averaging the gradients is strictly equivalent to averaging the weights themselves. Further, averaging tuned weights coming from the same initialization does not necessarily hurt the resulting averaged model's performance.&lt;ref name="ReferenceA" /&gt;

== Technical limitations ==
Federated learning requires frequent communication between nodes during the learning process. Thus, it requires not only enough local computing power and memory, but also high bandwidth connections to be able to exchange parameters of the machine learning model. However, the technology also avoid data communication, which can require significant resources before starting centralized machine learning. Nevertheless, the devices typically employed in federated learning are communication-constrained, for example IoT devices or smartphones are generally connected to Wi-fi networks, thus, even if the models are commonly less expensive to be transmitted compared to raw data, federated learning mechanisms may not be suitable in their general form.&lt;ref name="Survey-2019" /&gt;

Federated learning raises several statistical challenges:

* Heterogeneity between the different local datasets: each node may have some bias with respect to the general population, and the size of the datasets may vary significantly;&lt;ref name=":3"/&gt;
* Temporal heterogeneity: each local dataset's distribution may vary with time;
* [[Interoperability]] of each node's dataset is a prerequisite;
* Each node's dataset may require regular curations;
* Hiding training data might allow attackers to inject [[Backdoor (computing)|backdoors]] into the global model;&lt;ref&gt;How To Backdoor Federated Learning, Eugene Bagdasaryan, 2018&lt;/ref&gt;
* Lack of access to global training data makes it harder to identify unwanted biases entering the training e.g. age, gender, sexual orientation;
* Partial or total loss of model updates due to node failures affecting the global model.&lt;ref name = "Survey-2019" /&gt;

== Properties of federated learning ==

=== Privacy by design ===
The main advantage of using federated approaches to machine learning is to ensure data [[privacy]] or data secrecy. Indeed, no local data is uploaded externally, concatenated or exchanged. Since the entire database is segmented into local bits, this makes it more difficult to hack into it.

With federated learning, only machine learning parameters are exchanged. In addition, such parameters can be [[Encryption|encrypted]] before sharing between learning rounds to extend privacy and [[homomorphic encryption]] schemes can be used to directly make computations on the encrypted data without decrypting them beforehand. Despite such protective measures, these parameters may still leak information about the underlying data samples, for instance, by making multiple specific queries on specific datasets. Querying capability of nodes thus is a major attention point, which can be addressed using differential privacy and secure aggregation.&lt;ref&gt;Practical Secure Aggregation for Privacy Preserving Machine Learning, Keith Bonawitz, 2018&lt;/ref&gt;

It was found that the privacy issues of federated learning is often due to running estimates, which hinders the usage of advanced deep learning models. A Static Batch Normalization (sBN) for optimizing privacy constrained deep neural networks was developed.&lt;ref name=":3"/&gt; During the training phase, sBN does not track running estimates but simply normalize batch data. Only the statistics of hidden representations from local data after the model converges are calculated. This method is suitable for the FL framework as local models do not need to upload running estimates during training. Local models only upload their statistics for once after optimization, which significantly reduces data leakage risk.

=== Personalization ===
The generated model delivers insights based on the global patterns of nodes. However, if a participating node wishes to learn from global patterns but also adapt outcomes to its peculiar status, the federated learning methodology can be adapted to generate two models at once in a [[multi-task learning]] framework. In addition, [[Cluster analysis|clustering]] techniques may be applied to aggregate nodes that share some similarities after the learning process is completed. This allows the generalization of the models learned by the nodes according also to their local data.&lt;ref name=":3"/&gt;&lt;ref&gt;{{cite arXiv |last1=Sattler |first1=Felix |last2=Müller |first2=Klaus-Robert |last3=Samek |first3=Wojciech |title=Clustered Federated Learning: Model-Agnostic Distributed Multi-Task Optimization under Privacy Constraints |date=4 October 2019 |class=cs.LG |eprint=1910.01991 }}&lt;/ref&gt;

In the case of deep neural networks, it is possible to share some layers across the different nodes and keep some of them on each local node. Typically, first layers performing general [[pattern recognition]] are shared and trained all datasets. The last layers will remain on each local node and only be trained on the local node's dataset.&lt;ref&gt;{{cite arXiv |last1=Arivazhagan |first1=Manoj Ghuhan |last2=Aggarwal |first2=Vinay |last3=Singh |first3=Aaditya Kumar |last4=Choudhary |first4=Sunav |title=Federated Learning with Personalization Layers |date=2 December 2019 |class=cs.LG |eprint=1912.00818 }}&lt;/ref&gt;

Early personalization methods often introduce additional computation and communication overhead that may not be necessary. To significantly reduce computation and communication costs in FL, a “Masking Trick” approach was developed.&lt;ref name=":3" /&gt; The “Masking Trick” allows local clients to adaptively contribute to the training of global models much more flexibly and efficiently compared with classical federated learning.

=== Legal upsides of federated learning ===
Western legal frameworks emphasize more and more on data protection and data traceability. White House 2012 Report&lt;ref name="White House-2013"&gt;{{cite journal |title=Consumer Data Privacy in a Networked World: A Framework for Protecting Privacy and Promoting Innovation in the Global Digital Economy |journal=Journal of Privacy and Confidentiality |date=1 March 2013 |doi=10.29012/jpc.v4i2.623 |last1=Anonymous |doi-access=free }}&lt;/ref&gt; recommended the application of a data minimization principle, which is mentioned in European [[General Data Protection Regulation|GDPR]].&lt;ref&gt;Recital 39 of the Regulation (EU) 2016/679 (General Data Protection Regulation)&lt;/ref&gt; In some cases, it is illegal to transfer data from a country to another (e.g., genomic data), however international consortia are sometimes necessary for scientific advances. In such cases federated learning brings solutions to train a global model while respecting security constraints.

== Current research topics ==
Federated learning has started to emerge as an important research topic in 2015&lt;ref name=":1" /&gt; and 2016,&lt;ref name="Opt-2016"&gt;''Federated Optimization: Distributed Machine Learning for On-Device Intelligence,'' Jakub Konečný, H. Brendan McMahan, Daniel Ramage and Peter Richtárik, 2016&lt;/ref&gt; with the first publications on federated averaging in telecommunication settings. Another important aspect of active research is the reduction of the communication burden during the federated learning process. In 2017 and 2018, publications have emphasized the development of resource allocation strategies, especially to reduce communication&lt;ref name="ReferenceA" /&gt; requirements&lt;ref name="Comm-2017"&gt;{{cite arXiv|last1=Konečný |first1=Jakub |last2=McMahan |first2=H. Brendan |last3=Yu |first3=Felix X. |last4=Richtárik |first4=Peter |last5=Suresh |first5=Ananda Theertha |last6=Bacon |first6=Dave |title=Federated Learning: Strategies for Improving Communication Efficiency |date=30 October 2017 |class=cs.LG |eprint=1610.05492 }}&lt;/ref&gt; between nodes with gossip algorithms&lt;ref&gt;''Gossip training for deep learning, Michael Blot and al., 2017''&lt;/ref&gt; as well as on the characterization of the robustness to differential privacy attacks.&lt;ref&gt;''Differentially Private Federated Learning: A Client Level Perspective'' Robin C. Geyer and al., 2018&lt;/ref&gt; Other research activities focus on the reduction of the bandwidth during training through sparsification and quantization methods,&lt;ref name="Comm-2017"/&gt; where the machine learning models are sparsified and/or compressed before they are shared with other nodes.

Recent research advancements are starting to consider real-word propagating [[Communication channel|channels]]&lt;ref&gt;{{cite arXiv |last1=Amiri |first1=Mohammad Mohammadi |last2=Gunduz |first2=Deniz |title=Federated Learning over Wireless Fading Channels |date=10 February 2020 |class=cs.IT |eprint=1907.09769 }}&lt;/ref&gt; as in previous implementations ideal channels were assumed. Another active direction of research is to develop Federated learning for training heterogeneous local models with varying computation complexities and producing a single powerful global inference model.&lt;ref name=":3"/&gt;

A learning framework named Assisted learning was recently developed to improve each agent's learning capabilities without transmitting private data, models, and even learning objectives.&lt;ref&gt;{{Cite journal|last1=Xian|first1=Xun|last2=Wang|first2=Xinran|last3=Ding|first3=Jie|last4=Ghanadan|first4=Reza|date=2020|title=Assisted Learning: A Framework for Multi-Organization Learning|url=https://proceedings.neurips.cc//paper/2020/hash/a7b23e6eefbe6cf04b8e62a6f0915550-Abstract.html|journal=Advances in Neural Information Processing Systems|language=en|volume=33|arxiv=2004.00566}}&lt;/ref&gt; Compared with Federated learning that often requires a [[Master/slave (technology)|central controller]] to orchestrate the learning and optimization, [http://assisted-learning.org/ Assisted learning] aims to provide protocols for the agents to optimize and learn among themselves without a global model.

== Use cases ==
Federated learning typically applies when individual actors need to train models on larger datasets than their own, but cannot afford to share the data in itself with other (e.g., for legal, strategic or economic reasons). The technology yet requires good connections between local servers and minimum computational power for each node.&lt;ref name="Survey-2019" /&gt;

=== Transportation: self-driving cars ===
[[Self-driving car]]s encapsulate many machine learning technologies to function: [[computer vision]] for analyzing obstacles, [[machine learning]] for adapting their pace to the environment (e.g., bumpiness of the road). Due to the potential high number of self-driving cars and the need for them to quickly respond to real world situations, traditional cloud approach may generate safety risks. Federated learning can represent a solution for limiting volume of data transfer and accelerating learning processes.&lt;ref&gt;{{cite journal |title=Federated learning meets blockchain at 6G edge: a drone-assisted networking for disaster response | year= 2020 |doi=10.1145/3414045.3415949 |last1=Pokhrel |first1=Shiva Raj |pages=49–54| s2cid= 222179104 }}&lt;/ref&gt;&lt;ref name="Elbir-2020"&gt;{{cite arXiv |last1=Elbir |first1=Ahmet M. |last2=Coleri |first2=S. |title=Federated Learning for Vehicular Networks |date=2 June 2020 |class=eess.SP |eprint=2006.01412 }}&lt;/ref&gt;

=== Industry 4.0: smart manufacturing ===
In [[Industry 4.0]], there is a widespread adoption of machine learning techniques&lt;ref&gt;{{cite journal |last1=Cioffi |first1=Raffaele |last2=Travaglioni |first2=Marta |last3=Piscitelli |first3=Giuseppina |last4=Petrillo |first4=Antonella |last5=De Felice |first5=Fabio |title=Artificial Intelligence and Machine Learning Applications in Smart Production: Progress, Trends, and Directions |journal=Sustainability |date=2019 |volume=12 |issue=2 |pages=492 |doi=10.3390/su12020492 |language=en|doi-access=free }}&lt;/ref&gt; to improve the efficiency and effectiveness of industrial process while guaranteeing a high level of safety. Nevertheless, privacy of sensitive data for industries and manufacturing companies is of paramount importance. Federated learning algorithms can be applied to these problems as they do not disclose any sensitive data.&lt;ref name="Opt-2016" /&gt;

=== Medicine: digital health ===
Federated learning seeks to address the problem of data governance and privacy by training algorithms collaboratively without exchanging the data itself. Today’s standard approach of centralizing data from multiple centers comes at the cost of critical concerns regarding patient privacy and data protection. To solve this problem, the ability to train machine learning models at scale across multiple medical institutions without moving the data is a critical technology. Nature Digital Medicine published in September 2020 a paper The Future of Digital Health with Federated Learning&lt;ref&gt;{{cite journal |last1=Rieke |first1=Nicola |last2=Hancox |first2=Jonny |last3=Li |first3=Wenqi |last4=Milletarì |first4=Fausto |last5=Roth |first5=Holger R. |last6=Albarqouni |first6=Shadi |last7=Bakas |first7=Spyridon |last8=Galtier |first8=Mathieu N. |last9=Landman |first9=Bennett A. |last10=Maier-Hein |first10=Klaus |last11=Ourselin |first11=Sébastien |last12=Sheller |first12=Micah |last13=Summers |first13=Ronald M. |last14=Trask |first14=Andrew |last15=Xu |first15=Daguang |last16=Baust |first16=Maximilian |last17=Cardoso |first17=M. Jorge |title=The future of digital health with federated learning |journal=NPJ Digital Medicine |date=14 September 2020 |volume=3 |issue=1 |page=119 |doi=10.1038/s41746-020-00323-1 |pmid=33015372 |pmc=7490367 |arxiv=2003.08119 |s2cid=212747909 }}&lt;/ref&gt; where the authors explore how federated learning may provide a solution for the future of digital health and highlight the challenges and considerations that need to be addressed.

== References ==
{{reflist}}

== External links ==
*[https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:32016R0679 "Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016"] at eur-lex.europa.eu. Retrieved October 18, 2019.
*[https://ico.org.uk/about-the-ico/news-and-events/ai-blog-data-minimisation-and-privacy-preserving-techniques-in-ai-systems/ "Data minimisation and privacy-preserving techniques in AI systems"] at UK Information Commissioners Office. Retrieved July 22, 2020

[[Category:Machine learning]]
[[Category:Distributed algorithms]]
[[Category:Multi-agent systems]]</text>
      <sha1>r6mqccjee2kp41vjmiljrxw682f7azw</sha1>
    </revision>
  </page>
  <page>
    <title>Distill (journal)</title>
    <ns>0</ns>
    <id>61213249</id>
    <revision>
      <id>910294058</id>
      <parentid>905110116</parentid>
      <timestamp>2019-08-11T01:38:34Z</timestamp>
      <contributor>
        <username>Headbomb</username>
        <id>1461430</id>
      </contributor>
      <comment>Standardizing infobox journal with ([[User:Tokenzero/infoboxJournal|infoboxJournal.js]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2921" xml:space="preserve">{{Infobox journal
| title         = Distill
| image         = 
| caption       = 
| former_name   = &lt;!-- or |former_names= --&gt;
| abbreviation  = Distill
| discipline    = [[Computer science]]
| peer-reviewed = 
| language      = English
| editors       = Shan Carter, Chris Olah, Arvind Satyanarayan
| publisher     = 
| country       = 
| history       = 2017–present
| frequency     = Continuous
| openaccess    = Yes
| license       = [[CC-BY 4.0]]
| impact        = 
| impact-year   = 
| ISSN          = 
| eISSN         = 2476-0757
| CODEN         = 
| JSTOR         = 
| LCCN          = 2017201669
| OCLC          = 972506987
| website       = https://distill.pub/
| link1         = 
| link1-name    = 
| link2         = &lt;!-- up to |link5= --&gt;
| link2-name    = &lt;!-- up to |link5-name= --&gt;
}}
'''''Distill''''', is a [[peer-reviewed]] [[scientific journal]] covering [[machine learning]]. Articles may contain interactive graphics and so-called [[explorable explanation]]s. The journal was established in March 2017 by [[Google]], [[OpenAI]], [[DeepMind]], and [[YC research|Y Combinator Research]].&lt;ref&gt;{{Cite web |url=https://www.hpcwire.com/2017/03/22/google-launches-new-machine-learning-journal/ |title=Google Launches New Machine Learning Journal |date=2017-03-22 |website=HPCwire |access-date=2019-07-05 |type=Press release}}&lt;/ref&gt;&lt;ref&gt;{{Cite web |url=https://blog.ycombinator.com/distill-an-interactive-visual-journal-for-machine-learning-research/ |title=Distill: An Interactive, Visual Journal for Machine Learning Research |last=Nielsen |first=Michael |website=Y Combinator |access-date=2019-07-05 |type=Blog}}&lt;/ref&gt; The [[editors-in-chief]] are Shan Carter ([[Google Brain]]), Chris Olah ([[OpenAI]]), and Arvind Satyanarayan ([[MIT Computer Science and Artificial Intelligence Laboratory]]). The journal is indexed in [[Ei Compendex]].&lt;ref&gt;{{cite MIAR |title=Distill |issn=2476-0757 |accessdate=2019-07-06}}&lt;/ref&gt; Its launch was criticized as overly hyped by ''[[The Scholarly Kitchen]]'', which also noted that most authors were Google employees.&lt;ref&gt;{{cite web |last1=Andersen |first1=Keith |title=Has Google Become a Journal Publisher? |url=https://scholarlykitchen.sspnet.org/2018/06/11/has-google-become-a-journal-publisher/ |website=[[The Scholarly Kitchen]] |date=11 June 2018}}&lt;/ref&gt;

==References==
&lt;references /&gt;

==Further reading==
* {{cite web |title=Distill: A Journal with Interactive Images for Machine Learning Research |url=https://www.enago.com/academy/distill-a-journal-with-interactive-images-for-machine-learning-research/ |publisher=Enago Academy |date=12 May 2018}}

==External links==
*{{Official website|https://distill.pub/}}

[[Category:Machine learning]]
[[Category:Computer science journals]]
[[Category:Publications established in 2017]]
[[Category:Creative Commons Attribution-licensed journals]]
[[Category:English-language journals]]
[[Category:Continuous journals]]</text>
      <sha1>8of8v56j930kaezo8cqz84xu8zem3z1</sha1>
    </revision>
  </page>
  <page>
    <title>Machine learning in physics</title>
    <ns>0</ns>
    <id>61373032</id>
    <revision>
      <id>993911681</id>
      <parentid>974083053</parentid>
      <timestamp>2020-12-13T03:54:48Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 34 templates: del empty params (4×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="16443" xml:space="preserve">{{short description|Applications of machine learning to quantum physics}}
{{About|classical machine learning of quantum systems|machine learning enhanced by quantum computation|quantum machine learning}}
{{Quantum mechanics}}

Applying classical methods of machine learning to the study of quantum systems (sometimes called ''quantum machine learning'') is the focus of an emergent area of physics research. A basic example of this is [[quantum tomography|quantum state tomography]], where a quantum state is learned from measurement.&lt;ref name=":4"&gt;{{Cite journal|last=Torlai|first=Giacomo|last2=Mazzola|first2=Guglielmo|last3=Carrasquilla|first3=Juan|last4=Troyer|first4=Matthias|last5=Melko|first5=Roger|last6=Carleo|first6=Giuseppe|date=May 2018|title=Neural-network quantum state tomography|journal=Nature Physics|language=en|volume=14|issue=5|pages=447–450|doi=10.1038/s41567-018-0048-5|arxiv=1703.05334|bibcode=2018NatPh..14..447T|issn=1745-2481}}&lt;/ref&gt; Other examples include learning Hamiltonians,&lt;ref&gt;{{Cite journal|last=Cory|first=D. G.|last2=Wiebe|first2=Nathan|last3=Ferrie|first3=Christopher|last4=Granade|first4=Christopher E.|date=2012-07-06|title=Robust Online Hamiltonian Learning|journal=New Journal of Physics|volume=14|issue=10|pages=103013|arxiv=1207.1655|language=en|doi=10.1088/1367-2630/14/10/103013|bibcode=2012NJPh...14j3013G}}&lt;/ref&gt; learning quantum phase transitions,&lt;ref&gt;{{cite arxiv|last=Broecker|first=Peter|last2=Assaad|first2=Fakher F.|last3=Trebst|first3=Simon|date=2017-07-03|title=Quantum phase recognition via unsupervised machine learning|eprint=1707.00663|class=cond-mat.str-el}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Huembeli|first=Patrick|last2=Dauphin|first2=Alexandre|last3=Wittek|first3=Peter|year=2018|title=Identifying Quantum Phase Transitions with Adversarial Neural Networks|arxiv=1710.08382|journal=Physical Review B|volume=97|issue=13|pages=134109|doi=10.1103/PhysRevB.97.134109|bibcode=2018PhRvB..97m4109H|issn=2469-9950}}&lt;/ref&gt; and automatically generating new quantum experiments.&lt;ref name="Krenn 090405"&gt;{{Cite journal|last=Krenn|first=Mario|date=2016-01-01|title=Automated Search for new Quantum Experiments|journal=Physical Review Letters|volume=116|issue=9|pages=090405|arxiv=1509.02749|bibcode=2016PhRvL.116i0405K|doi=10.1103/PhysRevLett.116.090405|pmid=26991161}}&lt;/ref&gt;&lt;ref name="Knott 073033"&gt;{{Cite journal|last=Knott|first=Paul|date=2016-03-22|title=A search algorithm for quantum state engineering and metrology|journal=New Journal of Physics|volume=18|issue=7|pages=073033|arxiv=1511.05327|bibcode=2016NJPh...18g3033K|doi=10.1088/1367-2630/18/7/073033}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Dunjko|first=Vedran|last2=Briegel|first2=Hans J|date=2018-06-19|title=Machine learning &amp; artificial intelligence in the quantum domain: a review of recent progress|journal=Reports on Progress in Physics|volume=81|issue=7|pages=074001|doi=10.1088/1361-6633/aab406|pmid=29504942|bibcode=2018RPPh...81g4001D|issn=0034-4885|hdl=1887/71084|hdl-access=free}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Melnikov|first=Alexey A.|last2=Nautrup|first2=Hendrik Poulsen|last3=Krenn|first3=Mario|last4=Dunjko|first4=Vedran|last5=Tiersch|first5=Markus|last6=Zeilinger|first6=Anton|last7=Briegel|first7=Hans J.|year=1221|title=Active learning machine learns to create new quantum experiments|journal=Proceedings of the National Academy of Sciences|language=en|volume=115|issue=6|pages=1221–1226|doi=10.1073/pnas.1714936115|issn=0027-8424|pmc=5819408|pmid=29348200|arxiv=1706.00868}}&lt;/ref&gt; Classical machine learning is effective at processing large amounts of experimental or calculated data in order to characterize an unknown quantum system, making its application useful in contexts including [[Quantum information|quantum information theory]], quantum technologies development, and computational materials design. In this context, it can be used for example as a tool to interpolate pre-calculated interatomic potentials&lt;ref&gt;{{Cite journal|last=Behler|first=Jörg|last2=Parrinello|first2=Michele|date=2007-04-02|title=Generalized Neural-Network Representation of High-Dimensional Potential-Energy Surfaces|journal=Physical Review Letters|volume=98|issue=14|pages=146401|doi=10.1103/PhysRevLett.98.146401|pmid=17501293|bibcode=2007PhRvL..98n6401B}}&lt;/ref&gt; or directly solving the [[Schrödinger equation]] with a [[Variational method (quantum mechanics)|variational method]].&lt;ref name=":5" /&gt;

== Applications of machine learning to physics ==

=== Noisy data ===
The ability to experimentally control and prepare increasingly complex quantum systems brings with it a growing need to turn large and noisy data sets into meaningful information. This is a problem that has already been studied extensively in the classical setting, and consequently, many existing machine learning techniques can be naturally adapted to more efficiently address experimentally relevant problems. For example, [[Bayesian statistics|Bayesian]] methods and concepts of [[Algorithmic learning theory|algorithmic learning]] can be fruitfully applied to tackle quantum state classification,&lt;ref name="sentis2012quantum"&gt;{{cite journal|last1=Sentís|first1=Gael|last2=Calsamiglia|first2=John|last3=Muñoz-Tapia|first3=Raúl|last4=Bagan|first4=Emilio|year=2012|title=Quantum learning without quantum memory|journal=Scientific Reports|volume=2|page=708|arxiv=1106.2742|bibcode=2012NatSR...2E.708S|doi=10.1038/srep00708|pmc=3464493|pmid=23050092}}&lt;/ref&gt; Hamiltonian learning,&lt;ref&gt;{{cite journal|last1=Wiebe|first1=Nathan|last2=Granade|first2=Christopher|last3=Ferrie|first3=Christopher|last4=Cory|first4=David|year=2014|title=Quantum Hamiltonian learning using imperfect quantum resources|journal=Physical Review A|volume=89|issue=4|page=042314|arxiv=1311.5269|bibcode=2014PhRvA..89d2314W|doi=10.1103/physreva.89.042314|hdl=10453/118943}}&lt;/ref&gt; and the characterization of an unknown [[Unitary matrix|unitary transformation]].&lt;ref name="bisio2010"&gt;{{Cite journal|last1=Bisio|first1=Alessandro|last2=Chiribella|first2=Giulio|last3=D'Ariano|first3=Giacomo Mauro|last4=Facchini|first4=Stefano|last5=Perinotti|first5=Paolo|year=2010|title=Optimal quantum learning of a unitary transformation|journal=Physical Review A|volume=81|issue=3|pages=032324|arxiv=0903.0543|bibcode=2010PhRvA..81c2324B|doi=10.1103/PhysRevA.81.032324}}&lt;/ref&gt;&lt;ref name=":3"&gt;{{cite journal|last1=Jeongho|last2=Junghee Ryu|first2=Bang|last3=Yoo|first3=Seokwon|last4=Pawłowski|first4=Marcin|last5=Lee|first5=Jinhyoung|year=2014|title=A strategy for quantum algorithm design assisted by machine learning|journal=New Journal of Physics|volume=16|issue=1|page=073017|arxiv=1304.2169|bibcode=2014NJPh...16a3017K|doi=10.1088/1367-2630/16/1/013017}}&lt;/ref&gt; Other problems that have been addressed with this approach are given in the following list:

* Identifying an accurate model for the dynamics of a quantum system, through the reconstruction of the [[Hamiltonian (quantum mechanics)|Hamiltonian]];&lt;ref name=":0"&gt;{{Cite journal|last=Granade|first=Christopher E.|last2=Ferrie|first2=Christopher|last3=Wiebe|first3=Nathan|last4=Cory|first4=D. G.|date=2012-10-03|title=Robust Online Hamiltonian Learning|journal=New Journal of Physics|volume=14|issue=10|pages=103013|arxiv=1207.1655|bibcode=2012NJPh...14j3013G|doi=10.1088/1367-2630/14/10/103013|issn=1367-2630}}&lt;/ref&gt;&lt;ref name=":1"&gt;{{Cite journal|last=Wiebe|first=Nathan|last2=Granade|first2=Christopher|last3=Ferrie|first3=Christopher|last4=Cory|first4=D. G.|year=2014|title=Hamiltonian Learning and Certification Using Quantum Resources|journal=Physical Review Letters|volume=112|issue=19|pages=190501|arxiv=1309.0876|bibcode=2014PhRvL.112s0501W|doi=10.1103/PhysRevLett.112.190501|issn=0031-9007|pmid=24877920}}&lt;/ref&gt;&lt;ref name=":2"&gt;{{Cite journal|last=Wiebe|first=Nathan|last2=Granade|first2=Christopher|last3=Ferrie|first3=Christopher|last4=Cory|first4=David G.|date=2014-04-17|title=Quantum Hamiltonian Learning Using Imperfect Quantum Resources|journal=Physical Review A|volume=89|issue=4|pages=042314|arxiv=1311.5269|bibcode=2014PhRvA..89d2314W|doi=10.1103/PhysRevA.89.042314|issn=1050-2947|hdl=10453/118943}}&lt;/ref&gt;
* Extracting information on unknown states;&lt;ref name="sasaki2010a"&gt;{{Cite journal|last=Sasaki|first=Madahide|last2=Carlini|first2=Alberto|last3=Jozsa|first3=Richard|date=2001|title=Quantum Template Matching|journal=Physical Review A|volume=64|issue=2|pages=022317|arxiv=quant-ph/0102020|bibcode=2001PhRvA..64b2317S|doi=10.1103/PhysRevA.64.022317}}&lt;/ref&gt;&lt;ref name="sasaki2010b"&gt;{{Cite journal|last=Sasaki|first=Masahide|date=2002|title=Quantum learning and universal quantum matching machine|journal=Physical Review A|volume=66|issue=2|pages=022303|arxiv=quant-ph/0202173|bibcode=2002PhRvA..66b2303S|doi=10.1103/PhysRevA.66.022303}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Sentís|first=Gael|last2=Guţă|first2=Mădălin|last3=Adesso|first3=Gerardo|date=2015-07-09|title=Quantum learning of coherent states|journal=EPJ Quantum Technology|language=en|volume=2|issue=1|pages=17|doi=10.1140/epjqt/s40507-015-0030-4|issn=2196-0763|arxiv=1410.8700}}&lt;/ref&gt;&lt;ref name="sentis2012quantum" /&gt;&lt;ref&gt;{{Cite journal|last=Lee|first=Sang Min|last2=Lee|first2=Jinhyoung|last3=Bang|first3=Jeongho|date=2018-11-02|title=Learning unknown pure quantum states|journal=Physical Review A|language=en|volume=98|issue=5|pages=052302|arxiv=1805.06580|doi=10.1103/PhysRevA.98.052302|bibcode=2018PhRvA..98e2302L}}&lt;/ref&gt;&lt;ref name=":4" /&gt;
* Learning unknown unitary transformations and measurements;&lt;ref name="bisio2010" /&gt;&lt;ref name=":3" /&gt;
* Engineering of quantum gates from qubit networks with pairwise interactions, using time dependent&lt;ref&gt;{{Cite journal|last=Zahedinejad|first=Ehsan|last2=Ghosh|first2=Joydip|last3=Sanders|first3=Barry C.|date=2016-11-16|title=Designing High-Fidelity Single-Shot Three-Qubit Gates: A Machine Learning Approach|journal=Physical Review Applied|volume=6|issue=5|pages=054005|arxiv=1511.08862|bibcode=2016PhRvP...6e4005Z|doi=10.1103/PhysRevApplied.6.054005|issn=2331-7019}}&lt;/ref&gt; or independent&lt;ref name="Banchi"&gt;{{Cite journal|last=Banchi|first=Leonardo|last2=Pancotti|first2=Nicola|last3=Bose|first3=Sougato|date=2016-07-19|title=Quantum gate learning in qubit networks: Toffoli gate without time-dependent control|journal=[[npj Quantum Information]]|volume=2|pages=16019|bibcode=2016npjQI...216019B|doi=10.1038/npjqi.2016.19|doi-access=free}}&lt;/ref&gt; Hamiltonians.
* Improving the extraction accuracy of physical observables from absorption images of ultracold atoms (degenerate Fermi gas), by the generation of an ideal reference frame.&lt;ref name="Ness2020"&gt;{{Cite journal|last=Ness|first=Gal|last2=Vainbaum|first2=Anastasiya|last3=Shkedrov|first3=Constantine|last4=Florshaim|first4=Yanay|last5=Sagi|first5=Yoav|date=2020-07-06|title=Single-exposure absorption imaging of ultracold atoms using deep learning|journal=Physical Review Applied|volume=14|pages=014011|arxiv=2003.01643|doi=10.1103/PhysRevApplied.14.014011}}&lt;/ref&gt;

=== Calculated and noise-free data ===
Quantum machine learning can also be applied to dramatically accelerate the prediction of quantum properties of molecules and materials.&lt;ref&gt;{{Cite journal|last=von Lilienfeld|first=O. Anatole|date=2018-04-09|title=Quantum Machine Learning in Chemical Compound Space|journal=Angewandte Chemie International Edition|volume=57|issue=16|pages=4164–4169|doi=10.1002/anie.201709686|pmid=29216413}}&lt;/ref&gt; This can be helpful for the computational design of new molecules or materials. Some examples include

* Interpolating interatomic potentials;&lt;ref&gt;{{Cite journal|last=Bartok|first=Albert P.|last2=Payne|first2=Mike C.|last3=Risi|first3=Kondor|last4=Csanyi|first4=Gabor|date=2010|title=Gaussian approximation potentials: The accuracy of quantum mechanics, without the electrons|url=https://authors.library.caltech.edu/18339/1/Bartok2010p9871Phys_Rev_Lett.pdf|journal=Physical Review Letters|volume=104|issue=13|pages=136403|doi=10.1103/PhysRevLett.104.136403|pmid=20481899|arxiv=0910.1019|bibcode=2010PhRvL.104m6403B}}&lt;/ref&gt;
* Inferring molecular atomization energies throughout [[Chemical space|chemical compound space]];&lt;ref&gt;{{Cite journal|last=Rupp|first=Matthias|last2=Tkatchenko|first2=Alexandre|last3=Muller|first3=Klaus-Robert|last4=von Lilienfeld|first4=O. Anatole|date=2012-01-31|title=Fast and Accurate Modeling of Molecular Atomization Energies With Machine Learning|journal=Physical Review Letters|volume=355|issue=6325|pages=602|arxiv=1109.2618|bibcode=2012PhRvL.108e8301R|doi=10.1103/PhysRevLett.108.058301|pmid=22400967}}&lt;/ref&gt;
* Accurate potential energy surfaces with restricted Boltzmann machines;&lt;ref&gt;{{Cite journal|last=Xia|first=Rongxin|last2=Kais|first2=Sabre|date=2018-10-10|title=Quantum machine learning for electronic structure calculations|journal=Nature Communications|volume=9|issue=1|pages=4195|doi=10.1038/s41467-018-06598-z|pmc=6180079|pmid=30305624|arxiv=1803.10296|bibcode=2018NatCo...9.4195X}}&lt;/ref&gt;
* Automatic generation of new quantum experiments;&lt;ref name="Krenn 090405"/&gt;&lt;ref name="Knott 073033"/&gt;
* Solving the many-body, static and time-dependent Schrödinger equation;&lt;ref name=":5"&gt;{{Cite journal|last=Carleo|first=Giuseppe|last2=Troyer|first2=Matthias|date=2017-02-09|title=Solving the quantum many-body problem with artificial neural networks|journal=Science|volume=355|issue=6325|pages=602–606|arxiv=1606.02318|bibcode=2017Sci...355..602C|doi=10.1126/science.aag2302|pmid=28183973}}&lt;/ref&gt;
* Identifying phase transitions from entanglement spectra;&lt;ref&gt;{{Cite journal|last=van Nieuwenburg|first=Evert|last2=Liu|first2=Ye-Hua|last3=Huber|first3=Sebastian|year=2017|title=Learning phase transitions by confusion|journal=Nature Physics|volume=13|issue=5|pages=435|arxiv=1610.02048|bibcode=2017NatPh..13..435V|doi=10.1038/nphys4037}}&lt;/ref&gt;
* Generating adaptive feedback schemes for [[quantum metrology]] and [[quantum tomography]].&lt;ref&gt;{{Cite journal|last=Hentschel|first=Alexander|date=2010-01-01|title=Machine Learning for Precise Quantum Measurement|journal=Physical Review Letters|volume=104|issue=6|pages=063603|arxiv=0910.0762|bibcode=2010PhRvL.104f3603H|doi=10.1103/PhysRevLett.104.063603|pmid=20366821}}&lt;/ref&gt;&lt;ref&gt;{{cite arxiv|last=Quek|first=Yihui|last2=Fort|first2=Stanislav|last3=Ng|first3=Hui Khoon|date=2018-12-17|title=Adaptive Quantum State Tomography with Neural Networks|eprint=1812.06693|class=quant-ph}}&lt;/ref&gt;

=== Variational Circuits ===
Variational circuits are a family of algorithms which utilize training based on circuit parameters and an objective function.&lt;ref&gt;{{Cite web|url=https://qmlt.readthedocs.io/en/latest/variational.html|title=Variational Circuits — Quantum Machine Learning Toolbox 0.7.1 documentation|website=qmlt.readthedocs.io|access-date=2018-12-06}}&lt;/ref&gt; Variational circuits are generally composed of a classical device communicating input parameters (random or pre-trained parameters) into a quantum device, along with a classical [[Mathematical optimization]] function. These circuits are very heavily dependent on the architecture of the proposed quantum device because parameter adjustments are adjusted based solely on the classical components within the device.&lt;ref&gt;{{Cite web|url=https://medium.com/xanaduai/quantum-machine-learning-1-0-76a525c8cf69|title=Quantum Machine Learning 1.0|last=Schuld|first=Maria|date=2018-06-12|website=XanaduAI|access-date=2018-12-07}}&lt;/ref&gt; Though the application is considerably infantile in the field of quantum machine learning, it has incredibly high promise for more efficiently generating efficient optimization functions.

=== Sign problem ===
Machine learning techniques can be used to find a better manifold of integration for path integrals in order to avoid the sign problem.&lt;ref&gt;{{cite journal|arxiv=1709.01971|title=Deep Learning Beyond Lefschetz Thimbles|doi=10.1103/PhysRevD.96.094505|bibcode=2017PhRvD..96i4505A|year=2017|last1=Alexandru|first1=Andrei|last2=Bedaque|first2=Paulo F.|last3=Lamm|first3=Henry|last4=Lawrence|first4=Scott|journal=Physical Review D|volume=96|issue=9|pages=094505}}&lt;/ref&gt;

== See also ==
*[[Quantum computing]]
*[[Quantum machine learning]]
*[[Quantum algorithm for linear systems of equations]]
*[[Quantum annealing]]
*[[Quantum neural network]]

==References==
{{Reflist |30em}}

{{Quantum computing}}

[[Category:Machine learning]]
[[Category:Quantum information science]]
[[Category:Theoretical computer science]]
[[Category:Emerging technologies]]
[[Category:Quantum programming]]</text>
      <sha1>p2twbwtozbf84bcosbxmabjhrepyevw</sha1>
    </revision>
  </page>
  <page>
    <title>Machine learning in video games</title>
    <ns>0</ns>
    <id>60951296</id>
    <revision>
      <id>1003884038</id>
      <parentid>999142072</parentid>
      <timestamp>2021-01-31T04:29:03Z</timestamp>
      <contributor>
        <ip>125.239.194.94</ip>
      </contributor>
      <comment>/* AlphaZero */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="30320" xml:space="preserve">In [[video game]]s, various [[artificial intelligence]] techniques have been used in a variety of ways, ranging from [[non-player character]] (NPC) control to [[Procedural generation|procedural content generation]] (PCG). [[Machine learning]] is a [[subset]] of artificial intelligence that focuses on using algorithms and statistical models to make machines act without specific programming. This is in sharp contrast to traditional methods of artificial intelligence such as [[search tree]]s and [[expert system]]s.

Information on machine learning techniques in the field of games is mostly known to public through [[Research|research projects]] as most gaming companies choose not to publish specific information about their [[intellectual property]]. The most publicly known application of machine learning in games is likely the use of [[deep learning]] [[Intelligent agent|agents]] that compete with professional human players in complex [[strategy game]]s. There has been a significant application of machine learning on games such as [[Atari]]/ALE, ''[[Doom (1993 video game)|Doom]]'', ''[[Minecraft]]'', ''[[StarCraft (video game)|StarCraft]]'', and car racing.&lt;ref name="Justesen 2019 1"&gt;{{Cite journal|last1=Justesen|first1=Niels|last2=Bontrager|first2=Philip|last3=Togelius|first3=Julian|last4=Risi|first4=Sebastian|date=2019|title=Deep Learning for Video Game Playing|journal=IEEE Transactions on Games|volume=12|pages=1–20|doi=10.1109/tg.2019.2896986|issn=2475-1502|arxiv=1708.07902|s2cid=37941741}}&lt;/ref&gt; Other games that did not originally exists as video games, such as chess and Go have also been affected by the machine learning.&lt;ref name=":0"&gt;{{Cite journal|last1=Silver|first1=David|last2=Hubert|first2=Thomas|last3=Schrittwieser|first3=Julian|last4=Antonoglou|first4=Ioannis|last5=Lai|first5=Matthew|last6=Guez|first6=Arthur|last7=Lanctot|first7=Marc|last8=Sifre|first8=Laurent|last9=Kumaran|first9=Dharshan|date=2018-12-06|title=A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play|journal=Science|volume=362|issue=6419|pages=1140–1144|doi=10.1126/science.aar6404|pmid=30523106|issn=0036-8075|bibcode=2018Sci...362.1140S|s2cid=54457125|url=http://discovery.ucl.ac.uk/10069050/1/alphazero_preprint.pdf}}&lt;/ref&gt;

== Overview of relevant machine learning techniques ==
[[File:Colored neural network.svg|thumb|An artificial neural network is an interconnected group of nodes, akin to the vast network of [[neuron]]s in a [[brain]]. Here, each circular node represents an [[artificial neuron]] and an arrow represents a connection from the output of one artificial neuron to the input of another.]]

=== Deep learning ===
[[Deep learning]] is a subset of machine learning which focuses heavily on the use of [[artificial neural network]]s (ANN) that learn to solve complex tasks. Deep learning uses multiple layers of ANN and other techniques to progressively extract information from an input. Due to this complex layered approach, deep learning models often require powerful machines to train and run on.

==== Convolutional neural networks ====
[[Convolutional neural network]]s (CNN) are specialized ANNs that are often used to analyze image data. These types of networks are able to learn [[translation invariant]] patterns, which are patterns that are not dependent on location. CNNs are able to learn these patterns in a hierarchy, meaning that earlier convolutional layers will learn smaller local patterns while later layers will learn larger patterns based on the previous patterns.&lt;ref name=":7"&gt;{{Cite book|last=Chollet, Francois|title=Deep learning with Python|date=2017-10-28|isbn=9781617294433|oclc=1019988472}}&lt;/ref&gt; A CNN's ability to learn visual data has made it a commonly used tool for deep learning in games.&lt;ref name=":2" /&gt;&lt;ref name=":1" /&gt;

=== Recurrent neural network ===
[[Recurrent neural network]]s are a type of ANN that are designed to process sequences of data in order, one part at a time rather than all at once. An RNN runs over each part of a sequence, using the current part of the sequence along with memory of previous parts of the current sequence to produce an output. These types of ANN are highly effective at tasks such as [[speech recognition]] and other problems that depend heavily on temporal order. There are several types of RNNs with different internal configurations; the basic implementation suffers from a lack of [[Long-term memory|long term memory]] due to the [[vanishing gradient problem]], thus it is rarely used over newer implementations.&lt;ref name=":7" /&gt;

==== Long short-term memory ====
A [[long short-term memory]] (LSTM) network is a specific implementation of a RNN that is designed to deal with the [[vanishing gradient problem]] seen in simple RNNs, which would lead to them gradually "forgetting" about previous parts of an inputted sequence when calculating the output of a current part. LSTMs solve this problem with the addition of an elaborate system that uses an additional input/output to keep track of long term data.&lt;ref name=":7" /&gt; LSTMs have achieved very strong results across various fields, and were used by several monumental deep learning agents in games.&lt;ref name=":8"&gt;{{Cite web|url=https://openai.com/blog/openai-five/|title=OpenAI Five|date=2018-06-25|website=OpenAI|access-date=2019-06-04}}&lt;/ref&gt;&lt;ref name=":2" /&gt;

=== Reinforcement learning ===
[[Reinforcement learning]] is the process of training an agent using rewards and/or punishments. The way an agent is rewarded or punished depends heavily on the problem; such as giving an agent a positive reward for winning a game or a negative one for losing. Reinforcement learning is used heavily in the field of machine learning and can be seen in methods such as [[Q-learning]], [[Direct policy search|policy search]], Deep Q-networks and others. It has seen strong performance in both the field of games and [[robotics]].&lt;ref&gt;{{Cite book|title=Artificial intelligence : a modern approach|last=Russell, Stuart J. (Stuart Jonathan)|others=Norvig, Peter|isbn=9789332543515|edition= Third Indian |location=Noida, India|oclc=928841872}}&lt;/ref&gt;

=== Neuroevolution ===
[[Neuroevolution]] involves the use of both neural networks and [[evolutionary algorithm]]s. Instead of using gradient descent like most neural networks, neuroevolution models make use of evolutionary algorithms to update neurons in the network. Researchers claim that this process is less likely to get stuck in a local minimum and is potentially faster than state of the art deep learning techniques.&lt;ref&gt;{{cite arxiv|last1=Clune|first1=Jeff|last2=Stanley|first2=Kenneth O.|last3=Lehman|first3=Joel|last4=Conti|first4=Edoardo|last5=Madhavan|first5=Vashisht|last6=Such|first6=Felipe Petroski|date=2017-12-18|title=Deep Neuroevolution: Genetic Algorithms Are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning|eprint=1712.06567|class=cs.NE}}&lt;/ref&gt;

== Deep learning agents ==
Machine learning [[Intelligent agent|agents]] have been used to take the place of a human player rather than function as NPCs, which are deliberately added into video games as part of designed [[gameplay]]. Deep learning agents have achieved impressive results when used in competition with both humans and other artificial intelligence agents.&lt;ref name=":0" /&gt;&lt;ref&gt;{{Citation|last1=Zhen|first1=Jacky Shunjie|title=Neuroevolution for Micromanagement in the Real-Time Strategy Game Starcraft: Brood War|date=2013|work=Lecture Notes in Computer Science|pages=259–270|publisher=Springer International Publishing|isbn=9783319036793|last2=Watson|first2=Ian|doi=10.1007/978-3-319-03680-9_28|citeseerx=10.1.1.703.5110}}&lt;/ref&gt;

=== Chess ===
[[Chess]] is a [[turn-based strategy]] game that is considered a difficult AI problem due to the [[computational complexity]] of its board space. Similar strategy games are often solved with some form of a [[Minimax]] Tree Search. These types of AI agents have been known to beat professional human players, such as the historic 1997 [[Deep Blue versus Garry Kasparov]] match. Since then, machine learning agents have shown ever greater success than previous AI agents.

=== Go ===
[[Go (game)|Go]] is another turn-based strategy game which is considered an even more difficult AI problem than chess. The state space of is Go is around 10^170 possible board states compared to the 10^120 board states for Chess. Prior to recent deep learning models, AI Go agents were only able to play at the level of a human amateur.&lt;ref name=":1"&gt;{{Cite journal|last1=Silver|first1=David|last2=Huang|first2=Aja|last3=Maddison|first3=Chris J.|last4=Guez|first4=Arthur|last5=Sifre|first5=Laurent|last6=van den Driessche|first6=George|last7=Schrittwieser|first7=Julian|last8=Antonoglou|first8=Ioannis|last9=Panneershelvam|first9=Veda|date=January 2016|title=Mastering the game of Go with deep neural networks and tree search|journal=Nature|volume=529|issue=7587|pages=484–489|doi=10.1038/nature16961|pmid=26819042|issn=0028-0836|bibcode=2016Natur.529..484S|s2cid=515925}}&lt;/ref&gt;

==== AlphaGo ====
Google's 2015 [[AlphaGo]] was the first AI agent to beat a professional Go player.&lt;ref name=":1" /&gt; AlphaGo used a deep learning model to train the weights of a [[Monte Carlo tree search]] (MCTS). The deep learning model consisted of 2 ANN, a policy network to predict the probabilities of potential moves by opponents, and a value network to predict the win chance of a given state. The deep learning model allows the agent to explore potential game states more efficiently than a vanilla MCTS. The network were initially trained on games of humans players and then were further trained by games against itself.

==== AlphaGo Zero ====
[[AlphaGo Zero]], another implementation of AlphaGo, was able to train entirely by playing against itself. It was able to quickly train up to the capabilities of the previous agent.&lt;ref&gt;{{Cite journal|last1=Silver|first1=David|last2=Schrittwieser|first2=Julian|last3=Simonyan|first3=Karen|last4=Antonoglou|first4=Ioannis|last5=Huang|first5=Aja|last6=Guez|first6=Arthur|last7=Hubert|first7=Thomas|last8=Baker|first8=Lucas|last9=Lai|first9=Matthew|date=October 2017|title=Mastering the game of Go without human knowledge|journal=Nature|volume=550|issue=7676|pages=354–359|doi=10.1038/nature24270|pmid=29052630|issn=0028-0836|bibcode=2017Natur.550..354S|s2cid=205261034|url=http://discovery.ucl.ac.uk/10045895/1/agz_unformatted_nature.pdf}}&lt;/ref&gt;

=== ''StarCraft'' series ===
''[[StarCraft (video game)|StarCraft]]'' and its sequel ''[[StarCraft II: Wings of Liberty]]'' are [[real-time strategy]] (RTS) video games that have become popular environments for AI research. [[Blizzard]] and [[DeepMind]] have worked together to release a public ''StarCraft 2'' environment for AI research to be done on.&lt;ref&gt;{{cite arxiv|last1=Tsing|first1=Rodney|last2=Repp|first2=Jacob|last3=Ekermo|first3=Anders|last4=Lawrence|first4=David|last5=Brunasso|first5=Anthony|last6=Keet|first6=Paul|last7=Calderone|first7=Kevin|last8=Lillicrap|first8=Timothy|last9=Silver|first9=David|date=2017-08-16|title=StarCraft II: A New Challenge for Reinforcement Learning|eprint=1708.04782|class=cs.LG}}&lt;/ref&gt; Various deep learning methods have been tested on both games, though most agents usually have trouble outperforming the default AI with cheats enabled or skilled players of the game.&lt;ref name="Justesen 2019 1"/&gt;

==== Alphastar ====
[[AlphaStar (software)|Alphastar]] was the first AI agent to beat professional ''StarCraft 2'' players without any in-game advantages. The deep learning network of the agent initially received input from a simplified zoomed out version of the gamestate, but was later updated to play using a camera like other human players. The developers have not publicly released the code or architecture of their model, but have listed several state of the art machine learning techniques such as relational deep reinforcement learning, [[long short-term memory]], auto-regressive policy heads, pointer networks, and centralized value baseline.&lt;ref name=":2"&gt;{{Cite web|url=https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/|title=AlphaStar: Mastering the Real-Time Strategy Game StarCraft II|website=DeepMind|access-date=2019-06-04}}&lt;/ref&gt; Alphastar was initially trained with supervised learning, it watched replays of many human games in order to learn basic strategies. It then trained against different versions of itself and was improved through reinforcement learning. The final version was hugely successful, but only trained to play on a specific map in a protoss mirror matchup.

=== ''Dota 2'' ===
''[[Dota 2]]'' is a [[multiplayer online battle arena]] (MOBA) game. Like other complex games, traditional AI agents have not been able to compete on the same level as professional human player. The only widely published information on AI agents attempted on ''Dota 2'' is [[OpenAI]]'s deep learning Five agent.

==== OpenAI Five ====
[[OpenAI Five]] utilized separate [[Long short-term memory|LSTM]] networks to learn each hero. It trained using a [[reinforcement learning]] technique known as Proximal Policy Learning running on a system containing 256 [[Graphics processing unit|GPUs]] and 128,000 [[Multi-core processor|CPU cores]].&lt;ref name=":8" /&gt; Five trained for months, accumulating 180 years of game experience each day, before facing off with professional players.&lt;ref name=":3"&gt;{{Cite web|url=https://openai.com/five/|title=OpenAI Five|website=OpenAI|access-date=2019-06-04}}&lt;/ref&gt;&lt;ref name=":4"&gt;{{Cite web|url=https://openai.com/blog/how-to-train-your-openai-five/|title=How to Train Your OpenAI Five|date=2019-04-15|website=OpenAI|access-date=2019-06-04}}&lt;/ref&gt; It was eventually able to beat the 2018 ''Dota 2'' [[esports]] champion team in a 2019 series of games.

=== ''Planetary Annihilation'' ===
''[[Planetary Annihilation]]'' is a real-time strategy game which focuses on massive scale war. The developers use ANNs in their default AI agent.&lt;ref&gt;{{Cite web|url=https://www.engadget.com/2014/06/06/meet-the-computer-thats-learning-to-kill-and-the-man-who-progra/|title=Meet the computer that's learning to kill and the man who programmed the chaos|last=xavdematos|website=Engadget|access-date=2019-06-04}}&lt;/ref&gt;

=== Supreme Commander 2 ===
[[Supreme Commander 2]] is a [[real-time strategy]] (RTS) video game. 
The game uses [[Multilayer perceptron|Multilayer Perceprtrons]] (MLPs) to control a platoon’s reaction to encountered enemy units. Total of four MLPs are used, one for each platoon type: land, naval, bomber, and fighter.
&lt;ref&gt;http://www.gameaipro.com/GameAIPro/GameAIPro_Chapter30_Using_Neural_Networks_to_Control_Agent_Threat_Response.pdf&lt;/ref&gt;

=== Generalized games ===
There have been attempts to make machine learning agents that are able to play more than one game. These "general" gaming agents are trained to understand games based on shared properties between them.

==== AlphaZero ====
[[AlphaZero]] is a modified version of [[AlphaGo Zero]] which is able to play [[Shogi]], [[chess]], and [[Go (game)|Go]]. The modified agent starts with only basic rules of the game, and is also trained entirely through self-learning. DeepMind was able to train this generalized agent to be competitive with previous versions of itself on Go, as well as top agents in the other two games.&lt;ref name=":0"/&gt;

=== Strengths and weaknesses of deep learning agents ===
Machine learning agents are often not covered in many game design courses. Previous use of machine learning agents in games may not have been very practical, as even the 2015 version of AlphaGo took hundreds of CPUs and GPUs to train to a strong level.&lt;ref name=":0" /&gt; This potentially limits the creation of highly effective deep learning agents to large corporations or extremely wealthy individuals. The extensive training time of neural network based approaches can also take weeks on these powerful machines.&lt;ref name=":2" /&gt;

The problem of effectively training ANN based models extends beyond powerful hardware environments; finding a good way to represent data and learn meaningful things from it is also often a difficult problem. ANN models often overfit to very specific data and perform poorly in more generalized cases. AlphaStar shows this weakness, despite being able to beat professional players, it is only able to do so on a single map when playing a mirror protoss matchup.&lt;ref name=":2" /&gt; OpenAI Five also shows this weakness, it was only able to beat professional player when facing a very limited hero pool out of the entire game.&lt;ref name=":4" /&gt; This example show how difficult it can be to train a deep learning agent to perform in more generalized situations.

Machine learning agents have shown great success in a variety of different games.&lt;ref name=":3" /&gt;&lt;ref name=":0" /&gt;&lt;ref name=":2" /&gt; However, agents that are too competent also risk making games too difficult for new or casual players. Research has shown that challenge that is too far above a player's skill level will ruin lower player enjoyment.&lt;ref&gt;{{Cite journal|last1=Sweetser|first1=Penelope|last2=Wyeth|first2=Peta|date=2005-07-01|title=GameFlow|journal=Computers in Entertainment|volume=3|issue=3|pages=3|doi=10.1145/1077246.1077253|s2cid=2669730|issn=1544-3574}}&lt;/ref&gt; These highly trained agents are likely only desirable against very skilled human players who have many of hours of experience in a given game. Given these factors, highly effective deep learning agents are likely only a desired choice in games that have a large competitive scene, where they can function as an alternative practice option to a skilled human player.

== Computer vision-based players ==
[[Computer vision]] focuses on training computers to gain a high-level understanding of digital images or videos. Many computer vision techniques also incorporate forms of machine learning, and have been applied on various video games. This application of computer vision focuses on interpreting game events using visual data. In some cases, artificial intelligence agents have used [[model-free]] techniques to learn to play games without any direct connection to internal game logic, solely using video data as input.

=== ''Pong'' ===
[[Andrej Karpathy]] has demonstrated that relatively trivial neural network with just one hidden layer is capable of being trained to play ''[[Pong]]'' based on screen data alone.&lt;ref name=IBMdeveloper/&gt;&lt;ref&gt;{{Cite web|url=http://karpathy.github.io/2016/05/31/rl/|title=Deep Reinforcement Learning: Pong from Pixels|website=karpathy.github.io|access-date=2020-02-03}}&lt;/ref&gt;

=== Atari games ===
In 2013, a team at [[DeepMind]] demonstrated the use of [[deep Q-learning]] to play a variety of [[Atari]] video games &amp;mdash; ''[[Beamrider]]'', ''[[Breakout (video game)|Breakout]]'', ''[[Enduro (video game)|Enduro]]'', ''[[Pong]]'', ''[[Q*bert]]'', ''[[Seaquest (video game)|Seaquest]]'', and ''[[Space Invaders]]'' &amp;mdash; from screen data.&lt;ref&gt;{{cite arxiv|last1=Mnih|first1=Volodymyr|last2=Kavukcuoglu|first2=Koray|last3=Silver|first3=David|last4=Graves|first4=Alex|last5=Antonoglou|first5=Ioannis|last6=Wierstra|first6=Daan|last7=Riedmiller|first7=Martin|date=2013-12-19|title=Playing Atari with Deep Reinforcement Learning|eprint=1312.5602|class=cs.LG}}&lt;/ref&gt; The team expanded their work to create a learning algorithm called MuZero that was able the "learn" the rules and develop winning strategies for over 50 different Atari games based on screen data.&lt;ref&gt;{{cite web | url = https://www.engadget.com/deepmind-muzero-160024950.html | title = DeepMind's latest AI can master games without being told their rules | first = Igor | last = Bonifacic | date =December 23, 2020 | access-date = December 23, 2020 | work = [[Engadget]] }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | title = Mastering Atari, Go, chess and shogi by planning with a learned model | doi = 10.1038/s41586-020-03051-4 | journal = [[Nature (journal)|Nature]] | volume =  588 | pages = 604–609 | year = 2020 | first1= Julian |last1=Schrittwieser| first2= Ioannis |last2=Antonoglou| first3= Thomas |last3=Hubert| first4= Karen |last4=Simonyan| first5= Laurent |last5=Sifre| first6= Simon |last6=Schmitt| first7= Arthur |last7=Guez| first8= Edward |last8=Lockhart | first9=  Demis |last9=Hassabis | first10= Thore |last10=Graepel | first11= Timothy |last11=Lillicrap | first12 = David |last12=Silver | arxiv= 1911.08265 }}&lt;/ref&gt;

=== ''Doom'' ===
''[[Doom (1993 video game)|Doom]]'' (1993) is a first-person shooter (FPS) game. Student researchers from [[Carnegie Mellon University]] used computer vision techniques to create an agent that could play the game using only image pixel input from the game. The students used [[convolutional neural network]] (CNN) layers to interpret incoming image data and output valid information to a [[recurrent neural network]] which was responsible for outputting game moves.&lt;ref&gt;{{Cite journal|last1=Lample|first1=Guillaume|last2=Chaplot|first2=Devendra Singh|date=2017|title=Playing FPS Games with Deep Reinforcement Learning|url=http://dl.acm.org/citation.cfm?id=3298483.3298548|journal=Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence|series=AAAI'17|location=San Francisco, California, USA|publisher=AAAI Press|pages=2140–2146|bibcode=2016arXiv160905521L|arxiv=1609.05521}}&lt;/ref&gt;

=== ''Super Mario'' ===
Other uses of vision-based [[deep learning]] techniques for playing games have included playing ''[[Super Mario Bros.]]'' only using image input, using [[deep Q-learning]] for training.&lt;ref name=IBMdeveloper&gt;{{Cite web|url=https://developer.ibm.com/technologies/artificial-intelligence/articles/machine-learning-and-gaming/|title=Machine learning and gaming|website=IBM Developer|language=en-US|access-date=2020-02-03|first=M. Tim|last=Jones|date=June 7, 2019}}&lt;/ref&gt;

== Machine learning for procedural content generation in games ==
Machine learning has seen research for use in content recommendation and generation. [[Procedural generation|Procedural content generation]] is the process of creating data algorithmically rather than manually. This type of content is used to add replayability to games without relying on constant additions by human developers. PCG has been used in various games for different types of content generation, examples of which include weapons in ''[[Borderlands 2]]'',&lt;ref&gt;{{Cite web|url=https://www.eurogamer.net/articles/2012-07-16-how-many-weapons-are-in-borderlands-2|title=How many weapons are in Borderlands 2?|last=Yin-Poole|first=Wesley|date=2012-07-16|website=Eurogamer|access-date=2019-06-04}}&lt;/ref&gt; all world layouts in [[Minecraft]]&lt;ref&gt;{{Cite web|url=https://notch.tumblr.com/post/3746989361/terrain-generation-part-1|title=Terrain generation, Part 1|website=The Word of Notch|access-date=2019-06-04}}&lt;/ref&gt; and entire universes in ''[[No Man's Sky]]''.&lt;ref&gt;{{Cite web|url=https://www.technologyreview.com/s/529136/no-mans-sky-a-vast-game-crafted-by-algorithms/|title=A Science Fictional Universe Created by Algorithms|last=Parkin|first=Simon|website=MIT Technology Review|access-date=2019-06-04}}&lt;/ref&gt; Common approaches to PCG include techniques that involve [[Formal grammar|grammars]], [[Search algorithm|search-based algorithms]], and [[logic programming]].&lt;ref&gt;{{Citation|last1=Togelius|first1=Julian|title=Introduction|date=2016|work=Procedural Content Generation in Games|pages=1–15|publisher=Springer International Publishing|isbn=9783319427140|last2=Shaker|first2=Noor|last3=Nelson|first3=Mark J.|doi=10.1007/978-3-319-42716-4_1}}&lt;/ref&gt; These approaches require humans to manually define the range of content possible, meaning that a human developer decides what features make up a valid piece of generated content. Machine learning is theoretically capable of learning these features when given examples to train off of, thus greatly reducing the complicated step of developers specifying the details of content design.&lt;ref name=":5"&gt;{{Cite journal|last1=Summerville|first1=Adam|last2=Snodgrass|first2=Sam|last3=Guzdial|first3=Matthew|last4=Holmgard|first4=Christoffer|last5=Hoover|first5=Amy K.|last6=Isaksen|first6=Aaron|last7=Nealen|first7=Andy|last8=Togelius|first8=Julian|date=September 2018|title=Procedural Content Generation via Machine Learning (PCGML)|journal=IEEE Transactions on Games|volume=10|issue=3|pages=257–270|doi=10.1109/tg.2018.2846639|issn=2475-1502|arxiv=1702.00539|s2cid=9950600}}&lt;/ref&gt; Machine learning techniques used for content generation include [[Long short-term memory|Long Short-Term Memory]] (LSTM) [[Recurrent neural network|Recurrent Neural Networks]] (RNN), [[Generative adversarial network|Generative Adversarial networks]] (GAN), and [[K-means clustering]]. Not all of these techniques make use of ANNs, but the rapid development of deep learning has greatly increased the potential of techniques that do.&lt;ref name=":5" /&gt;

=== ''Galactic Arms Race'' ===
''[[Galactic Arms Race]]'' is a space shooter video game that uses [[neuroevolution]] powered PCG to generate unique weapons for the player. This game was a finalist in the 2010 Indie Game Challenge and its related research paper won the Best Paper Award at the 2009 IEEE Conference on Computational Intelligence and Games. The developers use a form of neuroevolution called cgNEAT to generate new content based on each player's personal preferences.&lt;ref&gt;{{Cite journal|last1=Hastings|first1=Erin J.|last2=Guha|first2=Ratan K.|last3=Stanley|first3=Kenneth O.|date=September 2009|title=Evolving content in the Galactic Arms Race video game|journal=2009 IEEE Symposium on Computational Intelligence and Games|pages=241–248|publisher=IEEE|doi=10.1109/cig.2009.5286468|isbn=9781424448142|s2cid=16598064|url=http://eplex.cs.ucf.edu/papers/hastings_cig09.pdf}}&lt;/ref&gt;

Each generated item is represented by a special ANN known as a [[Compositional pattern-producing network|Compositional Pattern Producing Network]] (CPPNs). During the evolutionary phase of the game cgNEAT calculates the fitness of current items based on player usage and other gameplay metrics, this fitness score is then used decide which CPPNs will reproduce to create a new item. The ending result is the generation of new weapon effects based on the player's preference.

=== ''Super Mario Bros.'' ===
''[[Super Mario Bros.]]'' has been used by several researchers to simulate PCG level creation. Various attempts having used different methods. A version in 2014 used n-grams to generate levels similar to the ones it trained on, which was later improved by making use of MCTS to guide generation.&lt;ref&gt;{{Cite web|url=https://www.aaai.org/ocs/index.php/AIIDE/AIIDE15/paper/view/11569|title=MCMCTS PCG 4 SMB: Monte Carlo Tree Search to Guide Platformer Level Generation|last=Summerville|first=Adam|website=www.aaai.org|access-date=2019-06-04}}&lt;/ref&gt; These generations were often not optimal when taking gameplay metrics such as player movement into account, a separate research project in 2017 tried to resolve this problem by generating levels based on player movement using Markov Chains.&lt;ref&gt;{{Cite journal|last1=Snodgrass|first1=Sam|last2=Ontañón|first2=Santiago|date=August 2017|title=Player Movement Models for Video Game Level Generation|journal=Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence|pages=757–763|location=California|publisher=International Joint Conferences on Artificial Intelligence Organization|doi=10.24963/ijcai.2017/105|isbn=9780999241103|doi-access=free}}&lt;/ref&gt; These projects were not subjected to human testing and may not meet human playability standards.

=== ''The Legend of Zelda'' ===
PCG level creation for ''[[The Legend of Zelda (video game)|The Legend of Zelda]]'' has been attempted by researchers at the University of California, Santa Cruz. This attempt made use of a Bayesian Network to learn high level knowledge from existing levels, while Principal Component Analysis (PCA) was used to represent the different low level features of these levels.&lt;ref&gt;{{Cite web|url=https://www.aaai.org/ocs/index.php/AIIDE/AIIDE15/paper/view/11570|title=Sampling Hyrule: Multi-Technique Probabilistic Level Generation for Action Role Playing Games|last=Summerville|first=James|website=www.aaai.org|access-date=2019-06-04}}&lt;/ref&gt; The researchers used PCA to compare generated levels to human made levels and found that they were considered very similar. This test did not include playability or human testing of the generated levels.

== Music generation ==
Music is often seen in video games and can be a crucial element for influencing the mood of different situations and story points. Machine learning has seen use in the experimental field of music generation; it is uniquely suited to processing raw [[unstructured data]] and forming high level representations that could be applied to the diverse field of music.&lt;ref name=":6"&gt;{{cite arxiv|last1=Pachet|first1=François-David|last2=Hadjeres|first2=Gaëtan|last3=Briot|first3=Jean-Pierre|date=2017-09-05|title=Deep Learning Techniques for Music Generation - A Survey|eprint=1709.01620|class=cs.SD}}&lt;/ref&gt; Most attempted methods have involved the use of ANN in some form. Methods include the use of basic [[feedforward neural network]]s, [[autoencoder]]s, [[Restricted Boltzmann machine|restricted boltzmann machines]], [[recurrent neural network]]s, [[convolutional neural network]]s, [[generative adversarial network]]s (GANs), and compound architectures that use multiple methods.&lt;ref name=":6" /&gt;

=== VRAE video game melody symbolic music generation system ===
The 2014 research paper on "Variational Recurrent Auto-Encoders" attempted to generate music based on songs from 8 different video games. This project is one of the few conducted purely on video game music. The neural network in the project was able to generate data that was very similar to the data of the games it trained off of.&lt;ref&gt;{{cite arxiv|last1=van Amersfoort|first1=Joost R.|last2=Fabius|first2=Otto|date=2014-12-20|title=Variational Recurrent Auto-Encoders|eprint=1412.6581|class=stat.ML}}&lt;/ref&gt; The generated data did not translate into good quality music.

== References ==
{{Reflist}}

== External links ==

[[Category:Machine learning]]
[[Category:Game artificial intelligence]]</text>
      <sha1>qryojrolwbbs68ohilunbtwcbdppaqx</sha1>
    </revision>
  </page>
  <page>
    <title>Category:Reinforcement learning</title>
    <ns>14</ns>
    <id>62022953</id>
    <revision>
      <id>920502251</id>
      <timestamp>2019-10-10T05:26:21Z</timestamp>
      <contributor>
        <username>Gufosowa</username>
        <id>21517019</id>
      </contributor>
      <comment>Created</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="220" xml:space="preserve">[[Reinforcement learning]] (RL) is an area of machine learning concerned with how software agents ought to take actions in an environment so as to maximize some notion of cumulative reward.

[[Category:Machine learning]]</text>
      <sha1>dr8ulyvmg4b285vx5ligwkrfkij6s79</sha1>
    </revision>
  </page>
  <page>
    <title>Knowledge distillation</title>
    <ns>0</ns>
    <id>62295363</id>
    <revision>
      <id>1005517083</id>
      <parentid>1005420183</parentid>
      <timestamp>2021-02-08T02:19:07Z</timestamp>
      <contributor>
        <ip>108.21.152.144</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="10970" xml:space="preserve">In [[machine learning]], '''knowledge distillation''' is the process of transferring knowledge from a large [[statistical model|model]] to a smaller one. While large models (such as very [[deep neural network]]s or [[Ensemble averaging (machine learning)|ensemble]]s of many models) have higher knowledge capacity than small models, this capacity might not be fully utilized.  It can be computationally just as expensive to evaluate a model even if it utilizes little of its knowledge capacity.  Knowledge distillation transfers knowledge from a large model to a smaller model without loss of [[Statistical model validation|validity]].  As smaller models are less expensive to evaluate, they can be deployed on less powerful hardware (such as a [[mobile device]]).&lt;ref name="Hinton"&gt;Hinton et al. (2015)&lt;/ref&gt;

Knowledge distillation has been successfully used in several applications of machine learning such as [[object detection]],&lt;ref&gt;Chen et al. (2017)&lt;/ref&gt; [[acoustic model]]s,&lt;ref&gt;Asami et al. (2017)&lt;/ref&gt; and [[natural language processing]].&lt;ref&gt;Cui et al. (2017)&lt;/ref&gt;&lt;ref&gt;Yu et al. (2017)&lt;/ref&gt;
Recently, it has also been introduced to graph neural networks applicable to non-grid data. &lt;ref&gt;Yang et al. (2020)&lt;/ref&gt;

== The concept of distillation ==

Transferring the knowledge from a large to a small model needs to somehow teach to the latter without loss of validity. If both models are trained on the same data, the small model may have insufficient capacity to learn a [[concision|concise knowledge representation]] given the same computational resources and same data as the large model.  However, some information about a concise knowledge representation is encoded in the [[pseudolikelihood|pseudolikelihoods]] assigned to its output: when a model correctly predicts a class, it assigns a large value to the output variable corresponding to such class, and smaller values to the other output variables. The distribution of values among the outputs for a record provides information on how the large model represents knowledge.  Therefore the goal of economical deployment of a valid model can be achieved by training only the large model on the data, exploiting its better ability to learn concise knowledge representations, and then distilling such knowledge into the smaller model, that would not be able to learn it on its own, by training it to learn the [[Soft-in soft-out decoder|soft output]] of the large model.&lt;ref name="Hinton"&gt;Hinton et al. (2015)&lt;/ref&gt;

Model compression, a methodology to compress the knowledge of multiple models into a single [[neural network]], was introduced in 2006. Compression was achieved by training a smaller model on large amounts of pseudo-data labelled by a higher-performing ensemble, optimising to match the [[logit]] of the compressed model to the logit of the ensemble.&lt;ref name="Buciluǎ"&gt;Buciluǎ et al. (2006)&lt;/ref&gt; Knowledge distillation is a generalisation of such approach, introduced by [[Geoffrey Hinton]] et al. in 2015, in a [[preprint]] that formulated the concept and showed some results achieved in the task of [[image classification]].&lt;ref name="Hinton"&gt;Hinton et al. (2015)&lt;/ref&gt;

== Formulation ==

Given a large model as a function of the vector variable &lt;math&gt;\mathbf{x}&lt;/math&gt;, trained for a specific [[statistical classification|classification]] task, typically the final layer of the network is a [[softmax function|softmax]] in the form
:&lt;math&gt;
y_i(\mathbf{x}|t) = \frac{e^{\frac{z_i(\mathbf{x})}{t}}}{\sum_j e^{\frac{z_j(\mathbf{x})}{t}}}
&lt;/math&gt;
where &lt;math&gt;t&lt;/math&gt; is a parameter called ''temperature'', that for a standard softmax is normally set to 1. The softmax operator converts the [[logit]] values &lt;math&gt;z_i(\mathbf{x})&lt;/math&gt; to pseudo-probabilities, and higher values of temperature have the effect of generating a softer distribution of pseudo-probabilities among the output classes. Knowledge distillation consists of training a smaller network, called the ''distilled model'', on a [[dataset]] called transfer set (different than the dataset used to train the large model) using the [[cross entropy]] as [[loss function]] between the output of the distilled model &lt;math&gt;\mathbf{y}(\mathbf{x}|t)&lt;/math&gt; and the output &lt;math&gt;\hat{\mathbf{y}}(\mathbf{x}|t)&lt;/math&gt; produced by the large model on the same record (or the average of the individual outputs, if the large model is an ensemble), using a high value of softmax temperature &lt;math&gt;t&lt;/math&gt; for both models&lt;ref name="Hinton" /&gt;
:&lt;math&gt;
E(\mathbf{x}|t) = -\sum_i \hat{y}_i(\mathbf{x}|t) \log y_i(\mathbf{x}|t) .
&lt;/math&gt;
In this context, a high temperature increases the entropy of the output, and therefore provides more information to learn for the distilled model compared to hard targets, at the same time reducing the variance of the [[gradient]] between different records and therefore allowing higher [[learning rate]]s.&lt;ref name="Hinton" /&gt;

If ground truth is available for the transfer set, the process can be strengthened by adding to the loss the cross-entropy between the output of the distilled model (computed with &lt;math&gt;t = 1&lt;/math&gt;) and the known label &lt;math&gt;\bar{y}&lt;/math&gt;
:&lt;math&gt;
E(\mathbf{x}|t) = -t^2 \sum_i \hat{y}_i(\mathbf{x}|t) \log y_i(\mathbf{x}|t) - \sum_i \bar{y}_i \log y_i(\mathbf{x}|1)
&lt;/math&gt;
where the component of the loss with respect to the large model is weighted by a factor of &lt;math&gt;t^2&lt;/math&gt; since, as the temperature increases, the gradient of the loss with respect to the model weights scales by a factor of &lt;math&gt;\frac{1}{t^2}&lt;/math&gt;.&lt;ref name="Hinton" /&gt;

== Relationship with model compression ==

Under the assumption that the logits have zero [[mean]], it is possible to show that model compression is a special case of knowledge distillation. The gradient of the knowledge distillation loss &lt;math&gt;E&lt;/math&gt; with respect to the logit of the distilled model &lt;math&gt;z_i&lt;/math&gt; is given by
:&lt;math&gt;
\begin{align}
    \frac{\partial}{\partial z_i} E
        &amp;= -\frac{\partial}{\partial z_i} \sum_j \hat{y}_j \log y_j \\
        &amp;= -\hat{y}_i \frac{1}{y_i} \frac{\partial}{\partial z_i} y_i \\
        &amp;= -\hat{y}_i \frac{1}{y_i} \frac{\partial}{\partial z_i} \frac{e^{\frac{z_i}{t}}}{\sum_j e^{\frac{z_j}{t}}} \\
        &amp;= -\hat{y}_i \frac{1}{y_i}
        \left(
            \frac{\frac{1}{t} e^{\frac{z_i}{t}} \sum_j e^{\frac{z_j}{t}} - \frac{1}{t} \left( e^{\frac{z_i}{t}} \right)^2}
                 {\left( \sum_j e^{\frac{z_j}{t}} \right)^2}
        \right) \\
        &amp;= -\hat{y}_i \frac{1}{y_i} \left( \frac{y_i}{t} - \frac{y_i^2}{t} \right) \\
        &amp;= \frac{1}{t} \left( y_i - \hat{y}_i \right) \\
        &amp;= \frac{1}{t} \left( \frac{e^{\frac{z_i}{t}}}{\sum_j e^{\frac{z_j}{t}}} - \frac{e^{\frac{\hat{z}_i}{t}}}{\sum_j e^{\frac{\hat{z}_j}{t}}} \right) \\
\end{align}
&lt;/math&gt;
where &lt;math&gt;\hat{z}_i&lt;/math&gt; are the logits of the large model. For large values of &lt;math&gt;t&lt;/math&gt; this can be approximated as
:&lt;math&gt;
\frac{1}{t}
\left(
    \frac{1 + \frac{z_i}{t}}{N + \sum_j \frac{z_j}{t}} -
    \frac{1 + \frac{\hat{z}_i}{t}}{N + \sum_j \frac{\hat{z}_j}{t}}
\right)
&lt;/math&gt;
and under the zero-mean hypothesis &lt;math&gt;\sum_j z_j = \sum_j \hat{z}_j = 0&lt;/math&gt; it becomes &lt;math&gt; \frac{z_i - \hat{z}_i}{NT^2} &lt;/math&gt;, which is the derivative of &lt;math&gt;\frac{1}{2} \left( z_i - \hat{z}_i \right)^2&lt;/math&gt;, i.e. the loss is equivalent to matching the logits of the two models, as done in model compression.&lt;ref name="Hinton" /&gt;

== Sample Weighting based Knowledge Transfer ==

Other than modifying the target, recently sample reweighting based approaches have been proposed to transfer knowledge &lt;ref&gt;Dhurandhar et al. (2018)&lt;/ref&gt; &lt;ref&gt;Dhurandhar et al. (2020)&lt;/ref&gt;. These have been shown to perform better than Knowledge Distillation particularly when the smaller model is much smaller than the larger one.

== References ==
&lt;references /&gt;
* {{cite conference|last1=Asami|first1=Taichi|first2=Ryo|last2=Masumura|first3=Yoshikazu|last3=Yamaguchi|first4=Hirokazu|last4=Masataki|first5=Yushi|last5=Aono|title=Domain adaptation of DNN acoustic models using knowledge distillation|conference=IEEE International Conference on Acoustics, Speech and Signal Processing|pages=5185–5189|year=2017}}
* {{cite conference|title=Model compression|book-title=Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining|year=2006|last1=Buciluǎ|first1=Cristian|last2=Caruana|first2=Rich|last3=Niculescu-Mizil|first3=Alexandru}}
* {{cite journal|last1=Chen|first1=Guobin|first2=Wongun|last2=Choi|first3=Xiang|last3=Yu|first4=Tony|last4=Han|first5=Manmohan|last5=Chandraker|title=Learning efficient object detection models with knowledge distillation|journal=Advances in Neural Information Processing Systems|pages=742–751|year=2017}}
* {{cite conference|last1=Cui|first1=Jia|first2=Brian|last2=Kingsbury|first3=Bhuvana|last3=Ramabhadran|first4=George|last4=Saon|first5=Tom|last5=Sercu|first6=Kartik|last6=Audhkhasi|first7=Abhinav|last7=Sethy|first8=Markus|last8=Nussbaum-Thom|first9=Andrew|last9=Rosenberg|title=Knowledge distillation across ensembles of multilingual models for low-resource languages|conference=IEEE International Conference on Acoustics, Speech and Signal Processing|pages=4825–4829|year=2017}}
* {{cite arXiv|title=Distilling the knowledge in a neural network|year=2015|eprint=1503.02531|last1=Hinton|first1=Geoffrey|last2=Vinyals|first2=Oriol|last3=Dean|first3=Jeff|class=stat.ML}}
* {{cite journal|last1=Yu|first1=Ruichi|first2=Ang|last2=Li|first3=Vlad I.|last3=Morariu|first4=Larry S.|last4=Davis|title=Visual relationship detection with internal and external linguistic knowledge distillation|journal=Proceedings of the IEEE International Conference on Computer Vision|pages=1974–1982|year=2017|arxiv=1707.09423|bibcode=2017arXiv170709423Y}}
* {{cite journal|last1=Yang|first1=Yiding|first2=Qiu|last2=Jiayan|first3=Song|last3=Mingli|first4=Tao|last4=Dacheng|first5=Wang|last5=Xinchao|title=Distilling Knowledge from Graph Convolutional Networks|journal=Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition|pages=7072-7081|year=2020|arxiv=2003.10477|bibcode=2020arXiv200310477Y}}
* {{cite conference|last1=Dhurandhar|first1=Amit|first2=Karthikeyan|last2=Shanmugam|first3=Ronny|last3=Luss|first4=Peder|last4=Olsen|title=Improving Simple Models with Confidence Profiles|conference=Advances in Neural Information Processing Systems|pages=10296--10306|year=2018}}
* {{cite conference|last1=Dhurandhar|first1=Amit|first2=Karthikeyan|last2=Shanmugam|first3=Ronny|last3=Luss|title=Enhancing Simple Models by Exploiting What they Already Know|conference=Intl. Conference on Machine Learning|pages=2525-2534|year=2020}}

== External links ==
* [https://ai.google/research/pubs/pub44873 Distilling the knowledge in a neural network – Google AI]
* [https://medium.com/neuralmachine/knowledge-distillation-dc241d7c2322 Knowledge distillation]

[[Category:Machine learning]]
[[Category:Deep learning]]</text>
      <sha1>pdbxvfhq2d0nlrp3325krosvj60xtlb</sha1>
    </revision>
  </page>
  <page>
    <title>Multi-agent learning</title>
    <ns>0</ns>
    <id>62285602</id>
    <revision>
      <id>1002461037</id>
      <parentid>977303380</parentid>
      <timestamp>2021-01-24T15:56:01Z</timestamp>
      <contributor>
        <username>Anair13</username>
        <id>12314876</id>
      </contributor>
      <minor/>
      <comment>typo "stationary"</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1768" xml:space="preserve">'''Multi-agent learning''' is the use of [[machine learning]] in a [[multi-agent system]].&lt;ref&gt;{{citation|last1=Albrecht|first1=Stefano|title=IJCAI-17 conference|url=http://www.cs.utexas.edu/~larg/ijcai17_tutorial/multiagent_learning.pdf|year=2017|contribution=Multiagent Learning: Foundations and Recent Trends. Tutorial|last2=Stone|first2=Peter}}&lt;/ref&gt; Typically, agents improve their decisions via experience. In particular, an agent has to learn how to coordinate with the other agents.

== Overview ==
According to an article by Shoham et al. in 2007, it is difficult to pinpoint all relevant articles in the domain.&lt;ref&gt;{{Cite journal|last1=Shoham|first1=Yoav|last2=Powers|first2=Rob|last3=Grenager|first3=Trond|date=2007-05-01|title=If multi-agent learning is the answer, what is the question?|journal=Artificial Intelligence|series=Foundations of Multi-Agent Learning|volume=171|issue=7|pages=365–377|doi=10.1016/j.artint.2006.02.006|issn=0004-3702|url=http://www.dklevine.com/archive/refs4122247000000001156.pdf}}&lt;/ref&gt; There are some inherent difficulties about multi-agent deep reinforcement learning.&lt;ref&gt;{{Cite journal|last1=Hernandez-Leal|first1=Pablo|last2=Kartal|first2=Bilal|last3=Taylor|first3=Matthew E.|date=2019-11-01|title=A survey and critique of multiagent deep reinforcement learning|journal=Autonomous Agents and Multi-Agent Systems|language=en|volume=33|issue=6|pages=750–797|doi=10.1007/s10458-019-09421-1|issn=1573-7454|arxiv=1810.05587|s2cid=52981002}}&lt;/ref&gt; The environment is not stationary anymore, thus the [[Markov property]] is violated: transitions and rewards does not only depend on the current state of an agent.

==References==
{{reflist}}

[[Category:Multi-agent systems]]
[[Category:Machine learning]]


{{Compu-ai-stub}}</text>
      <sha1>qto3kqlhn36p5tufyzp7d6ttzyrr06n</sha1>
    </revision>
  </page>
  <page>
    <title>Fairness (machine learning)</title>
    <ns>0</ns>
    <id>62683332</id>
    <revision>
      <id>1000936665</id>
      <parentid>996695168</parentid>
      <timestamp>2021-01-17T12:49:50Z</timestamp>
      <contributor>
        <ip>91.102.42.8</ip>
      </contributor>
      <comment>Typo fixing: ti -&gt; it</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="35976" xml:space="preserve">{{Multiple issues|
{{Manual|date=December 2019}}
{{Technical|date=December 2019}}
{{Rough translation|1=Spanish|date=December 2019}}
}}
In [[machine learning]], a given [[algorithm]] is said to be '''fair''', or to have '''fairness''', if its results are independent of given [[Dependent and independent variables|variables]], especially those considered sensitive, such as the traits of individuals which should not correlate with the outcome (i.e. gender, ethnicity, sexual orientation, disability, etc.).

== Context ==

Research about fairness in machine learning is a relatively recent topic. Most of the articles about it have been written in the last three years.&lt;ref name="Articles"&gt;[https://fairmlclass.github.io/1.html#/4 ''Moritz Hardt, Berkeley'']. Retrieved 18 December 2019&lt;/ref&gt; Some of the most important facts in this topic are the following:
* In 2018, IBM introduced AI Fairness 360, a [[Python (programming language)|Python]] library with several algorithms to reduce software [[bias]] and increase its fairness.&lt;ref&gt;{{cite web| title=IBM AI Fairness 360 open source toolkit adds new functionalities |url=http://www.techrepublic.com/google-amp/article/ibm-ai-fairness-360-open-source-toolkit-adds-new-functionalities/|publisher=Tech Republic}}&lt;/ref&gt;&lt;ref name="IBM"&gt;[https://aif360.mybluemix.net/ ''IBM AI Fairness 360'']. Retrieved 18 December 2019&lt;/ref&gt;
* In 2018, Facebook made public their use of a tool, Fairness Flow, to detect bias in their AI. However, the [[source code]] of the tool is not accessible, and it is not known whether it really corrects bias.&lt;ref name="Facebook"&gt;[https://qz.com/1268520/facebook-says-it-has-a-tool-to-detect-bias-in-its-artificial-intelligence/ ''Fairness Flow el detector de sesgos de Facebook'']. Retrieved 28 December 2019&lt;/ref&gt;
* In 2019, Google published a set of tools in [[GitHub]] to study the effects of fairness in the long run.&lt;ref name="Google"&gt;[https://github.com/google/ml-fairness-gym ''ML-Fairness gym'']. Retrieved 18 December 2019&lt;/ref&gt;

==Controversies==
The algorithms used for assuring fairness are still being improved. However, the main progress in this area is that some big corporations are realizing the impact that reducing [[algorithmic bias]] could have on society.

An example of the controversial use of an algorithm is the way that Facebook allocates news articles to users, which some people have complained can introduce political bias. 
Before elections, some candidates have tried to use Facebook for campaigning purposes, which can become a hotly disputed area.

==Transparency of algorithms==
Many people have complained that algorithms often cannot be inspected, to ensure that they are operating fairly, which cannot disadvantage some users.

But many commercial companies prefer to not reveal the details of the algorithms that they use, as they frequently state that it could assist rival companies to benefit from their technologies.

==Implications==
If an algorithm is not operating properly the effects on people can be significant and long-lasting, such as regarding education or employment opportunities, and access to financial credit services.

==International standards==
Because algorithms are constantly changing and are often proprietary, there are few recognised standards for their construction or operation.

Eventually, algorithms may become more highly regulated, but currently, there is little public oversight for them.

== Fairness criteria in classification problems&lt;ref name="Barocas"&gt;Solon Barocas; Moritz Hardt; Arvind Narayanan, [http://www.fairmlbook.org ''Fairness and Machine Learning'']. Retrieved 15 December 2019.&lt;/ref&gt; ==

In [[Statistical classification|classification]] problems, an algorithm learns a function to predict a discrete characteristic &lt;math display="inline"&gt; Y &lt;/math&gt;, the target variable, from known characteristics &lt;math display="inline"&gt; X &lt;/math&gt;. We model &lt;math display="inline"&gt; A &lt;/math&gt; as a discrete [[random variable]] which encodes some characteristics contained or implicitly encoded in &lt;math display="inline"&gt; X &lt;/math&gt; that we consider as sensitive characteristics (gender, ethnicity, sexual orientation, etc.). We finally denote by &lt;math display="inline"&gt; R &lt;/math&gt; the prediction of the [[Statistical classification|classifier]].
Now let us define three main criteria to evaluate if a given classifier is fair, that is if its predictions are not influenced by some of these sensitive variables.

=== Independence ===

We say the [[random variable]]s &lt;math display="inline"&gt;(R,A)&lt;/math&gt; satisfy '''independence''' if the sensitive characteristics &lt;math display="inline"&gt; A &lt;/math&gt; are [[Independence (probability theory)|statistically independent]] to the prediction &lt;math display="inline"&gt; R &lt;/math&gt;, and we write &lt;math display="inline"&gt; R \bot A &lt;/math&gt;.

We can also express this notion with the following formula:
&lt;math display="block"&gt; P(R = r | A = a) = P(R = r | A = b) \quad \forall r \in R \quad \forall a,b \in A &lt;/math&gt;
This means that the [[probability theory|probability]] of being classified by the algorithm in each of the groups is equal for two individuals with different sensitive characteristics.

Yet another equivalent expression for independence can be given using the concept of [[mutual information]] between [[random variables]], defined as
&lt;math display="block"&gt; I(X,Y) = H(X) + H(Y) - H(X,Y) &lt;/math&gt;
In this formula, &lt;math display="inline"&gt; H &lt;/math&gt; of the [[random variable]]. Then &lt;math display="inline"&gt; (R,A) &lt;/math&gt; satisfy independence if &lt;math display="inline"&gt; H(R,A) = 0 &lt;/math&gt;.

A possible [[relaxation (approximation)|relaxation]] of the independence nce definition include introducing a positive [[Slack variable|slack]] &lt;math display="inline&gt; \epsilon &gt; 0 &lt;/math&gt; and is given by the formula:
&lt;math diplay="block"&gt; P(R = r | A = a) \geq P(R = r | A = b) - \epsilon \quad \forall r \in R \quad \forall a,b \in A &lt;/math&gt;

Finally, another possible [[Relaxation (approximation)|relaxation]] is to require &lt;math display="inline"&gt; I(R,A) \leq \epsilon &lt;/math&gt;.

=== Separation ===

We say the [[random variable]]s &lt;math display="inline"&gt;(R,A,Y)&lt;/math&gt; satisfy '''[[separation of concerns|separation]]''' if the sensitive characteristics &lt;math display="inline"&gt; A &lt;/math&gt; are [[Independence (probability theory)|statistically independent]] to the prediction &lt;math display="inline"&gt; R &lt;/math&gt; given the target value &lt;math display="inline"&gt; Y &lt;/math&gt;, and we write &lt;math display="inline"&gt; R \bot A | Y &lt;/math&gt;.

We can also express this notion with the following formula:
&lt;math display="block"&gt; P(R = r | Y = q, A = a) = P(R = r | Y = q, A = b) \quad \forall r \in R \quad q \in Y \quad \forall a,b \in A &lt;/math&gt;
This means that the [[probability theory|probability]] of being classified by the algorithm in each of the groups is equal for two individuals with different sensitive characteristics given that they actually belong in the same group (have the same target variable).

Another equivalent expression, in the case of a binary target rate, is that the [[Sensitivity and specificity|true positive rate]] and the [[Sensitivity and specificity|false positive rate]] are equal (and therefore the [[Sensitivity and specificity|false negative rate]] and the [[Sensitivity and specificity|true negative rate]] are equal) for every value of the sensitive characteristics:
&lt;math display="block"&gt; P(R = 1 | Y = 1, A = a) = P(R = 1 | Y = 1, A = b) \quad \forall a,b \in A &lt;/math&gt;
&lt;math display="block"&gt; P(R = 1 | Y = 0, A = a) = P(R = 1 | Y = 0, A = b) \quad \forall a,b \in A &lt;/math&gt;

Finally, another possible relaxation of the given definitions is to allow the value for the difference between rates to be a [[Sign (mathematics)|positive number]] lower than a given [[slack variable|slack]] &lt;math display="inline&gt; \epsilon &gt; 0 &lt;/math&gt;, rather than equal to zero.

=== Sufficiency ===

We say the [[random variable]]s &lt;math display="inline"&gt;(R,A,Y)&lt;/math&gt; satisfy '''sufficiency''' if the sensitive characteristics &lt;math display="inline"&gt; A &lt;/math&gt; are [[Independence (probability theory)|statistically independent]] to the target value &lt;math display="inline"&gt; Y &lt;/math&gt; given the prediction &lt;math display="inline"&gt; R &lt;/math&gt;, and we write &lt;math display="inline"&gt; Y \bot A | R &lt;/math&gt;.

We can also express this notion with the following formula:
&lt;math display="block"&gt; P(Y = q | R = r, A = a) = P(Y = q | R = r, A = b) \quad \forall q \in Y \quad r \in R \quad \forall a,b \in A &lt;/math&gt;
This means that the [[probability theory|probability]] of actually being in each of the groups is equal for two individuals with different sensitive characteristics given that they were predicted to belong to the same group.

=== Relationships between definitions ===

Finally, we sum up some of the main results that relate the three definitions given above:

* If &lt;math display="inline"&gt; A &lt;/math&gt; and &lt;math display="inline"&gt; Y &lt;/math&gt; are not [[Independence (probability theory)|statistically independent]], then sufficiency and independence cannot both hold.
* Assuming &lt;math display="inline"&gt; Y &lt;/math&gt; is binary, if &lt;math display="inline"&gt; A &lt;/math&gt; and &lt;math display="inline"&gt; Y &lt;/math&gt; are not [[Independence (probability theory)|statistically independent]], and &lt;math display="inline"&gt; R &lt;/math&gt; and &lt;math display="inline"&gt; Y &lt;/math&gt; are not [[Independence (probability theory)|statistically independent]] either, then independence and separation cannot both hold.
* If &lt;math display="inline"&gt;(R,A,Y)&lt;/math&gt; as a [[joint distribution]] has positive [[probability theory|probability]] for all its possible values and &lt;math display="inline"&gt; A &lt;/math&gt; and &lt;math display="inline"&gt; Y &lt;/math&gt; are not [[Independence (probability theory)|statistically independent]], then separation and sufficiency cannot both hold.

==Metrics&lt;ref name="metrics_paper"&gt;Sahil Verma; Julia Rubin, [https://fairware.cs.umass.edu/papers/Verma.pdf ''Fairness Definitions Explained'']. Retrieved 15 December 2019&lt;/ref&gt;==

Most statistical measures of fairness rely on different metrics, so we will start by defining them. When working with a [[binary numeral system|binary]] classifier, both the predicted and the actual classes can take two values: positive and negative. Now let us start explaining the different possible relations between predicted and actual outcome:[[File:Binary confusion matrix.jpg|200x150px|frame|Confusion matrix]]
* '''True positive (TP)''': The case where both the predicted and the actual outcome are in a positive class.
* '''True negative (TN)''': The case where both the predicted outcome and the actual outcome are assigned to the negative class.
* '''False positive (FP)''': A case predicted to befall into a positive class assigned in the actual outcome is to the negative one.
* '''False negative (FN)''': A case predicted to be in the negative class with an actual outcome is in the positive one.
These relations can be easily represented with a [[confusion matrix]], a table that describes the accuracy of a classification model. In this matrix, columns and rows represent instances of the predicted and the actual cases, respectively.

By using these relations, we can define multiple metrics which can be later used to measure the fairness of an algorithm:
* '''Positive predicted value (PPV)''': the fraction of positive cases which were correctly predicted out of all the positive predictions. It is usually referred to as [[accuracy and precision|precision]], and represents the [[probability theory|probability]] of a correct positive prediction. It is given by the following formula:
&lt;math display="block"&gt; PPV = P(actual=+|prediction=+) = \frac{TP}{TP+FP}&lt;/math&gt;
* '''False discovery rate (FDR)''': the fraction of positive predictions which were actually negative out of all the positive predictions. It represents the [[probability theory|probability]] of an erroneous positive prediction, and it is given by the following formula:
&lt;math display="block"&gt; FDR = P(actual=-|prediction=+) = \frac{FP}{TP+FP} &lt;/math&gt;
* '''Negative predicted value (NPV)''': the fraction of negative cases which were correctly predicted out of all the negative predictions. It represents the [[probability theory|probability]] of a correct negative prediction, and it is given by the following formula:
&lt;math display="block"&gt; NPV = P(actual=-|prediction=-) = \frac{TN}{TN+FN} &lt;/math&gt;
* '''False omission rate (FOR)''': the fraction of negative predictions which were actually positive out of all the negative predictions. It represents the [[probability theory|probability]] of an erroneous negative prediction, and it is given by the following formula:
&lt;math display="block"&gt; FOR = P(actual=+|prediction=-) = \frac{FN}{TN+FN} &lt;/math&gt;
* '''True positive rate (TPR)''': the fraction of positive cases which were correctly predicted out of all the positive cases. It is usually referred to as sensitivity or recall, and it represents the [[probability theory|probability]] of the positive subjects to be classified correctly as such. It is given by the formula:
&lt;math display="block"&gt; TPR = P(prediction=+|actual=+) = \frac{TP}{TP+FN} &lt;/math&gt;
* '''False negative rate (FNR)''': the fraction of positive cases which were incorrectly predicted to be negative out of all the positive cases. It represents the [[probability theory|probability]] of the positive subjects to be classified incorrectly as negative ones, and it is given by the formula:
&lt;math display="block"&gt; FNR = P(prediction=-|actual=+) = \frac{FN}{TP+FN} &lt;/math&gt;
* '''True negative rate (TNR)''': the fraction of negative cases which were correctly predicted out of all the negative cases. It represents the [[probability theory|probability]] of the negative subjects to be classified correctly as such, and it is given by the formula:
&lt;math display="block"&gt; TNR = P(prediction=-|actual=-) = \frac{TN}{TN+FP} &lt;/math&gt;
* '''False positive rate (FPR)''': the fraction of negative cases which were incorrectly predicted to be positive out of all the negative cases. It represents the [[probability theory|probability]] of the negative subjects to be classified incorrectly as positive ones, and it is given by the formula:
&lt;math display="block"&gt; FPR = P(prediction=+|actual=-) = \frac{FP}{TN+FP} &lt;/math&gt;

== Other fairness criteria ==

[[File:RelationsEng.jpg|250x400px|frame|Relationship between fairness criteria as shown in Barocas et al.&lt;ref name="Barocas"/&gt;]]
The following criteria can be understood as measures of the three definitions given in the first section, or relaxation of them. In the table&lt;ref name="Barocas"/&gt; to the right, we can see the relationships between them.

To define these measures specifically, we will divide them into three big groups as done in Verma et al.:&lt;ref name="metrics_paper"/&gt; definitions based on a predicted outcome, on predicted and actual outcomes, and definitions based on predicted probabilities and the actual outcome.

We will be working with a binary classifier and the following notation: &lt;math display="inline"&gt; S &lt;/math&gt; refers to the score given by the classifier, which is the probability of a certain subject to be in the positive or the negative class.&lt;math display="inline"&gt; R &lt;/math&gt; represents the final classification predicted by the algorithm, and its value is usually derived from &lt;math display="inline"&gt; S &lt;/math&gt;, for example will be positive when &lt;math display="inline"&gt; S &lt;/math&gt; is above a certain threshold.&lt;math display="inline"&gt; Y &lt;/math&gt; represents the actual outcome, that is, the real classification of the individual and, finally, &lt;math display="inline"&gt; A &lt;/math&gt; denotes the sensitive attributes of the subjects.

=== Definitions based on predicted outcome ===

The definitions in this section focus on a predicted outcome &lt;math display="inline"&gt; R &lt;/math&gt; for various [[probability distribution|distributions]] of subjects. They are the simplest and most intuitive notions of fairness.

* '''Group fairness''', also referred to as '''statistical parity''', '''demographic parity''', '''acceptance rate''' and '''benchmarking'''. A classifier satisfies this definition if the subjects in the protected and unprotected groups have equal probability of being assigned to the positive predicted class. This is, if the following formula is satisfied:
&lt;math display="block"&gt; P(R = +|A = a) = P(R = +|A = b) \quad \forall a,b \in A &lt;/math&gt;

* '''Conditional statistical parity'''. Basically consists in the definition above, but restricted only to a [[subset]] of the attributes. In  mathematical notation this would be:
&lt;math display="block"&gt; P(R = +|L = l, A = a) = P(R = +|L = l, A = b) \quad \forall a,b \in A \quad \forall l \in L &lt;/math&gt;

=== Definitions based on predicted and actual outcomes ===

These definitions not only considers the predicted outcome &lt;math display="inline"&gt; R &lt;/math&gt; but also compare it to the actual outcome &lt;math display="inline"&gt; Y &lt;/math&gt;.

* '''Predictive parity''', also referred to as '''outcome test'''. A classifier satisfies this definition if the subjects in the protected and unprotected groups have equal PPV. This is, if the following formula is satisfied:
&lt;math display="block"&gt; P(Y = + | R = +, A = a) = P(Y = + | R = +, A = b) \quad \forall a,b \in A &lt;/math&gt;
: Mathematically, if a classifier has equal PPV for both groups, it will also have equal FDR, satisfying the formula:
&lt;math display="block"&gt; P(Y = - | R = +, A = a) = P(Y = - | R = +, A = b) \quad \forall a,b \in A &lt;/math&gt;

* '''False positive error rate balance''', also referred to as '''predictive equality'''. A classifier satisfies this definition if the subjects in the protected and unprotected groups have aqual FPR. This is, if the following formula is satisfied:
&lt;math display="block"&gt; P(R = + | Y = -, A = a) = P(R = + | Y = -, A = b) \quad \forall a,b \in A &lt;/math&gt;
: Mathematically, if a classifier has equal FPR for both groups, it will also have equal TNR, satisfying the formula:
&lt;math display="block"&gt; P(R = - | Y = -, A = a) = P(R = - | Y = -, A = b) \quad \forall a,b \in A &lt;/math&gt;

* '''False negative error rate balance''', also referred to as '''equal opportunity'''. A classifier satisfies this definition if the subjects in the protected and unprotected groups have equal FNR. This is, if the following formula is satisfied:
&lt;math display="block"&gt; P(R = - | Y = +, A = a) = P(R = - | Y = +, A = b) \quad \forall a,b \in A &lt;/math&gt;
: Mathematically, if a classifier has equal FNR for both groups, it will also have equal TPR, satisfying the formula:
&lt;math display="block"&gt; P(R = + | Y = +, A = a) = P(R = + | Y = +, A = b) \quad \forall a,b \in A &lt;/math&gt;

* [[Equalized odds]], also referred to as '''conditional procedure accuracy equality''' and '''disparate mistreatment'''. A classifier satisfies this definition if the subjects in the protected and unprotected groups have equal TPR and equal FPR, satisfying the formula:
&lt;math display="block"&gt; P(R = + | Y = y, A = a) = P(R = + | Y = y, A = b) \quad y \in \{+,-\} \quad \forall a,b \in A &lt;/math&gt;

* '''Conditional use accuracy equality'''. A classifier satisfies this definition if the subjects in the protected and unprotected groups have equal PPV and equal NPV, satisfying the formula:
&lt;math display="block"&gt; P(Y = y | R = y, A = a) = P(Y = y | R = y, A = b) \quad y \in \{+,-\} \quad \forall a,b \in A &lt;/math&gt;

* '''Overall accuracy equality'''. A classifier satisfies this definition if the subject in the protected and unprotected groups have equal prediction accuracy, that is, the probability of a subject from one class to be assigned to it. This is, if it satisfies the following formula:
&lt;math display="block"&gt; P(R = Y , A = a) = P(R = Y | A = b) \quad \forall a,b \in A &lt;/math&gt;

* '''Treatment equality'''. A classifier satisfies this definition if the subjects in the protected and unprotected groups have an equal ratio of FN and FP, satisfying the formula:
&lt;math display="block"&gt; \frac{FN_{A=a}}{FP_{A=a}} = \frac{FN_{A=b}}{FP_{A=b}} &lt;/math&gt;

=== Definitions based on predicted probabilities and actual outcome ===

These definitions are based in the actual outcome &lt;math display="inline"&gt; Y &lt;/math&gt; and the predicted probability score &lt;math display="inline"&gt; S &lt;/math&gt;.

* '''Test-fairness''', also known as '''calibration''' or '''matching conditional frequencies'''. A classifier satisfies this definition if individuals with the same predicted probability score &lt;math display="inline"&gt; S &lt;/math&gt; have the same probability to be classified in the positive class when they belong to either the protected or the unprotected group:
&lt;math display="block"&gt; P(Y = +|S = s,A = a) = P(Y = +|S = s,A = b) \quad \forall s \in S \quad \forall a,b \in A &lt;/math&gt;

* '''Well-calibration''' is an extension of the previous definition. It states that when individuals inside or outside the protected group have the same predicted probability score &lt;math display="inline"&gt; S &lt;/math&gt; they must have the same probability of being classified in the positive class, and this probability must be equal to &lt;math display="inline"&gt; S &lt;/math&gt;:
&lt;math display="block"&gt; P(Y = +|S = s,A = a) = P(Y = +|S = s,A = b) = s \quad \forall s \in S \quad \forall a,b \in A &lt;/math&gt;

* '''Balance for positive class'''. A classifier satisfies this definition if the subjects constituting the positive class from both protected and unprotected groups have equal average predicted probability score &lt;math display="inline"&gt; S &lt;/math&gt;. This means that the expected value of probability score for the protected and unprotected groups with positive actual outcome &lt;math display="inline"&gt; Y &lt;/math&gt; is the same, satisfying the formula:
&lt;math display="block"&gt; E(S|Y = +,A = a) = E(S|Y = +,A = b) \quad \forall a,b \in A &lt;/math&gt;

* '''Balance for negative class'''. A classifier satisfies this definition if the subjects constituting the negative class from both protected and unprotected groups have equal average predicted probability score &lt;math display="inline"&gt; S &lt;/math&gt;. This means that the expected value of probability score for the protected and unprotected groups with negative actual outcome &lt;math display="inline"&gt; Y &lt;/math&gt; is the same, satisfying the formula:
&lt;math display="block"&gt; E(S|Y = -,A = a) = E(S|Y = -,A = b) \quad \forall a,b \in A &lt;/math&gt;

== Algorithms ==

Fairness can be applied to machine learning algorithms in three different ways: [[data preprocessing]], [[mathematical optimization|optimization]] during software training, or post-processing results of the algorithm.

=== Preprocessing ===

Usually, the classifier is not the only problem; the [[dataset]] is also biased. The discrimination of a dataset &lt;math display="inline"&gt; D &lt;/math&gt; with respect to the group &lt;math display="inline"&gt; A = a &lt;/math&gt; can be defined as follows:
&lt;math display="block"&gt; disc_{A=a}(D) = \frac{|\{X\in D| X(A) \neq a, X(Y) = +\}|}{|\{X \in D | X(A) \neq a \}|} - \frac{|\{X\in D| X(A) = a, X(Y) = +\}|}{|\{X \in D | X(A) = a \}|}&lt;/math&gt;

That is, an approximation to the difference between the probabilities of belonging in the positive class given that the subject has a protected characteristic different from &lt;math display="inline"&gt; a &lt;/math&gt; and equal to &lt;math display="inline"&gt; a &lt;/math&gt;.

Algorithms correcting bias at preprocessing remove information about dataset variables which might result in unfair decisions, while trying to alter as little as possible. This is not as simple as just removing the sensitive variable, because other attributes can be correlated to the protected one.

A way to do this is to map each individual in the initial dataset to an intermediate representation in which it is impossible to identify whether it belongs to a particular protected group while maintaining as much information as possible. Then, the new representation of the data is adjusted to get the maximum accuracy in the algorithm.
 
This way, individuals are mapped into a new multivariable representation where the probability of any member of a protected group to be mapped to a certain value in the new representation is the same as the probability of an individual which doesn't belong to the protected group. Then, this representation is used to obtain the prediction for the individual, instead of the initial data. As the intermediate representation is constructed giving the same probability to individuals inside or outside the protected group, this attribute is hidden to the classificator.

An example is explained in Zemel et al.&lt;ref name="zemel"&gt;Richard Zemel; Yu (Ledell) Wu; Kevin Swersky; Toniann Pitassi; Cyntia Dwork, [https://www.cs.toronto.edu/~toni/Papers/icml-final.pdf ''Learning Fair Representations'']. Retrieved 1 December 2019&lt;/ref&gt; where a [[multinomial distribution|multinomial random variable]] is used as an intermediate representation. In the process, the system is encouraged to preserve all information except that which can lead to biased decisions, and to obtain a prediction as accurate as possible.

On the one hand, this procedure has the advantage that the preprocessed data can be used for any machine learning task. Furthermore, the classifier does not need to be modified, as the correction is applied to the [[Data set|dataset]] before processing. On the other hand, the other methods obtain better results in accuracy and fairness.&lt;ref name="datascience"&gt;Ziyuan Zhong, [https://towardsdatascience.com/a-tutorial-on-fairness-in-machine-learning-3ff8ba1040cb ''Tutorial on Fairness in Machine Learning'']. Retrieved 1 December 2019&lt;/ref&gt;

==== Reweighing&lt;ref name="reweighing"&gt;Faisal Kamiran; Toon Calders, [https://link.springer.com/content/pdf/10.1007%2Fs10115-011-0463-8.pdf ''Data preprocessing techniques for classification without discrimination'']. Retrieved 17 December 2019&lt;/ref&gt; ====

Reweighing is an example of a preprocessing algorithm. The idea is to assign a weight to each dataset point such that the weighted [[discrimination]] is 0 with respect to the designated group.

If the dataset &lt;math display="inline"&gt; D &lt;/math&gt; was unbiased the sensitive variable &lt;math display="inline"&gt; A &lt;/math&gt; and the target variable &lt;math display="inline"&gt; Y &lt;/math&gt; would be [[Independence (probability theory)|statistically independent]] and the probability of the [[Joint probability distribution|joint distribution]] would be the product of the probabilities as follows:
&lt;math display="block"&gt; P_{exp}(A = a \wedge Y = +) = P(A = a) \times P(Y = +) = \frac{|\{X \in D | X(A) = a\}|}{|D|} \times \frac{|\{X \in D| X(Y) = + \}|}{|D|}&lt;/math&gt;

In reality, however, the dataset is not unbiased and the variables are not [[Independence (probability theory)|statistically independent]] so the observed probability is:
&lt;math display="block"&gt; P_{obs}(A = a \wedge Y = +) = \frac{|\{X \in D | X(A) = a \wedge X(Y) = +\}|}{|D|} &lt;/math&gt;

To compensate for the bias, the software adds a [[weight function|weight]], lower for favored objects and higher for unfavored objects. For each &lt;math display="inline"&gt; X \in D &lt;/math&gt; we get:
&lt;math display="block"&gt; W(X) = \frac{P_{exp}(A = X(A) \wedge Y = X(Y))}{P_{obs}(A = X(A) \wedge Y = X(Y))} &lt;/math&gt;

When we have for each &lt;math display="inline"&gt; X &lt;/math&gt; a weight associated &lt;math display="inline"&gt; W(X) &lt;/math&gt; we compute the weighted discrimination with respect to group &lt;math display="inline"&gt; A = a &lt;/math&gt; as follows:
&lt;math display="block"&gt; disc_{A = a}(D) = \frac{\sum W(X) X \in \{X\in D| X(A) \neq a, X(Y) = +\}}{\sum W(X) X \in \{X \in D | X(A) \neq a \}} - \frac{\sum W(X) X \in \{X\in D| X(A) = a, X(Y) = +\}}{\sum W(X) X \in \{X \in D | X(A) = a \}} &lt;/math&gt;

It can be shown that after reweighting this weighted discrimination is 0.

===Optimization at training time===

Another approach is to correct the [[bias]] at training time. This can be done by adding constraints to the optimization objective of the algorithm.&lt;ref name="zafar"&gt;Muhammad Bilal Zafar; Isabel Valera; Manuel Gómez Rodríguez; Krishna P. Gummadi, [https://people.mpi-sws.org/~mzafar/papers/disparate_mistreatment.pdf ''Fairness Beyond Disparate Treatment &amp; Disparate Impact: Learning Classification without Disparate Mistreatment'']. Retrieved 1 December 2019&lt;/ref&gt; These constraints force the algorithm to improve fairness, by keeping the same rates of certain measures for the protected group and the rest of individuals. For example, we can add to the objective of the [[algorithm]] the condition that the false positive rate is the same for individuals in the protected group and the ones outside the protected group.

The main measures used in this approach are false positive rate, false negative rate, and overall misclassification rate. It is possible to add just one or several of these constraints to the objective of the algorithm. Note that the equality of false negative rates implies the equality of true positive rates so this implies the equality of opportunity. After adding the restrictions to the problem it may turn intractable, so a relaxation on them may be needed.

This technique obtains good results in improving fairness while keeping high accuracy and lets the [[programmer]] choose the fairness measures to improve. However, each machine learning task may need a different method to be applied and the code in the classifier needs to be modified, which is not always possible.&lt;ref name="datascience"/&gt;

==== Adversarial debiasing&lt;ref name="adversarial1"&gt;Brian Hu Zhang; Blake Lemoine; Margaret Mitchell, [https://arxiv.org/abs/1801.07593 ''Mitigating Unwanted Biases with Adversarial Learning'']. Retrieved 17 December 2019&lt;/ref&gt;&lt;ref name="adversarial2"&gt;Joyce Xu, [https://towardsdatascience.com/algorithmic-solutions-to-algorithmic-bias-aef59eaf6565 ''Algorithmic Solutions to Algorithmic Bias: A Technical Guide'']. Retrieved 17 December 2019&lt;/ref&gt; ====

We train two [[Statistical classification|classifiers]] at the same time through some gradient-based method (f.e.: [[gradient descent]]). The first one, the ''predictor'' tries to accomplish the task of predicting &lt;math display="inline"&gt; Y &lt;/math&gt;, the target variable, given &lt;math display="inline"&gt; X &lt;/math&gt;, the input, by modifying its weights &lt;math display="inline"&gt; W &lt;/math&gt; to minimize some [[loss function]] &lt;math display="inline"&gt;L_{P}(\hat{y},y)&lt;/math&gt;. The second one, the ''adversary'' tries to accomplish the task of predicting &lt;math display="inline"&gt; A &lt;/math&gt;, the sensitive variable, given &lt;math display="inline"&gt; \hat{Y} &lt;/math&gt; by modifying its weights &lt;math display="inline"&gt; U &lt;/math&gt; to minimize some loss function &lt;math display="inline"&gt;L_{A}(\hat{a},a) &lt;/math&gt;.

An important point here is that, in order to propagate correctly, &lt;math display="inline"&gt; \hat{Y} &lt;/math&gt; above must refer to the raw output of the classifier, not the discrete prediction; for example, with an [[artificial neural network]] and a classification problem, &lt;math display="inline"&gt; \hat{Y} &lt;/math&gt; could refer to the output of the [[softmax function|softmax layer]].

Then we update &lt;math display="inline"&gt; U &lt;/math&gt; to minimize &lt;math display="inline"&gt; L_{A} &lt;/math&gt; at each training step according to the [[gradient]] &lt;math display="inline"&gt; \nabla_{U}L_{A} &lt;/math&gt; and we modify &lt;math display="inline"&gt; W &lt;/math&gt; according to the expression:
&lt;math display="block"&gt; \nabla_{W}L_{P} - proj_{\nabla_{W}L_{A}}\nabla_{W}L_{P} - \alpha \nabla_{W}L_{A} &lt;/math&gt;
where &lt;math display="alpha"&gt; \alpha &lt;/math&gt; is a tuneable [[hyperparameter optimization|hyperparameter]] that can vary at each time step.

[[File:AdvFig2.jpg|100x150px|frame|Graphic representation of the vectors used in adversarial debiasing as shown in Zhan et al.&lt;ref name=adversarial1/&gt;]]
The intuitive idea is that we want the ''predictor'' to try to minimize &lt;math display="inline"&gt; L_{P} &lt;/math&gt; (therefore the term &lt;math display="inline"&gt; \nabla_{W}L_{P} &lt;/math&gt;) while, at the same time, maximize &lt;math display="inline"&gt; L_{A} &lt;/math&gt; (therefore the term &lt;math display="inline"&gt; - \alpha \nabla_{W}L_{A} &lt;/math&gt;), so that the ''adversary'' fails at predicting the sensitive variable from  &lt;math display="inline"&gt; \hat{Y} &lt;/math&gt;.

The term &lt;math display="inline"&gt; -proj_{\nabla_{W}L_{A}}\nabla_{W}L_{P} &lt;/math&gt; prevents the ''predictor'' from moving in a direction that helps the ''adversary'' decrease its loss function.

It can be shown that training a ''predictor'' classification model with this algorithm improves [[#Definitions based on predicted outcome|demographic parity]] with respect to training it without the ''adversary''.

===Postprocessing===

The final method tries to correct the results of a classifier to achieve fairness. In this method, we have a classifier that returns a score for each individual and we need to do a binary prediction for them. High scores are likely to get a positive outcome, while low scores are likely to get a negative one, but we can adjust the [[critical value|threshold]] to determine when to answer yes as desired. Note that variations in the threshold value affect the trade-off between the rates for true positives and true negatives.

If the score function is fair in the sense that it is independent of the protected attribute, then any choice of the threshold will also be fair, but classifiers of this type tend to be biased, so a different threshold may be required for each protected group to achieve fairness.&lt;ref name="hardt" /&gt; A way to do this is plotting the true positive rate against the false negative rate at various threshold settings (this is called ROC curve) and find a threshold where the rates for the protected group and other individuals are equal.&lt;ref name="hardt"&gt;Moritz Hardt; Eric Price; Nathan Srebro, [https://arxiv.org/abs/1610.02413 ''Equality of Opportunity in Supervised Learning'']. Retrieved 1 December 2019&lt;/ref&gt;

The advantages of postprocessing include that the technique can be applied after any classifiers, without modifying it, and has a good performance in fairness measures. The cons are the need to access to the protected attribute in test time and the lack of choice in the balance between accuracy and fairness.&lt;ref name="datascience"/&gt;

==== Reject Option based Classification&lt;ref name="roc"&gt;Faisal Kamiran; Asim Karim; Xiangliang Zhang, [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.722.3030&amp;rep=rep1&amp;type=pdf ''Decision Theory for Discrimination-aware Classification'']. Retrieved 17 December 2019&lt;/ref&gt; ====

Given a [[Statistical classification|classifier]] let &lt;math display="inline"&gt; P(+|X) &lt;/math&gt; be the probability computed by the classifiers as the [[probability]] that the instance &lt;math display="inline"&gt; X &lt;/math&gt; belongs to the positive class +. When &lt;math display="inline"&gt; P(+|X) &lt;/math&gt; is close to 1 or to 0, the instance &lt;math display="inline"&gt; X &lt;/math&gt; is specified with high degree of certainty to belong to class + or - respectively. However, when &lt;math display="inline"&gt; P(+|X) &lt;/math&gt; is closer to 0.5 the classification is more unclear.

We say &lt;math display="inline"&gt; X &lt;/math&gt; is a "rejected instance" if &lt;math display="inline"&gt; max(P(+|X), 1-P(+|X)) \leq \theta &lt;/math&gt; with a certain &lt;math display="inline"&gt; \theta &lt;/math&gt; such that &lt;math display="inline"&gt; 0.5 &lt; \theta &lt; 1 &lt;/math&gt;.

The algorithm of "ROC" consists on classifying the non-rejected instances following the rule above and the rejected instances as follows: if the instance is an example of a deprived group (&lt;math&gt;X(A) = a&lt;/math&gt;) then label it as positive, otherwise, label it as negative.

We can optimize different measures of [[discrimination]] (link) as functions of &lt;math display="inline"&gt; \theta &lt;/math&gt; to find the optimal &lt;math display="inline"&gt; \theta &lt;/math&gt; for each problem and avoid becoming discriminatory against the privileged group.&lt;ref name="roc" /&gt;

== See also ==

* [[Algorithmic bias]]
* [[Machine learning]]

== References ==
&lt;references /&gt;

[[Category:Machine learning]]
[[Category:Information ethics]]
[[Category:Computing and society]]
[[Category:Philosophy of artificial intelligence]]
[[Category:Discrimination]]
[[Category:Bias]]</text>
      <sha1>rsow5v0ihx0r9bzh8ojecb112lxi4ah</sha1>
    </revision>
  </page>
  <page>
    <title>Leakage (machine learning)</title>
    <ns>0</ns>
    <id>62817500</id>
    <revision>
      <id>988701417</id>
      <parentid>988697791</parentid>
      <timestamp>2020-11-14T19:27:07Z</timestamp>
      <contributor>
        <username>Olexa Riznyk</username>
        <id>9148555</id>
      </contributor>
      <comment>/* Training example leakage */ Changing "CV/TrainTest" to "CV/Train/Test"</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="5767" xml:space="preserve">{{Machine learning bar}}

In [[statistics]] and [[machine learning]], '''leakage''' (also '''data leakage''', or '''target leakage''') is the use of [[information]] in the model training process which would not be expected to be available at [[prediction]] time, causing the predictive scores (metrics) to overestimate the model's utility when run in a production environment.&lt;ref name="KaufmanKDD11"/&gt;

Leakage is often subtle and indirect, making it hard to detect and eliminate. Leakage can cause modeler to select a suboptimal model, which otherwise could be outperformed by a leakage-free model.&lt;ref name="KaufmanKDD11"&gt;{{cite journal |author1=Shachar Kaufman |author2=Saharon Rosset |author3=Claudia Perlich |title=Leakage in Data Mining: Formulation, Detection, and Avoidance |journal=Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining |date=January 2011 |volume=6 |pages=556–563 |doi=10.1145/2020408.2020496 |url=https://www.researchgate.net/publication/221653692 |accessdate=13 January 2020}}&lt;/ref&gt;


==Leakage modes==
Leakage can occur in many steps in the machine learning process. The leakage causes can be sub-classified into two possible sources of leakage for a model: features and training examples.&lt;ref name="KaufmanKDD11"/&gt;

===Feature leakage===
Column-wise leakage is caused by the inclusion of columns which are one of: a duplicate label, a proxy for the label, or the label itself, when training the model, which are not available at prediction time (anachronisms&lt;ref&gt;{{cite book |author1=Soumen Chakrabarti |title=Data Mining: Know it All. |date=2008 |publisher=Morgan Kaufmann Publishers |isbn=978-0-12-374629-0 |page=383 |chapter=9 |quote=Anachronistic variables are a pernicious mining problem. However, they aren’t any problem at all at deployment time—unless someone expects the model to work! Anachronistic variables are out of place in time. Specifically, at data modeling time, they carry information back from the future to the past.}}&lt;/ref&gt;). This can include leaks which partially give away the label. 

For example, including a "MonthlySalary" column when predicting "YearlySalary"; or "MinutesLate" when predicting "IsLate"; or more subtly "NumOfLatePayments" when predicting "ShouldGiveLoan".

===Training example leakage===
Row-wise leakage is caused by improper sharing of information between rows of data.

Data leakage types:
* Premature [[Feature engineering|featurization]]; leaking from premature featurization before [[Cross-validation (statistics)|CV]]/Train/Test split (must fit MinMax/ngrams/etc on only the train split, then transform the test set)
* Duplicate rows between train/validation/test (e.g. oversampling a dataset to pad its size before splitting; e.g. different rotations/augmentations of an single image; [[Bootstrapping (statistics)|bootstrap sampling]] before splitting; or duplicating rows to [[Oversampling and undersampling in data analysis|up sample]] the minority class) 
* [[Independent and identically distributed random variables|Non-i.i.d.]] data
** Time leakage (e.g. splitting a time-series dataset randomly instead of newer data in test set using a TrainTest split or rolling-origin cross validation)
** Group leakage -- not including a grouping split column (e.g. [[Andrew Ng]]'s group had 100k x-rays of 30k patients, meaning ~3 images per patient. The paper used random splitting instead of ensuring that all images of a patient was in the same split. Hence the model partially memorized the patients instead of learning to recognize pneumonia in chest x-rays. Revised paper had a drop in scores.&lt;ref name=GutsAIUkraineConfTalk18&gt;{{cite conference |url=https://www.youtube.com/watch?v=dWhdWxgt5SU |title=Yuriy Guts. TARGET LEAKAGE IN MACHINE LEARNING |last1=Guts |first1=Yuriy |lay-url=https://aiukraine.com/wp-content/uploads/2018/09/12_00-Yuriy-Guts-Target-Leakage-in-Machine-Learning-.pdf |date=30 October 2018 |location=Ukraine |conference=AI Ukraine Conference |format=Talk }}&lt;/ref&gt;&lt;ref&gt;{{cite web |last1=Nick |first1=Roberts |title=Replying to @AndrewYNg @pranavrajpurkar and 2 others |url=https://twitter.com/nizkroberts/status/931121395748270080 |publisher=Twitter |accessdate=13 January 2020 |archiveurl=https://web.archive.org/web/20180610093107/https://twitter.com/nizkroberts/status/931121395748270080 |archivedate=10 June 2018 |location=Brooklyn, NY, USA |date=16 November 2017 |quote=Replying to  @AndrewYNg   @pranavrajpurkar  and 2 others ... Were you concerned that the network could memorize patient anatomy since patients cross train and validation?  “ChestX-ray14 dataset contains 112,120 frontal-view X-ray images of 30,805 unique patients. We randomly split the entire dataset into 80% training, and 20% validation.” |url-status=live }}&lt;/ref&gt;)

For time-dependent datasets, the structure of the system being studied evolves over time (i.e. it is "non-stationary"). This can introduce systematic differences between the training and validation sets.  For example, if a model for [[stock market prediction|predicting stock values]] is trained on data for a certain five-year period, it is unrealistic to treat the subsequent five-year period as a draw from the same population.  As another example, suppose a model is developed to predict an individual's risk for being [[medical diagnosis|diagnosed]] with a particular disease within the next year.

==Detection==
{{Expand section|date=January 2020}}

==See also==
* [[AutoML]]
* [[Cross-validation (statistics)|Cross-validation]]
* [[Overfitting]]
* [[Resampling (statistics)]]
* [[Supervised learning]]
* [[Training, validation, and test sets]]

==References==
{{Reflist}}

[[Category:Machine learning]]
[[Category:Statistical classification]]

{{compu-ai-stub}}</text>
      <sha1>s09f5et7z5izfq6phw6ntqlo4vwvzur</sha1>
    </revision>
  </page>
  <page>
    <title>Flux (machine-learning framework)</title>
    <ns>0</ns>
    <id>60929882</id>
    <revision>
      <id>993892900</id>
      <parentid>990668220</parentid>
      <timestamp>2020-12-13T01:38:56Z</timestamp>
      <contributor>
        <username>N2e</username>
        <id>1143897</id>
      </contributor>
      <comment>/* top */ clarify the domain, for global readers who don't already know was "open source" is but at least grok the concept of software; library doesn't mean software library for most of the world</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="8467" xml:space="preserve">{{Infobox software
| name = Flux
| logo = FluxLogo.png
| author = Michael J Innes.&lt;ref name="JOSS"&gt;{{Cite journal|title=Flux: Elegant machine learning with Julia|journal = Journal of Open Source Software|volume = 3|issue = 25|pages = 602|last=Innes|first=Michael|date=2018-05-03|language=en|doi=10.21105/joss.00602|doi-access=free}}&lt;/ref&gt;
| latest release version = v0.10.3
| license = [[MIT License|MIT]]&lt;ref&gt;{{Cite web|url=https://github.com/FluxML/Flux.jl/blob/master/LICENSE.md|title=github.com/FluxML/Flux.jl/blob/master/LICENSE.md}}&lt;/ref&gt;
| repo = {{URL|https://github.com/FluxML/Flux.jl}}
| programming language = [[Julia (programming language)|Julia]]
| genre = [[Machine learning]] [[Library (computing)|library]]
| website = https://fluxml.ai
}}

'''Flux''' is an [[Open source|open-source]] machine-learning [[AI software|software]] library and ecosystem written in [[Julia (programming language)|Julia]].&lt;ref name="JOSS" /&gt;&lt;ref&gt;{{Cite web|url=https://julialang.org/blog/2018/12/ml-language-compiler|title=Building a Language and Compiler for Machine Learning|first1=Mike|last1=Innes|first2=James|last2=Bradbury|first3=Keno|last3=Fischer|first4=Dhairya|last4=Gandhi|first5=Neethu|last5=Mariya Joy|first6=Tejan|last6=Karmali|first7=Matt|last7=Kelley|first8=Avik|last8=Pal|first9=Marco|last9=Concetto Rudilosso|first10=Elliot|last10=Saba|first11=Viral|last11=Shah|first12=Deniz|last12=Yuret|website=julialang.org|access-date=2019-06-02}}&lt;/ref&gt; Its current stable release is v0.10.3.&lt;ref&gt;{{Citation|title=FluxML/Flux.jl v0.10.3|date=2020-03-04|url=https://github.com/FluxML/Flux.jl/releases/tag/v0.10.3|publisher=Flux|access-date=2020-03-27}}&lt;/ref&gt; It has a layer-stacking-based interface for simpler models, and has a strong support on interoperability with other Julia packages instead of a monolithic design.&lt;ref&gt;{{Cite web|url=https://juliacomputing.com/domains/ml-and-ai.html|title=Machine Learning and Artificial Intelligence|website=juliacomputing.com|access-date=2019-06-02}}&lt;/ref&gt; For example, GPU support is implemented transparently by CuArrays.jl&lt;ref&gt;{{Cite web|url=https://juliacomputing.com/blog/2018/11/15/julia-ml-three-papers.html|title=Julia at NeurIPS and the Future of Machine Learning Tools|last=Gandhi|first=Dhairya|date=2018-11-15|website=juliacomputing.com|access-date=2019-06-02}}&lt;/ref&gt; This is in contrast to some other machine learning frameworks which are implemented in other languages with Julia bindings,&amp;nbsp;such as [[TensorFlow|TensorFlow.jl]], and thus are more limited by the functionality present in the underlying implementation, which is often in C or C++.&lt;ref&gt;{{Cite journal|title=TensorFlow.jl: An Idiomatic Julia Front End for TensorFlow|journal = Journal of Open Source Software|volume = 3|issue = 31|pages = 1002|date=2018-11-01|language=en|doi=10.21105/joss.01002|last1 = Malmaud|first1 = Jonathan|last2 = White|first2 = Lyndon|doi-access = free}}&lt;/ref&gt;

Flux's focus on interoperability has enabled, for example, support for [[Neural Differential Equations]], by fusing Flux.jl and DifferentialEquations.jl into DiffEqFlux.jl.&lt;ref&gt;{{cite arxiv|last=Rackauckas|first=Chris|last2=Innes|first2=Mike|last3=Ma|first3=Yingbo|last4=Bettencourt|first4=Jesse|last5=White|first5=Lyndon|last6=Dixit|first6=Vaibhav|date=2019-02-06|title=DiffEqFlux.jl - A Julia Library for Neural Differential Equations|eprint=1902.02376|language=en|class=cs.LG}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://jaxenter.com/julia-machine-learning-library-154880.html|title=Machine learning meets math: Solve differential equations with new Julia library|date=2019-01-25|website=JAXenter|language=en-US|access-date=2019-10-21|last=Schlothauer|first=Sarah}}&lt;/ref&gt;

Flux supports recurrent and convolutional networks. It is also capable of [[differentiable programming]]&lt;ref&gt;{{Cite web|url=https://fluxml.ai/2019/03/05/dp-vs-rl.html|title=Flux – Reinforcement Learning vs. Differentiable Programming|website=fluxml.ai|access-date=2019-06-02}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://fluxml.ai/2019/02/07/what-is-differentiable-programming.html|title=Flux – What Is Differentiable Programming?|website=fluxml.ai|access-date=2019-06-02}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.techrepublic.com/article/julia-vs-python-which-programming-language-will-rule-machine-learning-in-2019/|title=Julia vs Python: Which programming language will rule machine learning in 2019?|last=Heath|first=Nick|date=December 6, 2018|website=TechRepublic|language=en|access-date=2019-06-03}}&lt;/ref&gt; through its source-to-source [[automatic differentiation]] package, Zygote.jl.&lt;ref&gt;{{cite arxiv|last=Innes|first=Michael|date=2018-10-18|title=Don't Unroll Adjoint: Differentiating SSA-Form Programs|eprint=1810.07951|language=en|class=cs.PL}}&lt;/ref&gt;

Julia is a popular language in machine-learning&lt;ref name=":0"&gt;{{Cite web|url=https://www.techrepublic.com/article/github-the-top-10-programming-languages-for-machine-learning/|title=GitHub: The top 10 programming languages for machine learning|last=Heath|first=Nick|date=January 25, 2019|website=TechRepublic|language=en|access-date=2019-06-03}}&lt;/ref&gt; and Flux.jl is its most highly regarded machine-learning repository.&lt;ref name=":0" /&gt; A demonstration&lt;ref&gt;{{cite arxiv|last=Saba|first=Elliot|last2=Fischer|first2=Keno|date=2018-10-23|title=Automatic Full Compilation of Julia Programs and ML Models to Cloud TPUs|eprint=1810.09868|language=en|class=cs.PL}}&lt;/ref&gt; compiling Julia code to run in Google's [[Tensor processing unit]] received praise from [[Google Brain]] AI lead [[Jeff Dean (computer scientist)|Jeff Dean]].&lt;ref&gt;{{cite tweet |user=JeffDean |number=1054951415339192321 |date=2018-10-23 |title=Julia + TPUs = fast and easily expressible ML computations |first=Jeff |last=Dean|language=en|access-date=2019-06-02}}&lt;/ref&gt;

Flux has been used as a framework to build neural networks that work with [[Homomorphic encryption|homomorphic encrypted]] data without ever decrypting it.&lt;ref&gt;{{Cite web|url=https://hub.packtpub.com/julia-computing-research-team-runs-machine-learning-model-on-encrypted-data-without-decrypting-it/|title=Julia Computing research team runs machine learning model on encrypted data without decrypting it|last=Patrawala|first=Fatema|date=2019-11-28|website=Packt Hub|language=en-US|access-date=2019-12-11}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://juliacomputing.com/blog/2019/11/22/encrypted-machine-learning.html|title=Machine Learning on Encrypted Data Without Decrypting It|date=2019-11-22|website=juliacomputing.com|access-date=2019-12-11}}&lt;/ref&gt; This kind of application is envisioned to be central for privacy to future [[application programming interface|API]] using machine-learning models.&lt;ref&gt;{{Cite web|url=https://analyticsindiamag.com/julia-computing-uses-homomorphic-encryption-for-ml-is-it-the-way-forward/|title=Julia Computing Uses Homomorphic Encryption For ML. Is It The Way Forward?|last=Yadav|first=Rohit|date=2019-12-02|website=Analytics India Magazine|language=en-US|access-date=2019-12-11}}&lt;/ref&gt;

Flux.jl is an [[intermediate representation]] for running high level programs on [[CUDA]] hardware.&lt;ref&gt;{{cite arxiv |title=Relay: A High-Level IR for Deep Learning |author=Roesch, Jared and Lyubomirsky, Steven and Kirisame, Marisa and Pollock, Josh and Weber, Logan and Jiang, Ziheng and Chen, Tianqi and Moreau, Thierry and Tatlock, Zachary |eprint=1904.08368 |year=2019 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal |doi=10.1109/tpds.2018.2872064 |year=2019 |publisher=Institute of Electrical and Electronics Engineers (IEEE) |volume=30 |number=4 |pages=827–841 |author=Tim Besard and Christophe Foket and Bjorn De Sutter |title=Effective Extensible Programming: Unleashing Julia on GPUs |journal=IEEE Transactions on Parallel and Distributed Systems |arxiv=1712.03112 }}&lt;/ref&gt; It was the predecessor to CUDAnative.jl which is also a [[General-purpose computing on graphics processing units|GPU programming]] language.&lt;ref&gt;{{cite thesis |type=PhD |title=Abstractions for Programming Graphics Processors in High-Level Programming Languages |author=Besard, Tim |year=2018 |publisher=Ghent University }}&lt;/ref&gt;

== See also ==
* [[Differentiable programming]]
* [[Comparison of deep-learning software]]

== References ==
&lt;!-- Inline citations added to your article will automatically display here. See en.wikipedia.org/wiki/WP:REFB for instructions on how to add citations. --&gt;
{{reflist}}

[[Category:Machine learning]]
[[Category:Free software programmed in Julia]]
[[Category:Software using the MIT license]]</text>
      <sha1>4djr3e0ua1wwol47hehpe5pm82y2vvq</sha1>
    </revision>
  </page>
  <page>
    <title>Node2vec</title>
    <ns>0</ns>
    <id>63616204</id>
    <revision>
      <id>995511005</id>
      <parentid>995255644</parentid>
      <timestamp>2020-12-21T12:52:58Z</timestamp>
      <contributor>
        <username>Leonardofribeiro</username>
        <id>16633222</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2426" xml:space="preserve">{{Orphan|date=May 2020}}

'''node2vec''' is an algorithm to generate vector representations of nodes on a [[Graph theory|graph.]] The ''node2vec'' framework learns low-dimensional representations for nodes in a graph through the use of [[random walk]]s through a graph starting at a target node. It is useful for a variety of [[machine learning]] applications. Besides reducing the engineering effort, representations learned by the algorithm lead to greater predictive power.&lt;ref&gt;{{Cite web|url=https://snap.stanford.edu/node2vec/|title=node2vec: Scalable Feature Learning for Networks}}&lt;/ref&gt; ''node2vec'' follows the intuition that random walks through a graph can be treated like sentences in a corpus. Each node in a graph is treated like an individual word, and a random walk is treated as a sentence. By feeding these "sentences" into a [[N-gram|skip-gram]], or by using the [[Bag-of-words model|continuous bag of words]] model paths found by random walks can be treated as sentences, and traditional data-mining techniques for documents can be used. The algorithm generalizes prior work which is based on rigid notions of network neighborhoods, and argues that the added flexibility in exploring neighborhoods is the key to learning richer representations of nodes in graphs.&lt;ref&gt;{{cite journal|last1=Grover|first1=Aditya|last2=Leskovec|first2=Jure|date=2016|title=node2vec: Scalable Feature Learning for Networks|journal=KDD : Proceedings. International Conference on Knowledge Discovery &amp; Data Mining|volume=2016|pages=855–864|doi=10.1145/2939672.2939754|pmid=27853626|pmc=5108654|arxiv=1607.00653|bibcode=2016arXiv160700653G}}&lt;/ref&gt; The algorithm is an extension of [[Gensim]]'s ''[[word2vec]]'' algorithm,&lt;ref&gt;{{Cite web|url=https://towardsdatascience.com/node2vec-embeddings-for-graph-data-32a866340fef|title=node2vec: Embeddings for Graph Data|last=Cohen|first=Elior|date=2018|website=Towards Data Science}}&lt;/ref&gt; and is considered one of the best classifiers for nodes in a graph.&lt;ref&gt;{{cite journal|last1=Khosla|first1=Megha|last2=Setty|first2=Vinay|last3=Anand|first3=Avishek|title=A Comparative Study for Unsupervised Network Representation Learning|journal=IEEE Transactions on Knowledge and Data Engineering|year=2019|pages=1|doi=10.1109/TKDE.2019.2951398|arxiv=1903.07902}}&lt;/ref&gt;

==See also==
* [[Struc2vec]]

==References==
{{Reflist}}

[[Category:Machine learning]]
[[Category:Unsupervised learning]]</text>
      <sha1>l6w6jlqd5lrcb6f2ha108yis5y62317</sha1>
    </revision>
  </page>
  <page>
    <title>Neural network Gaussian process</title>
    <ns>0</ns>
    <id>63513679</id>
    <revision>
      <id>993898324</id>
      <parentid>991011365</parentid>
      <timestamp>2020-12-13T02:16:47Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <comment>Add: url. | You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | Suggested by Abductive | [[Category:Artificial neural networks]] | via #UCB_Category 62/168</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="20432" xml:space="preserve">[[File:Infinitely wide neural network.webm|thumb|406x406px|'''Left''': a [[Bayesian network|Bayesian neural network]] with two hidden layers, transforming a 3-dimensional input (bottom) into a two-dimensional output &lt;math&gt;(y_1, y_2)&lt;/math&gt; (top). '''Right''': output [[probability density function]] &lt;math&gt;p(y_1, y_2)&lt;/math&gt; induced by the random weights of the network. '''Video''': as the width of the network increases, the output distribution simplifies, ultimately converging to a [[Multivariate normal distribution|multivariate normal]] in the infinite width limit.]]

[[Bayesian network]]s are a modeling tool for assigning probabilities to events, and thereby characterizing the uncertainty in a model's predictions. [[Deep learning]] and [[artificial neural network]]s are approaches used in [[machine learning]] to build computational models which learn from training examples. Bayesian neural networks merge these fields. They are a type of artificial neural network whose [[Statistical parameter|parameters]] and predictions are both probabilistic.&lt;ref&gt;{{Cite journal|last=MacKay|first=David J. C.|date=1992|title=A Practical Bayesian Framework for Backpropagation Networks|journal=Neural Computation|volume=4|issue=3|pages=448–472|doi=10.1162/neco.1992.4.3.448|s2cid=16543854|issn=0899-7667|url=https://resolver.caltech.edu/CaltechAUTHORS:MACnc92b}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|last=Neal|first=Radford M.|title=Bayesian Learning for Neural Networks|publisher=Springer Science and Business Media|year=2012}}&lt;/ref&gt; While standard artificial neural networks often assign high confidence even to incorrect predictions,&lt;ref&gt;
{{cite journal|last1=Guo|first1=Chuan|last2=Pleiss|first2=Geoff|last3=Sun|first3=Yu|last4=Weinberger|first4=Kilian Q.|date=2017|title=On calibration of modern neural networks|journal=Proceedings of the 34th International Conference on Machine Learning-Volume 70|arxiv=1706.04599}}
&lt;/ref&gt; Bayesian neural networks can more accurately evaluate how likely their predictions are to be correct.

Neural Network Gaussian Processes (NNGPs) are equivalent to Bayesian neural networks in a particular limit,&lt;ref name=":2" /&gt;&lt;ref name=":11"&gt;
{{cite journal|last1=Williams|first1=Christopher K. I.|date=1997|title=Computing with infinite networks|journal=Neural Information Processing Systems}}
&lt;/ref&gt;&lt;ref name=":0"&gt;{{cite journal|last1=Lee|first1=Jaehoon|last2=Bahri|first2=Yasaman|last3=Novak|first3=Roman|last4=Schoenholz|first4=Samuel S.|last5=Pennington|first5=Jeffrey|last6=Sohl-Dickstein|first6=Jascha|date=2017|title=Deep Neural Networks as Gaussian Processes|journal=International Conference on Learning Representations|arxiv=1711.00165|bibcode=2017arXiv171100165L}}&lt;/ref&gt;&lt;ref name=":3" /&gt;&lt;ref name=":1" /&gt;&lt;ref name=":4" /&gt;&lt;ref name=":9" /&gt;&lt;ref&gt;
{{cite arxiv|eprint=2002.08517|class=cs.LG|first1=Russell|last1=Tsuchida|first2=Tim|last2=Pearce|title=Avoiding Kernel Fixed Points: Computing with ELU and GELU Infinite Networks|date=2020|last3=van der Heide|first3=Christopher|last4=Roosta|first4=Fred|last5=Gallagher|first5=Marcus}}
&lt;/ref&gt;&lt;ref name=":5" /&gt; and provide a [[Closed-form expression|closed form]] way to evaluate Bayesian neural networks. They are a [[Gaussian process]] [[probability distribution]] which describes the distribution over predictions made by the corresponding Bayesian neural network. Computation in artificial neural networks is usually organized into sequential layers of [[artificial neuron]]s. The number of neurons in a layer is called the layer width. The equivalence between NNGPs and Bayesian neural networks occurs when the layers in a Bayesian neural network become infinitely wide (see figure). This 
[[Large width limits of neural networks|large width limit]] is of practical interest, since finite width neural networks typically perform strictly better as layer width is increased.&lt;ref name=":7"&gt;
{{Cite journal|last1=Novak|first1=Roman|last2=Bahri|first2=Yasaman|last3=Abolafia|first3=Daniel A.|last4=Pennington|first4=Jeffrey|last5=Sohl-Dickstein|first5=Jascha|date=2018-02-15|title=Sensitivity and Generalization in Neural Networks: an Empirical Study|url=https://openreview.net/forum?id=HJC2SzZCW|journal=International Conference on Learning Representations|arxiv=1802.08760|bibcode=2018arXiv180208760N}}&lt;/ref&gt;&lt;ref name=":8"&gt;
{{Cite journal|last1=Canziani|first1=Alfredo|last2=Paszke|first2=Adam|last3=Culurciello|first3=Eugenio|date=2016-11-04|title=An Analysis of Deep Neural Network Models for Practical Applications|url=https://openreview.net/forum?id=Bygq-H9eg|arxiv=1605.07678|bibcode=2016arXiv160507678C}}&lt;/ref&gt;&lt;ref name=":1" /&gt;&lt;ref name=":6"&gt;
{{Cite journal|last1=Neyshabur|first1=Behnam|last2=Li|first2=Zhiyuan|last3=Bhojanapalli|first3=Srinadh|last4=LeCun|first4=Yann|last5=Srebro|first5=Nathan|date=2019|title=Towards understanding the role of over-parametrization in generalization of neural networks|journal=International Conference on Learning Representations|arxiv=1805.12076|bibcode=2018arXiv180512076N}}
&lt;/ref&gt;

The NNGP also appears in several other contexts: it describes the distribution over predictions made by wide non-Bayesian artificial neural networks after random initialization of their parameters, but before training; it appears as a term in [[neural tangent kernel]] prediction equations; it is used in [[deep information propagation]] to characterize whether hyperparameters and architectures will be trainable.&lt;ref name=":10"&gt;
{{Cite journal|last1=Schoenholz|first1=Samuel S.|last2=Gilmer|first2=Justin|last3=Ganguli|first3=Surya|last4=Sohl-Dickstein|first4=Jascha|date=2016|title=Deep information propagation|journal=International Conference on Learning Representations|arxiv=1611.01232}}
&lt;/ref&gt; 
It is related to other [[large width limits of neural networks]].

== A cartoon illustration ==
[[File:Wide neural networks are described by a Gaussian process svg.svg|alt=|thumb|406x406px|When parameters &lt;math&gt;\theta&lt;/math&gt; of an infinite width network are sampled repeatedly from their prior &lt;math&gt;p(\theta)&lt;/math&gt;, the resulting distribution over network outputs is described by a Gaussian process.]]
Every setting of a neural network's parameters &lt;math&gt;\theta&lt;/math&gt; corresponds to a specific function computed by the neural network. A prior distribution &lt;math&gt;p(\theta)&lt;/math&gt; over neural network parameters therefore corresponds to a prior distribution over functions computed by the network. As neural networks are made infinitely wide, this distribution over functions converges to a Gaussian process for many architectures.

The figure to the right plots the one-dimensional outputs &lt;math&gt;z^L(\cdot;\theta)&lt;/math&gt; of a neural network for two inputs &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;x^*&lt;/math&gt; against each other. The black dots show the function computed by the neural network on these inputs for random draws of the parameters from &lt;math&gt;p(\theta)&lt;/math&gt;. The red lines are iso-probability contours for the joint distribution over network outputs &lt;math&gt;z^L(x;\theta)&lt;/math&gt; and &lt;math&gt;z^L(x^*;\theta)&lt;/math&gt; induced by &lt;math&gt;p(\theta)&lt;/math&gt;. This is the distribution in function space corresponding to the distribution &lt;math&gt;p(\theta)&lt;/math&gt; in parameter space, and the black dots are samples from this distribution. For infinitely wide neural networks, since the distribution over functions computed by the neural network is a Gaussian process, the joint distribution over network outputs is a multivariate Gaussian for any finite set of network inputs.

The notation used in this section is the same as the notation used below to derive the correspondence between NNGPs and fully connected networks, and more details can be found there.

== Architectures which correspond to an NNGP ==
The equivalence between infinitely wide Bayesian neural networks and NNGPs has been shown to hold for: single hidden layer&lt;ref name=":2"&gt;{{Citation|last=Neal|first=Radford M.|chapter=Priors for Infinite Networks|date=1996|title=Bayesian Learning for Neural Networks|series=Lecture Notes in Statistics|volume=118|pages=29–53|publisher=Springer New York|doi=10.1007/978-1-4612-0745-0_2|isbn=978-0-387-94724-2}}&lt;/ref&gt; and deep&lt;ref name=":0" /&gt;&lt;ref name=":3"&gt;
{{cite journal |last1=G. de G. Matthews |first1=Alexander |last2=Rowland |first2=Mark |last3=Hron |first3=Jiri |last4=Turner |first4=Richard E. |last5=Ghahramani | first5=Zoubin |date=2017 |title=Gaussian Process Behaviour in Wide Deep Neural Networks |journal=International Conference on Learning Representations |arxiv=1804.11271 |bibcode=2018arXiv180411271M }}
&lt;/ref&gt; [[fully connected network]]s as the number of units per layer is taken to infinity; [[convolutional neural network]]s as the number of channels is taken to infinity;&lt;ref name=":1"&gt;
{{cite journal |last1=Novak |first1=Roman |last2=Xiao |first2=Lechao |last3=Lee |first3=Jaehoon |last4=Bahri |first4=Yasaman |last5=Yang | first5=Greg |last6=Abolafia | first6=Dan | last7= Pennington |first7=Jeffrey |last8=Sohl-Dickstein |first8=Jascha |date=2018 |title=Bayesian Deep Convolutional Networks with Many Channels are Gaussian Processes |journal=International Conference on Learning Representations |arxiv=1810.05148 |bibcode=2018arXiv181005148N }}&lt;/ref&gt;&lt;ref name=":4"&gt;
{{cite journal |last1=Garriga-Alonso |first1= Adrià |last2= Aitchison |first2= Laurence |last3=Rasmussen |first3=Carl Edward |date=2018 |title=Deep Convolutional Networks as shallow Gaussian Processes |journal=International Conference on Learning Representations |arxiv= 1808.05587 |bibcode= 2018arXiv180805587G }}&lt;/ref&gt;&lt;ref name=":9"&gt;
{{cite arxiv |last1=Borovykh |first1=Anastasia |date=2018 |title=A Gaussian Process perspective on Convolutional Neural Networks |class=stat.ML |eprint=1810.10798 }}
&lt;/ref&gt; transformer networks as the number of attention heads is taken to infinity;&lt;ref&gt;{{Cite journal|last1=Hron|first1=Jiri|last2=Bahri|first2=Yasaman|last3=Sohl-Dickstein|first3=Jascha|last4=Novak|first4=Roman|date=2020-06-18|title=Infinite attention: NNGP and NTK for deep attention networks|journal=International Conference on Machine Learning|volume=2020|arxiv=2006.10540|bibcode=2020arXiv200610540H}}&lt;/ref&gt; [[Recurrent neural network|recurrent networks]] as the number of units is taken to infinity.&lt;ref name=":5" /&gt;
In fact, this NNGP correspondence holds for almost any architecture: Generally, if an architecture can be expressed solely via matrix multiplication and coordinatewise nonlinearities (i.e. a [[tensor program]]), then it has an infinite-width GP.&lt;ref name=":5"&gt;
{{cite journal |last1=Yang |first1=Greg |date=2019 |title=Tensor Programs I: Wide Feedforward or Recurrent Neural Networks of Any Architecture are Gaussian Processes |url=https://papers.nips.cc/paper/9186-wide-feedforward-or-recurrent-neural-networks-of-any-architecture-are-gaussian-processes.pdf |journal=Advances in Neural Information Processing Systems |arxiv=1910.12478 |bibcode=2019arXiv191012478Y }}
&lt;/ref&gt;
This in particular includes all feedforward or recurrent neural networks composed of multilayer perceptron, recurrent neural networks (e.g. [[LSTM]]s, [[Gated recurrent unit|GRUs]]), (nD or graph) [[Convolutional neural network|convolution]], pooling, skip connection, attention, [[batch normalization]], and/or layer normalization.

== Correspondence between an infinitely wide fully connected network and a Gaussian process ==

This section expands on the correspondence between infinitely wide neural networks and Gaussian processes for the specific case of a fully connected architecture. It provides a proof sketch outlining why the correspondence holds, and introduces the specific functional form of the NNGP for fully connected networks. The proof sketch closely follows the approach in ''Novak,'' ''et al., 2018''.&lt;ref name=":1" /&gt;

=== Network architecture specification ===

[[File:Fully connected architecture.pdf|thumb|An NNGP is derived which is equivalent to a Bayesian neural network with this fully connected architecture.]]

Consider a fully connected artificial neural network with inputs &lt;math&gt;x&lt;/math&gt;, parameters &lt;math&gt;\theta&lt;/math&gt; consisting of weights &lt;math&gt;W^l&lt;/math&gt; and biases &lt;math&gt;b^l&lt;/math&gt; for each layer &lt;math&gt;l&lt;/math&gt; in the network, pre-activations (pre-nonlinearity) &lt;math&gt;z^l&lt;/math&gt;, activations (post-nonlinearity) &lt;math&gt;y^l&lt;/math&gt;, pointwise nonlinearity &lt;math&gt;\phi(\cdot)&lt;/math&gt;, and layer widths &lt;math&gt;n^l&lt;/math&gt;. For simplicity, the width &lt;math&gt;n^{L+1}&lt;/math&gt; of the readout vector &lt;math&gt;z^L&lt;/math&gt; is taken to be 1. The parameters of this network have a prior distribution &lt;math&gt;p(\theta)&lt;/math&gt;, which consists of an isotropic Gaussian for each weight and bias, with the variance of the weights scaled inversely with layer width. This network is illustrated in the figure to the right, and described by the following set of equations:

:&lt;math block=""&gt;
\begin{align}
x &amp;\equiv \text{input} \\
y^l(x) &amp;= \left\{\begin{array}{lcl} 
x &amp; &amp; l = 0 \\
\phi\left(z^{l-1}(x)\right) &amp; &amp; l &gt; 0 
\end{array}\right. \\
z^l_i(x) &amp;= \sum_j W^l_{ij} y^l_j(x) + b^l_i \\
W^l_{ij} &amp;\sim \mathcal N\left( 0, \frac{\sigma^2_w}{n^l} \right) \\
b^l_i &amp;\sim \mathcal N\left( 0,\sigma^2_b \right) \\
\phi(\cdot) &amp;\equiv \text{nonlinearity} \\
y^l(x), z^{l-1}(x) &amp;\in \mathbb R^{n^l \times 1} \\
n^{L+1} &amp;= 1 \\
\theta &amp;= \left\{ W^0, b^0, \dots, W^L, b^L \right\} 
\end{align}
&lt;/math&gt;

=== &lt;math&gt;z^l | y^l&lt;/math&gt; is a Gaussian process ===

We first observe that the pre-activations &lt;math&gt;z^l&lt;/math&gt; are described by a Gaussian process conditioned on the preceding activations &lt;math&gt;y^l&lt;/math&gt;. This result holds even at finite width. 
Each pre-activation &lt;math&gt;z^l_i&lt;/math&gt; is a weighted sum of Gaussian random variables, corresponding to the weights &lt;math&gt;W^l_{ij}&lt;/math&gt; and biases &lt;math&gt;b^l_i&lt;/math&gt;, where the coefficients for each of those Gaussian variables are the preceding activations &lt;math&gt;y^l_j&lt;/math&gt;. 
Because they are a weighted sum of zero-mean Gaussians, the &lt;math&gt;z^l_i&lt;/math&gt; are themselves zero-mean Gaussians (conditioned on the coefficients &lt;math&gt;y^l_j&lt;/math&gt;).
Since the &lt;math&gt;z^l&lt;/math&gt; are jointly Gaussian for any set of &lt;math&gt;y^l&lt;/math&gt;, they are described by a Gaussian process conditioned on the preceding activations &lt;math&gt;y^l&lt;/math&gt;. 
The covariance or kernel of this Gaussian process depends on the weight and bias variances &lt;math&gt;\sigma_w^2&lt;/math&gt; and &lt;math&gt;\sigma_b^2&lt;/math&gt;, as well as the second moment matrix &lt;math&gt;K^l&lt;/math&gt; of the preceding activations &lt;math&gt;y^l&lt;/math&gt;,

:&lt;math block=""&gt;
\begin{align}
z^l_i \mid y^l &amp;\sim \mathcal{GP}\left( 0, \sigma^2_w K^l + \sigma^2_b \right) \\
K^l(x, x') &amp;= \frac{1}{n^l} \sum_i y_i^l(x) y_i^l(x')
\end{align}
&lt;/math&gt;

The effect of the weight scale &lt;math&gt;\sigma^2_w&lt;/math&gt; is to rescale the contribution to the covariance matrix from &lt;math&gt;K^l&lt;/math&gt;, while the bias is shared for all inputs, and so &lt;math&gt;\sigma_b^2&lt;/math&gt; makes the &lt;math&gt;z^l_i&lt;/math&gt; for different datapoints more similar and makes the covariance matrix more like a constant matrix.

=== &lt;math&gt;z^l | K^l&lt;/math&gt; is a Gaussian process ===

The pre-activations &lt;math&gt;z^l&lt;/math&gt; only depend on &lt;math&gt;y^l&lt;/math&gt; through its second moment matrix &lt;math&gt;K^l&lt;/math&gt;. Because of this, we can say that &lt;math&gt;z^l&lt;/math&gt; is a Gaussian process conditioned on &lt;math&gt;K^l&lt;/math&gt;, rather than conditioned on &lt;math&gt;y^l&lt;/math&gt;,

:&lt;math block=""&gt;
\begin{align}
z^l_i \mid K^l &amp;\sim \mathcal{GP}\left( 0, \sigma^2_w K^l + \sigma^2_b \right).
\end{align}
&lt;/math&gt;

=== As layer width &lt;math&gt;n^l \rightarrow \infty&lt;/math&gt;, &lt;math&gt;K^l \mid K^{l-1}&lt;/math&gt; becomes deterministic ===

As previously defined, &lt;math&gt;K^l&lt;/math&gt; is the second moment matrix of &lt;math&gt;y^l&lt;/math&gt;. Since &lt;math&gt;y^l&lt;/math&gt; is the activation vector after applying the nonlinearity &lt;math&gt;\phi&lt;/math&gt;, it can be replaced by &lt;math&gt;\phi\left(z^{l-1}\right)&lt;/math&gt;, resulting in a modified equation expressing &lt;math&gt;K^l&lt;/math&gt; for &lt;math&gt;l&gt;0&lt;/math&gt; in terms of &lt;math&gt;z^{l-1}&lt;/math&gt;,

:&lt;math block=""&gt;
\begin{align}
K^l(x, x') &amp;= 
\frac{1}{n^l} \sum_i \phi\left( z^{l-1}_i(x) \right) \phi\left( z^{l-1}_i(x') \right)
.
\end{align}
&lt;/math&gt;

We have already determined that &lt;math&gt;z^{l-1} | K^{l-1}&lt;/math&gt; is a Gaussian process. This means that the sum defining &lt;math&gt;K^l&lt;/math&gt; is an average over &lt;math&gt;n^l&lt;/math&gt; samples from a Gaussian process which is a function of &lt;math&gt;K^{l-1}&lt;/math&gt;,

&lt;math block=""&gt;
\begin{align}
\left\{ z^{l-1}_i(x), z^{l-1}_i(x') \right\} &amp;\sim \mathcal{GP}\left( 0, \sigma^2_w K^{l-1} + \sigma^2_b \right)
.
\end{align}
&lt;/math&gt;

As the layer width &lt;math&gt;n^l&lt;/math&gt; goes to infinity, this average over &lt;math&gt;n^l&lt;/math&gt; samples from the Gaussian process can be replaced with an integral over the Gaussian process:

:&lt;math block=""&gt;
\begin{align}
\lim_{n^l \rightarrow \infty} K^l(x, x') &amp;= \int dz dz' \phi( z ) \phi( z' ) \mathcal{N}\left( \left[\begin{array}{c} 
z \\
z' 
\end{array}\right]; 0, \sigma^2_w \left[ 
\begin{array}{cc} 
K^{l-1}(x, x) &amp; K^{l-1}(x, x') \\
K^{l-1}(x', x) &amp; K^{l-1}(x', x') 
\end{array}
\right] + \sigma^2_b \right) 
\end{align}
&lt;/math&gt;

So, in the infinite width limit the second moment matrix &lt;math&gt;K^l&lt;/math&gt; for each pair of inputs &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;x'&lt;/math&gt; can be expressed as an integral over a 2d Gaussian, of the product of &lt;math&gt;\phi(z)&lt;/math&gt; and &lt;math&gt;\phi(z')&lt;/math&gt;. 
There are a number of situations where this has been solved analytically, such as when &lt;math&gt;\phi(\cdot)&lt;/math&gt; is a [[Rectifier (neural networks)|ReLU]]&lt;ref&gt;
{{cite journal|last1=Cho|first1=Youngmin|last2=Saul|first2=Lawrence K.|date=2009|title=Kernel Methods for Deep Learning|url=http://papers.nips.cc/paper/3628-kernel-methods-for-deep-|journal=Neural Information Processing Systems|pages=342–350}}
&lt;/ref&gt; or [[error function]]&lt;ref name=":11" /&gt; nonlinearity.
Even when it can't be solved analytically, since it is a 2d integral it can generally be efficiently computed numerically.&lt;ref name=":0" /&gt;
This integral is deterministic, so &lt;math&gt;K^l | K^{l-1}&lt;/math&gt; is deterministic.

For shorthand, we define a functional &lt;math&gt;F&lt;/math&gt;, which corresponds to computing this 2d integral for all pairs of inputs, and which maps &lt;math&gt;K^{l-1}&lt;/math&gt; into &lt;math&gt;K^l&lt;/math&gt;,

:&lt;math block=""&gt;
\begin{align}
\lim_{n^l \rightarrow \infty} K^l
&amp;= F\left(
K^{l-1}
\right)
.
\end{align}
&lt;/math&gt;

=== &lt;math&gt;z^L \mid x&lt;/math&gt; is an NNGP ===

By recursively applying the observation that &lt;math&gt;K^l \mid K^{l-1}&lt;/math&gt; is deterministic as &lt;math&gt;n^l \rightarrow \infty&lt;/math&gt;, &lt;math&gt;K^L&lt;/math&gt; can be written as a deterministic function of &lt;math&gt;K^0&lt;/math&gt;,

:&lt;math block=""&gt;
\begin{align}
\lim_{\min\left( n^1, \dots, n^L\right) \rightarrow \infty} K^L
&amp;= F \circ F
\cdots
\left(
K^{0}
\right) = F^L\left(K^0\right)
,
\end{align}
&lt;/math&gt;

where &lt;math&gt;F^L&lt;/math&gt; indicates applying the functional &lt;math&gt;F&lt;/math&gt; sequentially &lt;math&gt;L&lt;/math&gt; times. 
By combining this expression with the further observations that the input layer second moment matrix &lt;math&gt;K^0(x,x')=\frac{1}{n^0} \sum_i x_i x'_i&lt;/math&gt; is a deterministic function of the input &lt;math&gt;x&lt;/math&gt;, and that &lt;math&gt;z^L | K^L&lt;/math&gt; is a Gaussian process, the output of the neural network can be expressed as a Gaussian process in terms of its input,

:&lt;math block=""&gt;
\begin{align}
z^L_i(x) &amp;\sim \mathcal{GP}\left( 0, \sigma^2_w F^L\left(K^0\right) + \sigma^2_b \right)
.
\end{align}
&lt;/math&gt;

== Software libraries ==
[https://github.com/google/neural-tangents Neural Tangents] is a [[free and open-source]] [[Python (programming language)|Python]] library used for computing and doing inference with the NNGP and [[neural tangent kernel]] corresponding to various common ANN architectures.&lt;ref&gt;{{Citation|last1=Novak|first1=Roman|title=Neural Tangents: Fast and Easy Infinite Neural Networks in Python|date=2019-12-05|work=International Conference on Learning Representations (ICLR)|volume=2020|arxiv=1912.02803|bibcode=2019arXiv191202803N|last2=Xiao|first2=Lechao|last3=Hron|first3=Jiri|last4=Lee|first4=Jaehoon|last5=Alemi|first5=Alexander A.|last6=Sohl-Dickstein|first6=Jascha|last7=Schoenholz|first7=Samuel S.}}&lt;/ref&gt;

== References ==
&lt;!-- Inline citations added to your article will automatically display here. See en.wikipedia.org/wiki/WP:REFB for instructions on how to add citations. --&gt;
{{reflist}}

[[Category:Computer science]]
[[Category:Bayesian networks]]
[[Category:Machine learning]]
[[Category:Deep learning]]
[[Category:Bayesian statistics]]
[[Category:Artificial neural networks]]
[[Category:Kernel methods for machine learning]]</text>
      <sha1>3yck2xeuevgydedzwrv99gvjr7j4c2t</sha1>
    </revision>
  </page>
  <page>
    <title>Automated Pain Recognition</title>
    <ns>0</ns>
    <id>59891758</id>
    <revision>
      <id>984636816</id>
      <parentid>983896100</parentid>
      <timestamp>2020-10-21T06:18:12Z</timestamp>
      <contributor>
        <username>WikiCleanerBot</username>
        <id>18872885</id>
      </contributor>
      <minor/>
      <comment>v2.03b - [[User:WikiCleanerBot#T20|Bot T20 CW#61]] - [[WP:WCW]] project (Reference before punctuation)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="12832" xml:space="preserve">'''Automated Pain Recognition (APR''') is a method for objectively measuring [[pain]] and at the same time represents an interdisciplinary research area that comprises elements of [[medicine]], [[psychology]], [[psychobiology]], and [[computer science]]. The focus is on computer-aided objective recognition of pain, implemented on the basis of [[machine learning]].&lt;ref&gt;{{Cite web|url=https://www.swp.de/suedwesten/staedte/ulm/schmerzen-messbar-machen-23426123.html|title=Forschung: Schmerzen messbar machen|last=GmbH|first=Südwest Presse Online-Dienste|date=2017-04-11|website=swp.de|language=de|access-date=2020-04-20}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.aerztezeitung.de/Medizin/Kuenstliche-Intelligenz-erkennt-den-Schmerz-296050.html|title=Künstliche Intelligenz erkennt den Schmerz|website=AerzteZeitung.de|language=de|access-date=2020-04-20}}&lt;/ref&gt;

Automated pain recognition allows for the valid, reliable detection and monitoring of pain in people who are unable to communicate verbally. The underlying machine learning processes are trained and validated in advance by means of unimodal or multimodal body signals. Signals used to detect pain may include [[Facial expression|facial expressions]] or [[Gesture|gestures]] and may also be of a ([[Psychophysiological|psycho]]-)[[physiological]] or [[paralinguistic]] nature. To date, the focus has been on identifying pain intensity, but visionary efforts are also being made to recognize the quality, site, and temporal course of pain. 

However, the clinical implementation of this approach is a controversial topic in the field of pain research. Critics of automated pain recognition argue that pain diagnosis can only be performed subjectively by humans. 
== Background ==
Pain diagnosis under conditions where verbal reporting is restricted - such as in verbally and/or cognitively impaired people or in patients who are sedated or mechanically ventilated - is based on behavioral observations by trained professionals.&lt;ref&gt;{{Cite book|title=Fundamentals of pain medicine|others=Cheng, Jianguo (Professor of anesthesiology),, Rosenquist, Richard W.|date = 8 February 2018|isbn=978-3-319-64922-1|location=Cham, Switzerland|oclc=1023425599}}&lt;/ref&gt; However, all known observation procedures (e.g., Zurich Observation Pain Assessment&lt;ref name=":1"&gt;Elisabeth Handel: ''Praxishandbuch ZOPA: Schmerzeinschätzung bei Patienten mit kognitiven und/oder Bewusstseinsbeeinträchtigungen.'' Huber, Bern 2010, {{ISBN|978-3-456-84785-6}}.&lt;/ref&gt; (ZOPA)); [[Pain Assessment in Advanced Dementia (PAINAD)|Pain Assessment in Advanced Dementia]] Scale (PAINAD)) require a great deal of specialist expertise. These procedures can be made more difficult by perception- and interpretation-related misjudgments on the part of the observer. With regard to the differences in design, methodology, evaluation sample, and conceptualization of the phenomenon of pain, it is difficult to compare the quality criteria of the various tools. Even if trained personnel could theoretically record pain intensity several times a day using observation instruments, it would not be possible to measure it every minute or second. In this respect, the goal of automated pain recognition is to use valid, robust pain response patterns that can be recorded multimodally for a temporally dynamic, high-resolution, automated pain intensity recognition system. 
== Procedure ==
For automated pain recognition, pain-relevant parameters are usually recorded using [[non-invasive]] sensor technology, which captures data on the (physical) responses of the person in pain. This can be achieved with camera technology that captures facial expressions, gestures, or posture, while audio sensors record paralinguistic features. (Psycho-)physiological information such as [[muscle tone]] and [[heart rate]] can be collected via [[Bipotential|biopotential]] sensors ([[Electrode|electrodes]]).&lt;ref&gt;{{Cite book|last=Anbarjafari, Gholamreza|title=Machine learning for face, emotion, and pain recognition|others=Gorbova, Jelena,, Hammer, Rain Eric,, Rasti, Pejman,, Noroozi, Fatemeh,, Society of Photo-optical Instrumentation Engineers|year=2018|isbn=978-1-5106-1986-9|location=Bellingham, Washington|oclc=1035460960}}&lt;/ref&gt;

Pain recognition requires the extraction of meaningful characteristics or patterns from the data collected. This is achieved using machine learning techniques that are able to provide an assessment of the pain after training (learning), e.g., "no pain," "mild pain," or "severe pain." 
== Parameters ==
Although the phenomenon of pain comprises different components (sensory discriminative, affective (emotional), cognitive, vegetative, and (psycho-)motor),&lt;ref&gt;{{citation|surname1=Henrik Kessler|title=Kurzlehrbuch Medizinische Psychologie und Soziologie|edition=3|publisher=Thieme|location=Stuttgart/New York|at=p.&amp;nbsp;34|isbn=978-3-13-136423-4|date=2015|language=German
}}&lt;/ref&gt; automated pain recognition currently relies on the measurable parameters of pain responses. These can be divided roughly into the two main categories of "''physiological responses''" and "''behavioral responses''".
=== Physiological responses ===
In humans, pain almost always initiates [[Autonomic nervous system|autonomic nervous]] processes that are reflected measurably in various physiological signals.&lt;ref&gt;{{Cite book|last=Birbaumer, Niels.|title=Biologische Psychologie : mit 41 Tabellen : [Bonusmaterial im Web]|date=2006|publisher=Springer|others=Schmidt, Robert F.|isbn=978-3-540-25460-7|edition=6., vollst. überarb. und erg. Aufl|location=Heidelberg|oclc=162267511}}&lt;/ref&gt; 
==== Physiological signals ====
Measurements can include [[electrodermal activity]] (EDA, also skin conductance), [[electromyography]] (EMG), [[Electrocardiography|electrocardiogram]] (ECG), blood volume pulse (BVP), [[electroencephalogram]] (EEG), [[Respiration of human|respiration]], and [[body temperature]],&lt;ref&gt;S. Gruss et al.: ''Pain Intensity Recognition Rates via Biopotential Feature Patterns with Support Vector Machines.'' In: ''PLoS One.'' Vol. 10, No. 10, 2015, S. 1–14, [[doi:10.1371/journal.pone.0140330]].&lt;/ref&gt;&lt;ref&gt;S. Walter et al.: ''Automatic pain quantification using autonomic parameters.'' In: ''Psychol. Neurosci.'' Nol. 7, No. 3, 2014, S. 363–380, [[doi:10.3922/j.psns.2014.041]].&lt;/ref&gt; which are regulatory mechanisms of the [[Sympathetic nervous system|sympathetic]] and [[Parasympathetic nervous system|parasympathetic]] systems. Physiological signals are mainly recorded using special non-invasive surface electrodes (for EDA, EMG, ECG, and EEG), a blood volume pulse sensor (BVP), a respiratory belt (respiration), and a thermal sensor (body temperature). [[Endocrinological]] and [[immunological]] parameters can also be recorded, but this requires measures that are somewhat invasive (e.g., blood sampling). 
=== Behavioral responses ===
Behavioral responses to pain fulfil two functions: protection of the body (e.g., through protective [[Reflex|reflexes]]) and external communication of the pain (e.g., as a cry for help). The responses are particularly evident in facial expressions, gestures, and paralinguistic features.
==== Facial expressions ====
Behavioral signals captured comprise facial expression patterns (expressive behavior), which are measured with the aid of video signals. Facial expression recognition is based on the everyday clinical observation that pain often manifests itself in the patient's facial expressions but that this is not necessarily always the case, since facial expressions can be inhibited through self-control. Despite the possibility that facial expressions may be influenced consciously, facial expression behavior represents an essential source of information for pain diagnosis and is thus also a source of information for automatic pain recognition. One advantage of video-based facial expression recognition is the contact-free measurement of the face, provided that it can be captured on video, which is not possible in every position (e.g., lying face down) or may be limited by bandages covering the face. Facial expression analysis relies on rapid, spontaneous, and temporary changes in neuromuscular activity that lead to visually detectable changes in the face.

==== Gestures ====
Gestures are also captured predominantly using non-contact camera technology. Motor pain responses vary and are strongly dependent on the type and cause of the pain. They range from abrupt protective reflexes (e.g., spontaneous retraction of extremities or doubling up) to [[Psychomotor agitation|agitation]] (pathological restlessness) and avoidance behavior (hesitant, cautious movements). 
==== Paralinguistic features of language ====
Among other things, pain leads to nonverbal linguistic behavior that manifests itself in sounds such as sighing, gasping, moaning, whining, etc. Paralinguistic features are usually recorded using highly sensitive microphones. 
== Algorithms ==
After the recording, pre-processing (e.g., filtering), and extraction of relevant [[Feature (machine learning)|features]], an optional [[Information Fusion|information fusion]] can be performed. During this process, modalities from different signal sources are merged to generate new or more precise knowledge. 

The pain is classified using machine learning processes. The method chosen has a significant influence on the [[Accuracy and precision|recognition rate]] and depends greatly on the quality and granularity of the underlying data. Similar to the field of [[affective computing]],&lt;ref&gt;{{Cite book|last=Picard, Rosalind W.|title=Affective computing|date=2000|publisher=MIT Press|isbn=0-262-66115-2|edition=1st MIT Press pbk.|location=Cambridge, Mass.|oclc=45432790}}&lt;/ref&gt; the following [[Classifier (machine learning)|classifiers]] are currently being used:&lt;br&gt;

''Support Vector Machine (SVM''): The goal of an [[Support-vector machine|SVM]] is to find a clearly defined optimal hyperplane with the greatest minimal distance to two (or more) classes to be separated. The hyperplane acts as a decision function for classifying an unknown pattern.

''Random Forest (RF''): [[Random forest|RF]] is based on the composition of random, uncorrelated decision trees. An unknown pattern is judged individually by each tree and assigned to a class. The final classification of the patterns by the RF is then based on a majority decision.

''k-Nearest Neighbors (k-NN''): The [[K-nearest neighbors algorithm|k-NN]] algorithm classifies an unknown object using the class label that most commonly classifies the k neighbors closest to it. Its neighbors are determined using a selected similarity measure (e.g., Euclidean distance, Jaccard coefficient, etc.).

''Artificial neural networks (ANNs''): [[Artificial neural network|ANNs]] are inspired by biological neural networks and model their organizational principles and processes in a very simplified manner. Class patterns are learned by adjusting the weights of the individual neuronal connections.
[[File:Simplified automated pain recognition process.png|none|thumb|440x440px|Simplified automated pain recognition process.]] 

== Databases ==
In order to classify pain in a valid manner, it is necessary to create representative, reliable, and valid pain [[Database|databases]] that are available to the machine learner for training. An ideal database would be sufficiently large and would consist of natural (not experimental), high-quality pain responses. However, natural responses are difficult to record and can only be obtained to a limited extent; in most cases they are characterized by suboptimal quality. The databases currently available therefore contain experimental or [[Quasi-experiment|quasi-experimental]] pain responses, and each database is based on a different pain model. The following list shows a selection of the most relevant pain databases (last updated: April 2020):&lt;ref&gt;{{Cite journal|last=Werner|first=Philipp|last2=Lopez-Martinez|first2=Daniel|last3=Walter|first3=Steffen|last4=Al-Hamadi|first4=Ayoub|last5=Gruss|first5=Sascha|last6=Picard|first6=Rosalind|date=2019|title=Automatic Recognition Methods Supporting Pain Assessment: A Survey|journal=IEEE Transactions on Affective Computing|pages=1|doi=10.1109/TAFFC.2019.2946774|issn=1949-3045}}&lt;/ref&gt;
* UNBC-McMaster Shoulder Pain
* BioVid Heat Pain
* EmoPain
* SenseEmotion
* X-ITE Pain

== References ==
&lt;references /&gt;
== External links ==
*[https://www.uniklinik-ulm.de/psychosomatische-medizin-und-psychotherapie/forschung/sektion-medizinische-psychologie/forschungsbereiche/schmerz-emotionen.html Automated Pain Research Group at the University of Ulm, Germany]


[[Category:Pain]]
[[Category:Pattern recognition]]
[[Category:Machine learning]]
[[Category:Pain management]]
[[Category:Classification algorithms]]
[[Category:Medicine]]</text>
      <sha1>o0xj3dwy2rlb5xcp9qtr2sb2cwok5tc</sha1>
    </revision>
  </page>
  <page>
    <title>Under-fitting</title>
    <ns>0</ns>
    <id>63723208</id>
    <redirect title="Overfitting" />
    <revision>
      <id>952285675</id>
      <timestamp>2020-04-21T13:36:45Z</timestamp>
      <contributor>
        <username>Nbarth</username>
        <id>570614</id>
      </contributor>
      <comment>init, redirect</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="144" xml:space="preserve">#REDIRECT [[Overfitting]]

{{R from antonym}}

[[Category:Statistical inference]]
[[Category:Regression analysis]]
[[Category:Machine learning]]</text>
      <sha1>0z68tgo2qipeik2agkvkp70luy4m4p9</sha1>
    </revision>
  </page>
  <page>
    <title>Underfitting</title>
    <ns>0</ns>
    <id>41110372</id>
    <redirect title="Overfitting" />
    <revision>
      <id>952285722</id>
      <parentid>582099637</parentid>
      <timestamp>2020-04-21T13:37:00Z</timestamp>
      <contributor>
        <username>Nbarth</username>
        <id>570614</id>
      </contributor>
      <comment>R from antonym</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="144" xml:space="preserve">#REDIRECT [[Overfitting]]

{{R from antonym}}

[[Category:Statistical inference]]
[[Category:Regression analysis]]
[[Category:Machine learning]]</text>
      <sha1>0z68tgo2qipeik2agkvkp70luy4m4p9</sha1>
    </revision>
  </page>
  <page>
    <title>Cancer Likelihood in Plasma</title>
    <ns>0</ns>
    <id>63729638</id>
    <revision>
      <id>974968848</id>
      <parentid>968963797</parentid>
      <timestamp>2020-08-26T00:42:09Z</timestamp>
      <contributor>
        <username>Funandtrvl</username>
        <id>2966869</id>
      </contributor>
      <comment>removed [[Category:Biology WikiProjects]] using [[WP:HC|HotCat]] wrong category</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="7202" xml:space="preserve">
'''Cancer Likelihood in Plasma''' (CLiP) refers to a set of [[ensemble learning]] methods for integrating various genomic features useful for the noninvasive detection of early cancers from blood [[Blood plasma|plasma]].&lt;ref&gt;{{Cite journal|last=Polikar|first=Robi|date=2009-01-11|title=Ensemble learning|url=http://www.scholarpedia.org/article/Ensemble_learning|journal=Scholarpedia|language=en|volume=4|issue=1|pages=2776|bibcode=2009SchpJ...4.2776P|doi=10.4249/scholarpedia.2776|issn=1941-6016|doi-access=free}}&lt;/ref&gt; An application of this technique for early detection of [[lung cancer]] (Lung-CLiP) was originally described by Chabon et al (2020)&lt;ref name=":0"&gt;{{Cite journal|last1=Chabon|first1=Jacob J.|last2=Hamilton|first2=Emily G.|last3=Kurtz|first3=David M.|last4=Esfahani|first4=Mohammad S.|last5=Moding|first5=Everett J.|last6=Stehr|first6=Henning|last7=Schroers-Martin|first7=Joseph|last8=Nabet|first8=Barzin Y.|last9=Chen|first9=Binbin|last10=Chaudhuri|first10=Aadel A.|last11=Liu|first11=Chih Long|s2cid=214647986|date=April 2020|title=Integrating genomic features for non-invasive early lung cancer detection|url=https://www.nature.com/articles/s41586-020-2140-0|journal=Nature|language=en|volume=580|issue=7802|pages=245–251|doi=10.1038/s41586-020-2140-0|pmid=32269342|bibcode=2020Natur.580..245C|issn=1476-4687}}&lt;/ref&gt; from the labs of [[Alizadeh|Ash Alizadeh]] and Max Diehn at [[Stanford University|Stanford]].&lt;ref&gt;{{Cite web|url=https://clip.stanford.edu/|title=CLiP|website=clip.stanford.edu|access-date=2020-04-22}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.genomeweb.com/cancer/stanford-team-debuts-new-liquid-biopsy-lung-cancer-screening-method|title=Stanford Team Debuts New Liquid Biopsy Lung Cancer Screening Method|website=GenomeWeb|language=en-us|access-date=2020-04-22}}&lt;/ref&gt;

This method relies on several improvements to cancer personalized profiling by deep sequencing ([[CAPP-Seq]])&lt;ref&gt;{{Cite journal|last1=Newman|first1=Aaron M.|last2=Bratman|first2=Scott V.|last3=To|first3=Jacqueline|last4=Wynne|first4=Jacob F.|last5=Eclov|first5=Neville C. W.|last6=Modlin|first6=Leslie A.|last7=Liu|first7=Chih Long|last8=Neal|first8=Joel W.|last9=Wakelee|first9=Heather A.|last10=Merritt|first10=Robert E.|last11=Shrager|first11=Joseph B.|date=May 2014|title=An ultrasensitive method for quantitating circulating tumor DNA with broad patient coverage|journal=Nature Medicine|language=en|volume=20|issue=5|pages=548–554|doi=10.1038/nm.3519|pmid=24705333|pmc=4016134|issn=1546-170X}}&lt;/ref&gt; for analysis of [[circulating tumor DNA]] (ctDNA). The CLiP technique integrates multiple distinctive genomic features of a cancer of interest findings within a machine-learning framework for cancer detection. For example, studies have shown that the majority of somatic mutations found in cell-free DNA (cfDNA) are not tumor derived, but instead reflect [[Clonal hematopoiesis|clonal hematopoeisis]] (also known as CHIP).&lt;ref name=":0" /&gt;&lt;ref&gt;{{Cite journal|last1=Razavi|first1=Pedram|last2=Li|first2=Bob T.|last3=Brown|first3=David N.|last4=Jung|first4=Byoungsok|last5=Hubbell|first5=Earl|last6=Shen|first6=Ronglai|last7=Abida|first7=Wassim|last8=Juluru|first8=Krishna|last9=De Bruijn|first9=Ino|last10=Hou|first10=Chenlu|last11=Venn|first11=Oliver|date=December 2019|title=High-intensity sequencing reveals the sources of plasma circulating cell-free DNA variants|journal=Nature Medicine|language=en|volume=25|issue=12|pages=1928–1937|doi=10.1038/s41591-019-0652-7|pmid=31768066|issn=1546-170X|pmc=7061455}}&lt;/ref&gt; Even though [[Clonal hematopoiesis|CHIP]] tends to target specific genes, it also involves many generally non-recurrent mutations that can be shed from [[White blood cell|leukocytes]] and detected in cfDNA, regardless of whether profiling patients with cancer and healthy adults.&lt;ref name=":0" /&gt;  However, genuine tumor derived [[Circulating tumor DNA|ctDNA mutations]] can be distinguished from CHIP-derived mutations. This is because unlike tumor-derived mutations, CHIP-derived mutations that are shed from leukocytes into plasma tend to occur on longer cfDNA fragments, and to lack specific [[mutational signatures]] such as those associated with tobacco smoking in lung cancer that are also found in tumor derived ctDNA molecules. CLiP integrates these features within hierarchical ensemble [[machine learning]] models that consider [[Mutation|somatic mutations]] and [[Copy-number variation|copy number alternations]], among other features.&lt;ref name=":0" /&gt; While the CLiP method is unique in relying exclusively on mutations and copy number alterations, it is related to a variety of other liquid biopsy methods being commercially developed for early cancer detection using ctDNA and proteins (e.g., CancerSEEK / DETECT-A &lt;ref&gt;{{Cite web|last1=KaiserApr. 28|first1=Jocelyn|last2=2020|last3=Pm|first3=1:40|date=2020-04-28|title=DNA blood test spots cancers in seemingly cancer-free women, but also produces false alarms|url=https://www.sciencemag.org/news/2020/04/blood-tests-spot-cancers-symptoms-appear-also-produce-false-positives|access-date=2020-06-11|website=Science {{!}} AAAS|language=en}}&lt;/ref&gt;), cfDNA fragmentation patterns (e.g., DELFI),&lt;ref&gt;{{Cite web|title=New blood test uses DNA 'packaging' patterns to detect multiple cancer types|url=https://www.sciencedaily.com/releases/2019/05/190529131206.htm|access-date=2020-06-11|website=ScienceDaily|language=en}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|title=Delfi Diagnostics – Early Detection of Cancer – Baltimore, MD|url=https://delfidiagnostics.com/|access-date=2020-06-11|website=Delfi Diagnostics|language=en-US}}&lt;/ref&gt; and DNA methylation (e.g., cfMeDIP-Seq,&lt;ref&gt;{{Cite journal|last1=Shen|first1=Shu Yi|last2=Burgener|first2=Justin M.|last3=Bratman|first3=Scott V.|last4=De Carvalho|first4=Daniel D.|s2cid=201675927|date=October 2019|title=Preparation of cfMeDIP-seq libraries for methylome profiling of plasma cell-free DNA|url=https://www.nature.com/articles/s41596-019-0202-2|journal=Nature Protocols|language=en|volume=14|issue=10|pages=2749–2780|doi=10.1038/s41596-019-0202-2|pmid=31471598|issn=1750-2799}}&lt;/ref&gt; GRAIL&lt;ref&gt;{{Cite web|date=2020-02-18|title=PATHFINDER Study|url=https://grail.com/clinical-studies/pathfinder-study/|access-date=2020-06-11|website=GRAIL|language=en-US}}&lt;/ref&gt;).

While the CLiP method has not yet been broadly applied for population-based cancer screening, it has been shown to distinguish discriminate early-stage lung cancers from risk-matched controls across multiple cohorts of patients enrolled across the US.&lt;ref&gt;{{Cite news|last=editor|first=Ian Sample Science|url=https://www.theguardian.com/society/2020/mar/25/ai-program-could-check-blood-for-signs-of-lung-cancer|title=AI program could check blood for signs of lung cancer|date=2020-03-25|work=The Guardian|access-date=2020-04-22|language=en-GB|issn=0261-3077}}&lt;/ref&gt;

== References ==
&lt;!-- Inline citations added to your article will automatically display here. See en.wikipedia.org/wiki/WP:REFB for instructions on how to add citations. --&gt;
{{reflist}}

[[Category:Machine learning]]
[[Category:Machine learning algorithms]]
[[Category:Cancer]]
[[Category:Blood tests]]
[[Category:Diagnosis classification]]</text>
      <sha1>a5thyhq9uzsyw3tiv6x11i02t2z952e</sha1>
    </revision>
  </page>
  <page>
    <title>Scikit-multiflow</title>
    <ns>0</ns>
    <id>63598972</id>
    <revision>
      <id>1000324764</id>
      <parentid>979635392</parentid>
      <timestamp>2021-01-14T17:12:44Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>Fix REFPUNCT + other minor fixes</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="6003" xml:space="preserve">{{short description|Machine learning library for data streams in Python}}

{{lowercase title}}

{{Infobox software
| name = scikit-mutliflow
| logo = Scikit-multiflow-logo.png
| screenshot = 
| caption = 
| collapsible = 
| author = Jacob Montiel, Jesse Read, Albert Bifet, Talel Abdessalem
| developer = The scikit-mutliflow development team and the open research community
| released = {{Start date and age|2018|01|df=yes}}
| latest release version = 0.5.3
| latest release date = {{Start date and age|2020|06|17|df=yes}}&lt;ref&gt;{{cite web |title=scikit-mutliflow Version 0.5.3 |url=https://scikit-multiflow.readthedocs.io/en/stable/whats_new.html#version-0-5-0}}&lt;/ref&gt;&lt;ref&gt;{{cite web |title=scikit-learn 0.5.3 |url=https://pypi.org/project/scikit-multiflow/0.5.3/|website=[[Python Package Index]]}}&lt;/ref&gt;
| latest preview version = 
| latest preview date = 
| repo = https://github.com/scikit-multiflow/scikit-multiflow
| programming language = [[Python (programming language)|Python]], [[Cython]]
| operating system = [[Linux]], [[macOS]], [[Microsoft Windows|Windows]]
| platform = 
| size = 
| language = 
| genre = Library for [[machine learning]]
| license = [[BSD-3|BSD 3-Clause license]]
| website = {{URL|https://scikit-multiflow.github.io/}}
}}

'''scikit-mutliflow''' (also known as '''skmultiflow''') is a [[Free and open-source software|free and open source software]] [[machine learning]] library for multi-output/multi-label and [[Data stream mining|stream data]] written in [[Python (programming language)|Python]].&lt;ref name=":0"&gt;{{Cite journal|last=Montiel|first=Jacob|last2=Read|first2=Jesse|last3=Bifet|first3=Albert|last4=Abdessalem|first4=Talel|date=2018|title=Scikit-Multiflow: A Multi-output Streaming Framework|url=http://jmlr.org/papers/v19/18-251.html|journal=Journal of Machine Learning Research|volume=19|issue=72|pages=1–5|issn=1533-7928}}&lt;/ref&gt;

== Overview ==
scikit-multiflow allows to easily design and run experiments and to extend existing stream learning algorithms.&lt;ref name=":0" /&gt; It features a collection of [[Statistical classification|classification]], [[Regression analysis|regression]], [[Concept drift|concept drift detection]] and [[anomaly detection]] algorithms. It also includes a set of data stream generators and evaluators. scikit-multiflow is designed to interoperate with Python's numerical and scientific libraries [[NumPy]] and [[SciPy]] and is compatible with [[Jupyter Notebook]]s.

== Implementation ==
The scikit-multiflow library is implemented under the [[open research]] principles and is currently distributed under the [[BSD-3|BSD 3-Clause license]]. scikit-multiflow is mainly written in Python, and some core elements are written in [[Cython]] for performance. scikit-multiflow integrates with other Python libraries such as [[Matplotlib]] for plotting, [[scikit-learn]] for incremental learning methods&lt;ref&gt;{{Cite web|url=https://scikit-learn.org/stable/modules/computing.html?highlight=incremental#incremental-learning|title=scikit-learn — Incremental learning|last=|first=|date=|website=scikit-learn.org|url-status=live|archive-url=|archive-date=|access-date=2020-04-08}}&lt;/ref&gt; compatible with the stream learning setting, [[Pandas (software)|Pandas]] for data manipulation, [[NumPy|Numpy]] and [[SciPy]].

== Components ==
The scikit-multiflow is composed of the following sub-packages:

* '''anomaly_detection:''' anomaly detection methods.
* '''data:''' data stream methods including methods for batch-to-stream conversion and generators.
* '''drift_detection:''' methods for concept drift detection.
* '''evaluation:''' evaluation methods for stream learning.
* '''lazy:''' methods in which generalisation of the training data is delayed until a query is received, i.e., neighbours-based methods such as [[K-nearest neighbors algorithm|kNN]].
* '''meta:''' meta learning (also known as [[Ensemble learning|ensemble]]) methods.
* '''neural_networks:''' methods based on [[neural network]]s.
* '''prototype:''' prototype-based learning methods.
* '''rules:''' rule-based learning methods.
* '''transform:''' perform data transformations.
* '''trees:''' tree-based methods, e.g. Hoeffding Trees which are a type of [[Decision tree learning|Decision Tree]] for data streams.

== History ==
scikit-multiflow started as a collaboration between researchers at [[Télécom Paris]] (Institut Polytechnique de Paris&lt;ref&gt;{{Cite web|url=https://www.ip-paris.fr/en/home-en/|title=Institut Polytechnique de Paris|last=|first=|date=|language=en-GB|url-status=live|archive-url=|archive-date=|access-date=2020-04-08}}&lt;/ref&gt;) and [[École Polytechnique]]. Development is currently carried by the [[University of Waikato]], Télécom Paris,  École Polytechnique and the open research community.

== See also ==
{{Portal|Free and open-source software}}
* [[Massive Online Analysis]] (MOA)&lt;ref&gt;{{Cite journal|last=Bifet|first=Albert|last2=Holmes|first2=Geoff|last3=Kirkby|first3=Richard|last4=Pfahringer|first4=Bernhard|date=2010|title=MOA: Massive Online Analysis|url=http://jmlr.org/papers/v11/bifet10a.html|journal=Journal of Machine Learning Research|volume=11|issue=52|pages=1601–1604|issn=1533-7928}}&lt;/ref&gt;
* MEKA&lt;ref&gt;{{Cite journal|last=Read|first=Jesse|last2=Reutemann|first2=Peter|last3=Pfahringer|first3=Bernhard|last4=Holmes|first4=Geoff|date=2016|title=MEKA: A Multi-label/Multi-target Extension to WEKA|url=http://jmlr.org/papers/v17/12-164.html|journal=Journal of Machine Learning Research|volume=17|issue=21|pages=1–5|issn=1533-7928}}&lt;/ref&gt;

== References ==
{{Reflist|30em}}

== External links ==

* [https://github.com/scikit-multiflow/scikit-multiflow GitHub repository]
* {{Official website|https://scikit-multiflow.github.io/}}

{{SciPy ecosystem}}

[[Category:Free statistical software]]
[[Category:Python (programming language) scientific libraries]]
[[Category:Data mining and machine learning software]]
[[Category:Free software programmed in Python]]
[[Category:Machine learning]]
[[Category:Artificial intelligence]]</text>
      <sha1>4l8vnsa57r9r4sadd9w6xqbgn8oanf1</sha1>
    </revision>
  </page>
  <page>
    <title>Large width limits of neural networks</title>
    <ns>0</ns>
    <id>64415394</id>
    <revision>
      <id>995422720</id>
      <parentid>995016799</parentid>
      <timestamp>2020-12-20T23:28:43Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 16 templates: del empty params (1×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="8524" xml:space="preserve">[[File:Infinitely wide neural network.webm|thumb|406x406px|Behavior of a neural network simplifies as it becomes infinitely wide. '''Left''': a [[Bayesian network|Bayesian neural network]] with two hidden layers, transforming a 3-dimensional input (bottom) into a two-dimensional output &lt;math&gt;(y_1, y_2)&lt;/math&gt; (top). '''Right''': output [[probability density function]] &lt;math&gt;p(y_1, y_2)&lt;/math&gt; induced by the random weights of the network. '''Video''': as the width of the network increases, the output distribution simplifies, ultimately converging to a [[Neural network Gaussian process]] in the infinite width limit.]]

[[Artificial neural network]]s are a class of models used in [[machine learning]], and inspired by [[neural circuit|biological neural networks]]. They are the core component of modern [[deep learning]] algorithms. Computation in artificial neural networks is usually organized into sequential layers of [[artificial neuron]]s. The number of neurons in a layer is called the layer width. Theoretical analysis of artificial neural networks sometimes considers the limiting case that layer width becomes large or infinite. This limit enables simple analytic statements to be made about neural network predictions, training dynamics, generalization, and loss surfaces. This wide layer limit is also of practical interest, since finite width neural networks often perform strictly better as layer width is increased.&lt;ref name=":7"&gt;
{{Cite journal|last1=Novak|first1=Roman|last2=Bahri|first2=Yasaman|last3=Abolafia|first3=Daniel A.|last4=Pennington|first4=Jeffrey|last5=Sohl-Dickstein|first5=Jascha|date=2018-02-15|title=Sensitivity and Generalization in Neural Networks: an Empirical Study|url=https://openreview.net/forum?id=HJC2SzZCW|journal=International Conference on Learning Representations|arxiv=1802.08760|bibcode=2018arXiv180208760N}}&lt;/ref&gt;&lt;ref name=":8"&gt;
{{Cite journal|last1=Canziani|first1=Alfredo|last2=Paszke|first2=Adam|last3=Culurciello|first3=Eugenio|date=2016-11-04|title=An Analysis of Deep Neural Network Models for Practical Applications|url=https://openreview.net/forum?id=Bygq-H9eg|arxiv=1605.07678|bibcode=2016arXiv160507678C}}&lt;/ref&gt;&lt;ref name=":1"&gt;
{{cite journal |last1=Novak |first1=Roman |last2=Xiao |first2=Lechao |last3=Lee |first3=Jaehoon |last4=Bahri |first4=Yasaman |last5=Yang | first5=Greg |last6=Abolafia | first6=Dan | last7= Pennington |first7=Jeffrey |last8=Sohl-Dickstein |first8=Jascha |date=2018 |title=Bayesian Deep Convolutional Networks with Many Channels are Gaussian Processes |journal=International Conference on Learning Representations |arxiv=1810.05148 |bibcode=2018arXiv181005148N }}&lt;/ref&gt;&lt;ref name=":6"&gt;
{{Cite journal|last1=Neyshabur|first1=Behnam|last2=Li|first2=Zhiyuan|last3=Bhojanapalli|first3=Srinadh|last4=LeCun|first4=Yann|last5=Srebro|first5=Nathan|date=2019|title=Towards understanding the role of over-parametrization in generalization of neural networks|journal=International Conference on Learning Representations|arxiv=1805.12076|bibcode=2018arXiv180512076N}}
&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last1=Lawrence|first1=Steve|last2=Giles|first2=C. Lee|last3=Tsoi|first3=Ah Chung|date=1996|title=What size neural network gives optimal generalization? convergence properties of backpropagation|citeseerx=10.1.1.125.6019|url=http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.125.6019}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Bartlett|first=P.L.|date=1998|title=The sample complexity of pattern classification with neural networks: the size of the weights is more important than the size of the network|url=https://ieeexplore.ieee.org/document/661502|journal=IEEE Transactions on Information Theory|volume=44|issue=2|pages=525–536|doi=10.1109/18.661502|issn=1557-9654}}&lt;/ref&gt;
__TOC__
== Theoretical approaches based on a large width limit ==

* The [[Neural Network Gaussian Process]] (NNGP) corresponds to the infinite width limit of Bayesian neural networks, and to the distribution over functions realized by non-Bayesian neural networks after random initialization.&lt;ref&gt;
{{Citation|last=Neal|first=Radford M.|chapter=Priors for Infinite Networks|date=1996|title=Bayesian Learning for Neural Networks|series=Lecture Notes in Statistics|volume=118|pages=29–53|publisher=Springer New York|doi=10.1007/978-1-4612-0745-0_2|isbn=978-0-387-94724-2}}
&lt;/ref&gt;&lt;ref&gt;
{{cite journal|last1=Lee|first1=Jaehoon|last2=Bahri|first2=Yasaman|last3=Novak|first3=Roman|last4=Schoenholz|first4=Samuel S.|last5=Pennington|first5=Jeffrey|last6=Sohl-Dickstein|first6=Jascha|date=2017|title=Deep Neural Networks as Gaussian Processes|journal=International Conference on Learning Representations|arxiv=1711.00165|bibcode=2017arXiv171100165L}}
&lt;/ref&gt;&lt;ref&gt;
{{cite journal |last1=G. de G. Matthews |first1=Alexander |last2=Rowland |first2=Mark |last3=Hron |first3=Jiri |last4=Turner |first4=Richard E. |last5=Ghahramani | first5=Zoubin |date=2017 |title=Gaussian Process Behaviour in Wide Deep Neural Networks |journal=International Conference on Learning Representations |arxiv=1804.11271 |bibcode=2018arXiv180411271M }}
&lt;/ref&gt;&lt;ref&gt;
{{cite journal |last1=Hron |first1=Jiri |last2=Bahri |first2=Yasaman |last3=Novak |first3=Roman |last4=Pennington |first4=Jeffrey |last5=Sohl-Dickstein | first5=Jascha |date=2020 |title=Exact posterior distributions of wide Bayesian neural networks |journal=ICML 2020 Workshop on Uncertainty &amp; Robustness in Deep Learning |arxiv=2006.10541}}
&lt;/ref&gt;
* The same underlying computations that are used to derive the NNGP kernel are also used in [[deep information propagation]] to characterize the propagation of information about gradients and inputs through a deep network.&lt;ref name=":10"&gt;
{{Cite journal|last1=Schoenholz|first1=Samuel S.|last2=Gilmer|first2=Justin|last3=Ganguli|first3=Surya|last4=Sohl-Dickstein|first4=Jascha|date=2016|title=Deep information propagation|journal=International Conference on Learning Representations|arxiv=1611.01232}}
&lt;/ref&gt;  This characterization is used to predict how model trainability depends on architecture and initializations hyper-parameters.
* The [[Neural tangent kernel|Neural Tangent Kernel]] describes the evolution of neural network predictions during gradient descent training. In the infinite width limit the NTK usually becomes constant, often allowing closed form expressions for the function computed by a wide neural network throughout gradient descent training.&lt;ref&gt;
{{Cite journal|last1=Jacot| first1=Arthur| last2=Gabriel| first2=Franck| last3=Hongler| first3=Clement|title=Neural tangent kernel: Convergence and generalization in neural networks|date=2018|journal=Advances in Neural Information Processing Systems|arxiv=1806.07572}}&lt;/ref&gt; The training dynamics essentially become linearized.&lt;ref name="Lee"&gt;{{Cite journal|last=Lee|first=Jaehoon|last2=Xiao|first2=Lechao|last3=Schoenholz|first3=Samuel S.|last4=Bahri|first4=Yasaman|last5=Novak|first5=Roman|last6=Sohl-Dickstein|first6=Jascha|last7=Pennington|first7=Jeffrey|date=2018-02-15|title=Wide Neural Networks of Any Depth Evolve as Linear Models Under Gradient Descent|arxiv=1902.06720}}&lt;/ref&gt;
* The study of infinite width neural networks with a different initial weight scaling and suitably large learning rates leads to qualitatively different nonlinear training dynamics than those described by the fixed neural tangent kernel.&lt;ref&gt;{{Cite book|last=Mei, Song Montanari, Andrea Nguyen, Phan-Minh|title=A Mean Field View of the Landscape of Two-Layers Neural Networks|date=2018-04-18|oclc=1106295873}}&lt;/ref&gt;&lt;ref&gt;
{{Cite arxiv|last1=Nguyen| first1=Phan-Minh| last2=Pham| first2=Huy Tuan|title=A Rigorous Framework for the Mean Field Limit of Multilayer Neural Networks|date=2020| class=cs.LG|eprint=2001.11443}}
&lt;/ref&gt;
* Catapult dynamics describe neural network training dynamics in the case that logits diverge to infinity as the layer width is taken to infinity, and describe qualitative properties of early training dynamics.&lt;ref&gt;
{{cite arxiv|last1=Lewkowycz|first1=Aitor|last2=Bahri|first2=Yasaman|last3=Dyer|first3=Ethan|last4=Sohl-Dickstein|first4=Jascha|last5=Gur-Ari|first5=Guy|date=2020|title=The large learning rate phase of deep learning: the catapult mechanism|class=stat.ML|eprint=2003.02218}}
&lt;/ref&gt;

== References ==
&lt;!-- Inline citations added to your article will automatically display here. See en.wikipedia.org/wiki/WP:REFB for instructions on how to add citations. --&gt;
{{reflist}}

[[Category:Computer science]]
[[Category:Machine learning]]
[[Category:Deep learning]]
[[Category:Artificial neural networks]]</text>
      <sha1>918uzeztfi1icf8up44uqgupczae9ze</sha1>
    </revision>
  </page>
  <page>
    <title>80 Million Tiny Images</title>
    <ns>0</ns>
    <id>64439717</id>
    <revision>
      <id>995334240</id>
      <parentid>971867401</parentid>
      <timestamp>2020-12-20T13:39:37Z</timestamp>
      <contributor>
        <username>Monkbot</username>
        <id>20483999</id>
      </contributor>
      <minor/>
      <comment>[[User:Monkbot/task 18|Task 18 (cosmetic)]]: eval 5 templates: del empty params (3×); del |url-status= (1×);</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3018" xml:space="preserve">{{short description|Dataset for training machine learning systems.}}
'''80 Million Tiny Images''' is a [[dataset]] intended for training [[machine learning]] systems.&lt;ref&gt;{{Cite web|last=Quach|first=Katyanna|date=1 July 2020|title=MIT apologizes, permanently pulls offline huge dataset that taught AI systems to use racist, misogynistic slurs|url=https://www.theregister.com/2020/07/01/mit_dataset_removed/|access-date=2020-07-02|website=www.theregister.com|language=en}}&lt;/ref&gt; It contains 79,302,017 32&amp;times;32 pixel color images, scaled down from images extracted from the [[World Wide Web]] in 2008 using automated [[web search]] queries on a set of 75,062 non-abstract nouns derived from [[WordNet]]. The words in the search terms were then used as labels for the images.&lt;ref name=Torralba2008&gt;{{Cite journal|last1=Torralba|first1=Antonio|last2=Fergus|first2=Rob|last3=Freeman|first3=William T.|s2cid=7487588|date=November 2008|title=80 million tiny images: a large data set for nonparametric object and scene recognition|url=http://people.csail.mit.edu/billf/papers/80millionImages.pdf|journal=IEEE Transactions on Pattern Analysis and Machine Intelligence|volume=30|issue=11|pages=1958–1970|doi=10.1109/TPAMI.2008.128|issn=1939-3539|pmid=18787244}}&lt;/ref&gt; The researchers used seven web search resources for this purpose: [[Altavista]], [[Ask.com]], [[Flickr]], [[Cydral]], [[Google]], [[Picsearch]] and [[Webshots]].&lt;ref name=Torralba2008/&gt;

The 80 Million Tiny Images dataset was retired from use by its creators in 2020,&lt;ref name=":0"&gt;{{Cite web|title=80 Million Tiny Images|url=https://groups.csail.mit.edu/vision/TinyImages/|access-date=2020-07-02|website=groups.csail.mit.edu}}&lt;/ref&gt; after reports that some of the labeling of several publicly available image datasets, including this, was causing models trained on them to exhibit racial and sexual bias.&lt;ref&gt;{{Cite web|last=Ustik|first=Georgina|date=2020-07-01|title=MIT removes huge dataset that teaches AI systems to use racist, misogynistic slurs|url=https://thenextweb.com/neural/2020/07/01/mit-removes-huge-dataset-that-teaches-ai-systems-to-use-racist-misogynistic-slurs/|access-date=2020-07-02|website=Neural {{!}} The Next Web|language=en-us}}&lt;/ref&gt;&lt;ref&gt;{{Cite arxiv|last1=Prabhu|first1=Vinay Uday|last2=Birhane|first2=Abeba|date=2020-06-24|title=Large image datasets: A pyrrhic win for computer vision?|class=cs.CY|eprint=2006.16923}}&lt;/ref&gt; They have asked other researchers not to use it for further research and to delete their copies of the dataset.&lt;ref name=":0" /&gt;

The [[CIFAR-10]] dataset uses a subset of the images in this dataset, but with independently generated labels.&lt;ref&gt;A. Krizhevsky. [https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf Learning multiple layers of features from tiny images]. Tech Report, 2009. University of Toronto&lt;/ref&gt;

== See also ==
* [[Systemic bias]]

== References ==
{{reflist}}

[[Category:Machine learning]]
[[Category:Datasets in computer vision]]


{{compsci-stub}}
{{sociology-stub}}</text>
      <sha1>lm055g395zu3sjp4o3ksjaqhwlet9hm</sha1>
    </revision>
  </page>
  <page>
    <title>Tensor sketch</title>
    <ns>0</ns>
    <id>64295245</id>
    <revision>
      <id>1000481548</id>
      <parentid>990883229</parentid>
      <timestamp>2021-01-15T08:14:04Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>References after punctuation per [[WP:REFPUNCT]], [[WP:CITEFOOT]], [[WP:PAIC]] + other fixes</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="26187" xml:space="preserve">{{short description|Algorithm for reducing the dimension of tensors}}
&lt;!-- {{for|Dimensional reduction}} comment out hatnote for unclearness --&gt;
{{Machine learning bar}}

In [[statistics]], [[machine learning]] and [[algorithms]], a '''tensor sketch''' is a type of [[dimensionality reduction]] that is particularly efficient when applied to [[Vector (mathematics and physics)|vectors]] that have [[tensor]] structure.&lt;ref&gt;{{Cite web |title=Low-rank Tucker decomposition of large tensors using: Tensor Sketch |url=https://amath.colorado.edu/faculty/becker/TensorSketch.pdf |website=amath.colorado.edu |publisher=[[University of Colorado Boulder]] |location=Boulder, Colorado}}&lt;/ref&gt;&lt;ref&gt;{{Cite web |last=Ahle |first=Thomas |last2=Knudsen |first2=Jakob |date=2019-09-03 |title=Almost Optimal Tensor Sketch |url=https://www.researchgate.net/publication/335617805_Almost_Optimal_Tensor_Sketch |access-date=2020-07-11 |website=[[Researchgate]]}}&lt;/ref&gt; Such a sketch can be used to speed up explicit [[kernel methods]], bilinear [[Pool (computer science)|pooling]] in [[neural network]]s and is a cornerstone in many numerical linear algebra algorithms.&lt;ref name="woodruff"&gt;Woodruff, David P. "Sketching as a Tool for Numerical Linear Algebra." Theoretical Computer Science 10.1-2 (2014): 1–157.&lt;/ref&gt;

==Mathematical definition==
Mathematically, a dimensionality reduction is a matrix &lt;math&gt;M\in\mathbb R^{k,d}&lt;/math&gt;, where &lt;math&gt;k&lt;d&lt;/math&gt;, such that for any vector &lt;math&gt;x\in\mathbb R^d&lt;/math&gt; it holds that
:&lt;math&gt;|\|Mx\|_2 - \|x\|_2| &lt; \varepsilon\|x\|_2&lt;/math&gt;
with high probability.
In other words &lt;math&gt;M&lt;/math&gt; preserves the norm of vectors up to a small error.

A Tensor sketch has the extra property that if &lt;math&gt;x = y \otimes z&lt;/math&gt; for some vectors &lt;math&gt;y\in\mathbb R^{d_1}, z\in\mathbb R^{d_2}&lt;/math&gt; such that &lt;math&gt;d_1d_2=d&lt;/math&gt;, the transformation &lt;math&gt;M(y\otimes z)&lt;/math&gt; can be computed extra efficiently.

Typically &lt;math&gt;M(y\otimes z) = M' y \circ M'' z&lt;/math&gt;, where &lt;math&gt;\circ&lt;/math&gt; is the ([[Hadamard product (matrices)|Hadamard]]) elementwise product.
Since each of &lt;math&gt;M' y&lt;/math&gt; and &lt;math&gt;M'' z&lt;/math&gt; can be computed in time respectively &lt;math&gt;kd_1&lt;/math&gt; and &lt;math&gt;kd_2&lt;/math&gt;, the computation is much faster than the full &lt;math&gt;M(y\otimes z)&lt;/math&gt; which would take time &lt;math&gt;kd=kd_1d_2&lt;/math&gt;.

For higher-order tensors, such as &lt;math&gt;x = y\otimes z\otimes t&lt;/math&gt; the savings are even more impressive.

==History==

The term tensor sketch was coined in 2013&lt;ref name="ninh"&gt;{{cite conference 
| title = Fast and scalable polynomial kernels via explicit feature maps
| last1 = Ninh
| first1 = Pham
| last2 = Rasmus
| first2 = Pagh
| date = 2013
| publisher = Association for Computing Machinery
| conference = SIGKDD international conference on Knowledge discovery and data mining
|doi = 10.1145/2487575.2487591}}
&lt;/ref&gt; describing a technique by [[Rasmus Pagh]]&lt;ref name="pagh"&gt;
{{cite journal 
| title = Compressed matrix multiplication
| last1 = Rasmus
| first1 = Pagh
| date = 2013
| publisher = Association for Computing Machinery
| journal = ACM Transactions on Computation Theory, August 2013 Article No.: 9
|doi = 10.1145/2493252.2493254}}
&lt;/ref&gt; from the same year.
Originally it was understood using the [[fast Fourier transform]] to do fast [[convolution]] of [[count sketch]]es.
Later research works generalized it to a much larger class of dimensionality reductions via Tensor random embeddings.

Tensor random embeddings were introduced in 2010 in a paper&lt;ref&gt;Kasiviswanathan, Shiva Prasad, et al. "The price of privately releasing contingency tables and the spectra of random matrices with correlated rows." Proceedings of the forty-second ACM symposium on Theory of computing. 2010.&lt;/ref&gt; on differential privacy and were first analyzed by Rudelson et al. in 2012 in the context of sparse recovery.&lt;ref&gt;Rudelson, Mark, and Shuheng Zhou. "Reconstruction from anisotropic random measurements." Conference on Learning Theory. 2012.&lt;/ref&gt;

Avron et al.&lt;ref name="avron"&gt;{{cite journal
| title = Subspace Embeddings for the Polynomial Kernel
|     first1 = Haim
| last1 = Avron
|     first2 = Huy
| last2 = Nguyen
|     first3 = David
| last3 = Woodruff
| date = 2013
| publisher = Association for Computing Machinery
| journal = NIPS'14: Proceedings of the 27th International Conference on Neural Information Processing Systems
|doi = 10.1145/2493252.2493254}}&lt;/ref&gt;
were the first to study the [[subspace embedding]] properties of tensor sketches, particularly focused on applications to [[polynomial kernel]]s.
In this context, the sketch is required not only to preserve the norm of each individual vector with a certain probability but to preserve the norm of all vectors in each individual [[linear subspace]].
This is a much stronger property, and it requires larger sketch sizes, but it allows the kernel methods to be used very broadly as explored in the book by David Woodruff.&lt;ref name="woodruff" /&gt;

==Tensor random projections==
The [[Khatri–Rao product#Face-splitting product|face-splitting product]] is defined as the tensor products of the rows (was proposed by [[Vadym Slyusar|V. Slyusar]]&lt;ref name= "Fortiana"&gt;Anna Esteve, Eva Boj &amp; Josep Fortiana (2009): Interaction Terms in Distance-Based Regression, Communications in Statistics – Theory and Methods, 38:19, P. 3501 [http://dx.doi.org/10.1080/03610920802592860]&lt;/ref&gt; in 1996&lt;ref name=slyusar&gt;{{Cite journal|last=Slyusar|first=V. I.|date= December 27, 1996|title=End products in matrices in radar applications. |url=http://slyusar.kiev.ua/en/IZV_1998_3.pdf|journal=Radioelectronics and Communications Systems.– 1998, Vol. 41; Number 3|pages=50–53}}&lt;/ref&gt;&lt;ref name=slyusar1&gt;{{Cite journal|last=Slyusar|first=V. I.|date=1997-05-20|title=Analytical model of the digital antenna array on a basis of face-splitting matrix products. |url=http://slyusar.kiev.ua/ICATT97.pdf|journal=Proc. ICATT-97, Kyiv|pages=108–109}}&lt;/ref&gt;&lt;ref name="DIPED"&gt;{{Cite journal|last=Slyusar|first=V. I.|date=1997-09-15|title=New operations of matrices product for applications of radars|url=http://slyusar.kiev.ua/DIPED_1997.pdf|journal=Proc. Direct and Inverse Problems of Electromagnetic and Acoustic Wave Theory (DIPED-97), Lviv.|pages=73–74}}&lt;/ref&gt;&lt;ref name=slyusar2&gt;{{Cite journal|last=Slyusar|first=V. I.|date=March 13, 1998|title=A Family of Face Products of Matrices and its Properties|url=http://slyusar.kiev.ua/FACE.pdf|journal=Cybernetics and Systems Analysis C/C of Kibernetika I Sistemnyi Analiz. – 1999.|volume=35|issue=3|pages=379–384|doi=10.1007/BF02733426}}&lt;/ref&gt;&lt;ref name=general&gt;{{Cite journal|last=Slyusar|first=V. I.|date=2003|title=Generalized face-products of matrices in models of digital antenna arrays with nonidentical channels|url=http://slyusar.kiev.ua/en/IZV_2003_10.pdf|journal=Radioelectronics and Communications Systems|volume=46|issue=10|pages=9–17}}&lt;/ref&gt; for [[radar]] and [[digital antenna array]] applications).
More directly, let &lt;math&gt;\mathbf{C}\in\mathbb R^{3\times 3}&lt;/math&gt; and &lt;math&gt;\mathbf{D}\in\mathbb R^{3\times 3}&lt;/math&gt; be two matrices.
Then the [[Khatri–Rao product#Face-splitting product|face-splitting product]] &lt;math&gt;\mathbf{C}\bullet \mathbf{D}&lt;/math&gt; is&lt;ref name=slyusar /&gt;&lt;ref name=slyusar1 /&gt;&lt;ref name="DIPED" /&gt;&lt;ref name=slyusar2 /&gt;
&lt;math&gt;
\mathbf{C} \bull \mathbf{D}
= 
\left[
\begin{array} { c }
\mathbf{C}_1 \otimes \mathbf{D}_1\\\hline 
\mathbf{C}_2 \otimes \mathbf{D}_2\\\hline
\mathbf{C}_3 \otimes \mathbf{D}_3\\
\end{array}
\right]
=
\left[
\begin{array} { c  c  c  c  c  c  c  c  c }
\mathbf{C}_{1,1}\mathbf{D}_{1,1} &amp; \mathbf{C}_{1,1}\mathbf{D}_{1,2} &amp; \mathbf{C}_{1,1}\mathbf{D}_{1,3} &amp; \mathbf{C}_{1,2}\mathbf{D}_{1,1} &amp; \mathbf{C}_{1,2}\mathbf{D}_{1,2} &amp; \mathbf{C}_{1,2}\mathbf{D}_{1,3} &amp; \mathbf{C}_{1,3}\mathbf{D}_{1,1} &amp; \mathbf{C}_{1,3}\mathbf{D}_{1,2} &amp; \mathbf{C}_{1,3}\mathbf{D}_{1,3}  \\\hline
\mathbf{C}_{2,1}\mathbf{D}_{2,1} &amp; \mathbf{C}_{2,1}\mathbf{D}_{2,2} &amp; \mathbf{C}_{2,1}\mathbf{D}_{2,3} &amp; \mathbf{C}_{2,2}\mathbf{D}_{2,1} &amp; \mathbf{C}_{2,2}\mathbf{D}_{2,2} &amp; \mathbf{C}_{2,2}\mathbf{D}_{2,3} &amp; \mathbf{C}_{2,3}\mathbf{D}_{2,1} &amp; \mathbf{C}_{2,3}\mathbf{D}_{2,2} &amp; \mathbf{C}_{2,3}\mathbf{D}_{2,3}  \\\hline
\mathbf{C}_{3,1}\mathbf{D}_{3,1} &amp; \mathbf{C}_{3,1}\mathbf{D}_{3,2} &amp; \mathbf{C}_{3,1}\mathbf{D}_{3,3} &amp; \mathbf{C}_{3,2}\mathbf{D}_{3,1} &amp; \mathbf{C}_{3,2}\mathbf{D}_{3,2} &amp; \mathbf{C}_{3,2}\mathbf{D}_{3,3} &amp; \mathbf{C}_{3,3}\mathbf{D}_{3,1} &amp; \mathbf{C}_{3,3}\mathbf{D}_{3,2} &amp; \mathbf{C}_{3,3}\mathbf{D}_{3,3}
\end{array}
\right].
&lt;/math&gt;
The reason this product is useful is the following identity:
:&lt;math&gt;(\mathbf{C} \bull \mathbf{D})(x\otimes y) = \mathbf{C}x \circ \mathbf{D} y
= \left[
\begin{array} { c }
(\mathbf{C}x)_1 (\mathbf{D} y)_1 \\
(\mathbf{C}x)_2 (\mathbf{D} y)_2 \\
\vdots
\end{array}\right],
&lt;/math&gt;
where &lt;math&gt;\circ&lt;/math&gt; is the element-wise ([[Hadamard product (matrices)|Hadamard]]) product.
Since this operation can be computed in linear time, &lt;math&gt;\mathbf{C} \bull \mathbf{D}&lt;/math&gt; can be multiplied on vectors with tensor structure much faster than normal matrices.

===Construction with fast Fourier transform===

The tensor sketch of Pham and Pagh&lt;ref name="ninh"/&gt; computes
&lt;math&gt;C^{(1)}x \ast C^{(2)}y&lt;/math&gt;, where &lt;math&gt;C^{(1)}&lt;/math&gt; and &lt;math&gt;C^{(2)}&lt;/math&gt; are independent [[count sketch]] matrices and &lt;math&gt;\ast&lt;/math&gt; is vector [[convolution]].
They show that, amazingly, this equals &lt;math&gt;C(x \otimes y)&lt;/math&gt; – a count sketch of the tensor product!

It turns out that this relation can be seen in terms of the [[Khatri–Rao product#Face-splitting product|face-splitting product]] as
:&lt;math&gt;C^{(1)}x \ast C^{(2)}y = \mathcal F^{-1}(\mathcal F C^{(1)}x \circ \mathcal F C^{(2)}y)&lt;/math&gt;, where &lt;math&gt;\mathcal F&lt;/math&gt; is the [[DFT matrix|Fourier transform matrix]].
Since &lt;math&gt;\mathcal F&lt;/math&gt; is an [[orthonormal]] matrix, &lt;math&gt;\mathcal F^{-1}&lt;/math&gt; doesn't impact the norm of &lt;math&gt;Cx&lt;/math&gt; and may be ignored.
What's left is that &lt;math&gt;C \sim \mathcal C^{(1)} \bullet \mathcal C^{(2)}&lt;/math&gt;.

On the other hand,
:&lt;math&gt;\mathcal F(C^{(1)}x \ast C^{(2)}y) = \mathcal F C^{(1)}x \circ \mathcal F C^{(2)}y=  (\mathcal F C^{(1)} \bull \mathcal F C^{(2)})(x \otimes y)&lt;/math&gt;.

===Application to general matrices===

The problem with the original tensor sketch algorithm was that it used [[count sketch]] matrices, which aren't always very good dimensionality reductions.

In 2020&lt;ref name="highdeg" /&gt; it was shown that any matrices with random enough independent rows suffice to create a tensor sketch.
This allows using matrices with stronger guarantees, such as real Gaussian [[Johnson–Lindenstrauss lemma|Johnson Lindenstrauss]] matrices.

In particular, we get the following theorem

:Consider a matrix &lt;math&gt;T&lt;/math&gt; with i.i.d. rows &lt;math&gt;T_1, \dots, T_m\in \mathbb R^d&lt;/math&gt;, such that &lt;math&gt;E[(T_1x)^2]=\|x\|_2^2&lt;/math&gt; and &lt;math&gt;E[(T_1x)^p]^{1/p} \le \sqrt{ap}\|x\|_2&lt;/math&gt;. Let &lt;math&gt;T^{(1)}, \dots, T^{(c)}&lt;/math&gt; be independent consisting of &lt;math&gt;T&lt;/math&gt; and &lt;math&gt;M = T^{(1)} \bullet \dots \bullet T^{(c)}&lt;/math&gt;.
: Then &lt;math&gt;|\|Mx\|_2 - \|x\|_2| &lt; \varepsilon\|x\|_2&lt;/math&gt; with probability &lt;math&gt;1-\delta&lt;/math&gt; for any vector &lt;math&gt;x&lt;/math&gt; if 
:&lt;math&gt;m = (4a)^{2c} \varepsilon^{-2} \log1/\delta + (2ae)\varepsilon^{-1}(\log1/\delta)^c&lt;/math&gt;.

In particular, if the entries of &lt;math&gt;T&lt;/math&gt; are &lt;math&gt;\pm1&lt;/math&gt;  we get &lt;math&gt;m = O(\varepsilon^{-2}\log1/\delta + \varepsilon^{-1}(\tfrac1c\log1/\delta)^c)&lt;/math&gt; which matches the normal [[Johnson–Lindenstrauss lemma|Johnson Lindenstrauss]] theorem of &lt;math&gt;m = O(\varepsilon^{-2}\log1/\delta)&lt;/math&gt; when &lt;math&gt;\varepsilon&lt;/math&gt; is small.

The paper&lt;ref name="highdeg" /&gt; also shows that the dependency on &lt;math&gt;\varepsilon^{-1}(\tfrac1c\log1/\delta)^c&lt;/math&gt; is necessary for constructions using tensor randomized projections with [[Normal distribution|Gaussian]] entries.

==Variations==

===Recursive construction===
Because of the exponential dependency on &lt;math&gt;c&lt;/math&gt; in tensor sketches based on  [[Khatri–Rao product#Face-splitting product|the face-splitting product]], a different approach was developed in 2020&lt;ref name="highdeg" /&gt; which applies

:&lt;math&gt;M(x\otimes y\otimes\cdots)
= M^{(1)}(x \otimes (M^{(2)}y \otimes \cdots))
&lt;/math&gt;

We can achieve such an &lt;math&gt;M&lt;/math&gt; by letting

:&lt;math&gt;M = M^{(c)}(M^{(c-1)}\otimes I_d)(M^{(c-2)}\otimes I_{d^2})\cdots(M^{(1)}\otimes I_{d^{c-1}})&lt;/math&gt;.

With this method, we only apply the general tensor sketch method to order 2 tensors, which avoids the exponential dependency in the number of rows.

It can be proved&lt;ref name="highdeg" /&gt; that combining &lt;math&gt;c&lt;/math&gt; dimensionality reductions like this only increases &lt;math&gt;\varepsilon&lt;/math&gt; by a factor &lt;math&gt;\sqrt{c}&lt;/math&gt;.

===Fast constructions===

The [[Johnson–Lindenstrauss lemma#Speeding up the JL transform|fast Johnson–Lindenstrauss transform]] is a dimensionality reduction matrix

Given a matrix &lt;math&gt;M\in\mathbb R^{k\times d}&lt;/math&gt;, computing the matrix vector product &lt;math&gt;Mx&lt;/math&gt; takes &lt;math&gt;kd&lt;/math&gt; time.
The ''Fast Johnson Lindenstrauss Transform'' (FJLT),&lt;ref&gt;{{cite encyclopedia
 | last1 = Ailon | first1 = Nir | last2 = Chazelle | first2 = Bernard
 | chapter = Approximate nearest neighbors and the fast Johnson–Lindenstrauss transform
 | title = Proceedings of the 38th Annual ACM Symposium on Theory of Computing
 | year = 2006
 | mr = 2277181
 | doi = 10.1145/1132516.1132597
 | pages = 557–563
 | publisher = ACM Press
 | location = New York
 | isbn = 1-59593-134-1}}
&lt;/ref&gt; was introduced by Ailon and [[Bernard Chazelle|Chazelle]] in 2006.

A version of this method takes
&lt;math&gt;M = \operatorname{SHD}&lt;/math&gt;
where
# &lt;math&gt;D&lt;/math&gt; is a [[diagonal matrix]] where each diagonal entry &lt;math&gt;D_{i,i}&lt;/math&gt; is &lt;math&gt;\pm1&lt;/math&gt; independently.
The matrix-vector multiplication &lt;math&gt;Dx&lt;/math&gt; can be computed in &lt;math&gt;O(d)&lt;/math&gt; time.
# &lt;math&gt;H&lt;/math&gt; is a [[Hadamard matrix]], which allows matrix-vector multiplication in time &lt;math&gt;O(d\log d)&lt;/math&gt;
# &lt;math&gt;S&lt;/math&gt; is a &lt;math&gt;k\times d&lt;/math&gt; [[sampling matrix]] which is all zeros, except a single 1 in each row.

If the diagonal matrix is replaced by one which has a tensor product of &lt;math&gt;\pm1&lt;/math&gt; values on the diagonal, instead of being fully independent, it is possible to compute &lt;math&gt;\operatorname{SHD}(x\otimes y)&lt;/math&gt; fast.

For an example of this, let &lt;math&gt;\rho,\sigma\in\{-1,1\}^2&lt;/math&gt; be two independent &lt;math&gt;\pm1&lt;/math&gt; vectors and let &lt;math&gt;D&lt;/math&gt; be a diagonal matrix with &lt;math&gt;\rho\otimes\sigma&lt;/math&gt; on the diagonal.
We can then split up &lt;math&gt;\operatorname{SHD}(x\otimes y)&lt;/math&gt; as follows:
:&lt;math&gt;\begin{align}
      &amp;\operatorname{SHD}(x\otimes y)
      \\
      &amp;\quad=
      \begin{bmatrix}
         1 &amp; 0 &amp; 0 &amp; 0 \\
         0 &amp; 0 &amp; 1 &amp; 0 \\
         0 &amp; 1 &amp; 0 &amp; 0
      \end{bmatrix}
      \begin{bmatrix}
         1 &amp; 1 &amp; 1 &amp; 1 \\
         1 &amp; -1 &amp; 1 &amp; -1 \\
         1 &amp; 1 &amp; -1 &amp; -1 \\
         1 &amp; -1 &amp; -1 &amp; 1
      \end{bmatrix}
      \begin{bmatrix}
         \sigma_1 \rho_1 &amp; 0 &amp; 0 &amp; 0 \\
         0 &amp; \sigma_1 \rho_2 &amp; 0 &amp; 0 \\
         0 &amp; 0 &amp; \sigma_2 \rho_1 &amp; 0 \\
         0 &amp; 0 &amp; 0 &amp; \sigma_2 \rho_2 \\
      \end{bmatrix}
      \begin{bmatrix}
         x_1y_1 \\
         x_2y_1 \\
         x_1y_2 \\
         x_2y_2
      \end{bmatrix}
      \\[5pt]
      &amp;\quad=
      \left(
      \begin{bmatrix}
         1 &amp; 0 \\
         0 &amp; 1 \\
         1 &amp; 0
      \end{bmatrix}
      \bullet
      \begin{bmatrix}
         1 &amp; 0 \\
         1 &amp; 0 \\
         0 &amp; 1
      \end{bmatrix}
      \right)
      \left(
      \begin{bmatrix}
         1 &amp; 1 \\
         1 &amp; -1
      \end{bmatrix}
      \otimes
      \begin{bmatrix}
         1 &amp; 1 \\
         1 &amp; -1
      \end{bmatrix}
      \right)
      \left(
      \begin{bmatrix}
         \sigma_1 &amp; 0 \\
         0 &amp; \sigma_2 \\
      \end{bmatrix}
      \otimes
      \begin{bmatrix}
         \rho_1 &amp; 0 \\
         0 &amp; \rho_2 \\
      \end{bmatrix}
      \right)
      \left(
      \begin{bmatrix}
         x_1 \\
         x_2
      \end{bmatrix}
      \otimes
      \begin{bmatrix}
         y_1 \\
         y_2
      \end{bmatrix}
      \right)
      \\[5pt]
      &amp;\quad=
      \left(
      \begin{bmatrix}
         1 &amp; 0 \\
         0 &amp; 1 \\
         1 &amp; 0
      \end{bmatrix}
      \bullet
      \begin{bmatrix}
         1 &amp; 0 \\
         1 &amp; 0 \\
         0 &amp; 1
      \end{bmatrix}
      \right)
      \left(
      \begin{bmatrix}
         1 &amp; 1 \\
         1 &amp; -1
      \end{bmatrix}
      \begin{bmatrix}
         \sigma_1 &amp; 0 \\
         0 &amp; \sigma_2 \\
      \end{bmatrix}
      \begin{bmatrix}
         x_1 \\
         x_2
      \end{bmatrix}
      \,\otimes\,
      \begin{bmatrix}
         1 &amp; 1 \\
         1 &amp; -1
      \end{bmatrix}
      \begin{bmatrix}
         \rho_1 &amp; 0 \\
         0 &amp; \rho_2 \\
      \end{bmatrix}
      \begin{bmatrix}
         y_1 \\
         y_2
      \end{bmatrix}
      \right)
      \\[5pt]
      &amp;\quad=
      \begin{bmatrix}
         1 &amp; 0 \\
         0 &amp; 1 \\
         1 &amp; 0
      \end{bmatrix}
      \begin{bmatrix}
         1 &amp; 1 \\
         1 &amp; -1
      \end{bmatrix}
      \begin{bmatrix}
         \sigma_1 &amp; 0 \\
         0 &amp; \sigma_2 \\
      \end{bmatrix}
      \begin{bmatrix}
         x_1 \\
         x_2
      \end{bmatrix}
      \,\circ\,
      \begin{bmatrix}
         1 &amp; 0 \\
         1 &amp; 0 \\
         0 &amp; 1
      \end{bmatrix}
      \begin{bmatrix}
         1 &amp; 1 \\
         1 &amp; -1
      \end{bmatrix}
      \begin{bmatrix}
         \rho_1 &amp; 0 \\
         0 &amp; \rho_2 \\
      \end{bmatrix}
      \begin{bmatrix}
         y_1 \\
         y_2
      \end{bmatrix}
      .
   \end{align}&lt;/math&gt;

In other words, &lt;math&gt;\operatorname{SHD}=S^{(1)}HD^{(1)} \bullet S^{(2)}HD^{(2)}&lt;/math&gt;, splits up into two Fast Johnson–Lindenstrauss transformations, and the total reduction takes time &lt;math&gt;O(d_1\log d_1+d_2\log d_2)&lt;/math&gt; rather than &lt;math&gt;d_1 d_2\log(d_1 d_2)&lt;/math&gt; as with the direct approach.

The same approach can be extended to compute higher degree products, such as &lt;math&gt;\operatorname{SHD}(x\otimes y\otimes z)&lt;/math&gt;

Ahle et al.&lt;ref name="highdeg" /&gt; shows that if &lt;math&gt;\operatorname{SHD}&lt;/math&gt; has &lt;math&gt;\varepsilon^{-2}(\log1/\delta)^{c+1}&lt;/math&gt; rows, then &lt;math&gt;|\|\operatorname{SHD}x\|_2-\|x\|| \le \varepsilon\|x\|_2&lt;/math&gt; for any vector &lt;math&gt;x\in\mathbb R^{d^c}&lt;/math&gt; with probability &lt;math&gt;1-\delta&lt;/math&gt;, while allowing fast multiplication with degree &lt;math&gt;c&lt;/math&gt; tensors.

Jin et al.,&lt;ref name="jin"&gt;Jin, Ruhui, Tamara G. Kolda, and Rachel Ward. "Faster Johnson–Lindenstrauss Transforms via Kronecker Products." arXiv preprint arXiv:1909.04801 (2019).&lt;/ref&gt; the same year, showed a similar result for the more general class of matrices call [[Restricted isometry property|RIP]], which includes the subsampled Hadamard matrices.
They showed that these matrices allow splitting into tensors provided the number of rows is &lt;math&gt;\varepsilon^{-2}(\log1/\delta)^{2c-1}\log d&lt;/math&gt;.
In the case &lt;math&gt;c=2&lt;/math&gt; this matches the previous result.

These fast constructions can again be combined with the recursion approach mentioned above, giving the fastest overall tensor sketch.

==Data aware sketching==
It is also possible to do so-called "data aware" tensor sketching.
Instead of multiplying a random matrix on the data, the data points are sampled independently with a certain probability depending on the norm of the point.&lt;ref&gt;{{cite conference
| title = Fast and Guaranteed Tensor Decomposition via Sketching
| first1 = Yining
| last1 = Wang
| first2 = Hsiao-Yu
| last2 = Tung
| first3 = Alexander
| last3 = Smola
| first4 = Anima
| last4 = Anandkumar
| conference = Advances in Neural Information Processing Systems 28 (NIPS 2015)
}}&lt;/ref&gt;

==Applications==

===Explicit polynomial kernels===
[[Kernel methods]] are popular in [[machine learning]] as they give the algorithm designed the freedom to design a "feature space" in which to measure the similarity of their data points.
A simple kernel-based binary classifier is based on the following computation:

:&lt;math&gt;\hat{y}(\mathbf{x'}) = \sgn \sum_{i=1}^n y_i k(\mathbf{x}_i, \mathbf{x'}),&lt;/math&gt;

where &lt;math&gt;\mathbf{x}_i\in\mathbb{R}^d&lt;/math&gt; are the data points, &lt;math&gt;y_i&lt;/math&gt; is the label of the &lt;math&gt;i&lt;/math&gt;th point (either −1 or +1), and &lt;math&gt;\hat{y}(\mathbf{x'})&lt;/math&gt; is the prediction of the class of &lt;math&gt;\mathbf{x'}&lt;/math&gt;.
The function &lt;math&gt;k : \mathbb{R}^d \times \mathbb R^d \to \mathbb R&lt;/math&gt; is the kernel.
Typical examples are the [[radial basis function kernel]], &lt;math&gt;k(x,x') = \exp(-\|x-x'\|_2^2)&lt;/math&gt;, and [[polynomial kernel]]s such as &lt;math&gt;k(x,x') = (1+\langle x, x'\rangle)^2&lt;/math&gt;.

When used this way, the kernel method is called "implicit".
Sometimes it is faster to do an "explicit" kernel method, in which a pair of functions &lt;math&gt;f, g : \mathbb{R}^d \to \mathbb{R}^D&lt;/math&gt; are found, such that &lt;math&gt;k(x,x') = \langle f(x), g(x')\rangle&lt;/math&gt;.
This allows the above computation to be expressed as

:&lt;math&gt;\hat{y}(\mathbf{x'})
= \sgn \sum_{i=1}^n y_i \langle f(\mathbf{x}_i), g(\mathbf{x'})\rangle
= \sgn \left\langle\left(\sum_{i=1}^n y_i f(\mathbf{x}_i)\right), g(\mathbf{x'})\right\rangle,&lt;/math&gt;

where the value &lt;math&gt;\sum_{i=1}^n y_i f(\mathbf{x}_i)&lt;/math&gt; can be computed in advance.

The problem with this method is that the feature space can be very large. That is &lt;math&gt;D &gt;&gt; d&lt;/math&gt;.
For example, for the polynomial kernel &lt;math&gt;k(x,x') = \langle x,x'\rangle^3&lt;/math&gt; we get &lt;math&gt;f(x) = x\otimes x\otimes x&lt;/math&gt; and &lt;math&gt;g(x') = x'\otimes x'\otimes x'&lt;/math&gt;, where &lt;math&gt;\otimes&lt;/math&gt; is the [[tensor product]] and &lt;math&gt;f(x),g(x')\in\mathbb{R}^D&lt;/math&gt; where &lt;math&gt;D=d^3&lt;/math&gt;.
If &lt;math&gt;d&lt;/math&gt; is already large, &lt;math&gt;D&lt;/math&gt; can be much larger than the number of data points (&lt;math&gt;n&lt;/math&gt;) and so the explicit method is inefficient.

The idea of tensor sketch is that we can compute approximate functions &lt;math&gt;f', g' : \mathbb R^d \to \mathbb R^t&lt;/math&gt; where &lt;math&gt;t&lt;/math&gt; can even be ''smaller'' than &lt;math&gt;d&lt;/math&gt;, and which still have the property that &lt;math&gt;\langle f'(x), g'(x')\rangle \approx k(x,x')&lt;/math&gt;.

This method was shown in 2020&lt;ref name="highdeg"&gt;{{cite conference
| title = Oblivious Sketching of High-Degree Polynomial Kernels
| first1 = Thomas
| last1 = Ahle
| first2 = Michael
| last2 = Kapralov
| first3 = Jakob
| last3 = Knudsen
| first4 = Rasmus
| last4 = Pagh
| first5 = Ameya
| last5 = Velingker
| first6 = David
| last6 = Woodruff
| first7 = Amir
| last7 = Zandieh
| date = 2020
| publisher = Association for Computing Machinery
| conference = ACM-SIAM Symposium on Discrete Algorithms
|doi = 10.1137/1.9781611975994.9| doi-access = free
}}&lt;/ref&gt; to work even for high degree polynomials and radial basis function kernels.

===Compressed matrix multiplication===

Assume we have two large datasets, represented as matrices &lt;math&gt;X, Y\in\mathbb R^{n \times d}&lt;/math&gt;, and we want to find the rows &lt;math&gt;i,j&lt;/math&gt; with the largest inner products &lt;math&gt;\langle X_i, Y_j\rangle&lt;/math&gt;.
We could compute &lt;math&gt;Z = X Y^T \in \mathbb R^{n\times n}&lt;/math&gt; and simply look at all &lt;math&gt;n^2&lt;/math&gt; possibilities.
However, this would take at least &lt;math&gt;n^2&lt;/math&gt; time, and probably closer to &lt;math&gt;n^2d&lt;/math&gt; using standard matrix multiplication techniques.

The idea of Compressed Matrix Multiplication is the general identity

:&lt;math&gt;X Y^T = \sum_{i=1}^d X_i \otimes Y_i&lt;/math&gt;

where &lt;math&gt;\otimes&lt;/math&gt; is the [[tensor product]].
Since we can compute a ([[Linear map|linear]]) approximation to &lt;math&gt;X_i \otimes Y_i&lt;/math&gt; efficiently, we can sum those up to get an approximation for the complete product.

===Compact multilinear pooling===
[[File:Multimodal Compact Multilinear Pooling.png|thumb|Tensor sketches can be used to decrease the number of variables needed when implementing Bilinear Pooling in a [[neural network]].]]

Bilinear pooling is the technique of taking two input vectors, &lt;math&gt;x, y&lt;/math&gt; from different sources, and using the tensor product &lt;math&gt;x\otimes y&lt;/math&gt; as the input layer to a neural network.

In&lt;ref&gt;Gao, Yang, et al. "Compact bilinear pooling." Proceedings of the IEEE conference on computer vision and pattern recognition. 2016.&lt;/ref&gt; the authors considered using tensor sketch to reduce the number of variables needed.

In 2017 another paper&lt;ref&gt;Algashaam, Faisal M., et al. "Multispectral periocular classification with multimodal compact multi-linear pooling." IEEE Access 5 (2017): 14572–14578.&lt;/ref&gt; takes the FFT of the input features, before they are combined using the element-wise product.
This again corresponds to the original tensor sketch.

==References==
{{Reflist}}

==Further reading==
*{{Cite web |last=Ahle |first=Thomas |last2=Knudsen |first2=Jakob |date=2019-09-03 |title=Almost Optimal Tensor Sketch |url=https://www.researchgate.net/publication/335617805_Almost_Optimal_Tensor_Sketch |access-date=2020-07-11 |website=[[Researchgate]]}}
*{{Cite journal|last=Slyusar|first=V. I.|date= December 27, 1996|title=End products in matrices in radar applications. |url=http://slyusar.kiev.ua/en/IZV_1998_3.pdf|journal=Radioelectronics and Communications Systems.– 1998, Vol. 41; Number 3|pages=50–53}}
*{{Cite journal|last=Slyusar|first=V. I.|date=1997-05-20|title=Analytical model of the digital antenna array on a basis of face-splitting matrix products. |url=http://slyusar.kiev.ua/ICATT97.pdf|journal=Proc. ICATT-97, Kyiv|pages=108–109}}
*{{Cite journal|last=Slyusar|first=V. I.|date=1997-09-15|title=New operations of matrices product for applications of radars|url=http://slyusar.kiev.ua/DIPED_1997.pdf|journal=Proc. Direct and Inverse Problems of Electromagnetic and Acoustic Wave Theory (DIPED-97), Lviv.|pages=73–74}}
*{{Cite journal|last=Slyusar|first=V. I.|date=March 13, 1998|title=A Family of Face Products of Matrices and its Properties|url=http://slyusar.kiev.ua/FACE.pdf|journal=Cybernetics and Systems Analysis C/C of Kibernetika I Sistemnyi Analiz.- 1999.|volume=35|issue=3|pages=379–384|doi=10.1007/BF02733426}}

[[Category:Dimension reduction]]
[[Category:Tensors]]
[[Category:Machine learning]]</text>
      <sha1>8y47erkniqi3b0xx4b82c18l47x39qi</sha1>
    </revision>
  </page>
  <page>
    <title>EM algorithm and GMM model</title>
    <ns>0</ns>
    <id>64563432</id>
    <revision>
      <id>1003395415</id>
      <parentid>996120349</parentid>
      <timestamp>2021-01-28T19:54:05Z</timestamp>
      <contributor>
        <username>Warycary</username>
        <id>20942671</id>
      </contributor>
      <comment>removed [[Category:Statistics]]; added [[Category:Regression models]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="6582" xml:space="preserve">{{Multiple issues|
{{Underlinked|date=September 2020}}
{{Orphan|date=September 2020}}
}}

In statistics, [[Expectation–maximization algorithm|EM (expectation maximization)]] algorithm handles latent variables, while [[Mixture model#Gaussian mixture model|GMM]] is the Gaussian mixture model.

== Background ==
In the picture below, are shown the red blood cell [[hemoglobin concentration]] and the red blood cell volume data of two groups of people, the Anemia group and the Control Group (i.e. the group of people without Anemia). As expected, people with Anemia have lower red blood cell volume and lower red blood cell hemoglobin concentration than those without Anemia.
[[File:Labeled GMM.png|thumb|GMM model with labels]]
&lt;math&gt;x&lt;/math&gt; is a random vector such as &lt;math&gt;x:=\big(\text{red blood cell volume}, \text{red blood cell hemoglobin concentration}\big)&lt;/math&gt;, and from medical studies [cite source] it is known that &lt;math&gt;x&lt;/math&gt; are normally distributed in each group, i.e. &lt;math&gt;x \sim \mathcal N(\mu, \Sigma)&lt;/math&gt;.

&lt;math&gt;z&lt;/math&gt; is denoted as the group where &lt;math&gt;x&lt;/math&gt; belongs, with &lt;math&gt;z_i = 0&lt;/math&gt; when &lt;math&gt;x_i&lt;/math&gt; belongs to Anemia Group and &lt;math&gt;z_i=1&lt;/math&gt; when &lt;math&gt;x_i&lt;/math&gt; belongs to Control Group. Also &lt;math&gt;z \sim \operatorname{Categorical}(k, \phi)&lt;/math&gt; where &lt;math&gt;k=2&lt;/math&gt;, &lt;math&gt;\phi_j \geq 0,&lt;/math&gt; and &lt;math&gt;\sum_{j=1}^k\phi_j=1&lt;/math&gt;. See [[Categorical distribution]].

The following procedure can be used to estimate &lt;math&gt;\phi, \mu , \Sigma&lt;/math&gt;.

A maximum likelihood estimation can be applied:

: &lt;math&gt;\ell(\phi,\mu,\Sigma)=\sum_{i=1}^m \log (p(x^{(i)};\phi,\mu,\Sigma))
=\sum_{i=1}^m \log \sum_{z^{(i)}=1}^k p\left(x^{(i)} \mid z^{(i)} ; \mu, \Sigma\right) p(z^{(i)} ; \phi)
&lt;/math&gt;

As the &lt;math&gt;z_i&lt;/math&gt; for each &lt;math&gt;x_i&lt;/math&gt; are known, the log likelihood function can be simplified as below:

: &lt;math&gt;\ell(\phi, \mu, \Sigma)=\sum_{i=1}^{m} \log p\left(x^{(i)} \mid z^{(i)} ; \mu, \Sigma\right)+\log p\left(z^{(i)} ; \phi\right)&lt;/math&gt;

Now the likelihood function can be maximized by making partial derivative over &lt;math&gt;\mu, \Sigma, \phi&lt;/math&gt;, obtaining:

: &lt;math&gt;\phi_{j} =\frac{1}{m} \sum_{i=1}^m 1\{z^{(i)}=j\}&lt;/math&gt;

: &lt;math&gt;\mu_j =\frac{\sum_{i=1}^m 1\{z^{(i)}=j\} x^{(i)}}{\sum_{i=1}^{m} 1\left\{z^{(i)}=j\right\}}&lt;/math&gt;

: &lt;math&gt;\Sigma_j =\frac{\sum_{i=1}^m 1\{z^{(i)}=j\} (x^{(i)}-\mu_j)(x^{(i)}-\mu_j)^T}{\sum_{i=1}^m 1\{z^{(i)}=j\}}&lt;/math&gt;&lt;ref name="Stanford CS229 Notes"&gt;{{cite web |last1=Ng |first1=Andrew |title=CS229 Lecture notes |url=http://cs229.stanford.edu/notes/cs229-notes8.pdf}}&lt;/ref&gt;

If &lt;math&gt;z_i&lt;/math&gt; is known, the estimation of the parameters results to be quite simple with maximum likelihood estimation. But if &lt;math&gt;z_i&lt;/math&gt; is unknown it is much more complicated.&lt;ref name="Machine Learning —Expectation-Maximization Algorithm (EM)"&gt;{{cite web |last1=Hui |first1=Jonathan |title=Machine Learning —Expectation-Maximization Algorithm (EM) |url=https://medium.com/@jonathan_hui/machine-learning-expectation-maximization-algorithm-em-2e954cb76959 |website=Medium |language=en |date=13 October 2019}}&lt;/ref&gt;
[[File:Unlabeled GMM.png|thumb|GMM without labels]]

Being &lt;math&gt;z&lt;/math&gt; a latent variable (i.e. not observed), with unlabelled scenario, the Expectation Maximization [[Algorithm]] is needed to estimate &lt;math&gt;z&lt;/math&gt; as well as other parameters. Generally, this problem is set as a GMM since the data in each group is normally distributed.
&lt;ref name="Multivariate normal distribution"&gt;{{cite web |last1=Tong |first1=Y. L. |title=Multivariate normal distribution |url=https://en.wikipedia.org/wiki/Multivariate_normal_distribution |website=Wikipedia |language=en |date=2 July 2020}}&lt;/ref&gt;{{Circular reference|date=July 2020}}

In machine learning, the latent variable &lt;math&gt;z&lt;/math&gt; is considered as a latent pattern lying under the data, which the observer is not able to see very directly.  &lt;math&gt;x_i&lt;/math&gt; is the known data, while &lt;math&gt;\phi, \mu, \Sigma&lt;/math&gt; are the parameter of the model. With the EM algorithm, some underlying pattern &lt;math&gt;z&lt;/math&gt; in the data &lt;math&gt;x_i&lt;/math&gt; can be found, along with the estimation of the parameters. The wide application of this circumstance in machine learning is what makes EM algorithm so important.&lt;ref name="Inference using EM algorithm"&gt;{{cite web |last1=Misra |first1=Rishabh |title=Inference using EM algorithm |url=https://towardsdatascience.com/inference-using-em-algorithm-d71cccb647bc |website=Medium |language=en |date=7 June 2020}}&lt;/ref&gt;

== EM algorithm in GMM ==
The EM algorithm consists of two steps: the E-step and the M-step. Firstly, the model parameters and the &lt;math&gt;z^{(i)}&lt;/math&gt; can be randomly initialized. In the E-step, the algorithm tries to guess the value of &lt;math&gt;z^{(i)}&lt;/math&gt; based on the parameters, while in the M-step, the algorithm updates the value of the model parameters based on the guess of &lt;math&gt;z^{(i)}&lt;/math&gt;of the E-step. These two steps are repeated until convergence is reached.

The algorithm in GMM is:

Repeat until convergence:

    1. (E-step) For each &lt;math&gt;i, j&lt;/math&gt;, set

    &lt;math&gt;w_{j}^{(i)}:=p\left(z^{(i)}=j | x^{(i)} ; \phi, \mu, \Sigma\right)&lt;/math&gt;

    2. (M-step) Update the parameters
    &lt;math&gt;\phi_{j} :=\frac{1}{m} \sum_{i=1}^{m} w_{j}^{(i)}&lt;/math&gt;
       &lt;math&gt;\mu_{j} :=\frac{\sum_{i=1}^{m} w_{j}^{(i)} x^{(i)}}{\sum_{i=1}^{m} w_{j}^{(i)}}&lt;/math&gt;
       &lt;math&gt;\Sigma_{j} :=\frac{\sum_{i=1}^{m} w_{j}^{(i)}\left(x^{(i)}-\mu_{j}\right)\left(x^{(i)}-\mu_{j}\right)^{T}}{\sum_{i=1}^{m} w_{j}^{(i)}}&lt;/math&gt;

&lt;ref name="Stanford CS229 Notes"&gt;{{cite web |last1=Ng |first1=Andrew |title=CS229 Lecture notes |url=http://cs229.stanford.edu/notes/cs229-notes8.pdf}}&lt;/ref&gt;

With Bayes Rule, the following result is obtained by the E-step:

&lt;math&gt;p\left(z^{(i)}=j | x^{(i)} ; \phi, \mu, \Sigma\right)=\frac{p\left(x^{(i)} | z^{(i)}=j ; \mu, \Sigma\right) p\left(z^{(i)}=j ; \phi\right)}{\sum_{l=1}^{k} p\left(x^{(i)} | z^{(i)}=l ; \mu, \Sigma\right) p\left(z^{(i)}=l ; \phi\right)}&lt;/math&gt;

According to GMM setting, these following formulas are obtained:
&lt;math&gt;p\left(x^{(i)} | z^{(i)}=j ; \mu, \Sigma\right)=\frac{1}{(2 \pi)^{n / 2}\left|\Sigma_{j}\right|^{1 / 2}} \exp \left(-\frac{1}{2}\left(x^{(i)}-\mu_{j}\right)^{T} \Sigma_{j}^{-1}\left(x^{(i)}-\mu_{j}\right)\right)&lt;/math&gt;
&lt;math&gt;p\left(z^{(i)}=j ; \phi\right)=\phi_j&lt;/math&gt;

In this way, a switch between the E-step and the M-step is possible, according to the randomly initialized parameters.

== References ==
{{Reflist}}

[[Category:Machine learning]]
[[Category:Regression models]]</text>
      <sha1>1n4m75icmqgmtx5s3k4tihl8j3po86s</sha1>
    </revision>
  </page>
  <page>
    <title>Tsetlin machine</title>
    <ns>0</ns>
    <id>57316019</id>
    <revision>
      <id>1005468268</id>
      <parentid>1005464385</parentid>
      <timestamp>2021-02-07T20:34:19Z</timestamp>
      <contributor>
        <username>Diannaa</username>
        <id>10728040</id>
      </contributor>
      <comment>remove copyright content from https://ieeexplore.ieee.org/document/9308291, https://link.springer.com/chapter/10.1007%2F978-3-030-63799-6_5, or elsewehere. See https://copypatrol.toolforge.org/en/?id=68198790</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="18762" xml:space="preserve">A '''Tsetlin Machine''' is an [[Artificial intelligence|Artificial Intelligence]] algorithm based on [[Propositional calculus|propositional logic.]]

[[File:Tm block.png|thumb|433x433px|A simple block diagram of the Tsetlin Machine]]

{{Machine learning bar}}

== Background ==
A '''Tsetlin machine''' is a form of [[learning automaton]] based upon algorithms from [[reinforcement learning]] to learn expressions from [[propositional logic]]. [[Ole-Christoffer Granmo]] gave the method its name after [[Michael Lvovitch Tsetlin]] and his [[Tsetlin automata]]. The method uses computationally simpler and more efficient primitives compared to more ordinary [[artificial neural network]]s, but while the method may be faster it has a steep drop in signal-to-noise ratio as the signal space increases.&lt;ref name=":5"&gt;{{cite arxiv|eprint=1804.01508|class=cs.AI|first=Ole-Christoffer|last=Granmo|title=The Tsetlin Machine - A Game Theoretic Bandit Driven Approach to Optimal Pattern Recognition with Propositional Logic|date=2018-04-04}}&lt;/ref&gt;

As of April 2018 it has shown promising results on a number of test sets.&lt;ref&gt;{{Cite web|last=Christiansen|first=Atle|title=The Tsetlin Machine outperforms neural networks - Center for Artificial Intelligence Research|url=https://cair.uia.no/milestones-and-discoveries/the-tsetlin-machine-outperforms-neural-networks/|access-date=2018-05-03|website=cair.uia.no}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|last=Øyvann|first=Stig|title=AI-gjennombrudd i Agder {{!}} Computerworld|url=http://www.cw.no/artikkel/forskning/ai-gjennombrudd-agder|access-date=2018-05-04|website=Computerworld|language=no}}&lt;/ref&gt;

== Types ==

* Original Tsetlin Machine&lt;ref name=":5" /&gt;
* Convolutional Tsetlin Machine&lt;ref name=":0"&gt;{{cite arxiv|last1=Granmo|first1=Ole-Christoffer|last2=Glimsdal|first2=Sondre|last3=Jiao|first3=Lei|last4=Goodwin|first4=Morten|last5=Omlin|first5=Christian W.|last6=Berge|first6=Geir Thore|date=2019-12-27|title=The Convolutional Tsetlin Machine|class=cs.LG|eprint=1905.09688}}&lt;/ref&gt;
* Regression Tsetlin Machine&lt;ref&gt;{{cite journal|last1=Abeyrathna|first1=K. Darshana|last2=Granmo|first2=Ole-Christoffer|last3=Zhang|first3=Xuan|last4=Jiao|first4=Lei|last5=Goodwin|first5=Morten|date=2020|title=The regression Tsetlin machine: a novel approach to interpretable nonlinear regression|url=https://royalsocietypublishing.org/doi/10.1098/rsta.2019.0165|journal=Philosophical Transactions of the Royal Society A|language=en}}"&lt;/ref&gt;
* Weighted Tsetlin Machine&lt;ref&gt;{{cite arxiv|last1=Phoulady|first1=Adrian|last2=Granmo|first2=Ole-Christoffer|last3=Gorji|first3=Saeed Rahimi|last4=Phoulady|first4=Hady Ahmady|date=2019-11-28|title=The Weighted Tsetlin Machine: Compressed Representations with Weighted Clauses|class=cs.LG|eprint=1911.12607}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Abeyrathna|first1=K. Darshana|last2=Granmo|first2=Ole-Christffer|last3=Goodwin|first3=Morten|date=2021|title=Extending the Tsetlin Machine With Integer-Weighted Clauses for Increased Interpretability|url=https://ieeexplore.ieee.org/document/9316190|journal=IEEE Access|language=en}}"&lt;/ref&gt;
* Arbitrarily Deterministic Tsetlin Machine&lt;ref&gt;{{cite arxiv|last1=Abeyrathna|first1=K. Darshana|last2=Granmo|first2=Ole-Christoffer|last3=Shafik|first3=Rishad|last4=Yakovlev|first4=Alex|last5=Wheeldon|first5=Adrian|last6=Lei|first6=Jie|last7=Goodwin|first7=Morten|date=2020-07-04|title=A Novel Multi-Step Finite-State Automaton for Arbitrarily Deterministic Tsetlin Machine Learning|class=cs.LG|eprint=2007.02114}}&lt;/ref&gt;
* Parallel Asynchronous Tsetlin Machine&lt;ref&gt;{{cite arxiv|last1=Abeyrathna|first1=K. Darshana|last2=Bhattarai|first2=Bimal|last3=Goodwin|first3=Morten|last4=Gorji|first4=Saeed|last5=Granmo|first5=Ole-Christoffer|last6=Jiao|first6=Lei|last7=Saha|first7=Rupsa|last8=Yadav|first8=Rohan K.|date=2020-09-10|title=Massively Parallel and Asynchronous Tsetlin Machine Architecture Supporting Almost Constant-Time Scaling|class=cs.LG|eprint=2009.04861}}&lt;/ref&gt;

== Applications ==

* Keyword Spotting&lt;ref&gt;{{cite arxiv|last1=Lei|first1=Jie|last2=Shafik|first2=Rishad|last3=Wheeldon|first3=Adrian|last4=Yakovlev|first4=Alex|last5=Granmo|first5=Ole-Christoffer|last6=Kawsar|first6=Fahim|last7=Akhil|first7=Mathur|date=2021-01-27|title=Low-Power Audio Keyword Spotting using Tsetlin Machines|class=cs.SD|eprint=2101.11336}}&lt;/ref&gt;
* Aspect-Based Sentiment Analysis&lt;ref&gt;{{cite conference|title=Human-Level Interpretable Learning for Aspect-Based Sentiment Analysis|first1=Rohan Kumar|last1=Yadav|first2=Lei|last2=Jiao|first3=Ole-Christoffer|last3=Granmo|first4=Morten|last4=Goodwin|year=2021|conference=The Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-21)|conference-url=https://aaai.org/Conferences/AAAI-21/|publisher=AAAI}}&lt;/ref&gt;
* Word Sense Disambiguation&lt;ref&gt;{{cite conference|title=Interpretability in Word Sense Disambiguation using Tsetlin Machine|first1=Rohan Kumar|last1=Yadav|first2=Lei|last2=Jiao|first3=Ole-Christoffer|last3=Granmo|first4=Morten|last4=Goodwin|year=2021|conference=13th International Conference on Agents and Artificial Intelligence (ICAART 2021)|publisher=INSTICC}}&lt;/ref&gt;
* Novelty Detection&lt;ref&gt;{{cite conference|title=Measuring the Novelty of Natural Language Text Using the Conjunctive Clauses of a Tsetlin Machine Text Classifier|first1=Bimal|last1=Bhattarai|first3=Lei|last3=Jiao|first2=Ole-Christoffer|last2=Granmo|year=2021|conference=13th International Conference on Agents and Artificial Intelligence (ICAART 2021)|publisher=INSTICC}}&lt;/ref&gt;
* Intrusion Detection&lt;ref&gt;{{cite conference|title=Intrusion Detection with Interpretable Rules Generated Using the Tsetlin Machine|first1=K. Darshana|last1=Abeyrathna|first3=Sasanka N.|last3=Ranasinghea|first2=Harsha S. Gardiyawasam|last2=Pussewalage|first4=Vladimir A.|last4=Oleshchuk|first5=Ole-Christoffer|last5=Granmo|year=2020|conference=2020 IEEE Symposium Series on Computational Intelligence (SSCI)|publisher=IEEE}}&lt;/ref&gt;
* Semantic Relation Analysis&lt;ref&gt;{{cite conference|title=Mining Interpretable Rules for Sentiment and Semantic Relation Analysis using Tsetlin Machines|first1=Rupsa|last1=Saha|first2=Ole-Christoffer|last2=Granmo|first3=Morten|last3=Goodwin|year=2020|conference=Lecture Notes in Computer Science: Proceedings of the 40th International Conference on Innovative Techniques and Applications of Artificial Intelligence (SGAI-2020)|publisher=Springer}}&lt;/ref&gt;
* Image Analysis&lt;ref name=":0"/&gt;
* Text Categorization&lt;ref&gt;{{cite journal|last1=Berge|first1=Geir Thore|last2=Granmo|first2=Ole-Christffer|last3=Tveit|first3=Tor O.|last4=Goodwin|first4=Morten|last5=Jiao|first5=Lei|last6=Matheussen|first6=Bernt Viggo|date=2019|title=Using the Tsetlin Machine to Learn Human-Interpretable Rules for High-Accuracy Text Categorization with Medical Applications|url=https://ieeexplore.ieee.org/document/8798633|journal=IEEE Access|language=en}}"&lt;/ref&gt;

== Original Tsetlin Machine ==
[[File:Tm block detailed.png|alt=A detailed block diagram of the original Tsetlin Machine|thumb|A detailed block diagram of the original Tsetlin Machine|361x361px]] 
{| class="wikitable"
|+
List of Hyperparameters&lt;ref name=":4" /&gt;
!Description 
!Symbol
|-
|Number of binary inputs
|&lt;math&gt;N_{Inputs}&lt;/math&gt;
|-
|Number of classes
|&lt;math&gt;N_{Classes}&lt;/math&gt;
|-
|Number of clauses per class
|&lt;math&gt;N_{Clauses}&lt;/math&gt;
|-
|Number of automaton states
|&lt;math&gt;2n&lt;/math&gt;
|-
|Automaton decision boundary
|&lt;math&gt;n&lt;/math&gt;
|-
|Automaton initialization state
|&lt;math&gt;\varnothing_{Init}&lt;/math&gt;
|-
|Feedback threshold 
|&lt;math&gt;T&lt;/math&gt;
|-
|Learning Sensitivity
|&lt;math&gt;s&lt;/math&gt;
|}

=== Tsetlin Automaton ===
[[File:A six states TA.png|thumb|363x363px]]The Tsetlin Automaton is the fundamental 'learning unit' of the Tsetlin machine. It solves the bandit problem, learning the optimal action in an environment from penalties and rewards. Computationally, it can be seen as an [[Finite-state machine|FSM]] that changes its states based on the inputs. The FSM will generate its outputs based on the current states. 
* A quintuple describes a two-action Tsetlin Automaton:

&lt;math&gt;\{\underline{\Phi}, \underline{\alpha}, \underline{\beta}, F(\cdot,\cdot), G(\cdot)\}.&lt;/math&gt;
* A Tsetlin Automaton consists of &lt;math&gt;2n&lt;/math&gt; states, here &lt;math&gt;6&lt;/math&gt;:

&lt;math&gt;\underline{\Phi} = \{\phi_1, \phi_2, \phi_3, \phi_4, \phi_5, \phi_6\}&lt;/math&gt;

* The FSM can be triggered by two input events

&lt;math&gt;\underline{\beta} = \{\beta_{\mathrm{Penalty}}, \beta_{\mathrm{Reward}}\}&lt;/math&gt;

* The rules of state migration of the FSM are stated as

&lt;math&gt;F(\phi_u, \beta_v) = \begin{cases}
     \phi_{u+1},&amp; \mathbf{if}~ 1 \le u \le 3 ~\mathbf{and}~ v = \text{Penalty}\\
     \phi_{u-1},&amp; \mathbf{if}~ 4 \le u \le 6 ~\mathbf{and}~ v = \text{Penalty}\\
     \phi_{u-1},&amp; \mathbf{if}~ 1 &lt; u \le 3 ~\mathbf{and}~ v = \text{Reward}\\
     \phi_{u+1},&amp; \mathbf{if}~ 4 \le u &lt; 6 ~\mathbf{and}~ v = \text{Reward}\\
     \phi_{u},&amp; \mathbf{otherwise}.
     \end{cases}&lt;/math&gt;

* It includes two output actions

&lt;math&gt;\underline{\alpha} = \{\alpha_1, \alpha_2\}&lt;/math&gt;

* Which can be generated by the algorithm

&lt;math&gt;G(\phi_u) = \begin{cases}
       \alpha_1, &amp; \mathbf{if}~ 1 \le u \le 3\\
       \alpha_2, &amp; \mathbf{if}~ 4 \le u \le 6.
     \end{cases}&lt;/math&gt;

=== Boolean Input ===

A basic Tsetlin Machine takes a vector &lt;math&gt;X=[x_1,\ldots,x_o]&lt;/math&gt; of &lt;math&gt;o&lt;/math&gt; Boolean features as input, to be classified into one of two classes, &lt;math&gt;y=0&lt;/math&gt; or &lt;math&gt;y=1&lt;/math&gt;. Together with their negated counterparts, &lt;math&gt;{\lnot} {x}_k&lt;/math&gt;, the features form a literal set &lt;math&gt;L = \{x_1,\ldots,x_o, \lnot x_1,\ldots, \lnot x_o\}&lt;/math&gt;.

=== Clauses Computing Module ===

A Tsetlin Machine pattern is formulated as a conjunctive clause &lt;math&gt;C_j&lt;/math&gt;, formed by ANDing a subset &lt;math&gt;L_j {\subseteq} L&lt;/math&gt; of the literal set:

&lt;center&gt;
&lt;math&gt;C_j (X)=\bigwedge_{{{l}_{k}} {\in} L_j} l_k&lt;/math&gt;.
&lt;/center&gt;

For example, the clause &lt;math&gt;C_j(X) = x_1 {\land} x_2 &lt;/math&gt; consists of the literals &lt;math&gt;L_j = \{x_1, x_2\}&lt;/math&gt; and outputs &lt;math&gt;1&lt;/math&gt; iff &lt;math&gt;x_1 = x_2 = 1&lt;/math&gt;.

=== Summation and Threshold Module ===

The number of clauses employed is a user-configurable parameter &lt;math&gt;n&lt;/math&gt;. Half of the clauses are assigned positive polarity. The other half is assigned negative polarity. The clause outputs, in turn, are combined into a classification decision through summation and thresholding using the unit step function &lt;math&gt;u(v) = 1 ~\mathbf{if}~ v \ge 0 ~\mathbf{else}~ 0&lt;/math&gt;:

&lt;center&gt;
&lt;math&gt;
\hat{y} = u\left(\sum_{j=1}^{n/2} C_j^+(X) - \sum_{j=1}^{n/2} C_j^-(X)\right).
&lt;/math&gt;
&lt;/center&gt;

In other words, classification is based on a majority vote, with the positive clauses voting for &lt;math&gt;y=1&lt;/math&gt; and the negative for &lt;math&gt;y=0&lt;/math&gt;. The classifier

&lt;center&gt;
&lt;math&gt;\hat{y} = u\left((x_1 \land \lnot x_2) + (\lnot x_1 \land x_2) - (x_1 \land x_2) - (\lnot x_1 \land \lnot x_2)\right)&lt;/math&gt;,
&lt;/center&gt;

for instance, captures the XOR-relation.

==== Resource Allocation ====

Resource allocation dynamics ensure that clauses distribute themselves across the frequent patterns, rather than missing some and overconcentrating on others. That is, for any input &lt;math&gt;X&lt;/math&gt;, the probability of reinforcing a clause gradually drops to zero as the clause output sum

&lt;center&gt;
&lt;math&gt;
v = \sum_{j=1}^{n/2} C_j^+(X) - \sum_{j=1}^{n/2} C_j^-(X)
&lt;/math&gt;
&lt;/center&gt;

approaches a user-set target &lt;math&gt;T&lt;/math&gt; for &lt;math&gt;y=1&lt;/math&gt; (&lt;math&gt;-T&lt;/math&gt; for &lt;math&gt;y=0&lt;/math&gt;).

If a clause is not reinforced, it does not give feedback to its Tsetlin Automata, and these are thus left unchanged.  In the extreme, when the voting sum &lt;math&gt;v&lt;/math&gt; equals or exceeds the target &lt;math&gt;T&lt;/math&gt; (the Tsetlin Machine has successfully recognized the input &lt;math&gt;X&lt;/math&gt;, no clauses are reinforced. Accordingly, they are free to learn new patterns, naturally balancing the pattern representation resources.

== Implementations ==

=== Software ===

* Tsetlin Machine in C language,&lt;ref&gt;{{Citation|title=cair/TsetlinMachineC|date=2019-04-18|url=https://github.com/cair/TsetlinMachineC|publisher=Centre for Artificial Intelligence Research (CAIR)|access-date=2020-07-27}}&lt;/ref&gt; on Python,&lt;ref&gt;{{Citation|title=cair/pyTsetlinMachine|date=2020-07-07|url=https://github.com/cair/pyTsetlinMachine|publisher=Centre for Artificial Intelligence Research (CAIR)|access-date=2020-07-27}}&lt;/ref&gt;&lt;ref&gt;{{Citation|title=cair/TsetlinMachine|date=2020-07-27|url=https://github.com/cair/TsetlinMachine|publisher=Centre for Artificial Intelligence Research (CAIR)|access-date=2020-07-27}}&lt;/ref&gt; on multithreaded Python &lt;ref&gt;{{Citation|title=cair/pyTsetlinMachineParallel|date=2020-07-07|url=https://github.com/cair/pyTsetlinMachineParallel|publisher=Centre for Artificial Intelligence Research (CAIR)|access-date=2020-07-27}}&lt;/ref&gt;， on CUDA &lt;ref&gt;{{Citation|title=cair/PyTsetlinMachineCUDA|date=2020-07-27|url=https://github.com/cair/PyTsetlinMachineCUDA|publisher=Centre for Artificial Intelligence Research (CAIR)|access-date=2020-07-27}}&lt;/ref&gt;
* Convolutional Tsetlin Machine &lt;ref&gt;{{Cite web|title=cair/convolutional-tsetlin-machine-tutorial|url=https://github.com/cair/convolutional-tsetlin-machine-tutorial|access-date=2020-07-27|website=GitHub|language=en}}&lt;/ref&gt;&lt;ref name=":0" /&gt;
* Weighted Tsetlin Machine in C++ &lt;ref&gt;{{Citation|last=Phoulady|first=Adrian|title=adrianphoulady/weighted-tsetlin-machine-cpp|date=2020-04-13|url=https://github.com/adrianphoulady/weighted-tsetlin-machine-cpp|access-date=2020-07-27}}&lt;/ref&gt;

=== Hardware ===
* One of the first [[Field-programmable gate array|FPGA]]-based hardware implementation&lt;ref name=":1"&gt;{{Citation|last=JieGH|title=JieGH/Hardware_TM_Demo|date=2020-03-22|url=https://github.com/JieGH/Hardware_TM_Demo|access-date=2020-07-22}}&lt;/ref&gt;&lt;ref name=":2"&gt;{{Cite web|last=JieGH|date=|title=Tsetlin Machine on Iris Data Set Demo, Handheld #MignonAI|url=https://www.youtube.com/watch?v=BzaPGByX-hg&amp;feature=youtu.be|url-status=live|archive-url=|archive-date=|access-date=|website=Youtube}}&lt;/ref&gt; of the Tsetlin Machine on the [[Iris (plant)|Iris]] dataset was developed by the µSystems (microSystems) Research Group at [[Newcastle University]].
* They also presented the first [[Application-specific integrated circuit|ASIC]] &lt;ref&gt;{{Cite web|title=https://twitter.com/olegranmo/status/1279045633916182528|url=https://twitter.com/olegranmo/status/1279045633916182528|access-date=2020-07-27|website=Twitter|language=en}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|title=mignon|url=http://www.mignon.ai/|access-date=2020-07-27|website=www.mignon.ai}}&lt;/ref&gt; implementation of the Tsetlin Machine focusing on energy frugality, claiming it could deliver 10 trillion operation per Joule.&lt;ref name="Bush"&gt;{{Cite web|last=Bush|first=Steve|date=2020-07-27|title=A low-power AI alternative to neural networks|url=https://www.electronicsweekly.com/news/research-news/low-power-ai-alternative-neural-networks-2020-07/|access-date=2020-07-27|website=Electronics Weekly|language=en-GB}}&lt;/ref&gt; The [[Application-specific integrated circuit|ASIC]] design had demoed on DATA2020.&lt;ref name=":3"&gt;{{Cite web|last=|first=|date=|title=Tsetlin Machine -- A new paradigm for pervasive AI|url=https://www.youtube.com/watch?v=TaspuovmSR8|url-status=live|archive-url=|archive-date=|access-date=|website=}}&lt;/ref&gt;

== Additional Read ==

=== Videos ===

* Tsetlin Machine—A new paradigm for pervasive [[Artificial intelligence|AI]] &lt;ref name=":3" /&gt;
* Keyword Spotting Using Tsetlin Machines &lt;ref&gt;{{Cite web|last=|first=|date=|title=Keyword Spotting Using Tsetlin Machines|url=https://www.youtube.com/watch?v=JW0tztpjX8k|url-status=live|archive-url=|archive-date=|access-date=|website=}}&lt;/ref&gt;
* IOLTS Presentation: Explainability and [[Dependability]] Analysis of [[Learning automaton|Learning Automata]] based AI hardware &lt;ref&gt;{{Cite web|last=|first=|date=|title=IOLTS Presentation: Explainability and Dependability Analysis of Learning Automata based AI hardware|url=https://www.youtube.com/watch?v=IjzZY0fDYiA&amp;feature=youtu.be|url-status=live|archive-url=|archive-date=|access-date=|website=}}&lt;/ref&gt;
* FPGA and uC co-design: Tsetlin Machine on Iris demo &lt;ref name=":1" /&gt;&lt;ref name=":2" /&gt;
* The-Ruler-of-Tsetlin-Automaton  &lt;ref&gt;{{Cite web|last=|first=|date=|title=The-Ruler-of-Tsetlin-Automaton|url=https://www.youtube.com/watch?v=LltDhg4ZuWo|url-status=live|archive-url=|archive-date=|access-date=|website=}}&lt;/ref&gt;
* [[Interpretation (model theory)|Interpretable]] clustering and [[Dimensionality reduction|dimension reduction]] with Tsetlin automata machine learning.&lt;ref&gt;{{Cite web|last=|first=|date=|title=Interpretable Clustering &amp; Dimension Reduction with Tsetlin Automata machine learning|url=https://www.youtube.com/watch?v=5-09LOGLcV8&amp;feature=youtu.be|url-status=live|archive-url=|archive-date=|access-date=|website=}}&lt;/ref&gt;
* Predicting and explaining economic growth using real-time [[Interpretation (model theory)|interpretable]] learning &lt;ref&gt;{{Cite web|last=|first=|date=|title=Predicting and explaining economic growth using real-time interpretable learning|url=https://www.youtube.com/watch?v=J6K7V7V7ayo&amp;feature=youtu.be|url-status=live|archive-url=|archive-date=|access-date=|website=}}&lt;/ref&gt;
* Early detection of breast cancer from a simple blood test&lt;ref&gt;{{Cite web|last=|first=|date=|title=Early detection of breast cancer from a simple blood test|url=https://www.youtube.com/watch?v=FrHN_aRLRug&amp;feature=youtu.be|url-status=live|archive-url=|archive-date=|access-date=|website=}}&lt;/ref&gt;
* Recent advances in Tsetlin Machines &lt;ref&gt;{{Cite web|last=|first=|date=|title=Recent advances in Tsetlin Machines|url=https://www.youtube.com/watch?v=GHelDh3bN00&amp;feature=youtu.be|url-status=live|archive-url=|archive-date=|access-date=|website=}}&lt;/ref&gt;

=== Papers ===
* [[Learning automaton|Learning Automata]] based Energy-efficient AI Hardware Design for IoT Applications &lt;ref name=":4"&gt;{{Cite journal|last1=Wheeldon|first1=A.|last2=Shafik|first2=R.|last3=Rahman|first3=T.|last4=Lei|first4=J.|last5=Yakovlev|first5=A.|last6=Granmo|first6=O. C.|date=2020|title=Learning Automata based Energy-efficient AI Hardware Design for IoT Applications|url=https://eprint.ncl.ac.uk/268038|journal=Philosophical Transactions of the Royal Society A|language=en}}&lt;/ref&gt;

=== Publications/News/Articles ===

* A low-power AI alternative to [[neural network]]s &lt;ref name="Bush"/&gt;

== Partners ==
&lt;gallery widths="260" heights="70"&gt;
File:Cair logo wide.png|The Centre for Artificial Intelligence Research (CAIR) at the University of Agder             https://twitter.com/CairEnglish    https://cair.uia.no/about-cair/
&lt;/gallery&gt;

== References ==
&lt;references /&gt;

[[Category:Finite automata]]
[[Category:Artificial intelligence]]
[[Category:Machine learning]]
[[Category:Classification algorithms]]
[[Category:Logic gates]]</text>
      <sha1>kdkw89e1axoo0b95m348scb5hn35put</sha1>
    </revision>
  </page>
  <page>
    <title>Matchbox Educable Noughts and Crosses Engine</title>
    <ns>0</ns>
    <id>63983302</id>
    <revision>
      <id>1005372591</id>
      <parentid>1005372235</parentid>
      <timestamp>2021-02-07T10:01:17Z</timestamp>
      <contributor>
        <username>WikiMacaroons</username>
        <id>35313544</id>
      </contributor>
      <comment>/* Legacy */ Another unreliable ref</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="19492" xml:space="preserve">{{good article}}
{{Use dmy dates|date=October 2020}}
{{short description|Mechanical computer made of matchboxes}}
{{use British English|date=July 2020}}
[[File:Mscroggs-MENACE-cropped.jpg|350px|thumb|A recreation of MENACE built by Matthew Scroggs|alt=MENACE recreation]]
The '''Matchbox Educable Noughts and Crosses Engine''' (sometimes called the '''Machine Educable Noughts and Crosses Engine''') or '''MENACE''' was a [[mechanical computer]] made from 304 [[matchbox]]es designed and built by [[Donald Michie]] in 1961. It was designed to play human opponents in games of [[noughts and crosses]] by returning a move for any given state of play and to refine its strategy through [[reinforcement learning]].

Michie did not have a computer readily available, so he worked around this restriction by building it out of matchboxes. The matchboxes used by Michie each represented a single possible layout of a Noughts and Crosses grid. When the computer first played, it would randomly choose moves based on the current layout. As it played more games, through a reinforcement loop, it disqualified strategies that led to losing games, and supplemented strategies that led to winning games. Michie held a tournament against MENACE in 1961, wherein he experimented with different openings.

Following MENACE's maiden tournament against Michie, it was shown to be a successful computer. Michie's essays on MENACE's weight initialisation and the BOXES algorithm used by MENACE became popular in the field of computer science research. Michie was honoured for his contribution to machine learning research, and was twice commissioned to program a MENACE simulation on an actual computer.

== Origin ==
[[File:Donald Michie teaching.jpg|275px|thumb|[[Donald Michie]] teaching a group of students at [[Turing Institute]]|alt=Donald Michie teaching]]
[[Donald Michie]] had been on the team decrypting the German [[Lorenz cipher|Tunny Code]] during [[World War II]].&lt;ref&gt;{{Cite web |title=Computer Pioneers - Donald Michie |url=https://history.computer.org/pioneers/michie.html |access-date=19 July 2020 |website=history.computer.org}}&lt;/ref&gt; Fifteen years later, he wanted to further display his mathematical and computational prowess with an early [[convolutional neural network]]. Since computer equipment was not obtainable for such uses,&lt;ref&gt;[http://www.cdpa.co.uk/UoP/HoC/Lectures/HoC_07b.PDF Lectures] Cultural Informatics Research Group&lt;/ref&gt; and Michie did not have a computer readily available,&lt;ref&gt;{{Cite web |last=Wright |first=Matt |title=Donald Michie: The AI pioneer who tested his computer program with a matchbox and some beads |url=https://scroll.in/article/955960/donald-michie-the-ai-pioneer-who-tested-his-computer-program-with-a-matchbox-and-some-beads |access-date=18 October 2020 |website=Scroll.in |language=en-US}}&lt;/ref&gt; he decided to display and demonstrate artificial intelligence in a more esoteric format and constructed a functional [[mechanical computer]] out of matchboxes and beads.&lt;ref name=":9"&gt;{{Cite web |date=21 December 2015 |title=Dr. Donald Michie |url=https://www.ithistory.org/honor-roll/dr-donald-michie |access-date=18 October 2020 |website=IT History Society |language=en}}&lt;/ref&gt;&lt;ref name=":1"&gt;{{Cite web |title=Menace: the Machine Educable Noughts And Crosses Engine |url=http://chalkdustmagazine.com/features/menace-machine-educable-noughts-crosses-engine/ |date=13 March 2016 |website=Chalkdust |language=en-GB |access-date=17 May 2020}}&lt;/ref&gt;&lt;ref name=":2" /&gt;

MENACE was reportedly constructed as the result of a [[Gambling|bet]] with a computer science colleague who postulated that such a machine was impossible.&lt;ref&gt;{{Cite news |date=9 July 2007 |title=Daily Telegraph obituary for Donald Michie |work=The Daily Telegraph |url=https://www.telegraph.co.uk/news/obituaries/1556846/Professor-Donald-Michie.html }}&lt;/ref&gt; Michie undertook the task of collecting and defining each matchbox as a 'fun project', later turned into a demonstration tool.&lt;ref name=":6"&gt;{{Cite book |last=Donald |first=Michie |title=BOXES: An experiment in adaptive control |publisher=University of Edinburgh |url=http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.474.2430&amp;rep=rep1&amp;type=pdf |citeseerx=10.1.1.474.2430|page=137}}&lt;/ref&gt; Michie completed his essay on MENACE in 1963,&lt;ref name=":2" /&gt; "Experiments on the mechanization of game-learning", as well as his essay on the BOXES Algorithm, written with R. A. Chambers&lt;ref name=":6" /&gt; and by then had built up an AI research unit in Hope Park Square, [[Edinburgh]], [[Scotland]].&lt;ref name=":7" /&gt;

MENACE "learned" by playing increasing matches of Noughts and Crosses. Each time, it would eliminate a losing strategy by the human player confiscating the beads that corresponded to each move.&lt;ref name=":8" /&gt; It reinforced winning strategies by making the moves more likely, by supplying extra beads. This was one of the earliest versions of the [[Reinforcement learning|Reinforcement Loop]], the schematic algorithm of looping the algorithm, dropping unsuccessful strategies until only the winning ones remain.&lt;ref name=":2" /&gt; This model starts as completely random, and gradually learns.

==Composition==
MENACE was made from 304 matchboxes glued together in an arrangement similar to a chest of drawers.&lt;ref name="sci"&gt;The Science Book, Second Edition, Dorling Kindersley Ltd., 2015, pg. 288&lt;/ref&gt; Each box had a code number, which was keyed into a chart. This chart had drawings of [[tic-tac-toe]] game grids with various configurations of X's, O's and empty squares,&lt;ref name=":2" /&gt; corresponding to all possible permutations a game could go through as it progressed.&lt;ref name=":8"&gt;{{Cite web |date=23 May 2018 |title=The History of Neural Networks and AI: Part II |url=https://opendatascience.com/the-history-of-neural-networks-and-ai-part-ii/ |access-date=19 September 2020 |website=Open Data Science|language=en-US}}&lt;/ref&gt;&lt;ref name=":4"&gt;{{Cite journal |last=Gardner |first=Martin |title=Mathematical Games |year=1962 |journal=Scientific American |volume=206 |issue=3 |pages=138–154 |doi=10.1038/scientificamerican0362-138 |jstor=24937263 |bibcode=1962SciAm.206c.138G}}&lt;/ref&gt; After removing duplicate arrangements (ones that were simply rotations or mirror images of other configurations), MENACE used 304 permutations in its chart and thus that many matchboxes.&lt;ref name=":0" /&gt;

Each individual matchbox tray contained a collection of coloured beads.&lt;ref&gt;core.ac.uk - ''The Machine Learning Revolution in AI'' by Luc De Raedt 
 [https://core.ac.uk/download/pdf/80808274.pdf Link]&lt;/ref&gt; Each colour represented a move on a square on the game grid, and so matchboxes with arrangements where positions on the grid were already taken would not have beads for that position. Additionally, at the front of the tray were two extra pieces of card in a "V" shape,&lt;ref name="sci" /&gt; the point of the "V" pointing at the front of the matchbox.&lt;ref name=":4" /&gt; Michie and his artificial intelligence team called MENACE's algorithm "Boxes",&lt;ref name=":7"&gt;{{Cite web |last=Muggleton |first=Stephen |date=10 July 2007 |title=Obituary for Donald Michie, an article in The Guardian from 2007. |url=https://www.theguardian.com/science/2007/jul/10/uk.obituaries1 |website=The Guardian}}&lt;/ref&gt; after the apparatus used for the machine. The first stage "Boxes" operated in five phases, each setting a definition and a precedent for the rules of the [[algorithm]] in relation to the game.&lt;ref&gt;{{Cite book |last=Russel |first=David |title=Springer Professional - Extract from "The BOXES Methodology". (Chapter 2. The Game Metaphor) |publisher=Springer London |year=2012 |isbn=9781849965279 |location=London }}&lt;/ref&gt;

==Operation==
MENACE played first, as O, since all matchboxes represented permutations only relevant to the "X" player.&lt;ref name=":10"&gt;{{Cite web |url=https://we-make-money-not-art.com/menace-2-an-artificial-intelligence-made-of-wooden-drawers-and-coloured-beads/ |title=MENACE 2, an artificial intelligence made of wooden drawers and coloured beads |date=12 April 2016}}&lt;/ref&gt;&lt;ref name=":0" /&gt; To retrieve MENACE's choice of move, the opponent or operator located the matchbox that matched the current game state, or a rotation or mirror image of it. For example, at the start of a game, this would be the matchbox for an empty grid. The tray would be removed and lightly shaken so as to move the beads around.&lt;ref name=":2" /&gt; Then, the bead that had rolled into the point of the "V" shape at the front of the tray was the move MENACE had chosen to make.&lt;ref name=":2" /&gt; Its colour was then used as the position to play on, and, after accounting for any rotations or flips needed based on the chosen matchbox configuration's relation to the current grid, the O would be placed on that square. Then the player performed their move, the new state was located, a new move selected, and so on, until the game was finished.&lt;ref name=":0" /&gt;

When the game had finished, the human player observed the game's outcome. As a game was played, each matchbox that was used for MENACE's turn had its tray returned to it ajar, and the bead used kept aside, so that MENACE's choice of moves and the game states they belonged to were recorded. Michie described his reinforcement system with "reward" and "punishment". Once the game was finished, if MENACE had won, it would then receive a "reward" for its victory. The removed beads showed the sequence of the winning moves.&lt;ref name=":10" /&gt; These were returned to their respective trays, easily identifiable since they were slightly open, as well as three bonus beads of the same colour.&lt;ref name=":4" /&gt; In this way, in future games MENACE would become more likely to repeat those winning moves, reinforcing winning strategies. If it lost, the removed beads were not returned, "punishing" MENACE, and meaning that in future it would be less likely, and eventually incapable if that colour of bead became absent, to repeat the moves that cause a loss.&lt;ref name=":1" /&gt; If the game was a draw, one additional bead was added to each box.&lt;ref name=":4" /&gt;

==Results in practice==
===Optimal strategy===
[[File:Tictactoe-X.svg|thumb|Optimal strategy for player X if starting in a corner. In each grid, the shaded red X denotes the optimal move, and the location of O's next move gives the next subgrid to examine.|alt=Optimal noughts and crosses strategy]]
Noughts and Crosses has a well-known optimal strategy.&lt;ref name=":5"&gt;{{Cite web|last=Cappiell|first=Emily|date=2020-11-30|title=How to Win Tic-Tac-Toe: The Strategies You Need to Master|url=https://www.rd.com/article/how-to-win-tic-tac-toe/|access-date=2021-02-06|website=Reader's Digest|language=en-US}}&lt;/ref&gt; It involves strategic placing to block the other player while simultaneously taking the win. However, if both players use this strategy, it always ends in a draw.&lt;ref name=":5" /&gt; This creates a stalement. If the human player is familiar with the optimal strategy, and MENACE can quickly learn it, then the games will eventually only end in draws. When the computer begins and plays a random-playing opponent, it has the odds of the computer winning turn quickly in its favour.&lt;ref name=":1" /&gt;

When playing against a player using optimal strategy, the odds of a draw grow to 100%. In Donald Michie's official tournament against MENACE, (1961)&lt;ref name=":2" /&gt; he used optimal strategy, and he and the computer began to draw consistently after twenty games. Michie's tournament&lt;ref name=":3"&gt;Trial and Error, Michie Donald, Penguin Science Surveys 1961 Vol 2&lt;/ref&gt; had the following milestones: Michie began by consistently opening with "Variant 0", the middle square. At 15 games, MENACE abandoned all non-corner openings. At just over 20, Michie switched to consistently using "Variant 1", the bottom-right square. At 60, he returned to Variant 0. As he neared 80 games, he moved to "Variant 2", the top-middle. At 110, he switched to "Variant 3", the top right. At 135, he switched to "Variant 4", middle-right. At 190, he returned to Variant 1, and at 210, he returned to Variant 0.

The trend in changes of beads in the "2" boxes runs:&lt;ref name=":3" /&gt;
{| {{Table|sort|class=floatcenter}}
! Variant !! Match number !! Bead change in "2" box
|-
! Variant 0
| 0
| 0
|-
! Variant 1
| 20
| -5
|-
! Variant 0
| 60
| 5
|-
! Variant 2
| 70
| 10
|-
! Variant 3
| 110
| 20
|-
! Variant 4
| 135
| 25
|-
! Variant 1
| 190
| 100
|-
! Variant 0
| 210
| 120
|-
|}

=== Correlation ===
[[File:Michie-MENACE-graph.png|thumb|A scatter graph showing the results of Donald Michie's games against MENACE|alt=Scatter graph of Michie's tournament.]]
Depending on the strategy employed by the human player, MENACE produces a different trend on [[Scatter plot|scatter graphs]] of wins.&lt;ref name=":2" /&gt; Using a random turn from the human player results in an almost-perfect positive trend. Playing the optimal strategy returns a slightly slower increase.&lt;ref name=":1" /&gt; The reinforcement does not create a perfect standard of wins; the algorithm will draw random uncertain conclusions each time. After the '''''j''th''' the correlation of near-perfect play runs:

&lt;math&gt;{1-D \over D-D^{(j+2)})}\sum_{i=0}^j D^{(ji+1)} V_i&lt;/math&gt;

Where '''''V&lt;sub&gt;i&lt;/sub&gt;''''' is the outcome (+1 is win, 0 is draw and -1 is loss) '''''D''''' is the Decay Factor (average of past values of wins and losses). Below, '''''M&lt;sub&gt;n&lt;/sub&gt;''''' is the multiplier for the nth round of the game.&lt;ref name=":2" /&gt; 
{| class="wikitable"
|+
!Outcome
!Reinforcement
|-
|Won
|&lt;math&gt;R_n=M_n^{-\mu+1}&lt;/math&gt;
|-
|Draw
|&lt;math&gt;R_n=M_n^{-\mu}&lt;/math&gt;
|-
|Lost
|&lt;math&gt;R_n=M_n^{-\mu-1}&lt;/math&gt;
|}

==Legacy==
Donald Michie's MENACE proved that a computer could "learn" from failure and success to become good at a task.&lt;ref name=":10" /&gt; It also used what would become core principles within the field of machine learning before they had been properly theorised. For example, the combination of how MENACE starts with equal numbers of types of beads in each matchbox, and how these are then be selected at random, creates a learning behaviour similar to weight initialisation in modern [[artificial neural networks]].&lt;ref&gt;{{Cite journal |last1=Yam |first1=Jim Y. F. |last2=Chow |first2=Tommy W. S. |date=1 January 2000 |title=A weight initialization method for improving training speed in feedforward neural network |url=http://www.sciencedirect.com/science/article/pii/S0925231299001277 |journal=Neurocomputing |language=en |volume=30 |issue=1 |pages=219–232 |doi=10.1016/S0925-2312(99)00127-7 |issn=0925-2312}}&lt;/ref&gt; In 1968, Donald Michie and R.A Chambers made another "BOXES"-based algorithm called GLEE, (Game Learning Expectimaxing Engine) which was tasked to learn how to balance a pole on a cart.&lt;ref&gt;{{Cite book |last1=Sutton |first1=Richard S. |url=https://books.google.com/books?id=6DKPtQEACAAJ |title=Reinforcement Learning: An Introduction |last2=Barto |first2=Andrew G. |date=13 November 2018 |publisher=MIT Press |isbn=978-0-262-03924-6 |language=en|p=753}}&lt;/ref&gt;

After the resounding reception of MENACE, Michie was invited to the US Office of Naval Research, where he was commissioned to build a "Boxes"-running program for an [[IBM]] Computer for use at [[Stanford University]].&lt;ref&gt;{{Cite news |date=8 July 2007 |title=Professor Donald Michie |journal=The Daily Telegraph |language=en-GB |url=https://www.telegraph.co.uk/news/obituaries/1556846/Professor-Donald-Michie.html |access-date=11 June 2020 |issn=0307-1235}}&lt;/ref&gt; Michie went on to create a simulation program of MENACE on a [[Ferranti Pegasus|Pegasus]] 2 computer with the aid of D. Martin.&lt;ref name=":2"&gt;{{Cite web |title=Experiments on the mechanization of Game Learning Part 1. Characterization of the model and its parameters |url=https://www.gwern.net/docs/rl/1963-michie.pdf |language=en |access-date=1 June 2020}}&lt;/ref&gt; There have been multiple recreations of MENACE in more recent years, both in its original physical form and as a computer program.&lt;ref name=":0"&gt;[https://warwick.ac.uk/fac/sci/dcs/research/em/publications/web-em/10/cs405_-_1362452_-_menaceem.pdf Matchbox Educable Noughts And Crosses Engine In Empirical Modelling]&lt;/ref&gt; Its algorithm was later converged into Christopher Watkin's Q-Learning algorithm.&lt;ref&gt;{{Cite book |last=Scaruffi |first=Piero |title=Intelligence is not Artificial - ''Why the Singularity is not coming any time soon and other Meditations on the Post-Human Condition and the Future of Intelligence'' |year=2016 |isbn=978-0-9765531-9-9 |pages=27}}&lt;/ref&gt; Although not as a functional computer, in examples of demonstration, MENACE has been used as a teaching aid for various neural network classes,&lt;ref&gt;{{Cite web |last=Zhao |first=Yibo |date=1 December 2013 |title=Machine Educable Engine on Noughts And Crosses in Modelling Study |url=https://warwick.ac.uk/fac/sci/dcs/research/em/teaching/cs405/web-em-10-abstracts/yibo/ |publisher=University of Warwick}}&lt;/ref&gt;&lt;ref&gt;{{Cite web |title=AI Topics.. Tic-Tac-Toe strategy in Computational Thinking, Introduction, MENACE |url=https://aitopics.org/class/Industry/Leisure%20&amp;%20Entertainment/Games/Tic-Tac-Toe }}&lt;/ref&gt;&lt;ref&gt;Ute Schmid - "Interactive Learning with Mutual Explanations" (How Humans and Machine Learning Systems can Profit From Each Other) - University of Bamberg, Germany&lt;nowiki/&gt; [https://www.universiteitleiden.nl/binaries/content/assets/science/dso/ute-schmid_mutualexplleiden-1.pdf Link]&lt;/ref&gt; including a well-publicised demonstration from Cambridge Researcher Matthew Scroggs.&lt;ref&gt;{{Cite AV media |url=https://www.youtube.com/watch?v=hK25eXRaBdc |title=‘Building a MENACE machine’, Matthew Scroggs, University College London |date=3 July 2017 |last=Scroggs |first=Matthew |type=Youtube |language=en}}&lt;/ref&gt;&lt;ref&gt;{{Cite web |date=11 November 2019 |title=Inspiring the Next Generation of Computer Scientists {{!}} King's Worcester|url=https://www.ksw.org.uk/inspiring-the-next-generation-of-computer-scientists/|access-date=12 June 2020|website=King's Worcester|language=en-GB}}&lt;/ref&gt; A copy of MENACE built by Scroggs was featured in the 2019 [[Royal Institution Christmas Lectures]].&lt;ref&gt;{{Cite web |last=Scroggs |first=Matthew |date=27 December 2019 |title=Visualising MENACE's learning |url=https://www.mscroggs.co.uk/blog/71 |website=mscroggs.co.uk}}&lt;/ref&gt;&lt;ref&gt;{{Cite tweet |user=rsi_science |number=1210666302890754049 |access-date=14 October 2020 |title=Menace Machine-creator pitched up with his 304 matchboxes to explain how he made it. |via=Twitter |language=en |date=27 December 2019}}&lt;/ref&gt;

== See also ==
*[[Hexapawn]]

== References ==&lt;!--- See [[Wikipedia:Footnotes]] on how to create references using&lt;ref&gt;&lt;/ref&gt; tags which will then appear here automatically --&gt;
{{Reflist}}

== Sources ==
* [https://books.google.co.uk/books?id=3o89gfE9pS0C&amp;printsec=frontcover&amp;dq=the+boxes+methodology&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwil1MTA3I7sAhWxTBUIHfX1AQ8Q6AEwAHoECAUQAg#v=onepage&amp;q&amp;f=false The BOXES Methodology], a book on the "Boxes" algorithm employed by MENACE.
* [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.474.2430&amp;rep=rep1&amp;type=pdf BOXES: An Experiment in Adaptive Control], Michie and R.A Chambers' paper on the AI implications of BOXES and MENACE.

== External links ==
&lt;!-- Use the format: * [http://www.example.com/ example.com] --&gt;
* [https://www.mscroggs.co.uk/menace/ Online simulation of MENACE]

&lt;!--- Categories ---&gt;
[[Category:PC games]]
[[Category:Machine learning]]
[[Category:Artificial intelligence]]
[[Category:Analog computers]]</text>
      <sha1>kvgftowbx2xs4xpzbdy59qm5zgfvmug</sha1>
    </revision>
  </page>
  <page>
    <title>GPT-3</title>
    <ns>0</ns>
    <id>64695824</id>
    <revision>
      <id>1005006333</id>
      <parentid>1004967935</parentid>
      <timestamp>2021-02-05T14:02:02Z</timestamp>
      <contributor>
        <username>Some1</username>
        <id>8695428</id>
      </contributor>
      <comment>Undid revision 1004967935 by [[Special:Contributions/Newstandards|Newstandards]] ([[User talk:Newstandards|talk]]) Looks promotional</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="20685" xml:space="preserve">{{short description|2020 Transformer language model}}
{{use mdy dates|date=August 2020}}
{{Infobox software 
| name                   = Generative Pre-trained Transformer 3 (GPT-3)
| logo                   = 
| screenshot             = 
| screenshot size        = 
| caption                = 
| author                 =  [[OpenAI]]&lt;ref name="arXiv_Brown_20200722"/&gt;
| developer              = 
| released               = June 11, 2020 (beta)
| latest release version = 
| latest release date    = 
| repo                   =
| programming language   =
| operating system       = 
| genre                  = [[Autoregressive]] [[Transformer (machine learning model)|Transformer]] [[language model]]
| license                = Code unavailable, only accessible by a paywalled API
| website                = {{URL|https://openai.com/blog/openai-api}}
}}
{{Artificial intelligence}}

'''Generative Pre-trained Transformer 3''' ('''GPT-3''') is an [[Autoregressive model|autoregressive]] [[language model]] that uses [[deep learning]] to produce human-like text.  It is the third-generation language prediction model in the GPT-n series  (and the successor to [[GPT-2]]) created by [[OpenAI]], a San Francisco-based [[artificial intelligence]] research laboratory.&lt;ref name="CNBC_Shead_20200723" /&gt; GPT-3's full version has a capacity of  175 billion [[parameter (machine learning)|machine learning parameters]]. GPT-3, which was introduced in May 2020, and was in beta testing as of July 2020,&lt;ref name="Medium_Bussler_20200721"&gt;{{Cite web| last = Bussler| first = Frederik| title = Will GPT-3 Kill Coding?| work = Towards Data Science| access-date = August 1, 2020| date = July 21, 2020| url = https://towardsdatascience.com/will-gpt-3-kill-coding-630e4518c04d}}&lt;/ref&gt;  is part of a trend in [[natural language processing]] (NLP) systems of pre-trained language representations.&lt;ref name="arXiv_Brown_20200722" /&gt; Before the release of GPT-3, the largest language model was [[Microsoft]]'s Turing NLG, introduced in February 2020, with a capacity of 17 billion parameters or less than a tenth of GPT-3s.&lt;ref name="analyticsindiamag_Sagar_20200603" /&gt;

The quality of the text generated by GPT-3 is so high that it is difficult to distinguish from that written by a human, which has both benefits and risks.&lt;ref name="analyticsindiamag_Sagar_20200603"/&gt; Thirty-one OpenAI researchers and engineers presented the original May 28, 2020 paper introducing GPT-3. In their paper, they warned of GPT-3's potential dangers and called for research to mitigate risk.&lt;ref name="arXiv_Brown_20200722"/&gt;{{rp|34}} [[David Chalmers]], an Australian philosopher, described GPT-3 as "one of the most interesting and important AI systems ever produced."&lt;ref name="DailyNous_Weinberg_Chalmer_20200730"/&gt;

[[Microsoft]] announced on September 22, 2020 that it had licensed "exclusive" use of GPT-3; others can still use the public API to receive output, but only Microsoft has control of the source code.&lt;ref&gt;{{Cite magazine |title=OpenAI is giving Microsoft exclusive access to its GPT-3 language model |url=https://www.technologyreview.com/2020/09/23/1008729/openai-is-giving-microsoft-exclusive-access-to-its-gpt-3-language-model/ |date=September 23, 2020 |last=Hao |first=Karen |access-date=2020-09-25 |work=[[MIT Technology Review]] |language=en |quote="The companies say OpenAI will continue to offer its public-facing [[API]], which allows chosen users to send text to GPT-3 or OpenAI’s other models and receive its output. Only OpenAI, however, will have access to GPT-3’s underlying code, allowing it to embed, repurpose, and modify the model as it pleases."}}&lt;/ref&gt;

== Background ==
According to ''[[The Economist]]'', improved algorithms, powerful computers, and an increase in digitized data have fueled a revolution in [[machine learning]], with new techniques in the 2010s resulting in "rapid improvements in tasks" including manipulating language.&lt;ref name="theeconomist_20200611"&gt;{{Cite news| issn = 0013-0613| title = An understanding of AI’s limitations is starting to sink in| work = The Economist|date=June 11, 2020| access-date = July 31, 2020| url = https://www.economist.com/technology-quarterly/2020/06/11/an-understanding-of-ais-limitations-is-starting-to-sink-in}}&lt;/ref&gt; Software models are trained to learn by using thousands or millions of examples in a "structure{{nbsp}}... loosely based on the neural architecture of the brain".&lt;ref name="theeconomist_20200611"/&gt; One architecture used in [[natural language processing]] (NLP) is a [[artificial neural network|neural network]] based on a [[deep learning]] model that was first introduced in 2017—the [[Transformer (machine learning model)|Transformer]].&lt;ref name="Polosukhin_2017"&gt;{{cite arxiv|last=Polosukhin|first=Illia|last2=Kaiser|first2=Lukasz|last3=Gomez|first3=Aidan N.|last4=Jones|first4=Llion|last5=Uszkoreit|first5=Jakob|last6=Parmar|first6=Niki|last7=Shazeer|first7=Noam|last8=Vaswani|first8=Ashish|date=2017-06-12|title=Attention Is All You Need|eprint=1706.03762|class=cs.CL}}&lt;/ref&gt; GPT-n models are based on this Transformer-based deep learning neural network architecture. There are a number of NLP systems capable of processing, mining, organizing, connecting, contrasting, understanding and generating answers to questions.&lt;ref name="thomsonreuters_nd"&gt;{{Cite web| title = Natural Language Processing| access-date = 2020-07-31| url = https://www.thomsonreuters.com/en/artificial-intelligence/natural-language-processing.html}}&lt;/ref&gt;

On June 11, 2018, OpenAI researchers and engineers posted their original paper on [[generative model]]s—language models—artificial intelligence systems—that could be pre-trained with an enormous and diverse [[Text corpus|corpus of text]] via [[Dataset (machine learning)|datasets]], in a process they called [[generative pre-training]] (GP).&lt;ref name="OpenAI_Radford_20200611"&gt;{{Cite web| pages = 12| access-date = July 31, 2020| date = June 11, 2018| last1 = Radford| first1 = Alec| last2 = Narasimhan| first2 = Karthik| last3 = Salimans| first3 = Tim| last4 = Sutskever| first4 = Ilya| title = Improving Language Understanding by Generative Pre-Training |url=https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf }}&lt;/ref&gt; The authors described how language understanding performances in natural language processing (NLP) were improved in GPT-n through a process of "generative pre-training of a language model on a diverse corpus of unlabeled text, followed by [[Discriminative model|discriminative]] fine-tuning on each specific task." This [[Unsupervised learning|eliminated the need for human supervision]] and for time-intensive hand-labeling.&lt;ref name="OpenAI_Radford_20200611"/&gt;

In February 2020, Microsoft introduced its Turing Natural Language Generation (T-NLG), which was then the "largest language model ever published at 17 billion parameters."&lt;ref name="Wired_Sterling_20200213"&gt;{{Cite news| issn = 1059-1028| last = Sterling| first = Bruce| title = Web Semantics: Microsoft Project Turing introduces Turing Natural Language Generation (T-NLG)| work = Wired| access-date = July 31, 2020| date = February 13, 2020| url = https://www.wired.com/beyond-the-beyond/2020/02/web-semantics-microsoft-project-turing-introduces-turing-natural-language-generation-t-nlg/}}&lt;/ref&gt; It performed better than any other language model at a variety of tasks which included [[Automatic summarization|summarizing texts]] and [[question answering|answering questions]].&lt;ref name="Wired_Sterling_20200213"/&gt;

== Capabilities ==

On May 28, 2020 [[arXiv]] a preprint by a group of 31 engineers and researchers at OpenAI described the development of GPT-3, a third-generation "state-of-the-art language model".&lt;ref name="arXiv_Brown_20200722"/&gt;&lt;ref name="analyticsindiamag_Sagar_20200603"&gt;{{Cite magazine| last = Sagar| first = Ram| title = OpenAI Releases GPT-3, The Largest Model So Far| work = Analytics India Magazine| access-date = July 31, 2020| date = June 3, 2020| url = https://analyticsindiamag.com/open-ai-gpt-3-language-model/}}&lt;/ref&gt; The team increased the capacity of GPT-3 by over two orders of magnitude from that of its predecessor, GPT-2,&lt;ref name="gpt2-with-quote"&gt;{{cite journal |title=Language Models are Unsupervised Multitask Learners |url=https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf |access-date=December 4, 2019|quote="GPT-2, is a 1.5B parameter Transformer"}}&lt;/ref&gt; making GPT-3 the largest non-sparse{{explain|date=September 2020}} language model to date.&lt;ref name="arXiv_Brown_20200722"&gt;{{cite arxiv| last1 = Brown| first1 = Tom B.| last2 = Mann| first2 = Benjamin| last3 = Ryder| first3 = Nick| last4 = Subbiah| first4 = Melanie| last5 = Kaplan| first5 = Jared| last6 = Dhariwal| first6 = Prafulla| last7 = Neelakantan| first7 = Arvind| last8 = Shyam| first8 = Pranav| last9 = Sastry| first9 = Girish| last10 = Askell| first10 = Amanda| last11 = Agarwal| first11 = Sandhini| last12 = Herbert-Voss| first12 = Ariel| last13 = Krueger| first13 = Gretchen| last14 = Henighan| first14 = Tom| last15 = Child| first15 = Rewon| last16 = Ramesh| first16 = Aditya| last17 = Ziegler| first17 = Daniel M.| last18 = Wu| first18 = Jeffrey| last19 = Winter| first19 = Clemens| last20 = Hesse| first20 = Christopher| last21 = Chen| first21 = Mark| last22 = Sigler| first22 = Eric| last23 = Litwin| first23 = Mateusz| last24 = Gray| first24 = Scott| last25 = Chess| first25 = Benjamin| last26 = Clark| first26 = Jack| last27 = Berner| first27 = Christopher| last28 = McCandlish| first28 = Sam| last29 = Radford| first29 = Alec| last30 = Sutskever| first30 = Ilya| last31 = Amodei| first31 = Dario| title = Language Models are Few-Shot Learners|arxiv=2005.14165 |date = July 22, 2020| url = http://arxiv.org/abs/2005.14165}}&lt;/ref&gt;{{rp|14|quote="Since we increase the capacity by over two orders of magnitude from GPT-2 to GPT-3"}}&lt;ref name="CNBC_Shead_20200723"&gt;{{Cite news| last = Shead| first = Sam| title = Why everyone is talking about the A.I. text generator released by an Elon Musk-backed lab| work = CNBC| access-date = July 31, 2020| date = July 23, 2020| url = https://www.cnbc.com/2020/07/23/openai-gpt3-explainer.html}} Four preprints were released between May 28 and July 22, 2020.&lt;/ref&gt; GPT-3's higher number of parameters grants it a higher level of accuracy relative to previous versions with smaller capacity.&lt;ref name="ZDNet_Tiernan_20200601"&gt;{{Cite web| last = Ray| first = Tiernan |date= June 1, 2020 | title = OpenAI’s gigantic GPT-3 hints at the limits of language models for AI| work = ZDNet| access-date = July 31, 2020| url = https://www.zdnet.com/article/openais-gigantic-gpt-3-hints-at-the-limits-of-language-models-for-ai/}}&lt;/ref&gt; GPT-3's capacity is ten times larger than that of [[Microsoft]]'s Turing NLG.&lt;ref name="analyticsindiamag_Sagar_20200603"/&gt;

Sixty percent of the weighted pre-training dataset for GPT-3 comes from a filtered version of [[Common Crawl]] consisting of 410 billion [[Byte pair encoding|byte-pair-encoded]] tokens.&lt;ref name="arXiv_Brown_20200722"/&gt;{{rp|9}} Other sources are 19 billion tokens from WebText2 representing 22% of the weighted total, 12 billion tokens from Books1 representing 8%, 55 billion tokens from Books2 representing 8%, and 3 billion tokens from Wikipedia representing 3%.&lt;ref name="arXiv_Brown_20200722"/&gt;{{rp|9}}  GPT-3 was trained on hundreds of billions of words and is capable of coding in CSS, JSX, Python, among others.&lt;ref name="Medium_Bussler_20200721"/&gt; Since GPT-3's training data was all-encompassing, it does not require further training for distinct language tasks.&lt;ref name="Medium_Bussler_20200721"/&gt;

On June 11, 2020, OpenAI announced that users could request access to its user-friendly GPT-3 [[Application programming interface|API]]—a "machine learning toolset"—to help OpenAI "explore the strengths and limits" of this new technology.&lt;ref name="OpenAI_20200611"&gt;{{cite web |url=https://openai.com/blog/openai-api/ |date=June 11, 2020 |work=OpenAI |title=OpenAI API}}&lt;/ref&gt;&lt;ref name="techcrunch_20200601"&gt;{{Cite web |title=TechCrunch – Startup and Technology News |work=TechCrunch |date=June 11, 2020 |access-date=July 31, 2020 |url= https://techcrunch.com/2020/06/11/openai-makes-an-all-purpose-api-for-its-text-based-ai-capabilities/ |quote=If you’ve ever wanted to try out OpenAI’s vaunted machine learning toolset, it just got a lot easier. The company has released an API that lets developers call its AI tools in on “virtually any English language task.” }}&lt;/ref&gt; The invitation described how this API had a general-purpose "text in, text out" interface that can complete almost "any English language task", instead of the usual single use-case.&lt;ref name="OpenAI_20200611"/&gt; According to one user, who had access to a private early release of the OpenAI GPT-3 API, GPT-3 was "eerily good" at writing "amazingly coherent text" with only a few simple prompts.&lt;ref name="Arram_20200709"&gt;{{Cite web| last = Arram| title = GPT-3: An AI that's eerily good at writing almost anything| work = Arram Sabeti| access-date = July 31, 2020| date = July 9, 2020| url = https://arr.am/2020/07/09/gpt-3-an-ai-thats-eerily-good-at-writing-almost-anything/}}&lt;/ref&gt;

Because GPT-3 can "generate news articles which human evaluators have difficulty distinguishing from articles written by humans,"&lt;ref name="analyticsindiamag_Sagar_20200603"/&gt; GPT-3 has the "potential to advance both the beneficial and harmful applications of language models."&lt;ref name="arXiv_Brown_20200722"/&gt;{{rp|34}} In their May 28, 2020 paper, the researchers described in detail the potential "harmful effects of GPT-3"&lt;ref name="analyticsindiamag_Sagar_20200603"/&gt; which include "misinformation, [[Spamming|spam]], [[phishing]], [[Abuse of process|abuse of legal and governmental processes]], [[Academic dishonesty|fraudulent academic essay]] writing and social engineering [[pretexting]]".&lt;ref name="arXiv_Brown_20200722"/&gt; The authors draw attention to these dangers to call for research on [[Risk management|risk mitigation]].&lt;ref name="arXiv_Brown_20200722"/&gt;{{rp|34}}

== Reviews ==

In his July 29, 2020, review in ''[[The New York Times]]'', [[Farhad Manjoo]] said that GPT-3—which can generate computer code and poetry, as well as prose—is not just "amazing", "spooky", and "humbling", but also "more than a little terrifying".&lt;ref name="NYT_Farhad_20190515"&gt;{{Cite news| issn = 0362-4331|first=Farhad |last=Manjoo| title = How Do You Know a Human Wrote This?| work = [[The New York Times]]| access-date = August 4, 2020| date = July 29, 2020| url = https://www.nytimes.com/2020/07/29/opinion/gpt-3-ai-automation.html?}}&lt;/ref&gt;

''[[Daily Nous]]'' presented a series of articles by nine philosophers on GPT-3.&lt;ref name="DailyNous_Weinberg_20200730"&gt;{{Cite web| editor-last = Weinberg| editor-first = Justin| title = Philosophers On GPT-3 (updated with replies by GPT-3)| work = [[Daily Nous]]| access-date = July 31, 2020| date = July 30, 2020| url = http://dailynous.com/2020/07/30/philosophers-gpt-3/}}&lt;/ref&gt; Australian philosopher [[David Chalmers]] described GPT-3 as "one of the most interesting and important AI systems ever produced".&lt;ref name="DailyNous_Weinberg_Chalmer_20200730"&gt;{{Cite web |first=David |last=Chalmers |author-link=David Chalmers |editor-last = Weinberg |editor-first = Justin |title =GPT-3 and General Intelligence |series= Philosophers On GPT-3 (updated with replies by GPT-3)| work = [[Daily Nous]]| access-date = August 4, 2020| date = July 30, 2020| url = https://dailynous.com/2020/07/30/philosophers-gpt-3/#chalmers}}&lt;/ref&gt;

A review in ''[[Wired (magazine)|Wired]]'' said that GPT-3 was "provoking chills across [[Silicon Valley]]".&lt;ref name="Wired_Simonite_20200722"&gt;{{Cite news| issn = 1059-1028| title = Did a Person Write This Headline, or a Machine?|first=Tom |last=Simonite| work = [[Wired (magazine)|Wired]]| access-date = July 31, 2020 |date=July 22, 2020| url = https://www.wired.com/story/ai-text-generator-gpt-3-learning-language-fitfully/}}&lt;/ref&gt;

The ''[[National Law Review]]'' said that GPT-3 is an "impressive step in the larger process", with OpenAI and others finding "useful applications for all of this power" while continuing to "work toward a more [[Artificial general intelligence|general]] intelligence".&lt;ref name="NTR_20200730"&gt;{{Cite web |first=Theodore |last=Claypoole |title = New AI Tool GPT-3 Ascends to New Peaks, But Proves How Far We Still Need to Travel |work = [[The National Law Review]] |date= July 30, 2020| access-date = August 4, 2020|volume=10 |number=214| url = https://www.natlawreview.com/article/new-ai-tool-gpt-3-ascends-to-new-peaks-proves-how-far-we-still-need-to-travel}}&lt;/ref&gt;

An article in the ''[[MIT Technology Review]],'' cowritten by Deep Learning critic [[Gary Marcus]],&lt;ref&gt;{{Cite web|last=Marcus|first=Gary|date=2018-12-01|title=The deepest problem with deep learning|url=https://medium.com/@GaryMarcus/the-deepest-problem-with-deep-learning-91c5991f5695|access-date=2020-09-29|website=Medium|language=en}}&lt;/ref&gt; stated that GPT-3's "comprehension of the world is often seriously off, which means you can never really trust what it says."&lt;ref name="Marcus_Davis_2020"&gt;{{cite magazine |last1=Marcus |first1=Gary |last2=Davis |first2=Ernest |url=https://www.technologyreview.com/2020/08/22/1007539/gpt3-openai-language-generator-artificial-intelligence-ai-opinion |title=GPT-3, Bloviator: OpenAI’s language generator has no idea what it’s talking about |date=August 22, 2020 |magazine=[[MIT Technology Review]] |access-date=August 23, 2020}}&lt;/ref&gt; According to the authors, GPT-3 models relationships between words without having an understanding of the meaning behind each word.

Jerome Pesenti, head of the Facebook A.I. lab, said GPT-3 is "unsafe," pointing to the [[sexist]], [[racist]] and other biased and negative language generated by the system when it was asked to discuss [[Jews]], women, black people, and the [[Holocaust]].&lt;ref&gt;{{Cite news|last=Metz|first=Cade|date=2020-11-24|title=Meet GPT-3. It Has Learned to Code (and Blog and Argue).|language=en-US|work=The New York Times|url=https://www.nytimes.com/2020/11/24/science/artificial-intelligence-ai-gpt3.html|access-date=2020-11-24|issn=0362-4331}}&lt;/ref&gt;

Nabla, a French start-up specialized in healthcare technology, tested GPT-3 as medical [[chatbot]], though OpenAI itself warned against such use. As expected, GPT-3 showed several limitations. For example, while testing GPT-3 responses about mental health issues, the AI advised a simulated patient to commit suicide.&lt;ref&gt;{{Cite web|date=2020-10-28|title=Medical chatbot using OpenAI’s GPT-3 told a fake patient to kill themselves|url=https://artificialintelligence-news.com/2020/10/28/medical-chatbot-openai-gpt3-patient-kill-themselves/|access-date=2021-01-08|website=AI News|language=en-GB}}&lt;/ref&gt;

== Applications ==
* GPT-3 has been used by [[Andrew Mayne]] for AI Writer,&lt;ref&gt;[https://www.aiwriter.app/ AI Writer]&lt;/ref&gt; which allows people to correspond with historical figures via email.
* GPT-3 has been used by [[Jason Rohrer]] in a retro-themed chatbot project named "Project December", which is accessible online and allows users to converse with several AIs using GPT-3 technology.
* GPT-3 was used by ''[[The Guardian]]'' to write an article about AI being harmless to human beings. It was fed some ideas and produced eight different essays, which were ultimately merged into one article.&lt;ref&gt;{{Cite news|last=GPT-3|date=2020-09-08|title=A robot wrote this entire article. Are you scared yet, human? {{!}} GPT-3|work=The Guardian|url=https://www.theguardian.com/commentisfree/2020/sep/08/robot-wrote-this-article-gpt-3|access-date=2020-09-15|issn=0261-3077}}&lt;/ref&gt;
* GPT-3 is used in ''[[AI Dungeon]]'', which generates text-based adventure games.

== References ==
{{reflist|30em}}

== External links ==
* [https://www.youtube.com/watch?v=_x9AwxfjxvE Video: OpenAI GPT-3 - Good At Almost Everything!] (Two Minute Papers)
* [https://www.youtube.com/watch?v=_8yVOC4ciXc Video: GPT3: An Even Bigger Language Model] ([[Brady Haran#Other YouTube channels|Computerphile]])
* [https://www.youtube.com/watch?v=kpiY_LemaTc Video: GPT-3 vs Human Brain] (Lex Fridman)

{{Deep Learning Software}}
{{Differentiable computing}}
{{emerging technologies|topics=yes|infocom=yes}}
{{Evolutionary computation}}
{{Existential risk from artificial intelligence}}
{{Software engineering}}

[[Category:Language modeling]]
[[Category:Machine learning]]
[[Category:Unsupervised learning]]
[[Category:Deep learning]]
[[Category:Artificial intelligence]]</text>
      <sha1>17bm826zkjvrilm1khsyn2wxbfwad0c</sha1>
    </revision>
  </page>
  <page>
    <title>Count sketch</title>
    <ns>0</ns>
    <id>64705026</id>
    <revision>
      <id>985784877</id>
      <parentid>985350712</parentid>
      <timestamp>2020-10-27T23:00:37Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* Relation to Tensor sketch */[[User:JCW-CleanerBot#Logic|task]], replaced: journal=Radioelectronics and Communications Systems. – 1998, Vol.  → journal=Radioelectronics and Communications Systems. – 1998 |volume=</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="5568" xml:space="preserve">{{short description|Method of a dimension reduction}}
{{Machine learning bar}}

'''Count sketch'''  is a type of [[dimensionality reduction]] that is particularly efficient in [[statistics]], [[machine learning]] and [[algorithms]].&lt;ref&gt;Faisal M. Algashaam; Kien Nguyen; Mohamed Alkanhal; Vinod Chandran; Wageeh Boles. "Multispectral Periocular Classification WithMultimodal Compact Multi-Linear Pooling" [1]. ''IEEE Access'', Vol. 5. 2017.&lt;/ref&gt;&lt;ref&gt;{{Cite web |last=Ahle |first=Thomas |last2=Knudsen |first2=Jakob |date=2019-09-03 |title=Almost Optimal Tensor Sketch |url=https://www.researchgate.net/publication/335617805_Almost_Optimal_Tensor_Sketch |access-date=2020-07-11 |website=[[Researchgate]]}}&lt;/ref&gt;
It was invented by 
Moses Charikar, Kevin Chen and Martin Farach-Colton&lt;ref&gt;Charikar, Moses, Kevin Chen, and Martin Farach-Colton. "Finding frequent items in data streams." International Colloquium on Automata, Languages, and Programming. Springer, Berlin, Heidelberg, 2002.&lt;/ref&gt; in an effort to speed up the [[AMS Sketch]] by Alon, Matias and Szegedy for approximating the frequency moments of streams.&lt;ref&gt;Alon, Noga, Yossi Matias, and Mario Szegedy. "The space complexity of approximating the frequency moments." Journal of Computer and system sciences 58.1 (1999): 137-147.&lt;/ref&gt;

The sketch is nearly identical to the [[Feature hashing]] algorithm by John Moody,&lt;ref&gt;Moody, John. "Fast learning in multi-resolution hierarchies." Advances in neural information processing systems. 1989.&lt;/ref&gt; but differs in its use of hash functions with low dependence, which makes it more practical.
In order to still have a high probability of success, the [[median trick]] is used to aggregate multiple count sketches, rather than the mean.

These properties allow use for explicit [[kernel methods]], bilinear [[Pool (computer science)|pooling]] in [[neural network]]s and is a cornerstone in many numerical linear algebra algorithms.&lt;ref name="woodruff"&gt;Woodruff, David P. "Sketching as a Tool for Numerical Linear Algebra." Theoretical Computer Science 10.1-2 (2014): 1–157.&lt;/ref&gt;

==Mathematical definition==

1. For constants &lt;math&gt;w&lt;/math&gt; and &lt;math&gt;d&lt;/math&gt; (to be defined later) independently choose &lt;math&gt;2d&lt;/math&gt; random hash functions
&lt;math&gt;h_1, \dots, h_d&lt;/math&gt; and &lt;math&gt;s_1,\dots,s_d&lt;/math&gt; such that
&lt;math&gt;h_i : [n] \to [w]&lt;/math&gt; and
&lt;math&gt;s_i : [n] \to \{\pm 1\}&lt;/math&gt;.
It is necessary that the hash families from which &lt;math&gt;h_i&lt;/math&gt; and &lt;math&gt;s_i&lt;/math&gt; are chosen be pairwise independent.

2. For each item &lt;math&gt;q_i&lt;/math&gt; in the stream, add &lt;math&gt;s_j(q_i)&lt;/math&gt; to the &lt;math&gt;h_j(q_i)&lt;/math&gt;th bucket of the &lt;math&gt;j&lt;/math&gt;th hash.

At the end of this process, one has &lt;math&gt;wd&lt;/math&gt; sums &lt;math&gt;(C_{ij})&lt;/math&gt; where
:&lt;math&gt;C_{ij} = \sum_{h_i(k)=j}s_i(k).&lt;/math&gt;

To estimate the count of &lt;math&gt;q&lt;/math&gt;s one computes the following value:
:&lt;math&gt;\text{median}_i\, s_i(q)\cdot C_{i, h_i(q)}.&lt;/math&gt;

==Relation to Tensor sketch==

The count sketch projection of the [[outer product]] of two vectors is equivalent to the [[convolution]] of two component count sketches. 

The count sketch computes a vector [[convolution]] 

&lt;math&gt;C^{(1)}x \ast C^{(2)}x^T&lt;/math&gt;, where &lt;math&gt;C^{(1)}&lt;/math&gt; and &lt;math&gt;C^{(2)}&lt;/math&gt; are independent count sketch matrices.

Pham and Pagh&lt;ref name="ninh"&gt;{{cite conference 
| title = Fast and scalable polynomial kernels via explicit feature maps
| last1 = Ninh
| first1 = Pham
| last2 = Rasmus
| first2 = Pagh
| date = 2013
| publisher = Association for Computing Machinery
| conference = SIGKDD international conference on Knowledge discovery and data mining
|doi = 10.1145/2487575.2487591}}
&lt;/ref&gt;  show that this equals &lt;math&gt;C(x \otimes x^T)&lt;/math&gt; – a count sketch &lt;math&gt;C&lt;/math&gt; of the [[outer product]] of vectors, where &lt;math&gt; \otimes &lt;/math&gt; denotes [[Kronecker product]].

To do fast convolution of count sketches can be used the [[fast Fourier transform]].
By using the [[Khatri–Rao_product#Face-splitting_product|face-splitting product]]&lt;ref&gt;{{Cite journal|last=Slyusar|first=V. I. |title=End products in matrices in radar applications |url=http://slyusar.kiev.ua/en/IZV_1998_3.pdf|journal=Radioelectronics and Communications Systems |year=1998 |volume=41 |issue=3|pages=50–53}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Slyusar|first=V. I.|date=1997-05-20|title=Analytical model of the digital antenna array on a basis of face-splitting matrix products. |url=http://slyusar.kiev.ua/ICATT97.pdf|journal=Proc. ICATT-97, Kyiv|pages=108–109}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Slyusar|first=V. I.|date=March 13, 1998|title=A Family of Face Products of Matrices and its Properties|url=http://slyusar.kiev.ua/FACE.pdf|journal=Cybernetics and Systems Analysis C/C of Kibernetika I Sistemnyi Analiz.- 1999.|volume=35|issue=3|pages=379–384|doi=10.1007/BF02733426}}&lt;/ref&gt; such structure computed much faster than normal matrices.

== See also ==
* [[Count–min sketch]]
* [[Tensorsketch]]

==References==
{{Reflist}}

==Further reading==

*Faisal M. Algashaam; Kien Nguyen; Mohamed Alkanhal; Vinod Chandran; Wageeh Boles. "Multispectral Periocular Classification WithMultimodal Compact Multi-Linear Pooling" [https://ieeexplore.ieee.org/document/7990127]. ''IEEE Access'', Vol. 5. 2017.
*{{Cite web |last=Ahle |first=Thomas |last2=Knudsen |first2=Jakob |date=2019-09-03 |title=Almost Optimal Tensor Sketch |url=https://www.researchgate.net/publication/335617805_Almost_Optimal_Tensor_Sketch |access-date=2020-07-11 |website=[[Researchgate]]}}

[[Category:Dimension reduction]]

[[Category:Machine learning]]</text>
      <sha1>qxh74c9itt52gz5p4uiajywr2gpsi03</sha1>
    </revision>
  </page>
  <page>
    <title>Decision tree pruning</title>
    <ns>0</ns>
    <id>5462075</id>
    <revision>
      <id>1004756181</id>
      <parentid>1004398753</parentid>
      <timestamp>2021-02-04T06:08:49Z</timestamp>
      <contributor>
        <username>JekkyBom</username>
        <id>40849926</id>
      </contributor>
      <comment>Statistic-based algorithm</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="7694" xml:space="preserve">[[File:Before after pruning.png|thumb|Before and After pruning]]

'''Pruning''' is a [[data compression]] technique in [[machine learning]] and [[search algorithm]]s that reduces the size of [[Decision tree learning|decision tree]]s by removing sections of the tree that are non-critical and redundant to classify instances. Pruning reduces the complexity of the final [[Statistical classification|classifier]], and hence improves predictive accuracy by the reduction of [[overfitting]].

One of the questions that arises in a decision tree algorithm is the optimal size of the final tree.  A tree that is too large risks [[overfitting]] the training data and poorly generalizing to new samples.  A small tree might not capture important structural information about the sample space.  However, it is hard to tell when a tree algorithm should stop because it is impossible to tell if the addition of a single extra node will dramatically decrease error.  This problem is known as the [[horizon effect]].  A common strategy is to grow the tree until each node contains a small number of instances then use pruning to remove nodes that do not provide additional information.&lt;ref name="tib"&gt;{{cite book |first=Trevor |last=Hastie |first2=Robert |last2=Tibshirani |first3=Jerome |last3=Friedman |title=The Elements of Statistical Learning |publisher=Springer |year=2001 |pages=269-272 |isbn=0-387-95284-5 }}&lt;/ref&gt;

Pruning should reduce the size of a learning tree without reducing predictive accuracy as measured by a [[cross-validation (statistics)|cross-validation]] set.  There are many techniques for tree pruning that differ in the measurement that is used to optimize performance.

==Techniques==
Pruning processes can be divided into two types (pre- and post-pruning).

'''Pre-pruning''' procedures prevent a complete induction of the training set by replacing a stop () criterion in the induction algorithm (e.g. max. Tree depth or information gain (Attr)&gt; minGain). Pre-pruning methods are considered to be more efficient because they do not induce an entire set, but rather trees remain small from the start. Prepruning methods share a common problem, the horizon effect. This is to be understood as the undesired premature termination of the induction by the stop () criterion.

'''Post-pruning''' (or just pruning) is the most common way of simplifying trees. Here, nodes and subtrees are replaced with leaves to improve complexity. Pruning can not only significantly reduce the size but also improve the classification accuracy of unseen objects. It may be the case that the accuracy of the assignment on the test set deteriorates, but the accuracy of the classification properties of the tree increases overall.

The procedures are differentiated on the basis of their approach in the tree (top-down or bottom-up).

=== Bottom-up pruning ===
These procedures start at the last node in the tree (the lowest point). Following recursively upwards, they determine the relevance of each individual node. If the relevance for the classification is not given, the node is dropped or replaced by a leaf. The advantage is that no relevant sub-trees can be lost with this method.
These methods include Reduced Error Pruning (REP), Minimum Cost Complexity Pruning (MCCP), or Minimum Error Pruning (MEP).

=== Top-down pruning ===
In contrast to the bottom-up method, this method starts at the root of the tree. Following the structure below, a relevance check is carried out which decides whether a node is relevant for the classification of all n items or not. By pruning the tree at an inner node, it can happen that an entire sub-tree (regardless of its relevance) is dropped. One of these representatives is pessimistic error pruning (PEP), which brings quite good results with unseen items.

==Pruning algorithms==

===Reduced error pruning===
One of the simplest forms of pruning is reduced error pruning.  Starting at the leaves, each node is replaced with its most popular class.  If the prediction accuracy is not affected then the change is kept.  While somewhat naive, reduced error pruning has the advantage of '''simplicity and speed'''.

===Cost complexity pruning===
Cost complexity pruning generates a series of trees {{tmath|T_0\dots T_m}} where {{tmath|T_0}} is the initial tree and {{tmath|T_m}} is the root alone.  At step {{tmath|i}}, the tree is created by removing a subtree from tree {{tmath|i-1}} and replacing it with a leaf node with value chosen as in the tree building algorithm.  The subtree that is removed is chosen as follows:
# Define the error rate of tree {{tmath|T}} over data set {{tmath|S}} as {{tmath|\operatorname{err}(T,S)}}.
# The subtree that minimizes &lt;math&gt;\frac{\operatorname{err}(\operatorname{prune}(T,t),S)-\operatorname{err}(T,S)}{\left\vert\operatorname{leaves}(T)\right\vert-\left\vert\operatorname{leaves}(\operatorname{prune}(T,t))\right\vert}&lt;/math&gt; is chosen for removal.
The function {{tmath|\operatorname{prune}(T,t)}} defines the tree obtained by pruning the subtrees {{tmath|t}} from the tree {{tmath|T}}.  Once the series of trees has been created, the best tree is chosen by generalized accuracy as measured by a training set or cross-validation.

===Statistic-based pruning===

The statistic-based pruning of leaves from the same and/or different levels of predictive model was proposed as a part of decision stream learning technique. Every group of leaves containing data samples similar according to the test statistics is merged into a new leaf, increasing the number of samples in nodes of trained model and reducing the tree width. The predictive model is growing till no improvements are achievable, considering different data recombinations, and resulting in deep directed acyclic graph architecture and statistically-significant data partition.&lt;ref name="Decision stream"&gt;{{cite journal|author1=Ignatov, D.Yu.|author2=Ignatov, A.D.|title=Decision Stream: Cultivating Deep Decision Trees|journal=IEEE ICTAI|pages=905-912|doi=10.1109/ICTAI.2017.00140|date=2017|arxiv=1704.07657|url=https://www.researchgate.net/publication/316471270_Decision_Stream_Cultivating_Deep_Decision_Trees}}&lt;/ref&gt;

==See also==
* [[Alpha–beta pruning]]
* [[Artificial neural network]]
* [[Null-move heuristic]]

==References==
*{{cite book |author-link=Judea Pearl |first=Judea |last=Pearl |title=Heuristics |publisher=Addison-Wesley |year=1984 }}
*{{cite book | last = Mansour | first =  Y.  | year = 1997 | chapter = Pessimistic decision tree pruning based on tree size
 | title = Proc. 14th International Conference on Machine Learning  | pages = 195–201  | chapter-url = http://citeseer.ist.psu.edu/76752.html
}}
*{{cite journal |first=L. A. |last=Breslow |first2=D. W. |last2=Aha |title=Simplifying Decision Trees: A Survey |journal=The Knowledge Engineering Review |volume=12 |issue=1 |year=1997 |pages=1–47 |doi=10.1017/S0269888997000015 }}
*{{cite journal |first=J. R. |last=Quinlan |title=Induction of Decision Trees |journal=Machine Learning |volume=1 |publisher=Kluwer Academic Publishers |year=1986 |pages=81–106 |doi=10.1007/BF00116251 |doi-access=free }}
{{reflist}}

==Further reading==
* [http://web.cs.iastate.edu/~honavar/kdd95_mdl.pdf MDL based decision tree pruning]
* [http://www.cp.eng.chula.ac.th/~boonserm/publication/ijcnn_kc2001.pdf Decision tree pruning using backpropagation neural networks]

==External links==
* [http://www.cis.upenn.edu/~mkearns/papers/pruning.pdf Fast, Bottom-Up Decision Tree Pruning Algorithm]
* [http://www.math.tau.ac.il/~mansour/ml-course/scribe11.ps Introduction to Decision tree pruning]

[[Category:Decision trees]] 
[[Category:Artificial intelligence]]
[[Category:Machine learning]]</text>
      <sha1>646bc5mhdtkkl94kcstqotf7ztm6r2f</sha1>
    </revision>
  </page>
  <page>
    <title>Data augmentation</title>
    <ns>0</ns>
    <id>51443362</id>
    <revision>
      <id>1001383961</id>
      <parentid>1001186297</parentid>
      <timestamp>2021-01-19T13:02:40Z</timestamp>
      <contributor>
        <username>WikiCleanerBot</username>
        <id>18872885</id>
      </contributor>
      <minor/>
      <comment>v2.04b - [[User:WikiCleanerBot#T20|Bot T20 CW#61]] - Fix errors for [[WP:WCW|CW project]] (Reference before punctuation)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3131" xml:space="preserve">{{one source|date=September 2020}}

'''Data augmentation''' in data analysis are techniques used to increase the amount of data by adding slightly modified copies of already existing data or newly created synthetic data from existing data. It acts as a [[Regularization (mathematics) |regularizer]] and helps reduce [[overfitting]] when training a machine learning model.&lt;ref name="Big Data 2019 6:60"&gt;{{cite journal | last1=Shorten | first1=Connor | last2=Khoshgoftaar | first2=Taghi M. | title=A survey on Image Data Augmentation for Deep Learning | journal=Mathematics and Computers in Simulation | publisher=springer | volume=6 | year=2019 | doi=10.1186/s40537-019-0197-0 | pages=60 | doi-access=free }}&lt;/ref&gt; It is closely related to [[Oversampling and undersampling in data analysis|oversampling]] in data analysis.

== Synthetic oversampling techniques for traditional [[machine learning]] ==
{{main|Oversampling and undersampling in data analysis#Oversampling techniques for classification problems}}

== Data augmentation for image classification ==

=== Transformations of images ===
Geometric transformations, flipping, color modification, cropping, rotation, noise injection and random erasing are used to augment image in deep learning.&lt;ref name="Big Data 2019 6:60"/&gt;

=== Adding new synthetic images ===
Because image data usually have too high dimensions for traditional synthetic oversampling methods, new methods are required for creating new synthetic images for deep learning.

[[Generative adversarial network]]s enable to create new synthetic images for data augmentation.&lt;ref name="Big Data 2019 6:60"/&gt;

Image recognition algorithms show improvement when transferring from synthetic images generated by the Unity Game Engine.&lt;ref name="bird2020simulation"&gt;{{cite conference |last=Bird |first=Jordan J |last2=Faria |first2=Diego R |last3=Ekart |first3=Aniko |last4=Ayrosa |first4=Pedro PS |title=From simulation to reality: CNN transfer learning for scene classification |conference=2020 IEEE 10th International Conference on Intelligent Systems (IS) |publisher=IEEE |place=Varna, Bulgaria |date=2020-08-30 |year=2020 |pages=619-625 }}&lt;/ref&gt;


== Data augmentation for Speaker Recognition ==
=== Transfer learning from synthetic speech ===
It has been noted that synthetic data generation of spoken MFCCs can improve the recognition of a speaker from their utterances via [[transfer learning]] from synthetic data.&lt;ref name="BirdFaria2020"&gt;{{cite journal|last1=Bird|first1=Jordan J.|last2=Faria|first2=Diego R.|last3=Premebida|first3=Cristiano|last4=Ekart|first4=Aniko|last5=Ayrosa|first5=Pedro P. S.|title=Overcoming Data Scarcity in Speaker Identification: Dataset Augmentation with Synthetic MFCCs via Character-level RNN|year=2020|pages=146–151|doi=10.1109/ICARSC49921.2020.9096166}}&lt;/ref&gt;

== See also ==
* [[Oversampling and undersampling in data analysis]]
* [[Generative adversarial network]]
* [[Data pre-processing]]
* [[Convolutional neural network]]
* [[Regularization (mathematics)]]
* [[Data preparation]]
* [[Data fusion]]

==References==
{{reflist}}

{{data}}

[[Category:Machine learning]]</text>
      <sha1>ecxh0ehdlo31zw02px10tiywl8puqd5</sha1>
    </revision>
  </page>
  <page>
    <title>Robotic process automation</title>
    <ns>0</ns>
    <id>47642826</id>
    <revision>
      <id>1001769687</id>
      <parentid>1001769559</parentid>
      <timestamp>2021-01-21T06:56:01Z</timestamp>
      <contributor>
        <username>GSS</username>
        <id>26778615</id>
      </contributor>
      <comment>Reverted to revision 1001558391 by [[Special:Contributions/Monkbot|Monkbot]] ([[User talk:Monkbot|talk]]): -spam</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="20094" xml:space="preserve">{{short description|Form of business process automation technology}}
'''Robotic process automation''' (or RPA) is a form of [[business process automation]] technology based on metaphorical [[software]] robots (bots) or on [[artificial intelligence]] (AI)/digital workers.&lt;ref name="NewScientistAI"&gt;{{Citation|title=AI interns:Software already taking jobs from humans|publisher=New Scientist|url=https://www.newscientist.com/article/mg22630151.700-ai-interns-software-already-taking-jobs-from-humans/#.VY2CxPlViko}}&lt;/ref&gt;  It is sometimes referred to as ''software robotics'' (not to be confused with [[robot software]]).

In traditional [[workflow]] [[automation]] tools, a [[software developer]] produces a list of actions to automate a task and interface to the back-end system using internal [[application programming interfaces]] (APIs) or dedicated [[scripting language]]. In contrast, RPA systems develop the action list by watching the user perform that task in the application's [[graphical user interface]] (GUI), and then perform the automation by repeating those tasks directly in the GUI. This can lower the barrier to use of automation in products that might not otherwise feature APIs for this purpose.

RPA tools have strong technical similarities to [[graphical user interface testing]] tools. These tools also automate interactions with the GUI, and often do so by [[programming by demonstration|repeating a set of demonstration actions]] performed by a user. RPA tools differ from such systems in that they allow data to be handled in and between multiple applications, for instance, receiving [[email]] containing an invoice, extracting the data, and then typing that into a [[bookkeeping]] system.

==Historic evolution==

The typical benefits of robotic automation include reduced cost; increased speed, accuracy, and consistency; improved quality and scalability of production. Automation can also provide extra security, especially for sensitive data and financial services.

As a form of automation, the concept has been around for a long time in the form of [[screen scraping]], which can be traced back to early forms of malware. However, RPA is much more extensible, consisting of [[API]] integration into other enterprise applications, connectors into [[ITSM]] systems, [[terminal services]] and even some types of [[AI]] (e.g. [[Machine Learning]]) services such as [[image recognition]].  It is considered to be a significant technological evolution in the sense that new software platforms are emerging which are sufficiently mature, resilient, scalable and reliable to make this approach viable for use in large enterprises&lt;ref name="HfSThreat"&gt;{{Citation|title=Robotic Automation Emerges as a Threat to Traditional Low Cost Outsourcing|publisher=HfS Research|url=http://www.hfsresearch.com/Robotic-Automation-as-Threat-to-Traditional-Low-Cost-Outsourcing|url-status=dead|archive-url=https://web.archive.org/web/20150921062911/http://www.hfsresearch.com/Robotic-Automation-as-Threat-to-Traditional-Low-Cost-Outsourcing|archive-date=2015-09-21}}&lt;/ref&gt; (who would otherwise be reluctant due to perceived risks to quality and reputation).

A principal barrier to the adoption of self-service is often technological: it may not always be feasible or economically viable to retro-fit new interfaces onto existing systems. Moreover, organisations may wish to layer a variable and configurable set of process rules on top of the system interfaces which may vary according to market offerings and the type of customer. This only adds to the cost and complexity of the technological implementation. Robotic automation software provides a pragmatic means of deploying new services in this situation, where the robots simply mimick the behaviour of humans to perform the back end transcription or processing. The relative affordability of this approach arises from the fact that no IT new transformation or investment is required; instead the software robots simply leverage greater use out of existing IT assets.

==Deployment==

The hosting of RPA services also aligns with the metaphor of a software robot, with each robotic instance having its own virtual workstation, much like a human worker. The robot uses keyboard and mouse controls to take actions and execute automations. Normally all of these actions take place in a [[virtual environment]] and not on screen; the robot does not need a physical screen to operate, rather it interprets the screen display electronically. The scalability of modern solutions based on architectures such as these owes much to the advent of [[virtualization]] technology, without which the scalability of large deployments would be limited by available capacity to manage physical hardware and by the associated costs. The implementation of RPA in business enterprises has shown dramatic cost savings when compared to traditional non-RPA solutions.&lt;ref&gt;[http://www.kpmg-institutes.com/content/dam/kpmg/sharedservicesoutsourcinginstitute/pdf/2015/robotics-improve-legacy-sourcing.pdf]&lt;/ref&gt;

There are however several risks with RPA. Criticism include risks of stifling innovation and creating a more complex maintenance environment of existing software that now needs to consider the use of graphical user interfaces in a way they weren't intended to be used.&lt;ref name="mit"&gt;{{cite web |last1=DeBrusk |first1=Chris |title=Five Robotic Process Automation Risks to Avoid |url=https://sloanreview.mit.edu/article/five-robotic-process-automation-risks-to-avoid/ |website=MIT Sloan Management Review |publisher=MIT Sloan Management Review |access-date=28 June 2018}}&lt;/ref&gt;

==Impact on employment==
{{See also|Technological unemployment|Automation}}
According to ''[[Harvard Business Review]]'', most operations groups adopting RPA have promised their employees that automation would not result in [[layoff]]s.&lt;ref name="HBR"&gt;{{Citation|title=What knowledge workers stand to gain from automation|publisher=Harvard Business Review|url=https://hbr.org/2015/06/what-knowledge-workers-stand-to-gain-from-automation}}&lt;/ref&gt; Instead, workers have been redeployed to do more interesting work. One academic study highlighted that knowledge workers did not feel threatened by automation: they embraced it and viewed the robots as team-mates.&lt;ref name="LSEXchanging"&gt;{{Citation|title=Robotic Process Automation at Xchanging|publisher=London School of Economics|url=http://www.xchanging.com/system/files/dedicated-downloads/robotic-process-automation.pdf}}&lt;/ref&gt; The same study highlighted that, rather than resulting in a lower "headcount", the technology was deployed in such a way as to achieve more work and greater productivity with the same number of people.

Conversely, however, some analysts proffer that RPA represents a threat to the [[business process outsourcing]] (BPO) industry.&lt;ref name="GartnerPredicts2014"&gt;{{Citation|title=Gartner Predicts 2014: Business and IT Services Are Facing the End of Outsourcing as We Know It|publisher=Gartner|url=https://www.gartner.com/doc/2656215/predicts--business-it-services}}&lt;/ref&gt; The thesis behind this notion is that RPA will enable enterprises to "repatriate" processes from offshore locations into local data centers, with the benefit of this new technology. The effect, if true, will be to create high-value jobs for skilled process designers in onshore locations (and within the associated supply chain of IT hardware, data center management, etc.) but to decrease the available opportunity to low skilled workers offshore. On the other hand, this discussion appears to be healthy ground for debate as another academic study was at pains to counter the so-called "myth" that RPA will bring back many jobs from offshore.&lt;ref name="LSEXchanging"/&gt;

===RPA actual deployment===
* Banking and Finance Process Automation
* Mortgage and Lending Process
* Customer Care Automation
* eCommerce Merchandising Operation
* [[Optical character recognition|OCR]] Application
* Data Extraction Process
* Fixed automation process

===Impact on society===
Academic studies&lt;ref name=" OxfordFutureJobs"&gt;{{Citation|title=THE FUTURE OF EMPLOYMENT: HOW SUSCEPTIBLE ARE JOBS TO COMPUTERISATION?|url=http://www.futuretech.ox.ac.uk/news-release-oxford-martin-school-study-shows-nearly-half-us-jobs-could-be-risk-computerisation|url-status=dead|archive-url=https://web.archive.org/web/20160205044724/http://www.futuretech.ox.ac.uk/news-release-oxford-martin-school-study-shows-nearly-half-us-jobs-could-be-risk-computerisation|archive-date=2016-02-05}}&lt;/ref&gt;&lt;ref name="LSERPALikelyOutcomes"&gt;{{Citation|title=Nine likely scenarios arising from the growing use of software robots|publisher=London School of Economics|url=http://eprints.lse.ac.uk/64032/1/blogs.lse.ac.uk-Nine%20likely%20scenarios%20arising%20from%20the%20growing%20use%20of%20robots.pdf}}&lt;/ref&gt; project that RPA, among other technological trends, is expected to drive a new wave of productivity and efficiency gains in the global labour market. Although not directly attributable to RPA alone, [[University of Oxford|Oxford University]] conjectures that up to 35% of all jobs might be automated by 2035.&lt;ref name=" OxfordFutureJobs" /&gt; 

There are geographic implications to the trend in robotic automation. In the example above where an offshored process is "repatriated" under the control of the client organization (or even displaced by a [[Business Process Outsourcing|Business Process Outsourcer]] from an offshore location to a data centre, the impact will be a deficit in economic activity to the offshore location and an economic benefit to the originating economy. On this basis, developed economies – with skills and technological infrastructure to develop and support a robotic automation capability – can be expected to achieve a net benefit from the trend.

In a [[TEDx]] talk&lt;ref name="TEDxDavidMoss"&gt;{{Citation|title=White Collar Robots: The Virtual Workforce|publisher=TEDx Talks|url=https://www.youtube.com/watch?v=1SximAg9t4w}}&lt;/ref&gt; hosted by [[University College London]] (UCL), entrepreneur David Moss explains that digital labour in the form of RPA is not only likely to revolutionize the cost model of the services industry by driving the price of products and services down, but that it is likely to drive up service levels, quality of outcomes and create increased opportunity for the personalization of services. 

In a separate [[TEDx]] in 2019 talk,&lt;ref name="TEDxKoichiHasegawa"&gt;{{Citation|title=Digital Robots for Everyone|publisher=TEDx Talks|url=https://www.youtube.com/watch?v=iTAVEbfdZs8&amp;list=PLwA4-E7yzkS_6gjQTAimjTYbqWfvH2Z6b&amp;index=3&amp;t}}&lt;/ref&gt; Japanese business executive, and former CIO of Barclays bank, Koichi Hasegawa noted that digital robots can be a positive effect on society if we start using a robot with empathy to help every person. He provides a case study of the Japanese insurance companies – Sompo Japan and Aioi – both of whom deployed bots to speed up the process of insurance pay-outs in past massive disaster incidents. 

Meanwhile, Professor Willcocks, author of the LSE paper&lt;ref name=" LSERPALikelyOutcomes" /&gt; cited above, speaks of increased job satisfaction and intellectual stimulation, characterising the technology as having the ability to "take the robot out of the human",&lt;ref name="TechWorldRobotHuman"&gt;{{Citation|title=Technology is not about to steal your job|publisher=www.techworld.com|url=http://www.techworld.com/careers/technology-is-not-about-steal-your-job-3634370}}&lt;/ref&gt; a reference to the notion that robots will take over the mundane and repetitive portions of people's daily workload, leaving them to be redeployed into more interpersonal roles or to concentrate on the remaining, more meaningful, portions of their day.

== Robotic process automation 2.0 ==
Robotic process automation 2.0, often referred to as "unassisted RPA" or RPAAI,&lt;ref&gt;{{Cite web|url=https://medium.com/@AIMDekTech/evolution-of-robotic-process-automation-the-path-to-cognitive-rpa-c3bd52c8b865|title=Evolution of Robotic Process Automation (RPA): The Path to Cognitive RPA|last=Technologies|first=AIMDek|date=2018-08-29|website=Medium|access-date=2019-01-28}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|title=RPAAI - Robotic Process Automation|url=http://rpaai.com/Robotic-Process-Automation/|website=rpaai.com|language=nl-NL|access-date=2020-05-06}}&lt;/ref&gt; is the next generation of RPA related technologies. Technological advancements and improvements around [[artificial intelligence]] technologies are making it easier for businesses to take advantage of the benefits of RPA without dedicating a large budget for development work.

While unassisted RPA has a number of benefits, it is not without drawbacks. Utilizing unassisted RPA, a process can be run on a computer without needing input from a user, freeing up that user to do other work. However, in order to be effective, very clear rules need to be established in order for the processes to run smoothly.&lt;ref&gt;{{Cite web|url=http://blog.symphonyhq.com/rpa-technical-insights-part-3-assisted-or-unassisted-robotic-process-automation-how-to-choose-the-right-delivery-model-for-your-project|title=RPA Technical Insights, Part 3: Assisted or Unassisted Robotic Process Automation: How to choose the right delivery model for your project|last=Brain|first=David|website=blog.symphonyhq.com|language=en-us|access-date=2019-01-28}}&lt;/ref&gt;

== Hyperautomation ==

[[Hyperautomation]] is the application of advanced technologies like RPA, [[Artificial Intelligence]], machine learning (ML) and Process Mining to augment workers and automate processes in ways that are significantly more impactful than traditional automation capabilities.&lt;ref&gt;{{Cite web|url=https://www.gartner.com/smarterwithgartner/gartner-top-10-strategic-technology-trends-for-2020/|title=Gartner Top 10 Strategic Technology Trends for 2020|website=Gartner}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.gigabitmagazine.com/ai/gartner-tech-trends-2020-what-hyperautomation/|title=Gartner Tech Trends 2020|website=Gigabit Magazine}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.techrepublic.com/article/hyperautomation-human-augmentation-and-distributed-cloud-among-top-10-technology-trends-for-2020/|title=Hyperautomation among top 10 technology trends for 2020|website=Tech Republic}}&lt;/ref&gt; Hyperautomation is the combination of automation tools to deliver work.&lt;ref&gt;{{Cite web|url=https://www.information-age.com/gartners-top-10-strategic-technology-trends-for-2020-123485796/|title=Gartner's top 10 strategic trends for 2020|website=Information Age}}&lt;/ref&gt;

Gartner’s report notes that this trend was kicked off with robotic process automation (RPA). The report notes that, “RPA alone is not hyperautomation. Hyperautomation requires a combination of tools to help support replicating pieces of where the human is involved in a task."&lt;ref&gt;{{Cite web|url=https://www.forbes.com/sites/peterhigh/2019/10/21/breaking-gartner-announces-top-10-strategic-technology-trends-for-2020/#4e6642c44074/|title= Gartner Announces Top 10 Strategic Technology Trends For 2020
|website=Forbes}}&lt;/ref&gt;

== Outsourcing ==
Back office clerical processes outsourced by large organisations - particularly those sent offshore - tend to be simple and transactional in nature, requiring little (if any) analysis or subjective judgement. This would seem to make an ideal starting point for organizations beginning to adopt robotic automation for the back office. Client organisations may choose to take outsourced processes back "in house" from their [[Business Process Outsourcing]] (BPO) providers, thus representing a threat to the future of the BPO business,&lt;ref name="CIO"&gt;{{Citation|title=IT Robots May Mean the End of Offshore Outsourcing|url=http://www.cio.com/article/721800/IT_Robots_May_Mean_the_End_of_Offshore_Outsourcing|publisher=CIO Magazine}}&lt;/ref&gt; or whether the BPOs implement such automations on their clients' behalf may well depend on a number of factors. 

Conversely however, a BPO provider may seek to effect some form of client lock-in by means of automation. By removing cost from a business operation, where the BPO provider is considered to be the owner of the intellectual property and physical implementation of a robotic automation solution (perhaps in terms of hardware, ownership of software licences, etc.), the provider can make it very difficult for the client to take a process back "in house" or elect a new BPO provider. This effect occurs as the associated cost savings made through automation would - temporarily at least - have to be reintroduced to the business in order to whilst the technical solution is reimplemented in the new operational context.

The geographically agnostic nature of software means that new business opportunities may arise for those organisations who have a political or regulatory impediment to offshoring or outsourcing. A robotised automation can be hosted in a data centre in any jurisdiction and this has two major consequences for BPO providers. Firstly, for example, a sovereign government may not be willing or legally able to outsource the processing of tax affairs and security administration.  On this basis, if robots are compared to a human workforce, this creates a genuinely new opportunity for a "third sourcing" option, after the choices of onshore vs. offshore. Secondly, and conversely, BPO providers have previously relocated outsourced operations to different political and geographic territories in response to changing [[wage inflation]] and new [[labor arbitrage]] opportunities elsewhere. By contrast, a data centre solution would seem to offer a fixed and predictable cost base that, if sufficiently low in cost on a robot vs. human basis,  would seem to eliminate any potential need or desire to continually relocate operational bases.

== Examples ==
* [[Speech recognition|Voice recognition]] and [[digital dictation]] software linked to join up business processes for straight through processing without manual intervention
* Specialised [[Remote Infrastructure Management]] software featuring automated investigation and resolution of problems, using robots for first line [[IT support]]
*[[Chatterbot|Chatbots]] used by internet retailers and service providers to service customer requests for information. Also used by companies to service employee requests for information from internal databases
* Presentation layer automation software, increasingly used by [[Business Process Outsourcing|Business Process Outsourcers]] to displace human labor
* [[IVR]] systems incorporating intelligent interaction with callers

==See also==
* [[Automation]]
*[[Business process automation]]

==References==
{{reflist|30em}}

==Sources==
*[https://www.nytimes.com/2012/12/12/opinion/global/jobs-productivity-and-the-great-decoupling.html?_r=0 Jobs, productivity and the great decoupling], by Professor McAfee, Principal Research Scientist at MIT’s Center for Digital Business.
*[https://www.economist.com/news/special-report/21569573-attractions-employing-robots-rise-software-machines Rise of the software machines], Economist Magazine.
*[https://www.nytimes.com/2018/08/05/technology/workplace-ai.html London School of Economics Releases First in a Series of RPA Case Studies], Reuters
*[http://www.managementthinking.eiu.com/sites/default/files/downloads/EIU_Humans%20&amp;%20machines_FINAL_WEB.pdf Humans and Machines: The role of people in technology-driven organisations], Economist Magazine.
*[https://web.archive.org/web/20150921062911/http://www.hfsresearch.com/Robotic-Automation-as-Threat-to-Traditional-Low-Cost-Outsourcing Robotic Automation as Threat to Traditional Low-Cost Outsourcing], HfS Research.
*[http://np.netpublicator.com/netpublication/n34908574 Times BPO Supplement],  Raconteur, June 2013
*[https://web.archive.org/web/20150413032822/http://outsourcemagazine.co.uk/visions-of-the-future-the-next-decade-in-bpo/ Visions of the Future: The Next Decade in BPO], Outsource Magazine.

[[Category:Business software]]
[[Category:Automation software]]
[[Category:Information economy]]
[[Category:Machine learning]]</text>
      <sha1>ix7s20wz21sb2kue055wmvrxczzpqfg</sha1>
    </revision>
  </page>
  <page>
    <title>ELMo</title>
    <ns>0</ns>
    <id>64781650</id>
    <revision>
      <id>998558526</id>
      <parentid>994039501</parentid>
      <timestamp>2021-01-05T23:14:04Z</timestamp>
      <contributor>
        <username>Badtemperedgeezer</username>
        <id>24933379</id>
      </contributor>
      <minor/>
      <comment>Fix erroneous reference to the Allen Institute for Brain Science. It was AI2 and UW (as shown on the paper's author list)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="1386" xml:space="preserve">{{short description|Word embedding system}}
{{Sources exist|date=September 2020}}
'''ELMo''' is a [[word embedding]] method for representing a sequence of words as a corresponding sequence of vectors.&lt;ref&gt;{{cite arXiv |vauthors=Peters ME, Neumann M, Iyyer M, Gardner M, Clark C, Lee K, Zettlemoyer L |date=2018 |title=Deep contextualized word representations |class=cs.CL |eprint=1802.05365 }}&lt;/ref&gt; Character-level tokens are taken as the inputs to a bi-directional [[Long short-term memory|LSTM]] which produces word-level embeddings. Like [[BERT (language model)|BERT]] (but unlike the word embeddings produced by "[[Bag-of-words model|Bag of Words]]" approaches, and earlier vector approaches such as [[Word2vec|Word2Vec]] and [[GloVe (machine learning)|GloVe]]), ELMo embeddings are context-sensitive, producing different representations for words that share the same spelling but have different meanings ([[Homonym|homonyms]]) such as "bank" in "river bank" and "bank balance".

It was created by researchers at the [[Allen Institute for Artificial Intelligence]]&lt;ref&gt;https://allennlp.org/elmo&lt;/ref&gt; and [[University of Washington]].

== References ==
{{reflist}}

{{software-stub}}

[[Category:Machine learning]]
[[Category:Natural language processing]]
[[Category:Natural language processing software]]
[[Category:Computational linguistics]]
[[Category:Artificial intelligence]]</text>
      <sha1>fs6w1r7n1sr3h9va96vrt6t3ebdylos</sha1>
    </revision>
  </page>
  <page>
    <title>Document classification</title>
    <ns>0</ns>
    <id>1331441</id>
    <revision>
      <id>1002299487</id>
      <parentid>1002299242</parentid>
      <timestamp>2021-01-23T19:43:19Z</timestamp>
      <contributor>
        <username>E3a</username>
        <id>16959298</id>
      </contributor>
      <comment>/* Applications */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="12856" xml:space="preserve">'''Document classification''' or '''document categorization''' is a problem in [[library science]], [[information science]] and [[computer science]]. The task is to assign a [[document]] to one or more [[Class (philosophy)|classes]] or [[Categorization|categories]]. This may be done "manually" (or "intellectually") or [[algorithmically]]. The intellectual classification of documents has mostly been the province of library science, while the algorithmic classification of documents is mainly in information science and computer science. The problems are overlapping, however, and there is therefore interdisciplinary research on document classification.

The documents to be classified may be texts, images, music, etc. Each kind of document possesses its special classification problems. When not otherwise specified, text classification is implied.

Documents may be classified according to their [[Subject (documents)|subjects]] or according to other attributes (such as document type, author, printing year etc.). In the rest of this article only subject classification is considered. There are two main philosophies of subject classification of documents: the content-based approach and the request-based approach.

=="Content-based" versus "request-based" classification==
'''Content-based classification''' is classification in which the weight given to particular subjects in a document determines the class to which the document is assigned. It is, for example, a common rule for classification in libraries, that at least 20% of the content of a book should be about the class to which the book is assigned.&lt;ref&gt;Library of Congress (2008). The subject headings manual. Washington, DC.: Library of Congress, Policy and Standards Division. (Sheet H 180: "Assign headings only for topics that comprise at least 20% of the work.")&lt;/ref&gt; In automatic classification it could be the number of times given words appears in a document.

'''Request-oriented classification''' (or -indexing) is classification in which the anticipated request from users is influencing how documents are being classified. The classifier asks themself: “Under which descriptors should this entity be found?” and “think of all the possible queries and decide for which ones the entity at hand is relevant” (Soergel, 1985, p.&amp;nbsp;230&lt;ref&gt;Soergel, Dagobert (1985). [https://books.google.com/books?id=cHbNCgAAQBAJ&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false Organizing information: Principles of data base and retrieval systems]. Orlando, FL: Academic Press.&lt;/ref&gt;).

Request-oriented classification may be classification that is targeted towards a particular audience or user group. For example, a library or a database for feminist studies may classify/index documents differently when compared to a historical library.  It is probably better, however, to understand request-oriented classification as ''policy-based classification'': The classification is done according to some ideals and reflects the purpose of the library or database doing the classification. In this way it is not necessarily a kind of classification or indexing based on user studies. Only if empirical data about use or users are applied should request-oriented classification be regarded as a user-based approach.

==Classification versus indexing==
Sometimes a distinction is made between assigning documents to classes ("classification") versus assigning [[Subject (documents)|subjects]] to documents ("[[subject indexing]]") but as [[Frederick Wilfrid Lancaster]] has argued, this distinction is not fruitful. "These terminological distinctions,” he writes, “are quite meaningless and only serve to cause confusion” (Lancaster, 2003, p.&amp;nbsp;21&lt;ref&gt;Lancaster, F. W. (2003). Indexing and abstracting in theory and practice. Library Association, London.&lt;/ref&gt;). The view that this distinction is purely superficial is also supported by the fact that a classification system may be transformed into a [[thesaurus]] and vice versa (cf., Aitchison, 1986,&lt;ref&gt;Aitchison, J. (1986). "A classification as a source for thesaurus: The Bibliographic Classification of H. E. Bliss as a source of thesaurus terms and structure." Journal of Documentation, Vol. 42 No. 3, pp. 160-181.&lt;/ref&gt; 2004;&lt;ref&gt;Aitchison, J. (2004). "Thesauri from BC2: Problems and possibilities revealed in an experimental thesaurus derived from the Bliss Music schedule." Bliss Classification Bulletin, Vol. 46, pp. 20-26.&lt;/ref&gt; Broughton, 2008;&lt;ref&gt;Broughton, V. (2008). "[https://link.springer.com/article/10.1007/s10516-007-9027-7 A faceted classification as the basis of a faceted terminology: Conversion of a classified structure to thesaurus format in the Bliss Bibliographic Classification] (2nd Ed.).]" Axiomathes, Vol. 18 No.2, pp. 193-210.&lt;/ref&gt; Riesthuis &amp; Bliedung, 1991&lt;ref&gt;Riesthuis, G. J. A., &amp; Bliedung, St. (1991). "Thesaurification of the UDC." Tools for knowledge organization and the human interface, Vol. 2, pp. 109-117. Index Verlag, Frankfurt.&lt;/ref&gt;). Therefore, the act of labeling a document (say by assigning a term from a [[controlled vocabulary]] to a document) is at the same time to assign that document to the class of documents indexed by that term (all documents indexed or classified as X belong to the same class of documents). In other words, labeling a document is the same as assigning it to the class of documents indexed under that label. 

==Automatic document classification (ADC)==
Automatic document classification tasks can be divided into three sorts: '''supervised document classification''' where some external mechanism (such as human feedback) provides information on the correct classification for documents, '''unsupervised document classification''' (also known as [[document clustering]]), where the classification must be done entirely without reference to external information, and '''semi-supervised document classification''',&lt;ref&gt;
Rossi, R. G., Lopes, A. d. A., and Rezende, S. O. (2016). [https://www.sciencedirect.com/science/article/pii/S0306457315000990 Optimization and label propagation in bipartite heterogeneous networks to improve transductive classification of texts].
Information Processing &amp; Management, 52(2):217–257.
&lt;/ref&gt; where parts of the documents are labeled by the external mechanism. There are several software products under various license models available.&lt;ref&gt;{{Cite web |url=https://pdfs.semanticscholar.org/bea4/a204239556a29228decc9e029c326e4900b7.pdf |title=An Interactive Automatic Document Classification Prototype |access-date=2017-11-14 |archive-url=https://web.archive.org/web/20171115082749/https://pdfs.semanticscholar.org/bea4/a204239556a29228decc9e029c326e4900b7.pdf |archive-date=2017-11-15 |url-status=dead }}&lt;/ref&gt;&lt;ref&gt;[https://seer.lcc.ufmg.br/index.php/jidm/article/download/43/41An Interactive Automatic Document Classification Prototype] {{webarchive |url=https://web.archive.org/web/20150424122349/https://seer.lcc.ufmg.br/index.php/jidm/article/download/43/41An |date=April 24, 2015 }}&lt;/ref&gt;&lt;ref&gt;[https://archive.is/20141208063727/http://www.artsyltech.com/da_classification.htmlAutomatic Document Classification - Artsyl]&lt;/ref&gt;&lt;ref&gt;[http://www.abbyy.com/ocr_sdk_windows/what_is_new/classification/ ABBYY FineReader Engine 11 for Windows]&lt;/ref&gt;&lt;ref&gt;[http://www.antidot.net/classifier/ Classifier - Antidot]&lt;/ref&gt;

=== Techniques ===
Automatic document classification techniques include:
* [[Expectation maximization]] (EM)
* [[Naive Bayes classifier]]
* [[tf–idf]]
* [[Instantaneously trained neural networks]]
* [[Latent semantic indexing]]
* [[Support vector machines]] (SVM)
* [[Artificial neural network]]
* [[k-nearest neighbor algorithm|K-nearest neighbour algorithms]]
* [[Decision tree learning|Decision trees]] such as [[ID3 algorithm|ID3]] or [[C4.5 algorithm|C4.5]]
* [[Concept Mining]]
* [[Rough set]]-based classifier
* [[Soft set]]-based classifier
* [[Multiple-instance learning]]
* [[Natural language processing]] approaches

== Applications ==
Classification techniques have been applied to
* [[spam filter]]ing, a process which tries to discern [[E-mail spam]] messages from legitimate emails
* email [[routing]], sending an email sent to a general address to a specific address or mailbox depending on topic&lt;ref&gt;Stephan Busemann, Sven Schmeier and Roman G. Arens (2000). [https://arxiv.org/abs/cs/0003060 Message classification in the call center]. In Sergei Nirenburg, Douglas Appelt, Fabio Ciravegna and Robert Dale, eds., Proc. 6th Applied Natural Language Processing Conf. (ANLP'00), pp. 158-165, ACL.&lt;/ref&gt;
* [[language identification]], automatically determining the language of a text
* genre classification, automatically determining the genre of a text&lt;ref&gt;{{Citation|last = Santini| first = Marina | last2 = Rosso| first2 = Mark| title = Testing a Genre-Enabled Application: A Preliminary Assessment| url = http://www.bcs.org/upload/pdf/ewic_fd08_paper7.pdf| series = BCS IRSG Symposium: Future Directions in Information Access| place = London, UK | pages= 54–63| year = 2008 }}&lt;/ref&gt;
* [[Readability|readability assessment]], automatically determining the degree of readability of a text, either to find suitable materials for different age groups or reader types or as part of a larger [[text simplification]] system
* [[sentiment analysis]], determining the attitude of a speaker or a writer with respect to some topic or the overall contextual polarity of a document.
* health-related classification using social media in public health surveillance &lt;ref&gt;X. Dai, M. Bikdash and B. Meyer, "From social media to public health surveillance: Word embedding based clustering method for twitter classification," SoutheastCon 2017, Charlotte, NC, 2017, pp. 1-7.
{{DOI|10.1109/SECON.2017.7925400}}&lt;/ref&gt;
* article triage, selecting articles that are relevant for manual literature curation, for example as is being done as the first step to generate manually curated annotation databases in biology &lt;ref name=":0"&gt;{{Cite journal
 | pmid = 18834495
| year = 2008
| last1 = Krallinger
| first1 = M
| title = Overview of the protein-protein interaction annotation extraction task of Bio ''Creative'' II
| journal = Genome Biology
| volume = 9 Suppl 2
| pages = S4
| last2 = Leitner
| first2 = F
| last3 = Rodriguez-Penagos
| first3 = C
| last4 = Valencia
| first4 = A
| doi = 10.1186/gb-2008-9-s2-s4
| pmc = 2559988
}}&lt;/ref&gt;
* [[computational humor|humor detection]], automatically determining if the given short text should be taken seriously or not, with usecases in chatbots and personal assistants. &lt;ref&gt;Annamoradnejad, I. (2020). [https://arxiv.org/abs/2004.12765 Colbert: Using bert sentence embedding for humor detection]. arXiv preprint arXiv:2004.12765.&lt;/ref&gt;

== See also ==
{{colbegin}}
* [[Categorization]]
* [[Classification (disambiguation)]]
* [[Compound term processing]]
* [[Concept-based image indexing]]
* [[Content-based image retrieval]]
* [[Document]]
* [[Supervised learning]], [[unsupervised learning]]
* [[Document retrieval]]
* [[Document clustering]]
* [[Information retrieval]]
* [[Knowledge organization]]
* [[Knowledge Organization System]]
* [[Library classification]]
* [[Machine learning]]
* [[Native Language Identification]]
* [[String metrics]]
* [[Subject (documents)]]
* [[Subject indexing]]
* [[Text mining]], [[web mining]], [[concept mining]]
{{colend}}

== Further reading ==
* Fabrizio Sebastiani. [https://arxiv.org/abs/cs.ir/0110053 Machine learning in automated text categorization]. ACM Computing Surveys, 34(1):1–47, 2002.
* Stefan Büttcher, Charles L. A. Clarke, and Gordon V. Cormack. [http://www.ir.uwaterloo.ca/book/ Information Retrieval: Implementing and Evaluating Search Engines]. MIT Press, 2010.

==References==
{{Reflist}}

== External links ==
* [https://web.archive.org/web/20070613200617/http://isp.imm.dtu.dk/thor/projects/multimedia/textmining/node11.html Introduction to document classification]
* [https://www.cs.technion.ac.il/~gabr/resources/atc/atcbib.html Bibliography on Automated Text Categorization]
* [http://liinwww.ira.uka.de/bibliography/Ai/query-classification.html Bibliography on Query Classification]
* [http://www.gabormelli.com/RKB/Text_Classification_Task Text Classification] analysis page
* [http://www.nltk.org/book/ch06.html Learning to Classify Text - Chap. 6 of the book Natural Language Processing with Python] (available online)
* [http://techtc.cs.technion.ac.il TechTC - Technion Repository of Text Categorization Datasets]
* [http://www.daviddlewis.com/resources/testcollections/ David D. Lewis's Datasets]
* [http://www.biocreative.org/tasks/biocreative-iii/ppi/ BioCreative III ACT (article classification task) dataset]

[[Category:Information science]]
[[Category:Natural language processing]]
[[Category:Knowledge representation]]
[[Category:Data mining]]
[[Category:Machine learning]]</text>
      <sha1>hzji18jcj3saw9626o0h6o5nrv7iozz</sha1>
    </revision>
  </page>
  <page>
    <title>Ablation (artificial intelligence)</title>
    <ns>0</ns>
    <id>65434605</id>
    <revision>
      <id>981887962</id>
      <parentid>981887661</parentid>
      <timestamp>2020-10-05T00:26:12Z</timestamp>
      <contributor>
        <username>Nbarth</username>
        <id>570614</id>
      </contributor>
      <minor/>
      <comment>/* References */ category</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2355" xml:space="preserve">In [[artificial intelligence]] (AI), particularly [[machine learning]] (ML), '''ablation''' is the removal of a component of an AI system. An '''ablation study''' studies the performance of an AI system by removing certain components, to understand the contribution of the component to the overall system. The term is by analogy with biology (removal of components of an organism), and, continuing the analogy, is particularly used in the analysis of [[artificial neural net]]s, by analogy with [[ablative brain surgery]].&lt;ref&gt;{{cite journal|first1=Richard|last1=Meyes|first2=Melanie|last2=Lu|first3=Constantin Waubert|last3=de Puiseau|first4=Tobias|last4=Meisen|title=Ablation Studies in Artificial Neural Networks|arxiv=1901.08644|url=https://arxiv.org/abs/1901.08644v2|date=2019-01-24}}&lt;/ref&gt; Ablation studies require that the system exhibit [[graceful degradation]]: that they continue to function even when certain components are missing or degraded.{{sfn|Newell|1975}}

==History==
The term is credited to [[Allen Newell]],{{sfn|Cohen|Howe|1988|p=40|loc=Ablation and substitution studies.}} who used it in his 1974 tutorial on [[speech recognition]], published in {{harvtxt|Newell|1975}}. The term is by analogy with [[ablation]] in biology. The motivation was that, while individual components are engineered, the contribution of an individual component to the overall system performance is not clear; removing components allows this analysis.{{sfn|Newell|1975}}

==References==
{{reflist}}
{{refbegin}}
* {{cite conference
|last=Newell |first=Allen |author-link=Allen Newell
|year=1975
|title=A Tutorial on Speech Understanding Systems
|conference=In Speech Recognition: Invited Papers Presented at the 1974 IEEE Symposium
|editor=D. Raj Reddy
|editor-link=Raj Reddy
|page=[{{GBurl|eJac7g7YfZIC|pg=PA43}} 43]
|location=New York
|publisher=Academic
}}
* {{cite journal|first1=Paul R.|last1=Cohen|first2=Adele E.|last2=Howe|title=How Evaluation Guides AI Research: The Message Still Counts More than the Medium|url=https://www.aaai.org/ojs/index.php/aimagazine/article/view/952|journal=AI Magazine|date=1988-12-15|issn=2371-9621|pages=35–43|volume=9|issue=4|doi=10.1609/aimag.v9i4.952}}
{{refend}}

{{compu-ai-stub}}

[[Category:Artificial intelligence]]
[[Category:Artificial neural networks]]
[[Category:Causality]]
[[Category:Machine learning]]</text>
      <sha1>1iwv97vjdn3jiajkcpt02w73t168v3w</sha1>
    </revision>
  </page>
  <page>
    <title>Automation in construction</title>
    <ns>0</ns>
    <id>65834550</id>
    <revision>
      <id>995409007</id>
      <parentid>995396621</parentid>
      <timestamp>2020-12-20T21:51:52Z</timestamp>
      <contributor>
        <ip>76.73.250.60</ip>
      </contributor>
      <comment>/* Transportation Construction */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2456" xml:space="preserve">{{short description|The combination of methods, processes, and systems}}
'''Automation in construction''' is the combination of methods, processes, and systems that allow for greater machine autonomy in construction activities. Construction automation may have multiple goals, including but not limited to, reducing [[jobsite]] injuries, decreasing activity completion times, and assisting with [[quality control]] and [[quality assurance]].&lt;ref&gt;{{cite web |title=The impact and opportunities of automation in construction |url=https://www.mckinsey.com/business-functions/operations/our-insights/the-impact-and-opportunities-of-automation-in-construction# |website=McKinsey &amp; Company |accessdate=13 November 2020}}&lt;/ref&gt; Some systems may be fielded as a direct response to increasing skilled labor shortages in some countries.&lt;ref&gt;{{cite news |last1=Vernon |first1=Joe |last2=Hughes |first2=Jeff |title=Using Automation to Combat the Impending Labor Shortage |url=https://www.industryweek.com/supply-chain/supply-chain-technology/article/22024093/using-automation-to-combat-the-impending-labor-shortage |accessdate=13 November 2020 |agency=Industry Week |date=1 September 2017}}&lt;/ref&gt; Opponents claim that increased automation may lead to less construction jobs and that software leaves [[heavy equipment]] vulnerable to [[hackers]].&lt;ref&gt;{{cite news |last1=Carter |first1=Jamie |title=Hacked Driverless Cars Could Cause Collisions And Gridlock In Cities, Say Researchers |url=https://www.forbes.com/sites/jamiecartereurope/2019/03/05/hacked-driverless-cars-could-cause-collisions-and-gridlock-in-cities-say-researchers/?sh=4f4c8d112a09 |accessdate=13 November 2020 |agency=Forbes |date=5 March 2019}}&lt;/ref&gt;

==Transportation construction==

[[Kratos Defense &amp; Security Solutions]] fielded the world’s first Autonomous [[Truck-Mounted Attenuator]] (ATMA) in 2017, in conjunction with Royal Truck &amp; Equipment.&lt;ref&gt;{{cite news |last1=Peck |first1=Abe |title=From War Zone to Work Zone |url=https://insideunmannedsystems.com/from-war-zone-to-work-zone/ |access-date=20 December 2020 |agency=Inside Unmanned Systems |publisher=Autonomous Media, LLC |date=23 July 2019}}&lt;/ref&gt;

==References==
{{Reflist}}

[[Category:Automation]]
[[Category:Automation software]]
[[Category:Construction]]
[[Category:Internet of things]]
[[Category:Machine learning]]
[[Category:Artificial intelligence applications]]
[[Category:Heavy equipment]]
[[Category:Self-driving cars]]</text>
      <sha1>fro9q11fb4aecitgnvdqptvbtvbdr3q</sha1>
    </revision>
  </page>
  <page>
    <title>Pythia (machine learning)</title>
    <ns>0</ns>
    <id>65978769</id>
    <revision>
      <id>997618759</id>
      <parentid>996215994</parentid>
      <timestamp>2021-01-01T12:21:51Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: doi added to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2968" xml:space="preserve">{{orphan|date=December 2020}}

Pythia&lt;ref&gt;{{Cite news|title=Oracle of AI solves classic ancient conundrums|language=en|work=[[The Times]]|url=https://www.thetimes.co.uk/article/oracle-of-ai-solves-classic-conundrums-v6pdtsps0|access-date=2020-11-30|issn=0140-0460}}&lt;/ref&gt;&lt;ref&gt;{{Cite news|title=AI is helping scholars restore ancient Greek texts on stone tablets|language=en-US|website=[[TechCrunch]]|url=https://social.techcrunch.com/2019/10/18/ai-is-helping-scholars-restore-ancient-greek-texts-on-stone-tablets/|access-date=2020-11-30}}&lt;/ref&gt; is an ancient text restoration model that recovers missing characters from a damaged text input using deep neural networks. It was created by [[Yannis Assael]], [[Thea Sommerschield]], and [[Jonathan Prag]], researchers from [[Google Deepmind|Google DeepMind]] and the [[University of Oxford]].&lt;ref&gt;{{Cite journal|last=Assael|first=Yannis|last2=Sommerschield|first2=Thea|last3=Prag|first3=Jonathan|date=2019|title=Restoring ancient text using deep learning: a case study on Greek epigraphy|url=http://dx.doi.org/10.18653/v1/d19-1668|journal=Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)|location=Stroudsburg, PA, USA|publisher=Association for Computational Linguistics|doi=10.18653/v1/d19-1668|doi-access=free}}&lt;/ref&gt;

To study the society and the history of ancient civilisations, [[ancient history]] relies on disciplines such as [[Epigraphy]], the study of ancient inscribed texts. Hundreds of thousands of these texts, known as [[inscriptions]], have survived to our day, but are often damaged over the centuries. Illegible parts of the text must then be restored by specialists, called [[Epigraphist|epigraphists]], in order to extract meaningful information from the text and use it to expand our knowledge of the context in which the text was written. Pythia takes as input the damaged text, and is trained to return hypothesised restorations of ancient Greek inscriptions, working as an assistive aid for ancient historians. Its [[neural network]] architecture works at both the character- and word-level, thereby effectively handling long-term context information, and dealing efficiently with incomplete word representations. Pythia is applicable to any discipline dealing with ancient texts ([[philology]], [[papyrology]], [[codicology]]) and can work in any language (ancient or modern).&lt;ref&gt;{{Cite web|title=Restoring ancient text using deep learning: a case study on Greek epigraphy|url=https://deepmind.com/research/publications/Restoring-ancient-text-using-deep-learning-a-case-study-on-Greek-epigraphy|access-date=2020-11-30|website=[[DeepMind]]}}&lt;/ref&gt;

== References ==
{{reflist}}

[[Category:Machine learning]]
[[Category:Artificial intelligence]]
[[Category:Digital humanities projects]]
[[Category:Digital humanities]]
[[Category:Epigraphy]]
[[Category:Ancient history]]</text>
      <sha1>kn4w5h44ixyf2a7ljs53mv9xvlwprm4</sha1>
    </revision>
  </page>
  <page>
    <title>Attention (machine learning)</title>
    <ns>0</ns>
    <id>66001552</id>
    <revision>
      <id>1004027523</id>
      <parentid>1004011320</parentid>
      <timestamp>2021-01-31T19:42:20Z</timestamp>
      <contributor>
        <username>Numiri</username>
        <id>2036731</id>
      </contributor>
      <minor/>
      <comment>/* A Language Translation Example */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="8122" xml:space="preserve">{{short description|Machine learning technique}}
In the context of [[neural networks]], '''attention''' is a technique that mimics cognitive [[attention]].  The effect enhances the important parts of the input data and fades out the rest -- the thought being that the network should devote more computing power on that small but important part of the data.  Which part of the data is more important than others depends on the context and is learned through training data by gradient descent.

They are used in a wide variety of machine learning models, including in [[natural language processing]] and [[computer vision]].&lt;ref name=allyouneed&gt;{{cite arxiv|last1=Vaswani|first1=Ashish|last2=Shazeer|first2=Noam|last3=Parmar|first3=Niki|last4=Uszkoreit|first4=Jakob|last5=Jones|first5=Llion|last6=Gomez|first6=Aidan N.|last7=Kaiser|first7=Lukasz|last8=Polosukhin|first8=Illia|date=2017-12-05|title=Attention Is All You Need|class=cs.CL|eprint=1706.03762}}&lt;/ref&gt;&lt;ref&gt;{{cite arxiv|last1=Ramachandran|first1=Prajit|last2=Parmar|first2=Niki|last3=Vaswani|first3=Ashish|last4=Bello|first4=Irwan|last5=Levskaya|first5=Anselm|last6=Shlens|first6=Jonathon|date=2019-06-13|title=Stand-Alone Self-Attention in Vision Models|class=cs.CV|eprint=1906.05909}}&lt;/ref&gt;

[[Transformer network]]s make extensive use of attention mechanisms to achieve their expressive power.&lt;ref name=allyouneed/&gt; Computer vision systems based on [[convolutional neural network]]s can also benefit from attention mechanisms.{{citation needed|date=December 2020}}

The two most common attention techniques used are '''dot-product attention''', which uses the [[dot product]] between vectors to determine attention, and '''multi-head attention''', which combines several different attention mechanisms to direct the overall attention of a network or sub-network.

== A Language Translation Example ==

To build a machine that translates English-to-French (see diagram below), one starts with an Encoder-Decoder and graft an attention unit to it.  The attention unit is a fully connected neural network that feeds a weighted combination of encoder outputs into the decoder.  
&lt;table&gt;
&lt;tr&gt;
&lt;td style="vertical-align:top"&gt;
{{plain image with caption|File:Attention-1-sn.png | Encoder-Decoder with attention. This diagram uses specific values to relieve an already cluttered notation alphabet soup.  The left part (in black) is the Encoder-Decoder, the middle part (in orange) is the attention unit, and the right part (in grey &amp; colors) is the computed data.  Grey regions in H matrix and w vector are zero values.  Subscripts are examples of vector sizes, except for i-1 which indicate time step. |  500px }}
&lt;/td&gt;
&lt;td&gt;
{| class="wikitable"
|+ Legend
|-
! label !! description
|-
| 100 || max sentence length
|-
| 300 || embedding size.  (word dimension)
|-
| 500 || length of hidden vector
|-
| 10k || dictionary size of 10,000 words
|-
| &lt;u&gt;x&lt;/u&gt;, &lt;u&gt;y&lt;/u&gt; || 10k 1-hot dictionary vector.  &lt;u&gt;x&lt;/u&gt; → x implemented as a lookup table rather than vector multiplication.
|-
| x, y || 300-long word embedding vector.  The vectors are usually pre-calculated from other projects such as Glove or Word2Vec.
|-
| h || 500-long encoder hidden vector.  At each point in time, this vector summarizes all the preceding words before it.  The final h can be viewed as a "sentence" vector, or a [[Thought_vector]] as Hinton calls it.
|-
| s || 500-long decoder hidden neuron RNN Encoder.
|-
| E || 500 neuron RNN Encoder.  300 + 300 inputs, 500  outputs.
|-
| D || 2-layer decoder.  1 layer with 500 neurons and the other layer with 300 neurons.
|-
| score || 100-long alignment score
|-
| w || 100-long vector attention weight.  These are "soft" weights which changes during the forward pass, in contrast to "hard" neuronal weights that change during the learning phase.
|-
| A || Attention module -- a fully connected network whose output is a 100-long score.  
|-
| H || 500x100.  100 hidden vectors h concatenated into a matrix
|-
| c || 500-long context vector = H * w.  c is a linear combination of h vectors  weighted by w.
|}
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

This table shows the calculations at each time step.  For clarity, it uses specific numerical values and shapes rather than letters.  The nested shapes depict the summarizing nature of h, where each h contains a history of the words that came before it.  Here, the attention scores were cooked up to get the desired attention weights.
{| class="wikitable"
|- 
| step || x || h, H = encoder output &lt;br&gt; these are 500x1 vectors represented as shapes || y&lt;sub&gt;i-1&lt;/sub&gt; = decoder input to Attention || alignment score || w = attention weight &lt;br&gt; = softmax( score ) || c = context vector = H*w || y = decoder output
|-
| 1 || I    || [[ File:icon-red-diamond.png  | 30px ]] = vector encoding for "I" || - || - || - || - || -
|-
| 2 || love || [[ File:icon-green-square.png | 30px ]] = vector encoding for "I love" || - || - || - || - || -
|-
| 3 || you  || [[ File:icon-blue-circle.png  | 30px ]] = vector encoding for "I love you" || - || - || - || - || -
|-
| 4 || -    || -   || y&lt;sub&gt;1&lt;/sub&gt; does not exist yet so we use this instead &lt;br&gt; [[ File:icon-blue-circle.png | 30px ]] || [.63 -3.2 -2.5 .5 .5 ...]  || [.94 .02 .04 0 0 ...] || .94 * [[ File:icon-red-diamond.png | 30px ]] + .02 * [[ File:icon-green-square.png | 30px ]] + .04 * [[ File:icon-blue-circle.png | 30px ]] || je
|-
| 5 || -    || -   || y&lt;sub&gt;1&lt;/sub&gt; || [-1.5 -3.9 .57 .5 .5 ...]  || [.11 .01   .88 0 0 ...] || .11 * [[ File:icon-red-diamond.png | 30px ]] + .01  * [[ File:icon-green-square.png | 30px ]] + .88  * [[ File:icon-blue-circle.png | 30px ]] || t'
|-
| 6 || -    || -   || y&lt;sub&gt;2&lt;/sub&gt; || [-2.8 .64 -3.2 .5 .5 ...]  || [.03 .95   .02 0 0 ...] || .03 * [[ File:icon-red-diamond.png | 30px ]] + .95  * [[ File:icon-green-square.png | 30px ]] + .02  * [[ File:icon-blue-circle.png | 30px ]] || aime
|}
Viewed as a matrix, the attention weights show how the network adjusts its focus according to context.
&lt;table&gt;
&lt;tr&gt; &lt;td&gt;      &lt;/td&gt; &lt;td&gt; I &lt;/td&gt; &lt;td&gt; love &lt;/td&gt; &lt;td&gt; you &lt;/td&gt; &lt;/tr&gt;
&lt;tr&gt; &lt;td&gt; je   &lt;/td&gt; 
     &lt;td style="background-color:black; color:white; border: 1px solid black"&gt;.94&lt;/td&gt;
     &lt;td style="background-color:white; color:black; border: 1px solid black"&gt;.02&lt;/td&gt;
     &lt;td style="background-color:white; color:black; border: 1px solid black"&gt;.04&lt;/td&gt; &lt;/tr&gt;
&lt;tr&gt; &lt;td&gt; t'   &lt;/td&gt; 
     &lt;td style="background-color:white; color:black; border: 1px solid black"&gt;.11&lt;/td&gt;
     &lt;td style="background-color:white; color:black; border: 1px solid black"&gt;.01&lt;/td&gt;
     &lt;td style="background-color:grey ; color:white; border: 1px solid black"&gt;.88&lt;/td&gt; &lt;/tr&gt;
&lt;tr&gt; &lt;td&gt; aime &lt;/td&gt; 
     &lt;td style="background-color:white; color:black; border: 1px solid black"&gt;.03&lt;/td&gt;
     &lt;td style="background-color:black; color:white; border: 1px solid black"&gt;.95&lt;/td&gt;
     &lt;td style="background-color:white; color:black; border: 1px solid black"&gt;.02&lt;/td&gt; &lt;/tr&gt;
&lt;/table&gt;
This view of the attention weights addresses the "explainability" problem that neural networks are criticized for.  Networks that perform verbatim translation without regard to word order would have a diagonally dominant matrix if they were analyzable in these terms.  The off-diagonal dominance shows that the attention mechanism is more nuanced.  On the first pass through the decoder, 94% of the attention weight is on the first English word "I", so the network offers the word "je".  On the second pass of the decoder, 88% of the attention weight is on the third English word "you", so it offers"t'".  On the last pass, 95% of the attention weight is on the second English word "love", so it offers "aime".

== References ==
{{reflist}}

== External links ==
* [[Alex Graves (computer scientist)|Alex Graves]] (4 May 2020), [https://www.youtube.com/watch?v=AIiwuClvH6k&amp;vl=en-GB Attention and Memory in Deep Learning] (video lecture), [[DeepMind]] / [[University College London|UCL]], via YouTube. 
* [https://www.youtube.com/watch?v=yGTUuEx3GkA Rasa Algorithm Whiteboard - Attention] via YouTube

{{Differentiable computing}}

[[Category:Machine learning]]


{{compsci-stub}}</text>
      <sha1>jrpzsp09kpv3tktu0wlmdib70xlz3o3</sha1>
    </revision>
  </page>
  <page>
    <title>Artificial intelligence in hiring</title>
    <ns>0</ns>
    <id>66026469</id>
    <revision>
      <id>997661918</id>
      <parentid>997526504</parentid>
      <timestamp>2021-01-01T17:01:37Z</timestamp>
      <contributor>
        <username>Doomsdayer520</username>
        <id>2807487</id>
      </contributor>
      <comment>refs section</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="17707" xml:space="preserve">'''Artificial intelligence (AI) in hiring''' involves the use of technology to automate aspects of the hiring process. Advances in artificial intelligence, such as the advent of machine learning and the growth of big data, enable AI to be utilized to recruit, screen, and predict the success of applicants.&lt;ref name=":32"&gt;{{Cite journal|last1=Tambe|first1=Prasanna|last2=Cappelli|first2=Peter|last3=Yakubovich|first3=Valery|date=August 2019|title=Artificial Intelligence in Human Resources Management: Challenges and a Path Forward|url=http://dx.doi.org/10.1177/0008125619867910|journal=California Management Review|volume=61|issue=4|pages=15–42|doi=10.1177/0008125619867910|s2cid=220124861|issn=0008-1256}}&lt;/ref&gt; Proponents of artificial intelligence in hiring claim it reduces bias, assists with finding qualified candidates, and frees up human resource workers' time for other tasks, while opponents worry that AI perpetuates inequalities in the workplace and will eliminate jobs.

== Background ==
Artificial intelligence has been a fascination of researchers since the term was coined in the mid-1950s.&lt;ref name=":52"&gt;{{Cite journal|last1=Engster|first1=Frank|last2=Moore|first2=Phoebe V|date=2020-02-29|title=The search for (artificial) intelligence, in capitalism|url=http://dx.doi.org/10.1177/0309816820902055|journal=Capital &amp; Class|volume=44|issue=2|pages=201–218|doi=10.1177/0309816820902055|s2cid=216159322|issn=0309-8168}}&lt;/ref&gt; Researchers have identified four main forms of intelligence that AI would need to possess to truly replace humans in the workplace: mechanical, analytical, intuitive, and empathetic.&lt;ref name=":02"&gt;{{Cite journal|last1=Huang|first1=Ming-Hui|last2=Rust|first2=Roland T.|date=2018-02-05|title=Artificial Intelligence in Service|url=http://dx.doi.org/10.1177/1094670517752459|journal=Journal of Service Research|volume=21|issue=2|pages=155–172|doi=10.1177/1094670517752459|s2cid=169814393|issn=1094-6705}}&lt;/ref&gt; [[Automation]] follows a predictable progression in which it will first be able to replace the mechanical tasks, then analytical tasks, then intuitive tasks, and finally empathy based tasks.&lt;ref name=":02" /&gt; However, full automation is not the only potential outcome of AI advancements. Humans may instead work alongside machines, enhancing the effectiveness of both. In the hiring context, this means that AI has already replaced many basic human resource tasks in recruitment and screening, while freeing up time for human resource workers to do other more creative tasks that can not yet be automated or do not make fiscal sense to automate.&lt;ref name=":62"&gt;{{Cite journal|last1=Caner|first1=Salih|last2=Bhatti|first2=Feyza|date=2020-09-12|title=A Conceptual Framework on Defining Businesses Strategy for Artificial Intelligence|url=http://dx.doi.org/10.7903/cmr.19970|journal=Contemporary Management Research|volume=16|issue=3|pages=175–206|doi=10.7903/cmr.19970|issn=1813-5498|doi-access=free}}&lt;/ref&gt; It also means that the type of jobs companies are recruiting and hiring form will continue to shift as the skillsets that are most valuable change.&lt;ref name=":72"&gt;{{Cite journal|last=Mashelkar|first=R. A.|date=2018-07-08|title=Exponential Technology, Industry 4.0 and Future of Jobs in India|url=http://dx.doi.org/10.1177/0974929218774408|journal=Review of Market Integration|volume=10|issue=2|pages=138–157|doi=10.1177/0974929218774408|s2cid=158398849|issn=0974-9292}}&lt;/ref&gt;

[[Human resources]] has been identified as one of the ten industries most affected by AI.&lt;ref name=":82"&gt;{{Cite journal|last=Mashelkar|first=R. A.|date=2018-07-08|title=Exponential Technology, Industry 4.0 and Future of Jobs in India|url=http://dx.doi.org/10.1177/0974929218774408|journal=Review of Market Integration|volume=10|issue=2|pages=138–157|doi=10.1177/0974929218774408|s2cid=158398849|issn=0974-9292}}&lt;/ref&gt; It is increasingly common for companies to use AI to automate aspects of their hiring process. The hospitality, finance, and tech industries in particular have incorporated AI into their hiring processes to significant extents.&lt;ref name=":92"&gt;{{Cite journal|last1=Torres|first1=Edwin N.|last2=Mejia|first2=Cynthia|date=2017-02-01|title=Asynchronous video interviews in the hospitality industry: Considerations for virtual employee selection|url=http://www.sciencedirect.com/science/article/pii/S0278431916303723|journal=International Journal of Hospitality Management|language=en|volume=61|pages=4–13|doi=10.1016/j.ijhm.2016.10.012|issn=0278-4319}}&lt;/ref&gt;

Human resources is fundamentally an industry based around making predictions.&lt;ref name=":14"&gt;{{Cite journal|last1=Agrawal|first1=Ajay|last2=Gans|first2=Joshua|last3=Goldfarb|first3=Avi|date=June 2018|title=Economic Policy for Artificial Intelligence|url=http://dx.doi.org/10.3386/w24690|location=Cambridge, MA|doi=10.3386/w24690}}&lt;/ref&gt; Human resource specialists must predict which people would make quality candidates for a job, which marketing strategies would get those people to apply, which applicants would make the best employees, what kinds of compensation would get them to accept an offer, what is needed to retain an employee, which employees should be promoted, what a companies staffing needs, among others.&lt;ref name=":14" /&gt; AI is particularly adept at prediction because it can analyze huge amounts of data. This enables AI to make insights many humans would miss and find connections between seemingly unrelated data points. This provides value to a company and has made it advantageous to use AI to automate or augment many human resource tasks.&lt;ref name=":14" /&gt;

== Uses ==
=== Screeners ===
Screeners are tests that allow companies to sift through a large applicant pool and extract applicants that have desirable features. Companies commonly screen through the use of questionnaires, coding tests, interviews, and resume analysis. Artificial Intelligence already plays a major role in the screening process. Resumes can be analyzed using AI for desirable characteristics, such as a certain amount of work experience or a relevant degree. Interviews can then be extended to applicant's whose resumes contain these characteristics.&lt;ref name=":14" /&gt;

What factors are used to screen applicants is a concern to ethicists and civil rights activists. A screener that favors people who have similar characteristics to those already employed at a company may perpetuate inequalities. For example, if a company that is predominantly white and male uses its employees' data to train its screener it may accidentally create a screening process that favors white, male applicants. The automation of screeners also has the potential to reduce biases. Biases against applicants with African American sounding names have been shown in multiple studies.&lt;ref name=":42"&gt;{{Cite journal|last=Rodgers|date=2019|title=Race in the Labor Market: The Role of Equal Employment Opportunity and Other Policies|url=http://dx.doi.org/10.7758/rsf.2019.5.5.10|journal=RSF: The Russell Sage Foundation Journal of the Social Sciences|volume=5|issue=5|pages=198|doi=10.7758/rsf.2019.5.5.10|s2cid=211443445|issn=2377-8253|doi-access=free}}&lt;/ref&gt; An AI screener has the potential to limit human bias and error in the hiring process, allowing more minority applicants to be successful.&lt;ref name=":102"&gt;{{Cite journal|last1=Reynolds|first1=Tania|last2=Zhu|first2=Luke|last3=Aquino|first3=Karl|last4=Strejcek|first4=Brendan|date=2020-07-02|title=Dual pathways to bias: Evaluators' ideology and ressentiment independently predict racial discrimination in hiring contexts.|url=http://dx.doi.org/10.1037/apl0000804|journal=Journal of Applied Psychology|doi=10.1037/apl0000804|pmid=32614205|issn=1939-1854}}&lt;/ref&gt;

=== Recruitment ===
[[Recruitment]] involves the identification of potential applicants and the marketing of positions. AI is commonly utilized in the recruitment process because it can help boost the number of qualified applicants for positions.  Companies are able to use AI to target their marketing to applicants who are likely to be good fits for a position. This often involves the use of social media sites advertising tools, which rely on AI. Facebook allows advertisers to target ads based on demographics, location, interests, behavior, and connections. Facebook also allows companies to target a "look-a-like" audience, that is the company supplies Facebook with a data set, typically the company's current employees, and Facebook will target the ad to profiles that are similar to the profiles in the data set.&lt;ref name=":22"&gt;{{Citation|title=Big Data|date=2018-02-16|url=http://dx.doi.org/10.1002/9781119426653.app1|work=Artificial Intelligence and Big Data|pages=75–82|place=Hoboken, NJ, USA|publisher=John Wiley &amp; Sons, Inc.|doi=10.1002/9781119426653.app1|isbn=978-1-119-42665-3|access-date=2020-10-31|doi-access=free}}&lt;/ref&gt; Additionally, job sites like Indeed, Glassdoor, and ZipRecruiter target job listings to applicants that have certain characteristics employers are looking for. Targeted advertising has many advantages for companies trying to recruit such being a more efficient use of resources, reaching a desired audience, and boosting qualified applicants. This has helped make it a mainstay in modern hiring.&lt;ref name=":22" /&gt;

Who receives a targeted ad can be controversial. In hiring, the implications of targeted ads have to do with who is able to find out about and then apply to a position. Most targeted ad algorithms are [[Trade secret|proprietary]] information. Some platforms, like Facebook and Google, allow users to see why they were shown a specific ad, but users who do not receive the ad likely never know of its existence and also have no way of knowing why they were not shown the ad.&lt;ref name=":22" /&gt;

=== Interviews ===
[[Chatbot|Chatbots]] were one of the first applications of AI and are commonly used in the hiring process. Interviewees interact with chatbots to answer interview questions. Their responses can then be analyzed by AI, providing prospective employers with a myriad of insights. Chatbots streamline the interview process and reduces human resource workers' labor.&lt;ref name=":122"&gt;{{Citation|last1=Vardarlier|first1=Pelin|title=Use of Artificial Intelligence as Business Strategy in Recruitment Process and Social Perspective|date=2019-11-10|url=http://dx.doi.org/10.1007/978-3-030-29739-8_17|work=Contributions to Management Science|pages=355–373|place=Cham|publisher=Springer International Publishing|isbn=978-3-030-29738-1|access-date=2020-11-07|last2=Zafer|first2=Cem|doi=10.1007/978-3-030-29739-8_17}}&lt;/ref&gt; Video interviews utilize AII and have become prevalent. HireVue, a leader in the space, has created technology that analyzes interviewees responses and gestures during recorded video interviews. Over 12 million interviewees have been screened by the over 700 companies that utilize the service.&lt;ref name=":122" /&gt;

== Controversies ==
Artificial intelligence in hiring confers many benefits, but it also has some challenges which have concerned experts.&lt;ref name=":112"&gt;{{Citation|last1=Costigan|first1=Ruth|title=9. Freedom to Protest and Public Order Law|date=2017-06-29|url=http://dx.doi.org/10.1093/he/9780198744276.003.0009|work=Civil Liberties &amp; Human Rights|publisher=Oxford University Press|isbn=978-0-19-874427-6|access-date=2020-10-31|last2=Stone|first2=Richard|doi=10.1093/he/9780198744276.003.0009}}&lt;/ref&gt; AI is only as good as the data it is using. Biases can inadvertently be baked into the data used in AI.&lt;ref name=":32" /&gt; Often companies will use data from their employees to decide what people to recruit or hire. This can perpetuate bias and lead to more homogenous workforces. Facebook Ads was an example of a platform that created such controversy for allowing business owners to specify what type of employee they are looking for. For example, job advertisements for nursing and teach could be set such that only women of a specific age group would see the advertisements. Facebook Ads has since then removed this function from its platform, citing the potential problems with the function in perpetuating biases and stereotypes against minorities.

It can also be hard to quantify what makes a good employee.&lt;ref name=":32" /&gt; This poses a challenge for training AI to predict which employees will be best. Commonly used metrics like performance reviews can be subjective and have been shown to favor white employees over Black employees and men over women.&lt;ref name=":42" /&gt;  Another challenge is the limited amount of available data. Employers only collect certain details about candidates during the initial stages of the hiring process. This requires AI to make determinations about candidates with very limited information to go off of. Additionally, many employers do not hire employees frequently and so have limited firm specific data to go off.&lt;ref name=":32" /&gt; To combat this, many firms will use algorithms and data from other firms in their industry.&lt;ref name=":32" /&gt; AI's reliance on applicant and current employees personal data raises privacy issues. These issues effect both the applicants and current employees, but also may have implications for third parties who are linked through social media to applicants or current employees. For example, a sweep of someone's social media will also show their friends and people they have tagged in photos or posts.&lt;ref name=":32" /&gt;

AI makes it easier for companies to search applicants social media accounts. A study conducted by Monash University found that 45% of hiring managers use social media to gain insight on applicants. Seventy percent of those surveyed said they had rejected an applicant because of things discovered on their applicant's social media, yet only 17% of hiring managers saw using social media in the hiring process as a violation of applicants privacy. Using social media in the hiring process is appealing to hiring managers because it offers them a less curated view of applicants lives. The privacy trade-off is significant. Social media profiles often reveal information about applicants that human resource departments are legally not allowed to require applicants to divulge like race, ability status, and sexual orientation.&lt;ref&gt;{{Citation|last1=Holland|first1=Peter|title=Changing Role of Social Media at Work: Implications for Recruitment and Selection|date=2017-08-09|url=http://dx.doi.org/10.1108/978-1-78714-315-920161011|work=Electronic HRM in the Smart Era|pages=287–309|publisher=Emerald Publishing Limited|isbn=978-1-78714-316-6|access-date=2020-11-07|last2=Jeske|first2=Debora|doi=10.1108/978-1-78714-315-920161011}}&lt;/ref&gt;

== AI and the future of hiring ==
AI is changing the way work is done. Artificial intelligence along with other technological advances such as improvements in robotics have placed 47% of jobs at risk of being eliminated in the near future.&lt;ref&gt;{{Cite journal|last1=Brougham|first1=David|last2=Haar|first2=Jarrod|date=March 2018|title=Smart Technology, Artificial Intelligence, Robotics, and Algorithms (STARA): Employees' perceptions of our future workplace|url=https://www.cambridge.org/core/product/identifier/S1833367216000559/type/journal_article|journal=Journal of Management &amp; Organization|language=en|volume=24|issue=2|pages=239–257|doi=10.1017/jmo.2016.55|issn=1833-3672|doi-access=free}}&lt;/ref&gt; Some classify the shifts in labor brought about by AI as a 4th industrial revolution, which they call Industrial Revolution 4.0.&lt;ref name=":72" /&gt; According to some scholars, however, the transformative impact of AI on labor has been overstated. The "no-real-change" theory holds that an IT revolution has already occurred, but that the benefits of implementing new technologies does not outweigh the costs associated with adopting them. This theory claims that the result of the IT revolution is thus much less impactful than had originally been forecasted.&lt;ref name=":132"&gt;{{Cite journal|last1=Boyd|first1=Ross|last2=Holton|first2=Robert J.|date=2017-08-29|title=Technology, innovation, employment and power: Does robotics and artificial intelligence really mean social transformation?|url=http://dx.doi.org/10.1177/1440783317726591|journal=Journal of Sociology|volume=54|issue=3|pages=331–345|doi=10.1177/1440783317726591|s2cid=149228281|issn=1440-7833}}&lt;/ref&gt; Other scholars refute this theory claiming that AI has already led to significant job loss for unskilled labor and that it will eliminate middle skill and high skill jobs in the future. This position is based around the idea that AI is not yet a technology of general use and that any potential 4th industrial revolution has not fully occurred.&lt;ref name=":132" /&gt; A third theory holds that the affect of AI and other technological advances is too complicated to yet be understood. This theory is centered around the idea that while AI will likely eliminate jobs in the short term it will also likely increase the demand for other jobs. The question then becomes will the new jobs be accessible to people and will they emerge near when jobs are eliminated.&lt;ref name=":132" /&gt;

Artificial intelligence has sped up the hiring process considerably, dramatically reducing costs. For example, Unilever has reviewed over 250,000 applications using AI and reduced its hiring process from 4 months to 4 weeks. This saved the company 50,000 hours of labor.&lt;ref name=":122" /&gt; The increased efficiency AI promises has sped up its adoption by human resource departments globally.&lt;ref name=":122" /&gt;

==References==
{{reflist}}

[[Category:Artificial intelligence]]
[[Category:Artificial intelligence applications]]
[[Category:Machine learning]]
[[Category:Automation]]
[[Category:Recruitment]]</text>
      <sha1>r19qbtdzuz5qojrc4niiv0iivjhdplt</sha1>
    </revision>
  </page>
  <page>
    <title>Struc2vec</title>
    <ns>0</ns>
    <id>65398093</id>
    <revision>
      <id>1002050241</id>
      <parentid>1001159977</parentid>
      <timestamp>2021-01-22T16:21:40Z</timestamp>
      <contributor>
        <username>Orenburg1</username>
        <id>10248457</id>
      </contributor>
      <minor/>
      <comment>sp</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="3461" xml:space="preserve">'''struc2vec''' is a framework to generate node vector representations on a [[Graph theory|graph]] that preserve the [[Similarity (network_science)#Structural equivalence|structural identity]].&lt;ref&gt;{{cite journal|last1=Hamilton|first1=Willian L.|last2=Ying|first2=Rex|last3=Leskovec|first3=Jure|title=Representation learning on graphs: Methods and applications|journal=IEEE Data Engineering Bulletin|year=2017|pages=1|arxiv=1709.05584}}&lt;/ref&gt; In contrast to ''[[node2vec]]'', that optimizes node embeddings so that nearby nodes in the graph have similar embedding, ''struc2vec'' captures the '''roles''' of nodes in a graph, even if structurally similar nodes are far apart in the graph. It learns low-dimensional representations for nodes in a graph, generating [[random walk]]s through a constructed [[Multidimensional network|multi-layer graph]] starting at each graph node. It is useful for [[machine learning]] applications where the downstream application is more related with the [[Similarity (network_science)#Structural equivalence|structural equivalence]] of the nodes (e.g., it can be used to detect nodes in networks with similar functions, such as interns in the social network of a corporation). ''struc2vec'' identifies nodes that play a similar role based solely on the structure of the graph, for example computing the structural identity of individuals in [[Social network|social networks]].&lt;ref&gt;{{Cite web|url=https://cse.msu.edu/~mayao4/dlg_book/chapters/chapter4.pdf|title=Deep Learning on Graphs, Chapter 4 Graph Embedding }}&lt;/ref&gt; In particular, ''struc2vec'' employs a degree-based method to measure the pairwise structural role similarity, which is then adopted to build the multi-layer graph. Moreover, the distance between the latent representation of nodes is strongly correlated to their structural similarity. The framework contains three optimizations: reducing the length of degree sequences considered, reducing the number of pairwise similarity calculations, and reducing the number of layers in the generated graph.

''struc2vec'' follows the intuition that [[Random walk|random walks]] through a graph can be treated as sentences in a corpus. Each node in a graph is treated as an individual word, and short random walk is treated as a sentence. In its final phase, the algorithm employs [[Gensim]]'s ''[[word2vec]]'' algorithm to learn embeddings based on biased random walks.&lt;ref&gt;{{Cite web|url=https://blog.acolyer.org/2017/09/15/struc2vec-learning-node-representations-from-structural-identity/|title=Struc2vec: learning node representations from structural identity|last=Colyer|first=Adrian|date=2017|website=The Morning Paper}}&lt;/ref&gt; Sequences of nodes are fed into a [[Word2vec|skip-gram]] or [[Word2vec|continuous bag of words]] model and traditional machine-learning techniques for classification can be used.&lt;ref&gt;{{cite journal|last1=Ribeiro|first1=Leonardo F. R.|last2=Savarese|first2=Pedro H. P.|last3=Figueiredo|first3=Daniel R.|date=2017|title=struc2vec: Learning Node Representations from Structural Identity|journal=KDD : Proceedings. International Conference on Knowledge Discovery &amp; Data Mining|volume=2017|pages=385–394|doi=10.1145/3097983.3098061|arxiv=1704.03165|s2cid=3948366}}&lt;/ref&gt; It is considered a useful framework to learn node embeddings based on structural equivalence.

==See also==
* [[Node2vec]]

==References==
{{Reflist}}

[[Category:Unsupervised learning]]

[[Category:Machine learning]]</text>
      <sha1>go44xwjh5bgz7be2apey3indpw0awfe</sha1>
    </revision>
  </page>
  <page>
    <title>Equalized odds</title>
    <ns>0</ns>
    <id>66205491</id>
    <revision>
      <id>996686691</id>
      <parentid>996686591</parentid>
      <timestamp>2020-12-28T02:26:56Z</timestamp>
      <contributor>
        <username>Rockyunited</username>
        <id>40770307</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="2145" xml:space="preserve">'''Equalized odds''',&lt;ref&gt;{{cite journal |last1=Hardt |first1=Moritz |title=Equality of Opportunity in Supervised Learning |journal=Neural Information Processing Systems |date=10/7/2016 |url=https://papers.nips.cc/paper/2016/hash/9d2682367c3935defcb1f9e247a97c0d-Abstract.html}}&lt;/ref&gt; also referred to as '''conditional procedure accuracy equality''' and '''disparate mistreatment''', is a measure of [[Fairness (machine learning)|fairness in machine learning]]. A classifier satisfies this definition if the subjects in the protected and unprotected groups have equal true positive rate and equal false positive rate,&lt;ref&gt;{{cite web |title=Fairness in ML 2: Equal opportunity and odds |url=https://www2.cs.duke.edu/courses/fall18/compsci590.1/lectures/FairML2.pdf |website=https://www2.cs.duke.edu/ |publisher=Duke Computer Science}}&lt;/ref&gt; satisfying the formula:

&lt;math display="block"&gt; P(R = + | Y = y, A = a) = P(R = + | Y = y, A = b) \quad y \in \{+,-\} \quad \forall a,b \in A &lt;/math&gt;

For example, &lt;math&gt;A&lt;/math&gt; could be gender, race, and other characteristics that we want to be free of bias, while &lt;math&gt;Y&lt;/math&gt; would be whether the person is qualified for the degree, and the output &lt;math&gt;R&lt;/math&gt; would be the school's decision whether to offer the person to study for the degree. In this context, higher university enrollment rates of African Americans compared to whites with similar test scores may also fulfill the condition of '''Equalized odds'''.

Originally, the concept is defined for binary class. In 2017, Blake Woodworth generalized the concept further for multiple classes.&lt;ref&gt;{{cite journal |last1=Woodworth |first1=Blake |title=Learning Non-Discriminatory Predictors Blake |journal=Proceedings of Machine Learning Research |date=2017 |volume=65 |page=1-34 |url=https://arxiv.org/abs/1702.06081}}&lt;/ref&gt;

==See also==
*[[Fairness (machine learning)]]
*[[Color blindness (racial classification)]]

==References==
{{reflist}}

[[Category:Machine learning]]
[[Category:Information ethics]]
[[Category:Computing and society]]
[[Category:Philosophy of artificial intelligence]]
[[Category:Discrimination]]
[[Category:Bias]]</text>
      <sha1>llgh3zcp3hv9pvodbspx2m5dliblglq</sha1>
    </revision>
  </page>
  <page>
    <title>Dimitris Drikakis</title>
    <ns>0</ns>
    <id>42718329</id>
    <revision>
      <id>1001878747</id>
      <parentid>1001877551</parentid>
      <timestamp>2021-01-21T20:30:14Z</timestamp>
      <contributor>
        <username>Chris the speller</username>
        <id>525927</id>
      </contributor>
      <minor/>
      <comment>cap, italics</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="24437" xml:space="preserve">{{Short description|Greek-British applied scientist, engineer and university professor}}
{{Infobox scientist
| honorific_prefix  = &lt;!-- see [[MOS:CREDENTIAL]] and [[MOS:HONORIFIC]] --&gt;
| name              = Dimitris Drikakis
| honorific_suffix  = 
| image             = Prof. Dimitris Drikakis2.jpg
| image_size        = 
| alt               = 
| caption           = 
| native_name       = 
| native_name_lang  = 
| birth_name        = Dimitris Drikakis
| birth_date        = {{birth year and age|1965}}
| birth_place       = [[Athens]], Greece
| death_date        = &lt;!-- {{death date and age|df=yes|YYYY|MM|DD|YYYY|MM|DD}} (death date then birth date) --&gt;
| death_place       = 
| death_cause       = 
| citizenship       = 
| other_names       = 
| field             = 
| known_for         = 
| home_town         = 
| title             = 
| boards            = 
| spouse            = 
| partner           = 
| children          = 
| parents           = 
| relatives         = 
| awards            = 
| education         = 
| alma_mater        = {{ubl|[[National Technical University of Athens]]}}
| thesis_title      = 
| thesis_url        = 
| thesis_year       = 
| doctoral_advisor  = 
| academic_advisors = 
| influences        = 
| workplaces        = [[Friedrich-Alexander-Universität Erlangen-Nürnberg]] (Germany)&lt;br /&gt;[[University of Manchester]] (UK)&lt;br /&gt;[[Queen Mary, University of London]] (UK)&lt;br /&gt;[[Cranfield University]] (UK)&lt;br /&gt;[[University of Strathclyde]] (UK, Scotland)&lt;br /&gt;[[University of Nicosia]] (Cyprus)
| doctoral_students = 
| notable_students  = 
| main_interests    = 
| notable_works     = 
| notable_ideas     = 
| influenced        = 
| signature         = 
| signature_alt     = 
| signature_size    = 
| website           = https://www.unic.ac.cy/drikakis-dimitris/
}}

'''Dimitris Drikakis''', [[PhD]], [[FRAeS]], [[CEng]], is a Greek-British applied scientist, engineer and university professor. His research is multidisciplinary. It covers [[fluid dynamics]], [[computational fluid dynamics]], [[acoustics]], [[heat transfer]], computational science from molecular to macro scale, [[materials]], [[machine learning]], and [[emerging technologies]]. He has applied his research to diverse fields such as [[Aerospace]] &amp; [[Defense industry|Defence]], [[Biomedical]], and [[Energy and Environment]] Sectors. He received The William Penney Fellowship Award by the [[Atomic Weapons Establishment]]  (AWE Plc) to recognise his contributions to compressible fluid dynamics. He was also the winner of NEF's Innovator of the Year Award&lt;ref&gt;{{Cite web|title=Innovation Awards 2014{{!}}STEM Foundation|url=https://stemfoundation.org.uk/news/2014/december/innovation_awards_2014|access-date=2021-01-05|website=stemfoundation.org.uk}}&lt;/ref&gt; by the UK's Institute of Innovation and Knowledge Exchange for a new generation carbon capture [[nanotechnology]] that uses [[carbon nanotubes]] for filtering out carbon dioxide and other gases.

== Education ==
He obtained his mechanical engineering degree (1982–1987) from the [[National Technical University of Athens]] in Greece. His diploma dissertation was in biofluid mechanics and concerned pulsating blood flow in an anisotropic elastic tube.

He carried out his PhD (1988–1991) at the National Technical University of Athens (NTUA) in the Laboratory of Aerodynamics, Fluids Section. His PhD concerned the development of computational fluid dynamics methods for high-speed compressible flows and co-supervised by the Flight Physics Division of Messerschmitt-Bölkow-Blohm (MBB), a German aerospace manufacturer formed later on the [https://www.airbus.com/ Airbus Group].

== Career ==
In 1992, he joined as research scientist and later on as a team leader at the Institute of Fluid Mechanics (Lehrstuhl für Strömungsmechanik – LSTM) of the [[University of Erlangen–Nuremberg]] (Friedrich-Alexander-Universität Erlangen-Nürnberg) under the direction of Professor Franz Durst. He researched in fluid dynamics and high-performance parallel computing at the early stages of developing parallel computers during that period.

In 1995, he joined as a lecturer the [[University of Manchester]] Institute of Science and Technology (UMIST), merged later with the University of Manchester. He worked in the Fluid Mechanics Division under Professor [[Brian Launder]] and Professor Michael Leschziner.&lt;ref&gt;{{Cite web|title=Michael A. Leschziner|url=https://scholar.google.com/citations?user=hLSK5tcAAAAJ&amp;hl=en|access-date=2021-01-05|website=scholar.google.com}}&lt;/ref&gt;

In 1999, he was offered a readership (associate professor position) at Queen Mary, [[University of London]] and became a full professor (professor of fluid dynamics) at the same university in 2001. He was 36 years of age.

In 2003 he joined [[Cranfield University]]  as a professor and head of the Fluid Mechanics and Computational Science Centre. He was appointed head of the Aerospace Science Departments (2005–2010). In 2012, he established the department of engineering physics in the same university, which later evolved to the Institute of Aerospace Sciences. He left Cranfield in 2015. During his tenure at Cranfield University, he held various management and leadership posts, including the director of research in the School of Aerospace, Transport &amp; Manufacturing.

In 2011, he was the founding director of the regional high-performance scientific computing centre at [[The Cyprus Institute]] in close partnership with the [[University of Illinois]] at Urbana-Champaign, US.

In July 2015, he was appointed as the executive dean of the Faculty of Engineering and Professor of Engineering Science at the [[University of Strathclyde]], Glasgow, one of the UK's largest engineering schools. He worked with principal and vice-chancellor, Professor Sir [[Jim McDonald (electrical engineer)]]. From 2015 to 2018, he held various executive posts as associate principal and executive director of Global Partnerships.

He left the University of Strathclyde in October 2018 to join the [[University of Nicosia]] in Cyprus as the vice president of global partnerships,&lt;ref&gt;{{Cite web|title=Professor Dimitris Drikakis|url=https://www.unic.ac.cy/drikakis-dimitris/|access-date=2021-01-05|website=University of Nicosia|language=en-US}}&lt;/ref&gt; executive director of research and innovation, with a full professor (cross-appointment) in the medical school&lt;ref&gt;{{Cite web|title=Our Faculty|url=https://www.med.unic.ac.cy/about-us/faculty-and-staff/faculty/|access-date=2021-01-05|website=Medical School - University of Nicosia|language=en-US}}&lt;/ref&gt; and the School of Sciences and Engineering.&lt;ref&gt;{{Cite web|last=unic_editorial|title=School of Sciences and Engineering - Faculty by School|url=https://www.unic.ac.cy/faculty-staff/school-of-sciences-and-engineering-faculty-by-school/|access-date=2021-01-05|website=University of Nicosia|language=en-US}}&lt;/ref&gt; The University of Nicosia is a private, English-speaking university, the largest in Cyprus. In 2019, he founded the Defence and Security Research Institute, a multidisciplinary institute dedicated to science and technology and collaboration with governments, industry and academic worldwide.

== Research ==
His research covers several topics, including:

* '''Advanced computational fluid dynamics methods:''' High-resolution and high-order methods.&lt;ref&gt;{{Cite book|last=Drikakis|first=D.|url=https://www.springer.com/gp/book/9783540221364|title=High-Resolution Methods for Incompressible and Low-Speed Flows|last2=Rider|first2=W.|date=2005|publisher=Springer-Verlag|isbn=978-3-540-22136-4|series=Computational Fluid and Solid Mechanics|location=Berlin Heidelberg|language=en}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Drikakis|first=D.|last2=Hahn|first2=M.|last3=Mosedale|first3=A.|last4=Thornber|first4=B.|date=2009-07-28|title=Large eddy simulation using high-resolution and high-order methods|url=https://royalsocietypublishing.org/doi/10.1098/rsta.2008.0312|journal=Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences|volume=367|issue=1899|pages=2985–2997|doi=10.1098/rsta.2008.0312}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Thornber|first=B.|last2=Mosedale|first2=A.|last3=Drikakis|first3=D.|last4=Youngs|first4=D.|last5=Williams|first5=R. J. R.|date=2008-05-01|title=An improved reconstruction method for compressible flows with low Mach number features|url=http://www.sciencedirect.com/science/article/pii/S0021999108000429|journal=Journal of Computational Physics|language=en|volume=227|issue=10|pages=4873–4894|doi=10.1016/j.jcp.2008.01.036|issn=0021-9991}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Thornber|first=B.|last2=Drikakis|first2=D.|last3=Williams|first3=R. J. R.|last4=Youngs|first4=D.|date=2008-05-01|title=On entropy generation and dissipation of kinetic energy in high-resolution shock-capturing schemes|url=http://www.sciencedirect.com/science/article/pii/S0021999108000405|journal=Journal of Computational Physics|language=en|volume=227|issue=10|pages=4853–4872|doi=10.1016/j.jcp.2008.01.035|issn=0021-9991}}&lt;/ref&gt;

* '''Transition and turbulence:''' in the Large Eddy Simulation frame, mainly implicit Large Eddy Simulation, and Direct Numerical Simulation.&lt;ref&gt;{{Cite journal|last=Drikakis|first=Dimitris|last2=Fureby|first2=Christer|last3=Grinstein|first3=Fernando F.|last4=Youngs|first4=David|date=2007-01-01|title=Simulation of transition and turbulence decay in the Taylor–Green vortex|url=https://doi.org/10.1080/14685240701250289|journal=Journal of Turbulence|volume=8|pages=N20|doi=10.1080/14685240701250289}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Thornber|first=Ben|last2=Mosedale|first2=Andrew|last3=Drikakis|first3=Dimitris|date=2007-10-01|title=On the implicit large eddy simulations of homogeneous decaying turbulence|url=http://www.sciencedirect.com/science/article/pii/S0021999107002690|journal=Journal of Computational Physics|language=en|volume=226|issue=2|pages=1902–1929|doi=10.1016/j.jcp.2007.06.030|issn=0021-9991}}&lt;/ref&gt;

* '''High-speed flows:''' featuring shock waves, turbulence, and instabilities.&lt;ref&gt;{{Cite journal|last=Thornber|first=B.|last2=Drikakis|first2=D.|last3=Youngs|first3=D. L.|last4=Williams|first4=R. J. R.|date=2010-07-10|title=The influence of initial conditions on turbulent mixing due to Richtmyer–Meshkov instability†|url=https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/abs/influence-of-initial-conditions-on-turbulent-mixing-due-to-richtmyermeshkov-instability/8962D31619E4D6EE06F2DEA2B4FE202E|journal=Journal of Fluid Mechanics|language=en|volume=654|pages=99–139|doi=10.1017/S0022112010000492|issn=1469-7645}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Panaras|first=Argyris G.|last2=Drikakis|first2=Dimitris|date=2009-08-10|title=High-speed unsteady flows around spiked-blunt bodies|url=https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/abs/highspeed-unsteady-flows-around-spikedblunt-bodies/5B8B2D17D4B4E0467AA14CAD74B7F3CF|journal=Journal of Fluid Mechanics|language=en|volume=632|pages=69–96|doi=10.1017/S0022112009006235|issn=1469-7645}}&lt;/ref&gt;

* '''Multiphase flows:''' He has developed and applied multiphase fluid dynamics methods to study diverse problems such as compressible fluid/solid interactions,&lt;ref&gt;{{Cite journal|last=Barton|first=P. T.|last2=Obadia|first2=B.|last3=Drikakis|first3=D.|date=2011-09-01|title=A conservative level-set based method for compressible solid/fluid problems on fixed grids|url=http://www.sciencedirect.com/science/article/pii/S002199911100413X|journal=Journal of Computational Physics|language=en|volume=230|issue=21|pages=7867–7890|doi=10.1016/j.jcp.2011.07.008|issn=0021-9991}}&lt;/ref&gt; two-phase flows,&lt;ref&gt;{{Cite journal|last=Romenski|first=Evgeniy|last2=Drikakis|first2=Dimitris|last3=Toro|first3=Eleuterio|date=2009-07-25|title=Conservative Models and Numerical Methods for Compressible Two-Phase Flow|url=https://doi.org/10.1007/s10915-009-9316-y|journal=Journal of Scientific Computing|language=en|volume=42|issue=1|pages=68|doi=10.1007/s10915-009-9316-y|issn=1573-7691}}&lt;/ref&gt; oil and gas flows,&lt;ref&gt;{{Cite journal|last=Frank|first=Michael|last2=Kamenicky|first2=Robin|last3=Drikakis|first3=Dimitris|last4=Thomas|first4=Lee|last5=Ledin|first5=Hans|last6=Wood|first6=Terry|date=2019-06-03|title=Multiphase Flow Effects in a Horizontal Oil and Gas Separator|url=https://www.mdpi.com/1996-1073/12/11/2116|journal=Energies|language=en|volume=12|issue=11|pages=2116|doi=10.3390/en12112116|doi-access=free}}&lt;/ref&gt; Coronavirus transmission and weather effects.&lt;ref&gt;{{Cite journal|last=Dbouk|first=Talib|last2=Drikakis|first2=Dimitris|date=2020-09-01|title=Weather impact on airborne coronavirus survival|url=https://aip.scitation.org/doi/10.1063/5.0024272|journal=Physics of Fluids|volume=32|issue=9|pages=093312|doi=10.1063/5.0024272|issn=1070-6631|pmc=7513827|pmid=32982135}}&lt;/ref&gt;
* '''Acoustics:''' acoustic fatigue and noise propagation.&lt;ref&gt;{{Cite journal|last=Kokkinakis|first=Ioannis W.|last2=Drikakis|first2=Dimitris|last3=Ritos|first3=Konstantinos|last4=Spottswood|first4=S. Michael|date=2020-06-01|title=Direct numerical simulation of supersonic flow and acoustics over a compression ramp|url=https://aip.scitation.org/doi/10.1063/5.0010548|journal=Physics of Fluids|volume=32|issue=6|pages=066107|doi=10.1063/5.0010548|issn=1070-6631}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Ritos|first=Konstantinos|last2=Drikakis|first2=Dimitris|last3=Kokkinakis|first3=Ioannis W.|last4=Spottswood|first4=S. Michael|date=2020-05-15|title=Computational aeroacoustics beneath high speed transitional and turbulent boundary layers|url=http://www.sciencedirect.com/science/article/pii/S0045793020300931|journal=Computers &amp; Fluids|language=en|volume=203|pages=104520|doi=10.1016/j.compfluid.2020.104520|issn=0045-7930}}&lt;/ref&gt; &lt;ref&gt;{{Cite journal|date=2019-02-17|title=Acoustic loading beneath hypersonic transitional and turbulent boundary layers|url=https://www.sciencedirect.com/science/article/pii/S0022460X18306941|journal=Journal of Sound and Vibration|language=en|volume=441|pages=50–62|doi=10.1016/j.jsv.2018.10.021|issn=0022-460X|doi-access=free}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Ritos|first=Konstantinos|last2=Kokkinakis|first2=Ioannis W.|last3=Drikakis|first3=Dimitris|last4=Spottswood|first4=S. Michael|date=2017-04-01|title=Implicit large eddy simulation of acoustic loading in supersonic turbulent boundary layers|url=https://aip.scitation.org/doi/10.1063/1.4979965|journal=Physics of Fluids|volume=29|issue=4|pages=046101|doi=10.1063/1.4979965|issn=1070-6631}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Ritos|first=K.|last2=Drikakis|first2=D.|last3=Kokkinakis|first3=I. W.|date=2019-03-17|title=Wall-pressure spectra models for supersonic and hypersonic turbulent boundary layers|url=http://www.sciencedirect.com/science/article/pii/S0022460X18307478|journal=Journal of Sound and Vibration|language=en|volume=443|pages=90–108|doi=10.1016/j.jsv.2018.11.001|issn=0022-460X}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Loiodice|first=S.|last2=Drikakis|first2=D.|last3=Kokkalis|first3=A.|date=2018-09-01|title=Emission surfaces and noise prediction from rotating sources|url=http://www.sciencedirect.com/science/article/pii/S0022460X18303079|journal=Journal of Sound and Vibration|language=en|volume=429|pages=245–264|doi=10.1016/j.jsv.2018.05.023|issn=0022-460X}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Loiodice|first=S.|last2=Drikakis|first2=D.|last3=Kokkalis|first3=A.|date=2018-01-06|title=An efficient algorithm for the retarded time equation for noise from rotating sources|url=http://www.sciencedirect.com/science/article/pii/S0022460X17306934|journal=Journal of Sound and Vibration|language=en|volume=412|pages=336–348|doi=10.1016/j.jsv.2017.09.030|issn=0022-460X}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Quaranta|first=Erika|last2=Drikakis|first2=Dimitris|date=2009-12-25|title=Noise radiation from a ducted rotor in a swirling-translating flow|url=https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/abs/noise-radiation-from-a-ducted-rotor-in-a-swirlingtranslating-flow/2010945E29D0DD3212E100157E9EB9F1|journal=Journal of Fluid Mechanics|language=en|volume=641|pages=463–473|doi=10.1017/S0022112009991972|issn=1469-7645}}&lt;/ref&gt;

* '''Bio-Medical:''' In 2020 and 2021, he published jointly with Dr Talib Dbouk a series of multiphase fluid dynamics papers investigating the contaminated saliva droplet spread, face masks, and the impact of weather on COVID-19.  
**1. The article by Dbouk, D. Drikakis, On coughing and airborne droplet transmission to humans Phys. Fluids 32, 053310 (2020) received to date one of the highest Altmetric Score of all American Institute of Physics publications.&lt;ref&gt;{{Cite web|title=Altmetric – On coughing and airborne droplet transmission to humans|url=https://aip.altmetric.com/details/82333718#score|access-date=2021-01-05|website=aip.altmetric.com}}&lt;/ref&gt;  
**2. The trilogy of articles&lt;ref&gt;{{Cite journal|last=Dbouk|first=Talib|last2=Drikakis|first2=Dimitris|date=2020-05-01|title=On coughing and airborne droplet transmission to humans|url=https://aip.scitation.org/doi/10.1063/5.0011960|journal=Physics of Fluids|volume=32|issue=5|pages=053310|doi=10.1063/5.0011960|issn=1070-6631|pmc=7239332|pmid=32574229}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Dbouk|first=Talib|last2=Drikakis|first2=Dimitris|date=2020-06-01|title=On respiratory droplets and face masks|url=https://aip.scitation.org/doi/10.1063/5.0015044|journal=Physics of Fluids|volume=32|issue=6|pages=063303|doi=10.1063/5.0015044|issn=1070-6631|pmc=7301882|pmid=32574231}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Dbouk|first=Talib|last2=Drikakis|first2=Dimitris|date=2020-09-01|title=Weather impact on airborne coronavirus survival|url=https://aip.scitation.org/doi/10.1063/5.0024272|journal=Physics of Fluids|volume=32|issue=9|pages=093312|doi=10.1063/5.0024272|issn=1070-6631|pmc=7513827|pmid=32982135}}&lt;/ref&gt; received public recognition through multiple news outlets coverage worldwide.
* '''Heat transfer and thermal management:''' He has developed heat transfer models for a broad range of scales and applications, including micro and nanofluidic devices &lt;ref&gt;{{Cite journal|last=Frank|first=Michael|last2=Drikakis|first2=Dimitris|date=2017-08-24|title=Solid-like heat transfer in confined liquids|url=https://doi.org/10.1007/s10404-017-1980-x|journal=Microfluidics and Nanofluidics|language=en|volume=21|issue=9|pages=148|doi=10.1007/s10404-017-1980-x|issn=1613-4990|pmc=6560482|pmid=31258457}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Frank|first=Michael|last2=Papanikolaou|first2=Michail|last3=Drikakis|first3=Dimitris|last4=Salonitis|first4=Konstantinos|date=2019-10-02|title=Heat transfer across a fractal surface|url=https://aip.scitation.org/doi/10.1063/1.5115585|journal=The Journal of Chemical Physics|volume=151|issue=13|pages=134705|doi=10.1063/1.5115585|issn=0021-9606}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Milnes|first=Joseph|last2=Drikakis|first2=Dimitris|date=2009-06-01|title=Qualitative assessment of RANS models for Hypervapotron flow and heat transfer|url=http://www.sciencedirect.com/science/article/pii/S0920379608004572|journal=Fusion Engineering and Design|series=Proceeding of the 25th Symposium on Fusion Technology|language=en|volume=84|issue=7|pages=1305–1312|doi=10.1016/j.fusengdes.2008.12.004|issn=0920-3796}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Milnes|first=Joseph|last2=Burns|first2=Alan|last3=Drikakis|first3=Dimitris|date=2012-09-01|title=Computational modelling of the HyperVapotron cooling technique|url=http://www.sciencedirect.com/science/article/pii/S0920379612003171|journal=Fusion Engineering and Design|language=en|volume=87|issue=9|pages=1647–1661|doi=10.1016/j.fusengdes.2012.06.014|issn=0920-3796}}&lt;/ref&gt;and fundamental science to understanding solid-fluid interfaces.&lt;ref&gt;{{Cite journal|last=Frank|first=Michael|last2=Drikakis|first2=Dimitris|date=2018-05-12|title=Thermodynamics at Solid–Liquid Interfaces|url=https://www.mdpi.com/1099-4300/20/5/362|journal=Entropy|language=en|volume=20|issue=5|pages=362|doi=10.3390/e20050362|pmc=7512882|pmid=33265452}}&lt;/ref&gt;
* '''Multiscale continuum and molecular modelling:''' He has developed coupling methods comprising molecular and continuum mechanics.&lt;ref&gt;{{Cite journal|last=Asproulis|first=Nikolaos|last2=Kalweit|first2=Marco|last3=Drikakis|first3=Dimitris|date=2012-04-01|title=A hybrid molecular continuum method using point wise coupling|url=http://www.sciencedirect.com/science/article/pii/S0965997810001304|journal=Advances in Engineering Software|series=CIVIL-COMP|language=en|volume=46|issue=1|pages=85–92|doi=10.1016/j.advengsoft.2010.10.010|issn=0965-9978}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Barton|first=P. T.|last2=Kalweit|first2=M.|last3=Drikakis|first3=D.|last4=Ball|first4=G.|date=2011-11-01|title=Multi-scale analysis of high-speed dynamic friction|url=https://aip.scitation.org/doi/10.1063/1.3660194|journal=Journal of Applied Physics|volume=110|issue=9|pages=093520|doi=10.1063/1.3660194|issn=0021-8979}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Kalweit|first=M.|last2=Drikakis|first2=D.|date=2008-05-27|title=Coupling strategies for hybrid molecular—continuum simulation methods:|url=https://journals.sagepub.com/doi/10.1243/09544062JMES716|journal=Proceedings of the Institution of Mechanical Engineers, Part C: Journal of Mechanical Engineering Science|language=en|doi=10.1243/09544062JMES716}}&lt;/ref&gt; He implemented these methods in microfluidic devices, amongst other applications.
*'''Machine learning and AI:''' The development of methods and models for engineering and medical applications.&lt;ref&gt;{{Cite journal|last=Asproulis|first=Nikolaos|last2=Drikakis|first2=Dimitris|date=2013-10-01|title=An artificial neural network-based multiscale method for hybrid atomistic-continuum simulations|url=https://doi.org/10.1007/s10404-013-1154-4|journal=Microfluidics and Nanofluidics|language=en|volume=15|issue=4|pages=559–574|doi=10.1007/s10404-013-1154-4|issn=1613-4990}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Frank|first=Michael|last2=Drikakis|first2=Dimitris|last3=Charissis|first3=Vassilis|date=2020-03-03|title=Machine-Learning Methods for Computational Science and Engineering|url=https://www.mdpi.com/2079-3197/8/1/15|journal=Computation|language=en|volume=8|issue=1|pages=15|doi=10.3390/computation8010015|doi-access=free}}&lt;/ref&gt;
* '''Nanotechnology and gas filtration:''' He developed a new generation carbon capture technology that uses carbon nanotubes for filtering out carbon dioxide and other gases at low or zero energy cost. This platform technology can be used across a wide range of applications in the power generation, automotive, aerospace, chemical, marine and built environment sectors. He has three patents in the UK Patent 2479257-A, US Patent 20130042762 and China Patent CN102892479.

== Other activities ==
He has been an associate editor in ''Computers and Fluids'',&lt;ref&gt;{{Cite book|url=https://www.journals.elsevier.com/computers-and-fluids/editorial-board|title=Computers &amp;amp; Fluids Editorial Board}}&lt;/ref&gt; ''Physics of Fluids'' (advisory board),&lt;ref&gt;{{Cite web|title=Physics of Fluids|url=https://aip.scitation.org/phf/info/advisory|access-date=2021-01-05|website=aip.scitation.org}}&lt;/ref&gt; [http://www.aspbs.com/ctn/ ''Journal of Computational and Theoretical Nanoscience''], [https://www.cambridge.org/core/journals/aeronautical-journal/information/editorial-board ''The Aeronautical Journal''], ''Journal of Fluids Engineering''. He is also on the editorial board of several journals in applied mathematics, engineering, biomedicine, energy, and nanotechnology.

He was on the Fluid Dynamics Technical Committee of the American Institute of Aeronautics and Astronautics (AIAA); on the board of directors of the European Aeronautics Science Network (EASN); Experts Panel and deputy chair of the European Research Council (Engineering), amongst other international committees.

==External link==
https://scholar.google.com/citations?user=JAQLmxcAAAAJ&amp;hl=en&amp;oi=ao

==References==
{{Reflist}}

{{Authority control}}

{{DEFAULTSORT:Drikakis, Dmitris}}
[[Category:University of Nicosia]]
[[Category:Living people]]
[[Category:Year of birth missing (living people)]]
[[Category:Place of birth missing (living people)]]
[[Category:Fluid dynamicists]]
[[Category:acoustics]]
[[Category:heat transfer]]
[[Category:molecules]]
[[Category:materials]]
[[Category:machine learning]]
[[Category:emerging technologies]]
[[Category:nanotechnology]]
[[Category:carbon nanotubes]]</text>
      <sha1>prj0hkok9p4j0jmitmpre4w8qjycgqb</sha1>
    </revision>
  </page>
  <page>
    <title>Neural network quantum states</title>
    <ns>0</ns>
    <id>66307448</id>
    <revision>
      <id>1002861163</id>
      <parentid>1000814555</parentid>
      <timestamp>2021-01-26T10:46:30Z</timestamp>
      <contributor>
        <username>Erostrato</username>
        <id>14808949</id>
      </contributor>
      <comment>Removed refimprove since more references were added</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="5179" xml:space="preserve">'''Neural Network Quantum States (NQS)''' is a general class of [[Variational_method_(quantum_mechanics)|variational]] [[quantum states]] parameterized in terms of an [[artificial neural network]]. It was first introduced in 2016 by the [[physicists]] [[Giuseppe Carleo]] and [[Matthias Troyer]] &lt;ref name="CarleoTroyer:2016" /&gt; to approximate [[wave functions]] of [[many-body]] [[quantum]] systems.

Given a [[many-body quantum state]] &lt;math&gt; |\Psi\rangle &lt;/math&gt; comprising &lt;math&gt; N &lt;/math&gt; degrees of freedom and a choice of associated quantum numbers &lt;math&gt; s_1 \ldots s_N &lt;/math&gt;, then an NQS parameterizes the wave-function amplitudes

&lt;math display="block"&gt;
\langle s_1 \ldots s_N |\Psi; W \rangle = F(s_1 \ldots s_N; W),
&lt;/math&gt;

where &lt;math&gt; F(s_1 \ldots s_N; W) &lt;/math&gt; is an [[artificial neural network]] of parameters (weights) &lt;math&gt; W &lt;/math&gt;, &lt;math&gt; N &lt;/math&gt; input variables (&lt;math&gt; s_1 \ldots s_N &lt;/math&gt; ) and one complex-valued output corresponding to the wave-function amplitude.

This variational form is used in conjunction with specific [[stochastic learning]] approaches to approximate quantum states of interest.

== Learning the Ground-State Wave Function ==

One common application of NQS is to find an approximate representation of the ground state [[wave function]] of a given [[Hamiltonian_(quantum_mechanics)|Hamiltonian]] &lt;math&gt; \hat{H} &lt;/math&gt;.
The learning procedure in this case consists in finding the best neural-network weights that minimize the variational energy

&lt;math display="block"&gt;
E(W) = \langle \Psi; W | \hat{H}|\Psi; W \rangle .
&lt;/math&gt;
 
Since, for a general artificial neural network, computing the expectation value is an exponentially costly operation in &lt;math&gt; N &lt;/math&gt;, stochastic techniques based, for example, on the [[Monte Carlo]] method are used to estimate &lt;math&gt; E(W) &lt;/math&gt;, analogously to what done in [[Variational Monte Carlo]], see for example &lt;ref name="BeccaSorella:2017"/&gt; for a review. 
More specifically, a set of &lt;math&gt; M &lt;/math&gt; samples &lt;math&gt; S^{(1)}, S^{(2)} \ldots S^{(M)} &lt;/math&gt;, with &lt;math&gt; S^{(i)}=s^{(i)}_1\ldots s^{(i)}_N &lt;/math&gt;, is generated such that they are uniformly distributed according to the [[Born rule|Born probability density]] &lt;math&gt; P(S) \propto |F(s_1 \ldots s_N; W)|^2 &lt;/math&gt;. Then it can be shown that the sample mean of the so-called "local energy" &lt;math&gt; E_{\mathrm{loc}}(S) = \langle S|\hat{H}|\Psi\rangle/ \langle S|\Psi\rangle &lt;/math&gt; is a statistical estimate of the quantum expectation value &lt;math&gt; E(W) &lt;/math&gt;, i.e.

&lt;math display="block"&gt;
E(W) \simeq \frac{1}{M} \sum_i^M E_{\mathrm{loc}}(S^{(i)}). 
&lt;/math&gt;

Similarly, it can be shown that the [[gradient]] of the energy with respect to the network weights &lt;math&gt; W &lt;/math&gt; is also approximated by a sample mean

&lt;math display="block"&gt;
\frac{\partial E(W)}{\partial W_k} \simeq \frac{1}{M} \sum_i^M (E_{\mathrm{loc}}(S^{(i)}) - E(W)) O^\star_k(S^{(i)}), 
&lt;/math&gt;

where &lt;math&gt; O(S^{(i)})= \frac{\partial \log F(S^{(i)};W)}{\partial W_k}&lt;/math&gt; and can be efficiently computed, in [[deep learning|deep networks]] through [[backpropagation]].

The stochastic approximation of the gradients is then used to minimize the energy &lt;math&gt; E(W) &lt;/math&gt; typically using a [[stochastic gradient descent]] approach. When the neural-network parameters are updated at each step of the learning procedure, a new set of samples &lt;math&gt; S^{(i)} &lt;/math&gt; is generated, in an iterative procedure similar to what done in [[unsupervised learning]].

== Connection with Tensor Networks ==

Neural-Network representations of quantum wave functions share some similarities with variational [[quantum states]] based on [[tensor networks]]. For example, connections with [[Matrix_product_state|matrix product states]] have been established.&lt;ref name="Chen:2018"/&gt; These studies have shown that NQS support volume law scaling for the [[entropy of entanglement]]. In general, given a NQS with fully-connected weights, it corresponds, in the worse case, to a [[matrix product state]] of exponentially large bond dimension in &lt;math&gt; N &lt;/math&gt;.

== References ==
{{reflist|refs=
&lt;ref name=CarleoTroyer:2016&gt;
{{cite journal
 |last1=Carleo |first1=Giuseppe
 |last2=Troyer |first2=Matthias
 |year=2017
 |title= Solving the quantum many-body problem with artificial neural networks
 |journal= Science
 |arxiv = 1606.02318
 |doi= 10.1126/science.aag2302
 |volume=355
 |pages=602–606
}}
&lt;/ref&gt;

&lt;ref name=BeccaSorella:2017&gt;
{{cite book 
| last1=Becca | first1=Federico
| last2=Sorella | first2=Sandro| 
title=Quantum Monte Carlo Approaches for Correlated Systems | publisher=Cambridge University Press|  date=2017 | isbn=9781316417041 | doi=10.1017/9781316417041  
}}
&lt;/ref&gt;

&lt;ref name=Chen:2018&gt;
{{cite journal
 |last1=Chen |first1=Jing
 |last2=Cheng |first2=Song
 |last3=Xie |first3=Haidong
 |last4=Wang |first4=Lei
 |last5=Xiang |first5=Tao
 |year=2018
 |title= Equivalence of restricted Boltzmann machines and tensor network states
 |journal= Phys. Rev. B
 |arxiv = 1701.04831
 |doi= 10.1103/PhysRevB.97.085104
 |volume=97
 |pages=085104
}}
&lt;/ref&gt;

}}

[[Category:Quantum mechanics]]
[[Category:Quantum Monte Carlo]]
[[Category:Machine learning]]</text>
      <sha1>axembncaspbjsgouuwxr76h59izuxqi</sha1>
    </revision>
  </page>
</mediawiki>
